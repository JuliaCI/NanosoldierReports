Julia Version 1.5.0-DEV.147
Commit e0740fe5a6 (2020-01-24 14:13 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed Missings ─────────── v0.4.3
 Installed GaussianMixtures ─── v0.3.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed LegacyStrings ────── v0.4.1
 Installed URIParser ────────── v0.4.0
 Installed Compat ───────────── v2.2.0
 Installed NearestNeighbors ─── v0.4.4
 Installed StatsBase ────────── v0.32.0
 Installed CMake ────────────── v1.1.2
 Installed OrderedCollections ─ v1.1.0
 Installed Arpack ───────────── v0.4.0
 Installed Distances ────────── v0.8.2
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed HDF5 ─────────────── v0.12.5
 Installed Distributions ────── v0.22.3
 Installed JLD ──────────────── v0.9.1
 Installed FillArrays ───────── v0.8.4
 Installed PDMats ───────────── v0.9.11
 Installed StatsFuns ────────── v0.9.3
 Installed DataAPI ──────────── v1.1.0
 Installed DataStructures ───── v0.17.9
 Installed StaticArrays ─────── v0.12.1
 Installed ScikitLearnBase ──── v0.5.0
 Installed QuadGK ───────────── v2.3.1
 Installed Arpack_jll ───────── v3.5.0+2
 Installed Rmath ────────────── v0.6.0
 Installed SpecialFunctions ─── v0.9.0
 Installed BinaryProvider ───── v0.5.8
 Installed BinDeps ──────────── v1.0.0
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed SortingAlgorithms ── v0.3.1
 Installed FileIO ───────────── v1.2.1
 Installed Blosc ────────────── v0.5.1
 Installed Parameters ───────── v0.12.0
 Installed Clustering ───────── v0.13.3
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_4f2dL7/Project.toml`
 [no changes]
  Updating `/tmp/jl_4f2dL7/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_nLKNZM/Project.toml`
 [no changes]
  Updating `/tmp/jl_nLKNZM/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_wRV1To/Project.toml`
 [no changes]
  Updating `/tmp/jl_wRV1To/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_pJMJHj/Project.toml`
 [no changes]
  Updating `/tmp/jl_pJMJHj/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_2ZBeGw/Project.toml`
 [no changes]
  Updating `/tmp/jl_2ZBeGw/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_2ZBeGw/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.11
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -3.588175278996516e6, [6.935171653343036, 99993.06482834666], [14.304528941344657 15.67159059798087 17.76190916768855; -380.2094396965749 282.180070765745 -18.528354448630658], [[31.09962199705156 32.402599520606294 36.23200590754272; 32.402599520606294 39.32798302048301 36.954213857638635; 36.23200590754272 36.95421385763864 48.23520209696846], [100093.00787415159 273.84072756984517 -274.3779804761672; 273.84072756984517 99772.21014830693 -92.58470961294725; -274.3779804761671 -92.58470961294725 100020.7933543761]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.520916e+03
      1       9.304078e+02      -5.905082e+02 |        5
      2       8.408260e+02      -8.958181e+01 |        4
      3       8.359929e+02      -4.833097e+00 |        2
      4       8.332553e+02      -2.737565e+00 |        0
      5       8.332553e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 833.2553307637004)
┌ Info: K-means with 272 data points using 5 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.063826
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.805457
[ Info: iteration 2, lowerbound -3.667128
[ Info: iteration 3, lowerbound -3.512009
[ Info: iteration 4, lowerbound -3.334052
[ Info: iteration 5, lowerbound -3.159907
[ Info: iteration 6, lowerbound -3.017176
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.917097
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.842390
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.783221
[ Info: iteration 10, lowerbound -2.731852
[ Info: iteration 11, lowerbound -2.692820
[ Info: iteration 12, lowerbound -2.656967
[ Info: iteration 13, lowerbound -2.622813
[ Info: iteration 14, lowerbound -2.591283
[ Info: iteration 15, lowerbound -2.564818
[ Info: dropping number of Gaussions to 3
[ Info: iteration 16, lowerbound -2.535463
[ Info: iteration 17, lowerbound -2.495304
[ Info: iteration 18, lowerbound -2.449591
[ Info: iteration 19, lowerbound -2.401693
[ Info: iteration 20, lowerbound -2.360091
[ Info: iteration 21, lowerbound -2.329068
[ Info: iteration 22, lowerbound -2.311066
[ Info: iteration 23, lowerbound -2.308090
[ Info: dropping number of Gaussions to 2
[ Info: iteration 24, lowerbound -2.302917
[ Info: iteration 25, lowerbound -2.299260
[ Info: iteration 26, lowerbound -2.299256
[ Info: iteration 27, lowerbound -2.299254
[ Info: iteration 28, lowerbound -2.299254
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sat Jan 25 11:06:36 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sat Jan 25 11:06:45 2020: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Sat Jan 25 11:06:47 2020: EM with 272 data points 0 iterations avll -2.063826
5.8 data points per parameter
, Sat Jan 25 11:06:49 2020: GMM converted to Variational GMM
, Sat Jan 25 11:06:57 2020: iteration 1, lowerbound -3.805457
, Sat Jan 25 11:06:57 2020: iteration 2, lowerbound -3.667128
, Sat Jan 25 11:06:57 2020: iteration 3, lowerbound -3.512009
, Sat Jan 25 11:06:57 2020: iteration 4, lowerbound -3.334052
, Sat Jan 25 11:06:57 2020: iteration 5, lowerbound -3.159907
, Sat Jan 25 11:06:57 2020: iteration 6, lowerbound -3.017176
, Sat Jan 25 11:06:58 2020: dropping number of Gaussions to 7
, Sat Jan 25 11:06:58 2020: iteration 7, lowerbound -2.917097
, Sat Jan 25 11:06:58 2020: dropping number of Gaussions to 6
, Sat Jan 25 11:06:58 2020: iteration 8, lowerbound -2.842390
, Sat Jan 25 11:06:58 2020: dropping number of Gaussions to 4
, Sat Jan 25 11:06:58 2020: iteration 9, lowerbound -2.783221
, Sat Jan 25 11:06:58 2020: iteration 10, lowerbound -2.731852
, Sat Jan 25 11:06:58 2020: iteration 11, lowerbound -2.692820
, Sat Jan 25 11:06:58 2020: iteration 12, lowerbound -2.656967
, Sat Jan 25 11:06:58 2020: iteration 13, lowerbound -2.622813
, Sat Jan 25 11:06:58 2020: iteration 14, lowerbound -2.591283
, Sat Jan 25 11:06:58 2020: iteration 15, lowerbound -2.564818
, Sat Jan 25 11:06:58 2020: dropping number of Gaussions to 3
, Sat Jan 25 11:06:58 2020: iteration 16, lowerbound -2.535463
, Sat Jan 25 11:06:58 2020: iteration 17, lowerbound -2.495304
, Sat Jan 25 11:06:58 2020: iteration 18, lowerbound -2.449591
, Sat Jan 25 11:06:58 2020: iteration 19, lowerbound -2.401693
, Sat Jan 25 11:06:58 2020: iteration 20, lowerbound -2.360091
, Sat Jan 25 11:06:58 2020: iteration 21, lowerbound -2.329068
, Sat Jan 25 11:06:58 2020: iteration 22, lowerbound -2.311066
, Sat Jan 25 11:06:58 2020: iteration 23, lowerbound -2.308090
, Sat Jan 25 11:06:58 2020: dropping number of Gaussions to 2
, Sat Jan 25 11:06:58 2020: iteration 24, lowerbound -2.302917
, Sat Jan 25 11:06:58 2020: iteration 25, lowerbound -2.299260
, Sat Jan 25 11:06:58 2020: iteration 26, lowerbound -2.299256
, Sat Jan 25 11:06:58 2020: iteration 27, lowerbound -2.299254
, Sat Jan 25 11:06:58 2020: iteration 28, lowerbound -2.299254
, Sat Jan 25 11:06:58 2020: iteration 29, lowerbound -2.299253
, Sat Jan 25 11:06:58 2020: iteration 30, lowerbound -2.299253
, Sat Jan 25 11:06:58 2020: iteration 31, lowerbound -2.299253
, Sat Jan 25 11:06:58 2020: iteration 32, lowerbound -2.299253
, Sat Jan 25 11:06:58 2020: iteration 33, lowerbound -2.299253
, Sat Jan 25 11:06:58 2020: iteration 34, lowerbound -2.299253
, Sat Jan 25 11:06:58 2020: iteration 35, lowerbound -2.299253
, Sat Jan 25 11:06:58 2020: iteration 36, lowerbound -2.299253
, Sat Jan 25 11:06:58 2020: iteration 37, lowerbound -2.299253
, Sat Jan 25 11:06:58 2020: iteration 38, lowerbound -2.299253
, Sat Jan 25 11:06:58 2020: iteration 39, lowerbound -2.299253
, Sat Jan 25 11:06:58 2020: iteration 40, lowerbound -2.299253
, Sat Jan 25 11:06:58 2020: iteration 41, lowerbound -2.299253
, Sat Jan 25 11:06:58 2020: iteration 42, lowerbound -2.299253
, Sat Jan 25 11:06:58 2020: iteration 43, lowerbound -2.299253
, Sat Jan 25 11:06:58 2020: iteration 44, lowerbound -2.299253
, Sat Jan 25 11:06:58 2020: iteration 45, lowerbound -2.299253
, Sat Jan 25 11:06:58 2020: iteration 46, lowerbound -2.299253
, Sat Jan 25 11:06:58 2020: iteration 47, lowerbound -2.299253
, Sat Jan 25 11:06:58 2020: iteration 48, lowerbound -2.299253
, Sat Jan 25 11:06:58 2020: iteration 49, lowerbound -2.299253
, Sat Jan 25 11:06:58 2020: iteration 50, lowerbound -2.299253
, Sat Jan 25 11:06:58 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777397305, 178.04509222602695]
β = [95.95490777397305, 178.04509222602695]
m = [2.000229257775261 53.85198717246073; 4.250300733269805 79.28686694436027]
ν = [97.95490777397305, 180.04509222602695]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.37587636119502266 -0.00895312382734798; 0.0 0.012748664777409902], [0.1840415554748329 -0.007644049042328437; 0.0 0.008581705166331437]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000003
avll from stats: -0.9923378093549512
avll from llpg:  -0.9923378093549512
avll direct:     -0.9923378093549513
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.975192073446394
avll from llpg:  -0.9751920734463938
avll direct:     -0.9751920734463938
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.0768649   -0.0248577   -0.0599395   -0.243132    -0.0860375    0.212785      0.0220526     0.161025     -0.220647     -0.246752      0.0265667  -0.103594    -0.0995638    0.058865     0.130114     0.0517134   -0.124566    -0.0954714   0.182235    -0.00970526   -0.0551362     0.237084    -0.182297    -0.030107      0.0136252   -0.0348879
 -0.113605     0.0572857    0.13546     -0.0441304    0.0707756   -0.239337     -0.0332111     0.00288057   -0.0747837    -0.00264951   -0.103846    0.00902488  -0.0181008   -0.0411534   -0.183926     0.0529611   -0.0338837    0.0977392  -0.159575    -0.048854     -0.117621      0.103023    -0.0276425   -0.101011      0.140323     0.149415
  0.114057     0.0902789    0.0153939   -0.0667609   -0.0351339    0.0135842     0.0199199     0.0815296    -0.158753      0.120705     -0.08955    -0.0862237   -0.149864     0.124474    -0.0965815   -0.0700228   -0.0502509   -0.0314531  -0.266438    -0.107609      0.126896      0.010654    -0.0478558   -0.18642      -0.0536801    0.132571
  0.0241912   -0.0722557   -0.0789246    0.0759982    0.0779033   -0.0131085    -0.229966     -0.153129     -0.0916438    -0.00560583    0.0267664   0.156867     0.0490783    0.0728534   -0.0362273   -0.0123105   -0.122005    -0.0863665   0.161894     0.0360446     0.196718      0.0760268   -0.0612796    0.0143015     0.0501122   -0.0288564
  0.0242359    0.307882    -0.0372463   -0.130046     0.0227881    0.203806      0.0554836     0.0938708     0.0245525     0.114741     -0.0838963   0.00686798  -0.0191629    0.0470508   -0.0496505    0.0274219   -0.129984    -0.0347046   0.127313     0.15329       0.169712      0.167335     0.0610527    0.122209     -0.0245801   -0.0709945
  0.0889909    0.0972422   -0.107954    -0.0423573   -0.0112312    0.231551      0.00803671    0.000625485   0.0992215     0.245006      0.0821665  -0.01559     -0.136066    -0.182015     0.136195    -0.0800342    0.0209871   -0.0329452  -0.0542432   -0.0199799    -0.27616      -0.0470908   -0.251692     0.0380308    -0.0639352   -0.0230763
 -0.113385    -0.0178849   -0.00276591   0.00566832  -0.0282117   -0.0454463    -0.0569276    -0.0184857     0.000326156  -0.178667     -0.113294    0.101777     0.0626809    0.0131638    0.0246565   -0.0334917    0.0932674   -0.111391   -0.0291259   -0.088763      0.0785746    -0.152287     0.0252448   -0.0154223     0.227828     0.127544
 -0.0909087    0.0683545    0.158272     0.0153459    0.0606377   -0.125415      0.0744004    -0.00784634    0.0210324     0.0294133    -0.294559    0.200409    -0.0799501   -0.260483     0.0171137    0.131754    -0.0759597   -0.20553    -0.0616573   -0.000556307  -0.0404666     0.160417    -0.0321373    0.00758628   -0.0820238   -0.0415152
  0.0919271   -0.00432961   0.0394427    0.156689    -0.0436397   -0.0926798    -0.108548      0.0206275    -0.0624924    -0.0681203    -0.151745    0.0482371    0.00560598  -0.0812967   -0.11122      0.157352     0.0931004    0.0537725   0.0771872    0.0648183    -0.107227     -0.064122    -0.076053     0.154647      0.283792     0.0420391
 -0.0258995    0.012738    -0.171914     0.0744988   -0.106298     0.194392      0.111333     -0.227719      0.0487916     0.0471        0.102762    0.0952917    0.00331919   0.21819      0.00650452  -0.053796    -0.0827232    0.0649146  -0.111851    -0.0477892    -0.0313       -0.112962     0.0886367    0.0435821     0.159766    -0.0764503
 -0.0151045   -0.0495903   -0.00400307  -0.124982     0.0276415   -0.209985     -0.163886     -0.231155      0.145306     -0.0256604    -0.031125    0.110886     0.0169428   -0.0398395   -0.0430071   -0.0972886    0.0407811    0.044448   -0.170458     0.0276361    -0.1286       -0.0527597   -0.00340188  -0.00158459    0.316321    -0.0288785
 -0.0697948    0.0140937   -0.106955     0.0363819   -0.265332     0.0137995     0.143651      0.0860571    -0.00182394   -0.125228      0.0720144   0.0842055   -0.0322111    0.0428461   -0.0408719    0.125103     0.0224637   -0.129779   -0.0213568   -0.161196     -0.0304265    -0.00884089   0.121762    -0.0738425    -0.0967228    0.0929367
 -0.249163    -0.139258     0.115773    -0.128274     0.0516877    0.000885092   0.0900933     0.066853     -0.0355879     0.0335542    -0.0182108  -0.250768     0.0737922   -0.122359     0.0836308   -0.0294109    0.05872      0.0264705   0.0780042   -0.0598786    -0.142887     -0.00920323   0.158844     0.0624928     0.267148    -0.0325953
  0.065925     0.125829     0.131035    -0.0306507   -0.180357    -0.0815311     0.0576293     0.0581398    -0.0138858     0.0339928    -0.0685016   0.043897    -0.129279    -0.0869895   -0.0187798    0.0401524    0.090916     0.0750459  -0.0834204    0.0478917    -0.0464685    -0.0273687   -0.0321477    0.0453129    -0.0370074    0.0209613
  0.0229826   -0.0443869   -0.077959     0.00922974   0.122997     0.182256      0.0348163    -0.0815937    -0.0620511    -0.264996      0.108193   -0.0253356   -0.014606     0.133465     0.0558947    0.0421407   -0.116069     0.0459478   0.0508836   -0.230214      0.0549597    -0.031649    -0.126554    -0.120337     -0.140491     0.0511938
  0.18193     -0.0620183    0.0238952   -0.0263623    0.00616886  -0.139422      0.16123       0.0799419     0.0334619     0.163789     -0.143542   -0.153258    -0.0457218   -0.00338137  -0.012568    -0.180102     0.104791    -0.0420473  -0.125493     0.0757642     0.0553683    -0.0496742   -0.0907821    0.0324748    -0.155668    -0.00214644
 -0.148787    -0.0524356    0.220437    -0.107147    -0.298487     0.00402912    0.0397772    -0.16553      -0.0244227    -0.0596205    -0.0462661  -0.0132921   -0.188747    -0.0196265   -0.0178797    0.0118452   -0.0460043   -0.0396648   0.063293    -0.157353     -0.00238238    0.0226144   -0.111661     0.0514603    -0.0649864    0.0683234
  0.0636157   -0.0200322   -0.0625257   -0.0752646   -0.0897019    0.0833981     0.0489036    -0.170573      0.0249482     0.00736706   -0.0536779   0.0275127    0.0551773   -0.223258     0.0172762    0.00373628  -0.0479881   -0.0491665   0.0785195    0.104739     -0.115611     -0.0901177    0.0881667    0.153731      0.0869758   -0.00102105
  0.0338956    0.0756298    0.0993614   -0.0906845   -0.0451627   -0.00121058   -0.0759877    -0.11492      -0.0147201     0.109122     -0.0362266  -0.0550743   -0.179333    -0.273254     0.203244    -0.0862677   -0.0795937   -0.064766   -0.143611     0.0104024    -0.0124746    -0.279328    -0.176228     0.0168599     0.00458192   0.0259551
  0.0317971    0.0711978    0.121756     0.294969    -0.0564018    0.0439059     0.105539     -0.0892123     0.135275     -0.0526427     0.120494    0.022406    -0.199987    -0.0916419   -0.156083     0.251197    -0.190827    -0.15332    -0.0865484   -0.157546     -0.0522244    -0.0583954    0.0934612    0.131787     -0.143146    -0.0764623
  0.102859     0.304638    -0.091051    -0.111749     0.169788     0.206155     -0.131486     -0.121063     -0.146233     -0.114936     -0.0584639   0.0265121   -0.0570533   -0.0750293    0.0582219   -0.0442566   -0.0466792    0.0604072   0.128443     0.170719     -0.0826343     0.101083     0.0115019   -0.000822616   0.0116119    0.0367894
 -0.0806371   -0.0995097   -0.0266155   -0.156289    -0.0919209   -0.0313245     0.0983037     0.109312      0.0718599     0.161473     -0.0428015   0.0563291   -0.184718    -0.158285    -0.105547     0.0548963    0.0902593    0.0220487  -0.0116855   -0.0729206     0.0492458    -0.115436     0.0654906    0.0774765    -0.0699536   -0.000361887
  0.158435    -0.080021    -0.0303475    0.0425799   -0.0192925   -0.153209      0.0885531    -0.0488767     0.0396792    -0.0813362     0.0788681   0.115115    -0.0789058   -0.191109     0.161991     0.00580982  -0.00346938  -0.0215443   0.0474421    0.0666435    -0.0595112     0.0438287    0.056596    -0.0751139     0.120715     0.0218079
  0.0442644   -0.0898256    0.0429156    0.0333081    0.125758    -0.127415     -0.0257246     0.00822235    0.0465428    -0.0758515     0.165319   -0.0542521   -0.0147131    0.0300012    0.147299     0.0603618   -0.0893187   -0.0301182  -0.142587     0.0316242    -0.000674371   0.0264523    0.0187072    0.184104      0.0774741   -0.0489809
 -0.00693645  -0.0399654   -0.0397833    0.0993288    0.0106678   -0.170339     -0.00209313    0.115943     -0.0866724    -0.0945957     0.125519   -0.0940741   -0.116601    -0.122176    -0.0254528    0.124455     0.15019     -0.142813   -0.0615924    0.161196      0.0250048    -0.150211     0.035775    -0.255813     -0.0202135    0.149247
  0.0057149    0.00948953   0.0837966    0.0372003    0.151385     0.113668     -0.000948432  -0.0625183    -0.0108454     0.0635087    -0.0392209   0.055938    -0.0501378   -0.210371    -0.0267641   -0.157062    -0.0546952    0.0157057  -0.116608     0.0983433     0.033998      0.0913736    0.234139     0.0971222     0.0276915    0.0441371
 -0.0807415    0.128899    -0.146432    -0.00904616  -0.137981     0.100396      0.0455129     0.0372087     0.0188133    -0.074934      0.124847   -0.102972    -0.141238     0.0541518    0.116099    -0.0390647    0.187465    -0.0770774  -0.270892    -0.00909307    0.200108      0.163041    -0.174401     0.036298     -0.149747    -0.186315
  0.00514229  -0.136487    -0.0556862    0.0415957    0.195339    -0.157434      0.0405672     0.0375328     0.0338264     0.000941477   0.0475311  -0.0351978    0.0960253    0.113186     0.12879     -0.0820575    0.0640844    0.0811304  -0.0526829    0.0560646     0.0751372     0.10912      0.0134477    0.145674     -0.0402838    0.0449146
 -0.0482444   -0.0622786    0.084757     0.158838    -0.0207283   -0.109574      0.327227     -0.0535939    -0.0254591    -0.0327025    -0.0608607   0.0100225   -0.16637     -0.162228    -0.161726     0.0013648    0.0862321   -0.074389   -0.00318835   0.026165     -0.0275066     0.167803    -0.0137293    0.192596      0.154527    -0.00587005
  0.068969    -0.0293523    0.193331     0.0237942    0.0335297   -0.141504     -0.0982899    -0.00142697   -0.00726924   -0.0175848    -0.160829    0.0183384   -0.0881671    0.0122677   -0.0643054   -0.0194311    0.138599    -0.149069   -0.052156    -0.0690003    -0.00359042   -0.159655     0.170117    -0.0954958    -0.109734    -0.0436882
 -0.0180278    0.0646074    0.156128     0.0261767    0.0754895   -0.148915      0.0368861     0.119248     -0.172025     -0.0707357     0.0729068  -0.0530596   -0.114852     0.032512    -0.0405395    0.052884     0.162094     0.0449773   0.0572081   -0.201742      0.109919     -0.0322018    0.175656    -0.0322389    -0.0489049    0.194171
  0.0323158    0.0752677    0.132605    -0.113218    -0.0147606   -0.108185      0.127195     -0.149586     -0.0284018     0.00198126    0.0560712   0.0376708   -0.0684192   -0.0858976    0.239305     0.0281071    0.0116287   -0.125298    0.113349    -0.0238207    -0.0783332     0.0773206   -0.149232     0.0692513    -0.0126452    0.00959069kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.380534166601934
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.380607
[ Info: iteration 2, average log likelihood -1.380523
[ Info: iteration 3, average log likelihood -1.380133
[ Info: iteration 4, average log likelihood -1.376150
[ Info: iteration 5, average log likelihood -1.361749
[ Info: iteration 6, average log likelihood -1.352920
[ Info: iteration 7, average log likelihood -1.351505
[ Info: iteration 8, average log likelihood -1.351009
[ Info: iteration 9, average log likelihood -1.350737
[ Info: iteration 10, average log likelihood -1.350572
[ Info: iteration 11, average log likelihood -1.350460
[ Info: iteration 12, average log likelihood -1.350373
[ Info: iteration 13, average log likelihood -1.350297
[ Info: iteration 14, average log likelihood -1.350224
[ Info: iteration 15, average log likelihood -1.350148
[ Info: iteration 16, average log likelihood -1.350067
[ Info: iteration 17, average log likelihood -1.349982
[ Info: iteration 18, average log likelihood -1.349890
[ Info: iteration 19, average log likelihood -1.349793
[ Info: iteration 20, average log likelihood -1.349690
[ Info: iteration 21, average log likelihood -1.349581
[ Info: iteration 22, average log likelihood -1.349461
[ Info: iteration 23, average log likelihood -1.349317
[ Info: iteration 24, average log likelihood -1.349144
[ Info: iteration 25, average log likelihood -1.348957
[ Info: iteration 26, average log likelihood -1.348788
[ Info: iteration 27, average log likelihood -1.348650
[ Info: iteration 28, average log likelihood -1.348537
[ Info: iteration 29, average log likelihood -1.348447
[ Info: iteration 30, average log likelihood -1.348376
[ Info: iteration 31, average log likelihood -1.348320
[ Info: iteration 32, average log likelihood -1.348276
[ Info: iteration 33, average log likelihood -1.348241
[ Info: iteration 34, average log likelihood -1.348213
[ Info: iteration 35, average log likelihood -1.348191
[ Info: iteration 36, average log likelihood -1.348173
[ Info: iteration 37, average log likelihood -1.348158
[ Info: iteration 38, average log likelihood -1.348145
[ Info: iteration 39, average log likelihood -1.348135
[ Info: iteration 40, average log likelihood -1.348127
[ Info: iteration 41, average log likelihood -1.348120
[ Info: iteration 42, average log likelihood -1.348114
[ Info: iteration 43, average log likelihood -1.348110
[ Info: iteration 44, average log likelihood -1.348106
[ Info: iteration 45, average log likelihood -1.348102
[ Info: iteration 46, average log likelihood -1.348100
[ Info: iteration 47, average log likelihood -1.348097
[ Info: iteration 48, average log likelihood -1.348096
[ Info: iteration 49, average log likelihood -1.348094
[ Info: iteration 50, average log likelihood -1.348093
┌ Info: EM with 100000 data points 50 iterations avll -1.348093
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3806073724539913
│     -1.380523219143175
│      ⋮
└     -1.348092713910771
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.348204
[ Info: iteration 2, average log likelihood -1.348080
[ Info: iteration 3, average log likelihood -1.347637
[ Info: iteration 4, average log likelihood -1.343993
[ Info: iteration 5, average log likelihood -1.331961
[ Info: iteration 6, average log likelihood -1.321401
[ Info: iteration 7, average log likelihood -1.317540
[ Info: iteration 8, average log likelihood -1.316002
[ Info: iteration 9, average log likelihood -1.315105
[ Info: iteration 10, average log likelihood -1.314386
[ Info: iteration 11, average log likelihood -1.313698
[ Info: iteration 12, average log likelihood -1.313012
[ Info: iteration 13, average log likelihood -1.312352
[ Info: iteration 14, average log likelihood -1.311752
[ Info: iteration 15, average log likelihood -1.311244
[ Info: iteration 16, average log likelihood -1.310826
[ Info: iteration 17, average log likelihood -1.310474
[ Info: iteration 18, average log likelihood -1.310168
[ Info: iteration 19, average log likelihood -1.309894
[ Info: iteration 20, average log likelihood -1.309642
[ Info: iteration 21, average log likelihood -1.309404
[ Info: iteration 22, average log likelihood -1.309176
[ Info: iteration 23, average log likelihood -1.308946
[ Info: iteration 24, average log likelihood -1.308719
[ Info: iteration 25, average log likelihood -1.308523
[ Info: iteration 26, average log likelihood -1.308392
[ Info: iteration 27, average log likelihood -1.308295
[ Info: iteration 28, average log likelihood -1.308207
[ Info: iteration 29, average log likelihood -1.308124
[ Info: iteration 30, average log likelihood -1.308044
[ Info: iteration 31, average log likelihood -1.307968
[ Info: iteration 32, average log likelihood -1.307895
[ Info: iteration 33, average log likelihood -1.307824
[ Info: iteration 34, average log likelihood -1.307757
[ Info: iteration 35, average log likelihood -1.307694
[ Info: iteration 36, average log likelihood -1.307637
[ Info: iteration 37, average log likelihood -1.307582
[ Info: iteration 38, average log likelihood -1.307528
[ Info: iteration 39, average log likelihood -1.307475
[ Info: iteration 40, average log likelihood -1.307421
[ Info: iteration 41, average log likelihood -1.307369
[ Info: iteration 42, average log likelihood -1.307320
[ Info: iteration 43, average log likelihood -1.307273
[ Info: iteration 44, average log likelihood -1.307229
[ Info: iteration 45, average log likelihood -1.307188
[ Info: iteration 46, average log likelihood -1.307150
[ Info: iteration 47, average log likelihood -1.307115
[ Info: iteration 48, average log likelihood -1.307083
[ Info: iteration 49, average log likelihood -1.307053
[ Info: iteration 50, average log likelihood -1.307026
┌ Info: EM with 100000 data points 50 iterations avll -1.307026
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3482042413837072
│     -1.348080398092224
│      ⋮
└     -1.3070257166530361
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.307164
[ Info: iteration 2, average log likelihood -1.306986
[ Info: iteration 3, average log likelihood -1.306560
[ Info: iteration 4, average log likelihood -1.302357
[ Info: iteration 5, average log likelihood -1.286033
[ Info: iteration 6, average log likelihood -1.270139
[ Info: iteration 7, average log likelihood -1.263746
[ Info: iteration 8, average log likelihood -1.261179
[ Info: iteration 9, average log likelihood -1.259696
[ Info: iteration 10, average log likelihood -1.258501
[ Info: iteration 11, average log likelihood -1.257285
[ Info: iteration 12, average log likelihood -1.255975
[ Info: iteration 13, average log likelihood -1.254760
[ Info: iteration 14, average log likelihood -1.253876
[ Info: iteration 15, average log likelihood -1.253387
[ Info: iteration 16, average log likelihood -1.253146
[ Info: iteration 17, average log likelihood -1.253008
[ Info: iteration 18, average log likelihood -1.252909
[ Info: iteration 19, average log likelihood -1.252828
[ Info: iteration 20, average log likelihood -1.252755
[ Info: iteration 21, average log likelihood -1.252683
[ Info: iteration 22, average log likelihood -1.252605
[ Info: iteration 23, average log likelihood -1.252517
[ Info: iteration 24, average log likelihood -1.252415
[ Info: iteration 25, average log likelihood -1.252301
[ Info: iteration 26, average log likelihood -1.252181
[ Info: iteration 27, average log likelihood -1.252065
[ Info: iteration 28, average log likelihood -1.251962
[ Info: iteration 29, average log likelihood -1.251880
[ Info: iteration 30, average log likelihood -1.251823
[ Info: iteration 31, average log likelihood -1.251785
[ Info: iteration 32, average log likelihood -1.251759
[ Info: iteration 33, average log likelihood -1.251742
[ Info: iteration 34, average log likelihood -1.251728
[ Info: iteration 35, average log likelihood -1.251716
[ Info: iteration 36, average log likelihood -1.251706
[ Info: iteration 37, average log likelihood -1.251696
[ Info: iteration 38, average log likelihood -1.251687
[ Info: iteration 39, average log likelihood -1.251679
[ Info: iteration 40, average log likelihood -1.251671
[ Info: iteration 41, average log likelihood -1.251664
[ Info: iteration 42, average log likelihood -1.251658
[ Info: iteration 43, average log likelihood -1.251652
[ Info: iteration 44, average log likelihood -1.251646
[ Info: iteration 45, average log likelihood -1.251640
[ Info: iteration 46, average log likelihood -1.251635
[ Info: iteration 47, average log likelihood -1.251630
[ Info: iteration 48, average log likelihood -1.251625
[ Info: iteration 49, average log likelihood -1.251620
[ Info: iteration 50, average log likelihood -1.251615
┌ Info: EM with 100000 data points 50 iterations avll -1.251615
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3071644407439114
│     -1.3069863111204367
│      ⋮
└     -1.2516150085838076
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.251829
[ Info: iteration 2, average log likelihood -1.251575
[ Info: iteration 3, average log likelihood -1.250514
[ Info: iteration 4, average log likelihood -1.240762
[ Info: iteration 5, average log likelihood -1.209083
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     1
│     3
│     5
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.168515
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.181507
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.176840
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      3
│      5
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.157533
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     1
│     4
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.178549
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.189931
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     1
│     3
│     5
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.156815
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.174860
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.170523
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      3
│      5
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.153231
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     1
│     4
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.176035
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.187997
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     1
│     3
│     5
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.155324
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.173965
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.170064
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      3
│      5
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.152983
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     1
│     4
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.175571
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.187662
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     1
│     3
│     5
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.154934
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.173695
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.169742
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      3
│      5
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.152728
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     1
│     4
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.175504
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.187585
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     1
│     3
│     5
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.154841
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.173633
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.169679
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      3
│      5
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.152668
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     1
│     4
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.175483
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.187539
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     1
│     3
│     5
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.154796
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.173609
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.169663
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      3
│      5
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.152647
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     1
│     4
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.175470
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.187503
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     1
│     3
│     5
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.154763
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.173592
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.169653
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      3
│      5
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.152633
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     1
│     4
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.175462
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.187477
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     1
│     3
│     5
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.154739
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.173582
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.169649
┌ Info: EM with 100000 data points 50 iterations avll -1.169649
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2518286020872205
│     -1.2515745756423973
│      ⋮
└     -1.1696489937694605
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      9
│     10
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.152878
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     14
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.132730
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      9
│     10
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.150964
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.115645
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      9
│     10
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.117900
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.072244
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     10
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.094961
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     19
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.059850
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.086445
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.073771
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     10
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.081675
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.056646
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     19
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.091221
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.065537
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.088180
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.075518
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.079117
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.063978
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     10
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.094385
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.059490
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.075525
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.064221
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.084733
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.079284
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     10
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.089059
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.056904
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.078246
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.070349
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     10
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.093358
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.061907
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     10
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.082816
┌ Warning: Variances had to be floored 
│   ind =
│    20-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.048848
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.098017
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.075867
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.088986
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.062139
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.074009
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.082933
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.085721
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.063610
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.076407
┌ Warning: Variances had to be floored 
│   ind =
│    20-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.051672
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.096599
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.074659
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     10
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.089144
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.057995
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.088813
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.068804
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.083698
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.061342
┌ Info: EM with 100000 data points 50 iterations avll -1.061342
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1528779901024966
│     -1.132730157565951
│      ⋮
└     -1.0613417579498012
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.380534166601934
│     -1.3806073724539913
│     -1.380523219143175
│     -1.380132642865844
│      ⋮
│     -1.0688035079103917
│     -1.0836977635664533
└     -1.0613417579498012
32×26 Array{Float64,2}:
  0.0262569    0.340002    -0.0404751   -0.188539    -0.523278     0.203625     0.0616341     0.0940959    0.0254151    0.117751    -0.0835443   0.0172571   -0.0539106    0.0609018   -0.0760025    0.0153169  -0.1314      -0.089933     0.125082      0.128803     0.175538     0.152226     0.0611051    0.117854    -0.0263199   -0.147512
  0.0176348    0.267854    -0.0443425   -0.102923     0.464449     0.204445     0.0699777     0.0891967    0.0243215    0.112844    -0.0925665   0.00988249  -6.30567e-5   0.0503053   -0.0728866    0.0412279  -0.129578    -0.016415     0.12806       0.165917     0.170494     0.187386     0.061018     0.0981652   -0.0265968    0.0035365
 -0.0574273   -0.0844915   -0.101757     0.0686378    0.0698951   -0.0121611   -0.228481     -0.231015    -0.0915035   -0.00808705  -0.0284686   0.166422     0.0405242    0.00173604   0.0258248    0.0200621  -0.271092    -0.0442954    0.0641944     0.0442725    0.266559     0.06113     -0.0681538   -0.00547366  -0.102442    -0.364129
  0.0848075   -0.0703554   -0.0469729    0.0810624    0.0780461   -0.0122235   -0.227887     -0.0531727   -0.0919603   -0.00897732   0.0324847   0.15106      0.0449951    0.115922     0.00608025  -0.0621951  -0.0371391   -0.0301289    0.258079      0.0356893    0.127014     0.0746776   -0.0490442    0.0321874    0.209113     0.304849
  0.0199312   -0.302026     0.0668866    0.109386     0.195687     0.0962123   -0.00166176   -0.0320452   -0.0111039    0.0689388    0.0599011   0.0776613   -0.0282161   -0.206814    -0.0396527   -0.149773   -0.0636074    0.00818983  -0.117667     -0.194247    -0.294982     0.104255     0.233901     0.0973591    0.0381224    0.0471855
 -0.0143141    0.36653      0.10127      0.00214974   0.101751     0.166208    -0.000871068  -0.0804083   -0.0115481    0.0580527   -0.125811    0.0551359   -0.114912    -0.226       -0.0256471   -0.144038   -0.0473416    0.0578264   -0.0948347     0.401338     0.368781     0.083189     0.24573      0.0966751    0.0168367    0.0390188
  0.112842     0.303453    -0.0902664   -0.108737     0.185052     0.261714    -0.134909     -0.130707    -0.141746    -0.1141      -0.0635883  -0.0331909   -0.0574249   -0.0751727    0.0212649   -0.297886   -0.0779481    0.0573391    0.118572      0.142047    -0.0882267    0.0791696    0.00810647  -0.0916722    0.0133452    0.00903358
  0.0829775    0.303437    -0.0901329   -0.121162     0.115115     0.178927    -0.126108     -0.12324     -0.165556    -0.115459    -0.0613261   0.138745    -0.0563676   -0.0656395    0.1035       0.608318   -0.0880421    0.0636495    0.142245      0.15075     -0.0800563    0.13355      0.0346634    0.139826     0.0114264    0.0913521
  0.137847     0.107118     0.0797497   -0.0730669   -0.014244    -0.105257     0.0900259     0.111841    -0.161666     0.139854    -0.0294309  -0.0886516   -0.70414      0.159794    -0.0966068   -0.0738924  -0.0119794   -0.122491    -0.266038     -0.115834     0.142581     0.00558518  -0.0480169   -0.227992    -0.145607     0.132582
  0.0666198    0.120298    -0.0183002   -0.0695168   -0.0522493    0.147862    -0.0319817     0.0807181   -0.161671     0.10438     -0.106836   -0.0865021    0.34365      0.0927194   -0.0964956   -0.0543722  -0.0766915    0.0681783   -0.267762     -0.114272     0.126443     0.00815657  -0.0478756   -0.121176     0.00752308   0.118746
  0.201878     0.0924742   -0.104983    -0.185631    -0.0125378    0.286163     0.010343      0.00630875   0.0224472    0.145934     0.0807696   0.0986105   -0.183001    -1.11996      0.141941    -0.0490206  -0.00203082   0.290433    -0.0417855     0.1004      -0.275963    -0.124649    -0.252145     0.0031061   -0.0639885   -0.0127958
  0.0240839    0.0950439   -0.099065    -0.0171133   -0.0172033    0.199759     0.00963732    0.00449471   0.131156     0.271928     0.0907868  -0.0833147   -0.136115     0.277446     0.137981    -0.0718431   0.0210519   -0.238188    -0.0930617    -0.0756      -0.275081     0.0249454   -0.251649     0.0430347   -0.063713    -0.0339382
 -0.0687257    0.141247    -0.190568    -0.0105617   -0.12793      0.104598     0.0515319     0.0289925    0.0204798   -0.080675     0.127748   -0.085121    -0.141573     0.0726047    0.121802    -1.28093     0.18734     -0.104788    -0.286308     -0.00892487   0.193457     0.308038    -0.215095     0.0475045   -0.167314    -0.174772
 -0.112041     0.141146    -0.0869563   -0.0154632   -0.1182       0.0992751    0.0430481     0.0419097    0.0189963   -0.0753075    0.122999   -0.111111    -0.141661     0.0730465    0.120084     1.10766     0.18768     -0.0618295   -0.249937     -0.0110049    0.196998     0.0591209   -0.115526     0.0292698   -0.129336    -0.201774
  0.0152895   -0.128065    -0.0899634    0.0355159    0.196638    -0.155859     0.044383      0.0192808    0.0191871    0.0348477    0.0443108  -0.0344828    0.0935045    0.138567     0.124851    -0.0841972   0.0641273    0.075415    -0.0219373     0.0558223    0.0627461    0.0957463    0.0204255    0.0857164   -0.0402735    0.0312884
  0.0681631    0.0664866    0.157164    -0.117728    -0.0157187   -0.107669     0.12465      -0.14903     -0.00693921   0.0111154    0.0395494   0.0242457   -0.0635699   -0.100003     0.237244     0.0279646   0.0124347   -0.136584     0.108509     -0.0234666   -0.0724266    0.0901204   -0.135827     0.0750272   -0.00940843   0.0147237
  0.035443    -0.0289729    0.0272564   -0.00214842   0.0394802   -0.0835966    0.0457062     0.00113246  -0.0250106   -0.0464675    0.0728519  -0.0747832   -0.0560939   -0.0404915    0.0702342    0.0335095   0.021025    -0.0168389   -0.000879162  -0.0406355    0.00550406  -0.0168027    0.115849     0.102174     0.0397253    0.0483604
 -0.00506125   0.0843426    0.0735649   -0.0632009    0.00358331  -0.10668     -0.0352676    -0.119983     0.0768072    0.0274769   -0.120365    0.064132    -0.0765891   -0.205166     0.0501663   -0.0215848  -0.0477344   -0.0833969   -0.121088      0.00295769  -0.0693892   -0.0361559   -0.0334284    0.00727279   0.0875652    0.0020632
  0.0416727   -0.0350715   -0.0540875   -0.182817    -0.0854538    0.189031     0.0362389     0.116019    -0.172943    -0.216326     0.0241807  -0.0900463   -0.111227     0.0564283    0.147341     0.0289332  -0.103997    -0.0962849    0.164965      0.0092836   -0.0893239    0.220819    -0.164882    -0.0246331    0.0452269   -0.0345017
 -0.0867124    0.0532746    0.165657    -0.0549234    0.055631    -0.211645    -0.0137053    -0.055664    -0.0271088   -0.00880505  -0.104803    0.0126075   -0.0296042   -0.0465676   -0.186448     0.0526163  -0.0169342    0.0918898   -0.163073     -0.061053    -0.116202     0.0594142    0.0220124   -0.0740042    0.0943284    0.0786955
  0.0261408   -0.0226609   -0.0815546    0.022329     0.123161     0.180716     0.0161417    -0.0605991   -0.0563835   -0.252814     0.111915   -0.0274982   -0.035254     0.0747073    0.0712153    0.0440861  -0.112192     0.0435005    0.0503392    -0.222345     0.0403265   -0.0427527   -0.102849    -0.106157    -0.104886     0.04442
  0.0113779   -0.0390871   -0.0196112    0.123196     0.0109863   -0.196892    -0.0278853     0.102329    -0.070022    -0.0940719    0.127426   -0.0875653   -0.131304    -0.155443    -0.0142611    0.129575    0.155745    -0.141188    -0.0618319     0.163094     0.0161229   -0.148783     0.0864038   -0.24653     -0.0104264    0.105234
 -0.0462994    0.00337702  -0.0924832    0.0128629   -0.259009    -0.00335734   0.132373      0.0825706   -0.00540927  -0.112016     0.0780362   0.0850225   -0.0352349    0.0658214   -0.0375923    0.0105509   0.0221434   -0.130823    -0.025675     -0.137859    -0.0500596   -0.0238409    0.0628629   -0.0650695   -0.0590887    0.0896208
  0.0438127    0.0457091    0.135932     0.158559    -0.0107256   -0.0366565    0.00182292   -0.0508383    0.0744148   -0.0265086   -0.017966    0.0231681   -0.139247    -0.0165227   -0.127884     0.0622248  -0.0370118   -0.160204    -0.0733152    -0.11145     -0.0396844   -0.10117      0.104915     0.0337412   -0.106111    -0.0812753
  0.0655204   -0.0738543    0.108759     0.158014    -0.0369003   -0.0923076   -0.0280383     0.0245362   -0.0529193   -0.0974313   -0.149991    0.0408014   -0.0461704   -0.100501    -0.191708     0.135586    0.0797363    0.0557785    0.0651015     0.0569377   -0.0972706   -0.031766    -0.0773284    0.155449     0.266178     0.0271306
  0.0717747    0.122623     0.130045    -0.0365554   -0.179019    -0.0735673    0.0593615     0.071246     0.0129947    0.0379558   -0.0913193   0.0636807   -0.130772    -0.0881828   -0.056137     0.0457134   0.0552241    0.0780096   -0.051461      0.0548028   -0.0407949   -0.0227126   -0.0435017    0.0340611   -0.0418767   -0.0104126
 -0.162286    -0.0767464   -0.00460881  -0.0295657    0.0132485    0.0615661    0.104674     -0.0348413   -0.0285735    0.0192648    0.0111142  -0.112485     0.0427861   -0.0170949    0.06909     -0.0544354   0.0226964    0.0609951    0.0234465    -0.062544    -0.0919251   -0.0199664    0.134564     0.049869     0.139948    -0.0390339
  0.0250997   -0.0913793   -0.0127643    0.0123584   -0.0526587   -0.0722776    0.128147      0.0218837    0.0527127    0.0236142   -0.0114078   0.0747007   -0.14915     -0.145975    -0.0277378    0.0237586   0.048194    -0.00723684   0.00346347    0.0138761   -0.00559194  -0.0293117    0.0506328    0.050888     0.0447503    0.00706941
 -0.0989251   -0.040475     0.20641     -0.0875414   -0.29899     -0.00224998   0.066832     -0.184891     0.00229438  -0.0557671   -0.0598342  -0.0251954   -0.150055    -0.0276319   -0.0340157    0.0164394  -0.0245195   -0.0407426    0.0358568    -0.156274    -0.00135594   0.0463533   -0.104927     0.0495352   -0.0464922    0.0560381
 -0.0452718   -0.00365924   0.00121729   0.0192889   -0.0370973   -0.0508586   -0.0337825    -0.0156553    0.00106449  -0.154884    -0.108298    0.100466     0.0665929    0.0246079    0.0252572   -0.0391537   0.0476882   -0.108653    -0.00260156   -0.0353492    0.0877491   -0.135239     0.0425483   -0.041187     0.193934     0.11585
  0.050148    -0.0196447    0.0859863    0.0209882    0.00475284   0.061952     0.160452      0.0813312    0.287402     0.190304    -0.148985   -0.198109    -0.0476588   -0.0148084   -0.0122404   -0.124908   -0.0709638   -0.0374949   -0.168232     -0.277098     0.230912    -0.0496582   -0.0841047   -0.459382    -0.15561     -0.0863024
  0.262464    -0.101229    -0.0343799   -0.0275598    0.00726154  -0.281456     0.165026      0.0852201   -0.124283     0.22871     -0.142872   -0.0909887   -0.047853    -0.0170612   -0.0108414   -0.176726    0.284069    -0.074459    -0.108423      0.312549    -0.112166    -0.0496486   -0.0876031    0.416018    -0.155414     0.0307296[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     19
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.084417
┌ Warning: Variances had to be floored 
│   ind =
│    21-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.042646
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.077300
┌ Warning: Variances had to be floored 
│   ind =
│    20-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.039006
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.074474
┌ Warning: Variances had to be floored 
│   ind =
│    21-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.037997
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.075306
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.043018
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.068148
┌ Warning: Variances had to be floored 
│   ind =
│    20-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.042585
┌ Info: EM with 100000 data points 10 iterations avll -1.042585
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.188726e+05
      1       6.506367e+05      -1.682359e+05 |       32
      2       6.193824e+05      -3.125431e+04 |       32
      3       6.034386e+05      -1.594379e+04 |       32
      4       5.935338e+05      -9.904832e+03 |       32
      5       5.862152e+05      -7.318536e+03 |       32
      6       5.821338e+05      -4.081419e+03 |       32
      7       5.802007e+05      -1.933122e+03 |       32
      8       5.790816e+05      -1.119055e+03 |       32
      9       5.781353e+05      -9.463854e+02 |       32
     10       5.770876e+05      -1.047653e+03 |       32
     11       5.759961e+05      -1.091489e+03 |       32
     12       5.748349e+05      -1.161168e+03 |       32
     13       5.737291e+05      -1.105844e+03 |       32
     14       5.730042e+05      -7.248983e+02 |       32
     15       5.725208e+05      -4.834230e+02 |       32
     16       5.721176e+05      -4.031657e+02 |       32
     17       5.717899e+05      -3.277284e+02 |       32
     18       5.716010e+05      -1.888742e+02 |       32
     19       5.715111e+05      -8.991640e+01 |       32
     20       5.714605e+05      -5.059677e+01 |       32
     21       5.714332e+05      -2.730132e+01 |       31
     22       5.714173e+05      -1.592815e+01 |       32
     23       5.714075e+05      -9.798168e+00 |       28
     24       5.714008e+05      -6.633132e+00 |       29
     25       5.713948e+05      -6.047517e+00 |       25
     26       5.713885e+05      -6.273872e+00 |       26
     27       5.713801e+05      -8.438235e+00 |       29
     28       5.713698e+05      -1.024635e+01 |       29
     29       5.713586e+05      -1.126317e+01 |       32
     30       5.713488e+05      -9.811270e+00 |       28
     31       5.713358e+05      -1.291033e+01 |       27
     32       5.713129e+05      -2.297524e+01 |       32
     33       5.712759e+05      -3.697358e+01 |       32
     34       5.712227e+05      -5.319442e+01 |       32
     35       5.711532e+05      -6.950830e+01 |       32
     36       5.710740e+05      -7.919702e+01 |       32
     37       5.709875e+05      -8.652693e+01 |       32
     38       5.709175e+05      -6.999923e+01 |       32
     39       5.708728e+05      -4.470224e+01 |       32
     40       5.708367e+05      -3.603535e+01 |       31
     41       5.708098e+05      -2.696252e+01 |       32
     42       5.707908e+05      -1.900272e+01 |       32
     43       5.707761e+05      -1.462692e+01 |       30
     44       5.707620e+05      -1.415024e+01 |       30
     45       5.707501e+05      -1.187587e+01 |       29
     46       5.707360e+05      -1.409232e+01 |       29
     47       5.707206e+05      -1.537678e+01 |       31
     48       5.706964e+05      -2.424436e+01 |       31
     49       5.706669e+05      -2.954829e+01 |       30
     50       5.706381e+05      -2.877518e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 570638.0777226214)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.301445
[ Info: iteration 2, average log likelihood -1.273929
[ Info: iteration 3, average log likelihood -1.249333
[ Info: iteration 4, average log likelihood -1.216773
[ Info: iteration 5, average log likelihood -1.168675
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     15
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.112226
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      7
│      8
│     10
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.099376
[ Info: iteration 8, average log likelihood -1.147379
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.095092
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      4
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.085459
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     15
│     21
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.078883
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     10
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.123819
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.121997
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.099960
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      8
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.081699
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     12
│     13
│     14
│     15
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.096648
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     10
│     19
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.112299
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.124971
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     17
│     18
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.090365
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.104861
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     10
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.097410
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.120740
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      8
│     18
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.073002
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     17
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.082644
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      3
│      7
│     10
│     14
│     15
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.079887
[ Info: iteration 26, average log likelihood -1.144275
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      8
│     18
│     21
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.075391
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      5
│     13
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.095865
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     10
│     14
│     15
│     17
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.089397
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.123728
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      3
│      8
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.082179
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.101057
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      7
│     10
│     14
│     15
│     19
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.063011
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.113472
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      4
│      8
│     18
│     20
│     22
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.067040
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.141444
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     14
│     15
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.095742
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      5
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.101483
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     17
│     18
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.081386
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.088598
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      3
│      4
│      7
│     14
│     15
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.078383
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.141766
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     10
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.098750
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     17
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.083683
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      7
│      8
│     14
│     19
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.072390
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     15
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.124866
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.110409
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      5
│     10
│     13
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.072220
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      7
│     14
│     17
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.090375
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     19
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.103648
┌ Info: EM with 100000 data points 50 iterations avll -1.103648
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.00132511  -0.00821203  -0.0452541   -0.0280696    0.0253301   -0.240392   -0.175466     -0.166784     0.137205    -0.0431013     0.00384935   0.163078     0.0153765   -0.0484647   -0.00401185   -0.111147     0.0451576    0.0418645   -0.0985354    0.00744833  -0.0879845   -0.104501     0.0928057   -0.0258014    0.316985     0.0173494
  0.0936663    0.00717756   0.0747195   -0.0677203   -0.0505407   -0.136011    0.111703     -0.113712     0.00843731  -0.0467509     0.0659336    0.0644617   -0.086594    -0.113225     0.206548      0.0215085    0.013339    -0.09667      0.0928863    0.00360781  -0.0639695    0.0726452   -0.0638056    0.0335981    0.025473     0.00983612
  0.031102     0.0875077    0.108603     0.262056    -0.0296018    0.0486028   0.0859581    -0.0936003    0.116522    -0.0502255     0.112963     0.0101228   -0.190352    -0.0651699   -0.163549      0.217365    -0.178784    -0.189084    -0.0820072   -0.152931    -0.0569593   -0.0559761    0.0992256    0.123522    -0.117544    -0.0731542
 -0.18417     -0.0931466    0.0953021   -0.0839857    0.0577209   -0.0507702   0.112836      0.0614626   -0.0600729   -0.000549348  -0.0182336   -0.334047     0.101677    -0.136523     0.0575426    -0.052504     0.0891331    0.0890715    0.0596838   -0.0801449   -0.115376     0.0246651    0.1866       0.0473829    0.187686    -0.00456695
 -0.0918392    0.0970287   -0.133027    -0.0176411   -0.124285     0.049414    0.0583064     0.0506265   -0.00844095  -0.0968112     0.118565    -0.0432616   -0.102752     0.0542362    0.118163      0.0298407    0.129169    -0.0925593   -0.153158    -0.0545941    0.156782     0.294711    -0.26248     -0.00768827  -0.157476    -0.0911944
  0.0247055   -0.0203615   -0.0826181    0.0107352    0.122654     0.182315    0.00859386   -0.055066    -0.0602457   -0.258753      0.112362    -0.0266202   -0.0329025    0.082033     0.0747046     0.0440449   -0.114551     0.0444856    0.0512412   -0.22585      0.0331726   -0.0410079   -0.108873    -0.108213    -0.104872     0.044871
 -0.0386696    0.0416389   -0.106331    -0.0167246   -0.251737     0.0436465   0.085785      0.0873352   -0.0408949   -0.120962      0.056099     0.0903363   -0.0512213    0.110663    -0.0281799     0.0158187    0.00900298  -0.100114     0.0220445   -0.12561     -0.113918    -0.0466356    0.146068    -0.0726137   -0.0382675    0.0802633
  0.101951     0.109152     0.0302588   -0.0712709   -0.0296863    0.0183006   0.0268281     0.0967842   -0.161181     0.117588     -0.066085    -0.0876323   -0.177328     0.125587    -0.0960356    -0.0598019   -0.0426483   -0.0261131   -0.265589    -0.115979     0.133857     0.00586379  -0.0476273   -0.170861    -0.0678685    0.127055
 -0.0535387    0.00608275  -0.00535278   0.0117573   -0.0384792   -0.0487126  -0.0530181    -0.0165894   -0.00452636  -0.158676     -0.107505     0.0992383    0.0668273    0.0304127    0.0439739    -0.0411767    0.0420265   -0.105306    -0.00608817  -0.0304249    0.0914374   -0.142968     0.0376076   -0.0522873    0.186129     0.118782
  0.0669802    0.00164124   0.194184     0.00792776   0.0082085   -0.120002   -0.108527      0.0198919    0.00283664  -0.0182528    -0.183069     0.0375213   -0.0763212    0.016037    -0.068301     -0.117948     0.126329    -0.128844    -0.0442218   -0.0637508   -0.00205915  -0.271557     0.158133    -0.0902658   -0.106476    -0.0640602
 -0.0120828   -0.018153     0.08243      0.156885    -0.0218674   -0.109691    0.329214     -0.0121818   -0.0324382   -0.0324395    -0.0628938    0.00643047  -0.224704    -0.162608    -0.163229      0.0110662    0.0779936   -0.0631081   -0.0021176    0.00608713  -0.0266371    0.1544      -0.0166333    0.204133     0.1537       0.00734474
  0.0700362   -0.00821312  -0.0676084   -0.0745405   -0.0885047    0.100033    0.0254514    -0.163878     0.0116459   -0.0132602    -0.0468997    0.0174829    0.0064339   -0.207528     0.0470794    -0.0245993   -0.045209    -0.0252704    0.0804228    0.0962466   -0.118779    -0.0397762    0.10401      0.119634     0.0712952    0.0117712
  0.0799109    0.0844973   -0.104288    -0.0771853   -0.00597308   0.217423    0.0196716     0.0138535    0.0747457    0.20607       0.0921228   -0.00925986  -0.169311    -0.29879      0.12747      -0.0571237    0.0244029   -0.00935648  -0.0433062   -0.0195098   -0.263118    -0.0334002   -0.22383      0.0245287   -0.0648093   -0.0145099
  0.0956436    0.254493    -0.0925247   -0.158993     0.134371     0.282072   -0.0792135    -0.0813825   -0.158844    -0.123178     -0.0342163    0.0238205   -0.059354    -0.0602983    0.0739912     0.00713986  -0.103761     0.0331441    0.13224      0.154746    -0.0799249    0.103813     0.0273954   -0.0330328    0.00412693   0.0202552
  0.0049611    0.0386604    0.0798447    0.0503278    0.149141     0.134875   -0.00166966   -0.0563916   -0.0125202    0.0583004    -0.0350914    0.0665937   -0.0698191   -0.211448    -0.0316237    -0.144578    -0.0548639    0.0337214   -0.101369     0.108108     0.0348021    0.0937793    0.236204     0.0961032    0.0270372    0.0424656
  0.0328548   -0.0788557    0.0265206    0.0133196    0.0898388   -0.118015   -0.00500214    0.00695371   0.047641    -0.0700398     0.167076    -0.115874    -0.0364477    0.0287373    0.149879      0.0509823   -0.0481021   -0.034349    -0.111199     0.0190886    0.00413089   0.00529658   0.0102959    0.18392      0.0687963   -0.0403899
  0.0672956   -0.0928958   -0.0903099   -0.190408    -0.0943189    0.297541    0.0287367     0.169777    -0.23332     -0.221064      0.0513619   -0.146071    -0.131748     0.0980115    0.180354      0.0384306   -0.0965738   -0.0688098    0.135457    -0.00804517  -0.0705823    0.393154    -0.254626    -0.0459254    0.0655082   -0.00996721
 -0.1106      -0.0228758    0.154478    -0.0970118   -0.276767     0.0147385   0.0473921    -0.159137     0.00349719  -0.068487     -0.039194    -0.0398945   -0.151335    -0.00476035  -0.00893742    0.0328742   -0.01032     -0.0315258    0.00640501  -0.157531     0.0241385    0.0479729   -0.10317      0.0495048   -0.0620752    0.0360487
  0.072871     0.125379     0.131359    -0.0375802   -0.177895    -0.0742116   0.0583589     0.0742685    0.0125886    0.0377405    -0.0925077    0.0632639   -0.131735    -0.0862067   -0.0509059     0.0470717    0.0563412    0.078847    -0.0532717    0.0512464   -0.0405153   -0.0233515   -0.0492079    0.032858    -0.0429962   -0.00728214
  0.0876366   -0.0738762    0.118253     0.161625    -0.0433111   -0.0928431  -0.106568      0.0223367   -0.0518677   -0.130495     -0.166313     0.0476935    0.00612314  -0.0910788   -0.167904      0.156147     0.0847425    0.0892112    0.0842581    0.0721956   -0.108118    -0.0715183   -0.092248     0.132233     0.287689     0.0339272
  0.11001      0.0427771   -0.0302795   -0.0383793   -0.0114636    0.0745007   0.0407535     0.0377412   -0.0878817    0.0780366     0.0247938   -0.0865769   -0.128641     0.169078     0.0459       -0.0362305   -0.0167622   -0.138866    -0.132666    -0.081436    -0.0755034    0.0067279   -0.137396    -0.101822    -0.018994     0.0501055
  0.0139873   -0.120144    -0.0958324    0.0324698    0.194513    -0.15        0.0469339     0.017984     0.0164351    0.030622      0.0465456   -0.0351708    0.0863938    0.13508      0.124255     -0.0842078    0.0675982    0.0697133   -0.0280328    0.0542606    0.0640109    0.102421     0.0138537    0.0859062   -0.0441332    0.023678
  0.0138456    0.0398465    0.11981     -0.0207876    0.0680202   -0.119469    0.0376642     0.133011    -0.162809    -0.110881      0.0612315   -0.159012    -0.185986     0.0505859   -0.0230477     0.0616075    0.10372      0.00795203   0.0534271   -0.167468     0.147378    -0.0182359    0.26019     -0.0342717   -0.0394856    0.140321
  0.0138625   -0.0484149    0.0383795    0.136209     0.0482236   -0.218655   -0.0393505     0.0974223   -0.0771938   -0.0912003     0.117283    -0.0822418   -0.157584    -0.177953     0.0156235     0.126151     0.158223    -0.140383    -0.0602506    0.165417     0.00818111  -0.116617     0.609948    -0.224292     0.012833     0.10801
  0.0190918    0.111348    -0.05526     -0.0310316    0.0470138    0.096291   -0.082362     -0.0225347   -0.0337079    0.0507435    -0.0418958    0.0850997    0.010561     0.057799    -0.0253793     0.00351795  -0.137809    -0.0443703    0.148351     0.0939735    0.185218     0.121392     0.00361095   0.0571449    0.0163931   -0.0394914
  0.0175786    0.11711      0.0995761   -0.149685    -0.0183325   -0.0010607  -0.0780028    -0.119767     0.0437879    0.102998     -0.0384277   -0.0532223   -0.176143    -0.296567     0.19351      -0.084907    -0.0722295   -0.111068    -0.133483     0.0184649   -0.016888    -0.217477    -0.179252     0.0103516    0.0179098    0.0297818
 -0.0843641    0.0594385    0.163837    -0.0831508    0.0540118   -0.211758   -0.0204494    -0.0127394   -0.0458972   -0.0324819    -0.0926554    0.0109688   -0.0347851   -0.0403791   -0.176424      0.0507547   -0.0227008    0.0799138   -0.143801    -0.0677594   -0.122758     0.107182    -0.0124702   -0.0841693    0.103012     0.0847729
  0.142521    -0.0307046    0.0110708   -0.0105726    0.0137969   -0.0839153   0.139319      0.0729348    0.055108     0.167073     -0.130776    -0.137355    -0.0457725   -0.0192804   -0.000839762  -0.149873     0.0942762   -0.0424665   -0.103349     0.0236683    0.0345661   -0.0389689   -0.0729402   -0.0225048   -0.131329    -0.0138133
  0.0169156   -0.0171581   -0.137365     0.0939342   -0.0927602   -0.14858     0.000747531   0.115903    -0.0646886   -0.109991      0.150082    -0.0987571   -0.0647106   -0.112264    -0.076824      0.140735     0.155255    -0.144917    -0.062644     0.155766     0.0356954   -0.207047    -1.18127     -0.303386    -0.0564664    0.0975343
 -0.0173526    0.0916732    0.110761     0.0121005    0.0577455   -0.120743    0.0684702    -0.0256767    0.0554782   -0.0148764    -0.232773     0.157562    -0.0721554   -0.216354    -0.00868433    0.106231    -0.0644775   -0.169517    -0.0861854   -0.00331684  -0.0528978    0.15848      0.0167213    0.00123416  -0.0583578   -0.045364
 -0.0792901   -0.0943647    0.00930726  -0.0796636   -0.0310195   -0.0149372   0.0939426     0.120229     0.0609063    0.126765     -0.0697082    0.0599659   -0.167951    -0.146545    -0.124087      0.072169     0.0832893   -0.00490652   0.00366939  -0.0153498    0.0325346   -0.109405     0.0660083    0.0832922   -0.0626573   -0.00155027
 -0.0273591    0.023823    -0.167468     0.0965479   -0.0926008    0.198663    0.0938353    -0.224762     0.0408164    0.0296707     0.0905272    0.0931429    0.00842862   0.225574     0.0264173    -0.053228    -0.0684153    0.0760683   -0.114373    -0.0542499   -0.0438578   -0.114391     0.0875911    0.0431229    0.160703    -0.0645602[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.118908
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     13
│     15
│     21
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.059756
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      3
│      5
│      7
│     10
│     15
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.032898
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│     13
│     14
│     15
│      ⋮
│     21
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.020710
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      3
│      4
│      7
│     15
│     18
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.064101
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      5
│     10
│     13
│     15
│     21
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.048915
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      3
│      7
│     14
│     15
│     18
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.036002
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│     10
│      ⋮
│     21
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.026363
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      3
│      7
│     15
│     18
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.051778
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     13
│     14
│     15
│     20
│     21
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.032814
┌ Info: EM with 100000 data points 10 iterations avll -1.032814
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.015382     -0.0680876    0.230443    -0.0840008   -0.198064     0.00771758   0.0828224    0.132619     -0.135044   -0.0309095    0.0272841    0.0165042    0.0830426   -0.0555514    0.0559722    -0.0560063    -0.00836288   0.164848    0.0532344   -0.0523731     0.0604756   0.0223063    0.00461345   0.0612307    0.0364677    -0.139775
  0.153117     -0.167799     0.0182332    0.0245145    0.172041     0.0147189    0.0417223    0.0325591     0.094911    0.0061979    0.0384936   -0.0562133   -0.010628     0.215099    -0.0521654    -0.115945     -0.0421766   -0.0391105   0.00174811   0.000536748   0.0382928   0.0891174    0.0472058    0.0593326    0.0743561     0.0286946
  0.163847      0.0784542    0.0151282    0.0527059   -0.0147692    0.283896     0.0419484   -0.0426269     0.0535895   0.0326582   -0.0319403    0.233871    -0.12297      0.0364126   -0.0502345     0.224988      0.0472354    0.0587525  -0.0523991   -0.00734595    0.149764   -0.0709019   -0.164272     0.0314472    0.0498407     0.124465
 -0.14171      -0.116913     0.122784     0.100603    -0.101573    -0.00936602  -0.181502     0.067621      0.0674793  -0.0942498    0.22244     -0.115046     0.0368476   -0.0328931    0.00822856   -0.112021     -0.109175     0.0583414   0.00384034  -0.162504     -0.0469341  -0.0708399   -0.198196     0.0176413    0.0485317    -0.0395896
 -0.037717     -0.0672271    0.203681    -0.063202    -0.0105318    0.12596      0.10949      0.154404     -0.110951   -0.132347     0.127463     0.0632067    0.125261    -0.095601     0.111724      0.153796     -0.0220173    0.0383454  -0.0940696   -0.0200819    -0.0832648  -0.117261    -0.133513    -0.181609    -0.0598515    -0.0578007
 -0.0899066    -0.133702     0.0925353    0.111372    -0.115624     0.141423     0.0985595   -0.0692504     0.0566854   0.027724    -0.118261     0.00975585   0.0252667   -0.0282884   -0.020578     -0.000723403   0.0775879   -0.0461008   0.200226     0.0902434     0.0968236   0.128359     0.130706    -0.0463261   -0.0645595     0.0860544
  0.0366615     0.041301    -0.0245733    0.0329656   -0.114747    -0.0126596   -0.0879229    0.159344     -0.0144268   0.0492301   -0.00582705  -0.0448093    0.019563    -0.00958706  -0.0621233     0.0474915    -0.0822024    0.0763673   0.104166     0.11058       0.057672   -0.00618894   0.0898969    0.0182045   -0.000624397  -0.134383
  0.0509102     0.111321    -0.0445147   -0.036028    -0.151426     0.0872425    0.0790332    0.260878     -0.0486014  -0.0589007    0.0185517   -0.247103    -0.154027     0.0603367    0.153996      0.114505     -0.0274746   -0.0173806   0.0345627    0.0601512     0.0135287  -0.182575    -0.0210302   -0.00453132  -0.125824      0.0411214
  0.0555776     0.0503579    0.101758     0.0697031    0.0641063    0.16963     -0.174441    -0.013841     -0.0390811   0.0806147   -0.106793     0.0627832    0.0725611   -0.0108764    0.0518043     0.116247      0.0173532    0.160464    0.217213     0.0466599    -0.108424   -0.0314789    0.136484    -0.0478203   -0.0165833     0.0489626
 -0.144009      0.0606556    0.0180437    0.0456477    0.0144287   -0.0186656   -0.103939     0.14063      -0.0839585  -0.125258     0.119189     0.11421      0.114279    -0.132861    -0.0831976    -0.0168853     0.0373663    0.183016   -0.0348754    0.0991781     0.354053   -0.112981    -0.02807      0.0448149   -0.0944793    -0.0897138
 -0.0497526    -0.0341216   -0.101913    -0.202514     0.196849    -0.00272879  -0.0791353    0.0715632    -0.01944    -0.065387     0.0773167   -0.108218    -0.115542     0.127332    -0.0433421     0.0422731    -0.0311655   -0.05846     0.0338383    0.0486668    -0.059239   -0.00520299   0.0392512   -0.0348063   -0.123984      0.0233177
  0.0757113     0.0017923    0.0400291   -0.112191    -0.0246408   -0.128809    -0.0314625    0.0478833    -0.0393999  -0.0914133    0.0319965   -0.177629    -0.0791941   -0.0089685   -0.139699      0.059566      0.102859    -0.0115604  -0.0531345   -0.0531461     0.139155   -0.0875322   -0.0139741    0.08805     -0.0752004    -0.295602
 -0.0553184    -0.0835361   -0.160851    -0.0312624   -0.0577883   -0.0351275    0.00177211  -0.000362081  -0.0329165  -0.065962     0.156214    -0.0727492    0.0696512   -0.0986333   -0.0594089    -0.0317524    -0.0708408   -0.0808162  -0.0763149   -0.1597       -0.0735654  -0.0896064    0.0200276   -0.00224463   0.0194028     0.00363928
  0.14873      -0.012981    -0.225184    -0.153674     0.0813236   -0.101642    -0.0385187    0.0141324    -0.135541    0.244795    -0.0177679   -0.0177151   -0.0510098    0.0949703    0.0214835     0.104441      0.026754    -0.0767372  -0.0184294   -0.0545752     0.118074   -0.0736208   -0.0719935   -0.117211     0.132057      0.0339092
 -0.0251456    -0.0391634    0.0671981    0.0322939   -0.022521    -0.0984868    0.103045     0.136417     -0.158028   -0.100677    -0.203715    -0.00233361   0.0354212    0.0574241    0.106648     -0.0177907    -0.0255379    0.0312711  -0.0778597   -0.0451432     0.182406   -0.047985    -0.0938016    0.140194     0.0965347     0.126347
 -0.0614417     0.0844927    0.0095084   -0.0584788    0.0629849   -0.0639133   -0.0944286    0.102643      0.0362569   0.0332257    0.0816775   -0.0494597   -0.160721     0.038227    -0.143555     -0.0506968     0.195104    -0.0177485  -0.117108    -0.00362198    0.111012    0.232972     0.119966    -0.162367     0.144549     -0.157013
 -0.107771     -0.0409102   -0.134543    -0.00446027   0.175649     0.0567813   -0.0306434   -0.00520024    0.0227899  -0.0204732   -0.0464918    0.110882    -0.0172458   -0.00821545   0.160315      0.0312237     0.233409     0.0411905   0.0669182    0.0237421    -0.120051    0.129213    -0.00781698   0.00504052   0.0378664    -0.0561735
  0.127496     -0.0623236   -0.0806386    0.0397048   -0.00986897   0.0880701   -0.169696     0.229784     -0.0197537  -0.0646178    0.0930036   -0.0259897    0.145389     0.16166     -0.175986     -0.0234093    -0.0863402   -0.139896    0.0940748    0.0466593    -0.0292817   0.0701882    0.077577    -0.0398475    0.0484857     0.122374
 -0.119854     -0.0127383    0.00077123  -0.054604    -0.0252728    0.0284429   -0.035658    -0.0833799     0.121959   -0.152118    -0.0644024    0.0401221    0.00669805  -0.0639637    0.166186     -0.0871671     0.138462     0.170023   -0.0810076    0.0472756    -0.0227269  -0.0039632   -0.0529501   -0.212304     0.0343432     0.159774
 -0.112244     -0.061441    -0.1169       0.117018    -0.080065    -0.128733    -0.212117    -0.0453885     0.017948   -0.0857844   -0.0351256   -0.0298512    0.180469     0.0432758   -0.0248525    -0.0857886    -0.0139056    0.0397332   0.236407    -0.08745       0.242898    0.0685494   -0.236468    -0.0119568   -0.110407      0.127703
  0.000562761  -0.140565     0.0478084    0.0835158   -0.0660523   -0.0474637    0.165677     0.0537025     0.0482767  -0.130217     0.289624     0.0311325    0.0741247    0.0820903    0.000872264  -0.012324      0.149995     0.122378    0.0497685   -0.190878      0.137704    0.00139338   0.0783728   -0.100436     0.04817      -0.0329739
 -0.0594464    -0.101454    -0.0847586   -0.02891     -0.0748121    0.00901806   0.270852    -0.130044      0.0700287  -0.0239994   -0.0632968   -0.028334    -0.00372078  -0.0129811   -0.202092      0.0588299     0.0247639   -0.185431   -0.0236471   -0.177522      0.100209    0.0349129    0.0644001    0.0268882    0.0323439    -0.0396842
  0.0128168     0.0147024    0.0899178    0.154772    -0.0894391   -0.0550332   -0.114711    -0.054144     -0.0448626   0.0120714    0.159044    -0.015507     0.0227288    0.108914    -0.0677722     0.0527321     0.0731928    0.0954684   0.0593983    0.0315426     0.142533    0.362264    -0.0590782    0.0589623    0.111727      0.0223809
  0.00578898    0.0589585    0.0879331    0.0238359    0.177855     0.161488    -0.1321       0.118375      0.0925679   0.11992      0.102128     0.0164254   -0.152577     0.130664     0.0985954     0.0648198    -0.145998    -0.029799   -0.0421615   -0.0130836    -0.0802989  -0.0354001    0.0216133   -0.0355941    0.0332273     0.125328
 -0.079593     -0.0267426    0.0437458    0.012193    -0.153012    -0.0312605   -0.042903     0.0842787     0.128927    0.0744084    0.124571    -0.0412158    0.0180619   -0.00487795   0.160935      0.0124246    -0.0766274   -0.0273233  -0.0549888   -0.1189       -0.0344579  -0.0428513    0.109037    -0.0112538    0.0774003     0.0510327
 -0.0987524     0.0129828    0.0582721    0.0577666    0.0888245   -0.126968     0.199669    -0.0116428     0.0991547  -0.0286774    0.167143     0.123187     0.0326258    0.0438457    0.0673461     0.081809     -0.00447391   0.123816    0.104243     0.0228211     0.0191873  -0.146625    -0.0445722   -0.148678     0.0180881     0.0256063
 -0.00513546    0.0740797    0.127904    -0.058727     0.0717364    0.0467082    0.098987    -0.0894847     0.0114119  -0.0324988    0.0875654   -0.241257    -0.0935457    0.19827     -0.0524273     0.0596651    -0.00181776   0.0697034   0.0407496   -0.0571105     0.0079772   0.0792492    0.134603     0.113379     0.0441582     0.0183239
 -0.15972       0.00415581   0.069733     0.016347     0.0236308   -0.25648      0.0243378   -0.0856302     0.0707472   0.00799488  -0.133271    -0.101671     0.192371     0.0341799   -0.255148     -0.030181      0.0217627    0.0713736   0.0994579    0.0479845     0.0552969  -0.132076    -0.0799776   -0.0343721    0.029345      0.0930634
  0.0636088    -0.0163681   -0.0455008    0.0519348    0.103662    -0.132998    -0.143122    -0.225784      0.046166    0.0910994    0.0284942    0.0404141    0.124541    -0.0814935   -0.0245601    -0.0324178     0.0574082    0.0344668  -0.171946    -0.118315      0.0311527   0.0272598   -0.106406     0.251091    -0.0819224     0.0451181
  0.112209     -0.0847943   -0.179706    -0.00586369   0.0531506    0.061018     0.14912     -0.143927     -0.0665313   0.0578063    0.0582605   -0.137219    -0.0034588    0.0409659    0.113462      0.0102069    -0.0546182    0.0664058  -0.181914     0.00351799   -0.010204   -0.0349409   -0.0215076    0.0436552    0.0436784    -0.0459782
  0.0167628     0.14804     -0.119082     0.0339968   -0.0295191   -0.0157024   -0.320659    -0.109288     -0.0223475  -0.0499836    0.0488679    0.100745    -0.209301     0.113387     0.111215      0.100501      0.136064     0.01079    -0.199668    -0.107101      0.011473   -0.131588     0.0468271    0.0469183   -4.44099e-5    0.0169475
 -0.0926493    -0.139414     0.065264     0.0597802   -0.0111753    0.0498629    0.0339586   -0.205108     -0.0115974   0.019557     0.0869601    0.0460061   -0.0761559    0.141835    -0.0189748     0.036198     -0.0220111    0.0324805   0.106025    -0.0209087    -0.0421479   0.0777515    0.0456429   -0.0823449   -0.165274      0.0632564kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.423114817257292
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423133
[ Info: iteration 2, average log likelihood -1.423061
[ Info: iteration 3, average log likelihood -1.422998
[ Info: iteration 4, average log likelihood -1.422919
[ Info: iteration 5, average log likelihood -1.422814
[ Info: iteration 6, average log likelihood -1.422678
[ Info: iteration 7, average log likelihood -1.422490
[ Info: iteration 8, average log likelihood -1.422204
[ Info: iteration 9, average log likelihood -1.421724
[ Info: iteration 10, average log likelihood -1.420936
[ Info: iteration 11, average log likelihood -1.419866
[ Info: iteration 12, average log likelihood -1.418815
[ Info: iteration 13, average log likelihood -1.418106
[ Info: iteration 14, average log likelihood -1.417756
[ Info: iteration 15, average log likelihood -1.417609
[ Info: iteration 16, average log likelihood -1.417550
[ Info: iteration 17, average log likelihood -1.417527
[ Info: iteration 18, average log likelihood -1.417517
[ Info: iteration 19, average log likelihood -1.417513
[ Info: iteration 20, average log likelihood -1.417511
[ Info: iteration 21, average log likelihood -1.417510
[ Info: iteration 22, average log likelihood -1.417509
[ Info: iteration 23, average log likelihood -1.417509
[ Info: iteration 24, average log likelihood -1.417509
[ Info: iteration 25, average log likelihood -1.417508
[ Info: iteration 26, average log likelihood -1.417508
[ Info: iteration 27, average log likelihood -1.417508
[ Info: iteration 28, average log likelihood -1.417508
[ Info: iteration 29, average log likelihood -1.417508
[ Info: iteration 30, average log likelihood -1.417507
[ Info: iteration 31, average log likelihood -1.417507
[ Info: iteration 32, average log likelihood -1.417507
[ Info: iteration 33, average log likelihood -1.417507
[ Info: iteration 34, average log likelihood -1.417507
[ Info: iteration 35, average log likelihood -1.417507
[ Info: iteration 36, average log likelihood -1.417507
[ Info: iteration 37, average log likelihood -1.417507
[ Info: iteration 38, average log likelihood -1.417507
[ Info: iteration 39, average log likelihood -1.417507
[ Info: iteration 40, average log likelihood -1.417507
[ Info: iteration 41, average log likelihood -1.417507
[ Info: iteration 42, average log likelihood -1.417507
[ Info: iteration 43, average log likelihood -1.417506
[ Info: iteration 44, average log likelihood -1.417506
[ Info: iteration 45, average log likelihood -1.417506
[ Info: iteration 46, average log likelihood -1.417506
[ Info: iteration 47, average log likelihood -1.417506
[ Info: iteration 48, average log likelihood -1.417506
[ Info: iteration 49, average log likelihood -1.417506
[ Info: iteration 50, average log likelihood -1.417506
┌ Info: EM with 100000 data points 50 iterations avll -1.417506
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.423133367446367
│     -1.4230607878446926
│      ⋮
└     -1.4175063355581006
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417521
[ Info: iteration 2, average log likelihood -1.417450
[ Info: iteration 3, average log likelihood -1.417385
[ Info: iteration 4, average log likelihood -1.417301
[ Info: iteration 5, average log likelihood -1.417197
[ Info: iteration 6, average log likelihood -1.417077
[ Info: iteration 7, average log likelihood -1.416956
[ Info: iteration 8, average log likelihood -1.416850
[ Info: iteration 9, average log likelihood -1.416765
[ Info: iteration 10, average log likelihood -1.416701
[ Info: iteration 11, average log likelihood -1.416651
[ Info: iteration 12, average log likelihood -1.416613
[ Info: iteration 13, average log likelihood -1.416582
[ Info: iteration 14, average log likelihood -1.416558
[ Info: iteration 15, average log likelihood -1.416538
[ Info: iteration 16, average log likelihood -1.416521
[ Info: iteration 17, average log likelihood -1.416507
[ Info: iteration 18, average log likelihood -1.416495
[ Info: iteration 19, average log likelihood -1.416484
[ Info: iteration 20, average log likelihood -1.416474
[ Info: iteration 21, average log likelihood -1.416465
[ Info: iteration 22, average log likelihood -1.416456
[ Info: iteration 23, average log likelihood -1.416447
[ Info: iteration 24, average log likelihood -1.416439
[ Info: iteration 25, average log likelihood -1.416432
[ Info: iteration 26, average log likelihood -1.416424
[ Info: iteration 27, average log likelihood -1.416417
[ Info: iteration 28, average log likelihood -1.416410
[ Info: iteration 29, average log likelihood -1.416403
[ Info: iteration 30, average log likelihood -1.416397
[ Info: iteration 31, average log likelihood -1.416391
[ Info: iteration 32, average log likelihood -1.416385
[ Info: iteration 33, average log likelihood -1.416379
[ Info: iteration 34, average log likelihood -1.416373
[ Info: iteration 35, average log likelihood -1.416368
[ Info: iteration 36, average log likelihood -1.416363
[ Info: iteration 37, average log likelihood -1.416358
[ Info: iteration 38, average log likelihood -1.416354
[ Info: iteration 39, average log likelihood -1.416349
[ Info: iteration 40, average log likelihood -1.416345
[ Info: iteration 41, average log likelihood -1.416341
[ Info: iteration 42, average log likelihood -1.416338
[ Info: iteration 43, average log likelihood -1.416334
[ Info: iteration 44, average log likelihood -1.416331
[ Info: iteration 45, average log likelihood -1.416328
[ Info: iteration 46, average log likelihood -1.416325
[ Info: iteration 47, average log likelihood -1.416322
[ Info: iteration 48, average log likelihood -1.416320
[ Info: iteration 49, average log likelihood -1.416317
[ Info: iteration 50, average log likelihood -1.416315
┌ Info: EM with 100000 data points 50 iterations avll -1.416315
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.417521360763238
│     -1.4174504102934253
│      ⋮
└     -1.4163150510575124
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416323
[ Info: iteration 2, average log likelihood -1.416273
[ Info: iteration 3, average log likelihood -1.416229
[ Info: iteration 4, average log likelihood -1.416179
[ Info: iteration 5, average log likelihood -1.416117
[ Info: iteration 6, average log likelihood -1.416043
[ Info: iteration 7, average log likelihood -1.415957
[ Info: iteration 8, average log likelihood -1.415861
[ Info: iteration 9, average log likelihood -1.415761
[ Info: iteration 10, average log likelihood -1.415661
[ Info: iteration 11, average log likelihood -1.415567
[ Info: iteration 12, average log likelihood -1.415479
[ Info: iteration 13, average log likelihood -1.415400
[ Info: iteration 14, average log likelihood -1.415330
[ Info: iteration 15, average log likelihood -1.415270
[ Info: iteration 16, average log likelihood -1.415220
[ Info: iteration 17, average log likelihood -1.415179
[ Info: iteration 18, average log likelihood -1.415145
[ Info: iteration 19, average log likelihood -1.415118
[ Info: iteration 20, average log likelihood -1.415095
[ Info: iteration 21, average log likelihood -1.415075
[ Info: iteration 22, average log likelihood -1.415057
[ Info: iteration 23, average log likelihood -1.415042
[ Info: iteration 24, average log likelihood -1.415027
[ Info: iteration 25, average log likelihood -1.415014
[ Info: iteration 26, average log likelihood -1.415001
[ Info: iteration 27, average log likelihood -1.414989
[ Info: iteration 28, average log likelihood -1.414978
[ Info: iteration 29, average log likelihood -1.414967
[ Info: iteration 30, average log likelihood -1.414956
[ Info: iteration 31, average log likelihood -1.414946
[ Info: iteration 32, average log likelihood -1.414936
[ Info: iteration 33, average log likelihood -1.414927
[ Info: iteration 34, average log likelihood -1.414918
[ Info: iteration 35, average log likelihood -1.414909
[ Info: iteration 36, average log likelihood -1.414901
[ Info: iteration 37, average log likelihood -1.414893
[ Info: iteration 38, average log likelihood -1.414885
[ Info: iteration 39, average log likelihood -1.414878
[ Info: iteration 40, average log likelihood -1.414871
[ Info: iteration 41, average log likelihood -1.414864
[ Info: iteration 42, average log likelihood -1.414858
[ Info: iteration 43, average log likelihood -1.414852
[ Info: iteration 44, average log likelihood -1.414846
[ Info: iteration 45, average log likelihood -1.414840
[ Info: iteration 46, average log likelihood -1.414835
[ Info: iteration 47, average log likelihood -1.414830
[ Info: iteration 48, average log likelihood -1.414825
[ Info: iteration 49, average log likelihood -1.414820
[ Info: iteration 50, average log likelihood -1.414816
┌ Info: EM with 100000 data points 50 iterations avll -1.414816
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4163230142231384
│     -1.4162729426288818
│      ⋮
└     -1.4148159594140457
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414821
[ Info: iteration 2, average log likelihood -1.414767
[ Info: iteration 3, average log likelihood -1.414716
[ Info: iteration 4, average log likelihood -1.414658
[ Info: iteration 5, average log likelihood -1.414586
[ Info: iteration 6, average log likelihood -1.414499
[ Info: iteration 7, average log likelihood -1.414397
[ Info: iteration 8, average log likelihood -1.414283
[ Info: iteration 9, average log likelihood -1.414163
[ Info: iteration 10, average log likelihood -1.414044
[ Info: iteration 11, average log likelihood -1.413932
[ Info: iteration 12, average log likelihood -1.413830
[ Info: iteration 13, average log likelihood -1.413740
[ Info: iteration 14, average log likelihood -1.413661
[ Info: iteration 15, average log likelihood -1.413594
[ Info: iteration 16, average log likelihood -1.413535
[ Info: iteration 17, average log likelihood -1.413484
[ Info: iteration 18, average log likelihood -1.413440
[ Info: iteration 19, average log likelihood -1.413401
[ Info: iteration 20, average log likelihood -1.413366
[ Info: iteration 21, average log likelihood -1.413335
[ Info: iteration 22, average log likelihood -1.413306
[ Info: iteration 23, average log likelihood -1.413280
[ Info: iteration 24, average log likelihood -1.413256
[ Info: iteration 25, average log likelihood -1.413233
[ Info: iteration 26, average log likelihood -1.413212
[ Info: iteration 27, average log likelihood -1.413192
[ Info: iteration 28, average log likelihood -1.413173
[ Info: iteration 29, average log likelihood -1.413155
[ Info: iteration 30, average log likelihood -1.413137
[ Info: iteration 31, average log likelihood -1.413120
[ Info: iteration 32, average log likelihood -1.413104
[ Info: iteration 33, average log likelihood -1.413087
[ Info: iteration 34, average log likelihood -1.413071
[ Info: iteration 35, average log likelihood -1.413055
[ Info: iteration 36, average log likelihood -1.413039
[ Info: iteration 37, average log likelihood -1.413024
[ Info: iteration 38, average log likelihood -1.413008
[ Info: iteration 39, average log likelihood -1.412992
[ Info: iteration 40, average log likelihood -1.412976
[ Info: iteration 41, average log likelihood -1.412960
[ Info: iteration 42, average log likelihood -1.412944
[ Info: iteration 43, average log likelihood -1.412928
[ Info: iteration 44, average log likelihood -1.412913
[ Info: iteration 45, average log likelihood -1.412897
[ Info: iteration 46, average log likelihood -1.412882
[ Info: iteration 47, average log likelihood -1.412867
[ Info: iteration 48, average log likelihood -1.412853
[ Info: iteration 49, average log likelihood -1.412838
[ Info: iteration 50, average log likelihood -1.412825
┌ Info: EM with 100000 data points 50 iterations avll -1.412825
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.414820799577512
│     -1.4147666889964696
│      ⋮
└     -1.4128249209888857
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412820
[ Info: iteration 2, average log likelihood -1.412752
[ Info: iteration 3, average log likelihood -1.412686
[ Info: iteration 4, average log likelihood -1.412610
[ Info: iteration 5, average log likelihood -1.412518
[ Info: iteration 6, average log likelihood -1.412406
[ Info: iteration 7, average log likelihood -1.412276
[ Info: iteration 8, average log likelihood -1.412131
[ Info: iteration 9, average log likelihood -1.411976
[ Info: iteration 10, average log likelihood -1.411819
[ Info: iteration 11, average log likelihood -1.411664
[ Info: iteration 12, average log likelihood -1.411517
[ Info: iteration 13, average log likelihood -1.411383
[ Info: iteration 14, average log likelihood -1.411262
[ Info: iteration 15, average log likelihood -1.411155
[ Info: iteration 16, average log likelihood -1.411060
[ Info: iteration 17, average log likelihood -1.410977
[ Info: iteration 18, average log likelihood -1.410904
[ Info: iteration 19, average log likelihood -1.410841
[ Info: iteration 20, average log likelihood -1.410784
[ Info: iteration 21, average log likelihood -1.410734
[ Info: iteration 22, average log likelihood -1.410689
[ Info: iteration 23, average log likelihood -1.410649
[ Info: iteration 24, average log likelihood -1.410613
[ Info: iteration 25, average log likelihood -1.410580
[ Info: iteration 26, average log likelihood -1.410549
[ Info: iteration 27, average log likelihood -1.410521
[ Info: iteration 28, average log likelihood -1.410494
[ Info: iteration 29, average log likelihood -1.410469
[ Info: iteration 30, average log likelihood -1.410446
[ Info: iteration 31, average log likelihood -1.410424
[ Info: iteration 32, average log likelihood -1.410403
[ Info: iteration 33, average log likelihood -1.410383
[ Info: iteration 34, average log likelihood -1.410364
[ Info: iteration 35, average log likelihood -1.410345
[ Info: iteration 36, average log likelihood -1.410328
[ Info: iteration 37, average log likelihood -1.410310
[ Info: iteration 38, average log likelihood -1.410294
[ Info: iteration 39, average log likelihood -1.410278
[ Info: iteration 40, average log likelihood -1.410262
[ Info: iteration 41, average log likelihood -1.410246
[ Info: iteration 42, average log likelihood -1.410231
[ Info: iteration 43, average log likelihood -1.410216
[ Info: iteration 44, average log likelihood -1.410202
[ Info: iteration 45, average log likelihood -1.410187
[ Info: iteration 46, average log likelihood -1.410173
[ Info: iteration 47, average log likelihood -1.410159
[ Info: iteration 48, average log likelihood -1.410145
[ Info: iteration 49, average log likelihood -1.410131
[ Info: iteration 50, average log likelihood -1.410118
┌ Info: EM with 100000 data points 50 iterations avll -1.410118
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.412819611427373
│     -1.4127520158426754
│      ⋮
└     -1.4101176736647454
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.423114817257292
│     -1.423133367446367
│     -1.4230607878446926
│     -1.4229981826049656
│      ⋮
│     -1.410145156368354
│     -1.4101313543055436
└     -1.4101176736647454
32×26 Array{Float64,2}:
  0.0207556    0.146024      0.0439464  -0.11809     0.153999   -0.00184974  -0.338223   -0.0801703   -0.0468545   0.174862     0.0174293   0.0990411  -0.138607    0.260304    0.0525166   0.177495    0.0908832    0.137619    0.105213     -0.0728538    0.0258814   -0.0464942  -0.0167217    0.0513698   0.0280164  -0.0170137
 -0.00864284  -0.114246     -0.0254354   0.0262705  -0.176445    0.0202275    0.246706    0.126791    -0.031582   -0.186387     0.0842308  -0.120924    0.0938065  -0.159879   -0.0816652  -0.117993   -0.0297921    0.0247347  -0.0283524    -0.0268943    0.00284815  -0.0231352  -0.0251713   -0.0863413  -0.100333    0.104601
 -0.0194053    0.0214706    -0.0583638   0.160659   -0.110408    0.0622448    0.212577   -0.0102932    0.35439    -0.301948     0.421558   -0.142762    0.530555   -0.202832   -0.210405    0.0194917  -0.356386    -0.316257   -0.023342      0.177183     0.476999     0.0837777  -0.260155     0.24385     0.27813    -0.27568
 -0.355055     0.219098      0.0691109   0.209982    0.480169    0.22418      0.0616237   0.240865     0.126164    0.226461    -0.0426578   0.0496962   0.248352   -0.0212023  -0.664361    0.239401    0.0897812    0.0774474  -0.210548      0.463251     0.212219     0.0989364  -0.200602    -0.0100679  -0.0275057   0.0924093
 -0.724998    -0.201655     -0.0618201   0.266032    0.217125   -0.0301239    0.376663    0.171528     0.270036   -0.13508     -0.0969105  -0.136466   -0.610297   -0.246897    0.488767   -0.131487    0.103803     0.0479399  -0.128371      0.00925419  -0.29864      0.236653    0.278353     0.118324    0.362147   -0.0273473
 -0.176393    -0.781971      0.186665    0.354538   -0.246342    0.130939     0.0488652  -0.384207     0.159612   -0.317791    -0.460056    0.162202   -0.0679145   0.252784    0.304254    0.4455     -0.247777    -0.370287   -0.0014404    -0.0903406   -0.254403    -0.111585    0.256673     0.0412831  -0.137918    0.208021
  0.851829     0.1777        0.689187   -0.361372   -0.451923   -0.0565353   -0.38242    -0.298853    -0.306919    0.316204    -0.0192989   0.303696    0.431807    0.267402   -0.327343   -0.0782309   0.124075     0.292975   -0.000735635  -0.167347     0.103648    -0.12632    -0.204805     0.225797   -0.220194   -0.187263
  0.320229    -0.172118     -0.0816865  -0.229672   -0.319682   -0.675275    -0.434656   -0.452778    -0.0564448   0.0790407    0.0660035  -0.0323236  -0.244023    0.0860992   0.955236   -0.0131705  -0.11639     -0.064422   -0.0458903    -0.46581     -0.0503005    0.121096    0.121256     0.0832195   0.165975   -0.385479
 -0.297262    -0.322795     -0.953141    0.0345602   0.354496    0.0528383   -0.165019   -0.260437    -0.153591    0.0480493    0.41658    -0.291784   -0.313737    0.212326    0.299554    0.372135    0.00488866  -0.280056    0.0724219    -0.305295     0.59699     -0.498428   -0.027608    -0.363891    0.130121    0.0660942
 -0.316663    -0.0976241    -0.205461   -0.577986    0.251132   -0.182775    -0.120684   -0.373439    -0.366466    0.408491     0.138827   -0.56141    -0.35326     0.775581    0.164491    0.34601     0.00453939  -0.265658    0.0223313     0.428202     0.271352     0.515425    0.253129    -0.268699   -0.164297   -0.159444
  0.815526     0.000711397  -0.364997    0.0651705  -0.0661351   0.173935     0.160855   -0.427148     0.0277019  -0.790523     0.124374   -0.0652128   0.269083    0.392459   -0.150501    0.300822    0.275012     0.190398   -0.241163     -0.377455     0.166099     0.155016    0.0109582   -0.753356   -0.0243181   0.158092
  0.285695     0.169014     -0.448683    0.223443    0.29953     0.244592    -0.180171    0.197078    -0.153795   -0.0239809   -0.0729951   0.0792106  -0.160054    0.160614   -0.0113523  -0.52588     0.020103     0.340217   -0.577093     -0.261236    -0.125853    -0.196477   -0.456502    -1.03045    -0.0108157  -0.221137
  0.247414    -0.249641      0.130599   -0.72333    -0.56514    -0.322023     0.240376    0.509147     0.216502   -0.690804    -0.0872727  -0.424987   -0.350627   -0.0394171   0.0055759  -0.387439    0.514555    -0.038565   -0.132248     -0.465814    -0.135081     0.118002    0.129609     0.0271528   0.0392918   0.411073
  0.265867    -0.352543     -0.13869    -0.296762   -0.326717   -0.210382     0.226615    0.72924     -0.145375   -0.293069    -0.440541   -0.88889    -0.241927    0.0950829  -0.406315   -0.212207    0.295518    -0.22017    -0.317047      0.503165    -0.329485     0.610106   -0.123097    -0.32683    -0.035515    0.236973
  0.323512    -0.101326     -0.139318    0.439369   -0.0743629  -0.0121916   -0.318384   -0.166559    -0.650339   -0.378472     0.1044     -0.31824     0.0512609  -0.0066161   0.194765   -0.624335    0.406205     0.216559    0.71123      -0.236678    -0.609744     0.178217   -0.236712    -0.123186   -0.108672   -0.248083
 -0.0859215   -0.179114     -0.159603    0.208384   -0.177347   -0.249428     0.124648    0.181214     0.529055   -0.638833     0.0815222   0.320919    0.409527    0.208284    0.482028   -0.439625    0.524864    -0.244996    0.918398     -0.462868     0.883753     0.165586   -0.342037     0.281916    0.526225   -0.0350326
 -0.511223     0.532327      0.483125   -0.14268     0.14012     0.0342089   -0.610528    0.64159     -0.205026    0.465718     0.152291    0.23515    -0.306949   -0.3896      0.0559103  -0.529427   -0.378581    -0.0455342   0.173044      0.181792     0.150081    -0.365782   -0.302067     0.545256   -0.460598   -0.0959473
  0.00687674   0.251439      0.535529   -0.0338526   0.0601318  -0.151784    -0.10132     0.731894     0.262903   -0.188559    -0.188048    0.442485   -0.0631788   0.0481366  -0.322698   -0.332132    0.0292871    0.45301     0.242808     -0.013576    -0.272233    -0.0854723   0.22172      0.25873     0.215995    0.0629179
 -0.543427     0.630755     -0.332292   -0.0845923   0.106185    0.407684     0.0632717   0.42944     -0.428882    0.323125    -0.288446    0.128902    0.203128   -0.130527   -0.656114    0.0964512   0.0765791    0.8044      0.378462      0.393448    -0.48444      0.523155   -1.04919     -0.117473    0.279348    0.00203507
  0.472771     0.628027     -0.465605   -0.754942    0.0319013   0.0463474   -0.15072     0.563817    -0.195634    0.00239772   0.672322   -0.0790158   0.121093    0.179987   -0.514625   -0.133306    0.344424     0.0692562   0.181856      0.0551087    0.423872     0.275731   -0.871405    -0.101531    0.223611    0.113435
 -0.28966      0.310943      0.234643    0.396103   -0.461811   -0.328509    -0.506651   -0.304926     0.382827   -0.0128538   -0.231329    0.123       0.15602     0.190665    0.201023   -0.19202    -0.0212766    0.0925548   0.241499     -0.0128745    0.133917     0.177116   -0.810479     0.0885552   0.494359   -0.760269
 -0.421875    -0.115484      0.416648    0.599496   -0.302993    0.092082     0.336958   -0.693249     0.135954    0.549224    -0.0678936   0.114594    0.274741   -0.498448    0.115105   -0.203697   -0.0308934    0.10099    -0.428834     -0.487118     0.0325099   -0.667435    0.615911     0.205914    0.117085   -0.262609
 -0.0161864    0.237811     -0.109379    0.339594    0.967138   -0.202649    -1.3115      0.0469137    0.0478514   0.31236     -0.069596   -0.0129614   0.144278    0.466749    0.0975951   0.502752   -0.179926     0.899121    0.0492059     0.218954    -0.0424465   -0.263117    0.465718    -0.0638299   0.0329511  -0.67484
 -0.0971822    0.282213     -0.18942     0.35923     0.439004    0.258895     0.0466122  -0.575124    -0.337889    0.471704     0.652445    0.490687    0.390206    0.236513    0.23813     0.273893   -0.432083     0.311611    0.643221     -0.229168     0.107269    -0.250826    0.322805     0.281272    0.349814   -0.358179
 -0.0266113    0.189522      0.311932   -0.460692   -0.550083    0.0660026    0.145184   -0.16792      0.358483    0.00702975  -1.07683     0.199001   -0.425838    0.232962   -0.0722501   0.458073   -0.0982983    0.105994   -0.171787      0.720954     0.144103    -0.16685    -0.0113066    0.138614   -0.818516    0.177529
 -0.045099    -0.282374      0.326397   -0.236077   -0.40634     0.0370257   -0.414421    0.246124    -0.139717    0.0287968   -0.62867     0.947603    0.281615    0.103392   -0.0751769   0.576596    0.0367515    0.225639   -0.0550649     0.350176     1.02274      0.208388   -0.00334699  -0.0714629   0.980306    0.339692
 -0.273064    -0.216878      0.535074   -0.254509    0.0188883  -0.303772     0.311281    0.0950637    1.05595     0.275822     0.121       0.140221   -0.0539027   0.122352   -0.372151    0.633458   -0.25634     -0.328613   -0.20679      -0.062699     0.505875    -0.0530837   0.523321     0.705702   -0.152569    0.483245
 -0.670289    -0.17992       0.603473   -0.0671816   0.229296    0.18257      0.303373   -0.174355     0.0549634   0.263089     0.453736    0.489826    0.176188   -0.0954078   0.722567    1.14072     0.59441     -0.518466    0.265653      0.758192     0.108539    -0.580079    0.359655     0.525982    0.231912    0.533322
  0.00229557  -0.184974     -0.333928   -0.0973172   0.282177    0.397928     0.401076    0.6166      -0.332339   -0.0397995    0.590131   -0.300749   -0.0968923  -0.656042   -0.123084   -0.200968   -0.250461     0.0191837  -0.171006     -0.0994879   -0.408292    -0.489923    0.47801      0.0226957  -0.510427    0.894261
 -0.116928     0.144271     -0.0694378   0.25745    -0.0777773   0.283588     0.485131   -0.532122    -0.454839    0.0376318    0.496082   -0.754431    0.204231   -0.71338    -0.179727    0.0159467   0.166052    -0.165632   -0.239714     -0.0585402    0.0196786    0.389148   -0.29603     -0.141944   -0.522541   -0.174739
 -0.105635    -0.605305     -0.258512    0.34515     0.328419    0.346196     0.427416   -0.00181654   0.0609196  -0.254839    -0.0349207  -0.409278   -0.105874    0.0470945  -0.344671    0.10022    -0.109733    -0.200776   -0.22603       0.127526    -0.170266     0.147529    0.204443    -0.259857    0.0248797   0.159774
  0.377721     0.100252      0.0856663  -0.289934   -0.0982126  -0.51045     -0.295325   -0.00774542  -0.224467   -0.00365634   0.247972    0.122289   -0.146312    0.0914555   0.645045    0.0179703   0.115762    -0.0162883   0.0661961    -0.425887     0.0622049   -0.225043    0.464482     0.0190113  -0.157951    0.235532[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410104
[ Info: iteration 2, average log likelihood -1.410091
[ Info: iteration 3, average log likelihood -1.410077
[ Info: iteration 4, average log likelihood -1.410064
[ Info: iteration 5, average log likelihood -1.410051
[ Info: iteration 6, average log likelihood -1.410039
[ Info: iteration 7, average log likelihood -1.410026
[ Info: iteration 8, average log likelihood -1.410014
[ Info: iteration 9, average log likelihood -1.410002
[ Info: iteration 10, average log likelihood -1.409991
┌ Info: EM with 100000 data points 10 iterations avll -1.409991
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.613186e+05
      1       6.988384e+05      -2.624802e+05 |       32
      2       6.886012e+05      -1.023720e+04 |       32
      3       6.844937e+05      -4.107519e+03 |       32
      4       6.823393e+05      -2.154363e+03 |       32
      5       6.808771e+05      -1.462208e+03 |       32
      6       6.798303e+05      -1.046846e+03 |       32
      7       6.789939e+05      -8.363176e+02 |       32
      8       6.783447e+05      -6.492244e+02 |       32
      9       6.778405e+05      -5.041764e+02 |       32
     10       6.774331e+05      -4.074687e+02 |       32
     11       6.770866e+05      -3.464587e+02 |       32
     12       6.767868e+05      -2.998252e+02 |       32
     13       6.765136e+05      -2.731783e+02 |       32
     14       6.762391e+05      -2.744718e+02 |       32
     15       6.759877e+05      -2.514493e+02 |       32
     16       6.757516e+05      -2.361257e+02 |       32
     17       6.755400e+05      -2.115501e+02 |       32
     18       6.753592e+05      -1.808383e+02 |       32
     19       6.751720e+05      -1.872010e+02 |       32
     20       6.749882e+05      -1.837424e+02 |       32
     21       6.748312e+05      -1.569941e+02 |       32
     22       6.746994e+05      -1.317911e+02 |       32
     23       6.745783e+05      -1.211383e+02 |       32
     24       6.744575e+05      -1.207864e+02 |       32
     25       6.743506e+05      -1.069194e+02 |       32
     26       6.742513e+05      -9.924708e+01 |       32
     27       6.741599e+05      -9.146306e+01 |       32
     28       6.740550e+05      -1.048840e+02 |       32
     29       6.739584e+05      -9.663267e+01 |       32
     30       6.738842e+05      -7.415063e+01 |       32
     31       6.738134e+05      -7.078519e+01 |       32
     32       6.737339e+05      -7.953117e+01 |       32
     33       6.736574e+05      -7.649325e+01 |       32
     34       6.735886e+05      -6.885143e+01 |       32
     35       6.735297e+05      -5.884143e+01 |       32
     36       6.734834e+05      -4.633819e+01 |       32
     37       6.734391e+05      -4.432501e+01 |       32
     38       6.733923e+05      -4.674101e+01 |       32
     39       6.733464e+05      -4.595317e+01 |       32
     40       6.733052e+05      -4.113817e+01 |       32
     41       6.732663e+05      -3.888353e+01 |       32
     42       6.732305e+05      -3.587690e+01 |       32
     43       6.731956e+05      -3.485073e+01 |       32
     44       6.731610e+05      -3.458690e+01 |       32
     45       6.731262e+05      -3.478426e+01 |       32
     46       6.730902e+05      -3.602317e+01 |       32
     47       6.730501e+05      -4.011132e+01 |       32
     48       6.730132e+05      -3.693916e+01 |       32
     49       6.729786e+05      -3.455035e+01 |       32
     50       6.729471e+05      -3.155817e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 672947.0562245515)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422262
[ Info: iteration 2, average log likelihood -1.417060
[ Info: iteration 3, average log likelihood -1.415454
[ Info: iteration 4, average log likelihood -1.414115
[ Info: iteration 5, average log likelihood -1.412868
[ Info: iteration 6, average log likelihood -1.411995
[ Info: iteration 7, average log likelihood -1.411529
[ Info: iteration 8, average log likelihood -1.411290
[ Info: iteration 9, average log likelihood -1.411146
[ Info: iteration 10, average log likelihood -1.411044
[ Info: iteration 11, average log likelihood -1.410964
[ Info: iteration 12, average log likelihood -1.410895
[ Info: iteration 13, average log likelihood -1.410836
[ Info: iteration 14, average log likelihood -1.410782
[ Info: iteration 15, average log likelihood -1.410733
[ Info: iteration 16, average log likelihood -1.410689
[ Info: iteration 17, average log likelihood -1.410648
[ Info: iteration 18, average log likelihood -1.410609
[ Info: iteration 19, average log likelihood -1.410574
[ Info: iteration 20, average log likelihood -1.410541
[ Info: iteration 21, average log likelihood -1.410509
[ Info: iteration 22, average log likelihood -1.410480
[ Info: iteration 23, average log likelihood -1.410453
[ Info: iteration 24, average log likelihood -1.410428
[ Info: iteration 25, average log likelihood -1.410404
[ Info: iteration 26, average log likelihood -1.410381
[ Info: iteration 27, average log likelihood -1.410360
[ Info: iteration 28, average log likelihood -1.410340
[ Info: iteration 29, average log likelihood -1.410321
[ Info: iteration 30, average log likelihood -1.410303
[ Info: iteration 31, average log likelihood -1.410287
[ Info: iteration 32, average log likelihood -1.410271
[ Info: iteration 33, average log likelihood -1.410256
[ Info: iteration 34, average log likelihood -1.410242
[ Info: iteration 35, average log likelihood -1.410228
[ Info: iteration 36, average log likelihood -1.410215
[ Info: iteration 37, average log likelihood -1.410203
[ Info: iteration 38, average log likelihood -1.410191
[ Info: iteration 39, average log likelihood -1.410180
[ Info: iteration 40, average log likelihood -1.410169
[ Info: iteration 41, average log likelihood -1.410159
[ Info: iteration 42, average log likelihood -1.410149
[ Info: iteration 43, average log likelihood -1.410139
[ Info: iteration 44, average log likelihood -1.410130
[ Info: iteration 45, average log likelihood -1.410121
[ Info: iteration 46, average log likelihood -1.410112
[ Info: iteration 47, average log likelihood -1.410103
[ Info: iteration 48, average log likelihood -1.410095
[ Info: iteration 49, average log likelihood -1.410087
[ Info: iteration 50, average log likelihood -1.410079
┌ Info: EM with 100000 data points 50 iterations avll -1.410079
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0876123   -0.0960888   -0.267518    0.0587844  -0.258454    0.055779     0.23756      -0.20988    -0.141521     -0.265073     0.206254   -0.35273      0.379046   -0.246697    -0.00453056  -0.105171    -0.194408    -0.166332    -0.00779565  -0.0229403     0.160922    0.208737    -0.166279   -0.108383   -0.0473153   -0.131583
 -0.0319375   -0.374695     0.211716   -0.047403    0.122551    0.210948    -0.0935633    -0.221895   -0.000984563   0.15718     -0.519194    0.140827    -0.525772    0.437805    -0.119007     0.385794    -0.661602     0.0261623   -0.132408     0.238532     -0.326772   -0.106808     0.636138   -0.190461   -0.42667      0.185796
 -0.761442    -0.435208    -0.16496     0.432466    0.259937    0.310453     0.334727      0.0492428  -0.129905      0.0560506   -0.0202219  -0.0757965   -0.391748   -0.452281     0.629401     0.104357     0.0263305   -0.173833    -0.0375089    0.0590714    -0.453262   -0.369454     0.500363    0.0353342   0.127955     0.316513
 -0.418675    -0.151571     0.27106    -0.423351   -0.133105    0.0345373    0.14618      -0.303701    0.454368      0.130429    -0.182802    0.206985    -0.0817392   0.229482     0.323109     0.977716    -0.00224239  -0.487838    -0.00581638   0.529952      0.539283   -0.312451     0.232818    0.444082   -0.159296     0.398795
 -0.605116     0.540637     0.47057    -0.310616    0.0218592  -0.061519    -0.444942      0.847677   -0.0105843     0.455265     0.0357179   0.178951    -0.36503    -0.287661     0.0759864   -0.618796    -0.286226     0.0467313    0.102905     0.189815      0.0620877  -0.244255    -0.287606    0.580315   -0.146915    -0.350045
 -0.0961643   -0.0109564   -0.339765   -0.439729    0.0844972   0.0143       0.197155      0.819363   -0.39731       0.00496171   0.0387989  -0.581395     0.0630902  -0.210056    -0.670894    -0.292215     0.28519      0.222839    -0.237653     0.110841     -0.181347   -0.268403     0.193292   -0.229517   -0.475661     0.495095
  1.12279      0.53594      0.300545   -0.329867   -0.224963   -0.0803      -0.101192     -0.17674     0.0600067    -0.172524     0.296433   -0.118053     0.639165    0.366083    -0.595455    -0.223116    -0.0906295    0.446241    -0.153249    -0.342398      0.492972    0.414895    -0.590139   -0.271985   -0.0488022   -0.516525
 -0.198996    -0.304592    -0.945254    0.0202792   0.47743    -0.0313972   -0.225593     -0.362954   -0.266713      0.0991088    0.331643   -0.430325    -0.266889    0.456696     0.0975492    0.416917     0.0773001   -0.0832382   -0.0117185   -0.000762297   0.56264    -0.0230611   -0.191454   -0.49214     0.106558     0.0344129
  9.01756e-5  -0.225299    -0.118163    0.0591044   0.0873864  -0.0191756    0.175832      0.16734     0.0101818    -0.153074    -0.0963931  -0.37734     -0.210067   -0.0660579   -0.20272     -0.181651     0.0330436    0.0199519   -0.11879      0.00684143   -0.257806    0.166511     0.0368046  -0.193524   -0.0594948    0.110398
 -0.205854     0.0090903   -0.21979     0.0374432  -0.333167   -0.139311    -0.0937118    -0.0794437   0.117162     -0.3227       0.425487    0.083491     0.750137    0.255896     0.18678     -0.27983      0.404274    -0.142403     1.06229     -0.335078      0.735836    0.0394863   -0.341872    0.321481    0.805865    -0.254646
  0.00974461   0.122086     0.0896052   0.106974   -0.198887   -0.0381532    0.137838      0.324411    0.813885     -0.548969    -0.444051    0.245987    -0.209385    0.559094    -0.177988    -0.0623489    0.0419499   -0.0768389    0.0351971    0.36237       0.2574      0.317729    -0.451677   -0.114741   -0.0254028   -0.217334
  0.412127     0.199567     0.195739    0.490808   -0.125729    0.143339    -0.000801557   0.532495    0.0678111    -0.359936     0.0496104   0.538678     0.231863   -1.00369      0.00337907  -0.114734     0.122973     0.567977     0.0646948   -0.511632     -0.108311   -0.658565    -0.103668    0.198703   -0.0993366    0.63831
 -0.230509     0.315818    -0.119085    0.634288    0.197643   -0.0296559   -0.273569     -0.548015    0.0364053     0.380782     0.183947    0.471946     0.423074    0.127477     0.243261     0.0680573   -0.3681       0.472398     0.182411    -0.237875      0.0986794  -0.450315     0.123183    0.0224596   0.352129    -0.80343
  0.773881    -0.00873039   0.0782723  -0.568337   -0.576215   -0.674489    -0.425428     -0.251064   -0.349413      0.239825     0.188109    0.0245458   -0.274419    0.134302     0.902873     0.0724231    0.060625    -0.253832    -0.0856485   -0.672035      0.145779   -0.681441     0.324085   -0.0535521  -0.428865    -0.0315106
  0.451029    -0.0854703   -0.0593544  -0.478131   -0.460807   -0.035621     0.27449       0.753443    0.0621969    -0.541404     0.0449535  -0.604184    -0.344333   -0.127498    -0.355407    -0.393311     0.408112    -0.599837    -0.337141     0.0931825    -0.107682    0.643831    -0.530588   -0.0744102   0.0775934    0.367581
  0.334003     0.397442    -0.244761   -0.589591    0.567862    0.129592    -0.158562      0.403448   -0.521233      0.24906      1.19588     0.415136    -0.123761    0.176045     0.148635    -0.17538     -0.116845     0.276276     0.170197    -0.04277       0.287248    0.347906     0.0653301  -0.077172    0.413437     0.307592
 -0.0379503    0.349424     0.632478    0.371439    0.254221   -0.0575447   -0.174702     -0.512888   -0.306236      0.648144     0.0332834   0.0886233    0.241819   -0.329425    -0.363806    -0.0388236   -0.0774267    0.305408    -0.154899     0.605045     -0.0115626   0.238317    -0.183842    0.130143   -0.317337    -0.21995
 -0.059269    -0.0215594    0.0316305   0.0720382   0.0653742  -0.00507848  -0.0308936     0.12246     0.052834     -0.091037     0.0207396   0.0043264   -0.057702    0.0407631   -0.0601244    0.0350965    0.0272907    0.0753058    0.0206484   -0.000828267  -0.0193399   0.00337486  -0.0323704  -0.0133939   0.0169314    0.101405
 -0.316989     0.517439    -0.255604   -0.0372078   0.0266945   0.53835      0.0377098     0.319397   -0.562042      0.145143    -0.221199    0.0137792    0.165895   -0.0990852   -0.681782     0.216131     0.265075     0.605432     0.421372     0.564225     -0.615974    0.575509    -1.19017    -0.0680371   0.184122     0.0720877
 -0.0639617    0.298404    -0.0622323  -0.325671    0.197952   -0.0770682   -0.442395     -0.257924   -0.229161      0.476365    -0.0109442  -0.0227127   -0.115645    0.516457     0.296691     0.312752     0.211364     0.240974     0.196823    -0.133099      0.0132651  -0.125463     0.142295    0.0704229   0.00416757  -0.192096
 -0.443059     0.162781    -0.125691    0.2203      0.607618    0.250514     0.144514      0.364803    0.392937      0.217026     0.23239    -0.0758411    0.442228   -0.146835    -0.65679      0.325197    -0.128337    -0.164703    -0.13677      0.300684      0.499968   -0.0219148   -0.0469174   0.153762    0.144092     0.102854
 -0.159938     0.272853    -0.332442    0.763232    0.493477   -0.0020247    0.132153     -0.0807352   0.213202     -0.39596      1.2136     -0.237118    -0.190017   -0.413175     0.512427    -0.152246    -0.483459    -0.540799     0.281734    -0.289962     -0.220248   -0.271022     0.0255064   0.0555814  -0.467623    -0.177162
  0.229808     0.0138947    0.356532   -0.217963   -0.145575    0.454344    -0.00865684   -0.0546779  -0.0967218     0.213891     0.179311    0.735109     0.183036    0.11023     -0.00915887   0.0464597    0.0148755   -0.114055    -0.329067    -0.118512      0.190163   -0.669935    -0.22443    -0.0235184   0.0378151   -0.147543
 -0.033664     0.0804034   -0.0615404   0.0154438  -0.152468    0.582668     0.591804     -0.740368   -0.729725      0.0855269    0.637573   -0.742879     0.138972   -0.713313    -0.189525     0.00810845   0.151545    -0.170566    -0.454262    -0.229652      0.0906716   0.283012     0.06419    -0.291292   -0.559543     0.0837932
  0.42869     -0.15859      0.267498    0.165097   -0.118056   -0.319655    -0.437246     -0.0675568  -0.334057     -0.306536    -0.0760342  -0.25247     -0.0879024   0.175436     0.165042    -0.684614     0.536339     0.33627      0.736048    -0.252788     -0.671822    0.186361    -0.0325386   0.146611   -0.231803    -0.145914
 -0.124542     0.0182282    0.95105    -0.0547857  -0.238857   -0.149801     0.225485     -0.0108407   0.403569      0.131075     0.257414    0.245033     0.12466    -0.0160115   -0.237022     0.473942    -0.121505    -0.0414271    0.487827     0.0282482     0.0422157   0.0402837    0.558643    1.21252     0.133919     0.338938
  0.774165    -0.426141    -0.275166    0.139789    0.145309    0.225723     0.323312     -0.27875    -0.0522599    -0.820158     0.123876    0.00724949   0.437505    0.394685    -0.04156      0.591732     0.384092     0.0728585   -0.338401    -0.339368     -0.106127   -0.0940419    0.706332   -0.504147   -0.0303305    0.479096
 -0.556621    -0.679758     0.475334    0.707612   -0.504602    0.00327077   0.273967     -0.526512    0.471155     -0.0165174   -0.531315   -0.294993     0.296688   -0.0614014   -0.0132556    0.132595     0.00885468  -0.444034    -0.141692    -0.318387     -0.0842838  -0.253574     0.0288809   0.219684   -0.0882401   -0.123031
  0.0466871    0.0156641    0.422151   -0.386397   -0.366252   -0.266433    -0.674194      0.312859   -0.0551644     0.105792    -0.857412    0.843935     0.145015    0.34339     -0.330961     0.315064     0.12625      0.62615     -0.00438544   0.283827      0.479533    0.126427    -0.0146527   0.0950219   0.404984     0.212014
  0.15091     -0.264909    -0.10028     0.159755   -0.191836   -0.457279    -0.412738     -0.622227    0.100887     -0.0378652   -0.188222   -0.126856    -0.130303    0.00772484   0.583012     0.225198    -0.0928339   -0.0404962   -0.1141      -0.240109      0.0692677   0.633978    -0.122655    0.0648162   0.568554    -0.415165
 -0.175017    -0.382566     0.236134   -0.459369   -0.286733   -0.447154     0.399372      0.276924    0.431054     -0.366091    -0.0400702  -0.176922    -0.343784    0.0334777    0.364853    -0.170881     0.11612     -0.00678672  -0.16462     -0.18417       0.154157    0.134915     0.543303    0.127863    0.0502351    0.27648
  0.303254     0.103757    -0.59561     0.238433    0.165148    0.238017    -0.244351      0.162387   -0.341081     -0.279494    -0.227743   -0.0372349   -0.245986    0.206502     0.0511221   -0.613383     0.112005     0.438663    -0.266663    -0.309272     -0.312711   -0.0925356   -0.451227   -1.1516      0.09076     -0.310699[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410072
[ Info: iteration 2, average log likelihood -1.410065
[ Info: iteration 3, average log likelihood -1.410057
[ Info: iteration 4, average log likelihood -1.410050
[ Info: iteration 5, average log likelihood -1.410043
[ Info: iteration 6, average log likelihood -1.410037
[ Info: iteration 7, average log likelihood -1.410030
[ Info: iteration 8, average log likelihood -1.410024
[ Info: iteration 9, average log likelihood -1.410017
[ Info: iteration 10, average log likelihood -1.410011
┌ Info: EM with 100000 data points 10 iterations avll -1.410011
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
