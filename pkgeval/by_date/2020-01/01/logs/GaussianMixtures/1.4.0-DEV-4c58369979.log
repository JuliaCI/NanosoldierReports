Julia Version 1.4.0-DEV.672
Commit 4c58369979 (2019-12-30 22:17 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed CMakeWrapper ─────── v0.2.3
 Installed GaussianMixtures ─── v0.3.0
 Installed OpenBLAS_jll ─────── v0.3.7+2
 Installed CMake ────────────── v1.1.2
 Installed Arpack ───────────── v0.4.0
 Installed SpecialFunctions ─── v0.9.0
 Installed StatsFuns ────────── v0.9.3
 Installed Clustering ───────── v0.13.3
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Rmath ────────────── v0.6.0
 Installed URIParser ────────── v0.4.0
 Installed NearestNeighbors ─── v0.4.4
 Installed LegacyStrings ────── v0.4.1
 Installed SortingAlgorithms ── v0.3.1
 Installed StaticArrays ─────── v0.12.1
 Installed BinDeps ──────────── v1.0.0
 Installed FillArrays ───────── v0.8.2
 Installed Distributions ────── v0.21.11
 Installed Blosc ────────────── v0.5.1
 Installed Missings ─────────── v0.4.3
 Installed Parameters ───────── v0.12.0
 Installed BinaryProvider ───── v0.5.8
 Installed OrderedCollections ─ v1.1.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed DataAPI ──────────── v1.1.0
 Installed FileIO ───────────── v1.2.1
 Installed QuadGK ───────────── v2.3.1
 Installed HDF5 ─────────────── v0.12.5
 Installed Compat ───────────── v2.2.0
 Installed DataStructures ───── v0.17.6
 Installed StatsBase ────────── v0.32.0
 Installed Distances ────────── v0.8.2
 Installed PDMats ───────────── v0.9.10
 Installed JLD ──────────────── v0.9.1
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+2
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_wa9u76/Project.toml`
 [no changes]
  Updating `/tmp/jl_wa9u76/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_HPFlxL/Project.toml`
 [no changes]
  Updating `/tmp/jl_HPFlxL/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_A7Z48Z/Project.toml`
 [no changes]
  Updating `/tmp/jl_A7Z48Z/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_7zX3NZ/Project.toml`
 [no changes]
  Updating `/tmp/jl_7zX3NZ/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_u9uTMq/Project.toml`
 [no changes]
  Updating `/tmp/jl_u9uTMq/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_u9uTMq/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -2.952778747494219e6, [31278.301535157814, 68721.6984648422], [-12029.834819542837 -30701.749334106687 -6950.836299374918; 11508.416162154152 30459.18886701049 7217.188635681583], [[23933.614049783064 9539.951404880272 -1314.1400008177995; 9539.951404880272 40698.98421561969 4584.780805596158; -1314.1400008177993 4584.780805596158 30958.958720964052], [76529.86301081118 -9686.435709450849 1493.2692439963935; -9686.435709450849 58021.430827841934 -4584.586734227865; 1493.2692439963935 -4584.586734227865 68371.0153301293]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.810185e+03
      1       1.312751e+03      -4.974343e+02 |        7
      2       1.225358e+03      -8.739301e+01 |        3
      3       1.119168e+03      -1.061902e+02 |        4
      4       1.045995e+03      -7.317248e+01 |        3
      5       9.880158e+02      -5.797927e+01 |        0
      6       9.880158e+02       0.000000e+00 |        0
K-means converged with 6 iterations (objv = 988.0158290932541)
┌ Info: K-means with 272 data points using 6 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.074011
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.722375
[ Info: iteration 2, lowerbound -3.558295
[ Info: iteration 3, lowerbound -3.401415
[ Info: iteration 4, lowerbound -3.249955
[ Info: iteration 5, lowerbound -3.119775
[ Info: dropping number of Gaussions to 7
[ Info: iteration 6, lowerbound -3.006836
[ Info: dropping number of Gaussions to 5
[ Info: iteration 7, lowerbound -2.905109
[ Info: iteration 8, lowerbound -2.809514
[ Info: iteration 9, lowerbound -2.734333
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.659545
[ Info: iteration 11, lowerbound -2.589891
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.516922
[ Info: iteration 13, lowerbound -2.448729
[ Info: iteration 14, lowerbound -2.396272
[ Info: iteration 15, lowerbound -2.356747
[ Info: iteration 16, lowerbound -2.328112
[ Info: iteration 17, lowerbound -2.311071
[ Info: iteration 18, lowerbound -2.307869
[ Info: dropping number of Gaussions to 2
[ Info: iteration 19, lowerbound -2.302918
[ Info: iteration 20, lowerbound -2.299260
[ Info: iteration 21, lowerbound -2.299256
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299254
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Wed Jan  1 15:47:05 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Wed Jan  1 15:47:11 2020: K-means with 272 data points using 6 iterations
11.3 data points per parameter
, Wed Jan  1 15:47:12 2020: EM with 272 data points 0 iterations avll -2.074011
5.8 data points per parameter
, Wed Jan  1 15:47:14 2020: GMM converted to Variational GMM
, Wed Jan  1 15:47:19 2020: iteration 1, lowerbound -3.722375
, Wed Jan  1 15:47:19 2020: iteration 2, lowerbound -3.558295
, Wed Jan  1 15:47:19 2020: iteration 3, lowerbound -3.401415
, Wed Jan  1 15:47:19 2020: iteration 4, lowerbound -3.249955
, Wed Jan  1 15:47:19 2020: iteration 5, lowerbound -3.119775
, Wed Jan  1 15:47:20 2020: dropping number of Gaussions to 7
, Wed Jan  1 15:47:20 2020: iteration 6, lowerbound -3.006836
, Wed Jan  1 15:47:20 2020: dropping number of Gaussions to 5
, Wed Jan  1 15:47:20 2020: iteration 7, lowerbound -2.905109
, Wed Jan  1 15:47:20 2020: iteration 8, lowerbound -2.809514
, Wed Jan  1 15:47:20 2020: iteration 9, lowerbound -2.734333
, Wed Jan  1 15:47:20 2020: dropping number of Gaussions to 4
, Wed Jan  1 15:47:20 2020: iteration 10, lowerbound -2.659545
, Wed Jan  1 15:47:20 2020: iteration 11, lowerbound -2.589891
, Wed Jan  1 15:47:20 2020: dropping number of Gaussions to 3
, Wed Jan  1 15:47:20 2020: iteration 12, lowerbound -2.516922
, Wed Jan  1 15:47:20 2020: iteration 13, lowerbound -2.448729
, Wed Jan  1 15:47:20 2020: iteration 14, lowerbound -2.396272
, Wed Jan  1 15:47:20 2020: iteration 15, lowerbound -2.356747
, Wed Jan  1 15:47:20 2020: iteration 16, lowerbound -2.328112
, Wed Jan  1 15:47:20 2020: iteration 17, lowerbound -2.311071
, Wed Jan  1 15:47:20 2020: iteration 18, lowerbound -2.307869
, Wed Jan  1 15:47:20 2020: dropping number of Gaussions to 2
, Wed Jan  1 15:47:20 2020: iteration 19, lowerbound -2.302918
, Wed Jan  1 15:47:20 2020: iteration 20, lowerbound -2.299260
, Wed Jan  1 15:47:20 2020: iteration 21, lowerbound -2.299256
, Wed Jan  1 15:47:20 2020: iteration 22, lowerbound -2.299254
, Wed Jan  1 15:47:20 2020: iteration 23, lowerbound -2.299254
, Wed Jan  1 15:47:20 2020: iteration 24, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 25, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 26, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 27, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 28, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 29, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 30, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 31, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 32, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 33, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 34, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 35, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 36, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 37, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 38, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 39, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 40, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 41, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 42, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 43, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 44, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 45, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 46, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 47, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 48, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 49, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: iteration 50, lowerbound -2.299253
, Wed Jan  1 15:47:20 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601416, 95.95490777398582]
β = [178.04509222601416, 95.95490777398582]
m = [4.250300733269907 79.2868669443618; 2.0002292577753673 53.85198717246127]
ν = [180.04509222601416, 97.95490777398582]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484505 -0.007644049042327387; 0.0 0.008581705166333407], [0.375876361194842 -0.008953123827346155; 0.0 0.012748664777409397]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000003
avll from stats: -0.9944997759977481
avll from llpg:  -0.9944997759977486
avll direct:     -0.9944997759977487
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9870270454146854
avll from llpg:  -0.9870270454146857
avll direct:     -0.9870270454146856
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.137528    -0.094775    -0.00164328  -0.0465249    0.0613801    0.0693114     0.118258    -0.0162649   -0.0500434    0.0434232   0.0337876   -0.0793335    0.066409    -0.000220533   0.0537922    -0.0287583    -0.0256875   -0.0393579    0.00941191   0.0618147    0.0391462     0.142761    -0.0880502    0.025482    -0.188281      0.0235201
  0.00350309  -0.117414     0.10721      0.112852    -0.186207    -0.00623197    0.0493363   -0.0525709   -0.201982    -0.0284972  -0.00943983   0.00176018  -0.0761358    0.110726     -0.0238767     0.0531754     0.204245     0.0421123    0.0461383    0.0310979   -0.0401459    -0.0471449    0.0923934   -0.143746    -0.0171017     0.169903
  0.00218814   0.0624517    0.0251729    0.0322544    0.130733    -0.0992026    -0.128798     0.114231    -0.014644     0.0227241  -0.0721349   -0.0453705   -0.0565621   -0.143443      0.0353001    -0.0192838    -0.115655     0.0677155    0.0578806    0.0806491    0.0251225     0.0375507   -0.0374559    0.0496489    0.0124701     0.136556
 -0.00795193  -0.0405823   -0.0346914    0.00844021  -0.114533     0.160011      0.00299533  -0.0464653   -0.219202     0.0642979   0.00536326   0.0310031    0.163609     0.113855     -0.149188      0.118709     -0.00873028  -0.0400033    0.165862    -0.0137032    0.194837     -0.0383419    0.0467156   -0.158031    -0.0396467    -0.0381801
  0.0585569   -0.0186972   -0.0787749   -0.102637     0.0508013    0.0181338     0.0500289    0.00085478   0.00896094   0.229612    0.205248     0.0793272    0.0535322   -0.0887279     0.0383535    -0.15804       0.0121109    0.136311    -0.0621653   -0.200735     0.0450708    -0.31552     -0.00660436   0.0848168    0.0109649     0.0154073
 -0.236944    -0.050041     0.0920483    0.123428    -0.0277573   -0.0900534     0.117371     0.0864929   -0.0190637   -0.184191    0.0256585   -0.0430882   -0.264515     0.0412186    -0.109516     -0.112923     -0.0748147    0.0970739    0.0708015   -0.0695068   -0.130746     -0.0718279   -0.0529326    0.166079    -0.0361209    -0.174504
 -0.113722     0.0224511   -0.302566     0.0148391    0.0760357   -0.0248941     0.195519     0.123912    -0.0319924    0.0558036  -0.146965     0.249043     0.0794656   -0.111496      0.142859     -0.0487995     0.0651032    0.0262237    0.070057    -0.0848688   -0.0116828     0.0269658   -0.0166098    0.170017     0.0173222     0.133075
  0.0617113   -0.0300011   -0.0569994    0.122693     0.19484      0.036703      0.0994867   -0.186616     0.0470493   -0.0767305  -0.0577465    0.0197416   -0.0219845    0.0737169    -0.0278658    -0.0330293    -0.0437457   -0.115535    -0.0929859    0.068337     0.0265117    -0.110057    -0.0347026   -0.0511418    0.0365882     0.126826
 -0.0749598    0.133181     0.0917955   -0.0379078   -0.0467873   -0.016835      0.10713     -0.156315    -0.0435617    0.034221   -0.115976     0.291498     0.124513     0.042669     -0.0326684     0.0293827     0.109113    -0.17775      0.138322     0.158821     0.112525      0.00594002  -0.0573825   -0.0302484   -0.0885634    -0.0131559
  0.022616     0.0776765   -0.159084    -0.0073587   -0.0674459    0.0395077     0.0414814    0.114698    -0.200882    -0.114069    0.13913      0.0950275   -0.0753377    0.105514     -0.1477       -0.190576     -0.0274932   -0.177302     0.116933     0.0261277    0.0175646     0.122139     0.0626333   -0.0476684    0.0689125     0.00765874
  0.12459     -0.0125267    0.0982077   -0.0519315   -0.125839    -0.0143057    -0.00156645   0.114484     0.116883    -0.248901    0.0991336   -0.0352813    0.139596     0.0161034    -0.042237      0.0286288     0.0534379    0.00733832   0.117293     0.110327     0.171156      0.0568002    0.189742    -0.0170883   -0.109345     -0.0921092
  0.22147      0.0577898   -0.126234    -0.016029     0.00612102   0.00399647   -0.146342    -0.174703    -0.116184    -0.253408    0.0341941   -0.114541    -0.0310753    0.15716      -0.102478      0.205833      0.0463857    0.0214798   -0.055725    -0.107248    -0.000320554   0.0527491    0.0962745    0.0667169   -0.178837     -0.0114568
 -0.324258    -0.15865      0.0274001    0.0445915    0.162077    -0.0501613    -0.0365178   -0.0271853   -0.259748    -0.0454602  -0.0327674   -0.0368256    0.143422    -0.0191455    -0.054483      0.0613792     0.0329308   -0.054924    -0.0581243   -0.117346    -0.0567142     0.0297746    0.146208     0.0110584   -0.208281      0.0382881
 -0.144843     0.0405851    0.0935646    0.0422192    0.272341     0.0391375     0.0579857    0.219159     0.00847944  -0.0373899  -0.15124     -0.155273     0.0694075   -0.0876956     0.0462328    -0.0583391    -0.130041     0.155083     0.0262143    0.0452798   -0.146563     -0.211948     0.00873018   0.0792002    0.0125257    -0.149143
  0.0574706   -0.180733     0.144527    -0.00476128   0.00365256  -0.184836      0.0599662    0.0902412   -0.147621     0.141972    0.057194    -0.0122422   -0.139717    -0.0226502    -0.106478      0.106994     -0.0822802    0.128395    -0.192887     0.0550915   -0.0805619     0.0994931    0.0931669    0.0427628    0.0409598     0.037889
 -0.0455854    0.117704    -0.0253307   -0.144582     0.164015    -0.139994     -0.140772     0.053238     0.106855    -0.259333    0.00602703  -0.0191965    0.100682    -0.0361659     0.151961      0.0511641     0.0259299   -0.0632155    0.132502     0.0291329    0.092322      0.0292504    0.0474828    0.0760509    0.00690121    0.0619302
 -0.208411    -0.06137     -0.0171482   -0.213333    -0.170587     0.0703662    -0.194723    -0.111433     0.00677839  -0.159481   -0.120032    -0.100939     0.0423807    0.104641     -0.0501964     0.0988404     0.0186209   -0.0637714   -0.0653182   -0.059071    -0.0906825    -0.0701239   -0.0423412    0.121249     0.0578964     0.238946
  0.0598083    0.0346429    0.0888302   -0.0327321    0.191262    -0.0314199     0.147405    -0.130226    -0.0516245    0.104449    0.0310554    0.0331497   -0.0658654    0.0736251     0.0349115    -0.0601662    -0.0285833   -0.148809     0.00368894  -0.0424262   -0.105378     -0.00767028   0.0896128    0.0711187   -0.0370315    -0.21663
  0.0482768    0.229223     0.0944268   -0.0378138   -0.0118127   -0.0535517    -0.0392738    0.0250982    0.135083    -0.055243    0.162895     0.0379767   -0.0533564    0.196912     -0.0784012    -0.0525639     0.137351    -0.00897711  -0.158673    -0.106468     0.0755491     0.0218709    0.0550471    0.0231822    0.0694756     0.0356094
  0.254274     0.0878135   -0.082324     0.0137251    0.0473578   -0.149591      0.0928021    0.0789616   -0.0829561   -0.11758     0.166076     0.0572678    0.11436      0.00968321    0.117728     -0.168112      0.050503     0.018993     0.044078    -0.137534     0.0390967    -0.0761258   -0.00743693  -0.0121363   -0.0440867     0.0738618
  0.0459562    0.0731868    0.128181     0.107512     0.0118276   -0.195345      0.14857      0.161687     0.0394062   -0.0332776  -0.00376943  -0.0504548    0.102324     0.00706869    0.0702397     0.192195      0.207494     0.0610311   -0.0958244   -0.0447814   -0.0154975     0.106308     0.14684     -0.0765924    0.0586372     0.0140831
  0.139201     0.108609    -0.0528881    0.0609894    0.0524511    0.183692     -0.00623862  -0.116143    -0.0336257    0.0872631   0.0196756   -0.0524909   -0.018164    -0.0471575     0.147998     -0.00911235   -0.00347679   0.0653513    0.11444      0.259309    -0.0873786     0.0151314    0.0262206   -0.0239485    0.175859     -0.302561
  0.0260157   -0.0560914    0.108783     0.191941    -0.098375     0.0336536     0.153256    -0.0198879   -0.0672464   -0.107466   -0.206794     0.224991     0.0981584    0.0735148    -0.0604945    -0.051944      0.0265263    0.00507374  -0.143055    -0.00936951  -0.166619     -0.0246249    0.216488    -0.0745337    0.253338     -0.0159084
 -0.0313505   -0.00145771   0.0951544    0.144789    -0.150181    -0.0668895    -0.0334868    0.0711036   -0.223168    -0.0846256  -0.00358679  -0.0645999   -0.0758185   -0.2565       -0.0521459    -0.121676     -0.18897     -0.133483    -0.00950594  -0.101371     0.0465934    -0.099567     0.0511715    0.0500513   -0.0481966    -0.149418
 -0.0799442    0.126307    -0.0205737    0.0582512    0.0639576   -0.000405928   0.127796    -0.0784831    0.0108439    0.0229871  -0.217796    -0.0583604    0.0240029    0.139126     -0.149883      0.0549471     0.223002     0.0191104   -0.0742908   -0.079188     0.0826379    -0.164764     0.103832     0.0116263   -0.143147      0.118188
  0.0642024   -0.0361505    0.103825     0.0764579   -0.0805624   -0.111341      0.122875    -0.0573222    0.0736513   -0.197821   -0.0814156   -0.0529986    0.00536101  -0.0172124    -0.0815432     0.00565838    0.0641077    0.0105543   -0.0296152    0.0599698    0.119332     -0.19171     -0.0765483   -0.00804881   0.0442198     0.0405452
  0.138225     0.119977     0.076679    -0.0105822    0.103311    -0.169934     -0.0557468   -0.136336    -0.0422515   -0.129974    0.065161     0.0522472    0.0905835   -0.0156241     0.0723854    -0.132642     -0.052297     0.0776865    0.0375318    0.113119     0.0807922    -0.0324984    0.0328805   -0.116007     0.124248      0.0428359
  0.0965604   -0.261664     0.00187963  -0.00543884  -0.0361042   -0.0570812    -0.185602    -0.0420715   -0.00196659   0.0675872  -0.0870754    0.133538     0.0449277   -0.0239529     0.224065     -0.105481      0.00302103   0.0965411   -0.178512    -0.0396906    0.0274778    -0.0603602   -0.0466162    0.0131227   -0.0846557     0.15144
  0.0714736   -0.163041     0.143953     0.0299324   -0.0826493    0.040874      0.0448593    0.0743028   -0.0163398   -0.0452123  -0.0627155   -0.210321    -0.0793888    0.0503662    -0.000280575  -0.0670396    -0.0291029    0.0338541   -0.0358475    0.0379907    0.0656678    -0.0792948   -0.0980331    0.0670576   -0.163511     -0.00858203
 -0.0141316    0.101567     0.037708    -0.065847    -0.139448     0.146581      0.0988738    0.0496739    0.0685227    0.21903     0.0599442   -0.148171     0.127826    -0.0154798    -0.0282077     0.0624279    -0.0714095    0.024913     0.126538    -0.0443085    0.146939     -0.0298575    0.145092     0.00742768  -0.20984      -0.118476
  0.100183    -0.21593     -0.171083    -0.0335826    0.119352     0.0180133    -0.0898854    0.128034    -0.180066     0.111583    0.101736     0.0567831   -0.0135655   -0.311496     -0.140216     -0.000756652   0.168711    -0.0124695   -0.0314238    0.00895563   0.0861807     0.0321743   -0.0148343    0.0211847    0.0146761    -0.0618906
 -0.0752502    0.0510642   -0.0761695    0.0310634   -0.221624    -0.049463     -0.158078    -0.0161682    0.024901     0.0568391  -0.195663     0.0423859   -0.0786204    0.0177715     0.0916724    -0.100286      0.121623    -0.209351    -0.0153514    0.0211161    0.0188723     0.206213     0.015441     0.0597943   -0.000747239  -0.0913512kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3886323159790426
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.388702
[ Info: iteration 2, average log likelihood -1.388645
[ Info: iteration 3, average log likelihood -1.388389
[ Info: iteration 4, average log likelihood -1.385729
[ Info: iteration 5, average log likelihood -1.373972
[ Info: iteration 6, average log likelihood -1.362239
[ Info: iteration 7, average log likelihood -1.359662
[ Info: iteration 8, average log likelihood -1.358832
[ Info: iteration 9, average log likelihood -1.358327
[ Info: iteration 10, average log likelihood -1.357941
[ Info: iteration 11, average log likelihood -1.357568
[ Info: iteration 12, average log likelihood -1.357121
[ Info: iteration 13, average log likelihood -1.356490
[ Info: iteration 14, average log likelihood -1.355647
[ Info: iteration 15, average log likelihood -1.354776
[ Info: iteration 16, average log likelihood -1.354013
[ Info: iteration 17, average log likelihood -1.353336
[ Info: iteration 18, average log likelihood -1.352729
[ Info: iteration 19, average log likelihood -1.352239
[ Info: iteration 20, average log likelihood -1.351915
[ Info: iteration 21, average log likelihood -1.351734
[ Info: iteration 22, average log likelihood -1.351639
[ Info: iteration 23, average log likelihood -1.351589
[ Info: iteration 24, average log likelihood -1.351561
[ Info: iteration 25, average log likelihood -1.351545
[ Info: iteration 26, average log likelihood -1.351534
[ Info: iteration 27, average log likelihood -1.351527
[ Info: iteration 28, average log likelihood -1.351521
[ Info: iteration 29, average log likelihood -1.351516
[ Info: iteration 30, average log likelihood -1.351512
[ Info: iteration 31, average log likelihood -1.351509
[ Info: iteration 32, average log likelihood -1.351505
[ Info: iteration 33, average log likelihood -1.351503
[ Info: iteration 34, average log likelihood -1.351500
[ Info: iteration 35, average log likelihood -1.351498
[ Info: iteration 36, average log likelihood -1.351497
[ Info: iteration 37, average log likelihood -1.351495
[ Info: iteration 38, average log likelihood -1.351494
[ Info: iteration 39, average log likelihood -1.351493
[ Info: iteration 40, average log likelihood -1.351492
[ Info: iteration 41, average log likelihood -1.351491
[ Info: iteration 42, average log likelihood -1.351491
[ Info: iteration 43, average log likelihood -1.351490
[ Info: iteration 44, average log likelihood -1.351490
[ Info: iteration 45, average log likelihood -1.351490
[ Info: iteration 46, average log likelihood -1.351489
[ Info: iteration 47, average log likelihood -1.351489
[ Info: iteration 48, average log likelihood -1.351489
[ Info: iteration 49, average log likelihood -1.351489
[ Info: iteration 50, average log likelihood -1.351489
┌ Info: EM with 100000 data points 50 iterations avll -1.351489
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3887015561935439
│     -1.388644681042695
│      ⋮
└     -1.351488900273901
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.351587
[ Info: iteration 2, average log likelihood -1.351490
[ Info: iteration 3, average log likelihood -1.350827
[ Info: iteration 4, average log likelihood -1.344306
[ Info: iteration 5, average log likelihood -1.327785
[ Info: iteration 6, average log likelihood -1.318446
[ Info: iteration 7, average log likelihood -1.315856
[ Info: iteration 8, average log likelihood -1.314697
[ Info: iteration 9, average log likelihood -1.313898
[ Info: iteration 10, average log likelihood -1.313232
[ Info: iteration 11, average log likelihood -1.312633
[ Info: iteration 12, average log likelihood -1.312059
[ Info: iteration 13, average log likelihood -1.311504
[ Info: iteration 14, average log likelihood -1.311025
[ Info: iteration 15, average log likelihood -1.310666
[ Info: iteration 16, average log likelihood -1.310411
[ Info: iteration 17, average log likelihood -1.310228
[ Info: iteration 18, average log likelihood -1.310090
[ Info: iteration 19, average log likelihood -1.309977
[ Info: iteration 20, average log likelihood -1.309877
[ Info: iteration 21, average log likelihood -1.309781
[ Info: iteration 22, average log likelihood -1.309686
[ Info: iteration 23, average log likelihood -1.309590
[ Info: iteration 24, average log likelihood -1.309495
[ Info: iteration 25, average log likelihood -1.309403
[ Info: iteration 26, average log likelihood -1.309320
[ Info: iteration 27, average log likelihood -1.309247
[ Info: iteration 28, average log likelihood -1.309185
[ Info: iteration 29, average log likelihood -1.309131
[ Info: iteration 30, average log likelihood -1.309082
[ Info: iteration 31, average log likelihood -1.309036
[ Info: iteration 32, average log likelihood -1.308991
[ Info: iteration 33, average log likelihood -1.308946
[ Info: iteration 34, average log likelihood -1.308902
[ Info: iteration 35, average log likelihood -1.308859
[ Info: iteration 36, average log likelihood -1.308818
[ Info: iteration 37, average log likelihood -1.308780
[ Info: iteration 38, average log likelihood -1.308744
[ Info: iteration 39, average log likelihood -1.308712
[ Info: iteration 40, average log likelihood -1.308682
[ Info: iteration 41, average log likelihood -1.308655
[ Info: iteration 42, average log likelihood -1.308632
[ Info: iteration 43, average log likelihood -1.308612
[ Info: iteration 44, average log likelihood -1.308593
[ Info: iteration 45, average log likelihood -1.308577
[ Info: iteration 46, average log likelihood -1.308563
[ Info: iteration 47, average log likelihood -1.308550
[ Info: iteration 48, average log likelihood -1.308538
[ Info: iteration 49, average log likelihood -1.308527
[ Info: iteration 50, average log likelihood -1.308516
┌ Info: EM with 100000 data points 50 iterations avll -1.308516
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3515869290658924
│     -1.351490005078164
│      ⋮
└     -1.3085159673720657
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.308647
[ Info: iteration 2, average log likelihood -1.308496
[ Info: iteration 3, average log likelihood -1.307842
[ Info: iteration 4, average log likelihood -1.301680
[ Info: iteration 5, average log likelihood -1.282795
[ Info: iteration 6, average log likelihood -1.266194
[ Info: iteration 7, average log likelihood -1.259241
[ Info: iteration 8, average log likelihood -1.255668
[ Info: iteration 9, average log likelihood -1.253153
[ Info: iteration 10, average log likelihood -1.251338
[ Info: iteration 11, average log likelihood -1.250095
[ Info: iteration 12, average log likelihood -1.249167
[ Info: iteration 13, average log likelihood -1.248338
[ Info: iteration 14, average log likelihood -1.247543
[ Info: iteration 15, average log likelihood -1.246877
[ Info: iteration 16, average log likelihood -1.246397
[ Info: iteration 17, average log likelihood -1.246074
[ Info: iteration 18, average log likelihood -1.245817
[ Info: iteration 19, average log likelihood -1.245579
[ Info: iteration 20, average log likelihood -1.245337
[ Info: iteration 21, average log likelihood -1.245084
[ Info: iteration 22, average log likelihood -1.244795
[ Info: iteration 23, average log likelihood -1.244425
[ Info: iteration 24, average log likelihood -1.243981
[ Info: iteration 25, average log likelihood -1.243496
[ Info: iteration 26, average log likelihood -1.243023
[ Info: iteration 27, average log likelihood -1.242629
[ Info: iteration 28, average log likelihood -1.242337
[ Info: iteration 29, average log likelihood -1.242163
[ Info: iteration 30, average log likelihood -1.242059
[ Info: iteration 31, average log likelihood -1.241987
[ Info: iteration 32, average log likelihood -1.241932
[ Info: iteration 33, average log likelihood -1.241886
[ Info: iteration 34, average log likelihood -1.241847
[ Info: iteration 35, average log likelihood -1.241814
[ Info: iteration 36, average log likelihood -1.241787
[ Info: iteration 37, average log likelihood -1.241765
[ Info: iteration 38, average log likelihood -1.241747
[ Info: iteration 39, average log likelihood -1.241732
[ Info: iteration 40, average log likelihood -1.241720
[ Info: iteration 41, average log likelihood -1.241710
[ Info: iteration 42, average log likelihood -1.241703
[ Info: iteration 43, average log likelihood -1.241697
[ Info: iteration 44, average log likelihood -1.241692
[ Info: iteration 45, average log likelihood -1.241688
[ Info: iteration 46, average log likelihood -1.241685
[ Info: iteration 47, average log likelihood -1.241683
[ Info: iteration 48, average log likelihood -1.241682
[ Info: iteration 49, average log likelihood -1.241680
[ Info: iteration 50, average log likelihood -1.241679
┌ Info: EM with 100000 data points 50 iterations avll -1.241679
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3086469020278688
│     -1.3084961835939326
│      ⋮
└     -1.2416792083489179
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.241887
[ Info: iteration 2, average log likelihood -1.241598
[ Info: iteration 3, average log likelihood -1.239410
[ Info: iteration 4, average log likelihood -1.217916
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.183767
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.171266
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.164373
[ Info: iteration 8, average log likelihood -1.159047
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.150188
[ Info: iteration 10, average log likelihood -1.160074
[ Info: iteration 11, average log likelihood -1.151915
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.144391
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.153934
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.151917
[ Info: iteration 15, average log likelihood -1.149261
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.141591
[ Info: iteration 17, average log likelihood -1.152075
[ Info: iteration 18, average log likelihood -1.145239
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.139563
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.143756
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.152958
[ Info: iteration 22, average log likelihood -1.147566
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.139276
[ Info: iteration 24, average log likelihood -1.149981
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.143141
[ Info: iteration 26, average log likelihood -1.143684
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.137165
[ Info: iteration 28, average log likelihood -1.149413
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.142800
[ Info: iteration 30, average log likelihood -1.143472
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.136980
[ Info: iteration 32, average log likelihood -1.149341
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.142741
[ Info: iteration 34, average log likelihood -1.143439
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.136946
[ Info: iteration 36, average log likelihood -1.149325
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.142727
[ Info: iteration 38, average log likelihood -1.143432
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.136940
[ Info: iteration 40, average log likelihood -1.149319
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.142722
[ Info: iteration 42, average log likelihood -1.143430
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.136940
[ Info: iteration 44, average log likelihood -1.149317
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.142720
[ Info: iteration 46, average log likelihood -1.143429
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.136941
[ Info: iteration 48, average log likelihood -1.149315
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.142719
[ Info: iteration 50, average log likelihood -1.143429
┌ Info: EM with 100000 data points 50 iterations avll -1.143429
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.241886784753295
│     -1.2415984446901054
│      ⋮
└     -1.1434289184026003
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.137206
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.136887
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.135984
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.124588
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.098563
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│      9
│     10
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.063739
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     25
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.076479
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.071463
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.064121
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.066706
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     25
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.068455
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│      9
│     10
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.061631
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.074496
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.062386
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     25
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.060029
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.072560
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.069289
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│      9
│     10
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.049823
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     25
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.060707
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.054062
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.046775
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.050007
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     25
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.052122
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│      9
│     10
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.045410
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.058323
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.046347
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     25
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.044100
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.057045
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.054727
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│      9
│     10
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.038514
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     25
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.055896
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.053328
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.046742
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.049974
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     25
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.052117
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│      9
│     10
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.045460
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.058291
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.046349
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     25
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.044160
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.057015
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.054727
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│      9
│     10
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.038593
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     25
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.055862
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.053335
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.046829
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.049943
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     25
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.052122
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│      9
│     10
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.045564
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.058256
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.046355
┌ Info: EM with 100000 data points 50 iterations avll -1.046355
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1372057439269394
│     -1.1368867894241201
│      ⋮
└     -1.0463553220066417
32×26 ┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3886323159790426
│     -1.3887015561935439
│     -1.388644681042695
│     -1.3883893308225665
│      ⋮
│     -1.045563501923085
│     -1.058255620228319
└     -1.0463553220066417
Array{Float64,2}:
  0.068453    -0.177162      0.181961     -0.0551554    0.00556536  -0.221941     0.199208     0.214061     -0.695151     0.261407    0.0626638    -0.0049887   -0.106832    -0.0364753   -0.0718203     0.0958088   -0.0860536    0.128981     -0.367366     -0.00832234  -0.109381     0.106793    -0.032836     0.0258702    0.0189508    0.00688852
  0.0518473   -0.184183      0.108345     -0.0151156   -0.0306855   -0.159431    -0.0022106    0.0553468     0.28389      0.0892972   0.080155     -0.014016    -0.185089    -0.00461889  -0.134464      0.117397    -0.0783165    0.1272       -0.0530529     0.0724283   -0.0034931    0.124483     0.150318     0.090276     0.0596535    0.0485115
 -0.038092     0.0737217    -0.116561      0.0592973   -0.158203    -0.0154449   -0.0859469    0.0332222    -0.0598509   -0.0429105  -0.0661706     0.0648851   -0.0849803    0.0311447    0.0239031    -0.166806     0.0554277   -0.190228      0.0303726    -0.00770476   0.023691     0.159783     0.0224528    0.0144687    0.0332075   -0.0397796
 -0.0988177   -0.030662     -0.273453      0.0357108    0.0860884   -0.0259785    0.119242     0.144179     -0.0446217    0.0481956  -0.13897       0.24234      0.0602847   -0.112493     0.106101     -0.0461845    0.0670262    0.0264406     0.0369424    -0.0851467   -0.0104174    0.0213517   -0.0215875    0.155359     0.0122184    0.127199
  0.0689441   -0.015935      0.0927418    -0.121632     0.24131     -0.0426919    0.113786    -0.253887     -0.121375     0.0907782   0.0319013     0.0611902    0.0241092    0.0746361    0.0371585    -0.68388     -0.0440771   -0.183133     -0.0657209    -0.0398802   -0.16239     -0.0241796   -0.0336189   -0.0863772    0.0608421   -0.21919
  0.0529972    0.134599      0.0774047     0.00942571   0.142187     0.00422706   0.167094    -0.0569034    -0.0153709    0.105545    0.0370782     0.0147372   -0.0336893    0.0802566    0.0259025     0.432077    -0.0182391   -0.14316       0.0815336    -0.061417    -0.0790324   -0.0763558    0.149927     0.216949    -0.112675    -0.214335
 -0.32493     -0.191503      0.0248091     0.0488168    0.159543    -0.0466842   -0.0281148    0.0320295    -0.270003    -0.0221592  -0.0316791    -0.0343739    0.103578    -0.0287452   -0.0530184     0.0529304    0.0128278   -0.180853     -0.0589413    -0.108076    -0.0547695    0.0401196    0.170811    -0.0257571   -0.207921     0.0382215
 -0.12751     -0.0878636     0.000955969  -0.0491271    0.0583397    0.0677303    0.134396    -0.0111381    -0.0653634    0.0424317   0.0331872    -0.0752329    0.0632216    0.0230867    0.0472492    -0.0561557   -0.0364178   -0.0416626    -0.0143996     0.0755963    0.0598904    0.134735    -0.0838769    0.0216526   -0.178069     0.0225336
 -0.0823388    0.210084     -0.0461943     0.0570612    0.077518    -0.00053816   0.115946    -0.0822149     0.00711184   0.0225344  -0.25322      -0.059871     0.0172121    0.121955    -0.157669      0.0734974    0.217786     0.0262933    -0.0703418    -0.131181     0.0950654   -0.177607     0.108194     0.0159547   -0.137917     0.169437
  0.0056545   -0.166386      0.0884599     0.104014    -0.182492    -0.00535624   0.0507183   -0.0512898    -0.201036    -0.0380559  -0.00450375   -0.00594432  -0.0655804    0.108927    -0.0252481     0.0386421    0.208444     0.064472      0.059965      0.0427742   -0.0388883   -0.0620763    0.0830977   -0.140228    -0.0162605    0.170269
  0.255242     0.0919433    -0.0719934     0.0182759    0.0482726   -0.168505     0.0865963    0.0673255    -0.0783243   -0.110488    0.173746      0.0555072    0.113875     0.00511372   0.114399     -0.169662     0.0092861    0.0431773     0.0485279    -0.129173     0.0386266   -0.0815826   -0.0422711   -0.036924    -0.0435606    0.0723017
  0.215699     0.0512383    -0.127706     -0.016795     0.0147055    0.0271974   -0.140948    -0.174399     -0.0883221   -0.255551    0.0302987    -0.119883    -0.0338321    0.156631    -0.111411      0.206025     0.0572088    0.017188     -0.0552342    -0.112456     0.00460377   0.0478095    0.0974177    0.0469739   -0.186904    -0.00265931
  0.00141433  -0.0323879     0.0982127    -0.0164148   -0.103729     0.0878411    0.0606706    0.064972      0.0031065    0.0888968  -0.012586     -0.175615     0.0229154    0.0135206   -0.0139931    -0.0039514   -0.0465717    0.0266488     0.0641973    -0.00238793   0.109317    -0.061185     0.0164066    0.0349467   -0.197461    -0.0565083
 -0.105176    -0.00115285    0.0114664    -0.100215    -0.016804    -0.0241159   -0.157742    -0.000696377  -0.0039705   -0.063292   -0.10205      -0.0813058    0.00650618  -0.0166038   -0.0027795     0.0397708   -0.0453405   -0.00133672   -0.0150585     0.022772    -0.0295945   -0.0175035   -0.0395893    0.109527     0.0190697    0.186914
  0.137943     0.123905     -0.0518998     0.0584468    0.0159269    0.176132    -0.0134741   -0.09943      -0.0421676    0.0939511   0.0430208    -0.023879    -0.0182286   -0.0681281    0.139061     -0.0171381   -0.0148521    0.0324799     0.139565      0.26855     -0.0743849    0.0527338   -0.00323602  -0.0331289    0.0940062   -0.291293
  0.0286275   -0.049457      0.103167      0.193192    -0.101257     0.03557      0.153956    -0.0256403    -0.0524499   -0.0394225  -0.193407      0.217682     0.0892152    0.0697469   -0.0335005    -0.0648942    0.0205251    0.000644191  -0.145628      0.021905    -0.166045    -0.00641595   0.228223    -0.0610532    0.243433    -0.0151625
 -0.059585    -0.101575     -0.0917938    -0.176597    -0.0141955    0.0112376    0.0434851   -0.0350078    -0.0409294    0.112688    0.133654      0.171969     0.119534    -0.0202808    0.00435789   -0.0806339    0.121024     0.135204     -0.0339354    -0.227552     0.0483535   -0.176009     0.0414632    0.00932866   0.00103662   0.0437285
  0.10518     -0.0320927    -0.070002     -0.0145274    0.0882906    0.0236883    0.0535268    0.0125879     0.0497397    0.340042    0.237271      0.0193886    0.0515007   -0.0799911    0.0553969    -0.171453    -0.0888012    0.21465      -0.0601922    -0.190459     0.0424282   -0.381715    -0.0288977    0.124441     0.0235899   -0.0263365
 -0.0288472    0.00121336    0.096313     -0.897361    -0.210223    -0.0687104   -0.0162559    0.0798487    -0.226219    -0.054998   -0.00312712   -0.0521374   -0.0460736   -0.265607    -0.0816315    -0.122702    -0.213467    -0.127396     -0.00773882   -0.102589     0.0420447   -0.0553043    0.0319371    0.0484736   -0.0398304   -0.12261
 -0.03858      0.000478686   0.0865338     1.08016     -0.0632557   -0.0680539   -0.0324449    0.0678535    -0.215953    -0.0608345   0.0193896    -0.0840784   -0.132013    -0.266311    -0.0568696    -0.10799     -0.173314    -0.138606     -0.00778206   -0.0997283    0.0744569   -0.158696    -0.077814     0.0519959   -0.0549268   -0.218197
  0.00858469  -0.0525738     0.0572564     5.03919e-5  -0.0451169   -0.0646662    0.0358763   -0.0952472     0.0116211   -0.0433821  -0.0773532     0.105266     0.0690138    0.00654869   0.00119222   -0.0128645    0.0452816   -0.0370925     0.00298916    0.0658139    0.0860158   -0.091243    -0.0572311   -0.00846217  -0.0196317    0.0468886
  0.0371187    0.209997      0.117811     -0.0433602   -0.0031642   -0.0295386   -0.041255     0.0214594     0.134786    -0.054856    0.153807      0.0419717   -0.0794613    0.0968848   -0.0686505    -0.0574674    0.123176     0.00855978   -0.136511     -0.101921     0.0896217    0.0308531    0.0565489    0.0286487    0.0700899    0.0441013
  0.0662001   -0.00463717    0.0573697    -0.00529908  -0.345705     0.0222781    0.015466     0.114238      0.186623    -0.232313    0.113916      0.0492624    0.141431    -0.00513703   0.0288945     0.00304595   0.059965    -0.00483001    0.109825      0.124269     0.194332    -0.0166147    0.202186    -0.0237591   -0.100465    -0.504295
  0.151785     0.0408167     0.137886     -0.123385    -0.0213604   -0.0690562    0.0121763    0.111172      0.0884953   -0.251585    0.0854703    -0.0617401    0.13818      0.039238    -0.117927      0.032989     0.0467651    0.00796207    0.100459      0.0624053    0.151606     0.0862185    0.162329    -0.0127247   -0.117938     0.307951
 -0.00791025  -0.157177     -0.0348007     0.0222636   -0.146605     0.241906     0.021572     0.12184      -0.357439     0.309577    0.00411415   -0.765329    -0.116162     0.165322    -0.144003      0.107561    -0.00625652  -0.037649      0.225044     -0.0146933    0.194403     0.0822011    0.0207737   -0.245546    -0.0793343   -0.00782771
 -0.00792949   0.0527601    -0.0351533    -0.00446876  -0.0542227    0.0982642    0.00768236  -0.186658     -0.124065    -0.130406    0.000559162   0.60239      0.385735     0.068364    -0.152415      0.133148    -0.0114335   -0.0387403     0.0665258    -0.0138377    0.195152    -0.12213      0.0622654   -0.0699224    0.0414806   -0.0359306
 -0.141007    -0.333364      0.0952585     0.0479986    0.258363     0.117399     0.0306193    0.198436      0.00816868  -0.0323198  -0.124845     -0.199157     0.0663118   -0.0917446   -0.000941996  -0.0360476   -0.218936     0.142797      0.000606701   0.0411536   -0.123662    -0.193103     0.0204231    0.0857591   -0.033465    -0.0694438
 -0.186926     0.536018      0.0953009     0.0365791    0.287699     0.00518235   0.069197     0.250286      0.00827851  -0.0496711  -0.171064     -0.0756031    0.0587783   -0.0842012    0.0176667    -0.0807346   -0.0575498    0.163329      0.0360882     0.0480624   -0.169699    -0.218555    -0.0106471    0.0539837    0.0592975   -0.216432
  0.0604992   -0.0308689    -0.03502       0.12463      0.176626     0.0273313    0.12326     -0.163333      0.0459013   -0.0740374  -0.0366248     0.0222337   -0.0124259    0.0741816   -0.0286489    -0.0441563   -0.0357823   -0.11542      -0.0861423     0.0548664   -0.00273673  -0.111584    -0.0340487   -0.0535873    0.0389655    0.143842
  0.104033     0.120927      0.0662141    -0.0011933    0.114778    -0.163084    -0.0541425   -0.156429     -0.0434689   -0.130578    0.0650011     0.0544507    0.0806357   -0.0188216    0.0489725    -0.108439    -0.0563371    0.0652033     0.0529513     0.0901086    0.0684213   -0.0368682    0.0476193   -0.112449     0.120536     0.0204824
  0.0610348   -0.0613848    -0.104686     -0.057853     0.125359    -0.0550187   -0.13165      0.0676082    -0.0323385   -0.0613733   0.0333794     0.053101     0.0729543   -0.164781     0.0180686     0.00508079   0.0961338   -0.0201282     0.0487843     0.0145531    0.0821762    0.025204     0.00507873   0.0471159   -0.00180466   0.00208598
 -0.084418     0.0152807     0.116146      0.107736     0.00906326  -0.137899     0.127001     0.122592     -0.00103301  -0.100112   -0.0119797    -0.0637961   -0.101834     0.0232137   -0.025501      0.0160237    0.0528081    0.0846774    -0.00681772   -0.0564217   -0.082271     0.0183238    0.0403468    0.0531751    0.0205382   -0.0875795[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     25
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.044279
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│      9
│     10
│     25
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.037693
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     25
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.044236
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│      9
│     10
│     25
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.037663
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     25
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.044232
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│      9
│     10
│     25
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.037657
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     25
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.044230
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│      9
│     10
│     25
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.037654
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     25
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.044229
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│      9
│     10
│     25
│     26
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
kind diag, method kmeans
[ Info: iteration 10, average log likelihood -1.037652
┌ Info: EM with 100000 data points 10 iterations avll -1.037652
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       7.998381e+05
      1       6.474010e+05      -1.524372e+05 |       32
      2       6.220952e+05      -2.530574e+04 |       32
      3       6.093479e+05      -1.274735e+04 |       32
      4       6.012138e+05      -8.134008e+03 |       32
      5       5.963824e+05      -4.831448e+03 |       32
      6       5.940711e+05      -2.311294e+03 |       32
      7       5.927884e+05      -1.282688e+03 |       32
      8       5.914659e+05      -1.322566e+03 |       32
      9       5.895773e+05      -1.888533e+03 |       32
     10       5.874753e+05      -2.102056e+03 |       32
     11       5.856845e+05      -1.790773e+03 |       32
     12       5.841932e+05      -1.491320e+03 |       32
     13       5.828777e+05      -1.315428e+03 |       32
     14       5.817525e+05      -1.125291e+03 |       32
     15       5.807424e+05      -1.010059e+03 |       32
     16       5.798062e+05      -9.361816e+02 |       32
     17       5.791542e+05      -6.519886e+02 |       32
     18       5.787182e+05      -4.360322e+02 |       32
     19       5.784192e+05      -2.989659e+02 |       32
     20       5.782280e+05      -1.912326e+02 |       32
     21       5.781137e+05      -1.142951e+02 |       32
     22       5.780471e+05      -6.657211e+01 |       31
     23       5.780078e+05      -3.931211e+01 |       32
     24       5.779826e+05      -2.517746e+01 |       29
     25       5.779605e+05      -2.211244e+01 |       32
     26       5.779407e+05      -1.978771e+01 |       30
     27       5.779211e+05      -1.962891e+01 |       32
     28       5.779051e+05      -1.599052e+01 |       31
     29       5.778910e+05      -1.414604e+01 |       30
     30       5.778729e+05      -1.809104e+01 |       30
     31       5.778517e+05      -2.117570e+01 |       31
     32       5.778329e+05      -1.875567e+01 |       31
     33       5.778102e+05      -2.274649e+01 |       32
     34       5.777846e+05      -2.557235e+01 |       30
     35       5.777542e+05      -3.044729e+01 |       28
     36       5.777146e+05      -3.953852e+01 |       32
     37       5.776659e+05      -4.878806e+01 |       32
     38       5.776131e+05      -5.272439e+01 |       32
     39       5.775409e+05      -7.227711e+01 |       32
     40       5.774396e+05      -1.012383e+02 |       32
     41       5.773053e+05      -1.342807e+02 |       32
     42       5.771563e+05      -1.490062e+02 |       32
     43       5.770248e+05      -1.315000e+02 |       32
     44       5.769043e+05      -1.204901e+02 |       32
     45       5.768220e+05      -8.235727e+01 |       32
     46       5.767758e+05      -4.615561e+01 |       32
     47       5.767498e+05      -2.605398e+01 |       30
     48       5.767335e+05      -1.631065e+01 |       31
     49       5.767255e+05      -8.003214e+00 |       28
     50       5.767213e+05      -4.178958e+00 |       27
K-means terminated without convergence after 50 iterations (objv = 576721.2783215852)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.298567
[ Info: iteration 2, average log likelihood -1.266269
[ Info: iteration 3, average log likelihood -1.235190
[ Info: iteration 4, average log likelihood -1.201441
[ Info: iteration 5, average log likelihood -1.150565
[ Info: iteration 6, average log likelihood -1.085035
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     15
│     17
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.019151
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.064723
[ Info: iteration 9, average log likelihood -1.051285
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     17
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.003414
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     15
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.041119
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.053601
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.043640
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.019117
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     19
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.011376
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.040708
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.032981
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     17
│     19
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.002070
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.029267
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.038535
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     15
│     17
│     19
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.011820
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.058794
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.020766
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     15
│     17
│     19
│     23
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -0.994152
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.065571
[ Info: iteration 26, average log likelihood -1.041962
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     17
│     19
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -0.993033
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     13
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.024583
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.045198
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     17
│     19
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.015440
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.048051
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.023223
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     17
│     19
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.006900
[ Info: iteration 34, average log likelihood -1.060364
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.011724
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     17
│     19
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.003476
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.045101
[ Info: iteration 38, average log likelihood -1.032378
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     15
│     17
│     19
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -0.992674
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.061167
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.020129
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     17
│     19
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.013545
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.049797
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.029453
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     13
│     15
│     17
│     19
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -0.987437
[ Info: iteration 46, average log likelihood -1.062834
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.019461
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     17
│     19
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.008738
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.046125
[ Info: iteration 50, average log likelihood -1.032578
┌ Info: EM with 100000 data points 50 iterations avll -1.032578
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0699208    0.0791629    0.122501      0.107845      0.0293205   -0.189993      0.148719    0.161316     0.00798967    0.000451739  -0.0242098   -0.0616676    0.0910218    0.00290962   0.0692228    0.162362      0.204548    0.0696811   -0.0904975   -0.0517116    -0.0262947    0.106147     0.140434    -0.0728364    0.0650272   0.00234475
 -0.0339624    0.00131465   0.0906758     0.0906537    -0.136416    -0.0684458    -0.0243661   0.0737181   -0.220757     -0.0581364     0.00801501  -0.0684027   -0.0899247   -0.265772    -0.0691199   -0.116249     -0.193859   -0.132938    -0.00764837  -0.101149      0.0587778   -0.107998    -0.0220282    0.0502129   -0.0476006  -0.170231
  0.059307     0.0631643    0.0856968    -0.0494834     0.181819    -0.0151976     0.142033   -0.146446    -0.0654975     0.0990355     0.0339851    0.0352729   -0.0074281    0.0774886    0.0315803   -0.0766205    -0.0295889  -0.166453     0.0168178   -0.0492536    -0.114506    -0.0543239    0.0660736    0.0753961   -0.0394328  -0.216043
 -0.112502    -0.00874363  -0.286722      0.0345204     0.0911794   -0.0274983     0.136478    0.135661    -0.0399981     0.0447326    -0.145637     0.249301     0.0614325   -0.109819     0.115493    -0.0402807     0.0639611   0.0250879    0.0496956   -0.0870826    -0.0184524    0.0244119   -0.0159512    0.15629      0.0257989   0.130807
 -0.786448    -0.0690578    0.0984882    -0.12277      -0.298402     0.126398      0.034265    0.0821596    0.157045     -0.32935       0.113185    -0.0582724    0.157183    -0.136114    -0.0124971    0.147524      0.0424768  -0.0170855    0.0898342   -0.000677129   0.23373      0.219689     0.157748    -0.0458419   -0.0380213  -0.359353
  0.107278    -0.244851    -0.000924864   0.000113813  -0.0293105   -0.0691729    -0.202927   -0.052136     0.00169961    0.069806     -0.0756882    0.127727     0.0436988    0.00220416   0.223434    -0.11095      -0.0019106   0.0969716   -0.155326    -0.0429301     0.026814    -0.0586601   -0.0313546    0.0170718   -0.0782309   0.145051
  0.0294739   -0.069545    -0.0750391    -0.07266       0.0315775    0.0174459     0.049789   -0.00725229  -0.000211952   0.231947      0.182674     0.082707     0.0661702   -0.0532721    0.0321325   -0.124388      0.0100217   0.194396    -0.0514973   -0.194513      0.0446501   -0.279113     0.00707636   0.0650824    0.0123063   0.0126715
  0.0617596   -0.102095     0.0754364     0.0757179    -0.0893824   -0.0884514     0.110419   -0.0566947    0.0364794    -0.134856     -0.0703144   -0.0539649    0.0215337   -0.0463096   -0.0694612    0.0107854     0.0861919   0.0396486   -0.0294623    0.0495624     0.105213    -0.19815     -0.0633585   -0.025811     0.0297928   0.0553069
  0.0958455   -0.222677    -0.16798       0.0139367     0.0956257    0.0163126    -0.101758    0.111682    -0.178583      0.106388      0.0742063    0.0574498    0.037948    -0.277295    -0.140017    -0.000630107   0.168721    0.00536915  -0.00726808   0.0101597     0.0697547    0.0339294   -0.0334622    0.00945875  -0.0195858  -0.050853
  0.0277373    0.224692     0.121271     -0.0423339    -0.00485974  -0.0297832    -0.0402831   0.02209      0.1309       -0.059418      0.156644     0.0380534   -0.0872893    0.110384    -0.0813116   -0.0546899     0.128173    0.00563768  -0.135929    -0.103064      0.0888734    0.0345514    0.057173     0.029408     0.0710002   0.0345862
 -0.0295066    0.106703    -0.0364597    -0.144191      0.174019    -0.131153     -0.1383      0.0550663    0.119879     -0.255961     -0.0081793   -0.00375781   0.11235     -0.0339518    0.14872      0.04044       0.0256702  -0.0628521    0.156277     0.0352587     0.0945216    0.0240534    0.0468117    0.0817912    0.0166169   0.0607631
  0.0998951    0.120816     0.0659998    -0.00195602    0.114811    -0.158036     -0.0521441  -0.155356    -0.0420764    -0.130103      0.0627105    0.0599159    0.0780228   -0.0177229    0.0470377   -0.110399     -0.0578011   0.0688701    0.0521288    0.0906593     0.0690968   -0.0369145    0.0478894   -0.112707     0.121501    0.0199872
 -0.00586529  -0.173828     0.0880107     0.0695345    -0.124919     0.00808371    0.0331471  -0.0428282   -0.16473      -0.00301787    0.0025179    0.0218119   -0.0439006    0.112273    -0.00447979   0.0637541     0.142191    0.0988114    0.120756     0.0522287    -0.0422732   -0.0654519    0.063706    -0.0698633   -0.0553426   0.11254
 -0.0800968    0.0503963   -0.105519      0.133451     -0.22014     -0.0351934    -0.157269   -0.0150022    0.0350222     0.0263184    -0.188977     0.0430108   -0.0788033   -0.00532822   0.11779     -0.102233      0.126353   -0.209547    -0.0233131    0.0167211     0.0264486    0.193321     0.0168249    0.0615291    0.0118351  -0.0844609
 -0.00948445  -0.0695176   -0.0139585     0.0146471    -0.0417549    0.177377      0.0148694   0.0086865   -0.197961      0.0705535    -0.0174803   -0.0901907    0.117345     0.0833462   -0.146084     0.0945059    -0.01199    -0.0139962    0.135263    -0.0057398     0.171189    -0.033928     0.035573    -0.123042    -0.0157429  -0.0294595
  0.060168    -0.180617     0.145656     -0.0349472    -0.0130276   -0.190616      0.098024    0.134193    -0.206984      0.176222      0.0705544   -0.0101873   -0.146216    -0.0203195   -0.102983     0.106434     -0.0821693   0.12824     -0.209091     0.0313331    -0.0554675    0.115905     0.0585575    0.0584264    0.0388827   0.0277847
 -0.197631    -0.0566376   -0.0167407    -0.21343      -0.15717      0.056088     -0.186831   -0.146728     0.00363513   -0.145431     -0.114812    -0.099326     0.0476848    0.0957809   -0.0378066    0.0984549     0.0198642  -0.0599706   -0.0830013   -0.012012     -0.0783205   -0.0660205   -0.0434047    0.114964     0.058836    0.241053
  0.0611075   -0.162817     0.150706     -0.002178     -0.0729621    0.0467893     0.0522196   0.0539853   -0.0183963    -0.0398726    -0.081987    -0.217247    -0.0701698    0.041644     9.0518e-5   -0.0703571    -0.0253728   0.0533707   -0.017744     0.0380526     0.0636651   -0.078731    -0.0977653    0.0668159   -0.171417    0.00206405
 -0.205044     0.164226     0.0970284     0.0407512     0.264571     0.0497014     0.0675845   0.22365      0.00483039   -0.0377267    -0.142071    -0.142245     0.0650042   -0.0852881    0.0409606   -0.0584027    -0.162608    0.161006     0.0193225    0.0456155    -0.216809    -0.245534     0.0053826    0.074656     0.018381   -0.165496
  0.0290669   -0.051047     0.107019      0.192536     -0.10356      0.0375231     0.150467   -0.0292789   -0.0525051    -0.0397822    -0.200087     0.220247     0.0887198    0.0704157   -0.0309964   -0.065127      0.0164065   0.00149255  -0.146107     0.0222084    -0.167357    -0.00751898   0.227152    -0.0632222    0.247224   -0.0149547
  0.0202512    0.115083    -0.151514     -0.0208873    -0.0653688    0.0170942     0.0543039   0.124659    -0.198217     -0.153779      0.128463     0.100183    -0.0897017    0.10164     -0.148313    -0.223455     -0.0490184  -0.17821      0.130394    -0.0228577     0.0223929    0.132552     0.0571649   -0.0500627    0.0739032   0.00841199
  0.128843     0.118864    -0.0481229     0.0526237     0.0193453    0.173958     -0.005481   -0.105731    -0.0416894     0.0974367     0.0333668   -0.0404533   -0.0212037   -0.0696752    0.142503    -0.0163561    -0.015733    0.0392836    0.13394      0.274897     -0.0808127    0.0603736   -0.00992543  -0.0294975    0.0886752  -0.281273
 -0.00258623   0.0579516    0.0515592     0.0260031     0.128674    -0.106439     -0.120901    0.16584     -0.0100972     0.0269203    -0.0805131   -0.0672908   -0.0350054   -0.134842     0.0387447   -0.0244012    -0.122003    0.0629863    0.0605855    0.0613467     0.0228099    0.0305711   -0.0353664    0.113444    -0.0281197   0.125676
  0.24863      0.0298539    0.0952948    -0.0493463    -0.177211    -0.0426963     0.0163777   0.117646     0.134375     -0.225732      0.0973418    0.00706288   0.137581     0.0373694   -0.0479338   -0.0022898     0.055984    0.00043863   0.110049     0.109948      0.165409     0.00414595   0.187842    -0.0145001   -0.121838   -0.0784701
 -0.0706974    0.155547    -0.0222381     0.0559351     0.0351557   -0.000959504   0.106787   -0.083878    -0.02905       0.0111764    -0.208638    -0.0502181    0.00686399   0.128704    -0.130978     0.0827737     0.212691    0.0567573   -0.0660961   -0.093288      0.0726751   -0.166544     0.110798    -0.0108779   -0.116211    0.171151
 -0.123978    -0.0741729    0.0182094    -0.039894      0.0119687    0.0705558     0.136023   -0.0158019   -0.0557557     0.0374086     0.0225757   -0.095718     0.0816285    0.00952431   0.0371932   -0.0948079    -0.0427532  -0.0903914   -0.0249788    0.0845043     0.10801      0.182803    -0.0443439   -0.0019939   -0.212321    0.0274201
 -0.210949    -0.049517     0.117814      0.125443      5.36736e-5  -0.0896535     0.119477    0.086197    -0.00742283   -0.181767     -0.00250228  -0.0653605   -0.290993     0.0405188   -0.131407    -0.129601     -0.0841514   0.0982518    0.0645504   -0.0645183    -0.134092    -0.060975    -0.0715354    0.177106    -0.023053   -0.180876
  0.217221     0.0529112   -0.126961     -0.0195089     0.0158204    0.028958     -0.140327   -0.17688     -0.0950191    -0.259293      0.0314656   -0.123328    -0.0350832    0.158665    -0.115834     0.210928      0.0689242   0.0163178   -0.0544805   -0.11622       0.00479553   0.0464054    0.101527     0.0430572   -0.188967   -0.00726053
  0.251539     0.0923868   -0.0719734     0.0225435     0.0452876   -0.167593      0.086434    0.0656171   -0.0799974    -0.109083      0.173251     0.0511343    0.115175     0.00278197   0.115893    -0.17272       0.016562    0.054768     0.0496968   -0.125853      0.0363571   -0.091394    -0.0413926   -0.0417041   -0.0441381   0.079855
 -0.0887067    0.118576     0.0601131    -0.0503732    -0.0831054    0.0543168     0.0922956  -0.0614929   -0.00573476    0.116257     -0.0126826    0.0700925    0.131617     0.00929829  -0.0248021    0.0514801     0.0148304  -0.116652     0.131099     0.0512256     0.130421    -0.0069754    0.0252298   -0.0117419   -0.141245   -0.0664868
 -0.309332    -0.195244     0.0255378     0.0358351     0.146241    -0.0323838    -0.0112022   0.025815    -0.23847      -0.0147801    -0.0228375   -0.0505296    0.0936999   -0.0190962   -0.0395984    0.0396522     0.0181983  -0.170465    -0.0549186   -0.0882691    -0.0421939    0.0503355    0.133798    -0.0210659   -0.210014    0.0361509
  0.0644776   -0.0307426   -0.0258299     0.124489      0.170666     0.0264627     0.130367   -0.179257     0.0451326    -0.0693966    -0.0396488    0.0183899   -0.0102276    0.0733812   -0.0256072   -0.0415796    -0.0323826  -0.112215    -0.0895454    0.0535668    -0.00872177  -0.114494    -0.0387352   -0.0537106    0.036078    0.145565[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     15
│     17
│     19
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -0.992894
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     15
│     17
│     19
│     23
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.979801
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     13
│     15
│     17
│     19
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.964496
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     15
│     17
│     19
│     23
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.990777
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     15
│     17
│     19
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.980992
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     13
│     15
│     17
│      ⋮
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.963433
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     15
│     17
│     19
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -0.992323
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     15
│     17
│     19
│     23
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.979477
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     13
│     15
│     17
│     19
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.964991
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     15
│     17
│     19
│     23
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.990777
┌ Info: EM with 100000 data points 10 iterations avll -0.990777
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0252049    -0.0226649   -0.0568395   -0.172745     0.00734734  -0.0404071   -0.0680006   -0.242694    -0.0464726    0.156496    -0.0515726    0.0160465    0.00682872   0.0723935   -0.0446907    -0.182711    -0.115984    -0.0192298     0.00963574  -0.00513768  -0.112314    -0.010473     0.0612528   -0.00482501    0.00811762   0.0414206
  0.0847604     0.108844     0.0203993   -0.181663     0.123287    -0.0538037    0.0190832   -0.232633     0.0836101    0.019176    -0.0184148    0.11519     -0.0847733   -0.0347609    0.082003      0.219529    -0.258717    -0.0754485    -0.144428    -0.00671928  -0.183685    -0.0676191   -0.0355728    0.0788992     0.120835    -0.00183407
  0.0447166     0.0138443    0.0665451    0.0120012    0.146836     0.13817     -0.0561207    0.0201787    0.122899     0.00653472  -0.0461783   -0.0771377    0.105208    -0.1054       0.114018      0.0203472    0.160941     0.0774055     0.0361463   -0.214996    -0.118115    -0.0113027   -0.0921256    0.0728832     0.0646274   -0.161322
  0.0885788    -0.0318204   -0.184261    -0.122662     0.0179001   -0.0555067    0.0432354    0.0319706    0.0863021    0.0160862    0.153453     0.0214737    0.109727     0.0417802    0.0847412    -0.0444      -0.0323042   -0.0113727     0.0625363    0.0808176    0.0736768   -0.0737221   -0.0683717    0.0892736     0.1156      -0.106601
 -0.194918     -0.115094    -0.0946813    0.20111     -0.0334684    0.182205    -0.131875     0.0743368   -0.0365877    0.0402821   -0.0652938   -0.104723    -0.104048    -0.0972967    0.176303      0.116113     0.121188     0.0150309     0.0828068   -0.145707    -0.094493    -0.106403    -0.0792365   -0.102324     -0.00532948   0.118276
  0.0591866     0.179253     0.00344744  -0.231885     0.0160776    0.0329808   -0.0701104   -0.0698334    0.200562    -2.16471e-5   0.109543    -0.0157825   -0.0358794   -0.0218298    0.0491195     0.163154    -0.00606223   0.055833      0.100847    -0.100112    -0.0757783    0.00616502  -0.060112    -0.00453351   -0.0154929    0.0307694
  0.175105      0.0654412    0.160336    -0.0303383    0.0049347    0.130378     0.12443      0.0344998    0.0862461    0.0603913   -0.0232829    0.043313    -0.028739    -0.179319    -0.117761      0.0536108   -0.0938611   -0.100215      0.0381973    0.0168369    0.0590965   -0.0134594   -0.129286     0.124098     -0.0896103    0.0440468
 -0.0233411    -0.00931703  -0.00801811  -0.00119442   0.201681    -0.202536     0.045802     0.0371311   -0.0850309    0.0473757    0.0516188   -0.20675     -0.00570438  -0.0927929   -0.046321     -0.0138748    0.105103    -0.0299065     0.0603587   -0.0884701    0.0480919   -0.0263346   -0.0305944   -0.103129     -0.0919307   -0.0136845
  0.0585825    -0.069657    -0.0392598   -0.0462898    0.0497183   -0.07121     -0.0978131   -0.039061    -0.00985304   0.165991    -0.148599     0.0294581   -0.059168     0.130023    -0.110846      0.0687558   -0.00318599  -0.0532265    -0.0461408    0.0956371   -0.137806     0.0319325    0.120002    -0.0449957     0.0500368   -0.0252087
 -0.0643574    -0.0888863   -0.112082    -0.032848     0.00214868   0.125055     0.193187     0.100525     0.113931     0.0624553    0.0537838   -0.0715564   -0.0920217   -0.0188721   -0.259212     -0.0469729    0.0875218    0.000547276   0.023017     0.155764     0.060334    -0.044776     0.0281557    0.181204     -0.0177215   -0.00150966
 -0.00127488    0.00761591  -0.22868     -0.0694486    0.0135148   -0.0475995   -0.154722     0.220564    -0.0301917   -0.00861048   0.00214015  -0.00135264  -0.0749958   -0.115885     0.115836      0.0181225   -0.0623667   -0.130689     -0.0707608   -0.0856783    0.0131588    0.127226    -0.104028     0.0572309     0.0696453   -0.242248
 -0.049107      0.0352422    0.0178383   -0.14922      0.024304     0.00981776   0.185905    -0.0635113    0.0583737   -0.162792    -0.00307177  -0.024679     0.0601195    0.138256     0.0867055     0.0521122    0.0490059   -0.0312334    -0.288855     0.0924798    0.00572698  -0.147022    -0.00276118  -0.0205177    -0.0469909   -0.0447976
  0.036284      0.119707    -0.0218187    0.116863     0.0351651    0.00531272  -0.0607711    0.122594     0.0479321    0.00509547  -0.0370985   -0.0192049   -0.217962     0.136923     0.0574169    -0.0332211    0.124572     0.0429803     0.0440149    0.039828     0.0407366   -0.115352     0.153106     0.0400608     0.224969     0.0892935
  0.197185      0.003762     0.0150178    0.0441801    0.0997664    0.149595     0.0442033   -0.0593838    0.0100834    0.207132    -0.0665858    0.00856841  -0.2071      -0.0454513   -0.106632      0.0446423    0.0298666   -0.054668      0.120272     0.0582306   -0.0429003    0.186193    -0.184537    -0.000319351  -0.102432    -0.0238405
  0.046341      0.174759     0.00274377  -0.00950281  -0.00514599   0.100889    -0.0564197   -0.0122421    0.0454087    0.123297    -0.123093    -0.0175833   -0.17493      0.0397855    0.0598165     0.09505      0.117309    -0.0863619     0.00734357   0.0684567   -0.106609    -0.0113417   -0.0133326   -0.15786       0.0932651    0.0685932
 -0.0446043     0.0621943    0.0711875    0.176287    -0.030942    -0.0171343    0.0313855   -0.125539     0.0978946    0.024535    -0.0592094    0.113642     0.0800108    0.0274283   -0.0519458    -0.00575236   0.176392    -0.0486835    -0.126382    -0.102907     0.0366539    0.293223     0.176426    -0.0560892    -0.248655     0.00316635
 -0.0899322    -0.0482563   -0.123798    -0.0182068    0.0542668   -0.00501603   0.181507     0.0990949    0.0947977   -0.0676559   -0.0443331    0.141305     0.0137641    0.0154531    0.141275     -0.0166265    0.10267     -0.175202     -0.179474    -0.0477898    0.129115    -0.145547    -0.11038      0.0442976     0.134647    -0.0424963
 -0.171576      0.185872     0.235317     0.131698    -0.0764848    0.0957375    0.00518089  -0.189134    -0.0437421    0.0308551    0.0745164    0.102766     0.0541209   -0.00327899   0.164455     -0.127675     0.0224742    0.0502719     0.00911581   0.0506705   -0.0122677    0.102344     0.010633    -0.0736748     0.0684885   -0.0691021
  0.0118496    -0.188956    -0.20363     -0.316075     0.109361     0.11311     -0.0175169    0.138118     0.236523    -0.00767453   0.136116    -0.219771     0.123802    -0.0484888   -0.0599223    -0.0254983    0.108781     0.00496667   -0.064175     0.188134    -0.0936707   -0.0411592    0.0481211   -0.0591903    -0.0159072   -0.138112
 -0.0583584    -0.116689    -0.0712203    0.0175166   -0.0675896    0.164163     0.116854     0.00348513  -0.0642641   -0.0745952   -0.17016     -0.0650773    0.263422     0.0705036    0.0310937    -0.0741522    0.0200523   -0.0192097     0.0698497   -0.0768502    0.044217    -0.0580545   -0.0625957    0.110824     -0.0495827   -0.0257748
 -0.211322      0.058213     0.165917    -0.0435338   -0.0761046   -0.0791601    0.0305153    0.186205     0.0214724    0.184584    -0.0660981    0.10567      0.0182922   -0.187077    -0.185754     -0.078591    -0.133225     0.0154261    -0.0165061   -0.0689151    0.0339447   -0.0641675    0.0112591   -0.197449      0.118174    -0.112512
 -0.138961      0.026291    -0.121916    -0.14018      0.0980222   -0.0886901    0.0901078   -0.0555222    0.00924431  -0.0759924    0.137484     0.0146968    0.0337995    0.142862    -0.120419      0.0422397   -0.0732008    0.145612     -0.0723025   -0.0251651   -0.00578796   0.0251376    0.00914225  -0.0703143     0.0286758   -0.0987527
  0.00624045   -0.093086     0.123526     0.0312712   -0.0605119    0.184735    -0.02064     -0.0929761   -0.0287904    0.130687     0.12366     -0.0279957    0.115857    -0.025918     0.108908      0.086457    -0.138018     0.00733308   -0.0203608    0.0320174    0.0868485    0.0866558    0.0829414    0.0120423    -0.0268793    0.126788
 -0.0136917     0.119223    -0.0482371   -0.00659147   0.0301092    0.125732     0.0912375   -0.0119842   -0.176518     0.13491     -0.165395     0.0683786    0.148951     0.0205144    0.000747557   0.120598     0.106614     0.0189661    -0.0827244   -0.0691861   -0.154126     0.183516     0.0925386    0.00257912    0.0762383   -0.0482023
 -0.155844      0.037489    -0.0606211    0.00726248  -0.166704     0.0618147    0.0963483    0.0276444   -0.0880536   -0.133241     0.0232989    0.182583    -0.0476541   -0.095283    -0.243868     -0.165594     0.0326141   -0.0230908     0.0326198   -0.186851    -0.081609    -0.134716     0.0494813   -0.0693517    -0.155165    -0.0514204
 -0.120418     -0.0960797   -0.154457    -0.0688581    0.0105783    0.00538345  -0.0940803   -0.0113858    0.11432     -0.172577    -0.128387     0.0843902    0.268324    -0.00891224  -0.180507      0.0634688   -0.0956989   -0.129496     -0.108169    -0.033083     0.106277    -0.0978719   -0.196837     0.0249292     0.190181    -0.12547
  0.123251      0.0461721   -0.00492044   0.0168942   -0.0731088   -0.0990524   -0.0306421    0.0206432   -0.0798634    0.053884     0.0762504    0.00955447  -0.0388651   -0.0446389    0.00353086   -0.0601184    0.0397533    0.0111193     0.24402     -0.0538094   -0.0201856   -0.0498935    0.131559    -0.100769     -0.0292649    0.0368321
  0.142241      0.035952     0.00179225   0.0217865    0.0736687   -0.0136281   -0.0808943   -0.0208703    0.119393     0.107163     0.0146111    0.0779537    0.0868214   -0.0837114   -0.0467475    -0.185857    -0.252995     0.126262     -0.182183     0.166431    -0.00543816  -0.121923    -0.0425304    0.121951      0.181765    -0.0909197
  0.000743319  -0.0368331   -0.0100627   -0.00426496   0.0450213    0.0352202   -0.0702653    0.0231921    0.0536496   -0.176882    -0.0454175   -0.115514    -0.0718514   -0.175962     0.0991101     0.0286957    0.0130745   -0.0550624     0.165209     0.00164714   0.0043135   -0.163257    -0.00256051   0.0581064    -0.00402481  -0.0187345
 -0.0404498    -0.198479     0.111891    -0.0975728    0.0900746    0.0843697   -0.0270319   -0.0370688   -0.10459      0.0344537   -0.0967804   -0.133822     0.0942049   -0.0489217   -0.0362698    -0.0970924   -0.0623861   -0.00132499    0.0167488    0.0162124   -0.00944796  -0.11001     -0.116639    -0.078014      0.0838646    0.0518338
  0.0476366    -0.0690436   -0.137433    -0.0163087    0.0438152   -0.0744715   -0.0918253   -0.0251595    0.0279219    0.0811199   -0.0328671   -0.0681436    0.00270106  -0.043318     0.0550184     0.198651     0.102313     0.0480518    -0.232727     0.232259    -0.0371666    0.0160407    0.0148773    0.160674      0.014231     0.195743
 -0.0280909     0.0149845   -0.106409    -0.211896    -0.0454414    0.193446     0.0055978   -0.0740962   -0.0241711    0.0721756   -0.0747364   -0.146749    -0.102871     0.191244    -0.0881024    -0.00655578   0.0782536    0.0632874     0.0359251   -0.0114105    0.0800564    0.0218792   -0.0930891   -0.0757058     0.0356265   -0.0738629kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4263699639297942
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.426388
[ Info: iteration 2, average log likelihood -1.426310
[ Info: iteration 3, average log likelihood -1.426247
[ Info: iteration 4, average log likelihood -1.426171
[ Info: iteration 5, average log likelihood -1.426079
[ Info: iteration 6, average log likelihood -1.425974
[ Info: iteration 7, average log likelihood -1.425863
[ Info: iteration 8, average log likelihood -1.425758
[ Info: iteration 9, average log likelihood -1.425658
[ Info: iteration 10, average log likelihood -1.425550
[ Info: iteration 11, average log likelihood -1.425395
[ Info: iteration 12, average log likelihood -1.425125
[ Info: iteration 13, average log likelihood -1.424647
[ Info: iteration 14, average log likelihood -1.423887
[ Info: iteration 15, average log likelihood -1.422914
[ Info: iteration 16, average log likelihood -1.422000
[ Info: iteration 17, average log likelihood -1.421382
[ Info: iteration 18, average log likelihood -1.421057
[ Info: iteration 19, average log likelihood -1.420910
[ Info: iteration 20, average log likelihood -1.420847
[ Info: iteration 21, average log likelihood -1.420820
[ Info: iteration 22, average log likelihood -1.420808
[ Info: iteration 23, average log likelihood -1.420803
[ Info: iteration 24, average log likelihood -1.420801
[ Info: iteration 25, average log likelihood -1.420799
[ Info: iteration 26, average log likelihood -1.420799
[ Info: iteration 27, average log likelihood -1.420798
[ Info: iteration 28, average log likelihood -1.420798
[ Info: iteration 29, average log likelihood -1.420798
[ Info: iteration 30, average log likelihood -1.420798
[ Info: iteration 31, average log likelihood -1.420797
[ Info: iteration 32, average log likelihood -1.420797
[ Info: iteration 33, average log likelihood -1.420797
[ Info: iteration 34, average log likelihood -1.420797
[ Info: iteration 35, average log likelihood -1.420797
[ Info: iteration 36, average log likelihood -1.420797
[ Info: iteration 37, average log likelihood -1.420797
[ Info: iteration 38, average log likelihood -1.420797
[ Info: iteration 39, average log likelihood -1.420797
[ Info: iteration 40, average log likelihood -1.420796
[ Info: iteration 41, average log likelihood -1.420796
[ Info: iteration 42, average log likelihood -1.420796
[ Info: iteration 43, average log likelihood -1.420796
[ Info: iteration 44, average log likelihood -1.420796
[ Info: iteration 45, average log likelihood -1.420796
[ Info: iteration 46, average log likelihood -1.420796
[ Info: iteration 47, average log likelihood -1.420796
[ Info: iteration 48, average log likelihood -1.420796
[ Info: iteration 49, average log likelihood -1.420796
[ Info: iteration 50, average log likelihood -1.420796
┌ Info: EM with 100000 data points 50 iterations avll -1.420796
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4263883449472137
│     -1.4263100274545204
│      ⋮
└     -1.4207960503676536
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420811
[ Info: iteration 2, average log likelihood -1.420732
[ Info: iteration 3, average log likelihood -1.420663
[ Info: iteration 4, average log likelihood -1.420578
[ Info: iteration 5, average log likelihood -1.420471
[ Info: iteration 6, average log likelihood -1.420344
[ Info: iteration 7, average log likelihood -1.420206
[ Info: iteration 8, average log likelihood -1.420069
[ Info: iteration 9, average log likelihood -1.419946
[ Info: iteration 10, average log likelihood -1.419843
[ Info: iteration 11, average log likelihood -1.419761
[ Info: iteration 12, average log likelihood -1.419698
[ Info: iteration 13, average log likelihood -1.419651
[ Info: iteration 14, average log likelihood -1.419616
[ Info: iteration 15, average log likelihood -1.419589
[ Info: iteration 16, average log likelihood -1.419568
[ Info: iteration 17, average log likelihood -1.419549
[ Info: iteration 18, average log likelihood -1.419533
[ Info: iteration 19, average log likelihood -1.419519
[ Info: iteration 20, average log likelihood -1.419505
[ Info: iteration 21, average log likelihood -1.419493
[ Info: iteration 22, average log likelihood -1.419482
[ Info: iteration 23, average log likelihood -1.419471
[ Info: iteration 24, average log likelihood -1.419462
[ Info: iteration 25, average log likelihood -1.419453
[ Info: iteration 26, average log likelihood -1.419446
[ Info: iteration 27, average log likelihood -1.419439
[ Info: iteration 28, average log likelihood -1.419433
[ Info: iteration 29, average log likelihood -1.419428
[ Info: iteration 30, average log likelihood -1.419424
[ Info: iteration 31, average log likelihood -1.419420
[ Info: iteration 32, average log likelihood -1.419417
[ Info: iteration 33, average log likelihood -1.419414
[ Info: iteration 34, average log likelihood -1.419412
[ Info: iteration 35, average log likelihood -1.419410
[ Info: iteration 36, average log likelihood -1.419408
[ Info: iteration 37, average log likelihood -1.419407
[ Info: iteration 38, average log likelihood -1.419406
[ Info: iteration 39, average log likelihood -1.419405
[ Info: iteration 40, average log likelihood -1.419404
[ Info: iteration 41, average log likelihood -1.419403
[ Info: iteration 42, average log likelihood -1.419403
[ Info: iteration 43, average log likelihood -1.419402
[ Info: iteration 44, average log likelihood -1.419401
[ Info: iteration 45, average log likelihood -1.419401
[ Info: iteration 46, average log likelihood -1.419401
[ Info: iteration 47, average log likelihood -1.419400
[ Info: iteration 48, average log likelihood -1.419400
[ Info: iteration 49, average log likelihood -1.419400
[ Info: iteration 50, average log likelihood -1.419400
┌ Info: EM with 100000 data points 50 iterations avll -1.419400
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4208106001223637
│     -1.4207321145919076
│      ⋮
└     -1.4193996188810818
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419410
[ Info: iteration 2, average log likelihood -1.419360
[ Info: iteration 3, average log likelihood -1.419317
[ Info: iteration 4, average log likelihood -1.419266
[ Info: iteration 5, average log likelihood -1.419205
[ Info: iteration 6, average log likelihood -1.419128
[ Info: iteration 7, average log likelihood -1.419038
[ Info: iteration 8, average log likelihood -1.418937
[ Info: iteration 9, average log likelihood -1.418831
[ Info: iteration 10, average log likelihood -1.418728
[ Info: iteration 11, average log likelihood -1.418635
[ Info: iteration 12, average log likelihood -1.418554
[ Info: iteration 13, average log likelihood -1.418488
[ Info: iteration 14, average log likelihood -1.418435
[ Info: iteration 15, average log likelihood -1.418394
[ Info: iteration 16, average log likelihood -1.418362
[ Info: iteration 17, average log likelihood -1.418337
[ Info: iteration 18, average log likelihood -1.418317
[ Info: iteration 19, average log likelihood -1.418300
[ Info: iteration 20, average log likelihood -1.418287
[ Info: iteration 21, average log likelihood -1.418275
[ Info: iteration 22, average log likelihood -1.418265
[ Info: iteration 23, average log likelihood -1.418256
[ Info: iteration 24, average log likelihood -1.418248
[ Info: iteration 25, average log likelihood -1.418240
[ Info: iteration 26, average log likelihood -1.418233
[ Info: iteration 27, average log likelihood -1.418226
[ Info: iteration 28, average log likelihood -1.418220
[ Info: iteration 29, average log likelihood -1.418213
[ Info: iteration 30, average log likelihood -1.418208
[ Info: iteration 31, average log likelihood -1.418202
[ Info: iteration 32, average log likelihood -1.418196
[ Info: iteration 33, average log likelihood -1.418191
[ Info: iteration 34, average log likelihood -1.418185
[ Info: iteration 35, average log likelihood -1.418180
[ Info: iteration 36, average log likelihood -1.418174
[ Info: iteration 37, average log likelihood -1.418169
[ Info: iteration 38, average log likelihood -1.418164
[ Info: iteration 39, average log likelihood -1.418159
[ Info: iteration 40, average log likelihood -1.418154
[ Info: iteration 41, average log likelihood -1.418149
[ Info: iteration 42, average log likelihood -1.418144
[ Info: iteration 43, average log likelihood -1.418139
[ Info: iteration 44, average log likelihood -1.418133
[ Info: iteration 45, average log likelihood -1.418128
[ Info: iteration 46, average log likelihood -1.418123
[ Info: iteration 47, average log likelihood -1.418118
[ Info: iteration 48, average log likelihood -1.418113
[ Info: iteration 49, average log likelihood -1.418108
[ Info: iteration 50, average log likelihood -1.418104
┌ Info: EM with 100000 data points 50 iterations avll -1.418104
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.419410398716172
│     -1.4193596111028166
│      ⋮
└     -1.4181035265445916
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418107
[ Info: iteration 2, average log likelihood -1.418053
[ Info: iteration 3, average log likelihood -1.418004
[ Info: iteration 4, average log likelihood -1.417949
[ Info: iteration 5, average log likelihood -1.417884
[ Info: iteration 6, average log likelihood -1.417804
[ Info: iteration 7, average log likelihood -1.417709
[ Info: iteration 8, average log likelihood -1.417602
[ Info: iteration 9, average log likelihood -1.417486
[ Info: iteration 10, average log likelihood -1.417367
[ Info: iteration 11, average log likelihood -1.417250
[ Info: iteration 12, average log likelihood -1.417141
[ Info: iteration 13, average log likelihood -1.417042
[ Info: iteration 14, average log likelihood -1.416955
[ Info: iteration 15, average log likelihood -1.416879
[ Info: iteration 16, average log likelihood -1.416814
[ Info: iteration 17, average log likelihood -1.416760
[ Info: iteration 18, average log likelihood -1.416713
[ Info: iteration 19, average log likelihood -1.416674
[ Info: iteration 20, average log likelihood -1.416640
[ Info: iteration 21, average log likelihood -1.416610
[ Info: iteration 22, average log likelihood -1.416584
[ Info: iteration 23, average log likelihood -1.416561
[ Info: iteration 24, average log likelihood -1.416539
[ Info: iteration 25, average log likelihood -1.416520
[ Info: iteration 26, average log likelihood -1.416502
[ Info: iteration 27, average log likelihood -1.416485
[ Info: iteration 28, average log likelihood -1.416468
[ Info: iteration 29, average log likelihood -1.416453
[ Info: iteration 30, average log likelihood -1.416437
[ Info: iteration 31, average log likelihood -1.416423
[ Info: iteration 32, average log likelihood -1.416409
[ Info: iteration 33, average log likelihood -1.416395
[ Info: iteration 34, average log likelihood -1.416381
[ Info: iteration 35, average log likelihood -1.416368
[ Info: iteration 36, average log likelihood -1.416355
[ Info: iteration 37, average log likelihood -1.416342
[ Info: iteration 38, average log likelihood -1.416329
[ Info: iteration 39, average log likelihood -1.416317
[ Info: iteration 40, average log likelihood -1.416305
[ Info: iteration 41, average log likelihood -1.416294
[ Info: iteration 42, average log likelihood -1.416282
[ Info: iteration 43, average log likelihood -1.416272
[ Info: iteration 44, average log likelihood -1.416261
[ Info: iteration 45, average log likelihood -1.416251
[ Info: iteration 46, average log likelihood -1.416241
[ Info: iteration 47, average log likelihood -1.416231
[ Info: iteration 48, average log likelihood -1.416222
[ Info: iteration 49, average log likelihood -1.416213
[ Info: iteration 50, average log likelihood -1.416205
┌ Info: EM with 100000 data points 50 iterations avll -1.416205
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4181066169340324
│     -1.418052768119032
│      ⋮
└     -1.416204679872169
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416205
[ Info: iteration 2, average log likelihood -1.416146
[ Info: iteration 3, average log likelihood -1.416091
[ Info: iteration 4, average log likelihood -1.416028
[ Info: iteration 5, average log likelihood -1.415952
[ Info: iteration 6, average log likelihood -1.415858
[ Info: iteration 7, average log likelihood -1.415744
[ Info: iteration 8, average log likelihood -1.415611
[ Info: iteration 9, average log likelihood -1.415464
[ Info: iteration 10, average log likelihood -1.415311
[ Info: iteration 11, average log likelihood -1.415160
[ Info: iteration 12, average log likelihood -1.415018
[ Info: iteration 13, average log likelihood -1.414888
[ Info: iteration 14, average log likelihood -1.414773
[ Info: iteration 15, average log likelihood -1.414672
[ Info: iteration 16, average log likelihood -1.414583
[ Info: iteration 17, average log likelihood -1.414505
[ Info: iteration 18, average log likelihood -1.414437
[ Info: iteration 19, average log likelihood -1.414378
[ Info: iteration 20, average log likelihood -1.414325
[ Info: iteration 21, average log likelihood -1.414279
[ Info: iteration 22, average log likelihood -1.414237
[ Info: iteration 23, average log likelihood -1.414200
[ Info: iteration 24, average log likelihood -1.414166
[ Info: iteration 25, average log likelihood -1.414136
[ Info: iteration 26, average log likelihood -1.414108
[ Info: iteration 27, average log likelihood -1.414081
[ Info: iteration 28, average log likelihood -1.414057
[ Info: iteration 29, average log likelihood -1.414034
[ Info: iteration 30, average log likelihood -1.414012
[ Info: iteration 31, average log likelihood -1.413992
[ Info: iteration 32, average log likelihood -1.413972
[ Info: iteration 33, average log likelihood -1.413952
[ Info: iteration 34, average log likelihood -1.413934
[ Info: iteration 35, average log likelihood -1.413916
[ Info: iteration 36, average log likelihood -1.413898
[ Info: iteration 37, average log likelihood -1.413881
[ Info: iteration 38, average log likelihood -1.413864
[ Info: iteration 39, average log likelihood -1.413847
[ Info: iteration 40, average log likelihood -1.413831
[ Info: iteration 41, average log likelihood -1.413815
[ Info: iteration 42, average log likelihood -1.413800
[ Info: iteration 43, average log likelihood -1.413785
[ Info: iteration 44, average log likelihood -1.413770
[ Info: iteration 45, average log likelihood -1.413755
[ Info: iteration 46, average log likelihood -1.413741
[ Info: iteration 47, average log likelihood -1.413728
[ Info: iteration 48, average log likelihood -1.413714
[ Info: iteration 49, average log likelihood -1.413702
[ Info: iteration 50, average log likelihood -1.413689
┌ Info: EM with 100000 data points 50 iterations avll -1.413689
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4162047130031263
│     -1.4161455911847445
│      ⋮
└     -1.4136889123077292
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4263699639297942
│     -1.4263883449472137
│     -1.4263100274545204
│     -1.4262466737129091
│      ⋮
│     -1.4137144640266992
│     -1.413701513561912
└     -1.4136889123077292
32×26 Array{Float64,2}:
 -0.511149    0.286195    0.227566    0.507        0.0240962  -0.366937   -0.220995     0.0209828   -0.296652    0.0260311    -0.223816     -0.249332   -0.0249627   0.0146002  -0.147326    -0.809509   -0.0753892   -0.106152    -0.0605483    0.0765562   0.28458     0.0854929  -0.0624817  -0.430252     0.0097305   -0.520805
  0.401703    0.0128305   0.822791   -0.414811    -0.144077   -0.414226    0.747064    -0.767609    -0.183865    0.164619      0.123873     -0.602049    0.659172    0.0485868   3.84592e-5  -0.278965   -0.359898    -0.197859     0.479658    -0.0564604   0.409549    0.321895   -0.514458   -0.256727     0.0831742   -0.202304
 -0.106706    0.851477   -0.121241   -0.202317    -0.0785861  -0.348486    0.533787    -0.692498    -0.055225   -0.281911     -0.0636551    -0.373196   -0.0300762   0.903905   -0.0431736   -0.0041003  -0.396221     0.0952474   -0.0170143    0.276192   -0.351271   -0.255291   -0.235744    0.338741    -0.118826     0.707197
 -0.0422745   0.777007   -0.0694036  -0.432574     0.243218   -0.391596   -0.0376354   -0.445305     0.239203    0.400517      0.426062      0.23517    -0.0534321   0.134767    0.546188    -0.174536   -0.142699    -0.102949     0.0937227    0.208413   -0.112699    0.0474867  -0.457529    0.525394     0.405212     0.0856529
 -0.244469    0.0523137  -0.334525    0.00029321  -0.128843   -0.191791    0.0529777    0.230609    -0.0643804   0.166951     -0.672649      0.222616    0.499018   -0.382405   -0.185271    -0.115014    0.0535031   -0.121641     0.0638653   -0.253988   -0.122498    0.924395    0.392602   -0.00252839   0.412798    -1.04491
 -0.0255939   0.0280854   0.15699    -0.0681409    0.141207   -0.595132   -0.0554657    0.0909705   -0.368571    0.0387028    -0.100004     -0.0188655   0.591859    0.0501773   0.166953     0.102557    0.38654      0.217873     0.0105404    0.0780368  -0.057932    0.650264    0.212833    0.131124     0.251678     0.285638
  0.27542     0.293404   -0.112972   -0.00518588   0.364396   -0.48919     0.0954544    0.319423    -0.474095   -0.0580093     0.31554      -0.478611   -0.338906   -0.119851   -0.298468     0.023897    0.229369    -0.184131     0.0371042   -0.0471938  -0.0776388  -0.23446     0.373848   -0.362252     0.266241     0.171666
 -0.0361743   0.0533946   0.182746   -0.120505    -0.272948    0.357094   -0.138216     0.222904    -0.442375    0.214567      0.417916     -0.430223   -0.527363   -0.0422238  -0.0366977    0.0603434   0.0192039    0.47962     -0.0120707   -0.204268    0.215432    0.239622    0.311656    0.0632363    0.120406     0.00637361
 -0.328046    0.157531   -0.181072   -0.345486    -0.305785    0.745624    0.0523804    0.0446357    0.359763   -0.300747     -0.437615      0.172045   -0.362019    0.109928   -0.608348     0.16119    -0.0989792   -0.0678603   -0.00857927  -0.288449   -0.27938    -0.262964    0.022886   -0.457358    -0.155555    -0.294581
  0.210108    0.217006   -0.626909   -0.555716    -0.286878    0.0730565   0.435405    -0.0732914    1.03852    -0.278106     -0.165268     -0.533943   -0.575838   -0.186312   -0.00822476  -0.178468    0.352468    -0.284744     0.00706119   0.204266   -0.437837   -0.1562     -0.126961    0.194389    -0.0103149   -0.778195
 -0.385858   -0.188996   -0.557694   -0.405355    -0.300538    0.0861651  -0.383567    -0.0147097   -0.291983    0.0804698     0.520341     -0.162271    0.283222    0.0631675  -0.250194     0.552791    0.0223594    0.088656    -0.0224636   -0.34819     0.416565   -0.301435   -0.350542   -0.137472     0.218153    -0.345631
  0.0736515  -0.138549   -0.578281    0.174954    -0.303245   -0.0478034   0.075718    -0.214602     0.881169   -0.167548     -0.135541      0.355761    0.317997    0.741723    0.526029     0.0632116   0.249742     0.13714      0.0391806   -0.490674    0.518673   -0.0581212  -0.300568   -0.0711293   -0.135908    -0.28703
 -0.0674093  -0.0754339  -0.272332   -0.26126     -0.214941    0.141092   -0.105598     0.0567531    0.200871   -0.0193647    -0.0414979     0.0394898   0.162526   -0.451931    0.0621498    0.252372   -0.00080044  -0.162879    -0.0724369    0.0359961  -0.186972    0.0325451  -0.0322694   0.139271     0.217115    -0.187895
  0.0869618  -0.333241   -0.285525   -0.0803296    0.598404    0.183657   -0.347617    -0.0504541    0.265013   -0.262687     -0.343117      0.270169    0.542986   -0.498396    0.108962     0.21954    -0.120557     0.106232    -0.00869798   0.143444   -0.284314   -0.506223   -0.36264    -0.0620416   -0.0501255    0.131807
  0.126093   -0.200405    0.221248    0.0616389    0.0403969   0.560728    0.115456    -0.457167     0.155434    0.388597      0.000338817   0.10699    -0.184296    0.243932    0.0130451   -0.219058   -0.186588     0.0626486   -0.00334119   0.229253   -0.0779898  -0.078954   -0.133431    0.187283    -0.369972     0.261442
 -0.0561447  -0.017335   -0.0462363   0.0644472    0.0754973   0.0528686   0.0757036    0.0882237   -0.0203425   0.00748771   -0.0256041     0.127827    0.0127035   0.245923   -0.0685464    0.0269684   0.00735248  -0.0313737    0.0396959   -0.115715    0.0915065  -0.182513   -0.0393199  -0.164366    -0.109626    -0.0281334
 -0.0920324  -0.211162    0.256464   -0.30257     -0.0515817   0.17777     0.00796948  -0.947863     0.562316    0.0658073    -0.384506      0.601467    0.728364    0.125336    0.193023     0.372242   -0.228305     0.00313077  -0.093951     0.107575   -0.123491    0.110252   -0.569785    0.410328    -0.0187797    0.180659
 -0.389603    0.0125831  -0.578586   -0.171613     0.147131   -0.223927    0.332888     0.682706     0.405733   -0.204932     -0.528314      0.483128   -0.0287755   0.0501372   0.499768     0.144754   -0.624673     0.207746     0.603684     0.764064   -0.359841   -0.26142    -0.725921    0.539687     0.00476473   0.325874
  0.774819    0.136977    0.469979    0.131735     0.437012    0.340967   -0.0840084   -0.344079     0.598531   -0.638372     -0.0136957     0.495762   -0.529371   -0.0199482   0.18088     -0.454786   -0.15873      0.0723132    0.0960393    0.0640229  -0.168691   -0.0375226  -0.589803    0.297748     0.437828     0.139695
  0.702657   -0.629215   -0.102019   -0.15291      0.168716    0.513858    0.265251     0.040469     1.08517    -0.0148812     0.284072      0.151224   -0.381164   -0.460797    0.249853     0.997221   -0.0806481   -0.281322    -0.562333     0.0884165  -0.457338   -0.339765    0.136493    0.0462391    0.0893103    0.357564
 -0.197522   -0.696771    0.127827    0.477733    -0.534371    0.145854   -0.0416108    0.368908     0.341736   -0.0182094     0.0921466     0.0446595   0.490543   -0.301712   -0.0393867    0.398805    0.231268    -0.264494     0.450088     0.0908961   0.107677    0.396317    0.448334    0.405368    -0.437218     0.00425025
  0.11006    -0.403223    0.0177592   0.431587    -0.538201    0.106211   -0.315619     0.628171    -0.129986    0.171174     -0.333791      0.0197837   0.188754   -0.30517     0.785048     0.297105    0.135708    -0.26252     -0.451368     0.0791852   0.201502    0.264167   -0.0470904   0.185754     0.830872     0.330978
  0.231399   -0.0199958   0.0322801   0.588538     0.141631   -0.341368    0.190712     0.00100885   0.104621    0.171036     -0.0166569     0.618116    0.367453   -0.164101    0.375037    -0.189593   -0.316176    -1.03684     -0.247155     0.121719   -0.0560736  -0.338728    0.120057   -0.0100751   -0.0606194   -0.159047
  0.48443     0.018505    0.537581    0.222339     1.02399    -0.441199    0.483607    -0.0687532   -0.370992    0.125168      0.177198      0.267593    0.179036   -0.0693032   0.0752088   -0.181433   -0.0731108    0.302612    -0.325676     0.0843015   0.230666   -0.140007    0.315236    0.277425     0.11909      0.436662
  0.0820965   0.592651   -0.110162   -0.258695     0.17468    -0.358196   -0.168589    -0.305466    -0.414247   -0.142986      0.113163     -0.0748152  -0.0209209   0.0757155  -0.399131    -0.203366    0.101266    -0.0490218   -0.402725    -0.580414    0.0142984  -0.0031198  -0.0171052  -0.707967     0.323529    -0.149178
  0.150064   -0.0939616  -0.0568853   0.0848111    0.039506   -0.0134567   0.0089712   -0.0401755    0.144226   -0.000452531   0.0888082    -0.0468615   0.011128   -0.0830905   0.113974     0.0218626  -0.0339732   -0.0531242   -0.00927828   0.0841489   0.14482    -0.0482966  -0.0293277   0.130568     0.0809539    0.0562172
 -0.788008    0.0553988   0.356164   -0.0814558   -0.465639   -0.0352509   0.0543308    0.247496    -0.497692    0.219138     -0.623191      0.343502    0.511887    0.264063    0.126198    -0.440421    0.39438     -0.0907282    0.300045    -0.432693    0.0856392   0.0120837   0.0720979  -0.487641    -0.791471    -0.21696
 -0.424366    0.346625    0.1523      0.247671     0.0731616   0.406982    0.160861    -0.0997744    0.161642    0.935328      0.46838       0.265656   -0.228243    1.07117    -0.119638    -0.100082    0.0545581   -0.254175    -0.269988    -0.0766625   0.396908    0.0572958   0.340513   -0.394026    -0.386757     0.0922638
 -0.099116   -0.303127    0.57668    -0.279598     0.562375    0.237075    0.00413723   0.0412079   -0.790183    0.0428766    -0.213851     -0.620611   -0.267294   -0.93876    [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
-0.630034    -0.245395   -0.233325     0.110847     0.329361     0.496463   -0.576433   -0.0463852   0.273845   -0.12954     -0.111142     0.152242
  0.135239   -0.0645841   0.0891546  -0.392592    -0.0973953  -0.0334639  -0.14602     -0.147357    -0.330379    0.0946273    -0.154357     -1.01807    -0.260228   -0.167987   -0.377806    -0.142701    0.441291     0.572534    -0.0861297    0.530082    0.0618101   0.723076    0.275069    0.111389     0.193389     0.248469
  0.128979   -0.608815   -0.443932    0.209799     0.124303    0.532679   -0.424488     0.900267    -0.0804382  -0.0906565     0.149548     -0.0467933  -0.715388   -0.0903914  -0.124827    -0.0428936   0.164392     0.259382    -0.134953    -0.0226263  -0.0378335  -0.554928    0.190738   -0.202496    -0.382716     0.0654231
 -0.228431    0.8658      0.0703603  -0.0973346    0.280999    0.15014     0.346413     0.178611    -0.0408773  -0.00385481    0.49899      -0.412552   -1.13316    -0.303735   -0.482053    -0.0658467   0.0694098    0.095065     0.245191    -0.397631   -0.313811   -0.305976    0.277217    0.114501    -0.1561      -0.545011[ Info: iteration 1, average log likelihood -1.413677
[ Info: iteration 2, average log likelihood -1.413665
[ Info: iteration 3, average log likelihood -1.413653
[ Info: iteration 4, average log likelihood -1.413642
[ Info: iteration 5, average log likelihood -1.413631
[ Info: iteration 6, average log likelihood -1.413620
[ Info: iteration 7, average log likelihood -1.413610
[ Info: iteration 8, average log likelihood -1.413600
[ Info: iteration 9, average log likelihood -1.413590
kind full, method kmeans
[ Info: iteration 10, average log likelihood -1.413581
┌ Info: EM with 100000 data points 10 iterations avll -1.413581
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.297950e+05
      1       7.105386e+05      -2.192564e+05 |       32
      2       6.949553e+05      -1.558325e+04 |       32
      3       6.895164e+05      -5.438965e+03 |       32
      4       6.869317e+05      -2.584653e+03 |       32
      5       6.852557e+05      -1.675964e+03 |       32
      6       6.840206e+05      -1.235169e+03 |       32
      7       6.830755e+05      -9.450324e+02 |       32
      8       6.822952e+05      -7.803671e+02 |       32
      9       6.816531e+05      -6.421133e+02 |       32
     10       6.811228e+05      -5.302487e+02 |       32
     11       6.806785e+05      -4.442917e+02 |       32
     12       6.802730e+05      -4.054762e+02 |       32
     13       6.799215e+05      -3.515619e+02 |       32
     14       6.796280e+05      -2.934416e+02 |       32
     15       6.793790e+05      -2.489952e+02 |       32
     16       6.791749e+05      -2.041639e+02 |       32
     17       6.789883e+05      -1.865492e+02 |       32
     18       6.788313e+05      -1.570369e+02 |       32
     19       6.786709e+05      -1.604087e+02 |       32
     20       6.785113e+05      -1.595337e+02 |       32
     21       6.783791e+05      -1.322213e+02 |       32
     22       6.782652e+05      -1.138871e+02 |       32
     23       6.781698e+05      -9.544445e+01 |       32
     24       6.780846e+05      -8.516238e+01 |       32
     25       6.780078e+05      -7.680457e+01 |       32
     26       6.779420e+05      -6.580387e+01 |       32
     27       6.778818e+05      -6.023406e+01 |       32
     28       6.778199e+05      -6.193156e+01 |       32
     29       6.777557e+05      -6.411429e+01 |       32
     30       6.776939e+05      -6.184899e+01 |       32
     31       6.776372e+05      -5.670006e+01 |       32
     32       6.775902e+05      -4.698083e+01 |       32
     33       6.775407e+05      -4.947407e+01 |       32
     34       6.774980e+05      -4.277341e+01 |       32
     35       6.774558e+05      -4.218342e+01 |       32
     36       6.774170e+05      -3.879125e+01 |       32
     37       6.773903e+05      -2.667846e+01 |       32
     38       6.773708e+05      -1.950266e+01 |       32
     39       6.773503e+05      -2.047749e+01 |       32
     40       6.773298e+05      -2.053149e+01 |       32
     41       6.773103e+05      -1.950004e+01 |       32
     42       6.772929e+05      -1.738737e+01 |       32
     43       6.772789e+05      -1.398794e+01 |       32
     44       6.772644e+05      -1.451511e+01 |       32
     45       6.772484e+05      -1.603745e+01 |       32
     46       6.772323e+05      -1.603984e+01 |       31
     47       6.772184e+05      -1.394455e+01 |       32
     48       6.772046e+05      -1.373877e+01 |       32
     49       6.771953e+05      -9.382717e+00 |       32
     50       6.771864e+05      -8.850239e+00 |       32
K-means terminated without convergence after 50 iterations (objv = 677186.4142704685)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425767
[ Info: iteration 2, average log likelihood -1.420629
[ Info: iteration 3, average log likelihood -1.419224
[ Info: iteration 4, average log likelihood -1.418094
[ Info: iteration 5, average log likelihood -1.416855
[ Info: iteration 6, average log likelihood -1.415769
[ Info: iteration 7, average log likelihood -1.415096
[ Info: iteration 8, average log likelihood -1.414749
[ Info: iteration 9, average log likelihood -1.414558
[ Info: iteration 10, average log likelihood -1.414432
[ Info: iteration 11, average log likelihood -1.414335
[ Info: iteration 12, average log likelihood -1.414255
[ Info: iteration 13, average log likelihood -1.414186
[ Info: iteration 14, average log likelihood -1.414124
[ Info: iteration 15, average log likelihood -1.414068
[ Info: iteration 16, average log likelihood -1.414017
[ Info: iteration 17, average log likelihood -1.413969
[ Info: iteration 18, average log likelihood -1.413925
[ Info: iteration 19, average log likelihood -1.413884
[ Info: iteration 20, average log likelihood -1.413845
[ Info: iteration 21, average log likelihood -1.413808
[ Info: iteration 22, average log likelihood -1.413774
[ Info: iteration 23, average log likelihood -1.413742
[ Info: iteration 24, average log likelihood -1.413712
[ Info: iteration 25, average log likelihood -1.413683
[ Info: iteration 26, average log likelihood -1.413656
[ Info: iteration 27, average log likelihood -1.413630
[ Info: iteration 28, average log likelihood -1.413606
[ Info: iteration 29, average log likelihood -1.413583
[ Info: iteration 30, average log likelihood -1.413562
[ Info: iteration 31, average log likelihood -1.413541
[ Info: iteration 32, average log likelihood -1.413521
[ Info: iteration 33, average log likelihood -1.413502
[ Info: iteration 34, average log likelihood -1.413484
[ Info: iteration 35, average log likelihood -1.413467
[ Info: iteration 36, average log likelihood -1.413450
[ Info: iteration 37, average log likelihood -1.413434
[ Info: iteration 38, average log likelihood -1.413418
[ Info: iteration 39, average log likelihood -1.413403
[ Info: iteration 40, average log likelihood -1.413388
[ Info: iteration 41, average log likelihood -1.413374
[ Info: iteration 42, average log likelihood -1.413360
[ Info: iteration 43, average log likelihood -1.413346
[ Info: iteration 44, average log likelihood -1.413332
[ Info: iteration 45, average log likelihood -1.413319
[ Info: iteration 46, average log likelihood -1.413306
[ Info: iteration 47, average log likelihood -1.413294
[ Info: iteration 48, average log likelihood -1.413281
[ Info: iteration 49, average log likelihood -1.413269
[ Info: iteration 50, average log likelihood -1.413257
┌ Info: EM with 100000 data points 50 iterations avll -1.413257
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.476979   -0.238349     -0.497681     0.343003   -0.429652     0.266867    -0.517263     0.926253     -0.193606   -0.108175     0.813404   -0.443328   -0.783863     0.177096     0.417718   -0.174205     0.0138081    0.0493184   0.0223899   0.0702763    0.367756    -0.629327   -0.322032    0.0587135   -0.413711     0.190603
 -1.10727     0.394083      0.0503514    1.31366    -0.180556    -0.326037     0.278609     0.667657     -0.289074    0.629327     0.060308   -0.198029   -0.371351    -0.517005     0.188899   -0.791898     0.222964     0.0747325  -0.177873   -0.255107     0.155159    -0.0731119   0.160528   -0.503838    -0.139835    -0.872365
 -0.707227    0.330549      0.141233    -0.138176   -0.147052    -0.0170135   -0.17839     -0.0181742    -0.218273    0.214218    -0.285785    0.474828    0.351109     0.787473     0.0759311  -0.193728     0.274088    -0.0654574   0.0824186  -0.435542     0.133618    -0.0620683  -0.153276   -0.420255    -0.472162    -0.142192
 -0.504152   -0.153987     -0.829413    -0.470928   -0.634089     0.104869    -0.328259     0.0651743     0.182179   -0.00843735  -0.151888   -0.17436     0.386328    -0.0180346    0.14907     0.439429     0.40681      0.295966    0.156403   -0.43676      0.098759    -0.102777   -0.218422   -0.0543269    0.0101923   -0.718125
  0.115692    0.110099      0.0843051   -0.142585    0.0555369   -0.0208851   -0.045491    -0.0982693    -0.265214    0.0962723    0.117279   -0.482321   -0.195266    -0.199778    -0.386214   -0.0039819    0.0485129    0.164342   -0.225985   -0.0395919   -0.00171082   0.113345    0.189345   -0.127902     0.104486     0.135525
 -0.059511    0.510223     -0.0489396   -0.588357    0.550028     0.291669     0.353084    -0.55943       0.243288   -0.182032     0.0797724   0.0691107  -0.560927    -0.383049    -1.01427    -0.212734     0.0194563    0.0333533   0.0662538  -0.437547    -0.434109    -0.231158    0.256865   -0.273362    -0.0982935   -0.877547
  0.032002    0.444049      0.0508734   -0.474907    0.121072    -0.168581     0.0851092    0.365412     -0.494212    0.15938      0.396418   -0.373051   -0.21488     -0.517509    -0.215681    0.458028     0.117399     0.108335   -0.0348281  -0.18099     -0.277292    -0.0280633   0.428687    0.199354     0.18564      0.11965
  0.112814   -0.159068     -0.302967    -0.145218    0.533513     0.00595605  -0.175265    -0.113535      0.421163   -0.221354    -0.280898    0.412875    0.534858    -0.319282     0.17546     0.286883    -0.19782     -0.0452306  -0.068823    0.161429    -0.37805     -0.436607   -0.472447    0.0253301    0.027424     0.2234
  0.318803    0.501852     -0.421866    -0.3366     -0.166617     0.0621421    0.119559    -0.194292      0.900263   -0.214592     0.189214   -0.17173    -0.592453    -0.333639     0.395164   -0.107005     0.0676665   -0.496983   -0.124313    0.293977    -0.432279    -0.0637713  -0.249812    0.495921     0.313584    -0.54277
  0.258614    0.304433      0.508332    -0.687984   -0.481953    -0.467688     0.747768    -0.997001      0.0047949   0.343823     0.279769   -0.443492    0.773673     0.180273     0.117663   -0.00319124  -0.263435    -0.160821    0.128259    0.176774     0.0921677    0.344992   -0.544553    0.0510128    0.216289     0.12315
  0.0750782  -0.486115      0.131077    -0.080237   -0.349611     0.76127     -0.102039    -0.179646      0.288154    0.297674    -0.0941785   0.29334     0.0592429    0.234691     0.128493    0.247523     0.135013     0.347294    0.173394    0.0229047   -0.269164    -0.0558793  -0.040039    0.334898    -0.579471     0.582823
 -0.32121    -0.305805     -0.12512      0.34927    -0.458033    -0.18442      0.00964966   0.310527      0.232225   -0.0778397   -0.419278    0.281301    0.817796    -0.599526     0.0444863   0.255975     0.076339    -0.533888    0.10393    -0.0830828   -0.16148      0.419204    0.414711    0.243638     0.00504303  -0.285202
  0.273794    0.0980837     0.451936     0.563311    0.489142    -0.261753     0.363107     0.000779058   0.0138232   0.452244    -0.0195459   0.285959   -0.0369978    0.0476168    0.162806   -0.339116    -0.171137    -0.690246   -0.378653    0.559615    -0.164427    -0.0196468   0.646731   -0.00192323   0.0132338    0.381171
  0.421546   -0.57611       0.0731193    0.0202945  -0.447671     0.351056    -0.373381    -0.240127     -0.342857   -0.344164    -0.521452   -0.713898    0.0203682   -1.32222      0.395171   -0.0932037   -0.257275     0.272433    0.269713    0.317715    -0.757398     0.0222499  -0.292194    0.032563     0.906093     0.159279
 -0.069568   -0.248552     -0.220755    -0.296855   -0.292907     0.416872     0.623747     0.391968     -0.0259022  -0.196655    -0.176181   -0.721737   -0.616619    -0.0910348   -0.716531   -0.0813616    0.396265     0.369876    0.367865    0.327954    -0.476909     0.182396    0.60682    -0.168039    -0.488129    -0.0304037
 -0.093403   -0.293808      0.671886    -0.341296    0.71386      0.536683    -0.177435    -0.57968      -0.395216    0.280306    -0.173703   -0.467072    0.0926621   -0.387574    -0.296487   -0.462777    -0.371648     0.163538    0.56634     0.763234    -0.0389787   -0.0206216  -0.0368709   0.0795638   -0.581848    -0.0398419
  0.420262   -0.956222     -0.156117    -0.141241    0.0422581    0.671726    -0.0719777    0.419649      0.848472    0.128195     0.262833    0.283161   -0.450557    -0.655635     0.123193    0.877819     0.00549936  -0.224604   -0.561774    0.0700673   -0.34464     -0.44115     0.298104   -0.169624     0.100273     0.21397
  0.0545926  -0.531769     -0.0548167    0.193621   -0.0740194    0.481653     0.201801    -0.503809      1.01366    -0.334375    -0.667871    0.360314   -0.00818513   0.628062     0.166895   -0.134054     0.0602025    0.0370715  -0.0907524   0.0798633    0.198428     0.214998   -0.618128   -0.0695391   -0.0617821   -0.2052
  0.191586   -0.232601      0.229453     0.0767151  -0.0573919   -0.0534454   -0.120231    -0.527197      0.178779    0.100565     0.174003    0.638083    0.751317     0.0439534    0.51221     0.290968    -0.273631    -0.633724   -0.257695   -0.00739679   0.491225    -0.187401   -0.679791    0.300326     0.328813     0.0670988
  0.0715162  -0.751451     -0.0731578    0.269174    0.138993     0.302432    -0.175948     0.553735     -0.318169    0.033441     0.0925143   0.0891926   0.0424276   -0.0593343   -0.239505    0.111266    -0.245347     0.117022    0.0310241  -0.163869     0.877511    -0.304197    0.205708   -0.367584    -0.276086    -0.369526
  0.262645   -0.0953644    -0.00916152  -0.318355    0.0459235    0.0695068   -0.41261      0.638953     -0.186707    0.272496    -0.295013   -0.417188   -0.272541    -0.403519    -0.119099    0.154958     0.149554     0.247871   -0.188138    0.23529      0.361504     0.952578    0.150706    0.0896016    0.90743     -0.257498
  0.716191   -0.000489453   0.115441     0.0363626   1.10356     -0.145864     0.319502    -0.0501716     0.276545   -0.267571    -0.0709571   0.473789   -0.116235    -0.201467     0.352863   -0.198484    -0.0318484    0.253738    0.103059    0.0660215   -0.118896    -0.413476   -0.170211    0.389681     0.204437     0.096217
  0.450392    0.287238     -0.71759      0.300031   -0.332654    -0.33434      0.523613    -0.0615796     0.780981   -0.00906116   0.488987    0.453345    0.0548122    0.91943      0.767748    0.292058     0.152803    -0.0701972  -0.0782976  -0.55411      0.342854     0.152592    0.319358    0.0668368    0.115582    -0.0123628
 -0.478294    0.66936      -0.468788    -0.331025   -0.00907437  -0.512999     0.233748    -0.291472      0.13257    -0.110439    -0.191472   -0.0100485  -0.163308     0.487853     0.139714    0.00482476  -0.635796     0.258191    0.344174    0.651554    -0.358447    -0.0130996  -0.673793    0.65198      0.114582     0.570467
  0.0138318  -0.100879      0.230541     0.0457733   0.160978    -0.54136     -0.0815437    0.07279      -0.382984    0.104581     0.0109952  -0.0431996   0.504712     0.11066      0.298611    0.0275568    0.371959     0.272225   -0.019566    0.125878     0.0692589    0.575902    0.177023    0.215815     0.184671     0.421216
 -0.476393   -0.241198     -0.253024     0.491645    0.611581     0.240964    -0.622901     0.913159     -0.204587   -0.341083    -0.338742   -0.137551   -0.671485    -0.285314    -0.408204   -0.409383     0.447395     0.229519   -0.202369   -0.100967    -0.47182     -0.421805    0.391589   -0.367314    -0.0679247    0.0882193
 -0.719152    0.203556      0.111925     0.0147545  -0.395482     0.199925    -0.396163    -0.327916     -0.20707     0.146253     0.45434    -0.299296   -0.428106     0.403518    -0.395146   -0.109949    -0.140538     0.175125   -0.301925    0.00323475   0.431308     0.265089    0.0425072  -0.0985915    0.345259    -0.0728971
 -0.535026    0.373108     -0.0672607   -0.0260965  -0.41474      0.408293     0.215723     0.256891      0.176901   -0.113607    -0.077371    0.383649   -0.257315     0.241113    -0.253428    0.226032    -0.275128    -0.745659    0.0746189  -0.343807    -0.159254    -0.733907   -0.32456    -0.408531    -0.225384    -0.200711
 -0.0467527   0.396504      0.110305     0.130703    0.178297    -0.503015     0.141842    -0.193773     -0.286804    0.00924955  -0.464257   -0.0693179   0.431133     0.00250545  -0.0551565  -0.656489    -0.0846364   -0.162796    0.155044   -0.24841      0.18359      0.403799   -0.0361302  -0.235213     0.0546841   -0.652805
  0.35518     0.229317     -0.209973    -0.0430522   0.255462    -0.588207    -0.0204155    0.022945     -0.564223   -0.0953966    0.544401   -0.491137   -0.102975     0.162946    -0.288832   -0.0170497    0.482275    -0.103333    0.0636075  -0.225143     0.254662    -0.340108    0.110331   -0.742763     0.278353     0.177054
 -0.0621891  -0.0722817    -0.109095    -0.0326827  -0.0580157    0.14089     -0.0150848    0.0282728     0.0608148   0.0481695   -0.0270733   0.0733677   0.0472691   -0.0272937   -0.0308116   0.0413511   -0.0107081   -0.0684525   0.0159315   0.00526948  -0.0118734   -0.0311847  -0.0104986  -0.0345162    0.0328516   -0.0887951
  0.375976    0.374768      0.388121     0.0391476   0.337027     0.225523     0.245332    -0.348692      0.0205151   0.0906601    0.199651   -0.0576883  -0.498453     0.347171     0.0636875  -0.262275    -0.284407     0.240271   -0.179598   -0.0817177    0.0216302   -0.251674   -0.15533     0.137855    -0.106707     0.29032[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413246
[ Info: iteration 2, average log likelihood -1.413235
[ Info: iteration 3, average log likelihood -1.413224
[ Info: iteration 4, average log likelihood -1.413213
[ Info: iteration 5, average log likelihood -1.413203
[ Info: iteration 6, average log likelihood -1.413193
[ Info: iteration 7, average log likelihood -1.413183
[ Info: iteration 8, average log likelihood -1.413173
[ Info: iteration 9, average log likelihood -1.413164
[ Info: iteration 10, average log likelihood -1.413155
┌ Info: EM with 100000 data points 10 iterations avll -1.413155
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
