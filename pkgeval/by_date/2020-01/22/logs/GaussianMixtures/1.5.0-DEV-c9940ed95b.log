Julia Version 1.5.0-DEV.133
Commit c9940ed95b (2020-01-21 18:51 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed URIParser ────────── v0.4.0
 Installed GaussianMixtures ─── v0.3.0
 Installed Missings ─────────── v0.4.3
 Installed Arpack_jll ───────── v3.5.0+2
 Installed ScikitLearnBase ──── v0.5.0
 Installed OrderedCollections ─ v1.1.0
 Installed QuadGK ───────────── v2.3.1
 Installed StatsBase ────────── v0.32.0
 Installed Rmath ────────────── v0.6.0
 Installed BinaryProvider ───── v0.5.8
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed PDMats ───────────── v0.9.10
 Installed Parameters ───────── v0.12.0
 Installed BinDeps ──────────── v1.0.0
 Installed DataStructures ───── v0.17.9
 Installed NearestNeighbors ─── v0.4.4
 Installed StatsFuns ────────── v0.9.3
 Installed FillArrays ───────── v0.8.4
 Installed CMake ────────────── v1.1.2
 Installed JLD ──────────────── v0.9.1
 Installed Arpack ───────────── v0.4.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed FileIO ───────────── v1.2.1
 Installed Clustering ───────── v0.13.3
 Installed StaticArrays ─────── v0.12.1
 Installed Blosc ────────────── v0.5.1
 Installed SortingAlgorithms ── v0.3.1
 Installed Distances ────────── v0.8.2
 Installed HDF5 ─────────────── v0.12.5
 Installed Compat ───────────── v2.2.0
 Installed DataAPI ──────────── v1.1.0
 Installed LegacyStrings ────── v0.4.1
 Installed SpecialFunctions ─── v0.9.0
 Installed Distributions ────── v0.22.3
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_lCTVTo/Project.toml`
 [no changes]
  Updating `/tmp/jl_lCTVTo/Manifest.toml`
 [no changes]
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_6NsfBa/Project.toml`
 [no changes]
  Updating `/tmp/jl_6NsfBa/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_ZYTtEu/Project.toml`
 [no changes]
  Updating `/tmp/jl_ZYTtEu/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_ICo4nz/Project.toml`
 [no changes]
  Updating `/tmp/jl_ICo4nz/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_NoMeh7/Project.toml`
 [no changes]
  Updating `/tmp/jl_NoMeh7/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_NoMeh7/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -3.696852407132402e6, [99746.01400954969, 253.9859904503134], [120.49777200883194 -12.723891681739232 -285.2077441588011; -385.6008720739521 325.46673649532477 611.160269152739], [[98853.85391987156 488.6426444711175 558.6578923057853; 488.6426444711175 98995.08505054827 -1120.5935995244827; 558.6578923057853 -1120.5935995244827 98570.6440750803], [774.9412521998644 -426.0807446759811 -856.5381423260285; -426.080744675981 606.4632014306147 731.1620186716655; -856.5381423260285 731.1620186716655 1562.3737804489779]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.263530e+03
      1       9.328861e+02      -3.306435e+02 |        3
      2       9.219640e+02      -1.092209e+01 |        2
      3       9.162075e+02      -5.756569e+00 |        2
      4       8.906851e+02      -2.552235e+01 |        0
      5       8.906851e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 890.6851278776494)
┌ Info: K-means with 272 data points using 5 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.078904
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.790224
[ Info: iteration 2, lowerbound -3.653066
[ Info: iteration 3, lowerbound -3.520475
[ Info: iteration 4, lowerbound -3.382959
[ Info: iteration 5, lowerbound -3.245754
[ Info: iteration 6, lowerbound -3.112788
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.983461
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.881704
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.816299
[ Info: iteration 10, lowerbound -2.789801
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.775201
[ Info: iteration 12, lowerbound -2.757469
[ Info: iteration 13, lowerbound -2.742972
[ Info: iteration 14, lowerbound -2.723255
[ Info: iteration 15, lowerbound -2.697375
[ Info: iteration 16, lowerbound -2.664934
[ Info: iteration 17, lowerbound -2.626399
[ Info: iteration 18, lowerbound -2.583277
[ Info: iteration 19, lowerbound -2.538014
[ Info: iteration 20, lowerbound -2.493463
[ Info: iteration 21, lowerbound -2.451945
[ Info: iteration 22, lowerbound -2.414420
[ Info: iteration 23, lowerbound -2.380531
[ Info: iteration 24, lowerbound -2.349965
[ Info: iteration 25, lowerbound -2.324735
[ Info: iteration 26, lowerbound -2.309763
[ Info: iteration 27, lowerbound -2.308474
[ Info: dropping number of Gaussions to 2
[ Info: iteration 28, lowerbound -2.302914
[ Info: iteration 29, lowerbound -2.299258
[ Info: iteration 30, lowerbound -2.299255
[ Info: iteration 31, lowerbound -2.299254
[ Info: iteration 32, lowerbound -2.299254
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Thu Jan 23 04:43:29 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Thu Jan 23 04:43:37 2020: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Thu Jan 23 04:43:39 2020: EM with 272 data points 0 iterations avll -2.078904
5.8 data points per parameter
, Thu Jan 23 04:43:41 2020: GMM converted to Variational GMM
, Thu Jan 23 04:43:50 2020: iteration 1, lowerbound -3.790224
, Thu Jan 23 04:43:50 2020: iteration 2, lowerbound -3.653066
, Thu Jan 23 04:43:50 2020: iteration 3, lowerbound -3.520475
, Thu Jan 23 04:43:50 2020: iteration 4, lowerbound -3.382959
, Thu Jan 23 04:43:50 2020: iteration 5, lowerbound -3.245754
, Thu Jan 23 04:43:50 2020: iteration 6, lowerbound -3.112788
, Thu Jan 23 04:43:50 2020: dropping number of Gaussions to 7
, Thu Jan 23 04:43:50 2020: iteration 7, lowerbound -2.983461
, Thu Jan 23 04:43:50 2020: dropping number of Gaussions to 6
, Thu Jan 23 04:43:50 2020: iteration 8, lowerbound -2.881704
, Thu Jan 23 04:43:50 2020: dropping number of Gaussions to 5
, Thu Jan 23 04:43:50 2020: iteration 9, lowerbound -2.816299
, Thu Jan 23 04:43:50 2020: iteration 10, lowerbound -2.789801
, Thu Jan 23 04:43:50 2020: dropping number of Gaussions to 3
, Thu Jan 23 04:43:50 2020: iteration 11, lowerbound -2.775201
, Thu Jan 23 04:43:50 2020: iteration 12, lowerbound -2.757469
, Thu Jan 23 04:43:50 2020: iteration 13, lowerbound -2.742972
, Thu Jan 23 04:43:50 2020: iteration 14, lowerbound -2.723255
, Thu Jan 23 04:43:50 2020: iteration 15, lowerbound -2.697375
, Thu Jan 23 04:43:50 2020: iteration 16, lowerbound -2.664934
, Thu Jan 23 04:43:50 2020: iteration 17, lowerbound -2.626399
, Thu Jan 23 04:43:50 2020: iteration 18, lowerbound -2.583277
, Thu Jan 23 04:43:50 2020: iteration 19, lowerbound -2.538014
, Thu Jan 23 04:43:50 2020: iteration 20, lowerbound -2.493463
, Thu Jan 23 04:43:50 2020: iteration 21, lowerbound -2.451945
, Thu Jan 23 04:43:50 2020: iteration 22, lowerbound -2.414420
, Thu Jan 23 04:43:50 2020: iteration 23, lowerbound -2.380531
, Thu Jan 23 04:43:50 2020: iteration 24, lowerbound -2.349965
, Thu Jan 23 04:43:50 2020: iteration 25, lowerbound -2.324735
, Thu Jan 23 04:43:50 2020: iteration 26, lowerbound -2.309763
, Thu Jan 23 04:43:50 2020: iteration 27, lowerbound -2.308474
, Thu Jan 23 04:43:50 2020: dropping number of Gaussions to 2
, Thu Jan 23 04:43:50 2020: iteration 28, lowerbound -2.302914
, Thu Jan 23 04:43:50 2020: iteration 29, lowerbound -2.299258
, Thu Jan 23 04:43:50 2020: iteration 30, lowerbound -2.299255
, Thu Jan 23 04:43:50 2020: iteration 31, lowerbound -2.299254
, Thu Jan 23 04:43:50 2020: iteration 32, lowerbound -2.299254
, Thu Jan 23 04:43:50 2020: iteration 33, lowerbound -2.299253
, Thu Jan 23 04:43:50 2020: iteration 34, lowerbound -2.299253
, Thu Jan 23 04:43:50 2020: iteration 35, lowerbound -2.299253
, Thu Jan 23 04:43:50 2020: iteration 36, lowerbound -2.299253
, Thu Jan 23 04:43:50 2020: iteration 37, lowerbound -2.299253
, Thu Jan 23 04:43:50 2020: iteration 38, lowerbound -2.299253
, Thu Jan 23 04:43:50 2020: iteration 39, lowerbound -2.299253
, Thu Jan 23 04:43:50 2020: iteration 40, lowerbound -2.299253
, Thu Jan 23 04:43:50 2020: iteration 41, lowerbound -2.299253
, Thu Jan 23 04:43:50 2020: iteration 42, lowerbound -2.299253
, Thu Jan 23 04:43:50 2020: iteration 43, lowerbound -2.299253
, Thu Jan 23 04:43:50 2020: iteration 44, lowerbound -2.299253
, Thu Jan 23 04:43:50 2020: iteration 45, lowerbound -2.299253
, Thu Jan 23 04:43:50 2020: iteration 46, lowerbound -2.299253
, Thu Jan 23 04:43:50 2020: iteration 47, lowerbound -2.299253
, Thu Jan 23 04:43:50 2020: iteration 48, lowerbound -2.299253
, Thu Jan 23 04:43:50 2020: iteration 49, lowerbound -2.299253
, Thu Jan 23 04:43:50 2020: iteration 50, lowerbound -2.299253
, Thu Jan 23 04:43:50 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222628627, 95.9549077737138]
β = [178.04509222628627, 95.9549077737138]
m = [4.250300733267698 79.2868669443293; 2.000229257773084 53.851987172449384]
ν = [180.04509222628627, 97.9549077737138]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547454387 -0.007644049042356393; 0.0 0.008581705166292255], [0.37587636119864604 -0.008953123827391041; 0.0 0.01274866477742083]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -1.001664517480473
avll from llpg:  -1.001664517480474
avll direct:     -1.001664517480474
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0246061269586824
avll from llpg:  -1.0246061269586824
avll direct:     -1.0246061269586824
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.0661268    -0.0836416    -0.0440673   -0.120342     0.00190495   0.0470194    0.178311    -0.0576035  -0.0102906  -0.168295     0.0158026   -0.0477767   -0.0335526    0.0665062   -0.177817     0.113432    -0.0844458     0.178003     0.0188307    0.0631913   0.035764     -0.0476531    -0.0364213   -0.047918     0.028908     0.0182834
 -0.0256842    -0.0149024     0.0750418   -0.0784167   -0.0314129   -0.100123    -0.0131791    0.085546    0.0713021   0.0159064   -0.00522136  -0.0547129    0.0203482   -0.00484433  -0.0815766    0.103795     0.161457      0.0557773   -0.0783612    0.232538   -0.112535      0.101303     -0.0965552    0.0638733    0.11361     -0.0581089
 -0.0849468     0.0999582    -0.0258205   -0.0205393   -0.0396993   -0.122117     0.114376     0.200119    0.12062    -0.100108     0.160514     0.0251485   -0.122135     0.0592153    0.00332605   0.0645174   -0.19261       0.0327202    0.00274216   0.0565759  -0.156031     -0.00701211   -0.0643341   -0.11013      0.0318272   -0.208123
  0.0162527    -0.0590204     0.0299058    0.0535166   -0.00841217   0.0641258   -0.0384995   -0.123194    0.0874414   0.00333718   0.0268176    0.09424     -0.00607077  -0.24027     -0.0159271    0.100366    -0.0593367    -0.0326284    0.0516643   -0.196295    0.000161882  -0.0683062     0.0473429   -0.103102    -0.0958118    0.152125
 -0.00314022   -0.0225928     0.00429575   0.0502828   -0.0719359    0.12916     -0.0745641   -0.0644804  -0.0482181   0.150984    -0.0784177   -0.00728817  -0.156505    -0.00943586  -0.0265323   -0.222271     0.207422     -2.53762e-5  -0.100491     0.244174   -0.105639      0.0872057     0.150663     0.107258    -0.0703362   -0.038624
  0.0519272    -0.0451292     0.039771    -0.0632524   -0.144378     0.073642    -0.0135419    0.0492633   0.203963    0.0759907    0.127522    -0.0823813    0.13946     -0.0261609    0.0479868    0.0619413    0.0295479     0.147967     0.105421    -0.0193808  -0.21921      -0.0215056    -0.123807     0.025786    -0.0126062    0.0702286
 -0.109887     -0.167843      0.121287    -0.00994213  -0.0924796    0.0866419   -0.045287     0.207912   -0.135914   -0.0715556   -0.0683647   -0.10017      0.161847    -0.049318     0.0470814   -0.0606065    0.000905461   0.0178602    0.0393217    0.1631     -0.022469      0.135533      0.134246    -0.017584    -0.132942    -0.0123436
 -0.144687      0.0718256    -0.165889    -0.0131683   -0.0972791   -0.0272233    0.00905704   0.0708169  -0.207864   -0.144681    -0.0217177    0.0429538    0.0659137    0.0553322   -0.0306999    0.00440269   0.0428039     0.228216     0.170638     0.182778   -0.20702       0.0375665    -0.129999    -0.011631    -0.00524164  -0.121459
  0.162671     -0.0370152     0.0904456    0.077486     0.00438591   0.124037     0.147538    -0.081761   -0.0976934   0.126895     0.00286787  -0.0206227   -0.0708689    0.031186     0.175378     0.0451342   -0.00184731   -0.0099572    0.130378     0.126341   -0.0526785    -0.000512847  -0.0274203   -0.0795521   -0.0109352   -0.0234271
 -0.128863      0.0119599    -0.0544056   -0.0246841    0.285593    -0.11803      0.159659     0.0284271  -0.106439    0.0795214    0.0114926   -0.0692701   -0.0278404   -0.0411989    0.0696522   -0.0602183    0.0942891    -0.105716    -0.00921161  -0.0448017   0.125682     -0.0253912     0.0669892    0.0114861   -0.165743    -0.126892
  0.0241614    -0.127681     -0.0341407   -0.117091    -0.135022     0.0274542    0.0346132   -0.143094   -0.0417333   0.117936    -0.195442    -0.0528668    0.10004     -0.0354385    0.028391    -0.109237    -0.109515      0.0530921   -0.0615179   -0.0352982  -0.171274      0.0398506     0.116349    -0.0939093   -0.0257458   -0.0605157
 -0.111019      0.0795235    -0.0679842    0.109296    -5.71442e-5   0.00401523  -0.0567848    0.0442356   0.0103244   0.111711    -0.0482719   -0.0782187   -0.00284804  -0.0236085    0.0107188    0.0916421   -0.0937038     0.143369     0.0420821    0.0854701  -0.0212768     0.0462373     0.067436     0.0558784   -0.251339     0.203002
 -0.0221411     0.0677397    -0.104152    -0.0809365    0.0481029   -0.00753219  -0.0161351    0.0490352  -0.17698    -0.0548007    0.0418836    0.0750823   -0.0698729   -0.324103    -0.0101014    0.0233163   -0.00758018   -0.237587    -0.102705     0.0691991   0.0123517    -0.0316604     0.151925     0.0877033   -0.0121235   -0.093911
  0.0521874     0.280199      0.0626669    0.104718    -0.0647063    0.170315    -0.067224    -0.0180953   0.0325948   0.11927      0.019376    -0.0132191   -0.146272    -0.207533    -0.063002     0.0575306   -0.116422      0.0736698    0.052881    -0.0594223   0.0441939     0.0197866     0.0555567    0.0286546    0.0333354   -0.268143
 -0.000577399   0.000376261   0.199043     0.0176149    0.13887      0.0712863    0.00634662  -0.0552619  -0.059172    0.174472    -0.0327252    0.110686     0.103942     0.166413     0.0295423    0.0409814    0.150439      0.279877    -0.0607944   -0.0911747  -0.0467578    -0.164777      0.016142    -0.152144    -0.160212     0.224887
 -0.148609      0.0793031    -0.042428    -0.12715      0.0967489   -0.048397    -0.0277234    0.05665    -0.0754139   0.0428955    0.102224    -0.0771459   -0.0354229    0.122643    -0.0465275   -0.00180577  -0.0960771    -0.129502    -0.154119    -0.13224     0.00171152   -0.1174        0.101422     0.132283    -0.00923856   0.103334
  0.0548497     0.116227      0.0239263   -0.00756352  -0.0278421    0.132357     0.215421     0.0307796  -0.0132126   0.0266633   -0.0877491    0.145295    -0.0545193    0.129511     0.13591      0.0843118   -0.0104827     0.0779745    0.128289     0.155495   -0.0875843    -0.0950208    -0.0484607    0.0688502   -0.131542    -0.000169905
  0.000846409   0.125586      0.145733    -0.0331398    0.05864      0.0503251    0.146465    -0.142625    0.0990057  -0.00648743   0.13376     -0.0205951   -0.0304721   -0.0690639    0.126672    -0.0189057    0.173592      0.0339078    0.160235     0.0762893  -0.0467535     0.203243     -0.0879131    0.0229787   -0.0129472   -0.0475384
  0.0113863    -0.117188      0.0230193    0.0358887    0.133254    -0.0498615   -0.0516858   -0.0401936   0.0632137   0.10124     -0.196922     0.0576332   -0.00655846   0.117888    -0.187471     0.0154774    0.0416285     0.203163     0.110612     0.278911    0.160797     -0.0664427    -0.0136189    0.21539      0.078436    -0.0885614
  0.119551      0.085023      0.0215843    0.13099     -0.0608772   -0.122273    -0.121921    -0.139795   -0.155948   -0.053357    -0.0447046   -0.0885947   -0.277063    -0.00396663   0.0104727    0.122094     0.0123541    -0.0118248   -0.134879     0.0154475  -0.0122213     0.0519387     0.0357309   -0.0879104   -0.0349497    0.129069
 -0.117354      0.201563     -0.0512417    0.0770952   -0.177214     0.0110552   -0.132137    -0.0383699  -0.125751   -0.168625     0.0117111   -0.0139779   -0.0829864    0.142578    -0.0232268   -0.0725304    0.052215      0.0685458    0.0818329    0.122861   -0.00824047   -0.0510992     0.172632    -0.106645    -0.061039     0.0274114
 -0.0394011     0.172655      0.00444452  -0.18992      0.0131576   -0.0600127    0.0615857    0.0661531   0.119195   -0.0528043    0.0236205   -0.0298019    0.0643819    0.209623     0.178295     0.0336903    0.0789785     0.0158761    0.15165     -0.0434749   0.00104509   -0.00656862   -0.0866525   -0.0170736    0.0519251    0.0039638
  0.265561     -0.027731     -0.0356849    0.0969329   -0.0928696    0.136881    -0.0742857    0.0534954  -0.139143   -0.00531939  -0.0536731    0.0444353    0.156184    -0.208282     0.00685754  -0.0103359    0.0248493    -0.0505553    0.0298643    0.131716    0.196998     -0.0295501     0.0839175   -0.0444832    0.104268    -0.0514244
  0.0252632    -0.0209308    -0.0856581   -0.0449557    0.183914     0.0906766   -0.100704    -0.0837337  -0.0101253   0.00212776   0.0966066    0.0417369    0.0257151    0.119737     0.00282138  -0.117982    -0.057897      0.015883     0.211099     0.0856043   0.0335935    -0.142492      0.133567     0.00948687  -0.00755009   0.0347625
  0.220896      0.134324      0.0384917    0.0562176   -0.208447    -0.0350099   -0.0148595   -0.0206981  -0.173294   -0.0526012    0.0933348    0.15637      0.184091     0.0262002   -0.0424472    0.0483306    0.0627824    -0.087151     0.167352    -0.0319522  -0.0970531     0.0817067     0.158815    -0.0252234   -0.0291831   -0.0297266
  0.0361607     0.0536908    -0.0582728   -0.032952    -0.187083     0.0505482    0.109253    -0.122313   -0.096964    0.046223    -0.0828679   -0.0991996   -0.109256    -0.0433347    0.076278    -0.104628    -0.181658      0.135071    -0.0910574   -0.0726835  -0.00764489   -0.118477      0.0932934    0.144155    -0.196601     0.247541
  0.0426662     0.209328      0.166037     0.173732     0.0817973   -0.0196081   -0.0536098    0.0643467  -0.0103474  -0.00139183   0.115942     0.0357899    0.127076    -0.123261     0.0362882    0.0055405   -0.072605      0.00202282  -0.0776483    0.094708    0.000902752  -0.0258665     0.00701734   0.275451    -0.0331231    0.0178978
 -0.16426      -0.0598764    -0.0593862    0.00918412  -0.0856288    0.128554    -0.0181834   -0.0837789   0.0962016   0.0336436    0.223109    -0.0446822    0.0214861    0.0365576   -0.0156862   -0.167269    -0.0506425     0.135739     0.0574356   -0.172183    0.0209058    -0.0541306    -0.0415611    0.0321854   -0.067781    -0.102311
 -0.0115568    -0.0807096     0.147181     0.0409529    0.147952    -0.0714167   -0.0120417   -0.0382505  -0.0807268   0.0636576    0.0201232    0.136423     0.0605723   -0.102998    -0.0973651   -0.117273     0.0637237    -0.0347031    0.0848608    0.0242496  -0.0127171     0.0678847     0.0132548   -0.0571792   -0.103806     0.125188
 -0.0814638     0.0933067    -0.0107471   -0.0514214   -0.102746    -0.0323759   -0.0753478    0.0546038   0.0375424   0.0615849    0.261921    -0.101521    -0.0991504    0.0346376    0.0882883   -0.0240484    0.0146866     0.0710203    0.130245     0.0487566   0.0950858    -0.0267782    -0.155131     0.127463     0.122549    -0.0914022
 -0.0149965    -0.069563     -0.162303    -0.0871709   -0.118501    -0.0220421    0.120567     0.0854859  -0.0134542  -0.0804508   -0.00262751  -0.0552024   -0.0881189   -0.052349     0.125336     0.316683    -0.130157     -0.0587779    0.0198849   -0.130924   -0.00471204   -0.199787     -0.0225354    0.156253     0.0108793   -0.147616
 -0.0395493     0.0246129    -0.134162     0.0246252    0.058505     0.0377551   -0.00165615   0.02897     0.0293198  -0.198423    -0.169296     0.0666721    0.0813469    0.14234     -0.0585522   -0.0466739    0.000122467  -0.216907    -0.0707399   -0.04319     0.0727889    -0.118512     -0.0243447   -0.0332934   -0.0573947   -0.0534974kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4069745376665197
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407054
[ Info: iteration 2, average log likelihood -1.406982
[ Info: iteration 3, average log likelihood -1.406272
[ Info: iteration 4, average log likelihood -1.397738
[ Info: iteration 5, average log likelihood -1.377533
[ Info: iteration 6, average log likelihood -1.369207
[ Info: iteration 7, average log likelihood -1.366322
[ Info: iteration 8, average log likelihood -1.364337
[ Info: iteration 9, average log likelihood -1.362977
[ Info: iteration 10, average log likelihood -1.361992
[ Info: iteration 11, average log likelihood -1.361354
[ Info: iteration 12, average log likelihood -1.361017
[ Info: iteration 13, average log likelihood -1.360843
[ Info: iteration 14, average log likelihood -1.360745
[ Info: iteration 15, average log likelihood -1.360682
[ Info: iteration 16, average log likelihood -1.360640
[ Info: iteration 17, average log likelihood -1.360611
[ Info: iteration 18, average log likelihood -1.360591
[ Info: iteration 19, average log likelihood -1.360577
[ Info: iteration 20, average log likelihood -1.360567
[ Info: iteration 21, average log likelihood -1.360560
[ Info: iteration 22, average log likelihood -1.360555
[ Info: iteration 23, average log likelihood -1.360552
[ Info: iteration 24, average log likelihood -1.360549
[ Info: iteration 25, average log likelihood -1.360548
[ Info: iteration 26, average log likelihood -1.360546
[ Info: iteration 27, average log likelihood -1.360545
[ Info: iteration 28, average log likelihood -1.360544
[ Info: iteration 29, average log likelihood -1.360544
[ Info: iteration 30, average log likelihood -1.360543
[ Info: iteration 31, average log likelihood -1.360543
[ Info: iteration 32, average log likelihood -1.360543
[ Info: iteration 33, average log likelihood -1.360543
[ Info: iteration 34, average log likelihood -1.360543
[ Info: iteration 35, average log likelihood -1.360542
[ Info: iteration 36, average log likelihood -1.360542
[ Info: iteration 37, average log likelihood -1.360542
[ Info: iteration 38, average log likelihood -1.360542
[ Info: iteration 39, average log likelihood -1.360542
[ Info: iteration 40, average log likelihood -1.360542
[ Info: iteration 41, average log likelihood -1.360542
[ Info: iteration 42, average log likelihood -1.360542
[ Info: iteration 43, average log likelihood -1.360542
[ Info: iteration 44, average log likelihood -1.360542
[ Info: iteration 45, average log likelihood -1.360542
[ Info: iteration 46, average log likelihood -1.360542
[ Info: iteration 47, average log likelihood -1.360542
[ Info: iteration 48, average log likelihood -1.360542
[ Info: iteration 49, average log likelihood -1.360542
[ Info: iteration 50, average log likelihood -1.360542
┌ Info: EM with 100000 data points 50 iterations avll -1.360542
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4070539552123849
│     -1.406981816689151
│      ⋮
└     -1.3605421841749732
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.360691
[ Info: iteration 2, average log likelihood -1.360548
[ Info: iteration 3, average log likelihood -1.359473
[ Info: iteration 4, average log likelihood -1.349086
[ Info: iteration 5, average log likelihood -1.327603
[ Info: iteration 6, average log likelihood -1.315314
[ Info: iteration 7, average log likelihood -1.309500
[ Info: iteration 8, average log likelihood -1.306217
[ Info: iteration 9, average log likelihood -1.304957
[ Info: iteration 10, average log likelihood -1.304562
[ Info: iteration 11, average log likelihood -1.304424
[ Info: iteration 12, average log likelihood -1.304367
[ Info: iteration 13, average log likelihood -1.304338
[ Info: iteration 14, average log likelihood -1.304322
[ Info: iteration 15, average log likelihood -1.304310
[ Info: iteration 16, average log likelihood -1.304301
[ Info: iteration 17, average log likelihood -1.304292
[ Info: iteration 18, average log likelihood -1.304285
[ Info: iteration 19, average log likelihood -1.304277
[ Info: iteration 20, average log likelihood -1.304270
[ Info: iteration 21, average log likelihood -1.304263
[ Info: iteration 22, average log likelihood -1.304255
[ Info: iteration 23, average log likelihood -1.304248
[ Info: iteration 24, average log likelihood -1.304241
[ Info: iteration 25, average log likelihood -1.304234
[ Info: iteration 26, average log likelihood -1.304227
[ Info: iteration 27, average log likelihood -1.304221
[ Info: iteration 28, average log likelihood -1.304214
[ Info: iteration 29, average log likelihood -1.304207
[ Info: iteration 30, average log likelihood -1.304201
[ Info: iteration 31, average log likelihood -1.304195
[ Info: iteration 32, average log likelihood -1.304189
[ Info: iteration 33, average log likelihood -1.304183
[ Info: iteration 34, average log likelihood -1.304177
[ Info: iteration 35, average log likelihood -1.304171
[ Info: iteration 36, average log likelihood -1.304166
[ Info: iteration 37, average log likelihood -1.304161
[ Info: iteration 38, average log likelihood -1.304156
[ Info: iteration 39, average log likelihood -1.304151
[ Info: iteration 40, average log likelihood -1.304147
[ Info: iteration 41, average log likelihood -1.304142
[ Info: iteration 42, average log likelihood -1.304138
[ Info: iteration 43, average log likelihood -1.304134
[ Info: iteration 44, average log likelihood -1.304131
[ Info: iteration 45, average log likelihood -1.304127
[ Info: iteration 46, average log likelihood -1.304123
[ Info: iteration 47, average log likelihood -1.304120
[ Info: iteration 48, average log likelihood -1.304117
[ Info: iteration 49, average log likelihood -1.304114
[ Info: iteration 50, average log likelihood -1.304110
┌ Info: EM with 100000 data points 50 iterations avll -1.304110
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3606907384610607
│     -1.360547859836047
│      ⋮
└     -1.304110378084814
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.304330
[ Info: iteration 2, average log likelihood -1.304084
[ Info: iteration 3, average log likelihood -1.302776
[ Info: iteration 4, average log likelihood -1.291148
[ Info: iteration 5, average log likelihood -1.264942
[ Info: iteration 6, average log likelihood -1.248793
[ Info: iteration 7, average log likelihood -1.242256
[ Info: iteration 8, average log likelihood -1.239103
[ Info: iteration 9, average log likelihood -1.237724
[ Info: iteration 10, average log likelihood -1.236972
[ Info: iteration 11, average log likelihood -1.236207
[ Info: iteration 12, average log likelihood -1.235157
[ Info: iteration 13, average log likelihood -1.233853
[ Info: iteration 14, average log likelihood -1.233022
[ Info: iteration 15, average log likelihood -1.232645
[ Info: iteration 16, average log likelihood -1.232352
[ Info: iteration 17, average log likelihood -1.232102
[ Info: iteration 18, average log likelihood -1.231893
[ Info: iteration 19, average log likelihood -1.231712
[ Info: iteration 20, average log likelihood -1.231546
[ Info: iteration 21, average log likelihood -1.231383
[ Info: iteration 22, average log likelihood -1.231213
[ Info: iteration 23, average log likelihood -1.231031
[ Info: iteration 24, average log likelihood -1.230845
[ Info: iteration 25, average log likelihood -1.230673
[ Info: iteration 26, average log likelihood -1.230532
[ Info: iteration 27, average log likelihood -1.230426
[ Info: iteration 28, average log likelihood -1.230345
[ Info: iteration 29, average log likelihood -1.230281
[ Info: iteration 30, average log likelihood -1.230227
[ Info: iteration 31, average log likelihood -1.230178
[ Info: iteration 32, average log likelihood -1.230132
[ Info: iteration 33, average log likelihood -1.230085
[ Info: iteration 34, average log likelihood -1.230037
[ Info: iteration 35, average log likelihood -1.229987
[ Info: iteration 36, average log likelihood -1.229934
[ Info: iteration 37, average log likelihood -1.229873
[ Info: iteration 38, average log likelihood -1.229795
[ Info: iteration 39, average log likelihood -1.229681
[ Info: iteration 40, average log likelihood -1.229495
[ Info: iteration 41, average log likelihood -1.229184
[ Info: iteration 42, average log likelihood -1.228714
[ Info: iteration 43, average log likelihood -1.228153
[ Info: iteration 44, average log likelihood -1.227685
[ Info: iteration 45, average log likelihood -1.227380
[ Info: iteration 46, average log likelihood -1.227150
[ Info: iteration 47, average log likelihood -1.226896
[ Info: iteration 48, average log likelihood -1.226566
[ Info: iteration 49, average log likelihood -1.226128
[ Info: iteration 50, average log likelihood -1.225621
┌ Info: EM with 100000 data points 50 iterations avll -1.225621
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3043299293865616
│     -1.3040836446021709
│      ⋮
└     -1.2256214355801565
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.225435
[ Info: iteration 2, average log likelihood -1.224733
[ Info: iteration 3, average log likelihood -1.223056
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.204276
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.170630
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.149001
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.152623
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.139010
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.133141
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.146216
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.139763
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.134359
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.148928
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.136537
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.141298
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.126276
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.141712
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.135104
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.141908
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.126369
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.147385
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.125423
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.138203
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.142145
[ Info: iteration 25, average log likelihood -1.143082
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      9
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.119073
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.151635
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.134442
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.135239
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.128197
[ Info: iteration 31, average log likelihood -1.158811
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.127182
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.137371
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.122257
[ Info: iteration 35, average log likelihood -1.152717
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.114944
[ Info: iteration 37, average log likelihood -1.145995
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.116980
[ Info: iteration 39, average log likelihood -1.155319
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.124735
[ Info: iteration 41, average log likelihood -1.143421
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.114226
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.149521
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.134097
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.138924
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.127414
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.147713
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.131190
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.136735
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.128323
┌ Info: EM with 100000 data points 50 iterations avll -1.128323
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2254353644915679
│     -1.2247329634874922
│      ⋮
└     -1.1283227919158636
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.147048
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.116500
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.124084
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.093327
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      9
│     10
│     23
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.067881
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     12
│     17
│     18
│     19
│     20
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.037865
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      4
│      7
│      8
│      9
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.027160
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│     12
│     18
│     19
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.048461
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      9
│     10
│     23
│     24
│     25
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.039799
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     12
│     18
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.020722
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      4
│      6
│      9
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.023572
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.064110
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      4
│      7
│      8
│      9
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.033044
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     12
│     18
│     19
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.056280
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      6
│      9
│     10
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.015283
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      4
│      7
│      8
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.034317
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     10
│     19
│     20
│      ⋮
│     26
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.041304
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     12
│     18
│     19
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.024645
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      6
│      7
│      8
│      9
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.003198
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     12
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.043406
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      4
│      7
│      8
│      ⋮
│     28
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -0.998646
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│     12
│     18
│     19
│     20
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.033920
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      7
│      9
│     19
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.020021
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     10
│     12
│     18
│     19
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.024855
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      9
│     18
│     19
│      ⋮
│     26
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.011118
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      4
│      6
│      7
│      ⋮
│     26
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.013414
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      8
│      9
│     18
│     19
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.023008
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│     10
│     12
│     18
│     19
│     20
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.021438
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      7
│      9
│     19
│      ⋮
│     28
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.021587
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│      8
│     10
│     12
│      ⋮
│     20
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.017138
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      9
│     18
│     19
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.025628
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      8
│     10
│     12
│     19
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.034466
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      4
│      7
│      9
│      ⋮
│     26
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.008091
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│      8
│     10
│     12
│      ⋮
│     20
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.025920
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      9
│     19
│     20
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.014699
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      7
│      8
│     10
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.009268
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│      9
│     19
│     20
│      ⋮
│     26
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.025235
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     12
│     18
│     19
│     20
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.015222
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      4
│      7
│      8
│      9
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -0.995703
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      4
│      6
│     12
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.031998
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      7
│      8
│      9
│     10
│      ⋮
│     26
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.010655
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│     12
│     18
│     19
│     20
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.022033
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      4
│      7
│      8
│      9
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.008961
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     12
│     18
│     19
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.016552
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      4
│      6
│      7
│      ⋮
│     26
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.004229
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     12
│     19
│     20
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.037061
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      4
│      7
│      8
│      9
│      ⋮
│     28
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -0.984765
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.044963
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      7
│      8
│      9
│      ⋮
│     26
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -0.992988
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      4
│      6
│     12
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -0.999534
┌ Info: EM with 100000 data points 50 iterations avll -0.999534
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1470480228034872
│     -1.1164998241324031
│      ⋮
└     -0.9995344597896496
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4069745376665197
│     -1.4070539552123849
│     -1.406981816689151
│     -1.4062718309592928
│      ⋮
│     -1.04496344401621
│     -0.9929879050153447
└     -0.9995344597896496
32×26 Array{Float64,2}:
 -0.00533125  -0.00502792   0.200757     0.00735668   0.136919      0.0686126   0.0037386   -0.0538396  -0.0424219    0.175626    -0.0389727    0.118945      0.0936789    0.175847     0.00576843    0.0508752    0.150202     0.233119    -0.0619737   -0.0453593  -0.068888    -0.156124    -0.00327812  -0.140928    -0.180415     0.225707
  0.0245823   -0.0511785    0.0292967    0.0556581   -0.000539793   0.083378   -0.0410285   -0.128646    0.0396789    0.0353038    0.0407306    0.110353     -0.0165317   -0.18169     -0.0417827     0.107108    -0.054985    -0.0440283    0.0548867   -0.10651    -0.0190792   -0.107477     0.0525605   -0.0944732   -0.0927678    0.155268
  0.0560371   -0.0454137    0.0318649   -0.069254    -0.144181      0.0753437  -0.00983233   0.0494105   0.209236     0.0759821    0.169758    -0.0846573     0.13622     -0.0248163    0.0364523     0.0741272    0.0279643    0.149316     0.0893252   -0.0435926  -0.215291    -0.0198338   -0.111307     0.0101518   -0.00232106   0.018977
  0.00730109  -0.115286     0.0199398    0.0254865    0.125035     -0.0907467  -0.0519824   -0.0329919   0.068059     0.101235    -0.199205     0.0440531    -0.00841946   0.0491378   -0.164513      0.0156632    0.0381681    0.202227     0.113098     0.277559    0.110811    -0.0694548   -0.0142062    0.215831     0.0752871   -0.0886512
 -0.0216338    0.124703    -0.0680964    0.0158098   -0.181575      0.0446279   0.0116513   -0.106382   -0.129231    -0.0526317   -0.0449351   -0.0604737    -0.129726     0.0530746    0.0195099    -0.0880356   -0.0487041    0.0961596   -0.0141589    0.0213225  -0.0220289   -0.0867112    0.136692     0.0122129   -0.109973     0.136064
 -0.0471613    0.0862509    0.00265219  -0.0444806   -0.10152      -0.0342452  -0.0354573    0.0655995   0.0422015    0.0775508    0.289506    -0.0798069    -0.0818194    0.0443451    0.0876925    -0.0271089    0.0433444    0.0610525    0.130023     0.0586638   0.0853783   -0.0227995   -0.159992     0.125043     0.132641    -0.0919865
 -0.149697     0.309382     0.205384    -0.069261    -0.0915381     0.135038   -0.0392204   -0.0420156   0.046183     0.0314824    0.22089      0.116428     -0.60179      0.135976    -0.0516707    -0.186582    -0.751656     0.131405     0.20588     -0.14114    -0.0456184   -0.0588233    0.037253     0.0288084   -0.0587212   -0.117473
 -0.146605    -0.30155     -0.0761027    0.0459272   -0.087723      0.105101    0.00561704  -0.111418    0.0544959    0.0241388    0.219881    -0.175685      0.378588    -0.011412    -0.0179082    -0.152368     0.31162      0.1453      -0.0317869   -0.18981     0.0444444   -0.0508137   -0.0234035    0.0285594   -0.0652237   -0.116408
 -0.0370974   -0.0773219   -0.141448    -0.0809436   -0.167969     -0.0109191   0.0782618    0.081998   -0.0198479   -0.0810608   -0.0076466   -0.0714596    -0.0763666   -0.0537899    0.12244       0.311555    -0.129334    -0.0496958    0.0260925   -0.129521    0.00849413  -0.187812    -0.0287508    0.145365     0.0591771   -0.148858
 -0.0973478    0.121494    -0.0494735   -0.0132955   -0.0189786    -0.115854    0.15874      0.22692     0.141879    -0.126607     0.146656     0.0056942    -0.121348     0.0424374   -0.0332        0.0546436   -0.196452     0.0386307   -0.0265469    0.122612   -0.232956    -0.0116866   -0.0600674   -0.109044     0.029502    -0.215087
  0.0134239   -0.119948    -0.0326298   -0.150959    -0.179741      0.0207493   0.0362721   -0.142293   -0.0426175    0.111368    -0.197906    -0.0423036     0.098043    -0.0313282    0.0173051    -0.15087     -0.108084     0.0549844   -0.09809     -0.0665544  -0.176296     0.0386639    0.103222    -0.0779527   -0.030598    -0.0695842
  0.218657     0.13163      0.0396592    0.0549696   -0.211796     -0.0351095  -0.0211016   -0.0208187  -0.178175    -0.069263     0.0981579    0.159809      0.17993      0.0282854   -0.0457093     0.0482447    0.0606282   -0.0798315    0.153908    -0.0329407  -0.0968497    0.0790419    0.132668     0.00436694  -0.0306205   -0.0315505
  0.00339058   0.124832     0.0809425   -0.0380928    0.0646761     0.0508085   0.145346    -0.108803    0.100043    -0.0056729    0.129424     0.00756962   -0.036858    -0.0734142    0.112752     -0.0208297    0.107376     0.0485739    0.139997     0.0869636  -0.0480592    0.201441    -0.104852     0.021252    -0.00975001  -0.0348351
  0.0116025    0.0658943   -0.0555036    0.0431591    0.0153566     0.0877315   0.0568782    0.0521354   0.019392    -0.0916246   -0.126495     0.111631      0.0180336    0.138426     0.0225944     0.0241224   -0.0117713   -0.0700158    0.033726     0.0531467  -0.0124302   -0.116061    -0.0345333    0.0157323   -0.0805217   -0.032388
  0.122647     0.0884699    0.019676     0.132717    -0.065599     -0.122484   -0.121734    -0.117865   -0.155363    -0.0540556   -0.0513859   -0.0863011    -0.277185    -0.00378491   0.00950826    0.108664     0.00624832  -0.0613568   -0.105758     0.0185198  -0.0152187    0.0690931    0.0604566   -0.0903681   -0.0400562    0.18707
 -0.0238088   -0.0191363    0.0748485   -0.074404    -0.0563311    -0.0833127  -0.00921      0.0698477   0.0899922    0.0235605    0.00318682   0.0132507     0.0283835   -0.0136946   -0.0823041     0.106185     0.151595     0.0518559   -0.0797835    0.233315   -0.110646     0.0835309   -0.0926767    0.0813299    0.129467    -0.0595249
 -0.115927     0.0852895   -0.0170235   -0.12568      0.0960343    -0.041802   -0.014191     0.047236   -0.056579     0.0390939    0.101074    -0.0785113    -0.0563278    0.121529    -0.0436871    -0.00242896  -0.0988137   -0.138458    -0.137369    -0.159199   -0.0477111   -0.105567     0.108034     0.134291    -0.0426134    0.0884325
 -0.0111712   -0.21323      0.147605     0.0814062    0.172849     -0.0742326  -0.0120816   -0.0575743  -0.0827096    0.0646808    0.0174843    0.135522      0.0620992   -0.103691    -0.101509     -0.119783     0.0657685   -0.0366509    0.124004    -0.0102429  -0.0116867    0.0659616    0.0133877   -0.0772963   -0.0997411    0.151824
 -0.0502783   -0.113687     0.0519038   -0.179303    -0.102964      0.0497102   0.178066    -0.0584994   0.0583519   -0.171534    -0.00881291  -0.0483181    -0.0297305    0.0662446   -0.180184      0.0283868   -0.0819074    0.194378     0.0339361    0.0715269   0.918091     0.477896    -0.111346    -0.0734934    0.0275414    0.0531129
 -0.0929281   -0.105185    -0.124472    -0.0947716   -0.01278       0.0416828   0.178167    -0.0557671  -0.03156     -0.16329      0.0546174   -0.0501236    -0.0301998    0.0656564   -0.17542       0.18882     -0.0700947    0.161615     0.00888909   0.0396032  -0.905178    -0.595508     0.0302061   -0.0506375    0.0281655    0.0251999
  0.0232809    0.129258     0.00624031   0.0727695   -0.041224      0.138978   -0.0769192   -0.0619842  -0.0176538    0.130863    -0.0514342   -0.000715498  -0.129355    -0.105554    -0.0623743    -0.0691436    0.0816102    0.0495112   -0.0254505    0.0994401  -0.029189     0.0521726    0.117802     0.0884085   -0.028951    -0.139917
 -0.0127323    0.0770953   -0.101905    -0.107698     0.0504629    -0.0241134  -0.0111133    0.0707491  -0.171858    -0.0307035    0.0395146    0.0727796    -0.0497263   -0.32133     -0.000196648  -0.0103839   -0.00134477  -0.177803    -0.101805     0.100577    0.0280827   -0.0266695    0.150691     0.112731    -0.0114091   -0.121299
 -0.0371062    0.165575     0.0113628   -0.201401     0.0554846    -0.0270231   0.0883462    0.0668098   0.0642318   -1.01899      0.0200212    0.0171702     0.0798782    0.222902     0.175855      0.118996     0.0740988    0.0174971    0.149557    -0.0266679  -0.0456071   -0.00800528  -0.146014    -0.0184172    0.0340687    0.000342285
 -0.0379942    0.192933     0.0197019   -0.103375    -0.0552054    -0.0609554   0.0262683    0.0606002   0.175737     1.51532      0.0201322   -0.0859561     0.0592346    0.189559     0.190731     -0.124032     0.0744204    0.0181764    0.149204    -0.061845    0.023072    -0.007659    -0.0773677   -0.0176832    0.0280455    0.00081074
  0.0393015    0.203626     0.15017      0.170459     0.106575     -0.0224523  -0.0499768    0.0567809  -0.0109427    0.0070762    0.149856     0.0390156     0.121479    -0.116905    -0.00510872    0.00439805  -0.0785578    0.00399624  -0.0724958    0.114007   -0.00407966  -0.0298918   -0.01742      0.278826    -0.0324373    0.0156446
  0.254885    -0.0280852   -0.0382234    0.0887641   -0.0929189     0.145414   -0.0941075    0.0522246  -0.143699     0.00612544  -0.125151     0.0442609     0.170573    -0.200589    -0.0691866    -0.0136048    0.0233838   -0.0521929    0.0431297    0.127252    0.184979     0.0176642    0.0819303   -0.0477869    0.0976633   -0.0510896
 -0.109763     0.0800071   -0.159603     0.108543     0.0105337     0.0122761  -0.0564075    0.0423403  -0.00983251   0.0589301   -0.0530653   -0.0747047     4.3779e-5   -0.0307903    0.0423279     0.092389    -0.1058       0.0544616    0.0398501    0.092867   -0.0181526    0.0640457    0.0626638    0.0576674   -0.281168     0.204002
 -0.212307     0.0658326   -0.233205    -0.0414532   -0.0942334    -0.0305079   0.0178893    0.0756357  -0.153914    -0.0913942    0.027298     0.0448162     0.0655816    0.0591497    0.0191811     0.00335886   0.024969     0.203891     0.158868     0.188202   -0.208415     0.0613647   -0.125188    -0.0116581   -0.0687214   -0.122697
 -0.130541    -0.037349    -0.0668657   -0.031986     0.28157      -0.116906    0.149843     0.0409412  -0.107855    -0.0139433    0.0193376   -0.0642048    -0.0171032   -0.0406878    0.0714478    -0.0516076    0.0930322   -0.12378     -0.0150576   -0.0431072   0.123996    -0.0343476    0.0645647    0.011018    -0.155414    -0.126662
 -0.00670939   0.0420928   -0.055639    -0.218349     0.0117269    -0.0276309   0.0354434    0.326322   -0.130683    -0.0230835   -0.103578    -0.0869576     0.0592679   -0.0513978    0.0511668    -0.132375    -0.0791423    0.0387838   -0.0583514   -0.0823146   0.0400107   -0.0885127    0.153951     0.0458161   -0.326808    -0.08961
 -0.055263    -0.0975225    0.0271656   -0.0506937    0.0340871     0.0820798  -0.081606     0.0892875  -0.0799519   -0.0504762    0.01778     -0.0303354     0.102951     0.0226354    0.0230075    -0.0885963   -0.021754     0.018019     0.107714     0.131474    0.00310177   0.0149786    0.136778    -0.00668968  -0.0657374    0.0212644
  0.16078     -0.0262108    0.113776     0.0366966   -0.00542402    0.122535    0.144711    -0.0825538  -0.105813     0.135662     0.00136199  -0.00969795   -0.0766466    0.0332836    0.115678      0.0766753    0.00401255  -0.00894908   0.137495     0.121834   -0.05357      0.0245028   -0.0247404   -0.0705993   -0.0129701   -0.0190867[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│      9
│     10
│      ⋮
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.036231
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      4
│      7
│      8
│      9
│      ⋮
│     26
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.998935
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      4
│      7
│      8
│      9
│      ⋮
│     28
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.995281
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      7
│      8
│      9
│      ⋮
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.008277
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      4
│      6
│      7
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.994293
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      7
│      8
│      9
│     10
│      ⋮
│     28
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.997292
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      7
│      8
│      9
│      ⋮
│     24
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.015723
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      4
│      7
│      8
│      9
│      ⋮
│     28
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.004990
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      4
│      7
│      8
│      9
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.997062
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      4
│      6
│      7
│      ⋮
│     24
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.988008
┌ Info: EM with 100000 data points 10 iterations avll -0.988008
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.589156e+05
      1       6.600950e+05      -1.988206e+05 |       32
      2       6.301131e+05      -2.998189e+04 |       32
      3       6.170822e+05      -1.303091e+04 |       32
      4       6.094925e+05      -7.589618e+03 |       32
      5       6.046047e+05      -4.887881e+03 |       32
      6       6.010963e+05      -3.508358e+03 |       32
      7       5.991880e+05      -1.908277e+03 |       32
      8       5.982933e+05      -8.947377e+02 |       32
      9       5.975642e+05      -7.291387e+02 |       32
     10       5.967046e+05      -8.595074e+02 |       32
     11       5.956602e+05      -1.044401e+03 |       32
     12       5.946841e+05      -9.761015e+02 |       32
     13       5.939379e+05      -7.462795e+02 |       32
     14       5.932192e+05      -7.186598e+02 |       32
     15       5.925205e+05      -6.986812e+02 |       32
     16       5.915166e+05      -1.003883e+03 |       32
     17       5.901542e+05      -1.362470e+03 |       32
     18       5.891714e+05      -9.827417e+02 |       32
     19       5.888167e+05      -3.547344e+02 |       32
     20       5.886928e+05      -1.239102e+02 |       32
     21       5.886516e+05      -4.120526e+01 |       29
     22       5.886314e+05      -2.015635e+01 |       31
     23       5.886199e+05      -1.148063e+01 |       28
     24       5.886135e+05      -6.457915e+00 |       28
     25       5.886082e+05      -5.281165e+00 |       27
     26       5.886061e+05      -2.133184e+00 |       16
     27       5.886053e+05      -8.098443e-01 |       13
     28       5.886043e+05      -9.154975e-01 |       12
     29       5.886034e+05      -9.507420e-01 |       17
     30       5.886026e+05      -7.982990e-01 |       10
     31       5.886023e+05      -3.382726e-01 |        9
     32       5.886020e+05      -2.155493e-01 |        4
     33       5.886020e+05      -7.445289e-02 |        0
     34       5.886020e+05       0.000000e+00 |        0
K-means converged with 34 iterations (objv = 588601.967254514)
┌ Info: K-means with 32000 data points using 34 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.279388
[ Info: iteration 2, average log likelihood -1.237787
[ Info: iteration 3, average log likelihood -1.201904
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.155488
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     16
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.111058
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     20
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.094285
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      8
│     13
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.061388
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     11
│     12
│     15
│     16
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.048602
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.082296
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     17
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.046451
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│      9
│     11
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.047247
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.064852
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     17
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.041323
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      9
│     11
│     16
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.047010
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.075118
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     12
│     13
│     17
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.004546
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     11
│     14
│     15
│      ⋮
│     20
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.020860
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      8
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.093181
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.070218
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     16
│     17
│     19
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.005789
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│      8
│      9
│     10
│      ⋮
│     22
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.008925
[ Info: iteration 22, average log likelihood -1.108529
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.031283
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     20
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.012426
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      8
│      9
│     11
│     13
│      ⋮
│     24
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.007044
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.094488
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.045727
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     11
│     13
│     16
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -0.984767
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      8
│     14
│     15
│     19
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.058277
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.063362
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     11
│     16
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.024537
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     13
│     19
│     22
│     24
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.005424
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      8
│     14
│     15
│     16
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.050070
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.076511
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     13
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.015407
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     16
│     17
│     19
│     22
│     24
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.018736
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      8
│     11
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.064661
[ Info: iteration 38, average log likelihood -1.052421
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     13
│     16
│     20
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -0.976904
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     17
│     19
│     22
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.026932
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      8
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.064294
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.043693
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -0.985197
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     19
│     21
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.055612
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      8
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.045045
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.048673
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -0.981652
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.082195
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      8
│     14
│     15
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.032906
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.038888
┌ Info: EM with 100000 data points 50 iterations avll -1.038888
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0564749    0.101862    0.019189     0.0346803   -0.0371468     0.137401    0.192892     0.0468806   -0.0135089    0.0164691  -0.0812578     0.145866     -0.0535229    0.117305      0.113899      0.0839724    -0.0232148     0.077927     0.13496     0.15096    -0.0877943   -0.0802281   -0.0391508    0.0588758   -0.116187    -0.0110355
  0.0561478   -0.0453934   0.0318801   -0.0663989   -0.134842      0.072827   -0.00943161   0.0488832    0.20287      0.0763968   0.170545     -0.0836476     0.136828    -0.0231        0.0346122     0.0695271     0.0289382     0.150634     0.0893892  -0.0378736  -0.213482    -0.0238701   -0.107696     0.00667332  -0.00577946   0.0249415
  0.0197719   -0.0402705   0.0279049    0.0531808    0.0147851     0.0844393  -0.0403005   -0.120229     0.0301002    0.0364524   0.0475455     0.105076     -0.014788    -0.151167     -0.0361031     0.101967     -0.0445621    -0.0276411    0.0533373  -0.103505   -0.0138516   -0.112405     0.0530983   -0.0889059   -0.106739     0.15705
 -0.0757316    0.184879   -0.0685852    0.076537    -0.177603      0.0135007  -0.128574    -0.0664503   -0.145118    -0.16716    -0.00383303   -0.0162936    -0.109097     0.141385     -0.0338654    -0.0730487     0.089642      0.0698147    0.0799342   0.125459   -0.0377657   -0.0560709    0.17448     -0.0972872   -0.0715807    0.0270414
  0.0344296    0.297279    0.0231726    0.0902474   -0.00243442    0.158411   -0.0699479   -0.045233     0.0141225    0.112532   -0.00504004   -0.00684554   -0.10375     -0.199144     -0.0877299     0.0678921    -0.10839       0.0980369    0.0539319  -0.0476847   0.0487135    0.0160155    0.0893444    0.0643124    0.0101139   -0.259899
 -0.0760173    0.0508847  -0.0690528    0.122166     0.0208286     0.0392134  -0.0518893    0.0462817   -0.0287905    0.0447218  -0.0821827    -0.0737434     0.0255756   -0.0439337     0.00611425    0.115604     -0.0986678     0.126394     0.0482619   0.113242   -0.00337782   0.0837873    0.0898561    0.0376443   -0.352483     0.206914
 -0.0265503   -0.0222585   0.0757911   -0.0652672   -0.0564286    -0.0747534  -0.0105281    0.0786801    0.0720922    0.0192081  -0.00183524    9.28818e-5    0.0377846   -0.0180639    -0.0777081     0.0877535     0.142305      0.0490173   -0.0740194   0.232646   -0.104062     0.0931242   -0.0760744    0.0713075    0.11447     -0.0587373
 -0.0899707    0.122119   -0.0347813   -0.00990728  -0.00262584   -0.117124    0.201644     0.163178     0.181483    -0.121532    0.192582      0.0180875    -0.126219     0.056402     -0.0320037     0.0653731    -0.107458      0.0473214   -0.0350054   0.214395   -0.378626    -0.0282856   -0.0697228   -0.0934594    0.0348073   -0.16014
 -0.0611967   -0.102805    0.0121413   -0.111191    -0.000905165   0.0253807   0.131011    -0.0520723    0.00360044  -0.110409    0.0180691    -0.0122344    -0.0169624    0.0254507    -0.16938       0.0577411    -0.0431454     0.130106     0.027917    0.0631457   0.0386763   -0.00275172  -0.0280711   -0.0688186    0.0042388    0.0710818
  0.151026    -0.0278966   0.11474      0.0229545   -0.00281422    0.119327    0.135906    -0.0795749   -0.102892     0.123969    0.0037846    -0.0111577    -0.0638008    0.027283      0.100191      0.0719388     0.000638175  -0.00897553   0.123213    0.122631   -0.052651     0.0340969   -0.0173538   -0.0659374   -0.0117349   -0.0176034
 -0.127636    -0.0343889  -0.0648253   -0.0335093    0.268604     -0.106124    0.140089     0.0442459   -0.112093    -0.0141857   0.0112265    -0.0684313    -0.0110189   -0.0393144     0.0695284    -0.0666877     0.0884214    -0.126627    -0.0137465  -0.0396932   0.112862    -0.0350756    0.0692342    0.0121364   -0.154306    -0.120967
  0.00738056  -0.113818   -0.0327212   -0.146916    -0.155945      0.0223249   0.0346529   -0.141499    -0.0435327    0.1084     -0.209176     -0.0379402     0.102497    -0.0256388     0.0159453    -0.148975     -0.104967      0.0554147   -0.0901981  -0.0609664  -0.17159      0.0363242    0.104797    -0.0731208   -0.0347641   -0.0667806
 -0.00141453  -0.284844    0.152974     0.13434      0.158514     -0.0874621  -0.0111521   -0.0629371   -0.100123     0.066214    0.0255558     0.15068       0.0813992   -0.104626     -0.0752154    -0.139064      0.0707182    -0.0425703    0.160285   -0.0669924  -0.00928504   0.0621079    0.0166414   -0.0630142   -0.114452     0.142772
 -0.0206047    0.0348361   0.201283    -0.00690143   0.134952      0.0410961   0.00123951   0.00116042  -0.0421114    0.152711   -0.0476973     0.15155       0.0543423    0.210011      0.00771886    0.0565976     0.0277396     0.210179    -0.0691634  -0.121358   -0.049722    -0.13089     -0.0189252   -0.134805    -0.184036     0.154605
 -0.00113359  -0.0071788  -0.0693504   -0.0441941    0.208395      0.0866922  -0.135797    -0.0438209   -0.00984473   0.0132616   0.155396      0.0511564     0.007991     0.114191      0.00381453   -0.0768318    -0.0295231     0.0264435    0.191819    0.0782845   0.0401211   -0.134951     0.114181    -0.0241616    0.0245449    0.118728
  0.0057899   -0.115522    0.0202235    0.0254289    0.125503     -0.0946024  -0.0512051   -0.0319098    0.0679499    0.101486   -0.198276      0.0456223    -0.00781812   0.0405577    -0.170893      0.0191401     0.0369926     0.203027     0.111128    0.288944    0.112004    -0.0666523   -0.0141864    0.220087     0.0776712   -0.0937558
 -0.0416804    0.161402    0.0210202   -0.157128     0.00780234   -0.0381663   0.0624085    0.0646324    0.0985522   -0.0657745   0.0211296    -0.0202587     0.0731975    0.20917       0.172462      0.0282407     0.0674428     0.0177948    0.141765   -0.0361914  -0.0277158   -0.00848266  -0.115728    -0.0171123    0.0312389    0.000401053
 -0.00271591   0.119329    0.0634047   -0.0297515    0.0650893     0.0510584   0.130634    -0.0928912    0.0935962   -0.0140394   0.119546      0.00767917   -0.0359712   -0.0567573     0.10864      -0.0181771     0.0834787     0.0435602    0.128613    0.0894559  -0.0442873    0.185555    -0.0908134    0.0178877   -0.0163253   -0.0294399
  0.220046     0.133186    0.0395963    0.0564592   -0.217033     -0.0364088  -0.0201959   -0.0206543   -0.177104    -0.0701175   0.0949977     0.161272      0.181321     0.0269977    -0.0455779     0.0481255     0.06104      -0.0821335    0.154356   -0.0318296  -0.0974581    0.0794665    0.133909     0.00316877  -0.0289962   -0.0317468
 -0.154824    -0.0877816   0.029273     0.00275854  -0.0874285     0.117703   -0.00988025  -0.0853795    0.0528416    0.0301099   0.223136     -0.0807662     0.0339995    0.0388789    -0.0307514    -0.166246     -0.0721886     0.142658     0.0498987  -0.171888    0.0207127   -0.0549383   -0.00458116   0.0308519   -0.0603261   -0.118307
 -0.0543978   -0.176556    0.13209     -0.0416949   -0.0308092     0.0818445  -0.0535083    0.148427    -0.0989678   -0.029067   -0.103367     -0.049116      0.157027     0.000834806   0.033388     -0.0536736     0.0118814     0.0699473    0.0266877   0.173608   -0.00404873   0.115425     0.12209     -0.0326353   -0.1356       0.0644902
 -0.0459314   -0.0517145  -0.126643    -0.0692507   -0.159312     -0.0160165   0.0790093    0.0853604   -0.0133202   -0.0808333   0.000464327  -0.0713097    -0.0733253   -0.0501449     0.106939      0.264922     -0.128297     -0.036569     0.0218923  -0.157818    0.00997349  -0.172894    -0.0234796    0.104249     0.0660395   -0.174288
 -0.118602     0.0824453  -0.0151146   -0.127772     0.0944996    -0.0418344  -0.016521     0.0464817   -0.0578194    0.0366276   0.101221     -0.0779452    -0.0581754    0.122979     -0.0419748    -0.00461083   -0.0969985    -0.138105    -0.140361   -0.156436   -0.0536082   -0.105939     0.102282     0.133095    -0.0472211    0.0889526
 -0.0970948   -0.322828    0.0885182   -0.0671012   -0.131492      0.0532529  -0.0483748    0.657705    -0.120326    -0.118235   -0.0662589    -0.053403      0.144671    -0.0309005     0.0432766    -0.126797     -0.0230806     0.0294018    0.0225916   0.212311   -0.00460802   0.055507     0.246492     0.0238433   -0.0692347   -0.0503652
  0.122593     0.0890083   0.0196849    0.132535    -0.0656071    -0.122363   -0.121533    -0.117995    -0.155612    -0.0544635  -0.0512715    -0.0864173    -0.277207    -0.0039641     0.00911297    0.107929      0.00622075   -0.0616867   -0.105099    0.0188142  -0.0149821    0.0688065    0.0606057   -0.0903002   -0.0397759    0.185589
 -0.0015712   -0.0224368  -0.00731624   0.0493209   -0.067966      0.118002   -0.0808119   -0.0564391   -0.0524419    0.138019   -0.0820842     0.000134634  -0.118717     0.00211906   -0.0258582    -0.186281      0.248535      0.00132375  -0.0976674   0.239016   -0.0956292    0.0733346    0.140305     0.101549    -0.0699893   -0.0219794
  0.028528     0.0305585  -0.0423306   -0.0607081   -0.180999      0.0665828   0.137777    -0.12769     -0.102128     0.0640398  -0.0792751    -0.104615     -0.113441    -0.0400118     0.0729098    -0.098154     -0.170532      0.121974    -0.0935506  -0.0788253  -0.00591185  -0.113318     0.0993386    0.11594     -0.158957     0.243395
 -0.0481554    0.0829481   0.00104693  -0.0418094   -0.101914     -0.035159   -0.0384168    0.0700885    0.040173     0.078033    0.290891     -0.0840264    -0.0832801    0.0436436     0.0867206    -0.0254603     0.0413519     0.0607873    0.129009    0.0635096   0.0849628   -0.0225555   -0.156416     0.121397     0.132285    -0.0914205
  0.127836     0.0814383   0.0434706    0.126827     0.00996046    0.0621335  -0.0723037    0.0507816   -0.0783983    0.0086629   0.00459684    0.0388886     0.139475    -0.155379     -0.0204932    -0.000342067  -0.0326002    -0.0188638   -0.0152758   0.120577    0.09469     -0.00622043   0.0367634    0.0956387    0.0261066    0.000372924
 -0.178429     0.0665652  -0.231597    -0.00400595  -0.0790075    -0.0222563  -0.00340383   0.0695642   -0.110961    -0.0418912   0.00533865    0.0137821     0.0566561    0.0370284     0.016149      0.0270353     0.0119497     0.160455     0.13431     0.167069   -0.163054     0.0659535   -0.0763843    0.00606611  -0.146898    -0.0375885
 -0.0130023    0.0788369  -0.102336    -0.106483     0.0501555    -0.0235752  -0.0121298    0.0712679   -0.172683    -0.0319985   0.0402439     0.0697656    -0.0492171   -0.316242     -0.000936073  -0.00982434    0.000861418  -0.177594    -0.102013    0.100188    0.0300116   -0.0240168    0.151193     0.111062    -0.0109497   -0.116633
 -0.0384495    0.0262696  -0.131054     0.0496193    0.0680084     0.0394974  -0.0879387    0.0248605    0.0329296   -0.193415   -0.171266      0.0694951     0.11003      0.149518     -0.0677636    -0.0416074     0.00490456   -0.220726    -0.0614558  -0.0461127   0.060007    -0.163837    -0.0455056   -0.0290421   -0.0480447   -0.0524433[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     20
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -0.981817
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      6
│      8
│      9
│     10
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.933337
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     20
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.941129
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.950597
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      6
│      9
│     10
│     11
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.943848
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      8
│      9
│     10
│     11
│      ⋮
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.950184
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -0.941840
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      6
│      8
│      9
│     10
│      ⋮
│     24
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.924296
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      9
│     10
│     11
│     13
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.953267
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      6
│      8
│      9
│     10
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.919708
┌ Info: EM with 100000 data points 10 iterations avll -0.919708
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0803916   -0.0190734    -0.135461    -0.0711214   -0.0523381   -0.0795095     0.0249992   -0.000928806   0.232798     0.0428807   -0.0544901  -0.161954     0.0767979   0.12308     -0.00669708  -0.0799425    0.160558      0.0112023    0.0662578    0.102274     0.187706    -0.141166    -0.00599455   0.00469612   0.154804     0.0132154
  0.0702435    0.133905      0.0680069    0.0968066    0.101003    -0.0865041     0.143709     0.12287      -0.153284     0.101101     0.0379299   0.090052     0.0951927   0.164485     0.190318    -0.0410653    0.152352      0.0332925    0.0714765   -0.122944    -0.153239    -0.0276401    0.072492    -0.0247509   -0.099554     0.0894533
 -0.0118124   -0.0822647     0.0860988    0.0446561    0.0436842   -0.0918542     0.110311    -0.126101     -0.141963     0.0616694   -0.0384064  -0.113779    -0.0392656  -0.0633488    0.0300454    0.181093     0.0273844    -0.0684561    0.130776     0.0593918    0.0853677    0.23941      0.0482353    0.00340856   0.0564682    0.203235
  0.129665     0.113257     -0.0514942   -0.0902558   -0.0652967   -0.000633281   0.044165    -0.0721463     0.048271    -0.00952494  -0.148028   -0.00390387   0.0844609   0.147512    -0.0230222   -0.0315082   -0.000141165  -0.199283     0.157038    -0.0141288    0.109086    -0.0207985   -0.0817901    0.0797006   -0.0768451   -0.0801405
 -8.19793e-5  -0.0319346     0.0615683   -0.105495    -0.00893176  -0.150479     -0.0890111   -0.135574     -0.0515248   -0.0552698    0.0983638   0.167608    -0.014647    0.109675     0.116243    -0.112365     0.0141486    -0.18636     -0.0770844   -0.16086      0.0107111    0.0643798    0.0669527    0.0489286    0.0370619   -0.0378315
  0.0944693    0.00892495   -0.114448     0.158213     0.117847     0.127669      0.0684531    0.139184      0.0625786   -0.0235999   -0.0478171   0.0640559    0.088466   -0.0143242   -0.0578409   -0.123065    -0.0686806    -0.088081     0.0482389   -0.0436735    0.0300888   -0.00240875   0.114466    -0.0585949    0.0289744    0.0770658
 -0.00655363  -0.0761423    -0.183132     0.0157168   -0.0448904   -0.00599384   -0.115363    -0.0872435    -0.046242     0.0593174    0.145476   -0.0679804    0.0117589   0.0533006   -0.121562     0.124053     0.0232831    -0.091289     0.116259    -0.0531116    0.0156387   -0.0921737    0.078172     0.0229932   -0.00702039  -0.118815
 -0.110971    -0.127062     -0.0652211   -0.0364775   -0.0492665    0.0549944    -0.126393    -0.0695379    -0.016418    -0.0594674   -0.0365686   0.0937408    0.135336    0.0136175   -0.0928883   -0.0562859   -0.153909     -0.155785     0.198314     0.0709006   -0.180194     0.0367189    0.0455679    0.0170517   -0.0852268   -0.127155
 -0.0410702    0.199596     -0.112739    -0.0545412   -0.00130955  -0.0162727     0.00103992  -0.00796354   -0.109093    -0.196227    -0.0361034   0.0462448    0.0401171   0.114876     0.168181     0.0406554   -0.218541      0.064503     0.1085      -0.0830746   -0.0835764    0.00436301   0.105649     0.228402    -0.0168945    0.138839
  0.158389     0.141355      0.0271055    0.00379915  -0.0817786    0.110574     -0.061396     0.172322      0.0844348   -0.125571    -0.0761078  -0.11085      0.0376003  -0.0270362   -0.0526047   -0.13419      0.0619021    -0.00389207   0.0337293    0.0487054    0.00886229  -0.11078      0.0737668    0.00600985  -0.0721902    0.104522
  0.222442     0.0507561     0.0180982   -0.164896     0.0602995   -0.0194714    -0.10011      0.0601603     0.201028     0.0959522    0.0737285   0.0347717    0.0612614   0.0636926   -0.165013     0.00989655   0.228461     -0.135448     0.190221    -0.0156088    0.134185    -0.0133281   -0.053101    -0.0333911   -0.102065     0.122243
 -0.0533406   -0.0526305     0.00420157   0.00682442  -0.0315748    0.0380389    -0.0888418    0.0434705     0.00134504   0.026472     0.0163265   0.0815923    0.0497302  -0.021313    -0.0321989    0.0318619   -0.249892     -0.0673415    0.117578    -0.0993995    0.0976381    0.0986851   -0.0933154    0.0843412    0.144479    -0.088881
  0.0740855    0.0501214    -0.00869909  -0.0234167    0.0746102   -0.00430975    0.115661     0.104146      0.0105132   -0.0248945    0.134648   -0.00341387  -0.0371307   0.0486303   -0.0397718   -0.0845843    0.0539075     0.0479529   -0.190776     0.0637101    0.138994    -0.0216608   -0.0914646   -0.00450114   0.0990589    0.145945
 -0.0259947   -0.0317696    -0.0426284    0.0390823   -0.00553233  -0.103712      0.0427463    0.183074      0.00141431  -0.03125     -0.130658    0.0216612    0.0782218   0.0344514   -0.051094    -0.00411656  -0.0071081    -0.0524524   -0.0746677   -0.0325492    0.187282     0.0598643   -0.0819076    0.0838191   -0.0874215    0.0126431
  0.0645254   -0.0554176    -0.026249    -0.0728989   -0.00478665   0.0875762     0.204411    -0.0542214     0.0977139   -0.0261405   -0.0111421  -0.0381545   -0.167055   -0.099776    -0.206904     0.0749841    0.049716     -0.0767411    0.00657117  -0.00423763  -0.1084      -0.0832644   -0.00368336   0.142923    -0.0728897    0.100424
 -0.0218438    0.0366337    -0.0107349   -0.0639762    0.0561676   -0.0364001     0.141205    -0.227247     -0.141416     0.0880259   -0.253871   -0.0705592    0.0246663   0.053596     0.199053    -0.193651    -0.0793123    -0.059806     0.0721047   -0.0120147   -0.107       -0.0226698    0.00285276   0.171814     0.0206773   -0.127044
 -0.0294195    0.172726     -0.239315    -0.0787721   -0.0607467    0.136915      0.0204801   -0.215113      0.0551574   -0.102124     0.0755876   0.0723239   -0.038528   -0.127946    -0.119326    -0.0355679   -0.00865067   -0.0596135   -0.016212    -0.020225     0.019066    -0.164432     0.115188    -0.0506188   -0.00615587   0.139385
  0.153465     0.095447      0.065762    -0.0355378    0.0958957   -0.003814     -0.00839667  -0.0879298    -0.201362     0.0239685   -0.127967   -0.00599636   0.02063     0.0797939   -0.0578632    0.00778315  -0.0294794    -0.0208295    0.116795     0.119258     0.0946302   -0.00302092   0.0545391    0.0424339    0.0859537   -0.0335439
 -0.0291992   -0.0905932    -0.0955133    0.145967     0.0406497    0.0285788     0.121329    -0.0397359     0.1316      -0.0800361    0.0363591   0.0879996   -0.147511   -0.15418     -0.0220243    0.124671     0.0481475    -0.140404    -0.130014    -0.0315694    0.0779586   -0.155709     0.0858156   -0.148246    -0.0495053   -0.0949157
 -0.188128     0.0813805    -0.199603    -0.0368984   -0.0670222    0.0444258    -0.0514272    0.0213138    -0.0724656    0.101299     0.106658   -0.0487445    0.139144    0.206003    -0.0798422    0.106827     0.0733604    -0.00179882  -0.0672503    0.171718     0.0312166   -0.0221374    0.023291     0.13971     -0.077795     0.0241607
 -0.222127    -0.0683639     0.00454413  -0.0115545   -0.185729     0.0975811    -0.0279178    0.0109109     0.0367745   -0.0636318    0.0242754   0.0996402    0.215089    0.00103681   0.107393    -0.0709868    0.0297721    -0.217298     0.0960559   -0.0782295   -0.0286756    0.00214627  -0.00584485  -0.0442892   -0.0907596    0.141551
 -0.0379012   -0.129403      0.162648     0.0245384    0.039108    -0.0557148     0.051966    -0.00913616   -0.0196748    0.0220299   -0.124767   -0.00249501  -0.0989453  -0.0489424   -0.156805     0.179845    -0.0503761    -0.0103664   -0.0298667   -0.105492    -0.0202345    0.0123617    0.105727     0.0310563    0.0307407    0.136589
  0.135452    -0.0543385    -0.078129     0.260658    -0.086607     0.204718      0.011163     0.105561      0.0519126    0.0630768   -0.0303468   0.261712    -0.121364   -0.0687903    0.138804    -0.0559101   -0.0982836     0.122034    -0.0364676    0.0989719    0.0390189   -0.0139308    0.0246714   -0.0494977    0.112323     0.101067
 -0.00706693  -0.0389583    -0.236313    -0.0185756   -0.012347    -0.0119871    -0.0180321    0.0534675     0.0138576   -0.0296142   -0.159308    0.118872    -0.0492955  -0.0465576    0.172991    -0.0866244   -0.0132136    -0.0156021   -0.243848     0.0317063   -0.0119358    0.132197    -0.0385059    0.0335424    0.0009538    0.0766624
  0.0592467    0.070926     -0.00168271   0.0921759   -0.07672     -0.108385     -0.0916274   -0.0479859     0.0682389   -0.0893486   -0.037186    0.0364267    0.114919   -0.0166507   -0.179026    -0.0289417   -0.0242779     0.0461025    0.0886134   -0.220601    -0.136219     0.00698459   0.104066    -0.0416539    0.145282     0.0596205
  0.107974     0.0302058    -0.0184769    0.177794    -0.158476     0.217219     -0.121866     0.113399     -0.0936024    0.011893     0.0231935   0.216937    -0.0634741  -0.163507    -0.0268053    0.144657    -0.0833537     0.127551     0.0919754   -0.104533    -0.194544     0.0365588   -0.0579899    0.00868249   0.0328803   -0.120735
  0.0310984   -0.143896     -0.0282182   -0.191802     0.0880438   -0.0881646     0.0669161    0.150483     -0.116154    -0.0417837   -0.169934    0.132493     0.0101531  -0.0787246    0.00629338   0.0966586   -0.0306704     0.154101    -0.050726    -0.128684     0.0406991   -0.00165176   0.0460927   -0.069786     0.0180106    0.0218855
  0.0713994   -0.000761977  -0.0864182    0.0739515    0.0590158    0.103392     -0.0933352   -0.0728807     0.178168     0.0260055    0.0395907   0.104823     0.0582959   0.0387891   -0.042231     0.00977347   0.12839      -0.0518318   -0.34477      0.0981882   -0.0216324   -0.0105379   -0.0105201    0.0523086   -0.110858    -0.0833229
  0.0928931   -0.0924004    -0.113028    -0.132586     0.0478502   -0.0628822     0.0241869   -0.100098     -0.0242124   -0.12345      0.0172848  -0.148725     0.0198184   0.0184959   -0.139037    -0.11193      0.0565512     0.0610479    0.0743927    0.0785994   -0.084781    -0.0229561   -0.0949972    0.00736116   0.0323013    0.128978
 -0.0468241    0.0652539     0.0739825    0.146675    -0.0503056   -0.0506656     0.159904     0.111384     -0.126585     0.0894189    0.0413888  -0.137945    -0.0750924  -0.0839631   -0.0282323   -0.0101701   -0.122672     -0.0217157    0.030546    -0.118542    -0.0947686    0.00142439  -0.192849     0.205503     0.0174261   -0.0122848
 -0.0263108    0.153151     -0.0187315   -0.159362    -0.0457908    0.139035     -0.0423173    0.265937     -0.0339686   -0.148549    -0.136842   -0.0926089   -0.0396806   0.00191247  -0.207869    -0.0407518    0.166946      0.170895    -0.0020888   -0.0425662    0.0547051   -0.005139    -0.00586248  -0.0565031    0.0103297    0.123205
  0.0205671   -0.116797     -0.0435147   -0.189142    -0.0477563    0.118253      0.0616166   -0.0376023    -0.0756827   -0.261317     0.176091    0.174786     0.0862284  -0.103308    -0.00492879   0.126919    -0.0799162    -0.0616109    0.0564293   -0.0597167    0.0340653   -0.0903683   -0.0488443   -0.00145347  -0.0616193   -0.0278347kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4267172294262698
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.426737
[ Info: iteration 2, average log likelihood -1.426665
[ Info: iteration 3, average log likelihood -1.426607
[ Info: iteration 4, average log likelihood -1.426537
[ Info: iteration 5, average log likelihood -1.426444
[ Info: iteration 6, average log likelihood -1.426301
[ Info: iteration 7, average log likelihood -1.426041
[ Info: iteration 8, average log likelihood -1.425528
[ Info: iteration 9, average log likelihood -1.424609
[ Info: iteration 10, average log likelihood -1.423373
[ Info: iteration 11, average log likelihood -1.422264
[ Info: iteration 12, average log likelihood -1.421606
[ Info: iteration 13, average log likelihood -1.421316
[ Info: iteration 14, average log likelihood -1.421204
[ Info: iteration 15, average log likelihood -1.421162
[ Info: iteration 16, average log likelihood -1.421146
[ Info: iteration 17, average log likelihood -1.421139
[ Info: iteration 18, average log likelihood -1.421137
[ Info: iteration 19, average log likelihood -1.421135
[ Info: iteration 20, average log likelihood -1.421135
[ Info: iteration 21, average log likelihood -1.421134
[ Info: iteration 22, average log likelihood -1.421134
[ Info: iteration 23, average log likelihood -1.421133
[ Info: iteration 24, average log likelihood -1.421133
[ Info: iteration 25, average log likelihood -1.421133
[ Info: iteration 26, average log likelihood -1.421133
[ Info: iteration 27, average log likelihood -1.421133
[ Info: iteration 28, average log likelihood -1.421133
[ Info: iteration 29, average log likelihood -1.421132
[ Info: iteration 30, average log likelihood -1.421132
[ Info: iteration 31, average log likelihood -1.421132
[ Info: iteration 32, average log likelihood -1.421132
[ Info: iteration 33, average log likelihood -1.421132
[ Info: iteration 34, average log likelihood -1.421132
[ Info: iteration 35, average log likelihood -1.421132
[ Info: iteration 36, average log likelihood -1.421132
[ Info: iteration 37, average log likelihood -1.421132
[ Info: iteration 38, average log likelihood -1.421132
[ Info: iteration 39, average log likelihood -1.421132
[ Info: iteration 40, average log likelihood -1.421132
[ Info: iteration 41, average log likelihood -1.421132
[ Info: iteration 42, average log likelihood -1.421132
[ Info: iteration 43, average log likelihood -1.421132
[ Info: iteration 44, average log likelihood -1.421132
[ Info: iteration 45, average log likelihood -1.421132
[ Info: iteration 46, average log likelihood -1.421131
[ Info: iteration 47, average log likelihood -1.421131
[ Info: iteration 48, average log likelihood -1.421131
[ Info: iteration 49, average log likelihood -1.421131
[ Info: iteration 50, average log likelihood -1.421131
┌ Info: EM with 100000 data points 50 iterations avll -1.421131
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4267369074904614
│     -1.426665047912086
│      ⋮
└     -1.4211314376867306
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421151
[ Info: iteration 2, average log likelihood -1.421076
[ Info: iteration 3, average log likelihood -1.421017
[ Info: iteration 4, average log likelihood -1.420949
[ Info: iteration 5, average log likelihood -1.420872
[ Info: iteration 6, average log likelihood -1.420791
[ Info: iteration 7, average log likelihood -1.420713
[ Info: iteration 8, average log likelihood -1.420646
[ Info: iteration 9, average log likelihood -1.420594
[ Info: iteration 10, average log likelihood -1.420555
[ Info: iteration 11, average log likelihood -1.420526
[ Info: iteration 12, average log likelihood -1.420505
[ Info: iteration 13, average log likelihood -1.420489
[ Info: iteration 14, average log likelihood -1.420476
[ Info: iteration 15, average log likelihood -1.420465
[ Info: iteration 16, average log likelihood -1.420456
[ Info: iteration 17, average log likelihood -1.420447
[ Info: iteration 18, average log likelihood -1.420439
[ Info: iteration 19, average log likelihood -1.420431
[ Info: iteration 20, average log likelihood -1.420423
[ Info: iteration 21, average log likelihood -1.420414
[ Info: iteration 22, average log likelihood -1.420405
[ Info: iteration 23, average log likelihood -1.420395
[ Info: iteration 24, average log likelihood -1.420383
[ Info: iteration 25, average log likelihood -1.420370
[ Info: iteration 26, average log likelihood -1.420356
[ Info: iteration 27, average log likelihood -1.420340
[ Info: iteration 28, average log likelihood -1.420323
[ Info: iteration 29, average log likelihood -1.420303
[ Info: iteration 30, average log likelihood -1.420282
[ Info: iteration 31, average log likelihood -1.420259
[ Info: iteration 32, average log likelihood -1.420235
[ Info: iteration 33, average log likelihood -1.420211
[ Info: iteration 34, average log likelihood -1.420185
[ Info: iteration 35, average log likelihood -1.420160
[ Info: iteration 36, average log likelihood -1.420135
[ Info: iteration 37, average log likelihood -1.420111
[ Info: iteration 38, average log likelihood -1.420088
[ Info: iteration 39, average log likelihood -1.420066
[ Info: iteration 40, average log likelihood -1.420045
[ Info: iteration 41, average log likelihood -1.420025
[ Info: iteration 42, average log likelihood -1.420007
[ Info: iteration 43, average log likelihood -1.419990
[ Info: iteration 44, average log likelihood -1.419975
[ Info: iteration 45, average log likelihood -1.419960
[ Info: iteration 46, average log likelihood -1.419947
[ Info: iteration 47, average log likelihood -1.419935
[ Info: iteration 48, average log likelihood -1.419924
[ Info: iteration 49, average log likelihood -1.419914
[ Info: iteration 50, average log likelihood -1.419904
┌ Info: EM with 100000 data points 50 iterations avll -1.419904
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4211508520154472
│     -1.4210762749148445
│      ⋮
└     -1.4199042072794463
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419907
[ Info: iteration 2, average log likelihood -1.419848
[ Info: iteration 3, average log likelihood -1.419796
[ Info: iteration 4, average log likelihood -1.419737
[ Info: iteration 5, average log likelihood -1.419667
[ Info: iteration 6, average log likelihood -1.419586
[ Info: iteration 7, average log likelihood -1.419493
[ Info: iteration 8, average log likelihood -1.419393
[ Info: iteration 9, average log likelihood -1.419293
[ Info: iteration 10, average log likelihood -1.419198
[ Info: iteration 11, average log likelihood -1.419112
[ Info: iteration 12, average log likelihood -1.419037
[ Info: iteration 13, average log likelihood -1.418973
[ Info: iteration 14, average log likelihood -1.418919
[ Info: iteration 15, average log likelihood -1.418874
[ Info: iteration 16, average log likelihood -1.418837
[ Info: iteration 17, average log likelihood -1.418806
[ Info: iteration 18, average log likelihood -1.418780
[ Info: iteration 19, average log likelihood -1.418758
[ Info: iteration 20, average log likelihood -1.418739
[ Info: iteration 21, average log likelihood -1.418723
[ Info: iteration 22, average log likelihood -1.418709
[ Info: iteration 23, average log likelihood -1.418696
[ Info: iteration 24, average log likelihood -1.418685
[ Info: iteration 25, average log likelihood -1.418674
[ Info: iteration 26, average log likelihood -1.418665
[ Info: iteration 27, average log likelihood -1.418655
[ Info: iteration 28, average log likelihood -1.418647
[ Info: iteration 29, average log likelihood -1.418638
[ Info: iteration 30, average log likelihood -1.418630
[ Info: iteration 31, average log likelihood -1.418622
[ Info: iteration 32, average log likelihood -1.418615
[ Info: iteration 33, average log likelihood -1.418607
[ Info: iteration 34, average log likelihood -1.418600
[ Info: iteration 35, average log likelihood -1.418594
[ Info: iteration 36, average log likelihood -1.418587
[ Info: iteration 37, average log likelihood -1.418580
[ Info: iteration 38, average log likelihood -1.418574
[ Info: iteration 39, average log likelihood -1.418568
[ Info: iteration 40, average log likelihood -1.418562
[ Info: iteration 41, average log likelihood -1.418556
[ Info: iteration 42, average log likelihood -1.418550
[ Info: iteration 43, average log likelihood -1.418545
[ Info: iteration 44, average log likelihood -1.418539
[ Info: iteration 45, average log likelihood -1.418534
[ Info: iteration 46, average log likelihood -1.418529
[ Info: iteration 47, average log likelihood -1.418524
[ Info: iteration 48, average log likelihood -1.418519
[ Info: iteration 49, average log likelihood -1.418514
[ Info: iteration 50, average log likelihood -1.418509
┌ Info: EM with 100000 data points 50 iterations avll -1.418509
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4199066110034348
│     -1.4198477723748437
│      ⋮
└     -1.4185089333012904
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418513
[ Info: iteration 2, average log likelihood -1.418453
[ Info: iteration 3, average log likelihood -1.418397
[ Info: iteration 4, average log likelihood -1.418334
[ Info: iteration 5, average log likelihood -1.418258
[ Info: iteration 6, average log likelihood -1.418167
[ Info: iteration 7, average log likelihood -1.418061
[ Info: iteration 8, average log likelihood -1.417943
[ Info: iteration 9, average log likelihood -1.417819
[ Info: iteration 10, average log likelihood -1.417694
[ Info: iteration 11, average log likelihood -1.417575
[ Info: iteration 12, average log likelihood -1.417464
[ Info: iteration 13, average log likelihood -1.417364
[ Info: iteration 14, average log likelihood -1.417275
[ Info: iteration 15, average log likelihood -1.417197
[ Info: iteration 16, average log likelihood -1.417128
[ Info: iteration 17, average log likelihood -1.417067
[ Info: iteration 18, average log likelihood -1.417013
[ Info: iteration 19, average log likelihood -1.416965
[ Info: iteration 20, average log likelihood -1.416921
[ Info: iteration 21, average log likelihood -1.416881
[ Info: iteration 22, average log likelihood -1.416843
[ Info: iteration 23, average log likelihood -1.416808
[ Info: iteration 24, average log likelihood -1.416774
[ Info: iteration 25, average log likelihood -1.416742
[ Info: iteration 26, average log likelihood -1.416711
[ Info: iteration 27, average log likelihood -1.416682
[ Info: iteration 28, average log likelihood -1.416654
[ Info: iteration 29, average log likelihood -1.416628
[ Info: iteration 30, average log likelihood -1.416602
[ Info: iteration 31, average log likelihood -1.416579
[ Info: iteration 32, average log likelihood -1.416556
[ Info: iteration 33, average log likelihood -1.416535
[ Info: iteration 34, average log likelihood -1.416516
[ Info: iteration 35, average log likelihood -1.416497
[ Info: iteration 36, average log likelihood -1.416480
[ Info: iteration 37, average log likelihood -1.416465
[ Info: iteration 38, average log likelihood -1.416450
[ Info: iteration 39, average log likelihood -1.416437
[ Info: iteration 40, average log likelihood -1.416424
[ Info: iteration 41, average log likelihood -1.416413
[ Info: iteration 42, average log likelihood -1.416402
[ Info: iteration 43, average log likelihood -1.416392
[ Info: iteration 44, average log likelihood -1.416383
[ Info: iteration 45, average log likelihood -1.416374
[ Info: iteration 46, average log likelihood -1.416366
[ Info: iteration 47, average log likelihood -1.416359
[ Info: iteration 48, average log likelihood -1.416352
[ Info: iteration 49, average log likelihood -1.416345
[ Info: iteration 50, average log likelihood -1.416339
┌ Info: EM with 100000 data points 50 iterations avll -1.416339
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4185133643742436
│     -1.4184526308914316
│      ⋮
└     -1.416338929433235
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416342
[ Info: iteration 2, average log likelihood -1.416278
[ Info: iteration 3, average log likelihood -1.416220
[ Info: iteration 4, average log likelihood -1.416151
[ Info: iteration 5, average log likelihood -1.416065
[ Info: iteration 6, average log likelihood -1.415956
[ Info: iteration 7, average log likelihood -1.415821
[ Info: iteration 8, average log likelihood -1.415664
[ Info: iteration 9, average log likelihood -1.415494
[ Info: iteration 10, average log likelihood -1.415320
[ Info: iteration 11, average log likelihood -1.415153
[ Info: iteration 12, average log likelihood -1.415000
[ Info: iteration 13, average log likelihood -1.414863
[ Info: iteration 14, average log likelihood -1.414743
[ Info: iteration 15, average log likelihood -1.414640
[ Info: iteration 16, average log likelihood -1.414550
[ Info: iteration 17, average log likelihood -1.414472
[ Info: iteration 18, average log likelihood -1.414404
[ Info: iteration 19, average log likelihood -1.414343
[ Info: iteration 20, average log likelihood -1.414289
[ Info: iteration 21, average log likelihood -1.414241
[ Info: iteration 22, average log likelihood -1.414197
[ Info: iteration 23, average log likelihood -1.414156
[ Info: iteration 24, average log likelihood -1.414119
[ Info: iteration 25, average log likelihood -1.414085
[ Info: iteration 26, average log likelihood -1.414053
[ Info: iteration 27, average log likelihood -1.414024
[ Info: iteration 28, average log likelihood -1.413996
[ Info: iteration 29, average log likelihood -1.413971
[ Info: iteration 30, average log likelihood -1.413946
[ Info: iteration 31, average log likelihood -1.413923
[ Info: iteration 32, average log likelihood -1.413901
[ Info: iteration 33, average log likelihood -1.413879
[ Info: iteration 34, average log likelihood -1.413859
[ Info: iteration 35, average log likelihood -1.413839
[ Info: iteration 36, average log likelihood -1.413820
[ Info: iteration 37, average log likelihood -1.413802
[ Info: iteration 38, average log likelihood -1.413784
[ Info: iteration 39, average log likelihood -1.413766
[ Info: iteration 40, average log likelihood -1.413749
[ Info: iteration 41, average log likelihood -1.413732
[ Info: iteration 42, average log likelihood -1.413715
[ Info: iteration 43, average log likelihood -1.413699
[ Info: iteration 44, average log likelihood -1.413683
[ Info: iteration 45, average log likelihood -1.413668
[ Info: iteration 46, average log likelihood -1.413652
[ Info: iteration 47, average log likelihood -1.413637
[ Info: iteration 48, average log likelihood -1.413622
[ Info: iteration 49, average log likelihood -1.413607
[ Info: iteration 50, average log likelihood -1.413593
┌ Info: EM with 100000 data points 50 iterations avll -1.413593
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4163418668946057
│     -1.416278043696493
│      ⋮
└     -1.41359266844948
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4267172294262698
│     -1.4267369074904614
│     -1.426665047912086
│     -1.4266070921040377
│      ⋮
│     -1.4136221616309763
│     -1.4136073252525736
└     -1.41359266844948
32×26 Array{Float64,2}:
  0.0910199   -0.26443     0.102952    -0.441511     -0.188078    -0.21239    -0.17923    -0.369234   -0.285198     0.399785   -0.68387    -0.883158    -0.115363     0.623279    0.421411    -0.575591    -0.322518   -0.35696      0.0405106   -0.121946    -0.00533584  -0.200669     0.203878    1.00119     0.171291   -0.147471
 -0.328317     0.346203    0.227656    -0.185676     -0.0174817   -0.582206   -0.501474    0.142689   -0.333908     0.5727     -0.703434    0.618551    -0.40579      0.0986196   0.233241     0.0978859    0.290446   -0.14241     -0.0834647   -0.227743     0.295981    -0.279394     0.414237    0.286675    0.0285541   0.0273142
 -0.946838     0.498967   -0.688555    -0.94093       0.341215    -0.359213    0.47396     0.45612    -0.409098     0.0624604   0.156886    0.340251     0.365015     0.733341    0.36561      0.248741    -0.755073    0.319807     0.151733     0.291494     0.389174    -0.54592      0.650143    0.366017   -0.220431    0.176922
 -0.78344      0.300249   -0.0871123   -0.211923     -0.240474    -0.035265   -0.191759    0.220725   -0.435615    -0.364716   -0.166025   -0.00610046   0.585658     0.0103967   0.198599     0.974089    -0.0829835  -0.742197    -0.0301705   -0.0346053    0.0206659   -1.05387      0.063464    0.204803   -0.294451   -0.398814
  0.388214    -0.426781    0.127123    -0.29762       0.406903    -0.266845    0.345008   -0.302398   -0.181479     0.233902   -0.251508   -0.205979     0.633761     0.380782   -0.242456     0.3674      -0.14827    -0.256132     0.0186464   -0.349633     0.0189046    0.212678    -0.390627    0.12375     0.323392    0.0913867
 -0.380608     0.174668    0.00427166   0.019375      0.104813    -0.117767    0.069946   -0.765404   -0.123865     0.162587   -0.318078    0.323703     0.0844448    0.0524778  -0.514732    -0.451889     0.0969306   0.00680621   0.570599     0.57045     -0.0414215    0.412389     0.701255    0.454292   -0.177574   -0.336904
  0.253385     0.296515   -1.25412     -0.20319       0.0090524    0.0727953   0.0209154   0.598478   -0.518768     0.29024     0.268308    0.0742903   -0.267402     0.571135    0.299139    -0.0938646   -0.0180539   0.119303     0.390473     0.249855     0.455587     0.265191    -0.1275      0.239645   -0.269244   -0.183523
 -0.178427    -0.127444    0.666175    -0.0247675    -0.257953    -0.15714    -0.0907669   0.508425   -0.528055    -0.141244    0.352002    0.192539     0.474153    -0.10297     0.168513    -0.38594     -0.0862713   0.150345     0.035474    -0.204015     0.90994      0.355458    -0.265813    0.671426   -0.609731   -0.353086
  0.238976     0.369527    0.206483     0.324449     -0.0717176   -0.11046    -0.326972    0.328315    0.0699723   -0.289308   -0.0150442  -0.542217     0.0335338   -0.224323    0.0019021    0.0132598   -0.157777    0.104041     0.202402    -0.522407    -0.887257    -0.332048    -0.187141   -0.554194    0.139424    0.662838
  0.109837    -0.0387258   1.06272     -0.0861643     0.460446     0.0569122   0.0634036  -0.322715    0.295485    -0.554749    0.0451627   0.644554     0.107425    -0.720956   -0.482557     0.508348    -0.0192319  -0.218386    -0.249369    -0.925101     0.0357619    0.212039    -0.220867   -0.920057    0.252545    0.40613
 -0.801708    -0.0634958  -0.20978      0.0681581     0.443738     0.404895   -0.0172639   0.018182   -0.381543    -0.553978   -0.326957   -0.270566    -0.352918    -0.206223   -0.565067     0.00960683  -0.014601    0.260052     0.422477     0.116807     0.308333     0.118124     0.386093   -0.250963    0.586672    1.27629
  0.240393    -0.0670951  -0.774508     0.375878      0.372378    -0.20345     0.199642    0.507539   -0.375517    -0.346175    0.486783    0.293289    -0.00572849  -0.330991   -0.629324     0.458449     0.127443    0.360264     0.37502      0.715282    -0.510774     0.0567321   -0.248143   -0.693186   -0.193755    0.0961208
  0.0691472    0.0863172   0.138965     0.000897819  -0.824        0.392505   -0.152922    0.132043    0.492322     0.370405   -0.406845   -0.182898    -0.953971     0.313336   -0.294895     0.0606147   -0.0355867  -0.338684    -0.214724    -0.0750143    0.00886667  -1.00281      0.338453   -0.211483    0.0357246  -0.0379642
  0.0989926    0.0510388   0.111366     0.255088     -0.151395     0.159653   -0.145593    0.300197    0.773087    -0.252164    0.226496    0.127062    -0.24091     -0.304714    0.518389    -0.0503234    0.237716    0.264234    -0.576452     0.102724    -0.185561    -0.241871    -0.0574667  -0.582735    0.0786231   0.126346
  0.75104     -0.355248    0.11078      0.54921      -0.015084     0.450216   -0.406477   -0.185513    0.330396     0.129824   -0.184004   -0.43657     -0.0276985   -0.316639   -0.113006    -0.254354     0.0888257   0.443787    -0.299132    -0.374633     0.0394614    0.557732    -0.349423   -0.0230181  -0.464026   -0.221265
 -0.00983522  -0.479555    0.109466     0.317743     -0.00549164   0.677601    0.160206   -0.36898     0.514151    -0.631153    0.205101   -0.421019     0.421768    -0.439818    0.55465     -0.152605    -0.16208    -0.00957689  -0.23575     -0.386966     0.0136487    0.121312    -0.0448451   0.45269     0.0310998   0.137785
 -0.0842494    0.0517471   0.0786624   -0.0503637     0.0876446   -0.112366   -0.0968104   0.021543    0.00200479   0.0648746  -0.423166   -0.0767915    0.0948702    0.131923   -0.185946     0.0186764   -0.0724693   0.0257527    0.0231147   -0.0644692    0.0967618   -0.0675365    0.0434334   0.0477774   0.0698088   0.105057
  0.0938529   -0.0673659  -0.0376124    0.0592933    -0.107543     0.0617377   0.0262082  -0.0175448  -0.0096378   -0.174815    0.247699    0.0874602   -0.004274    -0.143499    0.0428944    0.00627536  -0.0039606  -0.0849327    0.00886551  -0.0719383   -0.099224    -0.00112983  -0.0287681  -0.0718393  -0.0226558   0.0395612
  0.172749    -0.389704   -0.194892    -0.014205      0.315793    -0.0117066   0.534155   -0.763005    0.222222     0.16246    -0.22831     0.385231     0.259921    -0.109591    0.150054     0.495292     0.301742   -0.116528    -0.17578      0.194546    -0.348003    -0.0109172    0.636662   -0.103792   -0.0701109  -0.298949
 -0.333838    -0.18872     0.444619     0.370292      0.0884666   -0.316645   -0.0115476   0.153599    0.378749    -0.48524    -0.1343      0.258257     0.520634     0.0856468  -0.280019     0.11241      0.379865    0.164017     0.01633      0.203696    -0.122388     0.0805599    0.0302577  -0.240111    0.121562   -0.272648
  0.350376    -0.176508    0.0198563   -0.194924      0.0986995   -0.165401    0.0184542   0.163115    0.447747     0.0392422  -0.250098   -0.110726     0.519114     0.178322    0.0400872    0.390054    -0.317404   -0.215505    -0.749782     0.427931     0.302258     0.0558994   -0.534027   -0.300695   -0.684171   -0.491853
 -0.144716    -0.37289    -0.253043    -0.084094      0.0668005   -0.260567   -0.107822    0.393384    0.274096     0.26828     0.398739   -0.144538    -0.0491578    0.160818    0.140379     0.228494     0.329322   -0.276373    -0.806048    -0.145328    -0.26122      0.0971907   -0.305846   -0.171589    0.705901   -0.433034
  0.368783     0.255103   -0.0456915   -0.299322     -0.299496    -0.116323    0.163644    0.273024   -0.313931     0.235657    0.310417   -0.161527     0.429489     0.381015    0.161721     0.204086     0.334823   -0.0737929    0.745016    -0.0983331   -0.315873    -0.200964    -0.303076    0.64767    -0.335345   -0.458564
 -0.158804    -0.231103   -0.218495    -0.159685     -0.297374     0.600707    0.11722     0.213419   -0.057899    -0.0476748   0.145338    0.122607    -0.0751168    0.311567    0.00701717   0.0743096    0.212199   -0.340089     0.419231    -0.0438213    0.781931     0.0177649   -0.288695    0.57448    -0.240588   -0.292619
  0.12284     -0.290916    0.00694096  -0.349458     -0.371429     0.0670448   0.429475   -0.496275    0.0853438   -0.0463025  -0.357237    0.0686234   -0.339761    -0.168583   -0.10187     -0.0574862   -0.861391   -0.109955    -0.621628     0.189161     0.165317    -0.366899     0.18255     0.0904046   0.165861    0.516401
  0.0975713    0.0684574   0.260772     0.00764738   -0.607202     0.361138    0.20472    -0.26386    -0.601819    -0.0566043   0.129342   -0.0135505   -0.767193    -0.285445    0.0141325   -0.280087     0.369559   -0.163618     0.958989    -0.561528    -0.513775    -0.227291     0.303895    0.73452     0.421586    0.305648
  0.139047    -0.0496186   0.00454753  -0.81609       0.34134     -0.087792    0.290861    0.0296999  -0.0621539    0.226383    0.371133    0.0655984    0.175807     0.0411718  -0.00352989  -0.15722      0.0388172  -0.149925     0.0970496   -0.00591644  -0.0828041    0.19354     -0.423315   -0.0708679   0.562879    0.68124
  0.333416    -0.37131    -0.294112     0.267492     -0.083772     0.460197    0.591279   -0.395219    0.310442     0.0383349   0.082112    0.0472816   -0.133905     0.194395   -0.277512    -0.664923    -0.0345445   0.135673     0.475249     0.185527    -0.0270673    0.582612    -0.165023    0.0443414   0.43261     0.619501
 -0.0783541    0.874894    0.297175    -0.162736     -0.296867     0.0163634  -0.51884    -0.569081    0.28503     -0.167059   -0.0457345  -0.137288    -0.0292415   -0.386292   -0.16298      0.0288167    0.0352622   0.240676    -0.278147     0.260781     0.171902    -0.474171     0.933428   -0.503035   -0.583088    0.169527
 -0.10294      0.528788   -0.404983     0.251545     -0.400296     0.430529   -0.095382    0.138443    0.00115246  -0.199838    0.12009     0.541697    -0.511629    -0.405322    0.196792    -0.217754    -0.0284204   0.102115    -0.134608     0.399303     0.130157    -0.154714     0.262173   -0.12063    -0.453033    0.0413266
 -0.0251033    0.457915   -0.575216     0.0282232     0.638043    -0.35136    -0.199692   -0.037262   -0.455606     0.473304    0.106173    0.100017    -0.0463973    0.111375   -0.333714    -0.0788161   -0.0951227   0.0763341    0.290455    -0.351303    -0.165009     0.350511     0.259531   -0.0465591   0.122033   -0.118557
  0.242108     0.49735     0.109368     0.668816      0.0878201   -0.202217   -0.387855    0.363057   -0.0930008   -0.0847504  -0.0545288   0.247905    -0.529372     0.0534062  -0.201003    -0.811353    -0.329801    0.244948     0.192965    -0.126332     0.112787     0.378753    -0.149134   -0.256805    0.29514     0.0573672[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413578
[ Info: iteration 2, average log likelihood -1.413564
[ Info: iteration 3, average log likelihood -1.413550
[ Info: iteration 4, average log likelihood -1.413536
[ Info: iteration 5, average log likelihood -1.413523
[ Info: iteration 6, average log likelihood -1.413509
[ Info: iteration 7, average log likelihood -1.413497
[ Info: iteration 8, average log likelihood -1.413484
[ Info: iteration 9, average log likelihood -1.413472
[ Info: iteration 10, average log likelihood -1.413461
┌ Info: EM with 100000 data points 10 iterations avll -1.413461
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.857482e+05
      1       7.085483e+05      -2.771999e+05 |       32
      2       6.964557e+05      -1.209264e+04 |       32
      3       6.914866e+05      -4.969042e+03 |       32
      4       6.887458e+05      -2.740839e+03 |       32
      5       6.868556e+05      -1.890209e+03 |       32
      6       6.855371e+05      -1.318430e+03 |       32
      7       6.845918e+05      -9.453398e+02 |       32
      8       6.838216e+05      -7.702048e+02 |       32
      9       6.831969e+05      -6.247148e+02 |       32
     10       6.826900e+05      -5.068475e+02 |       32
     11       6.822658e+05      -4.242352e+02 |       32
     12       6.818986e+05      -3.672400e+02 |       32
     13       6.815421e+05      -3.564213e+02 |       32
     14       6.812130e+05      -3.291096e+02 |       32
     15       6.809326e+05      -2.804295e+02 |       32
     16       6.806612e+05      -2.713619e+02 |       32
     17       6.804094e+05      -2.518000e+02 |       32
     18       6.801732e+05      -2.361962e+02 |       32
     19       6.799570e+05      -2.162377e+02 |       32
     20       6.797788e+05      -1.781715e+02 |       32
     21       6.796132e+05      -1.656256e+02 |       32
     22       6.794666e+05      -1.466574e+02 |       32
     23       6.793250e+05      -1.415702e+02 |       32
     24       6.791906e+05      -1.343404e+02 |       32
     25       6.790745e+05      -1.160938e+02 |       32
     26       6.789766e+05      -9.797282e+01 |       32
     27       6.788796e+05      -9.700164e+01 |       32
     28       6.787839e+05      -9.569604e+01 |       32
     29       6.786869e+05      -9.693502e+01 |       32
     30       6.785916e+05      -9.539008e+01 |       32
     31       6.785045e+05      -8.702070e+01 |       32
     32       6.784162e+05      -8.830405e+01 |       32
     33       6.783436e+05      -7.261799e+01 |       32
     34       6.782717e+05      -7.187443e+01 |       32
     35       6.781911e+05      -8.066468e+01 |       32
     36       6.781129e+05      -7.818664e+01 |       32
     37       6.780392e+05      -7.366400e+01 |       32
     38       6.779671e+05      -7.212652e+01 |       32
     39       6.778945e+05      -7.257967e+01 |       32
     40       6.778231e+05      -7.139755e+01 |       32
     41       6.777568e+05      -6.630466e+01 |       32
     42       6.776949e+05      -6.192614e+01 |       32
     43       6.776374e+05      -5.748427e+01 |       32
     44       6.775802e+05      -5.715210e+01 |       32
     45       6.775165e+05      -6.372271e+01 |       32
     46       6.774535e+05      -6.300853e+01 |       32
     47       6.773856e+05      -6.791852e+01 |       32
     48       6.773195e+05      -6.606175e+01 |       32
     49       6.772596e+05      -5.996038e+01 |       32
     50       6.772104e+05      -4.913801e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 677210.4383959782)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425399
[ Info: iteration 2, average log likelihood -1.420407
[ Info: iteration 3, average log likelihood -1.419047
[ Info: iteration 4, average log likelihood -1.418017
[ Info: iteration 5, average log likelihood -1.416938
[ Info: iteration 6, average log likelihood -1.415963
[ Info: iteration 7, average log likelihood -1.415306
[ Info: iteration 8, average log likelihood -1.414942
[ Info: iteration 9, average log likelihood -1.414740
[ Info: iteration 10, average log likelihood -1.414611
[ Info: iteration 11, average log likelihood -1.414516
[ Info: iteration 12, average log likelihood -1.414439
[ Info: iteration 13, average log likelihood -1.414373
[ Info: iteration 14, average log likelihood -1.414315
[ Info: iteration 15, average log likelihood -1.414262
[ Info: iteration 16, average log likelihood -1.414213
[ Info: iteration 17, average log likelihood -1.414168
[ Info: iteration 18, average log likelihood -1.414126
[ Info: iteration 19, average log likelihood -1.414086
[ Info: iteration 20, average log likelihood -1.414048
[ Info: iteration 21, average log likelihood -1.414012
[ Info: iteration 22, average log likelihood -1.413979
[ Info: iteration 23, average log likelihood -1.413947
[ Info: iteration 24, average log likelihood -1.413916
[ Info: iteration 25, average log likelihood -1.413888
[ Info: iteration 26, average log likelihood -1.413860
[ Info: iteration 27, average log likelihood -1.413835
[ Info: iteration 28, average log likelihood -1.413811
[ Info: iteration 29, average log likelihood -1.413788
[ Info: iteration 30, average log likelihood -1.413766
[ Info: iteration 31, average log likelihood -1.413746
[ Info: iteration 32, average log likelihood -1.413727
[ Info: iteration 33, average log likelihood -1.413708
[ Info: iteration 34, average log likelihood -1.413691
[ Info: iteration 35, average log likelihood -1.413674
[ Info: iteration 36, average log likelihood -1.413658
[ Info: iteration 37, average log likelihood -1.413642
[ Info: iteration 38, average log likelihood -1.413627
[ Info: iteration 39, average log likelihood -1.413612
[ Info: iteration 40, average log likelihood -1.413598
[ Info: iteration 41, average log likelihood -1.413584
[ Info: iteration 42, average log likelihood -1.413571
[ Info: iteration 43, average log likelihood -1.413558
[ Info: iteration 44, average log likelihood -1.413545
[ Info: iteration 45, average log likelihood -1.413533
[ Info: iteration 46, average log likelihood -1.413521
[ Info: iteration 47, average log likelihood -1.413509
[ Info: iteration 48, average log likelihood -1.413497
[ Info: iteration 49, average log likelihood -1.413485
[ Info: iteration 50, average log likelihood -1.413474
┌ Info: EM with 100000 data points 50 iterations avll -1.413474
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.301169   -0.420986    0.0254455  -0.0413184   0.165503     0.0360496   -0.036767     0.189396    0.320653    -0.0393537    0.609534    -0.162085      0.207747   -0.147117    0.32826     -0.043215     0.314485    -0.186848   -0.382839   -0.0493796   -0.3693      0.18801     -0.905958   -0.432673      0.378543   -0.00903112
  0.179143    0.127954    0.0270755  -0.0821935  -0.256032     0.310625     0.250391    -0.0080295  -0.653039     0.15347      0.311518    -0.105556     -0.439869   -0.154373   -0.0789233   -0.00657594   0.610388    -0.127878    1.07224    -0.555175    -0.608944   -0.16855      0.131259    0.829305      0.230517   -0.08844
 -0.317458    0.428818   -0.337994   -0.0598007  -0.194944     0.350979    -0.179534    -0.0725139  -0.295532    -0.209739     0.0740177    0.242758      0.0515466  -0.149719    0.124431     0.292495    -0.0604107   -0.157792    0.0951041   0.0542175    0.279399   -0.33765      0.309233    0.0532837    -0.775123   -0.346058
 -0.0639121  -0.132255    0.069963    0.0599289   0.142336    -0.197047     0.122353    -0.772594    0.0520981    0.197767    -0.0954918    0.0914029     0.111214    0.0415969  -0.396766    -0.96656      0.192384     0.351857    0.546706    0.670589     0.105328    0.756971     0.530996    0.467626     -0.09347    -0.0723316
  0.282971   -0.280436    0.023065   -0.104944    0.00848707   0.00192806   0.0485053    0.143128    0.61891     -0.119096    -0.254808    -0.104963      0.317403    0.0848054   0.00841288   0.333635    -0.362084    -0.235932   -0.869802    0.485202     0.308714   -0.00304936  -0.436022   -0.399313     -0.526073   -0.339156
 -0.108845    0.0321973   0.660085    0.423329    0.217433    -0.226983    -0.202886    -0.153461    0.40233     -0.292067    -0.210494     0.565842      0.04651    -0.481661   -0.449618     0.449571     0.0709918   -0.076934   -0.365822   -0.435227    -0.317987   -0.110428    -0.0108769  -0.916571      0.312977    0.121657
  0.14782    -0.487184   -0.0775283  -0.242981   -0.478781    -0.0852919   -0.141088    -0.0270697  -0.00593211   0.331529    -0.455341    -0.798928     -0.259608    0.590365    0.711995    -0.0913774   -0.0725178   -0.515682   -0.169667   -0.258333    -0.413278   -0.823994     0.24354     0.457109      0.444505   -0.0802573
  0.264895   -0.060747   -0.0391839  -0.0212213  -0.0405188    0.136496    -0.00387887  -0.0775607   0.0504637    0.0344191    0.0502842    0.0471439    -0.094646   -0.0846868  -0.0669496   -0.0850302   -0.0809696   -0.0948884  -0.0218271  -0.0312169   -0.0217391   0.0512213   -0.147478   -0.0129307    -0.0134864   0.0832674
  0.25506    -0.311344    0.400185    0.197773    0.209475    -0.36429      0.0496377   -0.0922715   0.23314     -0.0895428    0.0025267   -0.0362549     0.739805   -0.0800454  -0.144843    -0.0920776    0.294031     0.298195   -0.0265947   0.00962927  -0.212771    0.400976    -0.273603    0.0877048    -0.0360005  -0.279189
  0.224161   -0.482874   -0.589696   -0.0818896   0.122681     0.240704     0.511508     0.19969    -0.201821     0.133444     0.0400678   -0.0093546     0.29955     0.461097   -0.219136     0.129753    -0.155013    -0.2517      0.494644   -0.170846     0.179531    0.277827    -0.799783    0.391266      0.232694   -0.00130072
  0.0923567   0.841477    0.106089   -0.0861344   0.22099     -0.0953383   -0.22048      0.425954    0.214532    -0.190562     0.129442    -0.829705      0.297854   -0.0674748  -0.00263732  -0.0986059    0.0472571    0.388364    0.401928   -0.363698    -0.933707   -0.138765    -0.0762239  -0.67688      -0.107495    0.503923
  0.0855432  -0.461508   -0.230096   -0.0424084   0.262331     0.0981816    0.597324    -0.850714    0.2793       0.130005    -0.190794     0.380716      0.264615   -0.0869814   0.197355     0.571779     0.385205    -0.162581   -0.233627    0.258745    -0.328003   -0.0930994    0.715744   -0.0582257    -0.0380561  -0.312678
 -0.60647    -0.319754   -0.0616147   0.252259   -0.212996     0.723724     0.00306475   0.531673    0.557572    -0.594433     0.0357026    0.000177704  -0.0750596   0.127325    0.00463755  -0.179698     0.553749     0.099327    0.121828    0.337685     0.460462    0.0759762    0.107767    0.0642481     0.189256    0.0213003
 -0.406339    0.50618     0.227565    0.655209   -0.103829    -0.333993    -0.492095     0.703555   -0.386195    -0.0165952    0.162162     0.426709     -0.223539   -0.026548    0.0509871   -0.712842    -0.244114     0.12496     0.170672   -0.32078      0.51442     0.405833    -0.346876    0.198577     -0.162551   -0.125399
  0.250825    0.154564   -0.701081   -0.603055    0.110045     0.469206    -0.0818312    0.744522   -0.00261223   0.545398     0.246286     0.313695     -0.580943    0.383137    0.257293    -0.145294     0.435929     0.241003    0.176547    0.442773     0.814305    0.241572    -0.568282   -0.123197     -0.1925      0.149281
  0.359911    0.44062    -0.263755    0.0472     -0.192095     0.268961     0.122449    -0.0690408  -0.208464     0.0509258   -0.00599886   0.287371     -0.544902    0.217561    0.151901    -0.697257    -0.0640082    0.0359871   0.561382   -0.169017    -0.0121214   0.239245     0.273186    0.102822      0.406289    0.406508
 -0.0975836  -0.100754   -0.0376376  -0.385589   -0.325731    -0.0649833    0.13857     -0.496946   -0.17649      0.33741     -0.560803    -0.110605     -0.266648    0.025811    0.00510378  -0.285143    -0.606265    -0.0267167  -0.240923   -0.0118061    0.463394   -0.142647     0.386688    0.616794     -0.119153    0.0964834
  0.319535    0.234403   -0.507207    0.395702   -0.188289    -0.237059    -0.0599217    0.57018    -0.465122    -0.162595     0.241699     0.359705     -0.403863   -0.280398   -0.49345      0.369486     0.191634     0.343655    0.504919    0.66481     -0.594878   -0.292852    -0.0410052  -0.780281     -0.362315    0.187161
 -0.0523915   0.425223   -0.273243   -0.0944681   0.202289    -0.500841    -0.0492325   -0.167273   -0.345547     0.53085     -0.69195      0.323978     -0.158626    0.527543   -0.657658     0.282561    -0.14887     -0.483272    0.439786    0.00860306  -0.15945     0.0225664    0.380627   -0.000966031   0.173524   -0.05652
 -0.0593026  -0.124035   -0.0661162  -0.691287    0.21265      0.0627436    0.471145    -0.254208   -0.191883    -0.15353      0.0980988   -0.108021     -0.0110336   0.0607151  -0.457571     0.141933    -0.32974     -0.240894    0.0500032   0.232166    -0.146029   -0.283104    -0.31514    -0.0904591     0.680276    1.08013
 -0.356597    0.0629826  -0.278353   -0.229039   -0.0638516    0.0795487    0.182584     0.192581   -0.313466    -0.133909    -0.0460286    0.137354      0.25155     0.264638    0.239638     0.254637    -0.176563    -0.10217     0.064843    0.0773598    0.503169   -0.293437     0.0767547   0.353946     -0.284113   -0.16917
  0.0827076   0.0878046  -1.03121     0.0615611   0.604537    -0.693248     0.076042     0.320734   -0.170381     0.248595     0.427515     0.0809817     0.119414    0.215665   -0.129224     0.119565    -0.267758     0.325355   -0.223889    0.0196109   -0.145278    0.617148     0.122329   -0.244236      0.341674   -0.228649
  0.844038   -0.304554   -0.247031    0.845518   -0.15874      0.600417    -0.108064    -0.345811    0.406818    -0.196066     0.0109349   -0.402976     -0.365777   -0.428902    0.0244088   -0.130839    -0.105022     0.506582   -0.132986   -0.318279    -0.108847    0.441173    -0.147615   -0.181137     -0.215181    0.0659033
  0.232199   -0.267149    0.851408   -0.0639942  -0.103167     0.388265    -0.776706     0.370526    0.00498902   0.0930817   -0.369049    -0.817823     -0.254768    0.362103   -0.946409    -0.203652    -0.184376    -0.153421   -0.186462   -0.961542     0.475031    0.19251     -0.302227    0.268131      0.266297    0.0347178
 -0.709903   -0.0165665  -0.440179    0.15654     0.671423     0.417       -0.066144    -0.179268   -0.605073    -0.440159    -0.175269    -0.354078     -0.42155    -0.55695    -0.40444      0.0195572    0.0124691    0.447704    0.622906    0.103105     0.25772     0.316563     0.592205   -0.122958      0.431199    1.47295
  0.422287    0.0909281   0.208043   -0.40914    -0.505351    -0.11146      0.0823704    0.184539   -0.250201     0.360788     0.308138    -0.0784904     0.482088    0.418741    0.272192     0.113734     0.321069    -0.215112    0.425327   -0.0308465    0.232624   -0.120692    -0.288557    0.944083     -0.692088   -0.77257
 -0.275413    0.075128    0.0742191   0.0998207   0.107316    -0.17762     -0.0835065    0.019206    0.00938824  -0.151647    -0.121268     0.143495     -0.0616308  -0.0311839  -0.175239     0.0262892    0.0588036    0.0534024  -0.0307142  -0.102547    -0.0455878  -0.0304864    0.278671   -0.251902      0.241601    0.147672
 -0.405877   -0.371788    0.166166   -0.0632501   0.867751     0.776732     0.247269    -0.809059    0.487652    -0.421442     0.215403    -0.364166      1.03108    -0.147048    0.435034    -0.571149    -0.45072     -0.699699   -0.30672    -0.834103     0.0570063   0.447291    -0.18426     0.776196      0.268704    0.0656789
 -0.0839707   0.768317    0.0469765   0.0547147  -0.560066     0.171525    -0.500104    -0.10632     0.413981    -0.127338     0.122448     0.135989     -0.655916   -0.411038    0.110151    -0.237214     0.00775347   0.218073   -0.866208    0.389825    -0.0380773  -0.721763     0.737132   -0.274667     -0.229314    0.140526
  0.630682   -0.41835     0.810445   -0.729782    0.621191    -0.473604     0.230765     0.108878    0.099207     0.263019    -0.105233     0.397089      0.0790683  -0.291776    0.74347      0.152513    -0.323939     0.21992    -0.646343   -1.00636      0.290518    0.433322     0.229382   -0.101204      0.0355976   0.509777
 -0.488143    0.237043    0.118821   -0.295713   -0.00688721  -0.535189    -0.071151     0.320751   -0.19392     -0.00776739  -0.140563    -0.0352436     0.51778     0.282575    0.148219     0.382954     0.123415    -0.198741    0.081666    0.0261939   -0.0227471  -0.511719    -0.0199467   0.232674      0.0938272  -0.118737
 -0.117083   -0.239494    0.960144    0.441013   -0.754124     0.618118     0.170549    -0.251185    0.213589    -0.466438    -0.303996     0.000656753  -0.170148   -0.682227    0.148112    -0.292254    -0.263079    -0.212298    0.167232   -0.25001     -0.254948   -0.458094    -0.103528    0.155648      0.130366    0.626259[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413463
[ Info: iteration 2, average log likelihood -1.413452
[ Info: iteration 3, average log likelihood -1.413442
[ Info: iteration 4, average log likelihood -1.413431
[ Info: iteration 5, average log likelihood -1.413421
[ Info: iteration 6, average log likelihood -1.413411
[ Info: iteration 7, average log likelihood -1.413401
[ Info: iteration 8, average log likelihood -1.413392
[ Info: iteration 9, average log likelihood -1.413382
[ Info: iteration 10, average log likelihood -1.413373
┌ Info: EM with 100000 data points 10 iterations avll -1.413373
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
