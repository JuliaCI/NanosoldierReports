Julia Version 1.5.0-DEV.133
Commit c9940ed95b (2020-01-21 18:51 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed Missings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.3
 Installed OrderedCollections â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed QuadGK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.3.1
 Installed ComputationalResources â”€â”€â”€â”€â”€â”€ v0.3.0
 Installed StatsBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.32.0
 Installed MLJBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.10.1
 Installed ScientificTypes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.1
 Installed LossFunctions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.1
 Installed Parsers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.10
 Installed Arpack_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v3.5.0+2
 Installed DataValueInterfaces â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed Reexport â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.0
 Installed BinaryProvider â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.8
 Installed LearnBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.2
 Installed CategoricalArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.7
 Installed Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
 Installed IteratorInterfaceExtensions â”€ v1.0.0
 Installed Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.0
 Installed Tables â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.11
 Installed Formatting â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.1
 Installed OpenSpecFun_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.3+1
 Installed PDMats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.10
 Installed JSON â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.21.0
 Installed DataStructures â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.17.9
 Installed TableTraits â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed StatsFuns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.3
 Installed Crayons â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v4.0.1
 Installed Arpack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed FillArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.4
 Installed FixedPointNumbers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.1
 Installed ProgressMeter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.2.0
 Installed InvertedIndices â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed ColorTypes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.1
 Installed OpenBLAS_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.7+4
 Installed SortingAlgorithms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.1
 Installed Compat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v3.2.0
 Installed DataAPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed RecipesBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.0
 Installed SpecialFunctions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.0
 Installed PrettyTables â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
 Installed Distributions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.21.12
  Updating `~/.julia/environments/v1.5/Project.toml`
  [a7f614a8] + MLJBase v0.10.1
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [b99e7846] + BinaryProvider v0.5.8
  [324d7699] + CategoricalArrays v0.7.7
  [3da002f7] + ColorTypes v0.8.1
  [34da2185] + Compat v3.2.0
  [ed09eef8] + ComputationalResources v0.3.0
  [a8cc5b0e] + Crayons v4.0.1
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [e2d170a0] + DataValueInterfaces v1.0.0
  [31c24e10] + Distributions v0.21.12
  [1a297f60] + FillArrays v0.8.4
  [53c48c17] + FixedPointNumbers v0.7.1
  [59287772] + Formatting v0.4.1
  [41ab1584] + InvertedIndices v1.0.0
  [82899510] + IteratorInterfaceExtensions v1.0.0
  [682c06a0] + JSON v0.21.0
  [7f8f8fb0] + LearnBase v0.2.2
  [30fc2ffe] + LossFunctions v0.5.1
  [a7f614a8] + MLJBase v0.10.1
  [e1d29d7a] + Missings v0.4.3
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [69de0a69] + Parsers v0.3.10
  [08abe8d2] + PrettyTables v0.6.0
  [92933f4c] + ProgressMeter v1.2.0
  [1fd47b50] + QuadGK v2.3.1
  [3cdcf5f2] + RecipesBase v0.7.0
  [189a3867] + Reexport v0.2.0
  [79098fc4] + Rmath v0.6.0
  [321657f4] + ScientificTypes v0.5.1
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [3783bdb8] + TableTraits v1.0.0
  [bd369af6] + Tables v0.2.11
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [9fa8497b] + Future 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath â†’ `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_L8wbQZ/Project.toml`
 [no changes]
  Updating `/tmp/jl_L8wbQZ/Manifest.toml`
 [no changes]
   Testing MLJBase
 Installed ScikitLearnBase â”€â”€â”€ v0.5.0
 Installed Distances â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed MultivariateStats â”€ v0.7.0
 Installed NearestNeighbors â”€â”€ v0.4.4
 Installed DataFrames â”€â”€â”€â”€â”€â”€â”€â”€ v0.20.0
 Installed TypedTables â”€â”€â”€â”€â”€â”€â”€ v1.2.0
 Installed SplitApplyCombine â”€ v1.0.0
 Installed Indexing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed WeakRefStrings â”€â”€â”€â”€ v0.6.2
 Installed DecisionTree â”€â”€â”€â”€â”€â”€ v0.10.1
 Installed PooledArrays â”€â”€â”€â”€â”€â”€ v0.5.3
 Installed FilePathsBase â”€â”€â”€â”€â”€ v0.7.0
 Installed Dictionaries â”€â”€â”€â”€â”€â”€ v0.2.1
 Installed CSV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.22
 Installed StaticArrays â”€â”€â”€â”€â”€â”€ v0.12.1
  Updating `/tmp/jl_I4yXVD/Project.toml`
  [336ed68f] + CSV v0.5.22
  [a93c6f00] + DataFrames v0.20.0
  [7806a523] + DecisionTree v0.10.1
  [b4f34e82] + Distances v0.8.2
  [6f286f6a] + MultivariateStats v0.7.0
  [b8a86587] + NearestNeighbors v0.4.4
  [9d95f2ec] + TypedTables v1.2.0
  Updating `/tmp/jl_I4yXVD/Manifest.toml`
  [336ed68f] + CSV v0.5.22
  [a93c6f00] + DataFrames v0.20.0
  [7806a523] + DecisionTree v0.10.1
  [85a47980] + Dictionaries v0.2.1
  [b4f34e82] + Distances v0.8.2
  [48062228] + FilePathsBase v0.7.0
  [313cdc1a] + Indexing v1.1.0
  [6f286f6a] + MultivariateStats v0.7.0
  [b8a86587] + NearestNeighbors v0.4.4
  [2dfb63ee] + PooledArrays v0.5.3
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [03a91e81] + SplitApplyCombine v1.0.0
  [90137ffa] + StaticArrays v0.12.1
  [9d95f2ec] + TypedTables v1.2.0
  [ea10d353] + WeakRefStrings v0.6.2
Running sandbox
Status `/tmp/jl_I4yXVD/Project.toml`
  [336ed68f] CSV v0.5.22
  [324d7699] CategoricalArrays v0.7.7
  [ed09eef8] ComputationalResources v0.3.0
  [a93c6f00] DataFrames v0.20.0
  [7806a523] DecisionTree v0.10.1
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.12
  [41ab1584] InvertedIndices v1.0.0
  [30fc2ffe] LossFunctions v0.5.1
  [a7f614a8] MLJBase v0.10.1
  [e1d29d7a] Missings v0.4.3
  [6f286f6a] MultivariateStats v0.7.0
  [b8a86587] NearestNeighbors v0.4.4
  [bac558e1] OrderedCollections v1.1.0
  [d96e819e] Parameters v0.12.0
  [08abe8d2] PrettyTables v0.6.0
  [92933f4c] ProgressMeter v1.2.0
  [321657f4] ScientificTypes v0.5.1
  [2913bbd2] StatsBase v0.32.0
  [bd369af6] Tables v0.2.11
  [9d95f2ec] TypedTables v1.2.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [9a3f8284] Random 
  [10745b16] Statistics 
  [8dfed614] Test 
Loading some models for testing...â”Œ Warning: The call to compilecache failed to create a usable precompiled cache file for DecisionTree [7806a523-6efd-50cb-b5f6-3fa6f1930dbb]
â”‚   exception = Required dependency ScikitLearnBase [6e75b9c4-186b-50bd-896f-2d2496a4843e] failed to load from a cache file.
â”” @ Base loading.jl:1041
      From worker 2:	â”Œ Warning: Module Distances with build ID 812252766992462 is missing from the cache.
      From worker 2:	â”‚ This may mean Distances [b4f34e82-e78d-54a5-968a-f98e89d6e8f7] does not support precompilation but is imported by a module that does.
      From worker 2:	â”” @ Base loading.jl:1016
      From worker 3:	â”Œ Warning: Module Distances with build ID 812253063313717 is missing from the cache.
      From worker 3:	â”‚ This may mean Distances [b4f34e82-e78d-54a5-968a-f98e89d6e8f7] does not support precompilation but is imported by a module that does.
      From worker 3:	â”” @ Base loading.jl:1016
â”Œ Warning: The call to compilecache failed to create a usable precompiled cache file for NearestNeighbors [b8a86587-4115-5ab1-83bc-aa920d37bbce]
â”‚   exception = Required dependency StaticArrays [90137ffa-7385-5640-81b9-e52037218182] failed to load from a cache file.
â”” @ Base loading.jl:1041
                                           Test Summary:           | Pass  Total
computational resources |    3      3
Test Summary:   | Pass  Total
model interface |    7      7
Test Summary:          | Pass  Total
one_dimensional_ranges |   39     39
Test Summary:                 | Pass  Total
one_dimensional_range_methods |   19     19
Test Summary:    | Pass  Total
scientific trait |    2      2
Test Summary: | Pass  Total
equality      |   10     10
Test Summary: | Pass  Total
Static type   |    7      7
Test Summary: | Pass  Total
utilities     |   22     22
Test Summary:        | Pass  Total
parameter inspection |    2      2
Test Summary: | Pass  Total
distributions |   49     49
Test Summary: | Pass  Total
info_dict     |   10     10
Test Summary: | Pass  Total
data          |  125    125
Test Summary: | Pass  Total
datasets      |   52     52
Test Summary: | Pass  Total
measures      |  202    202
Test Summary: | Pass  Total
@mlj_model    |   34     34
Test Summary: | Pass  Total
metadatautils |    9      9
Test Summary:      | Pass  Total
pipeline_static.jl |    4      4
[ Info: Training [34mMachine{ConstantClassifier} @ 3â€¦28[39m.
[ Info: Training [34mMachine{ConstantClassifier} @ 1â€¦84[39m.
Test Summary: | Pass  Total
machines      |   21     21
Test Summary: | Pass  Total
networks      |   35     35
[ Info: Training [34mNodalMachine{FeatureSelector} @ 1â€¦81[39m.
[ Info: Training [34mNodalMachine{FooBarRegressor} @ 1â€¦41[39m.
[ Info: Training [34mNodalMachine{SimpleDeterministicCompositeModel} @ 1â€¦69[39m.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 1â€¦58[39m.
[ Info: Training [34mNodalMachine{FooBarRegressor} @ 1â€¦75[39m.
[ Info: Updating [34mNodalMachine{SimpleDeterministicCompositeModel} @ 1â€¦69[39m.
[ Info: Updating [34mNodalMachine{FeatureSelector} @ 1â€¦58[39m.
[ Info: Training [34mNodalMachine{FooBarRegressor} @ 1â€¦75[39m.
[ Info: Training [34mNodalMachine{SimpleDeterministicCompositeModel} @ 1â€¦69[39m.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 1â€¦10[39m.
[ Info: Training [34mNodalMachine{FooBarRegressor} @ 1â€¦53[39m.
[ Info: Training [34mMachine{WrappedRidge} @ 4â€¦81[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 1â€¦16[39m.
[ Info: Training [34mNodalMachine{UnivariateBoxCoxTransformer} @ 1â€¦07[39m.
[ Info: Training [34mNodalMachine{FooBarRegressor} @ 6â€¦32[39m.
[ Info: Updating [34mMachine{WrappedRidge} @ 4â€¦81[39m.
â”Œ Info: Not retraining [34mNodalMachine{Standardizer} @ 1â€¦16[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
â”Œ Info: Not retraining [34mNodalMachine{UnivariateBoxCoxTransformer} @ 1â€¦07[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
[ Info: Updating [34mNodalMachine{FooBarRegressor} @ 6â€¦32[39m.
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 9â€¦72[39m.
[ Info: Spawning 3 sub-features to one-hot encode feature :x1.
[ Info: Training [34mNodalMachine{UnivariateStandardizer} @ 8â€¦98[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 1â€¦98[39m.
[ Info: Training [34mNodalMachine{DecisionTreeRegressor} @ 3â€¦60[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 4â€¦03[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 3â€¦49[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 4â€¦03[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 3â€¦49[39m.
[ Info: Training [34mMachine{Composite3} @ 1â€¦84[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 5â€¦25[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 1â€¦92[39m.
[ Info: Training [34mMachine{Composite3} @ 1â€¦82[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 8â€¦19[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 1â€¦20[39m.
Test Summary: | Pass  Total
composites    |   71     71
[ Info: Training [34mNodalMachine{FeatureSelector} @ 5â€¦52[39m.
[ Info: Training [34mNodalMachine{UnivariateStandardizer} @ 6â€¦06[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 1â€¦22[39m.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 1â€¦08[39m.
[ Info: Training [34mNodalMachine{UnivariateStandardizer} @ 5â€¦21[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 7â€¦04[39m.
[ Info: Updating [34mNodalMachine{FeatureSelector} @ 5â€¦52[39m.
â”Œ Info: Not retraining [34mNodalMachine{UnivariateStandardizer} @ 6â€¦06[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 1â€¦22[39m.
[ Info: Updating [34mNodalMachine{FeatureSelector} @ 1â€¦08[39m.
â”Œ Info: Not retraining [34mNodalMachine{UnivariateStandardizer} @ 5â€¦21[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 7â€¦04[39m.
[ Info: Training [34mMachine{Pipe} @ 4â€¦60[39m.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 1â€¦09[39m.
[ Info: Training [34mNodalMachine{UnivariateStandardizer} @ 4â€¦93[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 1â€¦12[39m.
[ Info: Training [34mMachine{Pipe21} @ 9â€¦68[39m.
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 1â€¦90[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 1â€¦31[39m.
[ Info: Training [34mMachine{Piper3} @ 1â€¦64[39m.
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 1â€¦05[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 1â€¦70[39m.
[ Info: Training [34mMachine{Piper3} @ 8â€¦54[39m.
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 3â€¦83[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 3â€¦49[39m.
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 3â€¦19[39m.
[ Info: Spawning 3 sub-features to one-hot encode feature :x3.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 1â€¦40[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 1â€¦52[39m.
[ Info: Training [34mMachine{Pipe4} @ 8â€¦41[39m.
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 1â€¦27[39m.
[ Info: Spawning 3 sub-features to one-hot encode feature :x3.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 2â€¦22[39m.
[ Info: Training [34mNodalMachine{StaticTransformer} @ 1â€¦43[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 1â€¦39[39m.
[ Info: Training [34mNodalMachine{StaticTransformer} @ 1â€¦60[39m.
[ Info: Training [34mMachine{Pipe9} @ 9â€¦03[39m.
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 9â€¦89[39m.
[ Info: Spawning 2 sub-features to one-hot encode feature :gender.
[ Info: Training [34mNodalMachine{UnivariateStandardizer} @ 4â€¦41[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 1â€¦09[39m.
Test Summary: | Pass  Total
pipelines     |  133    133
[ Info: Training [34mNodalMachine{KNNRegressor} @ 1â€¦72[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 9â€¦15[39m.
[ Info: Training [34mNodalMachine{UnivariateBoxCoxTransformer} @ 7â€¦56[39m.
[ Info: Training [34mNodalMachine{RidgeRegressor} @ 6â€¦49[39m.
â”Œ Info: Not retraining [34mNodalMachine{Standardizer} @ 9â€¦15[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
â”Œ Info: Not retraining [34mNodalMachine{UnivariateBoxCoxTransformer} @ 7â€¦56[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
[ Info: Updating [34mNodalMachine{RidgeRegressor} @ 6â€¦49[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 1â€¦52[39m.
[ Info: Training [34mNodalMachine{PCA} @ 1â€¦26[39m.
â”Œ Info: Not retraining [34mNodalMachine{Standardizer} @ 1â€¦52[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
â”Œ Info: Not retraining [34mNodalMachine{PCA} @ 1â€¦26[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
[ Info: Training [34mNodalMachine{RidgeRegressor} @ 5â€¦10[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 1â€¦45[39m.
[ Info: Training [34mNodalMachine{PCA} @ 3â€¦19[39m.
[ Info: Training [34mNodalMachine{RidgeRegressor} @ 6â€¦81[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 1â€¦83[39m.
[ Info: Training [34mNodalMachine{PCA} @ 3â€¦39[39m.
[ Info: Training [34mNodalMachine{UnivariateBoxCoxTransformer} @ 7â€¦87[39m.
[ Info: Training [34mNodalMachine{RidgeRegressor} @ 1â€¦99[39m.
[ Info: Training [34mNodalMachine{DecisionTreeRegressor} @ 9â€¦28[39m.
[ Info: Training [34mNodalMachine{DecisionTreeRegressor} @ 1â€¦96[39m.
Test Summary: | Pass  Total
arrows        |   12     12
Evaluating over 5 folds:  17%[====>                    ]  ETA: 0:00:00[KEvaluating over 5 folds:  33%[========>                ]  ETA: 0:00:03[KEvaluating over 5 folds:  50%[============>            ]  ETA: 0:00:02[KEvaluating over 5 folds:  67%[================>        ]  ETA: 0:00:01[KEvaluating over 5 folds:  83%[====================>    ]  ETA: 0:00:00[KEvaluating over 5 folds: 100%[=========================] Time: 0:00:01[K
[ Info: Distributing cross-validation computation among 2 workers.
[ Info: Distributing cross-validation computation among 2 workers.
Evaluating over 1 folds:  50%[============>            ]  ETA: 0:00:00[KEvaluating over 1 folds: 100%[=========================] Time: 0:00:00[K
[ Info: Distributing cross-validation computation among 2 workers.
Evaluating over 5 folds:  17%[====>                    ]  ETA: 0:00:00[KEvaluating over 5 folds:  33%[========>                ]  ETA: 0:00:00[KEvaluating over 5 folds:  50%[============>            ]  ETA: 0:00:00[KEvaluating over 5 folds:  67%[================>        ]  ETA: 0:00:00[KEvaluating over 5 folds:  83%[====================>    ]  ETA: 0:00:00[KEvaluating over 5 folds: 100%[=========================] Time: 0:00:00[K
Evaluating over 6 folds:  14%[===>                     ]  ETA: 0:00:00[KEvaluating over 6 folds:  29%[=======>                 ]  ETA: 0:00:00[KEvaluating over 6 folds:  43%[==========>              ]  ETA: 0:00:00[KEvaluating over 6 folds:  57%[==============>          ]  ETA: 0:00:00[KEvaluating over 6 folds:  71%[=================>       ]  ETA: 0:00:00[KEvaluating over 6 folds:  86%[=====================>   ]  ETA: 0:00:00[KEvaluating over 6 folds: 100%[=========================] Time: 0:00:00[K
[ Info: Distributing cross-validation computation among 2 workers.
[ Info: Distributing cross-validation computation among 2 workers.
cv (accelerated with CPUThreads): Test Failed at /home/pkgeval/.julia/packages/MLJBase/t7MaX/test/resampling.jl:157
  Expression: result.per_fold[1] â‰ˆ [1 / 2, 3 / 4, 1 / 2, 3 / 4, 1 / 2]
   Evaluated: [0.5, 0.5, 0.5, 0.5, 0.5] â‰ˆ [0.5, 0.75, 0.5, 0.75, 0.5]
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/MLJBase/t7MaX/test/resampling.jl:157
 [2] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1113
 [3] top-level scope at /home/pkgeval/.julia/packages/MLJBase/t7MaX/test/resampling.jl:146
 [4] top-level scope at /home/pkgeval/.julia/packages/MLJBase/t7MaX/test/test_utilities.jl:36
sample weights in evaluation (accelerated with CPUThreads): Test Failed at /home/pkgeval/.julia/packages/MLJBase/t7MaX/test/resampling.jl:212
  Expression: e â‰ˆ (1 / 3 + 13 / 14) / 2
   Evaluated: 0.7142857142857143 â‰ˆ 0.6309523809523809
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/MLJBase/t7MaX/test/resampling.jl:212
 [2] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1113
 [3] top-level scope at /home/pkgeval/.julia/packages/MLJBase/t7MaX/test/resampling.jl:202
 [4] top-level scope at /home/pkgeval/.julia/packages/MLJBase/t7MaX/test/test_utilities.jl:36
[ Info: Updating [34mMachine{Resampler} @ 1â€¦85[39m.
[ Info: Distributing cross-validation computation among 2 workers.
[ Info: Updating [34mMachine{Resampler} @ 1â€¦44[39m.
[ Info: Distributing cross-validation computation among 2 workers.
Evaluating over 1 folds:  50%[============>            ]  ETA: 0:00:00[KEvaluating over 1 folds: 100%[=========================] Time: 0:00:02[K
[ Info: Distributing cross-validation computation among 2 workers.
Evaluating over 1 folds:  50%[============>            ]  ETA: 0:00:00[KEvaluating over 1 folds: 100%[=========================] Time: 0:00:01[K
[ Info: Passing machine sample weights to any supported measures. 
Evaluating over 1 folds:  50%[============>            ]  ETA: 0:00:00[KEvaluating over 1 folds: 100%[=========================] Time: 0:00:00[K
Evaluating over 1 folds:  50%[============>            ]  ETA: 0:00:00[KEvaluating over 1 folds: 100%[=========================] Time: 0:00:00[K
[ Info: Passing machine sample weights to any supported measures. 
Evaluating over 6 folds:  14%[===>                     ]  ETA: 0:00:00[KEvaluating over 6 folds:  29%[=======>                 ]  ETA: 0:00:08[KEvaluating over 6 folds:  43%[==========>              ]  ETA: 0:00:04[KEvaluating over 6 folds:  57%[==============>          ]  ETA: 0:00:02[KEvaluating over 6 folds:  71%[=================>       ]  ETA: 0:00:01[KEvaluating over 6 folds:  86%[=====================>   ]  ETA: 0:00:01[KEvaluating over 6 folds: 100%[=========================] Time: 0:00:03[K
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Creating subsamples from a subset of all rows. 
Evaluating over 6 folds:  14%[===>                     ]  ETA: 0:00:00[KEvaluating over 6 folds:  29%[=======>                 ]  ETA: 0:00:00[KEvaluating over 6 folds:  43%[==========>              ]  ETA: 0:00:00[KEvaluating over 6 folds:  57%[==============>          ]  ETA: 0:00:00[KEvaluating over 6 folds:  71%[=================>       ]  ETA: 0:00:00[KEvaluating over 6 folds:  86%[=====================>   ]  ETA: 0:00:00[KEvaluating over 6 folds: 100%[=========================] Time: 0:00:00[K
[ Info: Training [34mMachine{Resampler} @ 1â€¦00[39m.
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Passing machine sample weights to any supported measures. 
Evaluating over 6 folds:  14%[===>                     ]  ETA: 0:00:00[KEvaluating over 6 folds:  29%[=======>                 ]  ETA: 0:00:00[KEvaluating over 6 folds:  43%[==========>              ]  ETA: 0:00:00[KEvaluating over 6 folds:  57%[==============>          ]  ETA: 0:00:00[KEvaluating over 6 folds:  71%[=================>       ]  ETA: 0:00:00[KEvaluating over 6 folds:  86%[=====================>   ]  ETA: 0:00:00[KEvaluating over 6 folds: 100%[=========================] Time: 0:00:00[K
[ Info: Training [34mMachine{Resampler} @ 1â€¦08[39m.
Evaluating over 6 folds:  14%[===>                     ]  ETA: 0:00:00[KEvaluating over 6 folds:  29%[=======>                 ]  ETA: 0:00:00[KEvaluating over 6 folds:  43%[==========>              ]  ETA: 0:00:00[KEvaluating over 6 folds:  57%[==============>          ]  ETA: 0:00:00[KEvaluating over 6 folds:  71%[=================>       ]  ETA: 0:00:00[KEvaluating over 6 folds:  86%[=====================>   ]  ETA: 0:00:00[KEvaluating over 6 folds: 100%[=========================] Time: 0:00:00[K
[ Info: Distributing cross-validation computation among 2 workers.
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Distributing cross-validation computation among 2 workers.
[ Info: Distributing cross-validation computation among 2 workers.
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Distributing cross-validation computation among 2 workers.
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Creating subsamples from a subset of all rows. 
[ Info: Distributing cross-validation computation among 2 workers.
[ Info: Training [34mMachine{Resampler} @ 8â€¦68[39m.
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Distributing cross-validation computation among 2 workers.
[ Info: Training [34mMachine{Resampler} @ 1â€¦78[39m.
[ Info: Distributing cross-validation computation among 2 workers.
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Creating subsamples from a subset of all rows. 
[ Info: Training [34mMachine{Resampler} @ 1â€¦89[39m.
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Training [34mMachine{Resampler} @ 4â€¦55[39m.
sample weights in training and evaluation (accelerated with CPUThreads): Test Failed at /home/pkgeval/.julia/packages/MLJBase/t7MaX/test/resampling.jl:360
  Expression: e1 â‰ˆ e2
   Evaluated: 0.7300908762543769 â‰ˆ 0.7592804880536185
Stacktrace:
 [1] top-level scope at /home/pkgeval/.julia/packages/MLJBase/t7MaX/test/resampling.jl:360
 [2] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1113
 [3] top-level scope at /home/pkgeval/.julia/packages/MLJBase/t7MaX/test/resampling.jl:271
 [4] top-level scope at /home/pkgeval/.julia/packages/MLJBase/t7MaX/test/test_utilities.jl:36
Test Summary:                                                                                               | Pass  Fail  Broken  Total
resampling                                                                                                  |  103     3       2    108
  checking measure/model compatibility                                                                      |    8                    8
  folds specified                                                                                           |    9                    9
  folds specified (accelerated with ComputationalResources.CPUProcesses)                                    |                  1      1
  folds specified (accelerated with CPUThreads)                                                             |    9                    9
  repeated resampling                                                                                       |    4                    4
  holdout                                                                                                   |    3                    3
  holdout (accelerated with ComputationalResources.CPUProcesses)                                            |    3                    3
  holdout (accelerated with CPUThreads)                                                                     |    3                    3
  cv                                                                                                        |    3                    3
  cv (accelerated with ComputationalResources.CPUProcesses)                                                 |    3                    3
  cv (accelerated with CPUThreads)                                                                          |    2     1              3
  stratified_cv                                                                                             |    6                    6
  sample weights in evaluation                                                                              |    1                    1
  sample weights in evaluation (accelerated with ComputationalResources.CPUProcesses)                       |    1                    1
  sample weights in evaluation (accelerated with CPUThreads)                                                |          1              1
  resampler as machine                                                                                      |    7                    7
  resampler as machine (accelerated with ComputationalResources.CPUProcesses)                               |                  1      1
  resampler as machine (accelerated with CPUThreads)                                                        |    7                    7
  custom strategy using resampling depending on X, y                                                        |    2                    2
  custom strategy using resampling depending on X, y (accelerated with ComputationalResources.CPUProcesses) |    2                    2
  custom strategy using resampling depending on X, y (accelerated with CPUThreads)                          |    2                    2
  sample weights in training and evaluation                                                                 |    8                    8
  sample weights in training and evaluation (accelerated with ComputationalResources.CPUProcesses)          |    8                    8
  sample weights in training and evaluation (accelerated with CPUThreads)                                   |    7     1              8
ERROR: LoadError: Some tests did not pass: 103 passed, 3 failed, 0 errored, 2 broken.
in expression starting at /home/pkgeval/.julia/packages/MLJBase/t7MaX/test/runtests.jl:114
err = ProcessFailedException(Base.Process[Process(`/opt/julia/bin/julia -Cnative -J/opt/julia/lib/julia/sys.so -g1 --code-coverage=none --color=no --compiled-modules=yes --check-bounds=yes --inline=yes --startup-file=no --track-allocation=none --eval 'append!(empty!(Base.DEPOT_PATH), ["/home/pkgeval/.julia", "/opt/julia/local/share/julia", "/opt/julia/share/julia", "/usr/local/share/julia"])
append!(empty!(Base.DL_LOAD_PATH), String[])

cd("/home/pkgeval/.julia/packages/MLJBase/t7MaX/test")
append!(empty!(ARGS), String[])
include("/home/pkgeval/.julia/packages/MLJBase/t7MaX/test/runtests.jl")
'`, ProcessExited(1))])
ERROR: Package MLJBase errored during testing
Stacktrace:
 [1] pkgerror(::String, ::Vararg{String,N} where N) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/Types.jl:54
 [2] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; coverage::Bool, julia_args::Cmd, test_args::Cmd, test_fn::Nothing) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/Operations.jl:1471
 [3] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; coverage::Bool, test_fn::Nothing, julia_args::Cmd, test_args::Cmd, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:313
 [4] test(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:300
 [5] #test#66 at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:294 [inlined]
 [6] test at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:294 [inlined]
 [7] #test#65 at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:293 [inlined]
 [8] test at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:293 [inlined]
 [9] test(::String; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:292
 [10] test(::String) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:292
 [11] top-level scope at none:13
