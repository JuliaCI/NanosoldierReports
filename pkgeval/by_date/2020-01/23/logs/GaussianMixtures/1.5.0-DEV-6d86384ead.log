Julia Version 1.5.0-DEV.142
Commit 6d86384ead (2020-01-23 18:34 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed GaussianMixtures â”€â”€â”€ v0.3.0
 Installed URIParser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed LegacyStrings â”€â”€â”€â”€â”€â”€ v0.4.1
 Installed OpenBLAS_jll â”€â”€â”€â”€â”€â”€â”€ v0.3.7+4
 Installed DataStructures â”€â”€â”€â”€â”€ v0.17.9
 Installed Clustering â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.13.3
 Installed Distributions â”€â”€â”€â”€â”€â”€ v0.22.3
 Installed CMake â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.2
 Installed OrderedCollections â”€ v1.1.0
 Installed BinaryProvider â”€â”€â”€â”€â”€ v0.5.8
 Installed Missings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.3
 Installed HDF5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.5
 Installed StatsFuns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.3
 Installed OpenSpecFun_jll â”€â”€â”€â”€ v0.5.3+1
 Installed PDMats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.11
 Installed BinDeps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed NearestNeighbors â”€â”€â”€ v0.4.4
 Installed JLD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.1
 Installed Distances â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed Blosc â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.1
 Installed CMakeWrapper â”€â”€â”€â”€â”€â”€â”€ v0.2.3
 Installed Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
 Installed DataAPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed StaticArrays â”€â”€â”€â”€â”€â”€â”€ v0.12.1
 Installed QuadGK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.3.1
 Installed Compat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.2.0
 Installed SpecialFunctions â”€â”€â”€ v0.9.0
 Installed SortingAlgorithms â”€â”€ v0.3.1
 Installed Arpack_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€ v3.5.0+2
 Installed FillArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.4
 Installed StatsBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.32.0
 Installed Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.0
 Installed FileIO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.2.1
 Installed ScikitLearnBase â”€â”€â”€â”€ v0.5.0
   Cloning [7d9fca2a-8960-54d3-9f78-7d1dccf2cb97] Arpack from https://github.com/JuliaLinearAlgebra/Arpack.jl.git
[?25l    Fetching: [>                                        ]  0.0 %[2K[?25h Installed Arpack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake â†’ `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_jpvNCp/Project.toml`
 [no changes]
  Updating `/tmp/jl_jpvNCp/Manifest.toml`
 [no changes]
  Building Blosc â†’ `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_8W3aWh/Project.toml`
 [no changes]
  Updating `/tmp/jl_8W3aWh/Manifest.toml`
 [no changes]
  Building HDF5 â”€â†’ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_fNUOR4/Project.toml`
 [no changes]
  Updating `/tmp/jl_fNUOR4/Manifest.toml`
 [no changes]
  Building Rmath â†’ `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_iex0La/Project.toml`
 [no changes]
  Updating `/tmp/jl_iex0La/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_J8BB3z/Project.toml`
 [no changes]
  Updating `/tmp/jl_J8BB3z/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_J8BB3z/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.11
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -692950.1717513413, [24496.95682119794, 75503.04317880208], [8973.514188956056 -8378.336930521595 5156.262966914093; -8869.43754365842 8593.542224921262 -5191.6591384445255], [[16806.027864204254 -6969.337779222347 -10206.373891666408; -6969.3377792223455 22171.193990471424 -4296.593600790945; -10206.373891666408 -4296.593600790945 17726.247896621506], [83908.38294680696 6549.710865023185 10505.46239504293; 6549.710865023185 78444.48571418725 3616.428296310596; 10505.46239504293 3616.428296310596 82331.60847201584]])
â”Œ Warning: rmprocs: process 1 not removed
â”” @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       2.279165e+03
      1       1.398405e+03      -8.807596e+02 |        5
      2       1.302532e+03      -9.587343e+01 |        2
      3       1.246455e+03      -5.607680e+01 |        2
      4       1.183163e+03      -6.329186e+01 |        2
      5       1.108085e+03      -7.507761e+01 |        0
      6       1.108085e+03       0.000000e+00 |        0
K-means converged with 6 iterations (objv = 1108.08546594757)
â”Œ Info: K-means with 272 data points using 6 iterations
â”” 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
â”Œ Info: EM with 272 data points 0 iterations avll -2.083919
â”” 5.8 data points per parameter
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
â”” @ Core ./broadcast.jl:631
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
â”” @ Core ./broadcast.jl:631
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
â”” @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.757421
[ Info: iteration 2, lowerbound -3.624766
[ Info: iteration 3, lowerbound -3.466140
[ Info: iteration 4, lowerbound -3.255593
[ Info: iteration 5, lowerbound -3.012342
[ Info: iteration 6, lowerbound -2.783630
[ Info: dropping number of Gaussions to 6
[ Info: iteration 7, lowerbound -2.593988
[ Info: iteration 8, lowerbound -2.464135
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.393615
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.344575
[ Info: iteration 11, lowerbound -2.322002
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.311122
[ Info: dropping number of Gaussions to 2
[ Info: iteration 13, lowerbound -2.302930
[ Info: iteration 14, lowerbound -2.299262
[ Info: iteration 15, lowerbound -2.299257
[ Info: iteration 16, lowerbound -2.299255
[ Info: iteration 17, lowerbound -2.299254
[ Info: iteration 18, lowerbound -2.299253
[ Info: iteration 19, lowerbound -2.299253
[ Info: iteration 20, lowerbound -2.299253
[ Info: iteration 21, lowerbound -2.299253
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Thu Jan 23 20:55:56 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Thu Jan 23 20:56:04 2020: K-means with 272 data points using 6 iterations
11.3 data points per parameter
, Thu Jan 23 20:56:06 2020: EM with 272 data points 0 iterations avll -2.083919
5.8 data points per parameter
, Thu Jan 23 20:56:08 2020: GMM converted to Variational GMM
, Thu Jan 23 20:56:16 2020: iteration 1, lowerbound -3.757421
, Thu Jan 23 20:56:16 2020: iteration 2, lowerbound -3.624766
, Thu Jan 23 20:56:16 2020: iteration 3, lowerbound -3.466140
, Thu Jan 23 20:56:16 2020: iteration 4, lowerbound -3.255593
, Thu Jan 23 20:56:16 2020: iteration 5, lowerbound -3.012342
, Thu Jan 23 20:56:16 2020: iteration 6, lowerbound -2.783630
, Thu Jan 23 20:56:16 2020: dropping number of Gaussions to 6
, Thu Jan 23 20:56:16 2020: iteration 7, lowerbound -2.593988
, Thu Jan 23 20:56:16 2020: iteration 8, lowerbound -2.464135
, Thu Jan 23 20:56:16 2020: dropping number of Gaussions to 5
, Thu Jan 23 20:56:16 2020: iteration 9, lowerbound -2.393615
, Thu Jan 23 20:56:16 2020: dropping number of Gaussions to 4
, Thu Jan 23 20:56:16 2020: iteration 10, lowerbound -2.344575
, Thu Jan 23 20:56:16 2020: iteration 11, lowerbound -2.322002
, Thu Jan 23 20:56:16 2020: dropping number of Gaussions to 3
, Thu Jan 23 20:56:16 2020: iteration 12, lowerbound -2.311122
, Thu Jan 23 20:56:16 2020: dropping number of Gaussions to 2
, Thu Jan 23 20:56:16 2020: iteration 13, lowerbound -2.302930
, Thu Jan 23 20:56:16 2020: iteration 14, lowerbound -2.299262
, Thu Jan 23 20:56:16 2020: iteration 15, lowerbound -2.299257
, Thu Jan 23 20:56:16 2020: iteration 16, lowerbound -2.299255
, Thu Jan 23 20:56:16 2020: iteration 17, lowerbound -2.299254
, Thu Jan 23 20:56:16 2020: iteration 18, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 19, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 20, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 21, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 22, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 23, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 24, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 25, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 26, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 27, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 28, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 29, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 30, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 31, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 32, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 33, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 34, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 35, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 36, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 37, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 38, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 39, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 40, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 41, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 42, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 43, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 44, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 45, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 46, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 47, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 48, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 49, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: iteration 50, lowerbound -2.299253
, Thu Jan 23 20:56:16 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [95.9549077739863, 178.04509222601374]
Î² = [95.9549077739863, 178.04509222601374]
m = [2.0002292577753717 53.85198717246131; 4.250300733269911 79.28686694436186]
Î½ = [97.9549077739863, 180.04509222601374]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763611948368 -0.008953123827345994; 0.0 0.012748664777409465], [0.1840415554748431 -0.0076440490423270845; 0.0 0.00858170516633351]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999996
avll from stats: -0.9565727623559008
avll from llpg:  -0.9565727623484839
avll direct:     -0.9565727623484839
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9913848792635859
avll from llpg:  -0.9913848792635861
avll direct:     -0.991384879263586
sum posterior: 100000.0
32Ã—26 Array{Float64,2}:
 -0.0145124    -0.0330047   -0.113702    -0.0836511     0.106991    -0.20249     -0.0351457   -0.0916942    0.0523469   -0.0158898   -0.14093     -0.0402336    0.0375473    0.0515135   -6.95794e-5   0.0271528  -0.0144836    0.0330331    0.105941     0.128907     0.146446     0.0475237   -0.0414234   -0.0116469    0.00373415   0.0592332
  0.0281918    -0.0452561   -0.10395      0.0755746    -0.0276099   -0.0435762   -0.163548    -0.0810947   -0.0737039   -0.177152    -0.102796     0.0945923   -0.0479663    0.0947726    0.0351732    0.017129    0.0369666    0.0127599   -0.224721    -0.095868    -0.0941942    0.0216072   -0.0356554   -0.105566    -0.0862895   -0.0223075
 -0.0122516     0.111664    -0.0737806   -0.0148567     0.127057     0.0821556    0.0170721   -0.172825     0.144682    -0.086588     0.114459    -0.0516613   -0.111381    -0.0925063    0.157159     0.0390877   0.0247752   -0.00971808  -0.112743     0.0746549   -0.0533879   -0.0877472    0.0639645    0.0512771    0.132585     0.13466
 -0.00413439    0.0536503   -0.0689769   -0.0549628     0.121228    -0.0440692   -0.134179    -0.112115    -0.0448897   -0.0537506    0.0919226    0.0712941    0.140844     0.127268     0.0583263    0.0932216  -0.0150168    0.199064     0.0480353   -0.215777    -0.0621654    0.122954     0.0471554    0.0272906   -0.00846257  -0.0699486
  0.0803307     0.113897     0.117841     0.0275794    -0.00466014   0.122591     0.184206     0.0659243    0.0350109    0.12303     -0.01653      0.00721415  -0.104698    -0.0460943   -0.0515531   -0.080547   -0.0282857   -0.129423     0.126219    -0.0284685   -0.103318     0.0484009    0.0386496    0.116268     0.099026    -0.0739105
  0.000317291  -0.112975     0.0362011   -0.0169495    -0.0671318    0.0563241   -0.00815579   0.0585878    0.150476     0.245232    -0.141351     0.0491406   -0.0114445    0.0144032   -0.132368     0.200339    0.141628     0.109625    -0.14179     -0.0039624   -0.169728    -0.176187    -0.0632294   -0.171356     0.0693107   -0.0363998
 -0.0354951    -0.0984559    0.0827246    0.0507436     0.134057    -0.00782312   0.183212    -0.122659    -0.107481    -0.0678844    0.119129     0.0254073    0.108763    -0.0232479    0.229002    -0.0908824  -0.103485     0.0638866    0.130671    -0.00931064  -0.171021     0.170123    -0.0666293    0.131971     0.019182     0.184502
 -0.0143181    -0.110813    -0.0948574    0.0388514     0.108566    -0.0948935   -0.190331    -0.0746951   -0.103581    -0.149804    -0.0363703   -0.0734026    0.00630887   0.131628    -0.0657757   -0.133535    0.0310087   -0.15558      0.0262204    0.0635307   -0.0206742    0.125542    -0.0231951    0.11336     -0.0223833    0.07608
  0.0787133    -0.00499646   0.0184712   -0.0857951    -0.0165891   -0.00592538   0.0140719    0.0151181   -0.00254622   0.0853692    0.0506915    0.0648944   -0.0660053    0.102214    -0.0432209   -0.0337631   0.00276224   0.0376301    0.147331    -0.0215059    0.0926406   -0.0527348    0.0756487   -0.121038     0.0860538    0.0703463
  0.0330872    -0.112974     0.103671    -0.157692      0.0678935   -0.062011     0.274743     0.180339    -0.0777456   -0.00972752  -0.00826084   0.0479289   -0.24314      0.117939     0.111837    -0.0528775   0.165756    -0.0598708    0.0870636    0.127485    -0.0108489    0.071794    -0.048039    -0.0313675    0.0607882   -0.0369383
 -0.0918223     0.0735547    0.105754    -0.0744549     0.0955782    0.130372    -0.0527331    0.00147805  -0.0874656   -0.120765    -8.20495e-5  -0.222878     0.0740153    0.0351935   -0.109943     0.0607693  -0.148577     0.201652     0.0897299    0.0233529   -0.0206602    0.100824    -0.0692618   -0.0994393    0.0720733    0.00580986
 -0.093788      0.0127778    0.147671     0.0292155     0.00865769   0.0190541   -0.0499957   -0.0475175   -0.12598     -0.0214858   -0.0538375    0.00702614  -0.0500789    0.0840734   -0.0457231    0.0534297  -0.0499469   -0.052737     0.050076    -0.00621058   0.0808597    0.0953893    0.0200928    0.00391259  -0.0834559    0.0217413
 -0.124932     -0.00552354  -0.036279     0.177021      0.0608494   -0.128234    -0.0559558   -0.0696889    0.0626684   -0.0977484    0.0389544    0.121292    -0.0493879    0.0442978   -0.0423924   -0.0800978   0.156061     0.0535653    0.0354036   -0.0951455    0.130347     0.0408703   -0.144439     0.0550571   -0.0264872   -0.0897398
 -0.0136036    -0.0884293   -0.0022981    0.0321376    -0.0443564   -0.12695      0.00362274  -0.0979911    0.00235661   0.0161397    0.0222288    0.0420957   -0.126309     0.0703801   -0.153402     0.0260638   0.1879      -0.0308945    0.021436     0.0400886   -0.0270083    0.0608701   -0.0709645    0.0598838    0.00731433  -0.290009
 -0.0380075    -0.138398     0.0639029    0.0199491     0.0636679    0.0676628    0.0117134   -0.0416088    0.0984422   -0.122154    -0.171476    -0.0823938   -0.0171597    0.175243     0.122088     0.124939   -0.113764    -0.16055      0.108584     0.121308     0.0139681   -0.0480793   -0.0412856   -0.161199    -0.11847      0.00921058
  0.0610129     0.225651     0.128788    -0.0501162     0.0972391    0.114507     0.109047     0.116028    -0.0695243   -0.0391253    0.123106     0.0387616   -0.00312178   0.0292749   -0.0656007   -0.0274558   0.0527973    0.0179589   -0.146896     0.155789     0.0208885    0.0477424    0.0615211   -0.101798     0.122366    -0.000541534
  0.123052     -0.0376254    0.044904     0.178447     -0.116378    -0.0476502    0.110122    -0.0519125   -0.0116416    0.0991309   -0.0662923   -0.0546234    0.00295076   0.194435    -0.0120349    0.0442279   0.0238453   -0.0293133    0.0877915    0.0982387   -0.0904455   -0.0697486   -0.141418     0.0216688    0.0553159   -0.0678489
  0.00412972   -0.115832    -0.129672    -0.116764      0.0594536   -0.142806     0.0428952   -0.0740853    0.128724    -0.129484    -0.0263136    0.110723    -0.0795535   -0.104426    -0.0489378   -0.181525   -0.0347338   -0.254297    -0.00498246  -0.157485    -0.0197469   -0.167596     0.0483706    0.0324898    0.0982977    0.00646176
  0.0654429     0.141045     0.0893796    0.0356872    -0.250557     0.0900476    0.0782664    0.0765715   -0.0160283   -0.129751    -0.0762649   -0.0979534    0.207943    -0.00439728   5.85434e-5  -0.0339686  -0.08476     -0.0987641   -0.0600336   -0.0303933    0.047533     0.13138     -0.0574098   -0.0347019   -0.0493838    0.0613134
  0.129135     -0.145466    -0.0822588    0.111814     -0.19739     -0.0631759    0.0822773    0.139918    -0.0474937    0.158937     0.0453292    0.0233104   -0.0588613    0.0796124   -0.0219726    0.0955941  -0.0154563   -0.0773159    0.0449473   -0.125152    -0.0377547    0.173512    -0.0863495    0.084165    -0.166026     0.0020002
  0.125096      0.0823034    0.0795766    0.177415      0.0150707   -0.178171    -0.146906    -0.01827      0.0597238   -0.112382     0.0527976    0.0730556    0.0357822    0.0793176    0.0842519   -0.0837902  -0.103273    -0.0238808    0.0534543   -0.0547711    0.0372617   -0.0917142   -0.192481     0.0881851   -0.0648717    0.0312479
  0.0523969    -0.179176    -0.0528131   -0.0604355    -0.0859834    0.0363623   -0.0374119    0.0721203    0.141652    -0.133825     0.0343715   -0.0793886   -0.0339999   -0.03985      0.0541823   -0.0627183  -0.0368157   -0.21722     -0.00297358   0.0257113   -0.10079     -0.144863     0.0896555    0.0499269    0.153299     0.181415
 -0.0140999     0.186869    -0.0798183   -0.075256     -0.011347     0.222735     0.0821376    0.137682     0.106049     0.213323     0.0508617    0.048915     0.136683    -0.134643    -0.101518    -0.140533    0.0209587    0.00753148  -0.0484945   -0.195104     0.122883    -0.0220327    0.00764943  -0.146426     0.092314    -0.00464992
 -0.069264      0.0147857   -0.10874      0.160088     -0.0759585    0.100546     0.115017    -0.0861214   -0.157712     0.0891765   -0.0228093    0.0661499   -0.0754663   -0.0415464   -0.0722768   -0.0454727  -0.18611     -0.160464    -0.00243253   0.0493236    0.0829869    0.0588017   -0.0499337    0.003685     0.129122     0.00525221
 -0.0973194     0.212594    -0.00664569  -0.015668      0.0705119   -0.142285     0.00443228  -0.041577     0.138911     0.00148694  -0.0418653    0.0866628   -0.157257    -0.0259165   -0.114569     0.103709    0.0444383   -0.147259    -0.0819967    0.0475715    0.00270169  -0.124757     0.0432122   -0.0335661    0.0927627   -0.00374348
 -0.0184202     0.0661273    0.0546906    0.0463798     0.0238192    0.00470334   0.0645463    0.0440559   -0.0724661   -0.076805     0.0810591   -0.0513505    0.0531682    0.355718     0.0577284    0.0308914   0.131236    -0.0671519   -0.0222229   -0.0222879    0.100199     0.0176339   -0.0221702    0.00212386  -0.107642     0.090594
 -0.0325976     0.275455     0.015541     0.000146231   0.0133915    0.129912     0.113031    -0.126021     0.0913579    0.0449966    0.0290178   -0.164262     0.199532    -0.120084    -0.10983      0.154884   -0.1825      -0.172869     0.0747726    0.0877354   -0.128181    -0.0825599    0.0506952   -0.0783744   -0.0271657    0.0793694
 -0.175683     -0.00848131  -0.0614564   -0.00940644    0.149805     0.068565    -0.0324843   -0.0741631    0.0602356    0.0443967    0.14163     -0.0793004   -0.0260116    0.0578187    0.124184    -0.0658946   0.107089     0.147772    -0.00724199   0.0392787   -0.0889805    0.00579139  -0.0470325   -0.117521    -0.102781    -0.213834
  0.0509775     0.180526     0.00831889   0.194892      0.0375371    0.0473582   -0.130251     0.125339    -0.0940652    0.0511851    0.0425565   -0.0547665   -0.0441536   -0.0395667    0.0710913    0.122968    0.0948036   -0.0327769   -0.0692488   -0.0668295    0.197891    -0.126886     0.00667205   0.114879    -0.0708702    0.113038
  0.197326      0.0824238   -0.14824      0.222875      0.0752297    0.0371858   -0.0655315   -0.167857     0.0188311    0.0231678    0.0253984    0.0594757    0.0673108    0.019917     0.149283    -0.122288    0.109454    -0.0826928   -0.0616724   -0.0692821   -0.00815004   0.0517586    0.0313883    0.150701    -0.11176      0.0364862
 -0.12285       0.210788    -0.156761     0.13539      -0.00527998  -0.0556136    0.0789389   -0.0419596    0.00884161  -0.0201347    0.0791779    0.0762705    0.0786898   -0.0883569   -0.0210741   -0.0994147  -0.064356     0.124443    -0.0976078   -0.0336788   -0.0255549   -0.18232     -0.0662856    0.0105745    0.0314134    0.0668418
  0.0435027    -0.0892656   -0.00704257   0.0240363     0.262379    -0.0706791    0.0282092    0.0311981   -0.0258029    0.122191     0.116045    -0.0496452   -0.145325     0.0658519    0.061946    -0.0560386   0.0346995   -0.100232     0.0455465   -0.0652602    0.118058    -0.0231467    0.166342    -0.0655319    0.133534     0.065781kind diag, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.4071513220664638
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407206
[ Info: iteration 2, average log likelihood -1.407155
[ Info: iteration 3, average log likelihood -1.406893
[ Info: iteration 4, average log likelihood -1.403187
[ Info: iteration 5, average log likelihood -1.387154
[ Info: iteration 6, average log likelihood -1.374936
[ Info: iteration 7, average log likelihood -1.372478
[ Info: iteration 8, average log likelihood -1.371757
[ Info: iteration 9, average log likelihood -1.371377
[ Info: iteration 10, average log likelihood -1.371130
[ Info: iteration 11, average log likelihood -1.370948
[ Info: iteration 12, average log likelihood -1.370799
[ Info: iteration 13, average log likelihood -1.370671
[ Info: iteration 14, average log likelihood -1.370560
[ Info: iteration 15, average log likelihood -1.370462
[ Info: iteration 16, average log likelihood -1.370376
[ Info: iteration 17, average log likelihood -1.370299
[ Info: iteration 18, average log likelihood -1.370230
[ Info: iteration 19, average log likelihood -1.370169
[ Info: iteration 20, average log likelihood -1.370116
[ Info: iteration 21, average log likelihood -1.370072
[ Info: iteration 22, average log likelihood -1.370040
[ Info: iteration 23, average log likelihood -1.370016
[ Info: iteration 24, average log likelihood -1.369998
[ Info: iteration 25, average log likelihood -1.369986
[ Info: iteration 26, average log likelihood -1.369977
[ Info: iteration 27, average log likelihood -1.369970
[ Info: iteration 28, average log likelihood -1.369965
[ Info: iteration 29, average log likelihood -1.369962
[ Info: iteration 30, average log likelihood -1.369959
[ Info: iteration 31, average log likelihood -1.369957
[ Info: iteration 32, average log likelihood -1.369956
[ Info: iteration 33, average log likelihood -1.369954
[ Info: iteration 34, average log likelihood -1.369953
[ Info: iteration 35, average log likelihood -1.369952
[ Info: iteration 36, average log likelihood -1.369952
[ Info: iteration 37, average log likelihood -1.369951
[ Info: iteration 38, average log likelihood -1.369950
[ Info: iteration 39, average log likelihood -1.369949
[ Info: iteration 40, average log likelihood -1.369949
[ Info: iteration 41, average log likelihood -1.369948
[ Info: iteration 42, average log likelihood -1.369947
[ Info: iteration 43, average log likelihood -1.369946
[ Info: iteration 44, average log likelihood -1.369945
[ Info: iteration 45, average log likelihood -1.369944
[ Info: iteration 46, average log likelihood -1.369943
[ Info: iteration 47, average log likelihood -1.369942
[ Info: iteration 48, average log likelihood -1.369941
[ Info: iteration 49, average log likelihood -1.369939
[ Info: iteration 50, average log likelihood -1.369937
â”Œ Info: EM with 100000 data points 50 iterations avll -1.369937
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4072056200911491
â”‚     -1.4071547051941184
â”‚      â‹®
â””     -1.3699374463618537
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.370058
[ Info: iteration 2, average log likelihood -1.369947
[ Info: iteration 3, average log likelihood -1.369578
[ Info: iteration 4, average log likelihood -1.366348
[ Info: iteration 5, average log likelihood -1.354853
[ Info: iteration 6, average log likelihood -1.343908
[ Info: iteration 7, average log likelihood -1.339122
[ Info: iteration 8, average log likelihood -1.336579
[ Info: iteration 9, average log likelihood -1.334710
[ Info: iteration 10, average log likelihood -1.333215
[ Info: iteration 11, average log likelihood -1.331971
[ Info: iteration 12, average log likelihood -1.330946
[ Info: iteration 13, average log likelihood -1.330130
[ Info: iteration 14, average log likelihood -1.329475
[ Info: iteration 15, average log likelihood -1.328917
[ Info: iteration 16, average log likelihood -1.328444
[ Info: iteration 17, average log likelihood -1.328078
[ Info: iteration 18, average log likelihood -1.327817
[ Info: iteration 19, average log likelihood -1.327639
[ Info: iteration 20, average log likelihood -1.327517
[ Info: iteration 21, average log likelihood -1.327436
[ Info: iteration 22, average log likelihood -1.327383
[ Info: iteration 23, average log likelihood -1.327350
[ Info: iteration 24, average log likelihood -1.327328
[ Info: iteration 25, average log likelihood -1.327315
[ Info: iteration 26, average log likelihood -1.327307
[ Info: iteration 27, average log likelihood -1.327301
[ Info: iteration 28, average log likelihood -1.327298
[ Info: iteration 29, average log likelihood -1.327296
[ Info: iteration 30, average log likelihood -1.327294
[ Info: iteration 31, average log likelihood -1.327293
[ Info: iteration 32, average log likelihood -1.327292
[ Info: iteration 33, average log likelihood -1.327292
[ Info: iteration 34, average log likelihood -1.327292
[ Info: iteration 35, average log likelihood -1.327291
[ Info: iteration 36, average log likelihood -1.327291
[ Info: iteration 37, average log likelihood -1.327291
[ Info: iteration 38, average log likelihood -1.327291
[ Info: iteration 39, average log likelihood -1.327291
[ Info: iteration 40, average log likelihood -1.327291
[ Info: iteration 41, average log likelihood -1.327291
[ Info: iteration 42, average log likelihood -1.327291
[ Info: iteration 43, average log likelihood -1.327291
[ Info: iteration 44, average log likelihood -1.327291
[ Info: iteration 45, average log likelihood -1.327291
[ Info: iteration 46, average log likelihood -1.327291
[ Info: iteration 47, average log likelihood -1.327291
[ Info: iteration 48, average log likelihood -1.327290
[ Info: iteration 49, average log likelihood -1.327290
[ Info: iteration 50, average log likelihood -1.327290
â”Œ Info: EM with 100000 data points 50 iterations avll -1.327290
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3700583818004597
â”‚     -1.3699465756899212
â”‚      â‹®
â””     -1.3272904775253354
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.327452
[ Info: iteration 2, average log likelihood -1.327294
[ Info: iteration 3, average log likelihood -1.326469
[ Info: iteration 4, average log likelihood -1.316727
[ Info: iteration 5, average log likelihood -1.293849
[ Info: iteration 6, average log likelihood -1.279502
[ Info: iteration 7, average log likelihood -1.274633
[ Info: iteration 8, average log likelihood -1.272801
[ Info: iteration 9, average log likelihood -1.271817
[ Info: iteration 10, average log likelihood -1.271148
[ Info: iteration 11, average log likelihood -1.270624
[ Info: iteration 12, average log likelihood -1.270188
[ Info: iteration 13, average log likelihood -1.269791
[ Info: iteration 14, average log likelihood -1.269390
[ Info: iteration 15, average log likelihood -1.268996
[ Info: iteration 16, average log likelihood -1.268629
[ Info: iteration 17, average log likelihood -1.268317
[ Info: iteration 18, average log likelihood -1.268080
[ Info: iteration 19, average log likelihood -1.267902
[ Info: iteration 20, average log likelihood -1.267757
[ Info: iteration 21, average log likelihood -1.267633
[ Info: iteration 22, average log likelihood -1.267525
[ Info: iteration 23, average log likelihood -1.267431
[ Info: iteration 24, average log likelihood -1.267351
[ Info: iteration 25, average log likelihood -1.267283
[ Info: iteration 26, average log likelihood -1.267226
[ Info: iteration 27, average log likelihood -1.267176
[ Info: iteration 28, average log likelihood -1.267130
[ Info: iteration 29, average log likelihood -1.267089
[ Info: iteration 30, average log likelihood -1.267051
[ Info: iteration 31, average log likelihood -1.267016
[ Info: iteration 32, average log likelihood -1.266983
[ Info: iteration 33, average log likelihood -1.266953
[ Info: iteration 34, average log likelihood -1.266925
[ Info: iteration 35, average log likelihood -1.266900
[ Info: iteration 36, average log likelihood -1.266879
[ Info: iteration 37, average log likelihood -1.266863
[ Info: iteration 38, average log likelihood -1.266850
[ Info: iteration 39, average log likelihood -1.266841
[ Info: iteration 40, average log likelihood -1.266834
[ Info: iteration 41, average log likelihood -1.266829
[ Info: iteration 42, average log likelihood -1.266826
[ Info: iteration 43, average log likelihood -1.266823
[ Info: iteration 44, average log likelihood -1.266821
[ Info: iteration 45, average log likelihood -1.266820
[ Info: iteration 46, average log likelihood -1.266818
[ Info: iteration 47, average log likelihood -1.266817
[ Info: iteration 48, average log likelihood -1.266816
[ Info: iteration 49, average log likelihood -1.266815
[ Info: iteration 50, average log likelihood -1.266814
â”Œ Info: EM with 100000 data points 50 iterations avll -1.266814
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.327451738151047
â”‚     -1.3272940281267873
â”‚      â‹®
â””     -1.266814080478803
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.267029
[ Info: iteration 2, average log likelihood -1.266790
[ Info: iteration 3, average log likelihood -1.265888
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     10
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.254814
[ Info: iteration 5, average log likelihood -1.235669
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     10
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.202795
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.203606
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.194907
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.189817
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     10
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.191778
[ Info: iteration 11, average log likelihood -1.194009
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     10
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.180605
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      5
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.189991
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.195965
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.187927
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     10
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.188194
[ Info: iteration 17, average log likelihood -1.190745
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     10
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.177901
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.189210
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.184432
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.181534
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     10
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.184279
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.188699
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.184109
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.181373
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     10
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.183933
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.188289
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.183554
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.180732
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     10
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.183224
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.187569
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.182700
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.179635
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     10
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.181714
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.185841
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.181037
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.178356
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     10
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.180946
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.185489
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.180844
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.178221
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     10
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.180815
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.185371
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.180710
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.178089
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     10
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.180642
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.185160
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.180418
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.177704
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     10
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.180108
â”Œ Info: EM with 100000 data points 50 iterations avll -1.180108
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.2670292865628783
â”‚     -1.2667896437851387
â”‚      â‹®
â””     -1.180108066009057
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.184805
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     19
â”‚     20
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.172222
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     19
â”‚     20
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.181821
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     19
â”‚     20
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.156504
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      1
â”‚      9
â”‚     19
â”‚     20
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.099305
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚     10
â”‚     13
â”‚     19
â”‚     20
â”‚     23
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.085535
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚     11
â”‚     19
â”‚     20
â”‚     21
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.085086
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      9
â”‚     19
â”‚     20
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.086578
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚     10
â”‚     13
â”‚     19
â”‚     20
â”‚     23
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.068998
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     11
â”‚     19
â”‚     20
â”‚     21
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.090895
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      9
â”‚     19
â”‚     20
â”‚     29
â”‚     30
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.077568
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     10
â”‚     13
â”‚     19
â”‚     20
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.076155
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚     11
â”‚     19
â”‚     20
â”‚     21
â”‚     23
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.074825
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      9
â”‚     19
â”‚     20
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.089689
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚     10
â”‚     13
â”‚     19
â”‚     20
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.070424
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     11
â”‚     19
â”‚     20
â”‚     21
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.084473
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      9
â”‚     19
â”‚     20
â”‚     23
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.073664
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     10
â”‚     13
â”‚     19
â”‚     20
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.081327
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚     11
â”‚     19
â”‚     20
â”‚     21
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.077433
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      9
â”‚     19
â”‚     20
â”‚     23
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.082497
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚     10
â”‚     13
â”‚     19
â”‚     20
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.073099
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     11
â”‚     19
â”‚     20
â”‚     21
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.085286
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      9
â”‚     19
â”‚     20
â”‚     23
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.074000
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     10
â”‚     13
â”‚     19
â”‚     20
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.080624
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚     11
â”‚     19
â”‚     20
â”‚     21
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.077126
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      9
â”‚     19
â”‚     20
â”‚     23
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.082291
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚     10
â”‚     13
â”‚     19
â”‚     20
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.072961
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     11
â”‚     19
â”‚     20
â”‚     21
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.085283
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      9
â”‚     19
â”‚     20
â”‚     23
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.074004
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     10
â”‚     13
â”‚     19
â”‚     20
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.080614
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚     11
â”‚     19
â”‚     20
â”‚     21
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.077132
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      9
â”‚     19
â”‚     20
â”‚     23
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.082287
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚     10
â”‚     13
â”‚     19
â”‚     20
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.072957
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     11
â”‚     19
â”‚     20
â”‚     21
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.085280
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      9
â”‚     19
â”‚     20
â”‚     23
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.074001
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     10
â”‚     13
â”‚     19
â”‚     20
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.080610
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚     11
â”‚     19
â”‚     20
â”‚     21
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.077129
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      9
â”‚     19
â”‚     20
â”‚     23
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.082283
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚     10
â”‚     13
â”‚     19
â”‚     20
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.072953
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     11
â”‚     19
â”‚     20
â”‚     21
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.085277
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      9
â”‚     19
â”‚     20
â”‚     23
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.073998
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     10
â”‚     13
â”‚     19
â”‚     20
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.080606
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚     11
â”‚     19
â”‚     20
â”‚     21
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.077126
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      9
â”‚     19
â”‚     20
â”‚     23
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.082280
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚     10
â”‚     13
â”‚     19
â”‚     20
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.072950
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     11
â”‚     19
â”‚     20
â”‚     21
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.085273
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      9
â”‚     19
â”‚     20
â”‚     23
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.073994
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     10
â”‚     13
â”‚     19
â”‚     20
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.080602
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚     11
â”‚     19
â”‚     20
â”‚     21
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.077122
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      9
â”‚     19
â”‚     20
â”‚     23
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.082276
â”Œ Info: EM with 100000 data points 50 iterations avll -1.082276
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.184805115389593
â”‚     -1.1722224082223476
â”‚      â‹®
â””     -1.0822764427951064
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.4071513220664638
â”‚     -1.4072056200911491
â”‚     -1.4071547051941184
â”‚     -1.4068934748591615
â”‚      â‹®
â”‚     -1.0806019634011874
â”‚     -1.077122429847662
â””     -1.0822764427951064
32Ã—26 Array{Float64,2}:
  0.0022511   -0.111135    -0.113195    -0.113762     0.0640037   -0.131736     0.0715465    -0.0768886     0.0969629   -0.118422    -0.0255664   0.084678    -0.0832703   -0.0959753   -0.0601236   -0.179292   -0.0843182   -0.240227    -0.00068887  -0.149711    -0.017179    -0.153226     0.0467527    0.0179055    0.131231      0.00846981
 -0.0266527   -0.0951126   -0.00266465   0.024913     0.261961    -0.0225648    0.0244832     0.0854974    -0.0326506    0.132701     0.175445   -0.0474437   -0.145264     0.0690178    0.0514158   -0.067427    0.0516221   -0.160277     0.04901     -0.0481098    0.172954    -0.0135355    0.183468    -0.073462     0.146254      0.0722811
  0.0375835   -0.0679626    0.0416029   -0.0681155    0.00882804  -0.0616595    0.112295      0.0472116    -0.0251024    0.0196635    0.0190364   0.0405662   -0.147595     0.099011    -0.0250341   -0.0115994   0.123       -0.0215194    0.0700292    0.0536469   -0.0095616    0.0260401   -0.0092873   -0.0479986    0.0425594    -0.0798445
  0.0731627   -0.0994915    0.00576826   0.0633864   -0.0978901    0.00201926  -0.00506794   -0.00208099    0.0515741   -0.00680455  -0.047289   -0.0504892   -0.0269886    0.0819471    0.0260439    0.0121879  -0.00581467  -0.101142     0.0544608    0.0682475   -0.0733878   -0.0965296   -0.0251025    0.032212     0.0686684     0.0523922
 -0.0392045   -0.135464     0.0642876    0.0408764    0.0672216    0.0731726    0.00848737   -0.0203182     0.0979973   -0.0852849   -0.215369   -0.0786608   -0.014056     0.183473     0.0977775    0.108631   -0.111393    -0.164408     0.128551     0.124169     0.0180576   -0.0383567   -0.0218182   -0.16037     -0.11589       0.0173352
  0.0420239    0.0363107   -0.00618101   0.0824347   -0.0228426    0.0575115   -0.000775949  -0.000493213  -0.0176643   -0.0326142   -0.0100747   0.0782931   -0.071511     0.0239537   -0.0100974   -0.0255451   0.0118945   -0.0561612   -0.0632044   -0.0713322   -0.101005     0.0369425    0.011013     0.00610411  -0.000673715  -0.0441733
  0.143724    -0.150337    -0.0775503    0.0609805   -0.203758    -0.0570161    0.0711982     0.135526     -0.0358828    0.16367      0.0338062   0.023277    -0.0580435    0.0847528   -0.0313765    0.0930938  -0.0119952   -0.07507      0.0480666   -0.118335    -0.0321004    0.160345    -0.104855     0.0990797   -0.167936      0.00506607
 -0.00338242   0.0542192   -0.068136    -0.0577838    0.12198     -0.0517011   -0.143108     -0.114825     -0.0492124   -0.0548145    0.0936956   0.085207     0.152735     0.132551     0.0825288    0.0979075  -0.0427618    0.200842     0.165805    -0.226756    -0.0657176    0.130747     0.0651382    0.00146033  -0.0063959    -0.0656083
 -0.157602    -0.00743239  -0.063616    -0.0133809    0.15163      0.0527876   -0.035961     -0.0790641     0.072125     0.0585028    0.116398   -0.0693148   -0.0251861    0.0631679    0.123856    -0.0653611   0.0844285    0.151325    -0.0177089    0.0392268   -0.0692895   -0.00771738  -0.0641109   -0.123697    -0.0767032    -0.137257
  0.00215436   0.0429675    0.0526395    0.0464566    0.0273977    0.00362163   0.0638519     0.0513648    -0.0649892   -0.0640288    0.0729721  -0.0530161    0.0527878    0.325883     0.0464783    0.056407    0.12668     -0.0700449   -0.017486    -0.00884152   0.0950597    0.0172924   -0.0274135   -0.0115128   -0.0908527     0.0624669
 -0.00261353  -0.107648     0.0456176   -0.0405166   -0.0741204    0.0390833   -0.0391891     0.0548352     0.100322     0.238321    -0.141623    0.00923715  -0.0182674    0.0271169   -0.135842     0.18753     0.0923563    0.104632    -0.145435    -0.00288375  -0.166052    -0.162843    -0.0679191   -0.168188     0.0775144    -0.0639042
 -0.104237     0.216037    -0.0153257    0.00636777   0.0893685   -0.16158      0.00321273   -0.0381699     0.111618    -0.00543589  -0.0411812   0.131566    -0.156644    -0.0261382   -0.090708     0.100562    0.032533    -0.150784    -0.0840755    0.0466672    0.00391081  -0.122501     0.0733481   -0.0246975    0.1375        0.0354199
 -0.137034     0.21558     -0.165241     0.126442    -0.00582252  -0.0323064    0.079612     -0.0375487    -0.0278404   -0.0225265    0.0807199   0.0647388    0.0630168   -0.0837352   -0.063774    -0.0985311  -0.0557666    0.123894    -0.0956496   -0.055149    -0.0287277   -0.138346    -0.0651349    0.00904424   0.0376542     0.0636204
  0.0136076    0.169554    -0.104081    -0.0158885    0.125292     0.0797516   -0.0118066    -0.166731      0.136074    -0.0994809    0.115686   -0.0710207   -0.108825    -0.0833521    0.149372     0.0290044   0.0407076   -0.0115568   -0.107703     0.0729715   -0.0328135   -0.0853673    0.0898652    0.0481548    0.143857      0.143103
 -0.0865649    0.0444744    0.141884    -0.0307129    0.0509154    0.0884756   -0.052198     -0.0230086    -0.104411    -0.0887423   -0.0300787  -0.0836918    0.0145431    0.0615218   -0.06003      0.086908   -0.0922527    0.0699488    0.0795139   -0.00415114   0.0290797    0.104889    -0.0178544   -0.0424718   -0.00231199    0.0151347
 -0.0794725    0.128402    -0.0247354    0.0921564    0.00332533   0.00878069   0.0338555    -0.101027      0.0751407   -0.0335841    0.0581752  -0.0369181    0.0783316   -0.0339653   -0.0804887    0.0360253  -0.0151804   -0.0417683    0.0545887    0.00160637   0.00166036  -0.0252874   -0.041463    -0.0103749   -0.0268345     0.0101221
  0.100127     0.0989209   -0.190102     0.247114     0.152155     0.12311     -0.0815347    -0.1809        0.0415498    0.309377    -0.0355248   0.0693021    0.0398102    0.00808764   0.155673     0.0279121   0.0941447   -0.250011    -1.1379      -0.0732069   -0.0538645    0.124663    -0.00780922   0.178872     0.0307095     0.0359722
  0.209622     0.083749    -0.135257     0.217195     0.119313    -0.15887     -0.0776303    -0.203682      0.00518431  -0.316771     0.0664566   0.054871     0.0795234    0.0629431    0.158295    -0.15649     0.128831    -0.00700784   0.675881    -0.0677168   -0.0110847   -0.0219536    0.0350722    0.130983    -0.253044      0.0434479
 -0.00669958   0.172638    -0.0885431   -0.821601    -0.00167954   0.220079     0.0772323     0.137399      0.171479     0.187936     0.0718212  -0.356471     0.132182    -0.127305    -0.0580143   -0.152521   -0.0445104    0.0446894   -0.0251081   -0.179397     0.0999249   -0.0237048    0.0147941   -0.130178     0.0983792    -0.00303427
  0.00530664   0.180083    -0.0852385    1.00222     -0.0130467    0.211222     0.074859      0.145098      0.103702     0.217231     0.0580391   0.654351     0.131563    -0.125731    -0.103109    -0.0747381   0.136277    -0.02928     -0.0297486   -0.19178      0.113033    -0.0225679    0.0154339   -0.134998     0.121508     -0.00370447
 -0.0570041    0.015934    -0.0942782    0.168762    -0.0542845    0.100768     0.112879     -0.0746986    -0.149307     0.0932099    0.0162685   0.0915404   -0.0884309   -0.0503037   -0.0808558   -0.048156   -0.207772    -0.191554     0.0245814    0.0412617    0.0801606    0.0611588   -0.0622331   -0.001633     0.129191     -0.00643589
  0.0560913    0.118159     0.113262     0.0321467   -0.326498     0.091479     0.0764141     0.107276      0.0154018   -0.115659    -0.107856   -0.0996489    0.212121     0.0047056    0.0119803   -0.0343153  -0.0749464   -0.0980383   -0.0206381   -0.0327228    0.048059     0.129665    -0.0517301   -0.040778    -0.0570761     0.0423689
 -0.0298992   -0.0680955   -0.112846    -0.0761232    0.128694    -0.201453    -0.0310782    -0.0940462     0.04557     -0.0158278   -0.159705   -0.0560358    0.0347838    0.0494979    0.0381142    0.0255271   0.00760335   0.0375329    0.10198      0.104292     0.125698     0.0473221   -0.0519926   -0.0121634    0.0015487     0.0550904
  0.129915     0.0874291    0.0914084    0.176876     0.0215913   -0.179153    -0.14786      -0.0128424     0.0928484   -0.129054     0.0938324   0.0400093    0.0364973    0.0774278    0.102865    -0.101548   -0.106288    -0.0353848    0.0481329   -0.0598846    0.0395544   -0.0898348   -0.164371     0.12338     -0.0611102     0.0381388
 -0.0259889   -0.113229     0.0833405    0.0434104    0.134752    -0.00430448   0.199704     -0.103469     -0.115094    -0.0684259    0.0506386   0.0216949    0.111339    -0.212474     0.241938    -0.114898   -0.107659    -0.427734    -0.0662589    0.0672999   -0.211039     0.0930556   -0.105737     0.143626    -0.0131403     0.198396
 -0.0917522   -0.0842321    0.0850856    0.0617443    0.199516    -0.00236611   0.173402     -0.133663     -0.138195    -0.0633265    0.176419    0.0192698    0.113455     0.0204113    0.226119    -0.0607822  -0.0988636    0.804277     0.342382    -0.0223413   -0.173317     0.227293    -0.0112275    0.124298     0.0498154     0.145141
  0.0446238    0.202434    -0.769878     0.18909     -0.053685     0.052523    -0.143715      0.127195     -0.0917833    0.0835333    0.0378926  -0.0231867   -0.0329523    0.038523     0.0492581    0.160193    0.10025     -0.0766345    0.041606    -0.0340564    0.233045    -0.17733     -0.00199174   0.116482    -0.0380057     0.105773
  0.0391285    0.144202     0.62225      0.186836     0.156776     0.031973    -0.121836      0.123566     -0.115559     0.0217207    0.0448367  -0.053322    -0.0574096   -0.157237     0.0603831    0.0962763   0.0902698   -0.135119    -0.154633    -0.0717386    0.149856    -0.0810732    0.0096697    0.110383    -0.101701      0.0708264
 -0.0177101   -0.110464    -0.131427     0.0337428    0.0743908   -0.37152     -0.170249     -0.0961333    -0.10018     -0.211486    -0.0408104  -0.0583655    0.00147794   1.61981     -0.0993699   -0.111378    0.0307507   -0.134753     0.0010461    0.064487    -0.0226731    0.135271    -0.0252615    0.0120489   -0.0974464     0.127475
  0.0166286   -0.128125     0.0450835    0.038455     0.163168     0.375561    -0.177545     -0.0864492    -0.0926861   -0.143844    -0.0167877  -0.0849185    0.0131626   -1.53878     -0.0877587   -0.131863    0.0311696   -0.125703     0.0429162    0.0613669   -0.0193935    0.133009    -0.0230448    0.292947     0.0537671     0.105719
 -0.0409443    0.335211     0.0953199   -0.0736261    0.161529     0.114441     0.11266       0.046404     -0.53124     -0.026968     0.211005    0.125693    -0.0250054    0.0385747   -0.153441    -0.0225329   0.0555606    0.00372725  -0.0555412    0.146032     0.0208      -0.0541134    0.0470464   -0.145515     0.151898      0.00185622
  0.208342     0.159342     0.125876     0.00173941   0.0577243    0.110728     0.110575      0.0660025     0.29602     -0.0486084    0.0783062  -0.00131868   0.0161784    0.0199984    0.00596193  -0.0851149   0.0525288    0.0329932   -0.230608     0.166755     0.0205396    0.0262618    0.0721096   -0.0566543    0.0996419    -0.00404182[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚     10
â”‚     13
â”‚     19
â”‚     20
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.072946
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚     10
â”‚     11
â”‚     13
â”‚      â‹®
â”‚     21
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.059754
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      9
â”‚     10
â”‚     13
â”‚      â‹®
â”‚     23
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.059169
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚     10
â”‚     11
â”‚     13
â”‚      â‹®
â”‚     21
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.069029
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚     10
â”‚     13
â”‚     19
â”‚     20
â”‚     29
â”‚     30
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.063446
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      1
â”‚      9
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     23
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.055253
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚     10
â”‚     13
â”‚     19
â”‚     20
â”‚     29
â”‚     30
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.072914
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚     10
â”‚     11
â”‚     13
â”‚      â‹®
â”‚     21
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.059683
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      9
â”‚     10
â”‚     13
â”‚      â‹®
â”‚     23
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.059130
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚     10
â”‚     11
â”‚     13
â”‚      â‹®
â”‚     29
â”‚     30
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.069025
â”Œ Info: EM with 100000 data points 10 iterations avll -1.069025
â”” 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.013562e+05
      1       6.728888e+05      -2.284674e+05 |       32
      2       6.511793e+05      -2.170947e+04 |       32
      3       6.374736e+05      -1.370572e+04 |       32
      4       6.280302e+05      -9.443443e+03 |       32
      5       6.210663e+05      -6.963862e+03 |       32
      6       6.150900e+05      -5.976320e+03 |       32
      7       6.097815e+05      -5.308487e+03 |       32
      8       6.058530e+05      -3.928512e+03 |       32
      9       6.035710e+05      -2.281999e+03 |       32
     10       6.021275e+05      -1.443528e+03 |       32
     11       6.010114e+05      -1.116043e+03 |       32
     12       6.001460e+05      -8.654596e+02 |       32
     13       5.995858e+05      -5.601300e+02 |       32
     14       5.992678e+05      -3.180067e+02 |       32
     15       5.990854e+05      -1.824240e+02 |       32
     16       5.989590e+05      -1.263833e+02 |       32
     17       5.988533e+05      -1.057027e+02 |       31
     18       5.987213e+05      -1.320335e+02 |       31
     19       5.984954e+05      -2.259324e+02 |       32
     20       5.982637e+05      -2.316922e+02 |       32
     21       5.980033e+05      -2.603811e+02 |       32
     22       5.977280e+05      -2.752674e+02 |       32
     23       5.974658e+05      -2.622338e+02 |       32
     24       5.972560e+05      -2.098044e+02 |       32
     25       5.970445e+05      -2.114248e+02 |       32
     26       5.967968e+05      -2.477969e+02 |       32
     27       5.965255e+05      -2.712118e+02 |       32
     28       5.963167e+05      -2.088036e+02 |       32
     29       5.962121e+05      -1.046486e+02 |       32
     30       5.961623e+05      -4.976865e+01 |       31
     31       5.961380e+05      -2.435116e+01 |       31
     32       5.961254e+05      -1.255648e+01 |       28
     33       5.961190e+05      -6.381832e+00 |       27
     34       5.961143e+05      -4.720004e+00 |       27
     35       5.961112e+05      -3.126453e+00 |       26
     36       5.961089e+05      -2.293634e+00 |       23
     37       5.961066e+05      -2.302117e+00 |       19
     38       5.961047e+05      -1.874805e+00 |       22
     39       5.961035e+05      -1.216627e+00 |       15
     40       5.961027e+05      -8.072575e-01 |       13
     41       5.961022e+05      -5.371192e-01 |       11
     42       5.961017e+05      -4.963410e-01 |        9
     43       5.961014e+05      -2.488548e-01 |        6
     44       5.961013e+05      -1.317666e-01 |        0
     45       5.961013e+05       0.000000e+00 |        0
K-means converged with 45 iterations (objv = 596101.2743256532)
â”Œ Info: K-means with 32000 data points using 45 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.321851
[ Info: iteration 2, average log likelihood -1.293635
[ Info: iteration 3, average log likelihood -1.263519
[ Info: iteration 4, average log likelihood -1.225370
[ Info: iteration 5, average log likelihood -1.182694
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.134901
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     26
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.100498
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      1
â”‚     13
â”‚     14
â”‚     17
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.079182
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.106967
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     8
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.076022
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚     13
â”‚     26
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.051064
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      4
â”‚     16
â”‚     17
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.065265
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.078700
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     1
â”‚     8
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.066133
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     21
â”‚     24
â”‚     26
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.059931
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     13
â”‚     17
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.072920
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      9
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.078371
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      8
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.053929
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      1
â”‚     13
â”‚     21
â”‚     24
â”‚     26
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.050016
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.087972
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     16
â”‚     17
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.062475
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     14
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.048689
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      1
â”‚      4
â”‚     21
â”‚     26
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.062256
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      9
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.094837
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     17
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.075636
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      8
â”‚     14
â”‚     16
â”‚     24
â”‚     26
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.030594
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      1
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.110468
[ Info: iteration 28, average log likelihood -1.104951
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     17
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.054317
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      8
â”‚     13
â”‚     24
â”‚     26
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.034189
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     1
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.103106
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      9
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.073295
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     16
â”‚     17
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.058485
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     13
â”‚     21
â”‚     24
â”‚     26
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.042475
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     1
â”‚     8
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.102879
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.089589
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     17
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.060572
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      8
â”‚     13
â”‚     24
â”‚     26
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.038930
[ Info: iteration 39, average log likelihood -1.105636
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      1
â”‚      9
â”‚     14
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.058337
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     13
â”‚     17
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.072413
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      8
â”‚     24
â”‚     26
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.052088
[ Info: iteration 43, average log likelihood -1.105287
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      9
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.069277
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     13
â”‚     17
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.057159
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      8
â”‚     16
â”‚     24
â”‚     26
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.029204
[ Info: iteration 47, average log likelihood -1.101205
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     1
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.065613
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      9
â”‚     14
â”‚     17
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.041190
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      8
â”‚     24
â”‚     26
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.051458
â”Œ Info: EM with 100000 data points 50 iterations avll -1.051458
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
 -0.127933     0.00691889  -0.041724    -0.0051445    0.131137      0.0482828   -0.020064    -0.0587905    0.0844293   0.0524059    0.104792    -0.0938706    -0.00867304   0.100247     0.0911191   -0.0187486   0.0917846     0.109766    -0.0271809     0.0346947   -0.0484291   -0.0258397   -0.0621801   -0.121749    -0.0526011   -0.105124
 -0.0956084    0.0556509    0.133114    -0.0807958    0.0720609     0.134316    -0.0462819   -4.29608e-5  -0.092079   -0.144626    -0.00392986  -0.2047        0.0662319    0.0416246   -0.0643907    0.121447   -0.141783      0.191853     0.0912853     0.0108097   -0.0259985    0.0863986   -0.0574341   -0.105201     0.0731817    0.00505201
 -0.0612695    0.0263516   -0.0900622    0.161672    -0.0435956     0.103619     0.112985    -0.06504     -0.150065    0.0878968    0.00905223   0.0919765    -0.0776998   -0.0532248   -0.0778611   -0.0508168  -0.210393     -0.201225     0.0123862     0.0371518    0.0753794    0.0558233   -0.0548718   -0.0281287    0.114838     0.00231246
  0.00782314  -0.115022    -0.122642    -0.117174     0.0657075    -0.15272      0.0642216   -0.0780811    0.11482    -0.129663    -0.0240661    0.0901691    -0.0779643   -0.104108    -0.0601318   -0.190626   -0.0876218    -0.240781    -0.000187703  -0.158102    -0.0251201   -0.169269     0.0514963    0.0253293    0.128772     0.00799744
  0.0128301   -0.0187365   -0.102301     0.0930676   -0.0374176     0.00753406  -0.167265    -0.0918175   -0.0740522  -0.173266    -0.0447326    0.121254     -0.0356594    0.0940024    0.0404962    0.0280172   0.047596      0.00998827  -0.227264     -0.0951987   -0.0942172    0.0322666   -0.0279462   -0.113066    -0.0885708    0.0009521
  0.128886     0.0848713    0.0917533    0.176909     0.0214577    -0.179264    -0.14735     -0.0140215    0.0929159  -0.129774     0.0962204    0.0412744     0.0370875    0.0776589    0.10251     -0.100573   -0.106011     -0.0346593    0.0475695    -0.0602979    0.0396155   -0.0894377   -0.163678     0.121228    -0.0608341    0.0381706
 -0.0773601    0.0274981    0.147127     0.0274657    0.0106049     0.0380469   -0.0657633   -0.045436    -0.117423   -0.0144743   -0.0570935    0.0302308    -0.0511033    0.09313     -0.0512607    0.0623409  -0.0179546    -0.0554633    0.0560151    -0.0196499    0.0827292    0.103164     0.0194592    0.0152027   -0.0786054    0.0278284
 -0.111286    -0.0249822   -0.0734325    0.189088     0.0526194    -0.117979    -0.0495076   -0.0733762    0.0366709  -0.102098     0.0453141    0.121807     -0.0299667    0.0430485   -0.0430436   -0.0811931   0.160281      0.0723451    0.0349352    -0.1221       0.128286     0.0246114   -0.138437     0.028309    -0.0136233   -0.0597956
  0.0176239   -0.0481006    0.0330037   -0.0796098   -0.0916609     0.0523955   -0.1072       0.0316357    0.0749473   0.178118    -0.126331     0.0140185    -0.0572049    0.0561658   -0.0951889    0.117724    0.092133      0.0739429   -0.117209      0.035835    -0.11161     -0.103203    -0.065029    -0.16087      0.0720259   -0.0206335
  0.0533285    0.117022     0.111018     0.0336844   -0.326216      0.091275     0.0769805    0.104084     0.011389   -0.11404     -0.106911    -0.0980721     0.21147      0.00352991   0.0108531   -0.0340824  -0.075442     -0.0957981   -0.0186006    -0.0322945    0.0477022    0.129422    -0.0522901   -0.043535    -0.0552393    0.0383196
 -0.0207017   -0.0945576   -0.0021656    0.0192781    0.259697     -0.0263212    0.0248259    0.0878361   -0.0287863   0.125766     0.17379     -0.0472259    -0.143466     0.0682385    0.0468124   -0.0697832   0.0481805    -0.162291     0.0502422    -0.0538786    0.171399    -0.0190834    0.183444    -0.0720895    0.145807     0.0715021
  0.0911521    0.243254     0.110754    -0.0333362    0.106291      0.112569     0.111273     0.0549177   -0.0930573  -0.038129     0.14117      0.0581834    -0.00294228   0.0289384   -0.069118    -0.0543284   0.0540485     0.0194763   -0.14986       0.157365     0.0207108   -0.00971298   0.0604222   -0.0989528    0.123315    -0.00127482
 -0.0031906   -0.154288    -0.157032    -0.071999    -0.0682478     0.34706     -0.0821343    0.0569294    0.134226   -0.075425     0.0604301   -0.023952     -0.0246019   -0.18501      0.0416476   -0.180939    0.000919448  -0.152723    -0.0512982     0.0715183    0.0503396    0.0344655    0.0213737    0.0985456    0.184277     0.129194
  0.00124144   0.0692479   -0.02284     -0.0673229   -0.0383438     0.180451     0.0684802    0.145555     0.198945    0.211052     0.0120477    0.072752      0.0773155   -0.0589368   -0.0964473   -0.0372466   0.0532382     0.0700422   -0.0792694    -0.158429     0.0407823   -0.0736908   -0.00412152  -0.133818     0.0916321   -0.00653405
 -0.00691911  -0.0832559    0.0137292    0.0252538   -0.054999     -0.14187      0.00716612  -0.0870819    0.0103505   0.0117776    0.022146     0.035412     -0.189536     0.0641322   -0.15289      0.0426482   0.186818     -0.021822     0.00657183    0.0228736   -0.0669809    0.0547823   -0.0584457    0.0389676    0.00498049  -0.270919
  0.00238171  -0.0700833    0.0116406   -0.0473999    0.0269034     0.0369087   -0.055689    -0.00437842   0.0430137   0.109984    -0.0519479    0.0220683    -0.00778475   0.08254     -0.00809018   0.0131934   0.111949      0.103829    -0.071684      0.0115139   -0.075609    -0.115786    -0.0398638   -0.145051    -0.0554182   -0.0914726
  0.120498    -0.00174213   0.00976775  -0.0484064   -0.000791729   0.0105979    0.0395996    0.0228661   -0.0103501   0.114885     0.0767713    0.0790904    -0.0571546    0.0996911   -0.0659061   -0.0259988   0.00661805    0.0230251    0.164821     -0.0266994    0.074813    -0.0636898    0.102831    -0.118672     0.0854141    0.0703745
 -0.103378     0.212324    -0.015484     0.00277578   0.0813175    -0.158077     0.00363117  -0.0357192    0.1122      0.00129786  -0.0420179    0.130934     -0.150969    -0.0267623   -0.0920231    0.102592    0.0342927    -0.150513    -0.0874462     0.0440195    0.00275471  -0.123223     0.0706333   -0.0282083    0.135048     0.0355051
 -0.0566699   -0.100223     0.0843229    0.0518644    0.16509      -0.00356935   0.187972    -0.117782    -0.128277   -0.0657621    0.106085     0.0212633     0.112428    -0.106598     0.234647    -0.0920476  -0.103781      0.126028     0.117872      0.0261891   -0.191949     0.151231    -0.0624022    0.134989     0.0140278    0.173906
  0.148961    -0.151999    -0.0776386    0.0610711   -0.203953     -0.0580859    0.073085     0.134161    -0.0348983   0.164792     0.0326082    0.0227213    -0.0603624    0.0873869   -0.0253626    0.094036   -0.0131163    -0.0750537    0.0481404    -0.116109    -0.0320463    0.157647    -0.103577     0.0977297   -0.171111     0.00515732
 -0.00137333  -0.0741823   -0.0142956    0.0386413    0.0941684    -0.0168382   -0.0912515   -0.0401847   -0.108038   -0.134452    -0.00345433  -0.0628715     0.0229008    0.209629    -0.0587003   -0.0468956   0.0539278    -0.112555     0.00554729    0.0476069    0.00420386   0.102415    -0.0265299    0.104072    -0.0493916    0.118849
 -0.0391991   -0.136223     0.0643545    0.0408771    0.0673854     0.0729013    0.00854486  -0.019682     0.0981783  -0.0858907   -0.216575    -0.0788067    -0.014014     0.183725     0.0988021    0.109724   -0.111193     -0.1647       0.128657      0.124362     0.0191599   -0.0378126   -0.0214982   -0.160221    -0.115915     0.0180993
 -0.00320505   0.052395    -0.0679263   -0.0574599    0.118824     -0.0499282   -0.143247    -0.113333    -0.0488581  -0.0535431    0.0914933    0.0809336     0.153271     0.134029     0.0804346    0.0971037  -0.0335974     0.199948     0.160904     -0.22531     -0.0668664    0.130558     0.0693306   -0.00384345  -0.00653438  -0.0672601
  0.0788545    0.108937     0.109653     0.0647902   -0.00512074    0.114103     0.183925     0.102596     0.0373176   0.136561     0.0352035    0.0250296    -0.104657    -0.0442975   -0.0635901   -0.0793026  -0.0242605    -0.124482     0.119224     -0.0409263   -0.106642     0.0513557    0.0491624    0.129874     0.0899373   -0.0728241
 -0.0652924    0.198529    -0.141697     0.0608954    0.0570377     0.022073     0.0326983   -0.0982233    0.052075   -0.062199     0.098718    -0.000600122  -0.0191511   -0.0867065    0.0448804   -0.0385423  -0.0118256     0.0588116   -0.104186      0.00805957  -0.0296566   -0.111756     0.00387744   0.0271814    0.0903581    0.101029
 -0.029186    -0.0615093   -0.112093    -0.0800756    0.124348     -0.201658    -0.0298423   -0.0916092    0.0453958  -0.0135045   -0.157514    -0.0576797     0.0364822    0.0481863    0.0406347    0.0243157   0.0171591     0.0391194    0.0961715     0.102726     0.125922     0.0471944   -0.0514826   -0.011833     0.00374772   0.0549914
  0.136538     0.103881    -0.149695     0.215844     0.107099      0.0207009   -0.0513536   -0.145703     0.0250347   0.00421273   0.0238141    0.070944      0.076293     0.0133911    0.134561    -0.0749259   0.105229     -0.112421    -0.0920883    -0.075781    -0.00531817   0.0300174    0.0213228    0.0959579   -0.0817219    0.0324937
  0.0431874    0.170661    -0.0747357    0.190825     0.0516334     0.0423913   -0.134897     0.12931     -0.106712    0.0533988    0.0420675   -0.0401469    -0.045256    -0.0614377    0.0571903    0.13005     0.0950461    -0.109973    -0.0598149    -0.0568318    0.196153    -0.133416     0.00552966   0.113846    -0.0710553    0.0883298
 -0.0509463    0.258661     0.0181308    0.0149572   -0.0334886     0.124323     0.119571    -0.112515     0.0920019   0.026621     0.0655795   -0.171958      0.190253    -0.098471    -0.106567     0.140102   -0.17748      -0.145274     0.0679842     0.102115    -0.100112    -0.0789662    0.0477153   -0.0394939   -0.0306764    0.0847522
  0.0172973   -0.100762     0.0895352   -0.189934     0.0754997    -0.0596667    0.305969     0.211511    -0.0931367  -0.0153813   -0.0319767    0.033993     -0.157902     0.126033     0.107031    -0.0394167   0.16551      -0.0542679    0.0698512     0.129695    -0.0209338    0.057467    -0.0447806   -0.0565965    0.059244    -0.0474597
  0.125471    -0.0131139    0.0453292    0.188045    -0.116729     -0.00769824   0.0836396   -0.0616555   -0.0203051   0.111362    -0.103749    -0.0335954    -0.0147862    0.197528    -0.00565376   0.0792036   0.0148262    -0.0210994    0.0896813     0.121604    -0.0565823   -0.0769952   -0.122471     0.0303826    0.00520571  -0.0608927
  0.0236744   -0.182398    -0.0406127   -0.0680308   -0.072504      0.0231622   -0.0856503    0.0669075    0.141917   -0.13721      0.0150159   -0.0799044    -0.0313648   -0.0327905    0.0604095   -0.0551636  -0.0271264    -0.188963     0.00592325    0.00391665  -0.0993677   -0.116111     0.0740587    0.0364565    0.133345     0.176064[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.106175
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.069905
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      9
â”‚     17
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.040269
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚      4
â”‚      8
â”‚     13
â”‚     21
â”‚     24
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.013675
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     16
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.074243
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      1
â”‚     13
â”‚     14
â”‚     17
â”‚     21
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.046831
[ Info: iteration 7, average log likelihood -1.049700
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      8
â”‚      9
â”‚     13
â”‚     16
â”‚     24
â”‚     26
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.008821
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚     17
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.082173
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     13
â”‚     14
â”‚     21
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.049911
â”Œ Info: EM with 100000 data points 10 iterations avll -1.049911
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
 -0.00782897   0.0267698   -0.154636    0.161854    0.0123979   -0.197849    -0.0619845  -0.0773489    0.0585055    0.0905465    -0.0615818    0.0325596   -0.166117     0.00291952   0.145656    -0.0139273    0.00342806  -0.0621323     0.121867    -0.130231    -0.0275659    -0.0843761    0.129113    -0.084358    0.0399816    -0.0887986
  0.207631     0.0053483    0.0847577  -0.132257    0.139469     0.0668805    0.0756295   0.0942392    0.174063    -0.0462254    -0.0364006   -0.0246496   -0.0914083    0.075004     0.130868    -0.150711     0.00441486  -0.0717107     0.11185     -0.261215    -0.137753     -0.12779     -0.0244474    0.120758   -0.000733798   0.0353877
 -0.123805     0.0416549   -0.115963    0.0349469  -0.0876983   -0.0368289    0.216305   -0.0317434    0.0168557    0.121833     -0.129962     0.036693    -0.00628703  -0.0657549    0.0161474   -0.0747649    0.0432902   -0.135001      0.113396     0.134865     0.0823186     0.166657    -0.0849355   -0.116585   -0.0330412     0.0907676
  0.0249966   -0.126767     0.146152   -0.14819    -0.0339051    0.0636935    0.142592   -0.0437299   -0.0168631   -0.171441     -0.172467     0.0824758   -0.0270467    0.119542    -0.0712539    0.0682862   -0.0847689    0.27811      -0.0634832   -0.00324212  -0.0835612    -0.0230165   -0.0552689    0.149497   -0.0267969    -0.0575217
 -0.0346874    0.0197596   -0.0780975   0.0634078  -0.157247     0.186086     0.110949   -0.0655188   -0.0627653   -0.00674041   -0.00829672   0.299034    -0.00226913   0.0620618   -0.0305996    0.012458    -0.0469284   -0.0481081     0.167154    -0.0721956    0.0607139     0.0910718    0.100597     0.0773779   0.0493524     0.202089
  0.0731239   -0.0484261   -0.0712557   0.0302843  -0.128148    -0.166823    -0.058124    0.0685997   -0.019697    -0.17203       0.00279098  -0.053604    -0.045626    -0.0396747    0.068893    -0.00714015  -0.0967689    0.0582207     0.0159603   -0.0377427    0.0248421     0.0266025    0.0860135   -0.0141699   0.00821103    0.0223939
 -0.143244    -0.181593     0.10825    -0.087616    0.210664     0.116604     0.246402    0.190939    -0.125331     0.0326076     0.00778079   0.0411026    0.165174     0.110549    -0.00941867  -0.0475035   -0.0410339   -0.0578483    -0.109474    -0.0472994   -0.186621     -0.0335856   -0.074582    -0.12036    -0.0237105     0.0411463
  0.182689    -0.0104796    0.248497    0.232248   -0.0865055   -0.236146     0.0306015  -0.0723539    0.0488968    0.00271034   -0.0509901   -0.0124227    0.0109213   -0.254956     0.0776174    0.0151825   -0.118734    -0.00153971   -0.00511691  -0.041728    -0.0152403     0.226418     0.0766587    0.0531142  -0.0113245     0.0930979
 -0.024164     0.0461096   -0.0234192   0.0397218   0.138719    -0.0304233    0.0615414  -0.0321359    0.0453263   -0.103529     -0.0253564    0.0878395    0.115902     0.0724912   -0.184728    -0.0609002   -0.121487     0.14086      -0.0776733   -0.0346135    0.0862709    -0.0150628    0.087895     0.0173349   0.0517738     0.0195428
 -0.0854205   -0.0334367    0.0304863  -0.124696    0.0508061    0.0300449    0.163336   -0.0941564    0.154826     0.0807681    -0.205785     0.0239525   -0.1504       0.0215695    0.0601968   -0.0127788   -0.0270918   -0.163675     -0.0581387    0.178769     0.00107668   -0.0707216   -0.00395521   0.0763866   0.0931686     0.0987723
 -0.0286066    0.0311194    0.102098    0.025781   -0.0954541    0.0953421    0.108999   -0.103055    -0.23671     -0.0418867     0.127431     0.119015    -0.0691876   -0.029613    -0.00799274  -0.0804782    0.0481132    0.0277771    -0.00541091  -0.0408877   -0.0636882    -0.0459927   -0.0384459   -0.112847    0.0890372    -0.105761
 -0.0208488   -0.0631545    0.0379751  -0.0890208   0.0855396   -0.108454    -0.0294045   0.0567229    0.0325705    0.0119215    -0.0312432   -0.0491373    0.173809     0.0050484   -0.0135281   -0.103419    -0.0594218    0.000138115   0.0486632   -0.045139    -0.00350402   -0.126773     0.0682472   -0.010589    0.0161358     0.0179015
  0.14883     -0.0769729   -0.0619329  -0.0250566   0.0900796   -0.0232575   -0.218921    0.170014    -0.100864     0.0953118     0.0596038    0.0341777    0.0445023   -0.0621645    0.132513     0.136545     0.00404123  -0.194361      0.00134275  -0.0680761    0.0515548    -0.229485    -0.128485    -0.111578   -0.085674     -0.0413115
 -0.0900164    0.00786542   0.0506685  -0.140063    0.0917091   -0.0459605   -0.0394509   0.0381502    0.105656     0.178666      0.0144526   -0.0214988    0.0363384    0.120897     0.0176102    0.0809729   -0.103632    -0.147994      0.116803     0.130545     0.111578      0.0142122    0.135466    -0.102399    0.0544945     0.0838787
 -0.0199344   -0.013903    -0.064898   -0.0131216   0.0580963   -0.0475749   -0.0409872  -0.208546     0.0759895    0.0424243    -0.321894     0.0945871    0.12284      0.0129848   -0.181265     0.0748717    0.139326    -0.0897761    -0.135109    -0.185862     0.0935172    -0.0033246   -0.102662     0.0597746  -0.0561542    -0.0472464
 -0.120815    -0.0706724   -0.145497    0.033381    0.174405     0.132681     0.0223467   0.120177     0.0112063   -0.0666588    -0.0866545   -0.175141     0.106146    -0.047673    -0.12302     -0.032811    -0.00298845   0.0475696    -0.00395075   0.0239148    0.0386845    -0.097805     0.00273801  -0.142776    0.133847      0.0663464
  0.0665327    0.0668434   -0.0121312  -0.134853    0.0160874   -0.0354315    0.131273    0.135546     0.013696     0.110718      0.0749348   -0.0851794    0.129097    -0.146444    -0.0899697    0.140627     0.195152    -0.147435     -0.0430779   -0.0570168    0.0760069     0.22878     -0.0900625    0.115338    0.110836     -0.17504
 -0.0707685   -0.0168466   -0.0414581  -0.128021   -0.100581     0.00537163   0.0342872   0.0809354   -0.133197    -0.0702561    -0.0615911    0.0910088    0.0846945   -0.0627869    0.118297    -0.165731     0.0153131   -0.0603275    -0.113998     0.00315272   0.0160327     0.0262394    0.074073    -0.0175817  -0.0826757     0.158299
  0.103583     0.105047     0.172822   -0.0285658   0.136912     0.0141252   -0.0847741   0.112998    -0.0549418    0.0811727    -0.0251604    0.191343    -0.0623675   -0.162465     0.0137445    0.157292     0.0180049   -0.0264097     0.0442595    0.236779     0.0326488     0.00260133  -0.109292    -0.0634797  -0.098638      0.0919617
 -0.0588096   -0.0229677   -0.0894525  -0.158221   -0.0276943   -0.105894    -0.0709504  -0.144128    -0.0998509    0.00414026   -0.0671686    0.060527     0.137761     0.0511143    0.0938753   -0.116368    -0.130713    -0.00980123    0.170034    -0.0521967   -0.0495311    -0.102141     0.150677    -0.27732     0.0314313    -0.129325
  0.057655    -0.00982706  -0.0311417  -0.0595774   0.0231407    0.0602297   -0.13325     0.174116     0.0449457   -0.0372881    -0.0343402    0.135562     0.0844687    0.116775     0.0348975    0.0385539    0.0383702   -0.0445572    -0.0269808    0.173731     0.1372       -0.155759     0.216533     0.0515709   0.129637     -0.0147343
  0.104174     0.175672     0.0402922   0.100844   -0.123597    -0.127376     0.0333339  -0.0269333   -0.00527755   0.0462337     0.137187     0.15177      0.115636     0.0736181    0.21327     -0.00316865  -0.0473125   -0.0974027    -0.14401      0.0424861   -0.000897425  -0.0797567    0.07532      0.0240126  -0.0173569    -0.0380149
  0.00283736   0.00905252   0.203925    0.0831851   0.0247991   -0.185035     0.223777    0.158542    -0.0180401    0.209637      0.0530848   -0.0322699   -0.0690012   -0.055998     0.0117485   -0.0439146   -0.200034    -0.232545     -0.0248243    0.0164829    0.184725     -0.0787453   -0.0492881    0.139139   -0.0444102    -0.0503256
  0.120927     0.1254       0.060359   -0.0110607  -0.08271     -0.0537285   -0.08147     0.105507     0.131641     0.0758834     0.0279539    0.00500438  -0.0603682    0.100734    -0.0856644   -0.00837538   0.188299     0.142578      0.037007     0.117193     0.0430502    -0.0183808   -0.0118802    0.0303463   0.118826     -0.0393216
  0.0421904   -0.0862563    0.0596462  -0.0963791  -0.239901    -0.120705     0.126715   -0.0407746    0.0556876   -0.209         0.112835    -0.160103    -0.179587     0.0278417   -0.0651149   -0.171413     0.0586078    0.063554     -0.009092     0.0428964    0.151274      0.0510132   -0.012141     0.0634163  -0.120333      0.0931062
  0.183655     0.114989    -0.115273    0.0808706  -0.0915108   -0.0380575    0.0163483   0.0447382   -0.118759     0.115579      0.0119866    0.0189712    0.135472    -0.0622074   -0.0984677   -0.177561    -0.111106     0.0573075    -0.211816    -0.0983005    0.0342127    -0.11152      0.145498     0.0850995  -0.0500007     0.271334
 -0.00127888  -0.0671551   -0.123164    0.12598     0.129194     0.0359705   -0.0435904   0.0415918    0.00140674  -0.000432961  -0.150739     0.0369709   -0.0620701    0.170945     0.0250446    0.0506001    0.0532123    0.0283161     0.200912    -0.0825923   -0.123392      0.129136    -0.116047    -0.12628    -0.224978     -0.171328
  0.0462767   -0.101875     0.059578   -0.0717405   0.0752392    0.0830544    0.0270473  -0.0115422   -0.138021    -0.0338418    -0.0319079    0.0700509    0.0417013    0.0447248   -0.0780288    0.184412    -0.0628408    0.0620814    -0.0461081    0.07923      0.0445046     0.0708137    0.0329774   -0.107165   -0.0162992     0.0593372
  0.110597    -0.0165145    0.0765828  -0.106969   -0.0106387    0.070556    -0.110182    0.0190708    0.0368823    0.0235078    -0.167601    -0.0120091    0.0316767    0.0460764   -0.014149     0.0813368   -0.0384697   -0.0795611     0.00621516  -0.107336    -0.012479      0.118227     0.0730538    0.0813944  -0.129705     -0.0670395
 -0.209087     0.0736271   -0.180752    0.0134165  -0.00850031   0.0172116    0.125323   -0.00323585  -0.0250544    0.151467     -0.114175    -0.0554533   -0.13436      0.0490318    0.183004     0.133008     0.00582485   0.0624223     0.0239036    0.0294168   -0.0347595     0.134113    -0.0902219   -0.0855894  -0.0188893     0.07279
 -0.211375    -0.00843355   0.0236316  -0.0923357  -0.110484    -0.0963739    0.0376437   0.268407     0.0509209    0.286836      0.217993    -0.0832884    0.150528     0.0427196   -0.00720497   0.167623     0.105972    -0.1553       -0.125767     0.0430727   -0.104947      0.00653439  -0.240062     0.186708   -0.0107184    -0.0807128
  0.0115924    0.0889732   -0.0305252  -0.0890573   0.109022     0.0989219   -0.02362     0.027216     0.0412946    0.00303662    0.06261      0.0123985    0.216559    -0.154529     0.0823769    0.0261228   -0.0916182    0.0518977    -0.0811985   -0.0316763   -0.036662      0.126527    -0.0287113    0.13384    -0.0781896     0.0878126kind full, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.4191776014098119
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419197
[ Info: iteration 2, average log likelihood -1.419128
[ Info: iteration 3, average log likelihood -1.419076
[ Info: iteration 4, average log likelihood -1.419013
[ Info: iteration 5, average log likelihood -1.418933
[ Info: iteration 6, average log likelihood -1.418831
[ Info: iteration 7, average log likelihood -1.418696
[ Info: iteration 8, average log likelihood -1.418500
[ Info: iteration 9, average log likelihood -1.418177
[ Info: iteration 10, average log likelihood -1.417615
[ Info: iteration 11, average log likelihood -1.416736
[ Info: iteration 12, average log likelihood -1.415665
[ Info: iteration 13, average log likelihood -1.414757
[ Info: iteration 14, average log likelihood -1.414222
[ Info: iteration 15, average log likelihood -1.413976
[ Info: iteration 16, average log likelihood -1.413876
[ Info: iteration 17, average log likelihood -1.413835
[ Info: iteration 18, average log likelihood -1.413819
[ Info: iteration 19, average log likelihood -1.413811
[ Info: iteration 20, average log likelihood -1.413808
[ Info: iteration 21, average log likelihood -1.413807
[ Info: iteration 22, average log likelihood -1.413806
[ Info: iteration 23, average log likelihood -1.413805
[ Info: iteration 24, average log likelihood -1.413804
[ Info: iteration 25, average log likelihood -1.413804
[ Info: iteration 26, average log likelihood -1.413804
[ Info: iteration 27, average log likelihood -1.413803
[ Info: iteration 28, average log likelihood -1.413803
[ Info: iteration 29, average log likelihood -1.413803
[ Info: iteration 30, average log likelihood -1.413802
[ Info: iteration 31, average log likelihood -1.413802
[ Info: iteration 32, average log likelihood -1.413802
[ Info: iteration 33, average log likelihood -1.413802
[ Info: iteration 34, average log likelihood -1.413802
[ Info: iteration 35, average log likelihood -1.413802
[ Info: iteration 36, average log likelihood -1.413802
[ Info: iteration 37, average log likelihood -1.413801
[ Info: iteration 38, average log likelihood -1.413801
[ Info: iteration 39, average log likelihood -1.413801
[ Info: iteration 40, average log likelihood -1.413801
[ Info: iteration 41, average log likelihood -1.413801
[ Info: iteration 42, average log likelihood -1.413801
[ Info: iteration 43, average log likelihood -1.413801
[ Info: iteration 44, average log likelihood -1.413801
[ Info: iteration 45, average log likelihood -1.413801
[ Info: iteration 46, average log likelihood -1.413801
[ Info: iteration 47, average log likelihood -1.413801
[ Info: iteration 48, average log likelihood -1.413801
[ Info: iteration 49, average log likelihood -1.413801
[ Info: iteration 50, average log likelihood -1.413801
â”Œ Info: EM with 100000 data points 50 iterations avll -1.413801
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4191970726316552
â”‚     -1.4191284115387302
â”‚      â‹®
â””     -1.4138006864385184
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413816
[ Info: iteration 2, average log likelihood -1.413749
[ Info: iteration 3, average log likelihood -1.413692
[ Info: iteration 4, average log likelihood -1.413624
[ Info: iteration 5, average log likelihood -1.413538
[ Info: iteration 6, average log likelihood -1.413436
[ Info: iteration 7, average log likelihood -1.413323
[ Info: iteration 8, average log likelihood -1.413208
[ Info: iteration 9, average log likelihood -1.413101
[ Info: iteration 10, average log likelihood -1.413007
[ Info: iteration 11, average log likelihood -1.412930
[ Info: iteration 12, average log likelihood -1.412870
[ Info: iteration 13, average log likelihood -1.412825
[ Info: iteration 14, average log likelihood -1.412791
[ Info: iteration 15, average log likelihood -1.412767
[ Info: iteration 16, average log likelihood -1.412748
[ Info: iteration 17, average log likelihood -1.412734
[ Info: iteration 18, average log likelihood -1.412721
[ Info: iteration 19, average log likelihood -1.412710
[ Info: iteration 20, average log likelihood -1.412700
[ Info: iteration 21, average log likelihood -1.412691
[ Info: iteration 22, average log likelihood -1.412682
[ Info: iteration 23, average log likelihood -1.412673
[ Info: iteration 24, average log likelihood -1.412666
[ Info: iteration 25, average log likelihood -1.412658
[ Info: iteration 26, average log likelihood -1.412651
[ Info: iteration 27, average log likelihood -1.412644
[ Info: iteration 28, average log likelihood -1.412638
[ Info: iteration 29, average log likelihood -1.412632
[ Info: iteration 30, average log likelihood -1.412626
[ Info: iteration 31, average log likelihood -1.412621
[ Info: iteration 32, average log likelihood -1.412616
[ Info: iteration 33, average log likelihood -1.412612
[ Info: iteration 34, average log likelihood -1.412607
[ Info: iteration 35, average log likelihood -1.412603
[ Info: iteration 36, average log likelihood -1.412599
[ Info: iteration 37, average log likelihood -1.412596
[ Info: iteration 38, average log likelihood -1.412592
[ Info: iteration 39, average log likelihood -1.412589
[ Info: iteration 40, average log likelihood -1.412586
[ Info: iteration 41, average log likelihood -1.412583
[ Info: iteration 42, average log likelihood -1.412580
[ Info: iteration 43, average log likelihood -1.412577
[ Info: iteration 44, average log likelihood -1.412574
[ Info: iteration 45, average log likelihood -1.412571
[ Info: iteration 46, average log likelihood -1.412568
[ Info: iteration 47, average log likelihood -1.412566
[ Info: iteration 48, average log likelihood -1.412563
[ Info: iteration 49, average log likelihood -1.412561
[ Info: iteration 50, average log likelihood -1.412558
â”Œ Info: EM with 100000 data points 50 iterations avll -1.412558
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4138162405704924
â”‚     -1.413748812809412
â”‚      â‹®
â””     -1.4125583811672993
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412566
[ Info: iteration 2, average log likelihood -1.412513
[ Info: iteration 3, average log likelihood -1.412469
[ Info: iteration 4, average log likelihood -1.412419
[ Info: iteration 5, average log likelihood -1.412357
[ Info: iteration 6, average log likelihood -1.412281
[ Info: iteration 7, average log likelihood -1.412192
[ Info: iteration 8, average log likelihood -1.412093
[ Info: iteration 9, average log likelihood -1.411992
[ Info: iteration 10, average log likelihood -1.411897
[ Info: iteration 11, average log likelihood -1.411813
[ Info: iteration 12, average log likelihood -1.411740
[ Info: iteration 13, average log likelihood -1.411678
[ Info: iteration 14, average log likelihood -1.411626
[ Info: iteration 15, average log likelihood -1.411582
[ Info: iteration 16, average log likelihood -1.411544
[ Info: iteration 17, average log likelihood -1.411512
[ Info: iteration 18, average log likelihood -1.411484
[ Info: iteration 19, average log likelihood -1.411459
[ Info: iteration 20, average log likelihood -1.411438
[ Info: iteration 21, average log likelihood -1.411419
[ Info: iteration 22, average log likelihood -1.411402
[ Info: iteration 23, average log likelihood -1.411386
[ Info: iteration 24, average log likelihood -1.411372
[ Info: iteration 25, average log likelihood -1.411359
[ Info: iteration 26, average log likelihood -1.411346
[ Info: iteration 27, average log likelihood -1.411335
[ Info: iteration 28, average log likelihood -1.411324
[ Info: iteration 29, average log likelihood -1.411313
[ Info: iteration 30, average log likelihood -1.411303
[ Info: iteration 31, average log likelihood -1.411293
[ Info: iteration 32, average log likelihood -1.411283
[ Info: iteration 33, average log likelihood -1.411273
[ Info: iteration 34, average log likelihood -1.411263
[ Info: iteration 35, average log likelihood -1.411254
[ Info: iteration 36, average log likelihood -1.411244
[ Info: iteration 37, average log likelihood -1.411234
[ Info: iteration 38, average log likelihood -1.411223
[ Info: iteration 39, average log likelihood -1.411213
[ Info: iteration 40, average log likelihood -1.411202
[ Info: iteration 41, average log likelihood -1.411191
[ Info: iteration 42, average log likelihood -1.411180
[ Info: iteration 43, average log likelihood -1.411169
[ Info: iteration 44, average log likelihood -1.411158
[ Info: iteration 45, average log likelihood -1.411147
[ Info: iteration 46, average log likelihood -1.411135
[ Info: iteration 47, average log likelihood -1.411123
[ Info: iteration 48, average log likelihood -1.411112
[ Info: iteration 49, average log likelihood -1.411100
[ Info: iteration 50, average log likelihood -1.411089
â”Œ Info: EM with 100000 data points 50 iterations avll -1.411089
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.412566256623558
â”‚     -1.412513194969039
â”‚      â‹®
â””     -1.411088760200452
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411087
[ Info: iteration 2, average log likelihood -1.411020
[ Info: iteration 3, average log likelihood -1.410959
[ Info: iteration 4, average log likelihood -1.410891
[ Info: iteration 5, average log likelihood -1.410809
[ Info: iteration 6, average log likelihood -1.410711
[ Info: iteration 7, average log likelihood -1.410597
[ Info: iteration 8, average log likelihood -1.410472
[ Info: iteration 9, average log likelihood -1.410340
[ Info: iteration 10, average log likelihood -1.410211
[ Info: iteration 11, average log likelihood -1.410090
[ Info: iteration 12, average log likelihood -1.409982
[ Info: iteration 13, average log likelihood -1.409887
[ Info: iteration 14, average log likelihood -1.409806
[ Info: iteration 15, average log likelihood -1.409737
[ Info: iteration 16, average log likelihood -1.409678
[ Info: iteration 17, average log likelihood -1.409629
[ Info: iteration 18, average log likelihood -1.409586
[ Info: iteration 19, average log likelihood -1.409550
[ Info: iteration 20, average log likelihood -1.409518
[ Info: iteration 21, average log likelihood -1.409491
[ Info: iteration 22, average log likelihood -1.409466
[ Info: iteration 23, average log likelihood -1.409444
[ Info: iteration 24, average log likelihood -1.409423
[ Info: iteration 25, average log likelihood -1.409404
[ Info: iteration 26, average log likelihood -1.409387
[ Info: iteration 27, average log likelihood -1.409370
[ Info: iteration 28, average log likelihood -1.409355
[ Info: iteration 29, average log likelihood -1.409340
[ Info: iteration 30, average log likelihood -1.409325
[ Info: iteration 31, average log likelihood -1.409312
[ Info: iteration 32, average log likelihood -1.409298
[ Info: iteration 33, average log likelihood -1.409286
[ Info: iteration 34, average log likelihood -1.409273
[ Info: iteration 35, average log likelihood -1.409261
[ Info: iteration 36, average log likelihood -1.409250
[ Info: iteration 37, average log likelihood -1.409238
[ Info: iteration 38, average log likelihood -1.409227
[ Info: iteration 39, average log likelihood -1.409217
[ Info: iteration 40, average log likelihood -1.409206
[ Info: iteration 41, average log likelihood -1.409196
[ Info: iteration 42, average log likelihood -1.409186
[ Info: iteration 43, average log likelihood -1.409176
[ Info: iteration 44, average log likelihood -1.409166
[ Info: iteration 45, average log likelihood -1.409157
[ Info: iteration 46, average log likelihood -1.409148
[ Info: iteration 47, average log likelihood -1.409138
[ Info: iteration 48, average log likelihood -1.409130
[ Info: iteration 49, average log likelihood -1.409121
[ Info: iteration 50, average log likelihood -1.409112
â”Œ Info: EM with 100000 data points 50 iterations avll -1.409112
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4110866541315725
â”‚     -1.4110204345936097
â”‚      â‹®
â””     -1.4091121189801563
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409114
[ Info: iteration 2, average log likelihood -1.409039
[ Info: iteration 3, average log likelihood -1.408971
[ Info: iteration 4, average log likelihood -1.408891
[ Info: iteration 5, average log likelihood -1.408793
[ Info: iteration 6, average log likelihood -1.408672
[ Info: iteration 7, average log likelihood -1.408528
[ Info: iteration 8, average log likelihood -1.408364
[ Info: iteration 9, average log likelihood -1.408189
[ Info: iteration 10, average log likelihood -1.408013
[ Info: iteration 11, average log likelihood -1.407844
[ Info: iteration 12, average log likelihood -1.407690
[ Info: iteration 13, average log likelihood -1.407553
[ Info: iteration 14, average log likelihood -1.407434
[ Info: iteration 15, average log likelihood -1.407332
[ Info: iteration 16, average log likelihood -1.407243
[ Info: iteration 17, average log likelihood -1.407166
[ Info: iteration 18, average log likelihood -1.407099
[ Info: iteration 19, average log likelihood -1.407039
[ Info: iteration 20, average log likelihood -1.406987
[ Info: iteration 21, average log likelihood -1.406939
[ Info: iteration 22, average log likelihood -1.406897
[ Info: iteration 23, average log likelihood -1.406858
[ Info: iteration 24, average log likelihood -1.406823
[ Info: iteration 25, average log likelihood -1.406791
[ Info: iteration 26, average log likelihood -1.406761
[ Info: iteration 27, average log likelihood -1.406732
[ Info: iteration 28, average log likelihood -1.406706
[ Info: iteration 29, average log likelihood -1.406680
[ Info: iteration 30, average log likelihood -1.406656
[ Info: iteration 31, average log likelihood -1.406633
[ Info: iteration 32, average log likelihood -1.406611
[ Info: iteration 33, average log likelihood -1.406589
[ Info: iteration 34, average log likelihood -1.406567
[ Info: iteration 35, average log likelihood -1.406546
[ Info: iteration 36, average log likelihood -1.406526
[ Info: iteration 37, average log likelihood -1.406505
[ Info: iteration 38, average log likelihood -1.406485
[ Info: iteration 39, average log likelihood -1.406466
[ Info: iteration 40, average log likelihood -1.406446
[ Info: iteration 41, average log likelihood -1.406427
[ Info: iteration 42, average log likelihood -1.406408
[ Info: iteration 43, average log likelihood -1.406389
[ Info: iteration 44, average log likelihood -1.406370
[ Info: iteration 45, average log likelihood -1.406352
[ Info: iteration 46, average log likelihood -1.406335
[ Info: iteration 47, average log likelihood -1.406318
[ Info: iteration 48, average log likelihood -1.406301
[ Info: iteration 49, average log likelihood -1.406284
[ Info: iteration 50, average log likelihood -1.406268
â”Œ Info: EM with 100000 data points 50 iterations avll -1.406268
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.409114195274027
â”‚     -1.4090394752845448
â”‚      â‹®
â””     -1.4062684649441677
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.4191776014098119
â”‚     -1.4191970726316552
â”‚     -1.4191284115387302
â”‚     -1.4190758933180363
â”‚      â‹®
â”‚     -1.4063007166740509
â”‚     -1.4062843678683274
â””     -1.4062684649441677
32Ã—26 Array{Float64,2}:
 -0.229411     0.269566     0.577118     0.0457365    0.161957   -0.051924     0.105697    0.227163   -0.0239827   -0.633241    -0.0479292    0.211007   -0.450596      0.379524    -0.0695784    0.0891729    -0.636376    0.266331    0.187991    -0.440422     0.834489   -0.332149    0.112812    0.536121    -0.234961     0.310924
 -0.339241    -0.193948     0.0667117   -0.284212     0.0240977   0.257347     0.0899997  -0.343721   -0.150633    -0.418299     0.164657    -0.0683554  -0.749341      0.688601     0.00163378  -0.0737723     0.114097    0.257284   -0.416952    -0.110781     0.391931    0.712073    0.237948    0.0726674   -0.428194     0.458988
 -0.304908    -0.376002     0.251916    -0.264048    -0.0912057   0.00747131   0.157469    0.675502    0.370027    -0.0474671    0.43824     -0.299886    0.274935      0.654138     0.262732     0.508854     -0.429239   -0.67244    -0.022335    -0.0478745    0.0684567  -0.0570803   0.447498    0.211648    -0.596721    -0.0254395
 -0.603624    -0.258107    -0.203182    -0.482868    -0.123158   -0.42289     -0.182002    0.304849   -0.0310555    0.443935     0.199802     0.156473    0.74774       0.532027     0.418166     0.152647      0.497181   -0.402041   -0.0017827    0.493225     0.259584    0.346529    0.171165    0.127599     0.0954721   -0.366048
  0.526838    -0.80611      0.442736    -0.293685    -0.138571    0.185831     0.535107   -0.0628047   0.02762     -0.285717     0.0669307    0.37118    -0.483699      0.099907    -0.225944    -0.653888     -0.727699    0.173829   -0.509394    -0.461335    -0.492278    0.199322   -1.02594    -0.355577     0.284135     0.386529
  0.345979    -0.453076     0.00467412   0.638928    -0.0472351  -0.0588784   -0.290082    0.0310166   0.112687    -0.199497     0.575353     0.270412   -0.236741     -0.074675     0.210799     0.241672     -0.704654   -0.121899   -0.183057    -0.996816    -0.132971    0.190804   -0.316205   -0.376051     0.242657    -0.798881
 -0.58291      0.158836     0.218834    -0.0507729   -0.989672    0.256246    -0.173923    0.0704286   0.489963     0.34321      0.227256     0.517386   -0.323329     -0.698204    -0.134964    -0.656469      0.0393268  -0.444576   -0.316043     0.116206     0.532829    0.196095   -0.0311429   0.0712973   -0.00657293   0.230876
  0.109274     0.431202     0.295572     0.0117509   -0.589854   -0.145824    -0.491683    0.277322   -0.120231     0.0256684   -0.15925      0.498566   -0.189699     -0.319303    -0.586843     0.516415     -0.271529   -0.126554   -0.035558    -0.363439    -0.145394   -0.0805404  -0.381497   -0.261754     0.328037     0.301986
  0.552988     0.152589    -0.755754    -0.413914     0.642306   -0.34795     -0.302357   -0.0126074   0.658586    -0.334271     0.292698    -0.130107    1.4903       -0.527227    -0.313911     0.388435      0.122182   -0.52973     1.15556      0.259799     0.718282   -1.12667    -1.24107    -0.623909     0.416734    -0.522344
 -0.195853     0.514127    -0.0256915    0.450325     0.0742152  -0.0101575   -0.497728    0.218149   -0.0921989    0.362955    -0.324377     0.382225    0.658603     -0.52408     -0.0443153    0.428757      0.148016   -0.231581    0.666982     0.0660505   -0.0382676  -0.594564    0.339454   -0.0197876    0.114747    -0.397821
 -0.218886     0.432558    -0.266924     0.160943     0.911477    0.493356     0.740045    0.14322     0.236473     0.339388    -0.244137     0.283513   -0.000323136  -0.150543    -0.289147     0.0224979    -0.671216   -0.606828   -0.281854     0.23983      0.316771    0.0674698   0.276895   -0.0125115    0.721185    -0.0260562
 -0.0199713    0.260418    -0.638307    -0.210044    -0.164087   -0.169139     0.466366    0.117372    0.608648     0.00992104  -0.0328627    0.141874   -0.248585      0.194178     0.161616     0.291156      0.359003    0.172932    0.575523    -0.567869    -0.106026    0.164959   -0.0297198  -0.102822     0.916417    -0.23405
  0.00685477  -0.315332     0.276845    -0.201127     0.212053   -0.183589     0.423401   -0.374228   -0.256079     0.0514764   -0.0121766   -0.571871    0.528409      0.0337744    0.438862    -0.527397      0.130336    0.0908008  -0.10708      0.120368    -0.233522   -0.148531   -0.175733    0.273231    -0.698625     0.14897
 -0.00855908  -0.513569     0.00726807   0.187843    -0.440715   -0.136434     0.361206    0.472914    0.0745289    0.623736    -0.729979     0.233907   -0.153514     -0.0811326   -0.223397    -0.588148     -0.139762   -0.0958961  -1.17578      0.0921174   -0.0027967   0.307169    0.554708    0.68638     -0.0439041   -0.359851
  0.0671861    0.166935    -0.0678694   -0.141137    -0.119911    0.0424277   -0.191009    0.0711557   0.0181556    0.0745683   -0.0118376    0.232257    0.0430962    -0.0943678   -0.0373283    0.329701     -0.108948   -0.0124271   0.250876    -0.142185    -0.145052    0.0888737   0.174802   -0.107802     0.140998    -0.0635045
 -0.163496     0.307057    -0.0686695    0.258788     0.17074     0.0954073    0.0467694  -0.0187543  -0.516798     0.063072    -0.475221    -0.217849   -0.23269      -0.318107    -0.382496     0.350777      1.25077     0.609151   -0.0358169    0.417773     0.403713   -0.0373253  -0.044745   -0.107577     0.363005     0.354434
  0.217026    -0.219785    -0.340464     0.210837    -0.400811   -0.780318    -0.564293   -0.0273147   0.13541     -0.341227    -0.0350229    0.0228433  -0.150639      0.0882553    0.13616     -0.72542       0.0193258   0.184625    0.199131     0.161611    -0.0343563  -0.281645    0.0260568   0.125248    -0.93243      0.15116
  0.565056    -0.138923     0.0863853    0.249783     0.522755   -1.01866      0.365231    0.319491   -0.592209    -0.253071     0.0148342   -0.0131257   0.24446      -0.113155     0.752037    -0.000139534  -0.354552    0.100931    0.0137396   -0.331967     0.105927   -0.640099   -0.255149    0.0292597    0.553652     0.371772
  0.387487    -0.409392    -0.158001     0.147105    -0.100515   -0.206044     0.199213    0.294767   -0.223042     0.418199     0.229285    -0.321435    0.139935     -0.0835236   -0.204678     0.0598803     0.0216786   0.106488    0.0997125   -0.415309    -0.816581   -0.606003   -0.0675916  -0.248509     0.109008    -0.211056
  0.200646    -0.134775    -0.102       -0.782605    -0.17485     0.16446     -0.163709   -0.600275   -0.0503516    0.0759052   -0.0347117   -0.332042    0.0660874    -0.0737079   -0.0698075    0.269458      0.0615999   0.177452    0.52523     -0.309504    -0.700255    0.184241   -0.239902   -0.100772    -0.248225     0.327332
  0.134786    -0.0380607    0.0847892    0.059045    -0.155326   -0.10308      0.355022   -0.545246    0.110411     0.56204      0.010258    -0.184574    0.490251     -0.395052     0.523251    -0.716097     -0.138631   -0.179666    0.0451745    0.278771    -0.670437   -0.0563668   0.0277298  -0.381126    -0.262278    -0.333182
 -0.0475232    0.00958969   0.192074     0.731324     0.534057    0.102503     0.194848   -0.474418   -0.075489     0.0366702    0.330535    -0.391962   -0.08174      -0.259048     0.231563    -0.356772      0.257421   -0.440711   -0.255511     0.639772     0.301024   -0.124842   -0.0700265  -0.0782135   -0.525059     0.153115
  0.384668    -0.055161     0.0488295   -0.416821    -0.19718    -0.0792068   -0.0524844   0.550954    0.105827     0.187844    -0.00643537  -0.833479   -0.151214      0.427386    -0.00485298  -0.0575985    -0.0455136  -0.295775   -0.840301     0.00282811   0.242153    0.26514    -0.408      -0.543046    -0.355568    -0.230968
  0.573364    -0.149916    -0.598728    -0.00235069  -0.208555    0.594868     0.0341456   0.268738   -0.139582     0.0872618    0.407744    -0.653376    0.129276     -0.175696     0.00155508  -0.336703     -0.194992   -0.263208   -0.334739     0.18401      0.365972   -0.0125777   0.697821    0.192251    -0.51922     -0.318454
  0.087646    -0.00809533   0.238424    -0.208131    -0.0841176  -0.052549     0.183492    0.177023   -0.0650924    0.0210618    0.13861     -0.229883   -0.0659494    -0.0726774    0.057302    -0.00559558   -0.384087   -0.0393714  -0.147642    -0.265439     0.0396268  -0.0752286  -0.234064    0.00118284  -0.122067     0.203893
  0.013699    -0.131735    -0.162128     0.0938347    0.0844643  -0.0468204   -0.132263   -0.0962814  -0.00509198   0.0104981   -0.0621329    0.0185952   0.0560975     0.0448169   -0.00853692  -0.0820829     0.279519   -0.0542253   0.00781804   0.176779    -0.0214936  -0.0688523   0.0392467  -0.0712754   -0.074304    -0.0496629
 -0.174143     0.234577    -0.132217     0.297895     0.115645   -0.111611     0.0710835  -0.107502    0.20069      0.149458     0.0123749    0.672719   -0.132162     -0.165572     0.122955     0.00559603   -0.103241   -0.206692   -0.111574    -0.268631     0.330735    0.665885   -0.535764    0.198257     0.197887     0.0210857
 -0.271225     0.213645     0.139122    -0.0520844   -0.0697635   0.216995     0.180778    0.17598     0.0194541   -0.0759859   -0.0645117    0.490357   -0.0589956     0.137514    -0.118625     0.256978     -0.0908105  -0.0372335  -0.011921     0.11638      0.327933    0.292653    0.436684    0.211466     0.382378     0.0348266
  0.403594     0.0666538   -0.328949    -0.041498     0.205803    0.451992    -0.419916   -0.236778    0.0962355   -0.210933    -1.03282      0.221256   -0.200053      0.168843    -0.0602754   -0.415698      0.323435    0.637828    0.0733218    0.274595    -0.215628    0.252221    0.240808   -0.0959598    0.616825    -0.507593
 -0.21058     -0.322414    -0.279186     0.769615     0.597724   -0.173674    -0.355179   -0.499471    0.113261    -0.530313     0.339792     0.92202    -0.0306981    -0.0681158   -0.213418    -0.0921247     0.1784      0.31381     0.397214     0.201422    -0.052318   -0.132795    0.163519    0.0596352    0.366191    -0.117238
 -0.193446     0.276187     0.420315    -0.565303    -0.122669   -0.055935     0.264161    0.342022   -0.198712     0.207276    -0.557091    -0.375169    0.244276     -0.00985013  -0.165849    -0.162962      0.313996    0.247624    0.15191      0.717513     0.0289625  -0.150089    0.0359941   0.349259    -0.207225     0.503263
  0.00278617   0.264633    -0.0405436   -0.118519     0.929903    0.368302     0.243934   -0.168503   -0.169244    -0.0343624   -0.409526    -0.0766196   0.448535      0.351862     0.155525     0.913862      0.227156    0.357017    0.336189     0.218164    -0.115003   -0.0747792   0.402142    0.00351741   0.0842611    0.145379[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406253
[ Info: iteration 2, average log likelihood -1.406238
[ Info: iteration 3, average log likelihood -1.406224
[ Info: iteration 4, average log likelihood -1.406210
[ Info: iteration 5, average log likelihood -1.406196
[ Info: iteration 6, average log likelihood -1.406183
[ Info: iteration 7, average log likelihood -1.406171
[ Info: iteration 8, average log likelihood -1.406159
[ Info: iteration 9, average log likelihood -1.406147
[ Info: iteration 10, average log likelihood -1.406136
â”Œ Info: EM with 100000 data points 10 iterations avll -1.406136
â”” 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.495844e+05
      1       6.948311e+05      -2.547534e+05 |       32
      2       6.849299e+05      -9.901131e+03 |       32
      3       6.807668e+05      -4.163105e+03 |       32
      4       6.783199e+05      -2.446890e+03 |       32
      5       6.766350e+05      -1.684980e+03 |       32
      6       6.753482e+05      -1.286799e+03 |       32
      7       6.743102e+05      -1.037970e+03 |       32
      8       6.735044e+05      -8.057679e+02 |       32
      9       6.728220e+05      -6.823696e+02 |       32
     10       6.722457e+05      -5.763148e+02 |       32
     11       6.717829e+05      -4.628284e+02 |       32
     12       6.713464e+05      -4.364555e+02 |       32
     13       6.709684e+05      -3.780312e+02 |       32
     14       6.706682e+05      -3.002038e+02 |       32
     15       6.703983e+05      -2.699262e+02 |       32
     16       6.701436e+05      -2.546967e+02 |       32
     17       6.698969e+05      -2.466931e+02 |       32
     18       6.696465e+05      -2.504007e+02 |       32
     19       6.694269e+05      -2.195686e+02 |       32
     20       6.692425e+05      -1.843824e+02 |       32
     21       6.690965e+05      -1.460307e+02 |       32
     22       6.689795e+05      -1.169717e+02 |       32
     23       6.688814e+05      -9.816167e+01 |       32
     24       6.687898e+05      -9.154679e+01 |       32
     25       6.687165e+05      -7.337966e+01 |       32
     26       6.686476e+05      -6.882501e+01 |       32
     27       6.685832e+05      -6.442471e+01 |       32
     28       6.685192e+05      -6.405111e+01 |       32
     29       6.684602e+05      -5.890268e+01 |       32
     30       6.684059e+05      -5.434410e+01 |       32
     31       6.683462e+05      -5.968060e+01 |       32
     32       6.682907e+05      -5.549112e+01 |       32
     33       6.682435e+05      -4.722486e+01 |       32
     34       6.682001e+05      -4.336907e+01 |       32
     35       6.681600e+05      -4.013537e+01 |       32
     36       6.681231e+05      -3.685777e+01 |       32
     37       6.680830e+05      -4.015610e+01 |       32
     38       6.680464e+05      -3.654056e+01 |       32
     39       6.680113e+05      -3.515408e+01 |       32
     40       6.679768e+05      -3.452708e+01 |       32
     41       6.679449e+05      -3.187930e+01 |       32
     42       6.679119e+05      -3.296899e+01 |       32
     43       6.678795e+05      -3.237669e+01 |       32
     44       6.678451e+05      -3.439724e+01 |       32
     45       6.678128e+05      -3.238296e+01 |       32
     46       6.677799e+05      -3.281585e+01 |       32
     47       6.677443e+05      -3.561246e+01 |       32
     48       6.677038e+05      -4.054604e+01 |       32
     49       6.676662e+05      -3.758014e+01 |       32
     50       6.676239e+05      -4.235047e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 667623.8581358483)
â”Œ Info: K-means with 32000 data points using 50 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417907
[ Info: iteration 2, average log likelihood -1.412970
[ Info: iteration 3, average log likelihood -1.411657
[ Info: iteration 4, average log likelihood -1.410710
[ Info: iteration 5, average log likelihood -1.409726
[ Info: iteration 6, average log likelihood -1.408805
[ Info: iteration 7, average log likelihood -1.408143
[ Info: iteration 8, average log likelihood -1.407756
[ Info: iteration 9, average log likelihood -1.407530
[ Info: iteration 10, average log likelihood -1.407379
[ Info: iteration 11, average log likelihood -1.407263
[ Info: iteration 12, average log likelihood -1.407164
[ Info: iteration 13, average log likelihood -1.407077
[ Info: iteration 14, average log likelihood -1.406996
[ Info: iteration 15, average log likelihood -1.406921
[ Info: iteration 16, average log likelihood -1.406852
[ Info: iteration 17, average log likelihood -1.406786
[ Info: iteration 18, average log likelihood -1.406725
[ Info: iteration 19, average log likelihood -1.406667
[ Info: iteration 20, average log likelihood -1.406613
[ Info: iteration 21, average log likelihood -1.406562
[ Info: iteration 22, average log likelihood -1.406513
[ Info: iteration 23, average log likelihood -1.406468
[ Info: iteration 24, average log likelihood -1.406425
[ Info: iteration 25, average log likelihood -1.406385
[ Info: iteration 26, average log likelihood -1.406347
[ Info: iteration 27, average log likelihood -1.406312
[ Info: iteration 28, average log likelihood -1.406279
[ Info: iteration 29, average log likelihood -1.406247
[ Info: iteration 30, average log likelihood -1.406218
[ Info: iteration 31, average log likelihood -1.406191
[ Info: iteration 32, average log likelihood -1.406165
[ Info: iteration 33, average log likelihood -1.406140
[ Info: iteration 34, average log likelihood -1.406118
[ Info: iteration 35, average log likelihood -1.406096
[ Info: iteration 36, average log likelihood -1.406076
[ Info: iteration 37, average log likelihood -1.406057
[ Info: iteration 38, average log likelihood -1.406038
[ Info: iteration 39, average log likelihood -1.406021
[ Info: iteration 40, average log likelihood -1.406005
[ Info: iteration 41, average log likelihood -1.405990
[ Info: iteration 42, average log likelihood -1.405975
[ Info: iteration 43, average log likelihood -1.405961
[ Info: iteration 44, average log likelihood -1.405947
[ Info: iteration 45, average log likelihood -1.405934
[ Info: iteration 46, average log likelihood -1.405922
[ Info: iteration 47, average log likelihood -1.405910
[ Info: iteration 48, average log likelihood -1.405898
[ Info: iteration 49, average log likelihood -1.405887
[ Info: iteration 50, average log likelihood -1.405875
â”Œ Info: EM with 100000 data points 50 iterations avll -1.405875
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.464149    -0.201029   -0.29434      0.0958637    0.838466    0.516345    -0.274258   -0.194431   -0.282805    -0.342566    -0.895928    -0.00554265   0.0728019    0.21896    -0.145109     -0.119419    0.458134     0.654809      0.108906     0.346158   -0.0327098  -0.0289221    0.242494    0.222521    0.393045    -0.285421
  0.8362      -0.154161   -0.885682     0.103743    -0.215039    0.298306     0.041234    0.423825   -0.300819    -0.00649577   0.29057     -0.577704     0.15074     -0.140742   -0.142371     -0.447004   -0.109954    -0.0659011    -0.530467     0.177526    0.351379   -0.245536     0.83009     0.42258    -0.593726    -0.226731
  0.513064    -0.120046    0.136364     0.196724     0.523304   -0.927176     0.414723    0.318618   -0.536075    -0.181211     0.0391789   -0.0635974    0.266262    -0.0786133   0.657657      0.0743229  -0.315418     0.147888     -0.0107075   -0.373085    0.0309179  -0.668409    -0.244067    0.0871266   0.422811     0.401079
  0.717704    -0.617297    0.00647419  -0.0328119    0.0738768  -0.245417     0.370837   -0.0158978  -0.0550819   -0.061803     0.0749297   -0.0204296   -0.0393213    0.320283   -0.0744267     0.177707   -0.540328     0.157708      0.236463    -0.587307   -1.21563    -0.0238348   -0.326279   -0.514673    0.091048    -0.382688
 -0.120051     0.0250189   0.095403     0.00668861   0.135759    0.0296299   -0.0612001   0.134433   -0.00730605  -0.185267     0.00366864   0.117668     0.00304347   0.189761   -0.0619888     0.160836    0.00313199   0.00227782    0.00504488   0.0291312   0.22505    -0.00685738   0.0755859   0.121051   -0.0263663    0.151738
 -0.0509325    0.0588103   0.100525     0.361694     0.608069    0.0826609    0.502868    0.381012    0.329847     0.0268873   -0.307525    -0.111391    -0.00841001   0.292271    0.248395     -0.171448   -0.423335    -0.430097     -0.490068     0.593725    0.435472    0.0297512    0.33687     0.132803   -0.045651    -0.287797
  0.00945521   0.61131    -0.141848    -0.658332    -0.325818    0.243645    -0.192901    0.0454175   0.295659     0.0282685   -0.496948     0.687361    -0.090528     0.0515517   0.0947863     0.255234   -0.0871417    0.399174      0.245165    -0.322531    0.0152292   0.620676     0.163726   -0.192266    0.608283    -0.0828565
 -0.226263     0.415868   -0.0187324   -0.271654    -0.0801517   0.0828176    0.161897   -0.452411   -0.38438     -0.270721    -0.160135     0.0245371   -0.418419     0.101895    0.103979     -0.326558    0.328769     0.0926784    -0.208321     0.323073    0.675553    0.607511     0.137699   -0.0481591   0.0450811    0.0899498
 -0.825171     0.234028    0.238219    -0.0104248   -0.878773    0.330999    -0.290697    0.176818    0.608388     0.285691     0.131568     0.567696    -0.255567    -0.566276   -0.283899     -0.378178    0.223435    -0.419639     -0.196587     0.268039    0.622161    0.234319     0.171758    0.279996   -0.00900477   0.270589
  0.344296     0.594858    0.144203    -0.3694      -0.348719    0.202653     0.054855   -0.280455   -0.0500017    0.239541     0.00426352  -0.880805     0.160483    -0.78968     0.000508189   0.26047    -0.591357    -0.495011      0.163734    -0.441568   -0.499191    0.290641    -0.038793    0.0879218  -0.134976     0.198873
 -0.231321    -0.388082    0.0932778   -0.514925    -0.143282    0.0475318    0.0420997   0.458761    0.110235    -0.073697     0.332918    -0.520998    -0.0291656    0.813171    0.106961      0.328889   -0.0528909   -0.336137     -0.311876    -0.0666985   0.347005    0.202276     0.203892    0.0487806  -0.463399    -0.0164669
  0.0778668   -0.0777615  -0.336884    -0.0509121   -0.146236   -0.294989    -0.420634    0.572276    0.358689     0.904224    -0.377918    -0.0442129    0.973217    -0.457       0.0723413     0.167108    0.306178    -0.600909     -0.0811112    0.409666   -0.291091   -0.190963    -0.442149   -0.26155     0.139276    -0.740494
  0.106674     0.148668    0.117228     0.0718832   -0.0658411   0.280965     0.341222   -0.0417508   0.158856     0.405577    -0.176699     0.179016    -0.135934    -0.626274   -0.161662     -0.199328   -0.169976    -0.140943     -0.316337     0.0127546  -0.0618047   0.185883    -0.265863    0.135985    0.0192211    0.181017
  0.039305     0.214562    0.200023     0.246545    -0.369201   -0.239515    -0.545596   -0.111604   -0.402466     0.0816036   -0.324898     0.619179     0.2986      -0.254835   -0.475681      0.0188306   0.177454     0.251951      0.394398    -0.384018   -0.379415   -0.507325    -0.187465   -0.0144801   0.138964    -0.128629
 -0.664718    -0.253406    0.460615     0.311318    -0.477235    0.177706     0.259527   -0.196766   -0.462884     0.58208     -0.85045      0.344007    -0.99197      0.537415   -0.168939     -0.330745    0.202305     0.276957     -1.39629     -0.422226   -0.633209    1.07431      0.984197    0.702534   -0.356187     0.371262
 -0.024577    -0.271299    0.180029    -0.260867     0.0163016  -0.0876152    0.392226   -0.72688    -0.134304     0.294277    -0.0350278   -0.451806     0.658102    -0.136508    0.563143     -0.732067    0.318453     0.138562     -0.0159746    0.34448    -0.440236    0.022007    -0.0251362   0.137329   -0.704815     0.117457
 -0.487389    -0.423836    0.289226     0.0261953    0.203167    0.536521     0.14703     0.490681   -0.995555     0.127064     0.769273     0.176035     0.864035    -0.900769   -0.0464673     0.111471    0.0476804    0.11547      -0.518733    -0.575709    0.115586    0.295123     0.0243226  -0.407361    0.0290508   -0.38953
 -0.230609     0.606455   -0.530013     0.71783      0.105644    0.0942667    0.557312    0.0349977   0.0386006    0.156813    -0.515057    -0.391679    -0.459938    -0.35462    -0.609154      0.862791    1.10296      0.574397      0.0695318   -0.371297   -0.0492171  -0.174426    -0.169824   -0.427623    0.324587     0.312956
  0.0753156   -0.104225    0.0985518    0.765355    -0.0464495  -0.394425    -0.500751   -0.166813    0.103032    -0.195776     0.346482    -0.129387    -0.0443356   -0.205841    0.338458     -0.568011   -0.105719     0.000833635   0.171447     0.129799    0.186215   -0.155133     0.140959   -0.325664   -0.657025    -0.339191
 -0.246313    -0.293891   -0.467711     0.93717      0.618189   -0.158918    -0.309274   -0.569114    0.187212    -0.518341     0.397693     1.045       -0.1798      -0.0916413  -0.132127     -0.0562805   0.0496748    0.0987843     0.100657     0.0248082   0.0264428   0.247966     0.0184155   0.182601    0.437593    -0.230808
  0.169658     0.251016   -0.249566    -0.0694041    0.683006   -0.0309727   -0.507372   -0.354597    0.203311    -0.452213     0.449319     0.0243809    0.608187    -0.115949   -0.0276322     0.697946    0.187731    -0.162749      1.20526     -0.0728551   0.340079   -0.779725    -0.556492   -0.661825    0.0643131    0.00655043
  0.125701    -0.334518   -0.237599    -0.364253     0.244185    0.264109     0.11469    -0.339364    0.200218     0.00806649   0.169134    -0.158418    -0.317875     0.21859    -0.120747      0.2529      0.0867714    0.316326      0.247462    -0.171513   -0.468021    0.274341    -0.0252644  -0.209962    0.0222963    0.228254
  0.294511    -0.279534   -0.200525    -0.147261    -0.246506   -0.250391     0.0676798   0.113292   -0.0595766    0.348273     0.102527    -0.370062     0.1974      -0.0304866   0.148301     -0.226262   -0.0283397   -0.182144     -0.0843111   -0.0890281  -0.377312   -0.308086    -0.0393916  -0.254359   -0.117742    -0.206952
 -0.116282     0.0617162   0.154226     0.0374133    0.20778    -0.0226928   -0.0545309   0.0793811  -0.298725     0.0112272   -0.16192     -0.0795384    0.179042     0.0450969   0.0204907     0.230172    0.278676     0.0805828     0.059752     0.357605    0.16803    -0.0636428    0.205432    0.24112    -0.137123     0.178994
 -0.186787     0.330848    0.588907    -0.609817    -0.140073   -0.133029     0.0938387   0.591408   -0.384123     0.25224     -0.481458    -0.579037     0.376738     0.0687927  -0.239199      0.100297    0.245009     0.332191      0.203588     0.543021   -0.018723   -0.328294    -0.0983921   0.122163   -0.270852     0.381397
  0.275745     0.280242    0.106816     0.322173    -0.186353   -0.0607699   -0.417783    0.640285    0.0722486   -0.210205     0.0633565    0.591037    -0.427722    -0.205923   -0.52829       0.703705   -0.626934    -0.52504      -0.132672    -0.340121    0.221386    0.00144312  -0.0923022  -0.160578    0.654206     0.00190348
 -0.424956     0.388053   -0.150067     0.110686     0.463832    0.284859     0.211205   -0.119667   -0.00389123   0.396499    -0.172183     0.360521     0.61588     -0.13413     0.0979745     0.510018    0.232788    -0.0192455     0.514321     0.447485   -0.12171    -0.197862     0.708936    0.0514225   0.396226    -0.126296
  0.00676378  -0.25933    -0.200813     0.108899    -0.244047   -0.00862362   0.406573   -0.116714    0.196987     0.5032       0.571845     0.227506    -0.139305    -0.295514    0.115904     -0.658045   -0.448585    -0.516532     -0.261727    -0.279169   -0.136482   -0.0945034   -0.0707241  -0.300468    0.190926    -0.262954
  0.39109     -0.479753    0.342058    -0.141064    -0.308041    0.0293757   -0.0902856   0.0292578  -0.0231084   -0.313516     0.127809    -0.0339966   -0.508785     0.0520773  -0.120195     -0.459959   -0.155535     0.175534     -0.59936     -0.227039    0.113141    0.188       -0.90423    -0.222882   -0.154772     0.443774
 -0.536517     0.169349   -0.204114    -0.0660366   -0.113681   -0.404169     0.23442     0.0935442   0.317921     0.202828     0.232199     0.41755      0.177322     0.401068    0.476933      0.206276   -0.130129    -0.333252      0.237813    -0.401688    0.304476    0.483141    -0.282543    0.125091    0.370705    -0.215293
  0.263818    -0.126597   -0.536417    -0.174238    -0.364997   -0.516873    -0.354382   -0.040257    0.372519    -0.234539    -0.485574     0.261686    -0.393226     0.339005    0.0445031    -0.191256    0.421311    -0.0167884     0.579864     0.546256   -0.167429   -0.346706     0.452433    0.205206   -0.0376044    0.317243
 -0.326372     0.320898    0.652146     0.00995154   0.089674    0.0766667    0.346352   -0.040412   -0.0802244   -0.58893     -0.0206433    0.207524    -0.552588     0.287634   -0.140071      0.0528535  -0.788602     0.426471      0.221883    -0.631123    0.661269   -0.336285     0.159746    0.646791   -0.315567     0.387722[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405864
[ Info: iteration 2, average log likelihood -1.405854
[ Info: iteration 3, average log likelihood -1.405843
[ Info: iteration 4, average log likelihood -1.405833
[ Info: iteration 5, average log likelihood -1.405822
[ Info: iteration 6, average log likelihood -1.405812
[ Info: iteration 7, average log likelihood -1.405802
[ Info: iteration 8, average log likelihood -1.405793
[ Info: iteration 9, average log likelihood -1.405783
[ Info: iteration 10, average log likelihood -1.405774
â”Œ Info: EM with 100000 data points 10 iterations avll -1.405774
â”” 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
â”Œ Info: K-means with 900 data points using 3 iterations
â”” 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
â”Œ Info: EM with 900 data points 10 iterations avll -2.043154
â”” 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
