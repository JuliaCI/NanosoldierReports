Julia Version 1.5.0-DEV.139
Commit c2abaeedf8 (2020-01-22 06:54 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Missings ─────────── v0.4.3
 Installed FillArrays ───────── v0.8.4
 Installed FileIO ───────────── v1.2.1
 Installed Parameters ───────── v0.12.0
 Installed StatsBase ────────── v0.32.0
 Installed Distributions ────── v0.22.3
 Installed ScikitLearnBase ──── v0.5.0
 Installed DataStructures ───── v0.17.9
 Installed SortingAlgorithms ── v0.3.1
 Installed Arpack_jll ───────── v3.5.0+2
 Installed StatsFuns ────────── v0.9.3
 Installed CMakeWrapper ─────── v0.2.3
 Installed Arpack ───────────── v0.4.0
 Installed DataAPI ──────────── v1.1.0
 Installed Blosc ────────────── v0.5.1
 Installed SpecialFunctions ─── v0.9.0
 Installed Rmath ────────────── v0.6.0
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed NearestNeighbors ─── v0.4.4
 Installed Compat ───────────── v2.2.0
 Installed Distances ────────── v0.8.2
 Installed JLD ──────────────── v0.9.1
 Installed PDMats ───────────── v0.9.11
 Installed OrderedCollections ─ v1.1.0
 Installed LegacyStrings ────── v0.4.1
 Installed CMake ────────────── v1.1.2
 Installed Clustering ───────── v0.13.3
 Installed QuadGK ───────────── v2.3.1
 Installed StaticArrays ─────── v0.12.1
 Installed BinaryProvider ───── v0.5.8
 Installed BinDeps ──────────── v1.0.0
 Installed URIParser ────────── v0.4.0
 Installed HDF5 ─────────────── v0.12.5
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_05F3Kt/Project.toml`
 [no changes]
  Updating `/tmp/jl_05F3Kt/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_xJhfHJ/Project.toml`
 [no changes]
  Updating `/tmp/jl_xJhfHJ/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_GFaJv3/Project.toml`
 [no changes]
  Updating `/tmp/jl_GFaJv3/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_Z9vxYD/Project.toml`
 [no changes]
  Updating `/tmp/jl_Z9vxYD/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_oSLphF/Project.toml`
 [no changes]
  Updating `/tmp/jl_oSLphF/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_oSLphF/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.11
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -2.2101158650111016e6, [2641.9948754955108, 97358.0051245045], [-3767.952399673417 671.5030546107566 432.244042537246; 3351.9121077530694 -155.20960281686766 -453.91511235035165], [[5675.990081456506 -43.2897218668452 -734.6865571737794; -43.2897218668452 3380.0217685669677 699.3753067858837; -734.6865571737794 699.3753067858837 3033.5159712895975], [94361.9036921493 -198.88150647117132 937.0592170566784; -198.88150647117126 95904.26049368604 -226.60106721286598; 937.0592170566786 -226.60106721286607 97095.15567800375]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.336896e+03
      1       9.320825e+02      -4.048136e+02 |        8
      2       8.677653e+02      -6.431716e+01 |        4
      3       8.553081e+02      -1.245721e+01 |        0
      4       8.553081e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 855.3081110796425)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.084490
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.858022
[ Info: iteration 2, lowerbound -3.743827
[ Info: iteration 3, lowerbound -3.626256
[ Info: iteration 4, lowerbound -3.490026
[ Info: iteration 5, lowerbound -3.352181
[ Info: iteration 6, lowerbound -3.235379
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -3.152054
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -3.086516
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -3.037012
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.985463
[ Info: iteration 11, lowerbound -2.931013
[ Info: iteration 12, lowerbound -2.882229
[ Info: iteration 13, lowerbound -2.843154
[ Info: iteration 14, lowerbound -2.818965
[ Info: iteration 15, lowerbound -2.810862
[ Info: dropping number of Gaussions to 3
[ Info: iteration 16, lowerbound -2.804399
[ Info: iteration 17, lowerbound -2.796948
[ Info: iteration 18, lowerbound -2.791809
[ Info: iteration 19, lowerbound -2.784613
[ Info: iteration 20, lowerbound -2.774373
[ Info: iteration 21, lowerbound -2.759838
[ Info: iteration 22, lowerbound -2.739605
[ Info: iteration 23, lowerbound -2.712409
[ Info: iteration 24, lowerbound -2.677599
[ Info: iteration 25, lowerbound -2.635645
[ Info: iteration 26, lowerbound -2.588444
[ Info: iteration 27, lowerbound -2.539127
[ Info: iteration 28, lowerbound -2.491248
[ Info: iteration 29, lowerbound -2.447522
[ Info: iteration 30, lowerbound -2.408906
[ Info: iteration 31, lowerbound -2.374800
[ Info: iteration 32, lowerbound -2.344755
[ Info: iteration 33, lowerbound -2.321005
[ Info: iteration 34, lowerbound -2.308483
[ Info: dropping number of Gaussions to 2
[ Info: iteration 35, lowerbound -2.303122
[ Info: iteration 36, lowerbound -2.299263
[ Info: iteration 37, lowerbound -2.299258
[ Info: iteration 38, lowerbound -2.299255
[ Info: iteration 39, lowerbound -2.299254
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Thu Jan 23 22:25:32 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Thu Jan 23 22:25:40 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Thu Jan 23 22:25:43 2020: EM with 272 data points 0 iterations avll -2.084490
5.8 data points per parameter
, Thu Jan 23 22:25:45 2020: GMM converted to Variational GMM
, Thu Jan 23 22:25:55 2020: iteration 1, lowerbound -3.858022
, Thu Jan 23 22:25:55 2020: iteration 2, lowerbound -3.743827
, Thu Jan 23 22:25:55 2020: iteration 3, lowerbound -3.626256
, Thu Jan 23 22:25:55 2020: iteration 4, lowerbound -3.490026
, Thu Jan 23 22:25:56 2020: iteration 5, lowerbound -3.352181
, Thu Jan 23 22:25:56 2020: iteration 6, lowerbound -3.235379
, Thu Jan 23 22:25:56 2020: dropping number of Gaussions to 7
, Thu Jan 23 22:25:56 2020: iteration 7, lowerbound -3.152054
, Thu Jan 23 22:25:56 2020: dropping number of Gaussions to 6
, Thu Jan 23 22:25:56 2020: iteration 8, lowerbound -3.086516
, Thu Jan 23 22:25:56 2020: dropping number of Gaussions to 5
, Thu Jan 23 22:25:56 2020: iteration 9, lowerbound -3.037012
, Thu Jan 23 22:25:56 2020: dropping number of Gaussions to 4
, Thu Jan 23 22:25:56 2020: iteration 10, lowerbound -2.985463
, Thu Jan 23 22:25:56 2020: iteration 11, lowerbound -2.931013
, Thu Jan 23 22:25:56 2020: iteration 12, lowerbound -2.882229
, Thu Jan 23 22:25:56 2020: iteration 13, lowerbound -2.843154
, Thu Jan 23 22:25:56 2020: iteration 14, lowerbound -2.818965
, Thu Jan 23 22:25:56 2020: iteration 15, lowerbound -2.810862
, Thu Jan 23 22:25:56 2020: dropping number of Gaussions to 3
, Thu Jan 23 22:25:56 2020: iteration 16, lowerbound -2.804399
, Thu Jan 23 22:25:56 2020: iteration 17, lowerbound -2.796948
, Thu Jan 23 22:25:56 2020: iteration 18, lowerbound -2.791809
, Thu Jan 23 22:25:56 2020: iteration 19, lowerbound -2.784613
, Thu Jan 23 22:25:56 2020: iteration 20, lowerbound -2.774373
, Thu Jan 23 22:25:56 2020: iteration 21, lowerbound -2.759838
, Thu Jan 23 22:25:56 2020: iteration 22, lowerbound -2.739605
, Thu Jan 23 22:25:56 2020: iteration 23, lowerbound -2.712409
, Thu Jan 23 22:25:56 2020: iteration 24, lowerbound -2.677599
, Thu Jan 23 22:25:56 2020: iteration 25, lowerbound -2.635645
, Thu Jan 23 22:25:56 2020: iteration 26, lowerbound -2.588444
, Thu Jan 23 22:25:56 2020: iteration 27, lowerbound -2.539127
, Thu Jan 23 22:25:56 2020: iteration 28, lowerbound -2.491248
, Thu Jan 23 22:25:56 2020: iteration 29, lowerbound -2.447522
, Thu Jan 23 22:25:56 2020: iteration 30, lowerbound -2.408906
, Thu Jan 23 22:25:56 2020: iteration 31, lowerbound -2.374800
, Thu Jan 23 22:25:56 2020: iteration 32, lowerbound -2.344755
, Thu Jan 23 22:25:56 2020: iteration 33, lowerbound -2.321005
, Thu Jan 23 22:25:56 2020: iteration 34, lowerbound -2.308483
, Thu Jan 23 22:25:56 2020: dropping number of Gaussions to 2
, Thu Jan 23 22:25:56 2020: iteration 35, lowerbound -2.303122
, Thu Jan 23 22:25:56 2020: iteration 36, lowerbound -2.299263
, Thu Jan 23 22:25:56 2020: iteration 37, lowerbound -2.299258
, Thu Jan 23 22:25:56 2020: iteration 38, lowerbound -2.299255
, Thu Jan 23 22:25:56 2020: iteration 39, lowerbound -2.299254
, Thu Jan 23 22:25:56 2020: iteration 40, lowerbound -2.299253
, Thu Jan 23 22:25:56 2020: iteration 41, lowerbound -2.299253
, Thu Jan 23 22:25:56 2020: iteration 42, lowerbound -2.299253
, Thu Jan 23 22:25:56 2020: iteration 43, lowerbound -2.299253
, Thu Jan 23 22:25:56 2020: iteration 44, lowerbound -2.299253
, Thu Jan 23 22:25:56 2020: iteration 45, lowerbound -2.299253
, Thu Jan 23 22:25:56 2020: iteration 46, lowerbound -2.299253
, Thu Jan 23 22:25:56 2020: iteration 47, lowerbound -2.299253
, Thu Jan 23 22:25:56 2020: iteration 48, lowerbound -2.299253
, Thu Jan 23 22:25:56 2020: iteration 49, lowerbound -2.299253
, Thu Jan 23 22:25:56 2020: iteration 50, lowerbound -2.299253
, Thu Jan 23 22:25:56 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.0450923753382, 95.95490762466181]
β = [178.0450923753382, 95.95490762466181]
m = [4.250300732058775 79.28686692655027; 2.000229256521095 53.85198716592918]
ν = [180.0450923753382, 97.95490762466181]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155530782781 -0.007644049058236878; 0.0 0.008581705143946976], [0.3758763632798753 -0.008953123852100377; 0.0 0.012748664783753633]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000006
avll from stats: -0.9873672002639091
avll from llpg:  -0.9873672002638071
avll direct:     -0.987367200263807
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9635340861185823
avll from llpg:  -0.9635340861185823
avll direct:     -0.9635340861185823
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.0420796    -0.141524     -0.0354486    0.118413    -0.108107     0.0731113   -0.0964269   -0.163852      0.139032    -0.139315    -0.103337     0.122032    -0.106332     0.112865    0.0316632     0.00407672  -0.236395    -0.0576487    0.133755    -0.197002    -0.033629     0.0660799    0.0142583    -0.0965551    0.069608      0.141164
  0.0368311     0.0740371     0.0453447   -0.220536    -0.133886    -0.0612552    0.0944597   -0.122155     -0.107917    -0.048069    -0.0148975   -0.00351061  -0.0317691    0.0489392   0.0325207    -0.0438912   -0.0764142   -0.0139998   -0.0183539   -0.0508691   -0.110752     0.0698358    0.162717      0.0328445   -0.0597989     0.280108
  0.0539233    -0.0507028     0.0615913    0.0402438    0.0142391    0.158977     0.0625717   -0.043006     -0.140304     0.196836     0.109224    -0.0303348   -0.159191    -0.0343727  -0.084567     -0.137978    -0.121651     0.147308     0.0996551    0.128195    -0.185744     0.122578     0.0791843    -0.073248    -0.117811      0.0338269
  0.0694018     0.00575223   -0.0989733    0.102685    -0.0198333   -0.174832    -0.0386904    0.0226653     0.0649781    0.194423     0.0132458   -0.0983489   -0.0066152    0.177766    0.0198923     0.103779     0.012749    -0.107874    -0.0322185    0.00601278   0.0756321   -0.0227845    0.021368      0.0246595    0.172487      0.10797
 -0.115001      0.049006     -0.0478832    0.0564151    0.0228326   -0.131671     0.213542     0.100167      0.102195    -0.0143292   -0.0122932   -0.140742     0.038057    -0.0385101  -0.120793      0.18084     -0.0650102   -0.105608     0.0529894   -0.0692815   -0.0696883    0.115608     0.12154      -0.169496    -0.0535412    -0.0116909
  0.0449718     0.0524783     0.00588065   0.0164023    0.146623    -0.150966    -0.0639944   -0.119075      0.0778485   -0.0396133   -0.0590365   -0.0969197    0.0174048   -0.0191522   0.17297       0.0915719    0.0748252   -0.091015    -0.331198     0.180095    -0.0346304   -0.0558222   -0.0205044    -0.0157472   -0.00564305    0.000837082
 -0.0826365     0.21663      -0.0176496   -0.0807186   -0.125376     0.0612727    0.0966052   -0.0483662     0.0216228   -0.056031    -0.05701      0.223569    -0.229558    -0.058161    0.12957       0.0335003   -0.131341     0.0130888    0.0328462   -0.0905624    0.0149597    0.129169     0.0090458     0.00591375   0.0220698    -0.0732585
  0.0391908    -0.0284131    -0.116449     0.0244325   -0.00189623   0.0773127    0.0615651   -0.238361     -0.0199887    0.0350405    0.140491     0.0885793   -0.272758     0.0484743   0.0675924    -0.0680551   -0.0237949    0.0383441    0.106179    -0.025983     0.122061     0.0279884    0.0868128    -0.0949379    0.0188875    -0.246202
  0.0556765    -0.165172      0.0150908    0.0969079   -0.126134    -0.0669053    0.0195333    0.209635     -0.0786681   -0.0337317    0.152246    -0.0693567   -0.161501    -0.0542336  -0.209855      0.112377     0.118625     0.20127      0.0230416    0.0325529    0.0336311   -0.0676084   -0.160842      0.0216745   -0.064148      0.0336247
 -0.0857889     0.0597588     0.122102    -0.0103549   -0.0336567    0.00454568   0.0202842   -0.0827679     0.0308685   -0.198686    -0.00808149   0.136432    -0.00967319  -0.0165104   0.0472686    -0.0319441    0.0813609    0.232251    -0.145877     0.0213683    0.0738788    0.103307     0.0574237    -0.0714641    0.0632196     0.0152955
  0.112432     -0.0285585    -0.0226052    0.0865583    0.0255508   -0.0549782    0.0654646   -0.145798      0.0240007   -0.043711    -0.0661015    0.040209     0.0155696    0.100438   -0.0223082    -0.00563698  -0.0751949    0.0264723    0.122814    -0.00703923   0.0593709    0.0956363    0.129694      0.100689     0.0573213     0.133601
 -0.00922139    0.0885086     0.0255419   -0.154843    -0.0684846   -0.0755511    0.00361015   0.000368071  -0.0525932   -0.205339     0.0380991   -0.0239174   -0.111775     0.0641718  -0.0541775     0.0941627    0.0465767    0.0145599   -0.132549     0.133517     0.0658667   -0.0327816    0.101184     -0.137674     0.0969168    -0.0489197
 -0.0163389    -0.0944211    -0.117097    -0.00657084   0.0496332    0.032846    -0.00670314   0.0196175    -0.0213823   -0.0420689   -0.0192888    0.0734952    0.0201546    0.120543   -0.0541015    -0.0176491    0.108753     0.0279322    0.120407    -0.109904     0.172906    -0.0810679    0.0990908     0.163977     0.100245      0.0241346
  0.075672     -0.0497515     0.0145746    0.0626657    0.0864159   -0.00739144  -0.0361104    0.00992848    0.0478013    0.0385063   -0.0410718   -0.19647      0.270555     0.176198   -0.102554      0.192734    -0.154591     0.188045     0.0938902   -0.0334566   -0.109985    -0.147168     0.0743631    -0.147131    -0.08027       0.0395948
 -0.070634     -0.0886399     0.10128     -0.0007542    0.117521    -0.00116415  -0.162795     0.0753325    -0.109325    -0.00432148   0.214557     0.182381    -0.0895363   -0.0761858   0.0447633     0.0416984   -0.20328     -0.0397193   -0.0686457    0.0175774    0.00861727  -0.138146    -0.0158259    -0.0608897    0.0208448    -0.0205271
  0.0636788     0.159921      0.0163308    0.0432435   -0.0528963   -0.132751     0.0275118    0.0312608    -0.0628652   -0.160125    -0.0761151    0.0415111   -0.0701326   -0.0902358   0.0969583     0.0655924   -0.147722    -0.149736     0.00713029   0.0378696   -0.193532     0.153409    -0.0284638     0.0629054    0.0908785     0.0337194
  0.0700039     0.17102       0.00329191  -0.0723834   -0.143023     0.0301875   -0.0981768   -0.18784       0.00865274   0.12901      0.218333    -0.0586048    0.0213622   -0.113844   -0.114523      0.129095    -0.217877    -0.0427239    0.064683    -0.033298     0.146666    -0.0829342   -0.090667      5.69331e-5  -0.0246655     0.0189261
  0.00301993    0.0208211    -0.0207348   -0.0101706   -0.110701     0.0456156   -0.0449347   -0.178017     -0.0461294   -0.0091073   -0.176416    -0.0704378   -0.0621013   -0.042004    0.0316122    -0.0235821    0.0393658    0.0467591    0.105999     0.0891798    0.174471     0.186871    -0.112909     -0.123118    -0.00371056    0.10739
 -0.0801603     0.0631668     0.148308     0.0385355    0.0110739    0.066097    -0.0229831   -0.0659468     0.0170434   -0.00598748  -0.100327     0.114722     0.0179405    0.0854478   0.0457868    -0.039172     0.191981     0.002685     0.0499545   -0.0781802   -0.125105     0.0517066    0.111907      0.0643342   -0.227102      0.0902714
 -0.00507331   -0.106078     -0.0678661   -0.12204     -0.0561853   -0.049547     0.0510121   -0.00688167    0.174427    -0.0169903   -0.0179042   -0.0976915    0.0741766    0.210446    0.124035     -0.122354     0.0776076   -0.0769041   -0.0623791   -0.119615     0.153771    -0.0872052    0.0675874     0.0864402    0.108784     -0.113553
  0.0581034    -0.0546708    -0.120885    -0.139534    -0.0688775    0.0296073   -0.142433    -0.151753      0.0186612   -0.0369042   -0.15776      0.127353     0.109779     0.0399738  -0.247455      0.16578      0.0508324    0.0370299   -0.0440061   -0.0239728   -0.0587417   -0.0141751    0.045337     -0.154457     0.102246      0.003635
  0.133898      0.118753      0.145541     0.0961805    0.2206       0.0435627   -0.134683    -0.0463916    -0.137872     0.0878802   -0.0857605    0.0882088   -0.00741128  -0.104025    0.000870624   0.0866417    0.191247     0.158598     0.0242199    0.0150119   -0.049288     0.00736463   0.0333524     0.0166406   -0.0191755     0.153782
  0.161332      0.205502      0.198895     0.0514653   -0.138034    -0.114922    -0.123809     0.0269876    -0.0410092   -0.161873     0.124565    -0.0828521   -0.174386    -0.108499    0.0482459     0.0128512   -0.031693     0.0544336   -0.146779     0.0730376    0.169143    -0.0411269    0.000866967   0.00628831  -0.0942447    -0.238359
 -0.176916     -0.215012     -0.25852      0.051532     0.132765    -0.148679    -0.106048     0.178285      0.0773463    0.0869645   -0.147654     0.0137486    0.237314    -0.0562842   0.0323115    -0.135347    -0.0115739   -0.0185456    0.139603     0.0263311   -0.0282302   -0.0312022   -0.0239773    -0.0459042    0.170573     -0.141041
 -0.254957     -0.0171632     0.0315809   -0.0906324   -0.108252    -0.126783     0.0481543   -0.140634     -0.119452     0.0248959   -0.0771854   -0.0200705    0.0430289    0.066504   -0.0739277    -0.0179576    0.00953474  -0.0992996    0.0591945   -0.0372711   -0.0688646   -0.21183      0.121698     -0.0636394    0.000535544  -0.0317589
 -0.000244385  -0.103144     -0.143523    -0.140742    -0.0793664    0.0055368    0.0426068    0.0572388    -0.0332316   -0.00409268  -0.134144     0.10311     -0.13258      0.106263   -0.116791     -0.0065125   -0.0934405   -0.0435916   -0.115415    -0.0232357    0.228808     0.150023    -0.188148     -0.120992     0.0427755     0.0265247
 -0.0239592    -0.118194      0.0689375   -0.0332839    0.1409      -0.00242303  -0.0163632    0.0849676    -0.00658737  -0.109543     0.0353507   -0.0127955    0.0126592    0.0423623  -0.13634       0.00801023   0.0338558   -0.0273934   -0.195415    -0.129437     0.113272     0.213518     0.137731     -0.0760788    0.0512281    -0.0260533
 -0.0160451     0.0266596     0.0180365    0.153971     0.0150151   -0.0677744   -0.105605    -0.0776505     0.039846     0.0601362    0.0773805   -0.0228251    0.0337795    0.266442   -0.168927     -0.0653622    0.0262002    0.103862    -0.00759958   0.0398483    0.0722375    0.19669      0.0201799    -0.167063    -0.0148239     0.0276288
 -0.0159545    -0.000293369   0.186277    -0.144855     0.0823726    0.00506078   0.067029     0.031852      0.164346     0.0260218   -0.00728991   0.112268     0.0302787    0.0375791  -0.146367     -0.0189593    0.10223     -0.0291803    0.0851594   -0.105727     0.207251     0.036313    -0.0300641     0.00728485  -0.000333301   0.0995265
  0.247658     -0.107169      0.0436972    0.0608842   -0.0566627   -0.179065    -0.104325    -0.0384506    -0.0308825    0.0193761    0.109657    -0.00296813  -0.0170026   -0.147924   -0.0595802    -0.0268235   -0.00372487   0.00228385  -0.233079    -0.0377709    0.0609051    0.111099    -0.0846924    -0.132976    -0.106648     -0.065926
  0.227056      0.0320382    -0.0200711   -0.156343    -0.00314362   0.0827091    0.00623683   0.129673     -0.141723    -0.0019971   -0.0646582    0.130256    -0.0416109   -0.171195    0.140905      0.103269     0.0331742    0.106706     0.0382432   -0.0680048   -0.00726528  -0.0611784    0.0131023     0.0727785    0.15679      -0.042943
  0.0269557     0.122997     -0.28967      0.130601     0.0801545   -0.141872     0.00266348   0.00786016   -0.103183    -0.0253299    0.188993    -0.0664128    0.137219     0.0721749   0.171361      0.0127605   -0.0763429   -0.208685     0.202428    -0.0107107   -0.0875239    0.00177562  -0.123577     -0.0673795   -0.067107     -0.0578755kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4290444949377987
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.429128
[ Info: iteration 2, average log likelihood -1.429048
[ Info: iteration 3, average log likelihood -1.428448
[ Info: iteration 4, average log likelihood -1.421052
[ Info: iteration 5, average log likelihood -1.402239
[ Info: iteration 6, average log likelihood -1.395830
[ Info: iteration 7, average log likelihood -1.394073
[ Info: iteration 8, average log likelihood -1.392544
[ Info: iteration 9, average log likelihood -1.391477
[ Info: iteration 10, average log likelihood -1.390866
[ Info: iteration 11, average log likelihood -1.390502
[ Info: iteration 12, average log likelihood -1.390266
[ Info: iteration 13, average log likelihood -1.390105
[ Info: iteration 14, average log likelihood -1.389991
[ Info: iteration 15, average log likelihood -1.389910
[ Info: iteration 16, average log likelihood -1.389848
[ Info: iteration 17, average log likelihood -1.389799
[ Info: iteration 18, average log likelihood -1.389759
[ Info: iteration 19, average log likelihood -1.389723
[ Info: iteration 20, average log likelihood -1.389690
[ Info: iteration 21, average log likelihood -1.389655
[ Info: iteration 22, average log likelihood -1.389616
[ Info: iteration 23, average log likelihood -1.389560
[ Info: iteration 24, average log likelihood -1.389448
[ Info: iteration 25, average log likelihood -1.389178
[ Info: iteration 26, average log likelihood -1.388724
[ Info: iteration 27, average log likelihood -1.388260
[ Info: iteration 28, average log likelihood -1.387909
[ Info: iteration 29, average log likelihood -1.387641
[ Info: iteration 30, average log likelihood -1.387446
[ Info: iteration 31, average log likelihood -1.387290
[ Info: iteration 32, average log likelihood -1.387166
[ Info: iteration 33, average log likelihood -1.387084
[ Info: iteration 34, average log likelihood -1.387040
[ Info: iteration 35, average log likelihood -1.387017
[ Info: iteration 36, average log likelihood -1.387004
[ Info: iteration 37, average log likelihood -1.386996
[ Info: iteration 38, average log likelihood -1.386991
[ Info: iteration 39, average log likelihood -1.386987
[ Info: iteration 40, average log likelihood -1.386984
[ Info: iteration 41, average log likelihood -1.386982
[ Info: iteration 42, average log likelihood -1.386980
[ Info: iteration 43, average log likelihood -1.386979
[ Info: iteration 44, average log likelihood -1.386978
[ Info: iteration 45, average log likelihood -1.386977
[ Info: iteration 46, average log likelihood -1.386976
[ Info: iteration 47, average log likelihood -1.386975
[ Info: iteration 48, average log likelihood -1.386975
[ Info: iteration 49, average log likelihood -1.386975
[ Info: iteration 50, average log likelihood -1.386974
┌ Info: EM with 100000 data points 50 iterations avll -1.386974
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.429127699937156
│     -1.4290483564823417
│      ⋮
└     -1.386974286667697
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.387099
[ Info: iteration 2, average log likelihood -1.386985
[ Info: iteration 3, average log likelihood -1.386662
[ Info: iteration 4, average log likelihood -1.383839
[ Info: iteration 5, average log likelihood -1.372270
[ Info: iteration 6, average log likelihood -1.359835
[ Info: iteration 7, average log likelihood -1.355057
[ Info: iteration 8, average log likelihood -1.352458
[ Info: iteration 9, average log likelihood -1.350577
[ Info: iteration 10, average log likelihood -1.349121
[ Info: iteration 11, average log likelihood -1.347924
[ Info: iteration 12, average log likelihood -1.346868
[ Info: iteration 13, average log likelihood -1.345912
[ Info: iteration 14, average log likelihood -1.345047
[ Info: iteration 15, average log likelihood -1.344278
[ Info: iteration 16, average log likelihood -1.343607
[ Info: iteration 17, average log likelihood -1.343042
[ Info: iteration 18, average log likelihood -1.342570
[ Info: iteration 19, average log likelihood -1.342167
[ Info: iteration 20, average log likelihood -1.341820
[ Info: iteration 21, average log likelihood -1.341514
[ Info: iteration 22, average log likelihood -1.341235
[ Info: iteration 23, average log likelihood -1.340979
[ Info: iteration 24, average log likelihood -1.340737
[ Info: iteration 25, average log likelihood -1.340505
[ Info: iteration 26, average log likelihood -1.340276
[ Info: iteration 27, average log likelihood -1.340035
[ Info: iteration 28, average log likelihood -1.339773
[ Info: iteration 29, average log likelihood -1.339496
[ Info: iteration 30, average log likelihood -1.339206
[ Info: iteration 31, average log likelihood -1.338904
[ Info: iteration 32, average log likelihood -1.338601
[ Info: iteration 33, average log likelihood -1.338317
[ Info: iteration 34, average log likelihood -1.338061
[ Info: iteration 35, average log likelihood -1.337831
[ Info: iteration 36, average log likelihood -1.337624
[ Info: iteration 37, average log likelihood -1.337439
[ Info: iteration 38, average log likelihood -1.337279
[ Info: iteration 39, average log likelihood -1.337146
[ Info: iteration 40, average log likelihood -1.337037
[ Info: iteration 41, average log likelihood -1.336951
[ Info: iteration 42, average log likelihood -1.336881
[ Info: iteration 43, average log likelihood -1.336825
[ Info: iteration 44, average log likelihood -1.336779
[ Info: iteration 45, average log likelihood -1.336740
[ Info: iteration 46, average log likelihood -1.336708
[ Info: iteration 47, average log likelihood -1.336680
[ Info: iteration 48, average log likelihood -1.336656
[ Info: iteration 49, average log likelihood -1.336635
[ Info: iteration 50, average log likelihood -1.336617
┌ Info: EM with 100000 data points 50 iterations avll -1.336617
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3870987599334001
│     -1.3869849034679556
│      ⋮
└     -1.3366170072437906
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.336782
[ Info: iteration 2, average log likelihood -1.336578
[ Info: iteration 3, average log likelihood -1.335776
[ Info: iteration 4, average log likelihood -1.328404
[ Info: iteration 5, average log likelihood -1.305612
[ Info: iteration 6, average log likelihood -1.289240
[ Info: iteration 7, average log likelihood -1.283286
[ Info: iteration 8, average log likelihood -1.280390
[ Info: iteration 9, average log likelihood -1.278862
[ Info: iteration 10, average log likelihood -1.278116
[ Info: iteration 11, average log likelihood -1.277586
[ Info: iteration 12, average log likelihood -1.277093
[ Info: iteration 13, average log likelihood -1.276654
[ Info: iteration 14, average log likelihood -1.276321
[ Info: iteration 15, average log likelihood -1.276097
[ Info: iteration 16, average log likelihood -1.275940
[ Info: iteration 17, average log likelihood -1.275815
[ Info: iteration 18, average log likelihood -1.275698
[ Info: iteration 19, average log likelihood -1.275577
[ Info: iteration 20, average log likelihood -1.275443
[ Info: iteration 21, average log likelihood -1.275293
[ Info: iteration 22, average log likelihood -1.275116
[ Info: iteration 23, average log likelihood -1.274926
[ Info: iteration 24, average log likelihood -1.274761
[ Info: iteration 25, average log likelihood -1.274634
[ Info: iteration 26, average log likelihood -1.274545
[ Info: iteration 27, average log likelihood -1.274486
[ Info: iteration 28, average log likelihood -1.274446
[ Info: iteration 29, average log likelihood -1.274419
[ Info: iteration 30, average log likelihood -1.274399
[ Info: iteration 31, average log likelihood -1.274383
[ Info: iteration 32, average log likelihood -1.274371
[ Info: iteration 33, average log likelihood -1.274362
[ Info: iteration 34, average log likelihood -1.274355
[ Info: iteration 35, average log likelihood -1.274349
[ Info: iteration 36, average log likelihood -1.274344
[ Info: iteration 37, average log likelihood -1.274340
[ Info: iteration 38, average log likelihood -1.274336
[ Info: iteration 39, average log likelihood -1.274333
[ Info: iteration 40, average log likelihood -1.274330
[ Info: iteration 41, average log likelihood -1.274327
[ Info: iteration 42, average log likelihood -1.274324
[ Info: iteration 43, average log likelihood -1.274321
[ Info: iteration 44, average log likelihood -1.274319
[ Info: iteration 45, average log likelihood -1.274317
[ Info: iteration 46, average log likelihood -1.274314
[ Info: iteration 47, average log likelihood -1.274312
[ Info: iteration 48, average log likelihood -1.274310
[ Info: iteration 49, average log likelihood -1.274308
[ Info: iteration 50, average log likelihood -1.274306
┌ Info: EM with 100000 data points 50 iterations avll -1.274306
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.33678190603896
│     -1.3365776594466228
│      ⋮
└     -1.2743064409907097
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.274517
[ Info: iteration 2, average log likelihood -1.274212
[ Info: iteration 3, average log likelihood -1.271532
[ Info: iteration 4, average log likelihood -1.246669
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.205539
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.198690
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.208475
[ Info: iteration 8, average log likelihood -1.200721
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.181170
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.200637
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.197409
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.196494
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.196292
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.190798
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.179484
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.197004
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.193725
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.187867
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.192906
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.188714
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.177827
[ Info: iteration 22, average log likelihood -1.195875
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.176553
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.191572
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.193573
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.189128
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.178573
[ Info: iteration 28, average log likelihood -1.197085
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.178077
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      8
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.175977
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.199316
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.191249
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.180236
[ Info: iteration 34, average log likelihood -1.198283
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.178763
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.176784
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.183557
[ Info: iteration 38, average log likelihood -1.203677
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.179850
[ Info: iteration 40, average log likelihood -1.199447
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.179438
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      8
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.177249
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.190526
[ Info: iteration 44, average log likelihood -1.200008
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.178732
[ Info: iteration 46, average log likelihood -1.198753
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.178942
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      8
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.176880
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.190664
[ Info: iteration 50, average log likelihood -1.199971
┌ Info: EM with 100000 data points 50 iterations avll -1.199971
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2745168231909447
│     -1.2742121688485222
│      ⋮
└     -1.1999705686330613
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.178994
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.174814
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.168713
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│      ⋮
│     16
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.142229
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│      ⋮
│     16
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.114197
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     11
│     13
│     14
│     15
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.108243
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│      ⋮
│     22
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.094119
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.120145
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│      ⋮
│     18
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.088753
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     15
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.088351
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│      ⋮
│     18
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.087862
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.090562
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│      ⋮
│     20
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.075763
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.093868
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     16
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.070123
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│      ⋮
│     20
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.084141
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.093567
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.087713
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│      ⋮
│     20
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.066917
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     15
│     16
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.083876
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│      ⋮
│     18
│     19
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.085154
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.097483
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│      ⋮
│     16
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.086552
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│     14
│     15
│     16
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.087176
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     22
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.064551
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.104383
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│      ⋮
│     19
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.079688
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│     14
│     15
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.090293
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│      ⋮
│     18
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.084719
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     11
│     13
│     14
│     15
│     16
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.098005
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│      ⋮
│     18
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.084677
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│     14
│     15
│     16
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.093395
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│      ⋮
│     18
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.069979
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     11
│     13
│      ⋮
│     16
│     19
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.082980
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│      ⋮
│     18
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.093772
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.096901
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│      ⋮
│     18
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.072881
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     16
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.074818
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.092437
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     15
│     16
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.090986
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│      ⋮
│     18
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.079204
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│     14
│     15
│     16
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.095115
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     11
│     13
│      ⋮
│     18
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.086851
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│     14
│     15
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.095067
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│      ⋮
│     18
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.081369
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│     14
│     15
│     16
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.081530
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     11
│     13
│      ⋮
│     19
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.070950
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│     14
│     15
│     16
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.104821
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│      ⋮
│     16
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.086576
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     12
│     13
│     14
│     15
│     16
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.084606
┌ Info: EM with 100000 data points 50 iterations avll -1.084606
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1789941732503038
│     -1.17481436950413
│      ⋮
└     -1.0846062647741332
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4290444949377987
│     -1.429127699937156
│     -1.4290483564823417
│     -1.428447867790485
│      ⋮
│     -1.104821483431226
│     -1.0865760817358379
└     -1.0846062647741332
32×26 Array{Float64,2}:
 -0.375552    0.0511491    0.296362    -0.0471501    -0.111442    -0.141475     0.182241     -0.0061537    -0.0362157   0.0442339   -0.0787833   -0.020951     0.0430407    0.0669194   -0.0637334   -0.0163321    0.156859   -0.104252     0.0588225   -0.081772     -0.0710505  -0.210852     0.107387   -0.0524899    0.00899221  -0.395988
 -0.166456   -0.0993149   -0.206049    -0.091842     -0.109115    -0.120861    -0.146527     -0.237463     -0.193347    0.00381966  -0.0770187   -0.021532     0.0428184    0.0653335   -0.0616552   -0.0172609   -0.0844931  -0.0931033    0.0584629   -0.000307673  -0.067557   -0.205675     0.109419   -0.0641898   -0.00190715   0.256378
 -0.145111    0.0526783    0.128942     0.0289887    -0.112226     0.0800552   -0.0456952     0.00580558    0.0228178   0.0111382   -0.031203    -0.00789103   0.0329541    0.0989464    0.0919698   -0.0324746    0.0877881  -0.0249735   -0.16894     -0.0810469    -0.128402   -0.0568486    0.211591    0.0691669   -0.26404      0.0804656
 -0.0223477   0.0719768    0.156215     0.0697121     0.16105      0.0511181    0.0189448    -0.125169      0.0117174  -0.0588035   -0.135285     0.241723    -0.00263709   0.0821444    0.0464976   -0.0463406    0.267014   -0.0195407    0.298351    -0.0779213    -0.122387    0.117227    -0.0627135   0.0793493   -0.201198     0.114465
 -0.111845   -0.196945    -0.0493408    0.120279     -0.10006      0.0259995   -0.0694157    -0.132401      0.139644   -0.752987    -0.0922947    0.0892978   -0.101156    -0.0554855    0.00591081   0.12084     -0.224852   -0.0591472    0.0788376   -0.299956     -0.0301529   0.0656459   -0.0354864  -0.0802349    0.154507     0.121932
  0.183526   -0.0686223   -0.0254623    0.124245     -0.121119     0.117603    -0.129504     -0.181799      0.123576    0.36691     -0.122634     0.1657      -0.112991     0.351296     0.0499845   -0.112329    -0.223027   -0.0554047    0.266388    -0.0984923    -0.0100087   0.0637576    0.0693011  -0.100729     0.0143175    0.144098
 -0.0542784   0.121445    -0.0500024    0.2684       -0.00859827  -0.0531445   -0.0906222    -0.0813393     0.0530424  -0.00648843   0.0796142   -0.0782047    0.0320878    0.209766    -0.15305     -0.0933291    0.124928    0.106146     0.0187286    0.03722       0.0719056   0.268729    -0.0186635  -0.166083    -0.605768    -0.0395289
  0.037349   -0.111166     0.0565772    0.055733      0.04171     -0.084419    -0.095278     -0.0769725     0.0192616   0.160791     0.0677414   -0.0175534    0.0344402    0.309605    -0.173944    -0.025299    -0.145565    0.11632     -0.0104272    0.0424308     0.0688997   0.0592799    0.0474927  -0.164687     0.761948     0.0521457
  0.0453912   0.112939     0.00279921  -0.194925     -0.248954     0.0248818   -0.14519      -0.224455      0.0158647   0.175783     0.398618    -0.0996894    0.0181795   -0.108836    -0.0566688    0.139257    -0.50658    -0.0332951   -0.111703    -0.00090799    0.231069   -0.0739017   -0.0639973   0.0277149   -0.0430059   -0.133113
  0.0957072   0.125915     0.00521324  -0.00108039   -0.0600763   -0.079059    -0.0635936    -0.137448      0.0201992   0.0497643   -0.0373088   -0.00736454   0.0283459   -0.11077     -0.178463     0.145552     0.212235   -0.0538216    0.171424    -0.033717      0.0860472  -0.0976413   -0.180772   -0.0317889   -0.0010308    0.106015
 -0.0148426  -0.106897    -0.0423107   -0.115402     -0.0558582   -0.0342248    0.0487068     0.000129624   0.171535    0.0111804    0.0113642   -0.0536701    0.104298     0.179081     0.141548    -0.133545     0.0777224  -0.0771481   -0.0625005   -0.127798      0.146282   -0.0863429    0.0617573   0.0926437    0.102805    -0.0851696
  0.030547    0.0972731    0.0414916   -0.237931     -0.150926    -0.0336036    0.0940931    -0.119914     -0.128192   -0.0628676   -0.00708269  -0.0418487   -0.0150232    0.0525013    0.0293972   -0.0493811   -0.108347   -0.0135741   -0.0166678   -0.0635565    -0.112474    0.0644178    0.161231    0.0362085   -0.0638716    0.269563
 -0.0763239   0.212854    -0.0233866   -0.0761977    -0.852512     0.0504308    0.15736      -0.00339211    0.056609   -0.0624999    0.0188277    0.228909    -0.229985    -0.0580605    0.124205     0.0172452   -0.119491    0.0156106    0.0160678   -0.116295      0.0254304   0.130846    -0.0273796   0.0154071   -0.00967679  -0.0298435
 -0.0923407   0.21471     -0.0123688   -0.0802258     0.756659     0.0539327    0.0332897    -0.11392      -0.0353761  -0.0538529   -0.101441     0.22677     -0.23047     -0.0577971    0.12593      0.0603765   -0.148991    0.0117766    0.0538163   -0.0330539     0.0325281   0.121115     0.0398517  -0.0194655    0.0471727   -0.133888
  0.0729873  -0.0785619   -0.142493    -0.0549631    -0.0330294   -0.134417    -0.0544863     0.0705894     0.0978425   0.168741    -0.402106    -0.0619598    0.0459819    0.167646    -0.118356     0.102225     0.0559557  -0.110831    -0.0372339   -0.00535453    0.0735814  -0.0297273    0.0888951   0.0248528    0.153791     0.106717
  0.0694523   0.0364267   -0.0698753    0.15954       0.0182886   -0.258161    -0.017162     -0.028968      0.0830775   0.226822     0.502871    -0.131004    -0.00336943   0.155288     0.145374     0.141877    -0.0104975  -0.104299    -0.0245618    0.0252897     0.0740063  -0.019219    -0.0757296   0.0248004    0.250024     0.106177
  0.121041    0.174709     0.0123458    0.0481199    -0.0536088   -0.130031     0.0691517     0.0356122    -0.0637738  -0.152387    -0.0739618    0.0395657   -0.059361    -0.0612762    0.0966567    0.0676086   -0.195872   -0.163524     0.00946663   0.0288335    -0.220172    0.135778    -0.0622274   0.0403396    0.0866272    0.0366968
 -0.0242692  -0.00563718   0.18869     -0.17742       0.080658    -0.00473198   0.0630376     0.0334943     0.156242    0.035411    -0.00654492   0.104146     0.0608082    0.0271893   -0.159839    -0.0306687    0.110376   -0.043597     0.0750804   -0.0809869     0.224937    0.0529535   -0.0109935  -0.0019001    0.00646897   0.120076
 -0.0505345  -0.0695882    0.0884431    0.000187083   0.121679     0.0106156   -0.128638      0.0614022    -0.119119   -0.0220269    0.162545     0.139352    -0.0641264   -0.0463702    0.0101749    0.0380526   -0.134568   -0.0569127   -0.105322    -0.0249975     0.0284202  -0.0501312    0.0321781  -0.0626622    0.0183047   -0.00178189
 -0.0706525   0.0520108   -0.0809754    0.0871927     0.0229104   -0.146697     0.211979      0.0986928     0.102316   -0.0150134   -0.00699412  -0.150461     0.0849985   -0.0502593   -0.15816      0.185455    -0.0613643  -0.107596     0.0682357   -0.103386     -0.0974294   0.114138     0.103469   -0.177704    -0.0485255    0.00741006
  0.137908   -0.0881173   -0.0504353   -0.00691853   -0.0630899   -0.0578061   -0.0274559     0.0274021    -0.0338523   0.014235    -0.0211684    0.0759906   -0.0776463   -0.00101836  -0.0823818    0.0130863   -0.0516596  -0.0619247   -0.193129    -0.0538053     0.126348    0.121184    -0.13101    -0.131595    -0.0141111   -0.0125213
  0.0430825  -0.0645596    0.0598724    0.00950986    0.0131734    0.151443     0.0788658    -0.0452852    -0.131103    0.184632     0.0917217   -0.0279537   -0.158391    -0.031863    -0.0932489   -0.128891    -0.109165    0.152066     0.089395     0.10739      -0.182585    0.11072      0.078636   -0.0280529   -0.112996     0.0345154
  0.0284503  -0.0492335   -0.111539    -0.149984     -0.0586658    0.0219374   -0.14857      -0.148963     -0.0176083  -0.0390059   -0.159665     0.128044     0.0914261    0.0408555   -0.258431     0.174974     0.0525828   0.03553     -0.0731402   -0.0182707    -0.0576351  -0.0382414    0.065609   -0.17139      0.155934     0.00685058
  0.228312    0.0308817   -0.0209932   -0.172992     -0.00214051   0.0409764   -0.000728505   0.127013     -0.149048   -0.00216432  -0.0249282    0.128722    -0.0514351   -0.157102     0.131359     0.0991869    0.0256782   0.0580411    0.0835733   -0.0408212     0.0465404  -0.0229056    0.0279349   0.142522     0.164473    -0.0253874
  0.0663066  -0.0573089    0.00994829   0.0603095     0.0783464   -0.00502035  -0.0409309     0.0172591     0.0134914   0.0505509   -0.0786219   -0.190777     0.259764     0.173773    -0.128638     0.150202    -0.153644    0.183963     0.0943696   -0.0517716    -0.109798   -0.142176     0.0691197  -0.117146    -0.0876649    0.0432383
  0.0451216   0.0492205    0.0244734    0.0144221     0.151262    -0.148043    -0.0580068    -0.085043      0.0491074  -0.0602234   -0.0197161   -0.0845482    0.0292317   -0.0169696    0.150281     0.0923099    0.0607703  -0.0830194   -0.298823     0.178607     -0.0435933  -0.0290295   -0.0199662  -0.0111387   -0.0128546   -0.0022879
  0.0409185  -0.0177233    0.0737318    0.0396632     0.0651243   -0.00558171   0.030179     -0.0866017    -0.0143047  -0.081275    -0.0302362    0.0861635    0.0162858    0.0120209   -0.00337314  -0.00115702   0.0485362   0.141523    -0.0118457   -0.00342438    0.0428144   0.0806264    0.0907022   0.00639841   0.0499478    0.0794058
 -0.0784435  -0.123977    -0.141366     0.015171      0.0823191   -0.0747149   -0.0648199     0.0771129     0.0088027   0.0194386   -0.0660823    0.0436401    0.111277     0.0219662   -0.0253909   -0.0496162    0.0685362   0.00646502   0.107194    -0.0289518     0.0696763  -0.0306703    0.0408984   0.0570563    0.117132    -0.0543312
 -0.0140891   0.0216494   -0.0506741   -0.033537     -0.100545     0.0419561   -0.0561505    -0.177849     -0.0147189  -0.0158594   -0.193985    -0.108348    -0.0787936   -0.036005     0.0429877   -0.0456726    0.0409223   0.0469112    0.102561     0.0871435     0.170303    0.184644    -0.111898   -0.105482    -0.00153982   0.105677
  0.0565335  -0.0326184    0.00165547  -0.041459     -0.0865005   -0.075498     0.0223524     0.103928     -0.0654036  -0.132013     0.123882    -0.0449529   -0.123459     0.0229182   -0.133134     0.0882408    0.0817299   0.102494    -0.0498368    0.0754974     0.0480079  -0.0704868   -0.0211909  -0.0587864    0.0354228   -0.0168109
  0.0750345   0.0736896    0.0611888    0.0253785    -0.0348443   -0.0152736   -0.0465187    -0.0735007    -0.0224076  -0.059411     0.126319     0.0135833   -0.194565    -0.0191206    0.0377141   -0.0214788   -0.0239612   0.0448923   -0.0414543    0.00961671    0.143111    0.0075402    0.0414573  -0.0553766   -0.0595497   -0.204828
  0.035191    0.169834    -0.279578     0.133999      0.0624189   -0.105573     0.0324958     0.00782094   -0.0913327  -0.0479387    0.194618     0.0102352    0.23195      0.0612771    0.164717     0.0218038   -0.0320798  -0.19941      0.207172    -0.0174548    -0.11605     0.00291601  -0.109099   -0.0905571   -0.066984    -0.0570594[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     22
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.063801
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     22
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.060382
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     22
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.060350
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     22
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.062316
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     22
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.061756
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     22
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.058894
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     22
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.061468
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     22
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.061783
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     22
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.058895
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     22
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.061454
┌ Info: EM with 100000 data points 10 iterations avll -1.061454
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.866910e+05
      1       7.048965e+05      -1.817945e+05 |       32
      2       6.770454e+05      -2.785109e+04 |       32
      3       6.631034e+05      -1.394195e+04 |       32
      4       6.546372e+05      -8.466208e+03 |       32
      5       6.476831e+05      -6.954140e+03 |       32
      6       6.416346e+05      -6.048415e+03 |       32
      7       6.367751e+05      -4.859543e+03 |       32
      8       6.338583e+05      -2.916816e+03 |       32
      9       6.321778e+05      -1.680540e+03 |       32
     10       6.311190e+05      -1.058704e+03 |       32
     11       6.306492e+05      -4.698277e+02 |       32
     12       6.304267e+05      -2.225008e+02 |       32
     13       6.303078e+05      -1.189481e+02 |       32
     14       6.302426e+05      -6.517338e+01 |       32
     15       6.301992e+05      -4.340398e+01 |       32
     16       6.301683e+05      -3.093923e+01 |       31
     17       6.301402e+05      -2.800970e+01 |       32
     18       6.301138e+05      -2.640998e+01 |       32
     19       6.300873e+05      -2.651819e+01 |       30
     20       6.300587e+05      -2.859535e+01 |       32
     21       6.300227e+05      -3.605341e+01 |       32
     22       6.299766e+05      -4.609915e+01 |       32
     23       6.299280e+05      -4.857821e+01 |       31
     24       6.298720e+05      -5.596200e+01 |       30
     25       6.298018e+05      -7.018154e+01 |       32
     26       6.297189e+05      -8.289598e+01 |       32
     27       6.296389e+05      -8.007175e+01 |       32
     28       6.295693e+05      -6.957811e+01 |       32
     29       6.295041e+05      -6.516548e+01 |       31
     30       6.294435e+05      -6.062649e+01 |       31
     31       6.293882e+05      -5.531438e+01 |       32
     32       6.293414e+05      -4.683850e+01 |       32
     33       6.293079e+05      -3.347546e+01 |       31
     34       6.292716e+05      -3.629097e+01 |       31
     35       6.292277e+05      -4.385797e+01 |       31
     36       6.291574e+05      -7.033936e+01 |       31
     37       6.290571e+05      -1.002459e+02 |       32
     38       6.289340e+05      -1.231012e+02 |       32
     39       6.288239e+05      -1.101218e+02 |       32
     40       6.287141e+05      -1.097861e+02 |       32
     41       6.286148e+05      -9.935428e+01 |       32
     42       6.285329e+05      -8.189876e+01 |       31
     43       6.284636e+05      -6.927765e+01 |       31
     44       6.283964e+05      -6.716951e+01 |       32
     45       6.283310e+05      -6.547241e+01 |       32
     46       6.282806e+05      -5.038978e+01 |       31
     47       6.282275e+05      -5.304389e+01 |       32
     48       6.281797e+05      -4.786585e+01 |       32
     49       6.281385e+05      -4.117473e+01 |       31
     50       6.280920e+05      -4.650845e+01 |       30
K-means terminated without convergence after 50 iterations (objv = 628091.9810391511)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.340211
[ Info: iteration 2, average log likelihood -1.306464
[ Info: iteration 3, average log likelihood -1.268611
[ Info: iteration 4, average log likelihood -1.227848
[ Info: iteration 5, average log likelihood -1.185903
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     27
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.122826
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│     10
│     13
│     14
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.080681
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.114819
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.105854
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     18
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.075891
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.077788
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     10
│     13
│     14
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.044380
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.095947
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.097622
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      3
│     17
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.060562
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      8
│     10
│     12
│     13
│      ⋮
│     16
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.052815
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     27
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.142073
[ Info: iteration 18, average log likelihood -1.131976
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.063436
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│     12
│     14
│     15
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.021202
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     10
│     20
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.104469
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.125348
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.078766
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     12
│     15
│     16
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.032991
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     10
│     13
│     14
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.071729
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.097571
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.084986
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     12
│     13
│     15
│     16
│     18
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.047364
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.100622
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      3
│      8
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.059485
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.089857
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     13
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.072485
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     15
│     16
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.074591
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     14
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.091520
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.062282
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     10
│     12
│     13
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.067950
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     16
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.093122
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.079191
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.076276
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      3
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.051661
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     10
│     13
│     14
│     15
│      ⋮
│     26
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.024986
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.132160
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     12
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.106050
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.098612
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     13
│     14
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.038159
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     10
│     12
│     17
│     20
│     26
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.053882
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.113912
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.095738
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     13
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.063107
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     10
│     14
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.060370
┌ Info: EM with 100000 data points 50 iterations avll -1.060370
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0339612    0.100866     0.04565      -0.243727    -0.15499     -0.0274178     0.0930974  -0.116542    -0.13438     -0.0657985    -0.0137852   -0.0437473   -0.00473241   0.053941    0.032062    -0.0504529   -0.117476    -0.0148495   -0.0139169   -0.0737734   -0.116864    0.0655767    0.169357     0.0343955    -0.0635541     0.279033
  0.0280235   -0.0491043   -0.111584     -0.149456    -0.0587217    0.0227147    -0.14893    -0.148951    -0.0177798   -0.0389586    -0.160663     0.128718     0.090699     0.041766   -0.260783     0.178601     0.0525276    0.0358807   -0.0698504   -0.0187356   -0.0579759  -0.0398799    0.0660948   -0.169943      0.153441      0.00833358
  0.0224159    0.0960189   -0.0126289    -0.117338    -0.025797    -0.0848648     0.0319754   0.00621946  -0.0493276   -0.173388      0.0230004   -0.00968593  -0.0810144    0.0707343  -0.0390988    0.0716442    0.0218543    0.0188665   -0.0779849    0.106024     0.0626135  -0.0154085    0.103407    -0.12382       0.0909247    -0.0464462
 -0.0872002    0.00173985   0.118775     -0.0119236   -0.0299486    0.004725      0.0647333  -0.0780203    0.0519345   -0.211235     -0.00516364   0.137321    -0.0084451   -0.0233643   0.0558441   -0.03082      0.0675335    0.230737    -0.13684      0.0213851    0.0730275   0.101906     0.0581938   -0.0718899     0.0827373    -0.0366929
 -0.0863299    0.0618289    0.141415      0.0490265    0.0194639    0.0662329    -0.0147487  -0.0591457    0.0175669   -0.0222011    -0.0820858    0.113209     0.0156697    0.0908574   0.0706964   -0.0391475    0.17457     -0.0239749    0.0592172   -0.0796313   -0.125442    0.0257926    0.077415     0.0746149    -0.2348        0.0970901
 -0.00578297  -0.0499009   -0.136026     -0.0926129   -0.101706     0.00480437    0.0493696   0.0611381   -0.0539805   -0.00332325   -0.134678     0.138379    -0.148829     0.0908695  -0.125764    -0.0114067   -0.0883493   -0.067133    -0.117217    -0.0612569    0.200631    0.156799    -0.20258     -0.13462       0.0540533     0.0291064
  0.0374293   -0.132151    -0.0371646     0.122545    -0.11064      0.0712025    -0.101076   -0.159962     0.13179     -0.187829     -0.108054     0.127674    -0.107335     0.152263    0.0288672    0.00413796  -0.22532     -0.0572982    0.17374     -0.198061    -0.0201727   0.0646271    0.0162844   -0.0933269     0.0826647     0.13331
  0.118572    -0.135273    -0.028164      0.0857039    0.0662907   -0.037241      0.121341   -0.185453     0.0313335   -0.0420149    -0.0390252    0.030576     0.0568025    0.101153    0.00544854  -0.0148266   -0.0396431    0.0328742    0.137245     0.00239234   0.0593001   0.0903672    0.12489      0.169935      0.0504295     0.215941
  0.15513      0.23859      0.228857      0.0411319   -0.141057    -0.140429     -0.116631    0.0234313   -0.0213901   -0.160594      0.122256    -0.0828857   -0.181208    -0.103204    0.0482552    0.015712    -0.0210777    0.0564121   -0.156679     0.0924593    0.163657   -0.0566493   -0.0148747   -0.00140752   -0.175975     -0.240214
 -0.27328     -0.0248117    0.0376703    -0.0706326   -0.11139     -0.131345      0.0134217  -0.127709    -0.115867     0.0248942    -0.0792306   -0.021052     0.0430643    0.0668353  -0.0625633   -0.0161494    0.0309603   -0.0997385    0.0589141   -0.0412993   -0.0697965  -0.210347     0.108723    -0.0598092     0.00184799   -0.0599125
  0.116985     0.168597     0.0168368     0.0418494   -0.0518994   -0.129542      0.0658547   0.0354839   -0.0626772   -0.15033      -0.0729226    0.0418943   -0.051048    -0.075488    0.096503     0.064347    -0.195096    -0.163867     0.0117689    0.0256282   -0.20925     0.136592    -0.0596913    0.040941      0.0858634     0.0371822
  0.273762     0.0267943   -0.0265849    -0.171849     0.017224     0.138291     -0.0285301   0.172289    -0.16509      0.00133254   -0.0821883    0.097947    -0.0470258   -0.180391    0.204823     0.0823455    0.0342799    0.12273      0.0423839   -0.00126971   0.0966633  -0.13115      0.0344084    0.37483       0.23706      -0.0577977
 -0.0162816    0.0433852   -0.13522       0.0407288    0.0196878   -0.156644      0.18257     0.107614     0.0460904   -0.0134073     0.010853    -0.0675405    0.0648697   -0.0891216  -0.0971447    0.210902    -0.038681    -0.114701     0.0804872   -0.0962734   -0.161528    0.126449     0.0863845   -0.218289     -0.0167354    -0.00544572
 -0.0204739   -0.105801    -0.0419462    -0.118575    -0.0612518   -0.0324746     0.0494762  -0.00244599   0.170992     0.00891983    0.0158402   -0.0593741    0.106828     0.185807    0.145807    -0.133008     0.0778179   -0.0785877   -0.0629905   -0.130642     0.146948   -0.0872016    0.0646869    0.0940829     0.103788     -0.0863414
  0.0762892   -0.0242206   -0.106933      0.0605088   -0.00472291  -0.200954     -0.0412397   0.0218166    0.0887765    0.195519      0.0391579   -0.098816     0.0290075    0.164506    0.0113242    0.122594     0.0230136   -0.107197    -0.0304398    0.0138834    0.0740998  -0.0212524    0.0130035    0.0257136     0.200845      0.107117
  0.308574    -0.106865     0.0389542     0.0706285   -0.0479968   -0.165687     -0.108342   -0.0218789    0.00415835   0.020056      0.106817    -0.00926253  -0.00819941  -0.06569    -0.0530161    0.0275642    0.00447164  -0.0568649   -0.262035    -0.0481222    0.0603696   0.110183    -0.0649855   -0.125742     -0.0926861    -0.0613748
 -0.00919224  -0.0659495   -0.0992756    -0.0271112    0.0299788    0.024776     -0.0204169   0.00176888  -0.0428704   -0.0229022    -0.019228     0.076641     0.0158538    0.0946318  -0.0647488   -0.0132852    0.123519     0.00129272   0.115306    -0.0840822    0.162728   -0.0722289    0.0942396    0.168708      0.0956792     0.0169073
  0.125044     0.144051     0.194138      0.0826544    0.203697     0.0444085    -0.138831   -0.0943928   -0.154065     0.0814509    -0.0847203    0.0943685   -0.012946    -0.0978522  -0.0324404    0.0859443    0.169243     0.169529     0.00812203   0.0563019   -0.0626734  -0.0079315    0.0361875    0.000978963  -0.021346      0.131992
  0.0666911   -0.0503401    0.0103457     0.0586727    0.0807237   -0.0121414    -0.0409151   0.0170865    0.0162492    0.042905     -0.0771547   -0.191941     0.252871     0.175864   -0.114922     0.152485    -0.144482     0.172096     0.0880506   -0.0423228   -0.10749    -0.139932     0.0659445   -0.12713      -0.0789936     0.0390764
 -0.185158    -0.208636    -0.270001      0.0609932    0.138469    -0.189226     -0.106411    0.170574     0.0788844    0.0864379    -0.160828     0.0083941    0.242612    -0.0442424   0.0280336   -0.125837     0.0115269    0.0105141    0.137947     0.0290444   -0.0245735  -0.0267516   -0.0263529   -0.0466147     0.164589     -0.139142
 -0.0102594    0.0128839    0.000423114   0.167044     0.0155752   -0.0679209    -0.0929295  -0.079179     0.0370837    0.0736512     0.0739648   -0.0497268    0.0330723    0.258637   -0.16285     -0.061664    -0.00395828   0.110097     0.00475802   0.0397804    0.0705009   0.167991     0.0132898   -0.165313      0.0442386     0.0030452
 -0.0191376   -0.13573      0.0672691    -0.0349956    0.141243    -0.000758036  -0.0115196   0.0830125   -0.0123366   -0.115577      0.0377768   -0.00885194   0.0218169    0.0515005  -0.120048     0.0119618    0.0545448   -0.0465653   -0.190248    -0.12868      0.12678     0.207229     0.128372    -0.0724914     0.0671937    -0.0152254
  0.0688815    0.117885     0.00318824   -0.105073    -0.157758    -0.0236682    -0.105168   -0.177065     0.017453     0.112853      0.195737    -0.055826     0.0232718   -0.11078    -0.115736     0.14217     -0.15721     -0.0437948    0.0200962   -0.0161732    0.16062    -0.0875867   -0.123048    -9.23495e-5   -0.0221797    -0.0180585
  0.0379869    0.162896    -0.2856        0.137842     0.0656495   -0.104145      0.0395747   0.00811869  -0.0899368   -0.0527208     0.194978     0.00895614   0.227287     0.0649258   0.165855     0.0225952   -0.0309965   -0.202239     0.208202    -0.0157896   -0.118736    0.00326204  -0.11387     -0.0967237    -0.0669979    -0.0579105
 -0.0147103    0.0232813   -0.0661835    -0.0365125   -0.0989494    0.0432368    -0.0530647  -0.181716    -0.0101614   -0.0171023    -0.196244    -0.109579    -0.0864223   -0.0407309   0.0457139   -0.0452963    0.0419397    0.0461224    0.0985817    0.0904565    0.171387    0.187455    -0.110798    -0.1047       -0.00176075    0.107393
 -0.0593811   -0.0789506    0.0778973    -0.00125413   0.114081     0.00375585   -0.161961    0.0844466   -0.125157    -0.000794013   0.20769      0.175814    -0.0894128   -0.078208    0.0447354    0.0293124   -0.19015     -0.022354    -0.0671567    0.0273756    0.027966   -0.138335    -0.0114162   -0.0430618    -0.000574719  -0.0226379
 -0.0150957    0.0077876    0.248345     -0.186775     0.0680051   -0.0100584     0.0578834   0.0432811    0.161096     0.036374     -0.00781414   0.0821641    0.047884     0.0510287  -0.162511    -0.0469739    0.110208    -0.0332835    0.0812573   -0.0856548    0.262892    0.04552     -0.0169524   -0.00308463    0.00323849    0.139523
  0.0546755    0.0459201    0.0137204     0.00728494   0.155947    -0.150634     -0.0515076  -0.212332     0.0680473   -0.0502877    -0.0571428   -0.0914167    0.0348821   -0.019217    0.193408     0.0872654    0.0521542   -0.0858622   -0.378718     0.179118    -0.0449089  -0.0112989   -0.0177888    0.00398003   -0.048001      0.0112299
  0.11862     -0.175021     0.0154173     0.091465    -0.15283     -0.0697977     0.0183102   0.216572    -0.0798275   -0.0594553     0.225691    -0.0729896   -0.141097    -0.0269008  -0.224344     0.0956108    0.127896     0.197077     0.0203264    0.035189     0.0289846  -0.115277    -0.158913     0.0198479    -0.0368217     0.0326247
  0.0421761   -0.0634678    0.0575613     0.00781568   0.0085527    0.153872      0.0823798  -0.0474436   -0.129337     0.189858      0.0924777   -0.0277159   -0.159429    -0.0292234  -0.0906693   -0.136844    -0.115767     0.15479      0.090926     0.109102    -0.184519    0.112605     0.0811153   -0.0259094    -0.115104      0.034652
  0.0221713   -0.0211745   -0.121092      0.024273    -0.0160312    0.0831276     0.0775046  -0.231303    -0.00801753   0.0372801     0.156517     0.0929337   -0.276668     0.0573888   0.0728403   -0.0656122   -0.0430144    0.045122     0.108241    -0.033808     0.127509    0.0278806    0.088967    -0.0963322     0.0272895    -0.252319
 -0.0799344    0.212076    -0.0190968    -0.0762216   -0.0827271    0.0491365     0.0945614  -0.063381     0.0161683   -0.0518108    -0.0333332    0.220306    -0.228258    -0.0536725   0.125534     0.033441    -0.127632     0.0101649    0.0315075   -0.0725323    0.0292881   0.122581     0.00284735  -0.00180143    0.0240235    -0.0736073[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     16
│     17
│     20
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.060763
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      8
│     15
│     16
│      ⋮
│     28
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.016104
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      8
│     12
│     13
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.996982
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│     15
│     16
│     17
│      ⋮
│     28
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.021726
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      8
│     10
│     15
│      ⋮
│     20
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.012688
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      8
│     12
│     13
│      ⋮
│     28
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.989338
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      8
│     15
│     16
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.017611
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      8
│     10
│     15
│      ⋮
│     28
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.011176
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      8
│     12
│     13
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.005803
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      8
│     15
│     16
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.006633
┌ Info: EM with 100000 data points 10 iterations avll -1.006633
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.044495     0.0287361    0.0207846   -0.127268      0.13849    -0.0141284     0.000387379   0.110178     0.0414823   -0.0413575     0.131575    -0.0124959    0.036621    -0.181461     0.0180414   -0.0601895   -0.103928     0.0465343     0.0367826    -0.142971     0.0970894   -0.13692     0.0784861    0.0433849  -0.113588    -0.0305709
  0.0485194    0.116048    -0.025756     0.048896      0.0482996  -0.0229901     0.0196481    -0.0247421    0.0490512    0.047267      0.041718    -0.218368     0.0577193    0.0413311    0.119381    -0.0189717    0.0116546   -0.117108     -0.124941      0.224936    -0.133403    -0.0590018  -0.1434       0.1322     -0.0803568    0.125437
 -0.0624025    0.0804616   -0.0382635   -0.0194735     0.0575622  -0.104789      0.143643     -0.11695      0.0708803   -0.0906102    -0.101485    -0.00844499  -0.142958    -0.010706     0.0334151   -0.0120092   -0.115892    -0.0878835    -0.0143374    -0.172829     0.0501436    0.127627   -0.00831269  -0.184288   -0.154221     0.0309716
  0.213455     0.0743489    0.0216658    0.0982666     0.0575481  -0.000138866   0.117584     -0.0707618    0.0706905   -0.00816402   -0.04835      0.0233       0.0515416   -0.102451     0.0847029   -0.137068    -0.0218838    0.0446338     0.0968916    -0.0522548    0.104575     0.109236   -0.26103      0.0415956  -0.120099     0.125242
  0.102445    -0.0280927    0.108331     0.111081     -0.129091    0.0339831     0.12252       0.204659    -0.0191099   -0.0692628    -0.0505437   -0.00838053  -0.0958274   -0.260739     0.0862729   -0.0851989    0.0163088    0.0485228     0.138301      0.102395     0.131636     0.119546   -0.0681794   -0.0246095   0.0904132   -0.0213571
 -0.0271353    0.0951681    0.0700668   -0.000516302   0.0431084  -0.103661     -0.199128     -0.0575178    0.079829    -0.0243574    -0.0586553    0.117858    -0.0218845   -0.0405796    0.15378     -0.0972711    0.0339273   -0.0690512    -0.102282     -0.0132641   -0.0699971   -0.0857611   0.127774    -0.123944   -0.0479322    0.0536143
 -0.0258481    0.0400881    0.0821506    0.0597686    -0.213455   -0.0177509     0.117598      0.0484444    0.0117888   -0.0994891    -0.217902     0.00806321  -0.0798694    0.00797463  -0.199087     0.0792639   -0.0289116    0.0125982     0.226162     -0.0268936    0.0663484   -0.122247    0.0789419    0.0687639  -0.036423     0.157168
  0.0664425   -0.0230955   -0.0216615   -0.0294202     0.132751    0.0179107    -0.0837447     0.0197114   -0.0439617    0.0179877    -0.0843128    0.0639521   -0.0642205    0.0923998    0.0963466    0.036864    -0.132611    -0.0408371     0.0414865     0.137468     0.0238847    0.103728   -0.0147817   -0.153023    0.0598074    0.00587183
 -0.0515763    0.206357    -0.00572016   0.0840073     0.0706062   0.0343189     0.021251      0.064082     0.112166    -0.00787006   -0.0459165   -0.0174783    0.0582458    0.143012    -0.0815979    0.0824362    0.0202325    0.0890358    -0.0504354    -0.104015    -0.0336768   -0.259833   -0.067829    -0.176877    0.0428799   -0.0128624
 -0.00486139   0.00504212  -0.0643279    0.0408088     0.147867    0.168626     -0.173687      0.0126614    0.0878592    0.0415977     0.276        0.063275     0.172481     0.142613     0.0696345   -0.121136     0.0567615    0.0493202    -0.0938638     0.0729811   -0.0894447    0.107091    0.00867257  -0.0174161   0.0148282    0.0564609
 -0.101233     0.0851301   -0.122775    -0.105295      0.0787284  -0.121014      0.0056925    -0.0301896    0.084371    -0.145567      0.0613507   -0.0551234    0.00841735   0.0388896    0.101727     0.0121185    0.0804226   -0.0885703    -0.0181481     0.0441058   -0.0120291   -0.0626302  -0.0032282    0.0337727   0.0674812    0.143077
  0.0181369   -0.0382907    0.0641664    0.0352711    -0.0239574   0.0170962    -0.0023405    -0.221502    -0.0847009    0.0706318    -0.039278     0.105043     0.0935494   -0.0397551   -0.154042    -0.0537066   -0.304082    -0.0148743    -0.0750845     0.0182901   -0.135771     0.0817583   0.0961475   -0.0673707   0.101952     0.0644992
  0.039006     0.132811    -0.332201     0.0332874     0.209705   -0.118746     -0.0904297    -0.0197549    0.051656     0.172804      0.0874105   -0.0984165    0.0640805   -0.0110112    0.00580263  -0.0713655    0.303229     0.02125       0.000993249   0.0884171    0.113439     0.0726238   0.193506     0.108115    0.0794373    0.00790521
  0.0108705    0.040592     0.054176    -0.122488      0.0247509   0.12743      -0.120345      0.0269903   -0.00255762   0.111662      0.145007     0.0586143    0.0305687   -0.027425     0.110338    -0.0755063   -0.110033    -0.0258067     0.0478377    -0.0382317   -0.00464922   0.093182    0.127966    -0.0412603   0.210385     0.0120158
  0.041305     0.0316899   -0.0983703    0.055294     -0.0459489   0.0787174     0.0177183    -0.100294     0.0214014   -0.131291      0.062541    -0.116265     0.115921     0.19685      0.0897786    0.0897151   -0.0326754   -0.206858     -0.0672758     0.0567619   -0.070016    -0.109922    0.0160262   -0.0866605   0.0391661   -0.0515787
 -0.00303542   0.130237     0.0893109   -0.0128824     0.0557378   0.065187      0.0139327    -0.147843    -0.0797795    0.00157573   -0.036619    -0.133967     0.137308    -0.0719373   -0.0300298   -0.154418    -0.116835    -0.11321      -0.0717072     0.0272559   -0.00937812  -0.0687741  -0.0264528   -0.108646   -0.0753965    0.118534
 -0.113151    -0.0231718    0.219174    -0.0377537    -0.127328    0.0123044     0.101774      0.0190122    0.022131    -0.0294939     0.114878     0.0654059   -0.0963706   -0.118701     0.02431      0.221072    -0.19443     -0.00926311    0.148455     -0.00459825  -0.0476243    0.0086734   0.0145694   -0.0385772   0.0243222   -0.110832
  0.116856    -0.125271    -0.0743286   -0.0640384     0.105395   -0.0577618    -0.0673212     0.0534972   -0.0103788   -0.0811668     0.111533    -0.0321553   -0.0452701    0.271598    -0.00717198   0.035253     0.0342474   -0.0187525    -0.0848541    -0.00262667   0.0456221    0.0999209   0.0281707    0.0155135   0.0440043    0.040895
  0.106101     0.00753122  -0.0287546   -0.122277      0.236155   -0.0233615     0.0128848    -0.00021441   0.0456968   -0.075694      0.0612029   -0.0465818    0.00147281  -0.161496    -0.0914744   -0.0236567   -0.0408338    0.133117      0.0115509     0.0808182   -0.0669521    0.0275687  -0.173445    -0.0392555  -0.0778219   -0.110536
 -0.253055     0.0915251    0.120122     0.0129289    -0.0334526  -0.0107681     0.0506604    -0.15722     -0.145197    -0.102295      0.0671613   -0.204748     0.0674265   -0.00365033   0.184704    -0.045608    -0.220802     0.0145102    -0.0510902    -0.102487    -0.0503625    0.0703869  -0.0292701   -0.0841169  -0.0201562    0.0452231
  0.172693    -0.0150568    0.0293583    0.130237      0.0849492  -0.117714      0.117972     -0.0157468    0.0324407   -0.0777585    -0.126503     0.126581     0.152932     0.11576     -0.109222    -0.0121531   -0.0753277   -0.000435815  -0.015111      0.0323477    0.11128      0.0625535  -0.0690657   -0.119988    0.00774861  -0.0540099
 -0.245183     0.0128155   -0.0804825    0.0844015     0.166173   -0.204771      0.0464592    -0.0309895    0.0654897    0.086617     -0.14884      0.00860413  -0.0945181    0.234309    -0.0821335    0.0283021    0.184408     0.0237838     0.0143446    -0.0280979   -0.0850506    0.0552159  -0.0489552   -0.0770257  -0.0562256   -0.185807
 -7.39275e-6  -0.0572866    0.0190954   -0.130823     -0.0963998   0.171536      0.113182      0.105512    -0.0258163   -0.0721256     0.109158    -0.222686     0.116162    -0.0317529    0.173689     0.0613512    0.172748     0.0361783    -0.271341      0.0348629    0.15928      0.0215962  -0.0576791   -0.0608892   0.065827    -0.0553435
 -0.124613     0.00135115  -0.0208516    0.0243094     0.0590813   0.0611986     0.0816665    -0.280972    -0.0739219    0.000531718   0.077382     0.083136    -0.0141822   -0.128256    -0.0816416    0.0825679    0.140022     0.209597      0.0249355     0.0531173    0.00273126   0.0020074   0.114211    -0.160469   -0.012225    -0.0600571
  0.101918     0.038479     0.117672    -0.148404     -0.0397849  -0.35156      -0.0339723    -0.0181726    0.0152283   -0.0630939     0.0146472    0.0558453   -0.071399    -0.0788221    0.0522832   -0.045378    -0.0448267   -0.0213333    -0.0394226    -0.206669     0.0709249    0.0172741   0.109735    -0.157805   -0.129901    -0.110377
 -0.00536861   0.0868249   -0.0242306   -0.0777119    -0.121902    0.0617045     0.135569      0.089308    -0.0458297    0.235856      0.049207     0.0104373   -0.212283    -0.0995404    0.0459993    0.11065      0.0200831    0.00867023    0.00039941   -0.0499002   -0.0395376    0.0151228   0.0341606    0.0317361   0.0419137    0.212823
  0.032221    -0.00393534   0.0499608    0.122442      0.0449428  -0.0841577    -0.116198     -0.0677077   -0.127739     0.0634078    -0.130358    -0.0190137   -0.089707    -0.21676      0.126166    -0.0339852    0.0137819    0.116294     -0.0051049    -0.084449     0.0555865   -0.0954009   0.072787    -0.0469085  -0.0561396    0.0600057
 -0.0884867    0.0136442   -0.133363     0.0211435    -0.0233626   0.0506304    -0.0935375    -0.0365799    0.00146782   0.012967     -0.141108     0.0351408    0.0782551   -0.0349068    0.0658661    0.0888087    0.0183178   -0.00771951    0.0626051     0.14245      0.043301    -0.0397121  -0.208849    -0.138522   -0.0946221    0.066307
  0.189704    -0.0790069   -0.0738735   -0.0347205    -0.0159743  -0.123892     -0.200668      0.131661     0.122786    -0.0280536     0.182388     0.0213494   -0.0362127   -0.092622     0.102618     0.078667    -0.0264847   -0.0353396    -0.0425416     0.0696116   -0.0521856    0.0166886   0.068267    -0.0152731   0.0106222    0.0313181
 -0.0765003    0.0995715    0.183585    -0.039562     -0.0111415  -0.222033     -0.0472891     0.0792081   -0.115042    -0.00631154   -0.114199    -0.0817197   -0.0582339    0.0617453   -0.213912     0.0608141    0.069077    -0.0339024    -0.000519409  -0.0240175   -0.0932646    0.0750367  -0.0486781   -0.0227517   0.039457     0.0494338
 -0.041642     0.0496972   -0.0672463    0.0180518    -0.0265315  -0.0055754    -0.0184478    -0.0444282   -0.0472262    0.0438579    -0.0403118   -0.0777799   -0.301044    -0.142896    -0.152164    -0.0893669    0.00693313  -0.096581     -0.180485     -0.0838884   -0.0514897    0.0728005  -0.0404768   -0.0663496   0.0767961   -0.0157932
  0.0863184   -0.0786454    0.0760024   -0.0475        0.0595573  -0.022194      0.0254254     0.144602     0.024515    -0.0887629     0.00419441   0.0160218    0.187534    -0.183557     0.131556     0.00363233   0.0178666    0.115713      0.02323       0.0963033   -0.184653    -0.0658979  -0.071575    -0.0490725   0.0498657   -0.0158526kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4233231924376035
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423345
[ Info: iteration 2, average log likelihood -1.423281
[ Info: iteration 3, average log likelihood -1.423238
[ Info: iteration 4, average log likelihood -1.423191
[ Info: iteration 5, average log likelihood -1.423135
[ Info: iteration 6, average log likelihood -1.423064
[ Info: iteration 7, average log likelihood -1.422959
[ Info: iteration 8, average log likelihood -1.422770
[ Info: iteration 9, average log likelihood -1.422382
[ Info: iteration 10, average log likelihood -1.421619
[ Info: iteration 11, average log likelihood -1.420437
[ Info: iteration 12, average log likelihood -1.419218
[ Info: iteration 13, average log likelihood -1.418445
[ Info: iteration 14, average log likelihood -1.418110
[ Info: iteration 15, average log likelihood -1.417989
[ Info: iteration 16, average log likelihood -1.417946
[ Info: iteration 17, average log likelihood -1.417931
[ Info: iteration 18, average log likelihood -1.417925
[ Info: iteration 19, average log likelihood -1.417922
[ Info: iteration 20, average log likelihood -1.417921
[ Info: iteration 21, average log likelihood -1.417920
[ Info: iteration 22, average log likelihood -1.417920
[ Info: iteration 23, average log likelihood -1.417919
[ Info: iteration 24, average log likelihood -1.417919
[ Info: iteration 25, average log likelihood -1.417919
[ Info: iteration 26, average log likelihood -1.417918
[ Info: iteration 27, average log likelihood -1.417918
[ Info: iteration 28, average log likelihood -1.417918
[ Info: iteration 29, average log likelihood -1.417918
[ Info: iteration 30, average log likelihood -1.417918
[ Info: iteration 31, average log likelihood -1.417917
[ Info: iteration 32, average log likelihood -1.417917
[ Info: iteration 33, average log likelihood -1.417917
[ Info: iteration 34, average log likelihood -1.417917
[ Info: iteration 35, average log likelihood -1.417917
[ Info: iteration 36, average log likelihood -1.417917
[ Info: iteration 37, average log likelihood -1.417917
[ Info: iteration 38, average log likelihood -1.417917
[ Info: iteration 39, average log likelihood -1.417917
[ Info: iteration 40, average log likelihood -1.417917
[ Info: iteration 41, average log likelihood -1.417917
[ Info: iteration 42, average log likelihood -1.417917
[ Info: iteration 43, average log likelihood -1.417917
[ Info: iteration 44, average log likelihood -1.417916
[ Info: iteration 45, average log likelihood -1.417916
[ Info: iteration 46, average log likelihood -1.417916
[ Info: iteration 47, average log likelihood -1.417916
[ Info: iteration 48, average log likelihood -1.417916
[ Info: iteration 49, average log likelihood -1.417916
[ Info: iteration 50, average log likelihood -1.417916
┌ Info: EM with 100000 data points 50 iterations avll -1.417916
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4233450330851287
│     -1.4232811744032288
│      ⋮
└     -1.4179163300847395
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417938
[ Info: iteration 2, average log likelihood -1.417871
[ Info: iteration 3, average log likelihood -1.417826
[ Info: iteration 4, average log likelihood -1.417776
[ Info: iteration 5, average log likelihood -1.417720
[ Info: iteration 6, average log likelihood -1.417659
[ Info: iteration 7, average log likelihood -1.417598
[ Info: iteration 8, average log likelihood -1.417540
[ Info: iteration 9, average log likelihood -1.417490
[ Info: iteration 10, average log likelihood -1.417450
[ Info: iteration 11, average log likelihood -1.417416
[ Info: iteration 12, average log likelihood -1.417388
[ Info: iteration 13, average log likelihood -1.417363
[ Info: iteration 14, average log likelihood -1.417338
[ Info: iteration 15, average log likelihood -1.417313
[ Info: iteration 16, average log likelihood -1.417287
[ Info: iteration 17, average log likelihood -1.417260
[ Info: iteration 18, average log likelihood -1.417231
[ Info: iteration 19, average log likelihood -1.417200
[ Info: iteration 20, average log likelihood -1.417169
[ Info: iteration 21, average log likelihood -1.417138
[ Info: iteration 22, average log likelihood -1.417107
[ Info: iteration 23, average log likelihood -1.417076
[ Info: iteration 24, average log likelihood -1.417047
[ Info: iteration 25, average log likelihood -1.417018
[ Info: iteration 26, average log likelihood -1.416992
[ Info: iteration 27, average log likelihood -1.416967
[ Info: iteration 28, average log likelihood -1.416943
[ Info: iteration 29, average log likelihood -1.416921
[ Info: iteration 30, average log likelihood -1.416901
[ Info: iteration 31, average log likelihood -1.416882
[ Info: iteration 32, average log likelihood -1.416865
[ Info: iteration 33, average log likelihood -1.416849
[ Info: iteration 34, average log likelihood -1.416834
[ Info: iteration 35, average log likelihood -1.416821
[ Info: iteration 36, average log likelihood -1.416809
[ Info: iteration 37, average log likelihood -1.416799
[ Info: iteration 38, average log likelihood -1.416789
[ Info: iteration 39, average log likelihood -1.416781
[ Info: iteration 40, average log likelihood -1.416774
[ Info: iteration 41, average log likelihood -1.416767
[ Info: iteration 42, average log likelihood -1.416761
[ Info: iteration 43, average log likelihood -1.416756
[ Info: iteration 44, average log likelihood -1.416752
[ Info: iteration 45, average log likelihood -1.416748
[ Info: iteration 46, average log likelihood -1.416744
[ Info: iteration 47, average log likelihood -1.416741
[ Info: iteration 48, average log likelihood -1.416738
[ Info: iteration 49, average log likelihood -1.416735
[ Info: iteration 50, average log likelihood -1.416733
┌ Info: EM with 100000 data points 50 iterations avll -1.416733
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4179378579296362
│     -1.417871266622301
│      ⋮
└     -1.4167329908133743
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416747
[ Info: iteration 2, average log likelihood -1.416690
[ Info: iteration 3, average log likelihood -1.416647
[ Info: iteration 4, average log likelihood -1.416599
[ Info: iteration 5, average log likelihood -1.416544
[ Info: iteration 6, average log likelihood -1.416479
[ Info: iteration 7, average log likelihood -1.416405
[ Info: iteration 8, average log likelihood -1.416327
[ Info: iteration 9, average log likelihood -1.416245
[ Info: iteration 10, average log likelihood -1.416164
[ Info: iteration 11, average log likelihood -1.416086
[ Info: iteration 12, average log likelihood -1.416011
[ Info: iteration 13, average log likelihood -1.415938
[ Info: iteration 14, average log likelihood -1.415869
[ Info: iteration 15, average log likelihood -1.415803
[ Info: iteration 16, average log likelihood -1.415740
[ Info: iteration 17, average log likelihood -1.415681
[ Info: iteration 18, average log likelihood -1.415625
[ Info: iteration 19, average log likelihood -1.415573
[ Info: iteration 20, average log likelihood -1.415525
[ Info: iteration 21, average log likelihood -1.415481
[ Info: iteration 22, average log likelihood -1.415440
[ Info: iteration 23, average log likelihood -1.415402
[ Info: iteration 24, average log likelihood -1.415367
[ Info: iteration 25, average log likelihood -1.415336
[ Info: iteration 26, average log likelihood -1.415307
[ Info: iteration 27, average log likelihood -1.415280
[ Info: iteration 28, average log likelihood -1.415256
[ Info: iteration 29, average log likelihood -1.415235
[ Info: iteration 30, average log likelihood -1.415215
[ Info: iteration 31, average log likelihood -1.415198
[ Info: iteration 32, average log likelihood -1.415182
[ Info: iteration 33, average log likelihood -1.415168
[ Info: iteration 34, average log likelihood -1.415156
[ Info: iteration 35, average log likelihood -1.415145
[ Info: iteration 36, average log likelihood -1.415135
[ Info: iteration 37, average log likelihood -1.415126
[ Info: iteration 38, average log likelihood -1.415118
[ Info: iteration 39, average log likelihood -1.415111
[ Info: iteration 40, average log likelihood -1.415104
[ Info: iteration 41, average log likelihood -1.415098
[ Info: iteration 42, average log likelihood -1.415092
[ Info: iteration 43, average log likelihood -1.415087
[ Info: iteration 44, average log likelihood -1.415082
[ Info: iteration 45, average log likelihood -1.415078
[ Info: iteration 46, average log likelihood -1.415074
[ Info: iteration 47, average log likelihood -1.415070
[ Info: iteration 48, average log likelihood -1.415066
[ Info: iteration 49, average log likelihood -1.415063
[ Info: iteration 50, average log likelihood -1.415059
┌ Info: EM with 100000 data points 50 iterations avll -1.415059
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4167471324938028
│     -1.4166898168805395
│      ⋮
└     -1.4150592974207834
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415067
[ Info: iteration 2, average log likelihood -1.415009
[ Info: iteration 3, average log likelihood -1.414960
[ Info: iteration 4, average log likelihood -1.414906
[ Info: iteration 5, average log likelihood -1.414841
[ Info: iteration 6, average log likelihood -1.414763
[ Info: iteration 7, average log likelihood -1.414671
[ Info: iteration 8, average log likelihood -1.414567
[ Info: iteration 9, average log likelihood -1.414455
[ Info: iteration 10, average log likelihood -1.414341
[ Info: iteration 11, average log likelihood -1.414231
[ Info: iteration 12, average log likelihood -1.414127
[ Info: iteration 13, average log likelihood -1.414032
[ Info: iteration 14, average log likelihood -1.413948
[ Info: iteration 15, average log likelihood -1.413873
[ Info: iteration 16, average log likelihood -1.413809
[ Info: iteration 17, average log likelihood -1.413753
[ Info: iteration 18, average log likelihood -1.413705
[ Info: iteration 19, average log likelihood -1.413663
[ Info: iteration 20, average log likelihood -1.413627
[ Info: iteration 21, average log likelihood -1.413594
[ Info: iteration 22, average log likelihood -1.413565
[ Info: iteration 23, average log likelihood -1.413539
[ Info: iteration 24, average log likelihood -1.413514
[ Info: iteration 25, average log likelihood -1.413492
[ Info: iteration 26, average log likelihood -1.413471
[ Info: iteration 27, average log likelihood -1.413451
[ Info: iteration 28, average log likelihood -1.413431
[ Info: iteration 29, average log likelihood -1.413413
[ Info: iteration 30, average log likelihood -1.413396
[ Info: iteration 31, average log likelihood -1.413379
[ Info: iteration 32, average log likelihood -1.413363
[ Info: iteration 33, average log likelihood -1.413348
[ Info: iteration 34, average log likelihood -1.413333
[ Info: iteration 35, average log likelihood -1.413319
[ Info: iteration 36, average log likelihood -1.413305
[ Info: iteration 37, average log likelihood -1.413292
[ Info: iteration 38, average log likelihood -1.413279
[ Info: iteration 39, average log likelihood -1.413266
[ Info: iteration 40, average log likelihood -1.413254
[ Info: iteration 41, average log likelihood -1.413242
[ Info: iteration 42, average log likelihood -1.413231
[ Info: iteration 43, average log likelihood -1.413219
[ Info: iteration 44, average log likelihood -1.413208
[ Info: iteration 45, average log likelihood -1.413198
[ Info: iteration 46, average log likelihood -1.413187
[ Info: iteration 47, average log likelihood -1.413177
[ Info: iteration 48, average log likelihood -1.413167
[ Info: iteration 49, average log likelihood -1.413157
[ Info: iteration 50, average log likelihood -1.413147
┌ Info: EM with 100000 data points 50 iterations avll -1.413147
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4150672498084866
│     -1.4150089680158071
│      ⋮
└     -1.4131471438799028
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413147
[ Info: iteration 2, average log likelihood -1.413071
[ Info: iteration 3, average log likelihood -1.413000
[ Info: iteration 4, average log likelihood -1.412918
[ Info: iteration 5, average log likelihood -1.412817
[ Info: iteration 6, average log likelihood -1.412692
[ Info: iteration 7, average log likelihood -1.412544
[ Info: iteration 8, average log likelihood -1.412379
[ Info: iteration 9, average log likelihood -1.412204
[ Info: iteration 10, average log likelihood -1.412030
[ Info: iteration 11, average log likelihood -1.411865
[ Info: iteration 12, average log likelihood -1.411714
[ Info: iteration 13, average log likelihood -1.411579
[ Info: iteration 14, average log likelihood -1.411460
[ Info: iteration 15, average log likelihood -1.411357
[ Info: iteration 16, average log likelihood -1.411268
[ Info: iteration 17, average log likelihood -1.411190
[ Info: iteration 18, average log likelihood -1.411123
[ Info: iteration 19, average log likelihood -1.411063
[ Info: iteration 20, average log likelihood -1.411010
[ Info: iteration 21, average log likelihood -1.410963
[ Info: iteration 22, average log likelihood -1.410919
[ Info: iteration 23, average log likelihood -1.410879
[ Info: iteration 24, average log likelihood -1.410842
[ Info: iteration 25, average log likelihood -1.410808
[ Info: iteration 26, average log likelihood -1.410775
[ Info: iteration 27, average log likelihood -1.410744
[ Info: iteration 28, average log likelihood -1.410714
[ Info: iteration 29, average log likelihood -1.410685
[ Info: iteration 30, average log likelihood -1.410657
[ Info: iteration 31, average log likelihood -1.410630
[ Info: iteration 32, average log likelihood -1.410603
[ Info: iteration 33, average log likelihood -1.410578
[ Info: iteration 34, average log likelihood -1.410552
[ Info: iteration 35, average log likelihood -1.410528
[ Info: iteration 36, average log likelihood -1.410504
[ Info: iteration 37, average log likelihood -1.410481
[ Info: iteration 38, average log likelihood -1.410458
[ Info: iteration 39, average log likelihood -1.410435
[ Info: iteration 40, average log likelihood -1.410413
[ Info: iteration 41, average log likelihood -1.410391
[ Info: iteration 42, average log likelihood -1.410370
[ Info: iteration 43, average log likelihood -1.410350
[ Info: iteration 44, average log likelihood -1.410329
[ Info: iteration 45, average log likelihood -1.410310
[ Info: iteration 46, average log likelihood -1.410290
[ Info: iteration 47, average log likelihood -1.410272
[ Info: iteration 48, average log likelihood -1.410254
[ Info: iteration 49, average log likelihood -1.410236
[ Info: iteration 50, average log likelihood -1.410219
┌ Info: EM with 100000 data points 50 iterations avll -1.410219
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4131468478560296
│     -1.4130710779514741
│      ⋮
└     -1.410218982640287
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4233231924376035
│     -1.4233450330851287
│     -1.4232811744032288
│     -1.423238085895078
│      ⋮
│     -1.410253664575318
│     -1.4102360606210402
└     -1.410218982640287
32×26 Array{Float64,2}:
 -0.835749   -0.267185   -0.416255     0.186907     0.357388    -0.772159    -0.793485   -0.0289076  -0.0645967    0.0967564    0.0267285  -0.472196    -0.352831    -0.137644    0.144579    0.316416     0.102319     0.0776185   -0.0856285    0.337833     -0.016723     0.0540555    0.861003    -0.308238     0.157191    -0.394304
  0.159517   -0.264592   -1.19958     -0.100992     0.0506052   -0.202711    -0.696591    0.0948939  -0.0246938   -0.168897     0.926749   -0.0202912    0.109886    -0.198136    0.569842    0.197602     0.323959     0.247333    -0.248029     0.536764      0.460876     0.107096    -0.171224     0.00867344   1.05401     -0.212938
  0.213276   -0.447465    0.235889    -0.232364     0.0520382   -0.0290817    0.210596   -0.26461     0.483989    -0.822936    -0.162772    0.334044     0.0342768   -0.292696   -0.252798    0.00389747  -0.310469     0.501006    -0.430271    -0.235495     -0.411434    -0.467805     0.35892      0.0808198   -0.332319    -0.468226
 -0.363321    0.216472    0.0130339    0.0973301    0.044984     0.00838617  -0.0243633  -0.0262995   0.266812    -0.11841      0.21325     0.318906    -0.0437979    0.16103     0.0255698  -0.0327468    0.225007     0.687184    -0.139926    -0.0433416    -0.322535     0.353847     0.759381     0.110225     0.0122454    0.180814
 -0.178211    0.337087   -0.460856    -0.247521    -0.0609643    0.181528     0.171489    0.153418   -0.0662415   -0.648553    -0.912687   -0.482616    -0.191213     0.273715    0.346695   -0.336479     0.147245    -0.343946    -0.882947    -0.341276     -0.253558    -0.207302    -0.261387    -0.513515    -0.185299    -0.157968
  0.212104    0.226608   -0.174748    -0.0918736   -0.346572    -0.245301    -0.24171     0.32126    -0.244406    -0.878903    -0.322761   -0.499141     0.41403      0.737138   -0.364766   -0.335613    -0.28748      0.401666    -0.0789219    0.876894     -0.584077     0.0434604   -0.250836    -0.317802     0.00557989   0.328081
  0.0839197   0.23038     0.543043    -0.0186451   -0.533372     0.0592422    0.34165    -0.0153176  -0.0406392    0.241691    -1.31892    -0.0295032    0.124892    -0.0823132   0.023766   -0.0430136    0.381126    -0.276792     0.306369    -0.238419     -0.352479    -0.523433     0.130849     0.413155    -0.396051     0.486997
 -0.0965046  -0.0211191   0.627243     0.127037    -0.104241    -0.00194866  -0.0798693  -0.284945   -0.307701     0.473591     0.377147    0.0366591   -0.417076    -0.0857697   0.124774    0.443997    -0.148491    -0.758782    -0.36804     -0.411184      0.418078     0.377821     0.232352    -0.498047    -0.138415     0.362078
  0.35358    -0.223264   -0.284573    -0.182161     0.321748     0.0662351   -0.0409082   0.116597   -0.0713397    0.274911    -0.0884018  -0.438291    -0.234723     0.100636   -0.236172   -0.0125376    0.137201    -0.471073     0.345375    -0.278897      0.54243     -0.268569    -0.63567     -0.411194    -0.0200294   -0.211007
 -0.120098    0.202144   -0.147548    -0.496096     0.151762     0.123982     0.149182    0.527544   -0.406413     0.147584    -0.640788    0.794579    -0.466422     0.0262759   0.510031   -0.314738     0.768005    -0.283625     0.249635     0.230771      0.939963    -0.266853    -0.698465     0.276039    -0.356614     0.105372
  0.145058   -0.315825   -0.480518     0.228817     0.0807088   -0.71261     -0.174041    0.481389    0.273233    -0.0232252   -0.0922981  -0.186485     0.184953     0.296369   -0.656261   -0.0172737    0.287627     0.396716     0.518036     0.62044      -0.0161096    0.0104149   -0.425262     0.47217     -0.158844    -0.0563858
  0.186767   -0.148378    0.238104     0.160973     0.332505    -0.192369     0.291911    0.110952    0.187156     0.742043     0.969812    0.589632     0.447619    -0.0260972   0.206269    0.157964     0.218131     0.148618     0.698562     0.322342      0.228489     0.343408    -0.031134     0.452988     0.281982     0.286328
  0.166862    0.146778    0.317867    -0.212005    -0.056063    -0.358993    -0.0584719  -0.655311   -0.652487     0.137912     0.0506275   0.272211     0.179993    -0.246334    0.650401    0.108965    -0.375017    -0.898128    -0.54819     -0.0637133    -0.359104    -0.803827    -0.0632875   -0.223611     0.102297    -0.351863
  0.708023    0.0690769   0.323774     0.0690041   -0.0778521    0.176165     0.600774   -0.198689    0.196601     0.18889     -0.168449   -0.00884307   0.214533    -0.455971    0.159868    0.169688    -0.814106    -0.397988    -0.146966     0.0325827    -0.00492515   0.611206    -0.99294      0.239131    -0.12571     -0.34932
 -0.473246   -0.293447    0.41354      0.37174      0.0543569    0.502438    -0.166276    0.0403419  -0.421722    -0.0691805    1.09552     0.0757906   -0.409748    -0.797246   -0.175898   -0.433674    -0.605803    -0.0813186    0.524317     0.218181     -0.0252067   -0.244724     0.249807     0.028048     0.370792    -0.0716536
 -0.151563    0.53386     0.314968     0.67243     -0.557963     0.973593     0.365765   -0.643124    0.289301    -0.124461     0.295393   -0.147661     0.2422      -0.419604   -0.105634   -0.34099     -0.749046     0.142103    -0.191693    -0.42243       0.0577604    0.888686     0.821225    -0.119943     0.473613     0.123143
 -0.0803872  -0.113481   -0.511965     0.325511    -0.360049     0.32097     -0.192574    0.448496   -0.268716     0.232398    -0.0558037  -0.513558     0.236742     0.0174087   0.430256   -0.131111     0.264228    -0.56829      0.480042     0.453696     -0.463004    -0.431853    -0.0489454   -0.444024     0.55577      0.144892
 -0.29629     0.594919   -0.386796     0.180628     0.152437    -0.0655743    0.111701    0.18484    -0.310729     0.341381     0.134026   -0.529672    -0.25078      0.0989182  -0.0111663   0.286191     0.0933634   -0.466405     0.702051     0.109277      0.160169     0.478454    -0.271184    -0.397773    -0.121612     0.403247
 -0.0229525  -0.0504917   0.0709273   -0.00975168   0.00458673  -0.0239009   -0.16593    -0.0729806  -0.182168     0.00225996  -0.0238737  -0.359939    -0.360152    -0.082667   -0.0399606   0.0138995   -0.182437    -0.495533    -0.0330587   -0.166905      0.0580582   -0.148779    -0.104011    -0.243288     0.119454    -0.0577336
  0.157536   -0.168632   -0.0852498   -0.400697     0.251443     0.173459    -0.0299748  -0.335109   -0.171225     0.30387      0.0460721  -0.0573008   -0.34961     -0.243781    0.301304   -0.00518348   0.681601    -0.0944054    0.123891    -0.491519      0.461024    -0.151302    -0.0311314   -0.184787     0.283403    -0.206717
 -0.453476    0.229696   -0.20583     -0.36678      0.0758444    0.16569     -0.0178676  -0.111318    0.494539    -0.190798    -0.0354199   0.254715    -0.236711     0.235525   -0.0985361  -0.125119     0.438144     0.603667     0.229899    -0.251134      0.0719963   -0.069833     0.537056     0.137891    -0.322576     0.367544
 -0.272297    0.0853375  -0.246689    -0.216614     0.240806     0.234053     0.305336   -0.193847    0.370648     0.407458    -0.238789    0.393787     0.240498    -0.567697    0.90893    -0.155327    -0.423492     0.170746     0.374855     0.108123      0.337267     0.0199655    0.00234514   0.289023     0.00515985  -0.242736
 -0.396152   -0.0251875   0.430129    -0.110346     0.467131     0.0149334    0.231102    0.255179   -0.070015    -0.0603845   -0.256464    0.127169    -0.0407753   -0.296961    0.0367256  -0.625886    -0.0798352    0.630632     0.0794979   -0.0222855     0.119904     0.185078    -0.0103872   -0.303237    -0.706917     0.00870287
 -0.170838    0.0913984   0.133532    -0.222774    -0.0864058   -0.380358     0.121474    0.169561   -0.272259     0.0540192    0.164784    0.169091     0.184183    -0.271885    0.230808   -0.464042     0.475791     0.443751    -0.421577    -0.000817328   0.0453285   -0.221404     0.435083     0.231549     0.795704     0.199604
  0.110643    0.252592   -0.357116     0.217461     0.171987     0.750096    -0.363409   -0.363854    0.678181    -0.263836     0.0464062  -0.1452       0.241686     0.323521   -0.219564    0.65571     -0.344471    -0.0286135    0.152266    -0.102318     -1.03905     -0.203275     0.0373       0.299352    -0.302499    -0.409974
  0.483692    0.254142    0.454307     0.0755125    0.233216    -0.601882    -0.343913   -0.261767    0.436409     0.0870111   -0.330487    0.324525     0.149024     0.317714   -0.267263    0.786015    -0.213887     0.189546    -0.435606    -0.104132      0.472581     0.488897    -0.106938    -0.0991772   -0.424958    -0.353572
  0.569242    0.0702187  -0.315558    -0.264288     0.0495345    0.0467425    0.421095    0.155429   -0.0785739   -0.255936    -0.115691   -0.070488    -0.00246967   0.137562   -0.0722606   0.0959163   -0.00280207  -0.206392     0.00985987   0.0469296     0.0134895    0.157297    -0.760153    -0.0263831   -0.0652133    0.00192238
  0.615484    0.0765927   0.7308       0.0138073   -0.424808    -0.324702    -0.022668    0.135969   -0.318231    -0.0571438   -0.244578   -0.16171      0.227732     0.0725135  -0.4994     -0.245014    -0.117251    -0.179861    -0.485158    -0.171147      0.258562     0.389102    -0.8745      -0.287622     0.0387038    0.286485
  0.313485    0.0709003  -0.026193     0.350675    -0.113565    -0.0770614   -0.31195     0.110469   -0.140547    -0.303314     0.192975   -0.159765    -0.207394     0.468926   -0.697905    0.362415    -0.258196     0.00441764  -0.565834    -0.127316     -0.692289     0.146697     0.361971    -0.426555     0.192224    -0.468512
  0.135787   -0.320721    0.138092     0.146281    -0.268798     0.0170035   -0.143187   -0.297909    0.151091    -0.456699     0.422852   -0.39197      0.0348669    0.299899   -0.500494    0.258084     0.0179247   -0.418945    -0.311964    -0.140988     -0.297144    -0.318643     0.1102      -0.125027    -0.099175     0.790513
  0.0728051  -0.0108887   0.00300747   0.0114097    0.10512     -0.02195     -0.0423631  -0.0268294   0.163102    -0.0513462    0.0157045   0.132556     0.217963    -0.150043    0.0418689  -0.0467559   -0.18735      0.249816    -0.0247365    0.183126     -0.0516468    0.00663919  -0.0114625    0.0871107    0.0768469   -0.198121
 -0.342381    0.238867    0.200064     0.27508     -0.154348    -0.0822325    0.14584    -0.0595391   0.00625573   0.16337      0.169066    0.130475     0.266523     0.164679    0.104298    0.104157    -0.139218     0.0243784   -0.004081     0.137525     -0.161153     0.094139     0.360299     0.0420151   -0.260725     0.506522[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410202
[ Info: iteration 2, average log likelihood -1.410186
[ Info: iteration 3, average log likelihood -1.410171
[ Info: iteration 4, average log likelihood -1.410156
[ Info: iteration 5, average log likelihood -1.410141
[ Info: iteration 6, average log likelihood -1.410127
[ Info: iteration 7, average log likelihood -1.410114
[ Info: iteration 8, average log likelihood -1.410101
[ Info: iteration 9, average log likelihood -1.410088
[ Info: iteration 10, average log likelihood -1.410076
┌ Info: EM with 100000 data points 10 iterations avll -1.410076
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.431754e+05
      1       7.059556e+05      -2.372198e+05 |       32
      2       6.917278e+05      -1.422782e+04 |       32
      3       6.857541e+05      -5.973662e+03 |       32
      4       6.828170e+05      -2.937074e+03 |       32
      5       6.810928e+05      -1.724195e+03 |       32
      6       6.798601e+05      -1.232694e+03 |       32
      7       6.789799e+05      -8.802708e+02 |       32
      8       6.782959e+05      -6.839205e+02 |       32
      9       6.777752e+05      -5.207793e+02 |       32
     10       6.773039e+05      -4.713001e+02 |       32
     11       6.768749e+05      -4.289794e+02 |       32
     12       6.764875e+05      -3.873867e+02 |       32
     13       6.761150e+05      -3.724523e+02 |       32
     14       6.757543e+05      -3.607404e+02 |       32
     15       6.754436e+05      -3.107166e+02 |       32
     16       6.751843e+05      -2.593214e+02 |       32
     17       6.749526e+05      -2.316219e+02 |       32
     18       6.747343e+05      -2.183020e+02 |       32
     19       6.745324e+05      -2.019053e+02 |       32
     20       6.743446e+05      -1.878688e+02 |       32
     21       6.741745e+05      -1.700997e+02 |       32
     22       6.740213e+05      -1.532095e+02 |       32
     23       6.738876e+05      -1.336794e+02 |       32
     24       6.737682e+05      -1.194303e+02 |       32
     25       6.736355e+05      -1.327006e+02 |       32
     26       6.735043e+05      -1.311164e+02 |       32
     27       6.733784e+05      -1.259122e+02 |       32
     28       6.732660e+05      -1.123831e+02 |       32
     29       6.731603e+05      -1.057451e+02 |       32
     30       6.730620e+05      -9.828462e+01 |       32
     31       6.729729e+05      -8.912095e+01 |       32
     32       6.728868e+05      -8.610374e+01 |       32
     33       6.728037e+05      -8.303883e+01 |       32
     34       6.727342e+05      -6.959740e+01 |       32
     35       6.726742e+05      -5.995243e+01 |       32
     36       6.726199e+05      -5.427015e+01 |       32
     37       6.725712e+05      -4.875428e+01 |       32
     38       6.725319e+05      -3.931003e+01 |       32
     39       6.724978e+05      -3.406133e+01 |       32
     40       6.724689e+05      -2.891512e+01 |       32
     41       6.724431e+05      -2.574254e+01 |       32
     42       6.724174e+05      -2.570047e+01 |       32
     43       6.723919e+05      -2.559288e+01 |       32
     44       6.723727e+05      -1.916382e+01 |       32
     45       6.723527e+05      -1.997120e+01 |       32
     46       6.723334e+05      -1.932657e+01 |       32
     47       6.723120e+05      -2.141829e+01 |       31
     48       6.722940e+05      -1.796635e+01 |       32
     49       6.722770e+05      -1.699611e+01 |       32
     50       6.722587e+05      -1.834356e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 672258.665110881)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421672
[ Info: iteration 2, average log likelihood -1.416674
[ Info: iteration 3, average log likelihood -1.415239
[ Info: iteration 4, average log likelihood -1.414112
[ Info: iteration 5, average log likelihood -1.412999
[ Info: iteration 6, average log likelihood -1.412102
[ Info: iteration 7, average log likelihood -1.411554
[ Info: iteration 8, average log likelihood -1.411258
[ Info: iteration 9, average log likelihood -1.411088
[ Info: iteration 10, average log likelihood -1.410974
[ Info: iteration 11, average log likelihood -1.410889
[ Info: iteration 12, average log likelihood -1.410822
[ Info: iteration 13, average log likelihood -1.410765
[ Info: iteration 14, average log likelihood -1.410716
[ Info: iteration 15, average log likelihood -1.410674
[ Info: iteration 16, average log likelihood -1.410636
[ Info: iteration 17, average log likelihood -1.410602
[ Info: iteration 18, average log likelihood -1.410572
[ Info: iteration 19, average log likelihood -1.410543
[ Info: iteration 20, average log likelihood -1.410518
[ Info: iteration 21, average log likelihood -1.410493
[ Info: iteration 22, average log likelihood -1.410471
[ Info: iteration 23, average log likelihood -1.410449
[ Info: iteration 24, average log likelihood -1.410429
[ Info: iteration 25, average log likelihood -1.410410
[ Info: iteration 26, average log likelihood -1.410391
[ Info: iteration 27, average log likelihood -1.410373
[ Info: iteration 28, average log likelihood -1.410355
[ Info: iteration 29, average log likelihood -1.410338
[ Info: iteration 30, average log likelihood -1.410320
[ Info: iteration 31, average log likelihood -1.410303
[ Info: iteration 32, average log likelihood -1.410285
[ Info: iteration 33, average log likelihood -1.410268
[ Info: iteration 34, average log likelihood -1.410250
[ Info: iteration 35, average log likelihood -1.410232
[ Info: iteration 36, average log likelihood -1.410213
[ Info: iteration 37, average log likelihood -1.410194
[ Info: iteration 38, average log likelihood -1.410176
[ Info: iteration 39, average log likelihood -1.410157
[ Info: iteration 40, average log likelihood -1.410138
[ Info: iteration 41, average log likelihood -1.410119
[ Info: iteration 42, average log likelihood -1.410101
[ Info: iteration 43, average log likelihood -1.410083
[ Info: iteration 44, average log likelihood -1.410065
[ Info: iteration 45, average log likelihood -1.410048
[ Info: iteration 46, average log likelihood -1.410032
[ Info: iteration 47, average log likelihood -1.410016
[ Info: iteration 48, average log likelihood -1.410000
[ Info: iteration 49, average log likelihood -1.409985
[ Info: iteration 50, average log likelihood -1.409971
┌ Info: EM with 100000 data points 50 iterations avll -1.409971
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.131535     0.516045      0.253948    0.602805    -0.489305     1.05691      0.339591   -0.553638    0.308607   -0.0855641   0.303831   -0.064528    0.164377    -0.428185    -0.0357085  -0.337479   -0.858604     0.00519237  -0.133331   -0.253927    0.0731858    0.89176      0.537409   -0.170243    0.401898    0.166859
 -0.168411     0.364511     -0.303511    0.160876     0.127176    -0.193346    -0.0452786   0.0745991  -0.392075    0.477148    0.243039   -0.431383   -0.281648     0.256227    -0.0916612   0.2692      0.251554    -0.435719     0.637103    0.0905199   0.339774     0.346467    -0.353607   -0.315117   -0.129311    0.396812
 -0.261226    -0.000804342   0.405889   -0.131441    -0.32387      0.189201    -0.328428   -0.545075   -0.48023    -0.0747299  -0.474356   -0.43364    -0.226312     0.124241     0.0534175  -0.0379058  -0.334814    -0.731451    -0.699989   -0.585634   -0.318898    -0.409613     0.0367221  -0.668508   -0.239016    0.0381218
 -0.0241316    0.20974      -0.516158    0.516662     0.0421974    0.475318    -0.359374   -0.211467    0.409039   -0.334119    0.328165   -0.0637815   0.0913962    0.518074    -0.408681    0.838792   -0.222712     0.224419    -0.113003   -0.277881   -1.17221      0.00339383   0.498581   -0.061527    0.129561   -0.383911
 -0.211973    -0.228366      0.210306    0.0863629    0.260878    -0.0761397   -0.224664    0.183012    0.385984   -0.0372611  -0.164613    0.0400522  -0.292483    -0.0749224   -0.178082    0.100822   -0.682879    -0.117831     0.445308    0.506757   -0.1284       0.111876    -0.360216   -0.30065    -0.484902   -0.780521
  0.00025786  -0.103144      0.0896852  -0.498187     0.541501     0.511374    -0.0345948  -0.0384436   0.432381   -0.369677   -0.221416    0.218613   -0.0287482    0.0437485   -0.317653   -0.205795    0.297092     0.779565     0.190501   -0.374832    0.194894     0.100487    -0.0765873  -0.119182   -0.676334    0.187551
  0.029586     0.208789      0.310456   -0.0520149   -0.662087    -0.121227     0.40561    -0.118895   -0.175423    0.152266    0.141892    0.0847634   0.20088      0.00279427   0.384999    0.0470946   0.629932    -0.248192    -0.380718   -0.408937    0.087283    -0.277057     0.459604    0.254126    0.570758    0.771599
  0.39502     -0.0319026     0.468721    0.12657     -0.426045    -0.365102    -0.177527    0.268397   -0.357413   -0.705061    0.250184   -0.221366   -0.0999866    0.448226    -1.05948    -0.208014    0.0581907    0.399556    -0.645664    0.0931196  -0.341037     0.219772     0.0326829  -0.35806     0.0778571   0.181539
 -0.0198514    0.215488     -0.18495    -0.216001     0.556663    -0.0365937    0.726049    0.386806    0.502975    0.409988    0.675547    0.798899    0.186529     0.252321     0.253854   -0.025971    0.228704     0.650182     0.43283     0.245142   -0.137075     0.497769     0.133171    0.618985    0.119494    0.395462
 -0.0891184   -0.366906      0.614676    0.375785     0.0283342   -0.0116641   -0.0570351  -0.258826   -0.096135    0.562208    1.17374     0.364113   -0.155911    -0.443622    -0.0437504   0.397483   -0.246346    -0.176822     0.381081    0.0757403   0.242205     0.30109      0.272044    0.271899    0.238528    0.159818
 -0.639715    -0.110857     -0.171076    0.0394969    0.0704133    0.466907    -0.0388653   0.0601685  -0.322888   -0.148241    0.623888   -0.201563   -0.235326    -0.382002     0.213866   -0.739421    0.0255403   -0.00573734   0.365486    0.0625281  -0.140641    -0.538793     0.449365   -0.0376486   0.329109    0.294154
  0.713162     0.147095      0.533802   -0.268398    -0.384121     0.199309     0.747213   -0.187716    0.340446    0.0330038  -0.836389   -0.0424956   0.21675      0.219417    -0.223552    0.103453    0.0765395   -0.465263     0.0744075  -0.276641   -0.0923392    0.0808522   -0.62274     0.442839   -0.50178     0.304189
  0.652414     0.08182       0.075869    0.00602986   0.0510946   -0.261284    -0.0561963  -0.0474947  -0.70145     0.183082    0.257458   -0.132032    0.0745395   -0.38631      0.184252   -0.0155935  -0.337736    -0.788276    -0.277209    0.122739    0.00559997  -0.195826    -0.629992   -0.0799775   0.490566   -0.441729
  0.527586     0.293848      0.575912    0.217613     0.227084    -0.62232     -0.378047   -0.298665    0.301228    0.281277   -0.328888    0.138573    0.00995264   0.378949    -0.287322    0.936971   -0.145789    -0.071773    -0.576744   -0.191328    0.506271     0.583483    -0.081192   -0.24789    -0.340701   -0.281959
  0.307979    -0.601015     -0.0152118   0.106076     0.0809354   -0.315784    -0.227804   -0.0333568   0.345642   -0.0595457   0.508393   -0.489965    0.428377     0.411757    -0.496083    0.360647   -0.180686    -0.409286     0.151078    0.306831   -0.393311    -0.163257    -0.0773503  -0.202945    0.0454288   0.422442
 -0.554807     0.200189      0.707075    0.125886     0.0977373   -0.399241     0.768164    0.332076   -0.195661    0.227953   -0.237636   -0.0553124   0.267842    -0.296337     0.176106   -0.418682   -0.226045     0.00362712   0.253888    0.329773    0.136793     0.251778    -0.0208767  -0.0701538  -0.679246    0.578848
  0.00805746  -0.330084     -1.14423     0.459899    -0.0847965   -0.530655    -0.174714    0.696482    0.520174   -0.167814   -0.405328   -0.337773    0.159335     0.293323    -0.869651   -0.358742    0.306819     0.898104     0.493422    0.71286     0.128317     0.0589482   -0.234252    0.810499   -0.0686289  -0.0697994
 -0.748421     0.0202016    -0.168115   -0.457671    -0.00628314  -0.316883     0.0863559  -0.211605    0.349827   -0.304128   -0.196068    0.022072   -1.09948     -0.234044    -0.27073     0.2498      0.0929173    0.237872    -0.180138   -0.626953   -0.116115    -0.0134446    1.03155    -0.319806   -0.364346    0.0773273
  0.598007     0.0774282    -0.0526203   0.0598111   -0.141348     0.177938     0.367998    0.158561   -0.0569549  -0.225101   -0.0258973  -0.147248   -0.133586    -0.0411859   -0.219223    0.189687   -0.28839     -0.452904    -0.225983   -0.198309   -0.0814707    0.332545    -0.6343     -0.169085   -0.020517    0.014735
 -0.583488     0.0237574     0.138492    0.0958206    0.11319     -0.789471    -0.747909   -0.0291906  -0.141492    0.13831    -0.185459    0.407305    0.206291     0.550032     0.157062   -0.0853416   0.82157      0.476273     0.0373483   0.273744   -0.26272     -0.39922      0.767364    0.276194   -0.477276    0.13375
 -0.402158    -0.34581      -0.979077    0.178295     0.292543    -0.543052    -0.894229    0.0755962  -0.109677    0.0314722   0.764516   -0.329963   -0.0880862   -0.259464     0.499144    0.176081    0.180672     0.259659    -0.335484    0.672598    0.343831     0.222886     0.329447   -0.210429    0.830787   -0.281213
  0.342972    -0.11452      -0.663881   -0.737246     0.0976558    0.00951284  -0.214428   -0.468659   -0.052477   -0.210689    0.18654    -0.0573272  -0.410281    -0.0216881    0.100363    0.28269     0.582476     0.0250806   -0.201868   -0.451609    0.245244    -0.25783      0.0418323   0.0418726   0.519891   -0.294533
 -0.179773     0.0351838    -0.265345   -0.160718     0.334903     0.304395     0.286452   -0.201494    0.162569    0.729493   -0.289178    0.225576   -0.0339504   -0.604494     0.921089    0.0609909  -0.00641806  -0.223136     0.38568    -0.368513    0.557919    -0.0485132   -0.0916981   0.0354928   0.0314292  -0.407796
 -0.158872     0.19617       0.0613341   0.21695     -0.0807106    0.0211135    0.0180192  -0.0950481   0.14413    -0.0164683   0.0891321   0.138223    0.176477     0.0705749    0.0134023   0.146144   -0.225814     0.0871015   -0.0201239   0.0760769  -0.205609     0.00045124   0.225       0.107572   -0.145547    0.136311
  0.0255985    0.0144336    -0.0769099  -0.0515374    0.116317    -0.0545868   -0.02338     0.0995917  -0.0479163   0.0403835  -0.0771338  -0.04638    -0.0600863    0.0319532    0.108172   -0.0400035   0.0559206   -0.0582922    0.0610908  -0.016769    0.0982341    0.0728457   -0.0562608  -0.252598    0.0162224  -0.0406036
  0.314816    -0.0104928    -0.193565   -0.108337     0.0409954   -0.235957     0.0588307   0.201351    0.188692    0.202042    0.131103    0.22691     0.569346    -0.237903     0.433947   -0.0741018   0.223565     0.323871     0.273306    0.545427    0.255386     0.122353    -0.2768      0.226585    0.507293   -0.0861202
 -0.186232     0.413695     -0.659974   -0.111528     0.0702841   -0.0323426    0.215626    0.310531   -0.0834492  -0.703968   -0.777517   -0.448232    0.0456883    0.359224     0.383239   -0.37776     0.0192556    0.0843585   -0.600866    0.110115   -0.26398      0.0157205   -0.357826   -0.429315   -0.316191   -0.0383664
  0.0294835    0.120636     -0.485016    0.276745    -0.50789      0.335476    -0.372772    0.644293   -0.141441   -0.170153   -0.575021   -0.48481     0.139467     0.232859     0.0447526  -0.132348    0.402345    -0.483878     0.367185    0.373424   -0.4814      -0.483991    -0.108497   -0.518488    0.465612    0.192507
  0.150977    -0.119114      0.22484    -0.113189     0.0966435   -0.0124289    0.108699   -0.392051    0.446722   -0.641249   -0.146793    0.35103     0.430417    -0.370058     0.108594   -0.108279   -0.590197     0.432448    -0.427086    0.147099   -0.453245    -0.363799     0.209395    0.422042   -0.238732   -0.414481
  0.043427    -0.126763      0.0218952  -0.211526     0.138946    -0.068892    -0.0923261  -0.0720017  -0.152496   -0.0148389  -0.110906   -0.213282   -0.199555    -0.100294     0.0230965  -0.133109    0.100942    -0.0981246   -0.0572129  -0.149045    0.147457    -0.132745    -0.0662108  -0.203856    0.0958617  -0.0420708
 -0.0140828    0.155809     -0.104862   -0.614828     0.0767244    0.133115     0.146739    0.502459   -0.447004   -0.061297   -0.617897    0.672344   -0.696138     0.0771776    0.234884   -0.400308    0.679253    -0.271724     0.093869    0.225286    0.859206    -0.366409    -0.791777    0.22772    -0.331002    0.0600221
 -0.316517     0.130738      0.669762    0.0191267    0.169627    -0.0642958   -0.0524077   0.0462064  -0.148397    0.389883   -0.160831    0.382592    0.201301    -0.495611     0.213402   -0.735046    0.0481221    0.880076    -0.254656   -0.141977    0.305824     0.158124     0.296424   -0.0764249   0.152048   -0.205028[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409958
[ Info: iteration 2, average log likelihood -1.409945
[ Info: iteration 3, average log likelihood -1.409932
[ Info: iteration 4, average log likelihood -1.409920
[ Info: iteration 5, average log likelihood -1.409909
[ Info: iteration 6, average log likelihood -1.409898
[ Info: iteration 7, average log likelihood -1.409888
[ Info: iteration 8, average log likelihood -1.409878
[ Info: iteration 9, average log likelihood -1.409868
[ Info: iteration 10, average log likelihood -1.409859
┌ Info: EM with 100000 data points 10 iterations avll -1.409859
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
