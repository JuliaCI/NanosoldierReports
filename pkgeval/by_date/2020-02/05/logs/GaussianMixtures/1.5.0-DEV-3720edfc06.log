Julia Version 1.5.0-DEV.230
Commit 3720edfc06 (2020-02-03 20:02 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed GaussianMixtures ─── v0.3.0
  Installed Missings ─────────── v0.4.3
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed CMakeWrapper ─────── v0.2.3
  Installed JLD ──────────────── v0.9.2
  Installed NearestNeighbors ─── v0.4.4
  Installed SpecialFunctions ─── v0.9.0
  Installed BinDeps ──────────── v1.0.0
  Installed Arpack_jll ───────── v3.5.0+2
  Installed Distances ────────── v0.8.2
  Installed Rmath ────────────── v0.6.0
  Installed StatsFuns ────────── v0.9.3
  Installed StatsBase ────────── v0.32.0
  Installed BinaryProvider ───── v0.5.8
  Installed Blosc ────────────── v0.5.1
  Installed LegacyStrings ────── v0.4.1
  Installed FileIO ───────────── v1.2.1
  Installed OrderedCollections ─ v1.1.0
  Installed HDF5 ─────────────── v0.12.5
  Installed DataStructures ───── v0.17.9
  Installed Clustering ───────── v0.13.3
  Installed PDMats ───────────── v0.9.11
  Installed StaticArrays ─────── v0.12.1
  Installed DataAPI ──────────── v1.1.0
  Installed Compat ───────────── v2.2.0
  Installed QuadGK ───────────── v2.3.1
  Installed Parameters ───────── v0.12.0
  Installed URIParser ────────── v0.4.0
  Installed SortingAlgorithms ── v0.3.1
  Installed CMake ────────────── v1.1.2
  Installed ScikitLearnBase ──── v0.5.0
  Installed FillArrays ───────── v0.8.4
  Installed Arpack ───────────── v0.4.0
  Installed Distributions ────── v0.22.4
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                         #                                                                          2.1%#####                                                                      7.0%#########                                                                 13.3%###############                                                           21.6%######################                                                    31.2%###############################                                           43.8%###################################                                       49.9%#################################################                         68.6%###############################################################           88.0%######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_IcTw06/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -759116.9869434416, [46220.67924828908, 53779.32075171092], [-10071.605126770126 29014.407847882336 -1652.2742301701714; 10477.55137342785 -29239.029712352392 1885.5932529332044], [[25203.244589385387 2862.8833481177603 -8503.222667572041; 2862.8833481177603 44530.990465349445 -391.3146840842155; -8503.222667572041 -391.3146840842155 42806.63673857105], [74981.57753428066 -2963.1181133175714 8521.008127622083; -2963.1181133175714 56168.95382682141 300.7978246867818; 8521.008127622083 300.7978246867819 57163.95720304619]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.541211e+03
      1       1.040146e+03      -5.010655e+02 |        6
      2       9.785883e+02      -6.155725e+01 |        4
      3       9.070310e+02      -7.155723e+01 |        5
      4       8.553578e+02      -5.167328e+01 |        2
      5       8.546732e+02      -6.846165e-01 |        0
      6       8.546732e+02       0.000000e+00 |        0
K-means converged with 6 iterations (objv = 854.6731531549763)
┌ Info: K-means with 272 data points using 6 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.070315
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.848673
[ Info: iteration 2, lowerbound -3.724578
[ Info: iteration 3, lowerbound -3.583946
[ Info: iteration 4, lowerbound -3.414096
[ Info: iteration 5, lowerbound -3.233658
[ Info: iteration 6, lowerbound -3.065731
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.920474
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.781495
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.655684
[ Info: iteration 10, lowerbound -2.558543
[ Info: dropping number of Gaussions to 4
[ Info: iteration 11, lowerbound -2.482346
[ Info: iteration 12, lowerbound -2.431027
[ Info: dropping number of Gaussions to 3
[ Info: iteration 13, lowerbound -2.390943
[ Info: iteration 14, lowerbound -2.355510
[ Info: iteration 15, lowerbound -2.328880
[ Info: iteration 16, lowerbound -2.311573
[ Info: iteration 17, lowerbound -2.307757
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.302918
[ Info: iteration 19, lowerbound -2.299259
[ Info: iteration 20, lowerbound -2.299256
[ Info: iteration 21, lowerbound -2.299254
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: 46 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Thu Feb  6 04:49:53 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Thu Feb  6 04:50:01 2020: K-means with 272 data points using 6 iterations
11.3 data points per parameter
, Thu Feb  6 04:50:04 2020: EM with 272 data points 0 iterations avll -2.070315
5.8 data points per parameter
, Thu Feb  6 04:50:06 2020: GMM converted to Variational GMM
, Thu Feb  6 04:50:14 2020: iteration 1, lowerbound -3.848673
, Thu Feb  6 04:50:14 2020: iteration 2, lowerbound -3.724578
, Thu Feb  6 04:50:14 2020: iteration 3, lowerbound -3.583946
, Thu Feb  6 04:50:14 2020: iteration 4, lowerbound -3.414096
, Thu Feb  6 04:50:14 2020: iteration 5, lowerbound -3.233658
, Thu Feb  6 04:50:14 2020: iteration 6, lowerbound -3.065731
, Thu Feb  6 04:50:14 2020: dropping number of Gaussions to 7
, Thu Feb  6 04:50:14 2020: iteration 7, lowerbound -2.920474
, Thu Feb  6 04:50:14 2020: dropping number of Gaussions to 6
, Thu Feb  6 04:50:14 2020: iteration 8, lowerbound -2.781495
, Thu Feb  6 04:50:14 2020: dropping number of Gaussions to 5
, Thu Feb  6 04:50:14 2020: iteration 9, lowerbound -2.655684
, Thu Feb  6 04:50:14 2020: iteration 10, lowerbound -2.558543
, Thu Feb  6 04:50:14 2020: dropping number of Gaussions to 4
, Thu Feb  6 04:50:14 2020: iteration 11, lowerbound -2.482346
, Thu Feb  6 04:50:14 2020: iteration 12, lowerbound -2.431027
, Thu Feb  6 04:50:14 2020: dropping number of Gaussions to 3
, Thu Feb  6 04:50:14 2020: iteration 13, lowerbound -2.390943
, Thu Feb  6 04:50:14 2020: iteration 14, lowerbound -2.355510
, Thu Feb  6 04:50:14 2020: iteration 15, lowerbound -2.328880
, Thu Feb  6 04:50:14 2020: iteration 16, lowerbound -2.311573
, Thu Feb  6 04:50:14 2020: iteration 17, lowerbound -2.307757
, Thu Feb  6 04:50:14 2020: dropping number of Gaussions to 2
, Thu Feb  6 04:50:14 2020: iteration 18, lowerbound -2.302918
, Thu Feb  6 04:50:14 2020: iteration 19, lowerbound -2.299259
, Thu Feb  6 04:50:14 2020: iteration 20, lowerbound -2.299256
, Thu Feb  6 04:50:14 2020: iteration 21, lowerbound -2.299254
, Thu Feb  6 04:50:14 2020: iteration 22, lowerbound -2.299254
, Thu Feb  6 04:50:14 2020: iteration 23, lowerbound -2.299253
, Thu Feb  6 04:50:14 2020: iteration 24, lowerbound -2.299253
, Thu Feb  6 04:50:14 2020: iteration 25, lowerbound -2.299253
, Thu Feb  6 04:50:14 2020: iteration 26, lowerbound -2.299253
, Thu Feb  6 04:50:14 2020: iteration 27, lowerbound -2.299253
, Thu Feb  6 04:50:14 2020: iteration 28, lowerbound -2.299253
, Thu Feb  6 04:50:14 2020: iteration 29, lowerbound -2.299253
, Thu Feb  6 04:50:14 2020: iteration 30, lowerbound -2.299253
, Thu Feb  6 04:50:14 2020: iteration 31, lowerbound -2.299253
, Thu Feb  6 04:50:14 2020: iteration 32, lowerbound -2.299253
, Thu Feb  6 04:50:14 2020: iteration 33, lowerbound -2.299253
, Thu Feb  6 04:50:14 2020: iteration 34, lowerbound -2.299253
, Thu Feb  6 04:50:14 2020: iteration 35, lowerbound -2.299253
, Thu Feb  6 04:50:14 2020: iteration 36, lowerbound -2.299253
, Thu Feb  6 04:50:14 2020: iteration 37, lowerbound -2.299253
, Thu Feb  6 04:50:14 2020: iteration 38, lowerbound -2.299253
, Thu Feb  6 04:50:14 2020: iteration 39, lowerbound -2.299253
, Thu Feb  6 04:50:14 2020: iteration 40, lowerbound -2.299253
, Thu Feb  6 04:50:14 2020: iteration 41, lowerbound -2.299253
, Thu Feb  6 04:50:14 2020: iteration 42, lowerbound -2.299253
, Thu Feb  6 04:50:14 2020: iteration 43, lowerbound -2.299253
, Thu Feb  6 04:50:14 2020: iteration 44, lowerbound -2.299253
, Thu Feb  6 04:50:14 2020: iteration 45, lowerbound -2.299253
, Thu Feb  6 04:50:14 2020: 46 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601615, 95.95490777398382]
β = [178.04509222601615, 95.95490777398382]
m = [4.250300733269892 79.28686694436159; 2.000229257775351 53.851987172461186]
ν = [180.04509222601615, 97.95490777398382]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.184041555474843 -0.007644049042327646; 0.0 0.00858170516633329], [0.3758763611948755 -0.008953123827346686; 0.0 0.01274866477740952]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.0000000001
avll from stats: -0.9935441246308314
avll from llpg:  -0.9935441246308319
avll direct:     -0.9935441246308319
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9811641716305084
avll from llpg:  -0.9811641716305084
avll direct:     -0.9811641716305084
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
  0.0331122   -0.120013     0.0477868   -0.0151162   -0.037681     0.119559    -0.110011    -0.0464852   -0.0132892    -0.059793   -0.119486     0.0602414  -0.0181403   -0.0750501   -0.1063       0.03881     -0.0613556   -0.105638    -0.00268926   -0.0129305   -0.111093     0.0962584     0.185349    -0.0124842    -0.00899733   0.296421
 -0.147615     0.0834018   -0.0180871   -0.142349     0.0320899    0.0277616    0.0518309    0.07141      0.278429     -0.118216   -0.0358366    0.098778   -0.00914716  -0.063561     0.00221071   0.0492848   -0.0581628    0.0958814    0.254429     -0.124445     0.091224    -0.0540026     0.0189074    0.0425753     0.175207     0.22593
 -0.218942    -0.0301476   -0.205702     0.0716799    0.0503291   -0.0997628    0.0277207   -0.10386      0.0560572    -0.0419994  -0.0816404   -0.0422057   0.0817391   -0.00964963  -0.219881    -0.0347014   -0.0660313   -0.027359     0.0348937    -0.0135519   -0.0807118   -0.178564     -0.0876445    0.0788753     0.133057     0.159662
 -0.0508331    0.0110315    0.0716156   -0.0953492    0.00449354  -0.0975743   -0.103666     0.115264     0.0628325     0.0720293  -0.0207152    0.0243743  -0.0646034    0.148763    -0.0206024   -0.0334256   -0.153509    -0.0121367   -0.107487      0.12764     -0.12799     -0.091109      0.00468795   0.119506     -0.024222    -0.177069
 -0.111111     0.154917    -0.0661214   -0.0663778   -0.0020835    0.102514     0.209254     0.102606    -0.0554548    -0.131124    0.164533     0.0727978   0.00108203   0.0209927    0.0189194    0.0219845   -0.00534546  -0.12808     -0.00076544    0.0649639   -0.0853841    0.000124058   0.0537728   -0.163272     -0.0536673   -0.0841369
 -0.0051922   -0.167711     0.0693872   -0.195003    -0.13341     -0.0250828   -0.169671    -0.0594751   -0.0873797     0.0390697  -0.0665719   -0.0222554   0.105836     0.026031    -0.0816972   -0.0156486    0.097051    -0.00552488   0.0171457     0.13932      0.229088     0.00181548    0.0129291    0.0858498    -0.0666971   -0.0118301
  0.219946     0.00869534  -0.0936243    0.0782645    0.0534102   -0.0223291   -0.0571993    0.103976     0.00999271    0.049565   -0.0409741   -0.214682   -0.066035    -0.0631444   -0.110657     0.164715     0.0733994   -0.0369469   -0.00822531    0.130394     0.0945548    0.158135     -0.0847451   -0.221481      0.0561076   -0.0887174
 -0.0777479   -0.0869717   -0.0142157    0.0312964   -0.192946     0.0784804    0.0819099   -0.0496696   -0.00080504   -0.13351     0.056689    -0.114742    0.243021     0.10216      0.0485679    0.143369    -0.258173    -0.00638723   0.0689428     0.126193     0.11064      0.0416295     0.118132     0.0299213    -0.123281     0.0514712
  0.154308     0.158514     0.0118844   -0.0477754    0.0466983    0.0255277   -0.0345934   -0.0159902    0.207422      0.0585406  -0.0135114    0.118014   -0.0753025   -0.0119645   -0.00624134   0.0400673   -0.0117226   -0.103546    -0.0665492    -0.00837229  -0.194232    -0.0870479    -0.074291    -0.0841068     0.0671083    0.0771135
 -0.137853     0.0293414    0.109636    -0.00512839   0.0492228   -0.0475923    0.074892    -0.0415974   -0.130031      0.0970543   0.060869     0.0137968   0.103131     0.0256537   -0.00353147  -0.0700115   -0.0781015   -0.0247747    0.119234     -0.0221225   -0.106845    -0.0923564     0.0442813   -0.0376237    -0.0504013   -0.0473342
  0.0679581    0.0188694   -0.0632149   -0.0109404   -0.0397543   -0.101788    -0.053536     0.0484543   -0.0474674     0.0166484   0.0682785    0.063556    0.0470272    0.00329624  -0.141983     0.159995    -0.104032    -0.0137345    0.030399      0.0247749    0.0912179    0.0729859     0.0224371    0.000675594  -0.133621     0.0286732
 -0.094595     0.0498918   -0.165496     0.00173829   0.00406441  -0.14436      0.141        0.0889658   -0.165396     -0.0385453  -0.0874682   -0.0142557   0.0783868    0.109016     0.0651692    0.0479239    0.0580813   -0.00146256   0.000125043   0.0136679   -0.0561602    0.0343359     0.0824887    0.114365      0.178653     0.117927
 -0.210977     0.0552162   -0.123674     0.0533228    0.0769268   -0.019984     0.0724714    0.120246     0.167087     -0.200349    0.0376776    0.06821    -0.0425853    0.125252    -0.134532    -0.00448671   0.00577638  -0.241508     0.0409161     0.0452721    0.122102    -0.129202      0.0259265   -0.0814504     0.109375    -0.079146
  0.100522     0.0986498    0.00185043   0.11291      0.163018    -0.0233187    0.00536861   0.363337    -0.0761651     0.0200828  -0.00297196  -0.0225685   0.013508    -0.017327     0.0256216   -0.0396099   -0.105862     0.0418344   -0.0680909    -0.171906    -0.0085654    0.013866      0.00855025  -0.22519       0.124373     0.0937744
  0.0799046   -0.0717642    0.0544868   -0.0501034   -0.0802644    0.0330463    0.0501502   -0.0976458   -0.0721062     0.0800485  -0.0319948   -0.0834565   0.00781675   0.125743    -0.0505202   -0.0295595    0.041184    -0.095954     0.144488      0.0207546    0.0356273    0.0231971    -0.133918    -0.00970837   -0.1019      -0.166641
  0.149801    -0.0741016   -0.169251     0.177429     0.0204884   -0.0835342   -0.0515379    0.0881335   -0.0383998     0.0641534   0.0314199    0.0311813  -0.113052    -0.0333001    9.34889e-5  -0.225447    -0.13718      0.048672     0.243867      0.0250085    0.0548342   -0.000778137  -0.0139742    0.10009      -0.0791386   -0.0557154
  0.0911233   -0.036591     0.215785    -0.0169996    0.0168152    0.139733     0.104765    -0.0230415   -0.0402239    -0.0776897   0.0608284    0.125873   -0.00580029  -0.164202    -0.0288111   -0.018982     0.12095      0.200612     0.129348      0.120589    -0.0194746   -0.00152089    0.0444614    0.103421      0.220211     0.0905654
  0.0672982    0.133383     0.075498    -0.213292     0.0295293   -0.0210289    0.0281642   -0.0100448   -0.116721      0.0762954  -0.123015     0.14082    -0.109063    -0.015312     0.0161431   -0.141452     0.0471657   -0.199373     0.117604     -0.019198     0.107143     0.0485237     0.0557164   -0.0291849    -0.0808926   -0.000828526
  0.00963428   0.0528056   -0.072758    -0.0217773    0.142793     0.0412398   -0.100355    -0.0674159    0.0553605    -0.127791    0.0229667   -0.0798245   0.187577     0.0664584    0.0673904    0.158827     0.0888413   -0.0274693    0.0305794    -0.132306    -0.131401     0.00372004   -0.0116926    0.0549552     0.114719    -0.0131561
  0.02714      0.148158    -0.263385    -0.0537893    0.0623808   -0.026856     0.242531    -0.0741113   -0.0416784     0.0345749   0.109313    -0.0167408  -0.0498615   -0.0210756   -0.0507846   -0.0218822   -0.0290508    0.0889073   -0.0523691    -0.0575436    0.108625    -0.205736     -0.0609329    0.154979     -0.0161927   -0.107752
  0.0346891    0.0397663   -0.0564625    0.0771226   -0.135793     0.173804    -0.0198543   -0.0157712    0.077322     -0.0146924   0.0138695   -0.196855   -0.031267    -0.087727     0.0246059    0.045809    -0.0934076    0.202109     0.00499732   -0.00211344  -0.0465333    0.0405287    -0.11289      0.0442714    -0.0634332    0.00217124
 -0.0556354    0.0137338    0.0740379   -0.00481653  -0.114064    -0.213988     0.0134058    0.0774107    0.000371632  -0.0134806  -0.0163044   -0.0674219  -0.0297648    0.18586     -0.0287382   -0.0542119   -0.0986719    0.0430095    0.0961444    -0.138982     0.0702204   -0.00732515    0.0117598   -0.108733     -0.163293     0.0193835
  0.145885     0.0388114   -0.0229986   -0.148517     0.17786     -0.0823324    0.012119     0.0986003   -0.0170839    -0.0305309  -0.0175154   -0.0772949  -0.113114     0.12702      0.109429    -0.0935217    0.0854387    0.0436274    0.156754     -0.00628251   0.00845411  -0.0134764    -0.0469288    0.14685      -0.232606     0.0521738
 -0.0246388   -0.17529      0.0288228    0.0100963   -0.0477018    0.127196     0.123133     0.136273    -0.038516      0.103952   -0.124737    -0.0797281  -0.0558846    0.0526129   -0.0579164    0.0141069    0.0543828    0.0131022    0.0912391    -0.0360588   -0.249556    -0.100196      0.0392588   -0.0332411     0.0368812   -0.00453339
  0.129397     0.157985    -0.138206    -0.0335534   -0.057338    -0.0171939    0.184809    -0.00291141   0.0357727    -0.0268923  -0.0484554    0.20086     0.153863    -0.0591055   -0.121144     0.0486449   -0.106768     0.0955239   -0.139872     -0.0196489   -0.133651     0.0739308     0.100917     0.0556511     0.0121686    0.0687427
 -0.0608726    0.0716849   -0.00535963  -0.230298     0.0479499    0.217104     0.161643     0.145937    -0.000442723   0.0231083   0.0126328    0.0185648   0.258694     0.00803056  -0.0264321   -0.107709     0.0474547    0.0944554   -0.00310254   -0.0305198   -0.258363    -0.114198      0.0248958   -0.0797153     0.0196712   -0.0851536
 -0.211411    -0.089296    -0.226992    -0.0511034   -0.0199908   -0.00673053  -0.0383375   -0.0313913    0.0423942     0.139449    0.0587865   -0.0968157  -0.0755654    0.0056191   -0.193508    -0.0711489   -0.0988511   -0.0566641   -0.0220455     0.021313     0.00487853  -0.0471684     0.144126    -0.00121117    0.0523425   -0.108211
 -0.208041    -0.157768    -0.0350914   -0.121532    -0.0151493    0.210455    -0.00066563  -0.0159737   -0.0665619    -0.162983    0.0167353   -0.176182   -0.0330478    0.166078    -0.0454694    0.0587444   -0.24885     -0.0971317   -0.151465      0.058403    -0.0789954   -0.0896719    -0.155915    -0.149511      0.106172     0.231276
  0.00527992  -0.0557726    0.00633113   0.0544776   -0.275734     0.050896     0.0338891    0.0553109    0.0540291     0.0609528  -0.0597971    0.0461695   0.00292699   0.213718     0.0159964    0.268871     0.0727666    0.130628    -0.0370428     0.102729     0.103819    -0.0139897    -0.157978     0.0127501    -0.0331577    0.0041212
 -0.0263059   -0.178314     0.177809    -0.150035    -0.0850019    0.0106376   -0.053059     0.00733942   0.0533474     0.191292   -0.124789     0.110327   -0.0723091   -0.0940071   -0.0960698   -0.0896077    0.0407943   -0.00372067   0.0153348    -0.0136348   -0.119546    -0.109707     -0.024315     0.14667       0.303834    -0.0248661
 -0.0390561    0.0334279    0.0859455   -0.0356209   -0.00540012  -0.0359877   -0.0120429    0.052715     0.027422      0.0558475   0.0621468    0.0415652  -0.0983758    0.0221039   -0.0339034   -0.0934902    0.0554296   -0.0422544    0.100808     -0.0487918   -0.063717    -0.0472663    -0.0613019   -0.0118492     0.031736     0.049308
  0.203421    -0.0892556   -0.114735    -0.00810307   0.0916474    0.0940545    0.0390823    0.0932642   -0.0129626    -0.148747   -0.00955444  -0.0351008  -0.12229     -0.0543355   -0.0921       0.160609    -0.0444856    0.0527016    0.1036        0.0397915    0.0557129    0.0183771    -0.0313107    0.206893     -0.01334      0.0892088kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3892915065919191
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.389356
[ Info: iteration 2, average log likelihood -1.389281
[ Info: iteration 3, average log likelihood -1.388599
[ Info: iteration 4, average log likelihood -1.380881
[ Info: iteration 5, average log likelihood -1.362261
[ Info: iteration 6, average log likelihood -1.354575
[ Info: iteration 7, average log likelihood -1.352885
[ Info: iteration 8, average log likelihood -1.352179
[ Info: iteration 9, average log likelihood -1.351722
[ Info: iteration 10, average log likelihood -1.351325
[ Info: iteration 11, average log likelihood -1.350902
[ Info: iteration 12, average log likelihood -1.350363
[ Info: iteration 13, average log likelihood -1.349686
[ Info: iteration 14, average log likelihood -1.349192
[ Info: iteration 15, average log likelihood -1.348941
[ Info: iteration 16, average log likelihood -1.348803
[ Info: iteration 17, average log likelihood -1.348707
[ Info: iteration 18, average log likelihood -1.348630
[ Info: iteration 19, average log likelihood -1.348560
[ Info: iteration 20, average log likelihood -1.348490
[ Info: iteration 21, average log likelihood -1.348418
[ Info: iteration 22, average log likelihood -1.348341
[ Info: iteration 23, average log likelihood -1.348261
[ Info: iteration 24, average log likelihood -1.348182
[ Info: iteration 25, average log likelihood -1.348108
[ Info: iteration 26, average log likelihood -1.348042
[ Info: iteration 27, average log likelihood -1.347983
[ Info: iteration 28, average log likelihood -1.347930
[ Info: iteration 29, average log likelihood -1.347881
[ Info: iteration 30, average log likelihood -1.347834
[ Info: iteration 31, average log likelihood -1.347786
[ Info: iteration 32, average log likelihood -1.347736
[ Info: iteration 33, average log likelihood -1.347679
[ Info: iteration 34, average log likelihood -1.347613
[ Info: iteration 35, average log likelihood -1.347536
[ Info: iteration 36, average log likelihood -1.347452
[ Info: iteration 37, average log likelihood -1.347351
[ Info: iteration 38, average log likelihood -1.347202
[ Info: iteration 39, average log likelihood -1.346967
[ Info: iteration 40, average log likelihood -1.346615
[ Info: iteration 41, average log likelihood -1.346129
[ Info: iteration 42, average log likelihood -1.345525
[ Info: iteration 43, average log likelihood -1.344938
[ Info: iteration 44, average log likelihood -1.344418
[ Info: iteration 45, average log likelihood -1.343968
[ Info: iteration 46, average log likelihood -1.343541
[ Info: iteration 47, average log likelihood -1.343117
[ Info: iteration 48, average log likelihood -1.342783
[ Info: iteration 49, average log likelihood -1.342548
[ Info: iteration 50, average log likelihood -1.342382
┌ Info: EM with 100000 data points 50 iterations avll -1.342382
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3893560311554785
│     -1.3892813009335
│      ⋮
└     -1.3423823672936863
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.342356
[ Info: iteration 2, average log likelihood -1.342154
[ Info: iteration 3, average log likelihood -1.341544
[ Info: iteration 4, average log likelihood -1.336634
[ Info: iteration 5, average log likelihood -1.322447
[ Info: iteration 6, average log likelihood -1.310973
[ Info: iteration 7, average log likelihood -1.306400
[ Info: iteration 8, average log likelihood -1.303913
[ Info: iteration 9, average log likelihood -1.302373
[ Info: iteration 10, average log likelihood -1.301499
[ Info: iteration 11, average log likelihood -1.300994
[ Info: iteration 12, average log likelihood -1.300692
[ Info: iteration 13, average log likelihood -1.300509
[ Info: iteration 14, average log likelihood -1.300397
[ Info: iteration 15, average log likelihood -1.300325
[ Info: iteration 16, average log likelihood -1.300274
[ Info: iteration 17, average log likelihood -1.300234
[ Info: iteration 18, average log likelihood -1.300195
[ Info: iteration 19, average log likelihood -1.300153
[ Info: iteration 20, average log likelihood -1.300104
[ Info: iteration 21, average log likelihood -1.300045
[ Info: iteration 22, average log likelihood -1.299972
[ Info: iteration 23, average log likelihood -1.299880
[ Info: iteration 24, average log likelihood -1.299771
[ Info: iteration 25, average log likelihood -1.299655
[ Info: iteration 26, average log likelihood -1.299538
[ Info: iteration 27, average log likelihood -1.299422
[ Info: iteration 28, average log likelihood -1.299312
[ Info: iteration 29, average log likelihood -1.299210
[ Info: iteration 30, average log likelihood -1.299118
[ Info: iteration 31, average log likelihood -1.299036
[ Info: iteration 32, average log likelihood -1.298963
[ Info: iteration 33, average log likelihood -1.298900
[ Info: iteration 34, average log likelihood -1.298844
[ Info: iteration 35, average log likelihood -1.298794
[ Info: iteration 36, average log likelihood -1.298748
[ Info: iteration 37, average log likelihood -1.298705
[ Info: iteration 38, average log likelihood -1.298665
[ Info: iteration 39, average log likelihood -1.298626
[ Info: iteration 40, average log likelihood -1.298589
[ Info: iteration 41, average log likelihood -1.298554
[ Info: iteration 42, average log likelihood -1.298522
[ Info: iteration 43, average log likelihood -1.298492
[ Info: iteration 44, average log likelihood -1.298466
[ Info: iteration 45, average log likelihood -1.298442
[ Info: iteration 46, average log likelihood -1.298422
[ Info: iteration 47, average log likelihood -1.298404
[ Info: iteration 48, average log likelihood -1.298387
[ Info: iteration 49, average log likelihood -1.298373
[ Info: iteration 50, average log likelihood -1.298359
┌ Info: EM with 100000 data points 50 iterations avll -1.298359
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3423555556734745
│     -1.3421537765230744
│      ⋮
└     -1.2983587706652138
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.298479
[ Info: iteration 2, average log likelihood -1.298320
[ Info: iteration 3, average log likelihood -1.297698
[ Info: iteration 4, average log likelihood -1.291383
[ Info: iteration 5, average log likelihood -1.273651
[ Info: iteration 6, average log likelihood -1.262206
[ Info: iteration 7, average log likelihood -1.258309
[ Info: iteration 8, average log likelihood -1.256197
[ Info: iteration 9, average log likelihood -1.254515
[ Info: iteration 10, average log likelihood -1.253176
[ Info: iteration 11, average log likelihood -1.251982
[ Info: iteration 12, average log likelihood -1.250740
[ Info: iteration 13, average log likelihood -1.249557
[ Info: iteration 14, average log likelihood -1.248571
[ Info: iteration 15, average log likelihood -1.247729
[ Info: iteration 16, average log likelihood -1.246833
[ Info: iteration 17, average log likelihood -1.245788
[ Info: iteration 18, average log likelihood -1.244718
[ Info: iteration 19, average log likelihood -1.243823
[ Info: iteration 20, average log likelihood -1.243260
[ Info: iteration 21, average log likelihood -1.242962
[ Info: iteration 22, average log likelihood -1.242811
[ Info: iteration 23, average log likelihood -1.242727
[ Info: iteration 24, average log likelihood -1.242676
[ Info: iteration 25, average log likelihood -1.242643
[ Info: iteration 26, average log likelihood -1.242621
[ Info: iteration 27, average log likelihood -1.242607
[ Info: iteration 28, average log likelihood -1.242597
[ Info: iteration 29, average log likelihood -1.242591
[ Info: iteration 30, average log likelihood -1.242586
[ Info: iteration 31, average log likelihood -1.242584
[ Info: iteration 32, average log likelihood -1.242581
[ Info: iteration 33, average log likelihood -1.242580
[ Info: iteration 34, average log likelihood -1.242579
[ Info: iteration 35, average log likelihood -1.242578
[ Info: iteration 36, average log likelihood -1.242577
[ Info: iteration 37, average log likelihood -1.242577
[ Info: iteration 38, average log likelihood -1.242576
[ Info: iteration 39, average log likelihood -1.242576
[ Info: iteration 40, average log likelihood -1.242576
[ Info: iteration 41, average log likelihood -1.242575
[ Info: iteration 42, average log likelihood -1.242575
[ Info: iteration 43, average log likelihood -1.242575
[ Info: iteration 44, average log likelihood -1.242575
[ Info: iteration 45, average log likelihood -1.242575
[ Info: iteration 46, average log likelihood -1.242574
[ Info: iteration 47, average log likelihood -1.242574
[ Info: iteration 48, average log likelihood -1.242574
[ Info: iteration 49, average log likelihood -1.242574
[ Info: iteration 50, average log likelihood -1.242574
┌ Info: EM with 100000 data points 50 iterations avll -1.242574
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2984793652906828
│     -1.2983200527861385
│      ⋮
└     -1.2425737059016346
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.242761
[ Info: iteration 2, average log likelihood -1.242541
[ Info: iteration 3, average log likelihood -1.241496
[ Info: iteration 4, average log likelihood -1.231174
[ Info: iteration 5, average log likelihood -1.204960
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.172514
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.159538
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.151074
[ Info: iteration 9, average log likelihood -1.158990
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.145679
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.147889
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.145115
[ Info: iteration 13, average log likelihood -1.154654
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.142375
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.144137
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.140683
[ Info: iteration 17, average log likelihood -1.150348
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.138893
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.141700
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.139514
[ Info: iteration 21, average log likelihood -1.150059
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.138508
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.141156
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.138711
[ Info: iteration 25, average log likelihood -1.149298
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.137356
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.139762
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.137107
[ Info: iteration 29, average log likelihood -1.148137
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.136304
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.138983
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.136487
[ Info: iteration 33, average log likelihood -1.147794
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.135975
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.138671
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.136246
[ Info: iteration 37, average log likelihood -1.147663
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.135847
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.138556
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.136168
[ Info: iteration 41, average log likelihood -1.147633
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.135811
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.138520
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.136141
[ Info: iteration 45, average log likelihood -1.147629
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.135800
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.138506
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.136130
[ Info: iteration 49, average log likelihood -1.147629
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.135795
┌ Info: EM with 100000 data points 50 iterations avll -1.135795
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2427606162022953
│     -1.242540850327001
│      ⋮
└     -1.1357948481000837
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.138754
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     13
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.130450
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.137324
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     13
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.114837
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.082205
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     12
│     13
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.057579
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.073752
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     13
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.043399
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.052847
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│     13
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.055741
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.055484
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     12
│     13
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.043214
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.065626
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     13
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.038468
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.049355
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│     13
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.053112
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.054290
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     12
│     13
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.042853
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.065465
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     13
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.038314
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.049293
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│     13
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.053081
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.054225
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     12
│     13
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.042783
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.065449
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     13
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.038400
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.049570
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│     13
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.053277
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.054107
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     12
│     13
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.042564
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.065171
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     13
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.037519
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.046434
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     13
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.047004
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     11
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.038122
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     12
│     13
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.039609
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.058981
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     13
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.030939
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.042572
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     13
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.046550
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     13
│     14
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.038605
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     12
│     13
│     14
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.034145
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     14
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.052663
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     13
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.031395
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.040879
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     13
│     14
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.045573
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     13
│     14
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.038229
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     12
│     13
│     14
│     17
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.033864
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.053257
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     13
│     14
│     17
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.030861
┌ Info: EM with 100000 data points 50 iterations avll -1.030861
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1387540136816334
│     -1.1304499923347446
│      ⋮
└     -1.0308609749976496
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3892915065919191
│     -1.3893560311554785
│     -1.3892813009335
│     -1.3885992827159266
│      ⋮
│     -1.0338635511071421
│     -1.053256855919543
└     -1.0308609749976496
32×26 Array{Float64,2}:
 -0.136074    -0.0720008    0.0255921   -0.0550985    -0.0652768   -0.0133007   0.00464828   0.0400288   -0.0734941   -0.0915378    -0.0102422   -0.117706    -0.0339224    0.16466      -0.0140301   -0.000256594  -0.138759   -0.038422   -0.0186337    -0.039018     0.0223687   -0.0541782   -0.0720989   -0.125021    -0.0418006    0.118664
  0.0297801   -0.129703     0.062343    -0.00427626   -0.0362881    0.120617   -0.111922    -0.0310547   -0.0133293   -0.0593389    -0.0986051    0.049189    -0.0143719   -0.0468915    -0.102386     0.0339902    -0.0360081  -0.090761   -0.00157078   -0.0220021   -0.109812     0.096366     0.185237    -5.20608e-5   0.00104303   0.295995
  0.00525076  -0.0578443   -0.00215231   0.0552698    -0.302737     0.0133996   0.0403682   -0.0102634    0.0448681    0.10077       0.0736438    0.034692    -0.0245947    0.233516      0.0303627   -0.185217      0.0533525   0.121225   -0.0227686     0.113189     0.129734     0.0372668   -0.169436     0.0236021   -0.0812834   -0.0175705
 -0.104166    -0.0594396    0.00694103   0.0517801    -0.288531     0.0242206   0.0286311    0.1207       0.0530854    0.0187544    -0.177727     0.0827135    0.0482783    0.161897      0.0179471    0.757256      0.0937966   0.128048   -0.0504781     0.0879253    0.0131169   -0.0596333   -0.141956    -0.00198567  -0.041043     0.00763888
 -0.0105428   -0.0134926   -0.0311815    0.0482678    -0.201275     0.133335    0.0277648   -0.0382531    0.036771    -0.094825      0.0570213   -0.149867     0.0822026    0.000960335   0.0429508    0.0849098    -0.163064    0.0975471   0.0330372     0.0640847    0.0231128    0.0357122   -0.00223972   0.032091    -0.0934605    0.0372324
  0.0343945   -0.0819712    0.124453    -0.0914341    -0.0779239    0.0561723  -0.0519788   -0.0328499   -0.0817031   -0.0501422    -0.00491522   0.0463206    0.0533907   -0.0443755    -0.0525735    0.00155091    0.128933    0.0883259   0.0478863     0.12396      0.10099      0.0311282    0.0256828    0.0700553    0.0638104    0.0292352
 -0.0412653    0.00304242   0.0854171   -0.0701234    -0.0104198   -0.04121    -0.0312828    0.0556195    0.00789665   0.0565203     0.0243338    0.0377667   -0.100733     0.033454     -0.00858993  -0.0599843     0.0386612  -0.0431086   0.0893439    -0.0554067   -0.0610708   -0.0471988   -0.0604868   -0.00973644   0.047477     0.040692
  0.138568     0.0463188   -0.022556    -0.157279      0.153971    -0.0581145   0.0198069    0.117133     0.030977    -0.027734      0.0242452   -0.0667337   -0.109138     0.125738      0.104847    -0.104012      0.0853294   0.0434416   0.172144     -0.00878162   0.0127383   -0.0135472   -0.047328     0.147074    -0.235321     0.0469924
 -0.0306087   -0.153986    -0.0315387    0.0443588    -0.219132     0.178617    0.121816     0.0721742   -0.0386515    0.143658     -0.113578    -0.149199    -0.0268768    0.0773026    -0.0389367    0.0305304     0.0269768  -0.0331152   0.164798     -0.576775    -0.339665    -0.081696     0.0435584    0.0158392   -0.0872482   -0.178263
 -0.0202661   -0.205113     0.0808384    0.034304      0.0712214    0.141969    0.124588     0.205171    -0.0352795    0.0349395    -0.149451    -0.0604288   -0.05295      0.0180007    -0.0844425   -0.0106978     0.072544    0.0387392   0.0297298     0.479279    -0.129504    -0.116071     0.0401508   -0.0670472    0.111252     0.127444
 -0.232197    -0.0175253   -0.194848     0.0742931     0.0503586   -0.0840995   0.0299605   -0.0966711    0.0534711   -0.0378672    -0.0867936   -0.0388268    0.108035    -0.0153503    -0.234813    -0.0359637    -0.0686546  -0.0162362   0.0158308     0.00880195  -0.0801834   -0.179185    -0.09876      0.0779891    0.132362     0.112643
 -0.206515     0.0670633   -0.119051     0.051345      0.0810089   -0.027024    0.0518255    0.111235     0.178369    -0.187804      0.0557693    0.100496    -0.030219     0.109032     -0.131756    -0.00115756    0.0185652  -0.235077    0.041758      0.0270964    0.0615228   -0.130888     0.0196929   -0.06747      0.101162    -0.0821072
 -0.278013    -0.0732455   -0.226755    -0.167395     -0.00365893  -0.367447   -0.129553    -0.0311648    0.0423377    0.149096      0.0583801   -0.0904491   -0.0593462   -0.0314004    -0.189402    -0.0548844    -0.0917942  -0.0283402  -0.0734927     0.142422    -0.0338577   -0.0265234    0.142998     0.0536931   -0.453664    -0.161443
 -0.141952    -0.102788    -0.234032     0.0355269    -0.0258101    0.5227      0.0801552   -0.0304374    0.0640686    0.102558      0.0588299   -0.107441    -0.0890533    0.0477065    -0.195514    -0.0509518    -0.0904649  -0.0835881   0.100846     -0.141994     0.0302382   -0.0426266    0.143413    -0.095841     0.573384    -0.0552943
 -0.202033     0.0697071   -0.0168229   -0.116663      0.0340425    0.0215208   0.0768779    0.0567678    0.284981    -0.0798687     0.0246708   -0.0860017   -0.0066077   -0.482286     -0.00164377   0.105963     -0.0519211   0.0913946   0.260015     -0.0817538    0.0950689   -0.0781971    0.00943351   0.0564739    0.0509408    0.227551
 -0.11634      0.0937925   -0.00876513  -0.165697      0.0288965    0.0351446   0.0349179    0.0815055    0.271938    -0.158061     -0.040163     0.279848    -0.0135352    0.326338      0.00392389   0.0079349    -0.0478991   0.0991366   0.254482     -0.150412     0.090032    -0.0144393    0.033307     0.00775464   0.347732     0.227928
 -0.0987229    0.0209337    0.106877     0.000563169   0.0335353   -0.0422097   0.0750039   -0.039429    -0.0949291    0.102182      0.0665222    0.00936575   0.0830684    0.0177428     0.143505    -0.067053     -0.05153    -0.597946    0.10381      -0.0185203   -0.107326    -0.0414384    0.0160844   -0.232071    -0.0527898   -0.0513006
 -0.302901     0.0251151    0.124197    -0.00463123    0.0316172   -0.068575    0.0749942   -0.0344908   -0.193046     0.0885322     0.0608929   -0.0058312    0.154217     0.0289286    -0.177643    -0.0713152    -0.0195904   0.629212    0.104118     -0.0266607   -0.107354    -0.138834     0.0598254    0.107242    -0.0467187    0.0231961
  0.0611121    0.0193048   -0.0655569   -0.0121518    -0.0455324   -0.0934057  -0.0550386    0.0241159   -0.0614106    0.000178124   0.071004     0.0540498    0.055557    -0.00228532   -0.136325     0.193279     -0.103202   -0.0141976   0.00818812    0.0200961    0.0714636    0.0661924    0.0259728   -0.00891631  -0.139392     0.0257433
  0.0874037    0.0826474    0.00962544   0.120623      0.162461    -0.039228    0.00824674   0.358885    -0.0409736    0.0203369    -0.00417652  -0.0148181    0.0322546   -0.022479      0.0347039   -0.0337761    -0.114725    0.0426272  -0.0579724    -0.174781    -0.00873204   0.0138862    0.00643382  -0.237932     0.126574     0.0335199
  0.0019769    0.104491    -0.143798    -0.135415      0.0484153    0.113567    0.180526     0.013265    -0.0612512    0.0168902     0.0594308    0.00333403   0.120958    -0.00229429   -0.0376162   -0.0671379     0.0317219   0.0857626  -0.0182666    -0.0762994   -0.0908004   -0.1617      -0.0156727    0.0539198    0.0365917   -0.0883047
 -0.0222552   -0.200638     0.179936    -0.136481     -0.0807173    0.010552   -0.0577144    0.0103127    0.0548198    0.194226     -0.131269     0.101649    -0.0903733   -0.0889274    -0.088844    -0.140709      0.0411621   0.0162997   0.00540764   -0.0191238   -0.188859    -0.115472    -0.00781149   0.148184     0.314713    -0.0345493
  0.251122     0.102962    -0.0406531   -0.0480759     0.0264339   -0.266694   -0.0317443   -0.147878     0.116617     0.0587827    -0.00119749   0.108259    -0.0899608    0.0090345    -0.028891    -0.0154502     0.0121973  -0.0880253  -0.0597285    -0.00917828  -0.195166    -0.0811574   -0.267741    -0.0310622   -0.00560237   0.0819742
  0.0912342    0.22033      0.0610449   -0.0491995     0.0681868    0.2945     -0.0371073    0.070077     0.322534     0.064073     -0.0086751    0.129438    -0.0649115   -0.183159     -0.0254966    0.0785549    -0.0674947  -0.112605   -0.0769471    -0.013939    -0.194945    -0.0962982    0.0389557   -0.113037     0.0913792    0.0734004
  0.0933822   -0.0654721    0.0495      -0.0445898    -0.0643089    0.0424551   0.0814064   -0.0971307   -0.0795424    0.058037     -0.0338628   -0.0754433    0.0219768    0.125822     -0.0422321   -0.0388228     0.0364794  -0.139829    0.147447      0.0207165    0.036928     0.0246396   -0.157984    -0.0469122   -0.101298    -0.163861
  0.0985512    0.0456767   -0.0689608   -0.0191837     0.0670538    0.0380645   0.0563614    0.00235033   0.0507936   -0.114283     -0.00387741   0.0347014    0.0842522   -0.0224148    -0.0505631    0.127269     -0.0123621   0.0525421  -0.0115545    -0.0425905   -0.0792369    0.0169962    0.0198767    0.111225     0.0531064    0.0428325
 -0.0798642    0.0590199    0.0205475   -0.0401924     0.00144206  -0.0184194   0.0389295    0.137031     0.013145    -0.0496971     0.0728409    0.0407395   -0.0322392    0.0963094     0.00161488   0.00714202   -0.0910352  -0.0444795  -0.0672221     0.0764467   -0.123496    -0.0586986    0.0214826   -0.00377714  -0.0203816   -0.133532
  0.0493602    0.0430384   -0.129924     0.0216565     0.0159777   -0.0780429   0.0217798    0.0985122   -0.0823371   -0.00279427   -0.0387458   -0.113641     0.00220314   0.00166789   -0.0339539    0.100449      0.0648551  -0.0124798  -0.000376101   0.0690249    0.00412529   0.0869859    0.00369897  -0.0594234    0.116921     0.0132742
  0.140968    -0.0940905   -0.126128     0.233328      0.0198696   -0.0835098  -0.0651816    0.0901195   -0.0541821    0.0749503     0.00276736   0.00959264  -0.166352    -0.0161135     0.0103756   -0.225059     -0.0999927   0.0393653   0.266481     -0.791425     0.0465234   -0.00603472   0.0368176    0.100541    -0.0605482   -0.0974479
  0.144004    -0.0632313   -0.214769     0.132647      0.0187062   -0.0829819  -0.032602     0.0852371   -0.0548235    0.0852905     0.0275036    0.0863551    0.0652641   -0.0323013    -0.00440511  -0.230354     -0.191775    0.0306541   0.227208      1.24533      0.052861    -0.0345902   -0.0757655    0.10102     -0.104532    -0.00140255
 -0.212225     0.225823     0.0205563   -0.150523      0.0459651   -0.0222318   0.317335     0.0359872   -0.14204      0.108287     -0.122171     0.205201    -0.0951297    0.109781      0.0164875   -0.111949      0.19336    -0.0667531   0.0112525    -0.0523166    0.0617791    0.0910129   -0.557936    -0.107137    -0.100729     0.0502545
  0.16741      0.0831975    0.1395      -0.286573      0.0241104   -0.0195478  -0.239731    -0.0871011   -0.0726259    0.039824     -0.122266     0.0662299   -0.143913    -0.105552      0.015454    -0.167718     -0.122536   -0.277896    0.208559     -0.0409771    0.084889     0.0107633    0.807646     0.060608    -0.0362541   -0.0598231[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     12
│     13
│     14
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.038655
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     12
│     13
│     14
│     17
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.025245
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     11
│     12
│     13
│     14
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.029529
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     12
│     13
│     14
│     17
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.031226
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     12
│     13
│     14
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.032100
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     11
│     12
│     13
│     14
│     17
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.022538
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     12
│     13
│     14
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.038152
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     12
│     13
│     14
│     17
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.025110
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     11
│     12
│     13
│     14
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.029463
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     12
│     13
│     14
│     17
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.031071
┌ Info: EM with 100000 data points 10 iterations avll -1.031071
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.237143e+05
      1       6.490169e+05      -1.746974e+05 |       32
      2       6.179622e+05      -3.105470e+04 |       32
      3       6.045902e+05      -1.337202e+04 |       32
      4       5.981286e+05      -6.461639e+03 |       32
      5       5.928975e+05      -5.231071e+03 |       32
      6       5.891797e+05      -3.717750e+03 |       32
      7       5.871508e+05      -2.028929e+03 |       32
      8       5.859552e+05      -1.195632e+03 |       32
      9       5.851375e+05      -8.176555e+02 |       32
     10       5.844979e+05      -6.396224e+02 |       32
     11       5.839172e+05      -5.807400e+02 |       32
     12       5.833987e+05      -5.185108e+02 |       32
     13       5.829343e+05      -4.643540e+02 |       32
     14       5.825460e+05      -3.883477e+02 |       32
     15       5.822065e+05      -3.394086e+02 |       32
     16       5.818932e+05      -3.133629e+02 |       32
     17       5.816756e+05      -2.176011e+02 |       32
     18       5.815469e+05      -1.286585e+02 |       32
     19       5.814758e+05      -7.110554e+01 |       32
     20       5.814341e+05      -4.173452e+01 |       31
     21       5.813957e+05      -3.839792e+01 |       31
     22       5.813339e+05      -6.178013e+01 |       32
     23       5.812556e+05      -7.827364e+01 |       30
     24       5.811268e+05      -1.288184e+02 |       32
     25       5.809547e+05      -1.721428e+02 |       31
     26       5.808459e+05      -1.087933e+02 |       30
     27       5.808043e+05      -4.158851e+01 |       32
     28       5.807862e+05      -1.813207e+01 |       32
     29       5.807780e+05      -8.198700e+00 |       27
     30       5.807729e+05      -5.019564e+00 |       27
     31       5.807677e+05      -5.241148e+00 |       26
     32       5.807632e+05      -4.526689e+00 |       24
     33       5.807606e+05      -2.613320e+00 |       26
     34       5.807580e+05      -2.538998e+00 |       22
     35       5.807562e+05      -1.808526e+00 |       18
     36       5.807550e+05      -1.219177e+00 |       19
     37       5.807538e+05      -1.143736e+00 |       16
     38       5.807531e+05      -7.916000e-01 |       17
     39       5.807525e+05      -5.716057e-01 |       15
     40       5.807517e+05      -7.516803e-01 |       15
     41       5.807508e+05      -9.599068e-01 |       17
     42       5.807501e+05      -7.159663e-01 |       12
     43       5.807493e+05      -7.895972e-01 |       10
     44       5.807489e+05      -3.821185e-01 |       10
     45       5.807485e+05      -3.465991e-01 |       11
     46       5.807483e+05      -2.822388e-01 |        4
     47       5.807482e+05      -8.026419e-02 |        0
     48       5.807482e+05       0.000000e+00 |        0
K-means converged with 48 iterations (objv = 580748.1765648047)
┌ Info: K-means with 32000 data points using 48 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.294867
[ Info: iteration 2, average log likelihood -1.262177
[ Info: iteration 3, average log likelihood -1.233061
[ Info: iteration 4, average log likelihood -1.200799
[ Info: iteration 5, average log likelihood -1.167820
[ Info: iteration 6, average log likelihood -1.123069
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.064523
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.059496
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.052632
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.053260
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.026273
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.024035
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      7
│      8
│     18
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.023230
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.065348
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     16
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.024102
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.045918
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.035655
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│      9
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.009680
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      8
│     10
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.028733
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.068077
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.037740
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      9
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.023554
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│      8
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.019433
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.064375
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.036747
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.032415
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      5
│      7
│      8
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.005129
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.069156
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.032533
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.027317
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      5
│      8
│      9
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.027157
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.053592
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.026196
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      8
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.019228
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     15
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.036372
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      7
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.027920
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      8
│      9
│     16
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.022063
[ Info: iteration 38, average log likelihood -1.075763
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.040938
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.030246
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      7
│      8
│     10
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -0.996439
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     14
│     15
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.051915
[ Info: iteration 43, average log likelihood -1.066725
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      5
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.013577
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      7
│      8
│      9
│     14
│     16
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.003617
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.084547
[ Info: iteration 47, average log likelihood -1.051520
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     10
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.018043
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      8
│     15
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.023350
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      7
│     16
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.041424
┌ Info: EM with 100000 data points 50 iterations avll -1.041424
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.133303    -0.0727096    0.0261777    -0.056059    -0.0656767    -0.0148005    0.00471752   0.043061    -0.0705064   -0.0906896   -0.0117411   -0.118125    -0.0350787    0.165912    -0.0108998   -0.000427035  -0.139704    -0.0389075    -0.0182396   -0.0408471    0.0232646   -0.0522623   -0.0727426    -0.120754     -0.0470817     0.114855
 -0.0202005   -0.200369     0.180226     -0.139037    -0.0814471     0.0103509   -0.0614654    0.00908844   0.0627068    0.191241    -0.130854     0.102009    -0.0908373   -0.0867662   -0.0820481   -0.138204      0.0438518    0.0165626     0.00816115  -0.0174988   -0.192766    -0.111986    -0.00822628    0.149105      0.313674     -0.0348036
  0.0916683    0.127555    -0.168471      0.00144686  -0.0354383    -0.157344     0.126034     0.0357877   -0.24038     -0.0441926   -0.0320483   -0.0130611    0.0803684    0.0514852    0.115883    -0.0548827     0.0418095    0.0936894     0.029146    -0.078401    -0.253564    -0.0179047   -0.181517      0.137317      0.156195      0.109466
  0.146399    -0.0867116   -0.164514      0.197623     0.0189287    -0.0833576   -0.0570137    0.0862155   -0.0521003    0.0830166    0.0118574    0.0390315   -0.0856398   -0.0228473    0.00188093  -0.22746      -0.13699      0.0363653     0.256769     0.00740172   0.0515872   -0.0175618   -0.0105636     0.100865     -0.0835072    -0.06255
 -0.122939     0.150455    -0.0792751    -0.0591297   -0.0203119     0.103397     0.280992     0.168768    -0.0440335   -0.125432     0.169088     0.0895271   -0.00784915   0.0298917    0.0468708   -0.00174485    0.00156086  -0.116229     -0.0294872    0.0502328   -0.0869111   -0.010659     0.0461015    -0.145188     -0.0647586    -0.085738
  0.195931     0.164163    -0.400827     -0.0428412    0.0456935     0.00350341   0.221199    -0.0525377   -0.159144    -0.0124616    0.138576    -0.0195949   -0.0856068    0.0100973    0.0262862   -0.0252073     0.024982     0.0738872    -0.0299479   -0.0720081    0.217951    -0.16784     -0.087525      0.282049     -0.0459749    -0.0968534
 -0.0338526    0.0733647   -0.00394614   -0.214018     0.0469122     0.195862     0.143532     0.107655    -0.0160643    0.0276316    0.0109339    0.0176337    0.241406     0.00776918  -0.050201    -0.106951      0.0658919    0.0866444    -0.00458923  -0.0774531   -0.249541    -0.137851     0.040712     -0.0228219     0.0707627    -0.0851425
 -0.214693     0.0450383    0.0687625    -0.022407     0.04556      -0.0592132    0.0790469   -0.0341753   -0.188335     0.0723851    0.0646461   -0.00574762   0.0973121    0.0242882   -0.0190744   -0.058451     -0.0154862    0.0153405     0.10765     -0.0244512   -0.0882691   -0.0931289    0.0228013    -0.0962166    -0.0696568    -0.0137725
  0.141504     0.106702    -0.143599     -0.0226123    0.0300968     0.0879988    0.201862    -0.0698568    0.168917     0.0778924    0.104552    -0.018522    -0.0432968   -0.0384729   -0.0165282   -0.015998     -0.076434     0.0922119    -0.0561194   -0.0831602   -0.0586145   -0.189975    -0.0250705     0.0818941    -0.0208859    -0.11923
 -0.195051    -0.0402845   -0.222257     -0.0659149   -0.000937195   0.0935999    0.0141646   -0.00240105   0.0363735    0.0848852    0.0855312   -0.0865277   -0.0891509    0.0149976   -0.152063    -0.0537139    -0.0628723   -0.0674496     0.048866    -0.0118161   -0.0146152   -0.0256695    0.112407     -0.0464266     0.0687876    -0.116305
  0.200564    -0.0877292   -0.0941079    -0.0187171    0.128924      0.112731     0.0334155    0.0881671   -0.00935139  -0.143108    -0.00203735  -0.0215312   -0.110232    -0.060412    -0.119586     0.153494     -0.067778     0.0535101     0.0936022    0.0465589    0.0567373    0.0173058   -0.027043      0.20268       0.0452252     0.0848544
  0.0295927   -0.129397     0.0622347    -0.00534972  -0.0365212     0.121116    -0.109367    -0.0320127   -0.0134262   -0.0572519   -0.0988246    0.0492052   -0.0143284   -0.0471812   -0.102169     0.0339375    -0.0363298   -0.0913089    -0.00147352  -0.0221045   -0.10973      0.0968008    0.185113     -0.000166947   0.000365482   0.296102
 -0.00633286   0.0432785   -0.0322436    -0.0238032    0.126573      0.0324532   -0.0563904   -0.0661434    0.0883126   -0.111167     0.0303792   -0.0742839    0.180697     0.0673927    0.0726951    0.149382      0.10254     -0.0162417     0.0314117   -0.126816    -0.126143     0.00472546  -0.0225789     0.0569363     0.0973462    -0.0218802
 -0.0154569   -0.0223964   -0.0297083     0.0421367   -0.212704      0.128578     0.0307296   -0.0337702    0.0379126   -0.0946898    0.0587121   -0.148971     0.0893142    0.00737172   0.0435976    0.0831723    -0.174355     0.0946884     0.0250442    0.0651209    0.0230814    0.0369111    0.00632365    0.0377841    -0.105481      0.0421602
 -0.162467     0.0138607   -0.15356       0.0132433    0.0924697    -0.0339248    0.00792468  -0.0668226    0.0948718   -0.0449022   -0.0556942   -0.059722     0.0268604    0.0249093   -0.113519    -0.0364142    -0.0100715    0.0375962    -0.0671303    0.0244612   -0.0383985   -0.10463     -0.0840959     0.0561948    -0.013126      0.0732404
 -0.212036     0.0696447   -0.118463      0.0529552    0.0799429    -0.0313563    0.0484343    0.115519     0.181466    -0.190314     0.0528692    0.105429    -0.0300983    0.117099    -0.130048    -0.00336253    0.0205704   -0.241925      0.043032     0.0260855    0.0523321   -0.12944      0.0206887    -0.0639678     0.10379      -0.0828098
 -0.0343397    0.00385501   0.0854181    -0.0726519   -0.00918319   -0.0443405   -0.0270808    0.0562635    0.0125923    0.0547858    0.0277115    0.0371915   -0.10151      0.0368594   -0.00477711  -0.0633418     0.0400616   -0.0423965     0.0928334   -0.0541722   -0.0582093   -0.0473201   -0.0601085    -0.00465684    0.0354468     0.0405933
 -0.0182524   -0.125269     0.0134257    -0.163407    -0.125125     -0.0234977   -0.167748    -0.0474558   -0.0787031    0.0436261   -0.0514139   -0.0372788    0.079041     0.0538035   -0.088764    -0.0196035     0.0806784    0.00170999    0.00692304   0.118862     0.18625      0.0296807    0.0314587     0.0630995    -0.0982834    -0.0296089
 -0.0250316   -0.177046     0.0257618     0.0343603   -0.0624499     0.157008     0.123938     0.143021    -0.0345822    0.0830621   -0.13003     -0.104699    -0.0425889    0.049303    -0.0592949    0.00679513    0.0527475    0.00414015    0.0922314   -0.0195396   -0.225115    -0.100112     0.0411344    -0.0234476     0.0132868    -0.0171725
 -0.043631    -0.0583339    0.000930535   0.053681    -0.294776      0.0183773    0.0348123    0.0491752    0.0495789    0.0632951   -0.0379712    0.0567446    0.00845434   0.201086     0.0249987    0.242116      0.0720011    0.124626     -0.0352322    0.100649     0.0769124   -0.007301    -0.156906      0.0125039    -0.0646578    -0.00720001
  0.0643868    0.0196454   -0.0659263    -0.0148966   -0.0444024    -0.0943454   -0.056159     0.0264585   -0.0654118    0.00133727   0.0711853    0.0529049    0.056178    -0.00122957  -0.133332     0.188677     -0.101344    -0.0118459     0.00355369   0.0188261    0.072183     0.06578      0.0246516    -0.00683977   -0.148226      0.0247766
  0.0838511    0.0823891    0.0099733     0.11661      0.162259     -0.0429       0.00948176   0.353455    -0.042143     0.021191    -0.00369625  -0.0132103    0.0297282   -0.0203095    0.0375109   -0.0351138    -0.111771     0.0418768    -0.0512016   -0.170913    -0.00924333   0.0140806    0.00610257   -0.232808      0.120398      0.0307061
 -0.158401     0.0820068   -0.0126813    -0.141697     0.0314966     0.028472     0.0554746    0.0693139    0.278327    -0.119921    -0.00821133   0.100769    -0.0101441   -0.0698306    0.0011172    0.0560121    -0.049899     0.095375      0.25722     -0.116963     0.0925039   -0.0456635    0.0215554     0.0316356     0.2021        0.227757
  0.0932045   -0.0658536    0.0495477    -0.0441537   -0.0647495     0.0412767    0.0816491   -0.0977639   -0.0777965    0.0585931   -0.0338237   -0.0754819    0.0223336    0.125824    -0.042112    -0.0388863     0.0366993   -0.140079      0.147709     0.0207187    0.0365669    0.0253317   -0.157904     -0.045975     -0.101747     -0.164288
  0.173393     0.160275     0.00908301   -0.048573     0.0468235     0.00719883  -0.0343161   -0.0418101    0.217164     0.0614509   -0.00479197   0.118584    -0.0779075   -0.0847941   -0.0271912    0.0305073    -0.0267507   -0.100057     -0.0677348   -0.0117186   -0.195066    -0.0885261   -0.118014     -0.0710142     0.0422717     0.077722
  0.0483195    0.033872    -0.130372      0.022974     0.0167825    -0.0705248    0.00553198   0.107158    -0.0774031    0.00287578  -0.0414139   -0.136134    -0.00574069  -1.48688e-5  -0.0420284    0.110453      0.0679749   -0.0228558    -0.00255972   0.083534     0.0351285    0.0997225    0.0294206    -0.0694396     0.11039       0.00835836
  0.14571      0.0460695   -0.00745734   -0.154218     0.209208     -0.0518223    0.00923123   0.144506     0.0459741   -0.0390996    0.0334801   -0.0802958   -0.11811      0.0957905    0.0988706   -0.117539      0.090714     0.0192474     0.215075     0.00892525   0.0126222    0.0168984   -0.0453707     0.083158     -0.201293      0.0451691
 -0.0247527    0.153736     0.0808462    -0.215254     0.035555     -0.0210427    0.0388433   -0.0257166   -0.102122     0.0760589   -0.121915     0.13691     -0.120333     0.00119787   0.0155748   -0.139475      0.0339454   -0.171138      0.111278    -0.041671     0.0726057    0.0510631    0.122529     -0.026284     -0.0662279    -0.00474539
 -0.0543097    0.00614949   0.101596     -0.0411108    0.0124762    -0.097302    -0.0764914    0.12601      0.059513     0.00982575   0.00649914   0.00624415  -0.0469905    0.154654    -0.0137238    0.0122619    -0.152201    -0.000919742  -0.116108     0.0898899   -0.143156    -0.0910731   -0.000608564   0.0983443    -0.0236615    -0.172904
  0.122402     0.168478    -0.0813458    -0.0332187   -0.0497015    -0.0206123    0.18381     -0.00358098   0.0772854   -0.0540676   -0.0398751    0.197201     0.152558    -0.060124    -0.115058     0.0607488    -0.098292     0.121546     -0.139856    -0.0380064   -0.132744     0.0448068    0.102725      0.0634881     0.0137648     0.0694498
  0.0845337   -0.0372662    0.210857      0.0136473    0.0128657     0.121883     0.0641688   -0.0193514   -0.0441074   -0.13718      0.0577921    0.112891    -0.00747853  -0.164527    -0.0286394    0.000581171   0.147646     0.197416      0.127462     0.115454    -0.0470762   -0.0102231    0.046525      0.0887748     0.245429      0.0852544
 -0.23357     -0.0161427   -0.19874       0.0729295    0.049473     -0.0821028    0.0301344   -0.0962586    0.0549674   -0.0372062   -0.0851325   -0.0380989    0.108459    -0.0164592   -0.235007    -0.0361374    -0.0677813   -0.0172322     0.0179375    0.00725983  -0.0783863   -0.179324    -0.0979605     0.0845285     0.13184       0.111365[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.065321
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      5
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.017780
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│      9
│     10
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.992081
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│     16
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.012963
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.026356
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      7
│      8
│      9
│     10
│     18
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.993870
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.028255
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│      5
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.002412
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│      9
│     10
│     15
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.992691
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      5
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.030816
┌ Info: EM with 100000 data points 10 iterations avll -1.030816
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0912573   -0.0624336    -0.0311804   -0.0107791    0.110129    -0.110409   -0.169385   -0.107178    -0.0596293   -0.183809    -0.0302243    0.10017      -0.0584369   -0.0949583    0.0788862    0.0151581    0.126632    -0.000670463  -0.126703    -0.119486    -0.0349332   -0.0348159     0.0669268    0.0623864   -0.0389755   -0.11702
 -0.0173045    0.145132     -0.0041309    0.0582642    0.0649627   -0.122926    0.118336    0.0951604   -0.114467    -0.106761     0.00176669  -0.00668229   -0.0672079   -0.0770292    0.0686406   -0.157868    -0.194209    -0.143128      0.0821426    0.00809633   0.0215941    0.126885     -0.0617221    0.016207     0.0082805    0.266523
 -0.254115     0.0167023     0.0323134   -0.158578     0.143777     0.100826    0.112023    0.0192908   -0.0531874    0.00808283  -0.058665    -0.00485897    0.159998    -0.0534178   -0.0400525    0.168946     0.0767762   -0.044927     -0.00997808   0.0177812   -0.0238209   -0.149267      0.029505    -0.042665     0.0912423   -0.0263492
 -0.115007    -0.00561279    0.102331     0.0311343    0.189735     0.0219249  -0.124594   -0.118429     0.0232217   -0.106055     0.107386     0.0647569     0.193394    -0.0613874    0.038949     0.00608766   0.00805168   0.001983      0.104827    -0.0107492   -0.28958      0.0620902     0.0428855    0.0369516   -0.115739    -0.0743136
  0.264051     0.162111      0.0899737   -0.14792      0.0872324   -0.0664241   0.254091    0.0669567   -0.0264863    0.0658039   -0.0859061   -0.0475696    -0.00529725   0.0858244   -0.0136501   -0.0146164    0.131933    -0.0344723    -0.0405305   -0.175039    -0.172768    -0.109891      0.0405686    0.0564777    0.0759205   -0.0343821
  0.115125     0.112558      0.0763126    0.022757    -0.0925434    0.152813   -0.060502   -0.0392988   -0.202564     0.139344     0.0540442   -0.0564917    -0.133496     0.0653666    0.0269776   -0.0284286    0.0214018   -0.0334782     0.00418     -0.065697    -0.0692458   -0.000784011   0.153242     0.0502191   -0.0610129    0.0259094
 -0.0278565   -0.222285      0.0724852   -0.0548681   -0.0781436    0.109364    0.159883   -0.0574916   -0.0330308    0.00271275  -0.0390243    0.139473      0.0704831   -0.157705     0.0783045    0.0479492   -0.0640398    0.0859349    -0.13582     -0.00252785   0.0698431    0.00250597   -0.0218313    0.184724    -0.0318177    0.0842437
  0.130893    -0.0454327     0.128303     0.0349793   -0.0717216   -0.006836   -0.102118    0.0958983    0.00086904  -0.0407237   -0.0913182    0.013032     -0.0986139    0.0140804    0.0193128    0.0126791   -0.0319012    0.220254      0.108516    -0.0506359    0.0145715    0.132788     -0.0528801   -0.0493705   -0.00671664   0.0206721
 -0.0106547   -0.0654384    -0.0314552   -0.0280947   -0.0760797   -0.064383    0.104449    0.190043    -0.0769786   -0.209032    -0.0631129   -0.138141     -0.00356991  -0.0866421   -0.139771     0.0581404    0.0349698    0.000337024  -0.0513547    0.0725733   -0.0204972   -0.00188387   -0.132156    -0.145785     0.118154    -0.0614844
  0.0124443    0.0949315    -0.101113     0.0682554   -0.0817584    0.155146   -0.126436   -0.0489704   -0.24974      0.00746873  -0.0608558    0.000445832   0.192028    -0.159658    -0.0108397    0.0878158    0.0791702    0.0244416    -0.0698784   -0.0618162    0.0125782   -0.0221058     0.0963655   -0.026823    -0.0888951   -0.0840209
 -0.0302211    0.110453     -0.0897417   -0.00227936   0.177051     0.0346317   0.0994442   0.0753852    0.218625    -0.285816     0.0162736   -0.0287902    -0.0101426    0.135103     0.101894    -0.0105668   -0.0749676   -0.0582147    -0.0322386   -0.00167534   0.0824256   -0.0609543    -0.0388167    0.0391807    0.0782909   -0.234862
 -0.250694    -0.0746911    -0.346039    -0.0109152    0.00249913  -0.0245602   0.0351666  -0.0763544   -0.197202    -0.156572    -0.0747631   -0.169319      0.0809273    0.0307572   -0.0319701    0.206698     0.0370155   -0.0367217     0.11235      0.0546725   -0.120025    -0.023818     -0.0891401   -0.013812    -0.0223662   -0.0560399
  0.0297915    0.0730535     0.0362222    0.047893     0.145262    -0.0418661   0.11444     0.172767    -0.0281088   -0.0048732    0.0515542   -0.148114     -0.0891739    0.0456123    0.114879    -0.0167813    0.0542616    0.015331     -0.0190242   -0.00591704  -0.0623924   -0.045119     -0.0966416    0.08685     -0.168591     0.1255
 -0.136276     0.149974      0.117868    -0.0243795   -0.00722404  -0.0167005   0.15043    -0.0202381   -0.330506    -0.00979196  -0.149936     0.071893     -0.0468362    0.00249021   0.0281782    0.0703704    0.13468      0.147949      0.0217075    0.0472173   -0.0542662   -0.102071      0.0154236    0.102855    -0.0076356    0.0626505
 -0.0739895   -0.0415784    -0.24004     -0.03215     -0.0982322   -0.0745121   0.0643951  -0.0426855   -0.0119772   -0.128204    -0.187786     0.109823      0.0302616    0.11999      0.086076     0.0461805    0.155759    -0.00940536    0.147189     0.0174395    0.00860707  -0.183774      0.0582231   -0.0458119   -0.0855052   -0.0186804
 -0.0765348   -0.0517745    -0.00518362  -0.0551107    0.0855417    0.190833   -0.117968   -0.073156    -0.146148     0.0880644   -0.0577254   -0.0698642     0.0411823    0.0504035   -0.029292    -0.13081     -0.0707839   -0.0779171    -0.112325     0.201168    -0.148638    -0.0632788     0.0440217    0.031915    -0.0871496    0.0550646
 -0.179516     0.000477599   0.0550958   -0.10742     -0.0926807   -0.0172415   0.0130255   0.00109179  -0.10238     -0.0403161   -0.0614908    0.106228      0.100785     0.0523582    0.00362304   0.0817767    0.00548334  -0.0513785     0.142513    -0.124664     0.164051    -0.0157219     0.145041     0.216587    -0.0204837   -0.155995
 -0.014998    -0.020375      0.0406187    0.0416095    0.0355404    0.0228064  -0.104031   -0.0204214    0.102185     0.0467596   -0.0563821   -0.0304966    -0.146675     0.00556274  -0.0203614   -0.0133375   -0.0327723   -0.026734      0.112689    -0.00377172   0.0148965   -0.066224     -0.0126015   -0.00469497   0.00723399   0.154363
 -0.00344106  -0.11916       0.0397384   -0.00916188   0.153796    -0.183061   -0.0994657  -0.0467772    0.0712134   -0.0208519    0.219598     0.142606     -0.156197     0.193622     0.0663956   -0.0915373    0.0185806    0.16046      -0.0939777   -0.259156    -0.0962504    0.0889896     0.0291293   -0.0177366    0.0536207    0.0591425
  0.121453     0.0865112    -0.0742015    0.0837742   -0.0413402    0.0275997  -0.13772     0.0920697    0.228838    -0.0648223   -0.0715002   -0.0339709    -0.0275548   -0.0217926   -0.141004    -0.0999753    0.11626      0.11786      -0.0690789   -0.0511937    0.0996478   -0.0496579    -0.0713526   -0.0669162   -0.086287     0.0943348
 -0.075312     0.0349304     0.226633     0.0811691    0.0303082    0.0695273  -0.139029    0.0623231    0.0211929   -0.0295549    0.0667511    0.099383     -0.135677     0.196723     0.0855613   -0.0167374   -0.182538     0.160148     -0.068078    -0.070596    -0.00931063   0.00511501    0.225139    -0.111448    -0.00449994   0.0884558
 -0.0190194    0.127811      0.0128597   -0.0170546    0.102384     0.0936116  -0.0481612  -0.0795393   -0.0356601   -0.0218468    0.0409065    0.168523      0.0262564    0.20577     -0.0560131   -0.0849546    0.124468    -0.143475      0.0284783   -0.0484504   -0.0163313    0.0795485     0.0197059   -0.146302    -0.0490881   -0.201497
  0.0713867   -0.09473      -0.191582     0.0697348   -0.125505    -0.180674    0.0483324   0.0102532   -0.0190114    0.0760073    0.0687595    0.0050877    -0.0949084   -0.0809284   -0.0175329    0.112356    -0.0739335   -0.00186848    0.0117617   -0.0205607   -0.18405     -0.166464      0.0986138    0.00466315  -0.0702207   -0.128669
 -0.034948     0.0710885     0.0824652    0.180796     0.113265    -0.235346   -0.0458498  -0.08254     -0.0696344   -0.13267      0.0495008   -0.120347      0.184335     0.116066    -0.0112047   -0.174041    -0.0995817   -0.311213     -0.100485    -0.186758     0.0578759   -0.137864     -0.0685792   -0.0773873    0.0669542   -0.032894
  0.0767738    0.0509778     0.111792    -0.152665     0.127659    -0.018309   -0.0558337  -0.275261     0.170386     0.125938    -0.0683153    0.00373172   -0.0866578    0.0557256   -0.251421    -0.0529064   -0.147711    -0.0105247     0.131206    -0.00246127   0.0669593    0.165456     -0.0659161    0.059954    -0.00599013  -0.104814
  0.0457802    0.0392182    -0.0733776   -0.0595408   -0.0990554    0.0458253   0.189676    0.0699398    0.0302476   -0.101171    -0.176783     0.180918      0.251734    -0.127651     0.147954    -0.145699    -0.0953674    0.120593      0.208898    -0.0188868    0.137999    -0.00443184    0.0543162   -0.0017438   -0.0521378    0.0810207
 -0.0682636    0.0392103    -0.0285092   -0.010892    -0.0687511    0.0566477  -0.0468414   0.101099     0.0950533    0.0317869    0.0190756   -0.100178     -0.115615     0.0120729    0.117885     0.171035    -0.0685898   -0.102414      0.0735862    0.0782623    0.0335961   -0.0318052    -0.0901917    0.0752311    0.0653879    0.0337834
  0.198885     0.0679244     0.0359124    0.0251286    0.0528377   -0.2835     -0.0999613  -0.120112     0.160037     0.00236284   0.111781     0.0296115     0.13483     -0.00765297  -0.0283879    0.128457     0.124026     0.0223692    -0.0789463    0.057465    -0.106407    -0.00527566    0.160151     0.179728    -0.0228514   -0.0926482
 -0.0287149   -0.059529     -0.0262311    0.0591489   -0.016871    -0.131455   -0.0491782   0.0610932   -0.0734022   -0.22743      0.0121918   -0.0814302    -0.0626558   -0.0385069    0.111736    -0.132958    -0.0211496    0.0801869     0.0187335   -0.116521    -0.00927438   0.0488281    -0.0395695    0.0944002   -0.0663538   -0.0365187
  0.0601219    0.112367      0.179403     0.250063    -0.0259994   -0.0472851  -0.135401    0.0916453   -0.0947339    0.0422736   -0.129452    -0.00345122    0.0779793   -0.0354581   -0.0526593    0.0392611    0.00666843   0.00425793   -0.0414409   -0.130437     0.103004     0.129053      0.0693755    0.00866685   0.0642548    0.148941
 -0.0587745   -0.0354203     0.130353    -0.309606     0.27355      0.185681    0.14232     0.125722     0.0461378    0.1591       0.065893    -0.0213897     0.0412884   -0.0238674   -0.106665    -0.0434088    0.0297323    0.0424694    -0.0560733   -0.0778423    0.153455     0.105091     -0.0361519    0.00602802  -0.161646     0.0191361
 -0.141775    -0.0304413     0.0885734   -0.19954     -0.0895689    0.118596   -0.0486539   0.040873    -0.104043    -0.00702556  -0.0976633   -0.029231      0.112474     0.0287413    0.0343907   -0.151063     0.0541258    0.0104718    -0.15976      0.0288729    0.100703    -0.136049      0.00230597   0.0233993   -0.0763284    0.147281kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.420001680535428
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420020
[ Info: iteration 2, average log likelihood -1.419962
[ Info: iteration 3, average log likelihood -1.419921
[ Info: iteration 4, average log likelihood -1.419872
[ Info: iteration 5, average log likelihood -1.419811
[ Info: iteration 6, average log likelihood -1.419736
[ Info: iteration 7, average log likelihood -1.419642
[ Info: iteration 8, average log likelihood -1.419521
[ Info: iteration 9, average log likelihood -1.419347
[ Info: iteration 10, average log likelihood -1.419063
[ Info: iteration 11, average log likelihood -1.418576
[ Info: iteration 12, average log likelihood -1.417816
[ Info: iteration 13, average log likelihood -1.416875
[ Info: iteration 14, average log likelihood -1.416029
[ Info: iteration 15, average log likelihood -1.415482
[ Info: iteration 16, average log likelihood -1.415205
[ Info: iteration 17, average log likelihood -1.415080
[ Info: iteration 18, average log likelihood -1.415025
[ Info: iteration 19, average log likelihood -1.415000
[ Info: iteration 20, average log likelihood -1.414990
[ Info: iteration 21, average log likelihood -1.414985
[ Info: iteration 22, average log likelihood -1.414982
[ Info: iteration 23, average log likelihood -1.414981
[ Info: iteration 24, average log likelihood -1.414980
[ Info: iteration 25, average log likelihood -1.414979
[ Info: iteration 26, average log likelihood -1.414979
[ Info: iteration 27, average log likelihood -1.414979
[ Info: iteration 28, average log likelihood -1.414979
[ Info: iteration 29, average log likelihood -1.414978
[ Info: iteration 30, average log likelihood -1.414978
[ Info: iteration 31, average log likelihood -1.414978
[ Info: iteration 32, average log likelihood -1.414978
[ Info: iteration 33, average log likelihood -1.414978
[ Info: iteration 34, average log likelihood -1.414978
[ Info: iteration 35, average log likelihood -1.414977
[ Info: iteration 36, average log likelihood -1.414977
[ Info: iteration 37, average log likelihood -1.414977
[ Info: iteration 38, average log likelihood -1.414977
[ Info: iteration 39, average log likelihood -1.414977
[ Info: iteration 40, average log likelihood -1.414977
[ Info: iteration 41, average log likelihood -1.414977
[ Info: iteration 42, average log likelihood -1.414977
[ Info: iteration 43, average log likelihood -1.414977
[ Info: iteration 44, average log likelihood -1.414977
[ Info: iteration 45, average log likelihood -1.414977
[ Info: iteration 46, average log likelihood -1.414977
[ Info: iteration 47, average log likelihood -1.414977
[ Info: iteration 48, average log likelihood -1.414977
[ Info: iteration 49, average log likelihood -1.414977
[ Info: iteration 50, average log likelihood -1.414977
┌ Info: EM with 100000 data points 50 iterations avll -1.414977
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4200202393048968
│     -1.4199622473677034
│      ⋮
└     -1.4149765634142708
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414995
[ Info: iteration 2, average log likelihood -1.414935
[ Info: iteration 3, average log likelihood -1.414892
[ Info: iteration 4, average log likelihood -1.414841
[ Info: iteration 5, average log likelihood -1.414778
[ Info: iteration 6, average log likelihood -1.414703
[ Info: iteration 7, average log likelihood -1.414618
[ Info: iteration 8, average log likelihood -1.414531
[ Info: iteration 9, average log likelihood -1.414448
[ Info: iteration 10, average log likelihood -1.414374
[ Info: iteration 11, average log likelihood -1.414312
[ Info: iteration 12, average log likelihood -1.414259
[ Info: iteration 13, average log likelihood -1.414210
[ Info: iteration 14, average log likelihood -1.414164
[ Info: iteration 15, average log likelihood -1.414117
[ Info: iteration 16, average log likelihood -1.414070
[ Info: iteration 17, average log likelihood -1.414023
[ Info: iteration 18, average log likelihood -1.413975
[ Info: iteration 19, average log likelihood -1.413930
[ Info: iteration 20, average log likelihood -1.413889
[ Info: iteration 21, average log likelihood -1.413852
[ Info: iteration 22, average log likelihood -1.413820
[ Info: iteration 23, average log likelihood -1.413794
[ Info: iteration 24, average log likelihood -1.413773
[ Info: iteration 25, average log likelihood -1.413755
[ Info: iteration 26, average log likelihood -1.413741
[ Info: iteration 27, average log likelihood -1.413729
[ Info: iteration 28, average log likelihood -1.413720
[ Info: iteration 29, average log likelihood -1.413711
[ Info: iteration 30, average log likelihood -1.413704
[ Info: iteration 31, average log likelihood -1.413698
[ Info: iteration 32, average log likelihood -1.413692
[ Info: iteration 33, average log likelihood -1.413687
[ Info: iteration 34, average log likelihood -1.413682
[ Info: iteration 35, average log likelihood -1.413677
[ Info: iteration 36, average log likelihood -1.413673
[ Info: iteration 37, average log likelihood -1.413668
[ Info: iteration 38, average log likelihood -1.413664
[ Info: iteration 39, average log likelihood -1.413660
[ Info: iteration 40, average log likelihood -1.413656
[ Info: iteration 41, average log likelihood -1.413652
[ Info: iteration 42, average log likelihood -1.413648
[ Info: iteration 43, average log likelihood -1.413644
[ Info: iteration 44, average log likelihood -1.413639
[ Info: iteration 45, average log likelihood -1.413635
[ Info: iteration 46, average log likelihood -1.413631
[ Info: iteration 47, average log likelihood -1.413627
[ Info: iteration 48, average log likelihood -1.413623
[ Info: iteration 49, average log likelihood -1.413619
[ Info: iteration 50, average log likelihood -1.413615
┌ Info: EM with 100000 data points 50 iterations avll -1.413615
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4149949621086253
│     -1.414935019719557
│      ⋮
└     -1.4136147154032166
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413625
[ Info: iteration 2, average log likelihood -1.413573
[ Info: iteration 3, average log likelihood -1.413535
[ Info: iteration 4, average log likelihood -1.413493
[ Info: iteration 5, average log likelihood -1.413444
[ Info: iteration 6, average log likelihood -1.413384
[ Info: iteration 7, average log likelihood -1.413314
[ Info: iteration 8, average log likelihood -1.413233
[ Info: iteration 9, average log likelihood -1.413146
[ Info: iteration 10, average log likelihood -1.413056
[ Info: iteration 11, average log likelihood -1.412968
[ Info: iteration 12, average log likelihood -1.412886
[ Info: iteration 13, average log likelihood -1.412814
[ Info: iteration 14, average log likelihood -1.412752
[ Info: iteration 15, average log likelihood -1.412702
[ Info: iteration 16, average log likelihood -1.412660
[ Info: iteration 17, average log likelihood -1.412626
[ Info: iteration 18, average log likelihood -1.412597
[ Info: iteration 19, average log likelihood -1.412573
[ Info: iteration 20, average log likelihood -1.412551
[ Info: iteration 21, average log likelihood -1.412532
[ Info: iteration 22, average log likelihood -1.412516
[ Info: iteration 23, average log likelihood -1.412500
[ Info: iteration 24, average log likelihood -1.412486
[ Info: iteration 25, average log likelihood -1.412473
[ Info: iteration 26, average log likelihood -1.412461
[ Info: iteration 27, average log likelihood -1.412449
[ Info: iteration 28, average log likelihood -1.412438
[ Info: iteration 29, average log likelihood -1.412428
[ Info: iteration 30, average log likelihood -1.412418
[ Info: iteration 31, average log likelihood -1.412408
[ Info: iteration 32, average log likelihood -1.412398
[ Info: iteration 33, average log likelihood -1.412389
[ Info: iteration 34, average log likelihood -1.412380
[ Info: iteration 35, average log likelihood -1.412371
[ Info: iteration 36, average log likelihood -1.412363
[ Info: iteration 37, average log likelihood -1.412354
[ Info: iteration 38, average log likelihood -1.412345
[ Info: iteration 39, average log likelihood -1.412337
[ Info: iteration 40, average log likelihood -1.412329
[ Info: iteration 41, average log likelihood -1.412321
[ Info: iteration 42, average log likelihood -1.412313
[ Info: iteration 43, average log likelihood -1.412305
[ Info: iteration 44, average log likelihood -1.412298
[ Info: iteration 45, average log likelihood -1.412290
[ Info: iteration 46, average log likelihood -1.412283
[ Info: iteration 47, average log likelihood -1.412276
[ Info: iteration 48, average log likelihood -1.412270
[ Info: iteration 49, average log likelihood -1.412263
[ Info: iteration 50, average log likelihood -1.412257
┌ Info: EM with 100000 data points 50 iterations avll -1.412257
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4136246806398456
│     -1.4135730389345813
│      ⋮
└     -1.4122567951268505
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412259
[ Info: iteration 2, average log likelihood -1.412200
[ Info: iteration 3, average log likelihood -1.412143
[ Info: iteration 4, average log likelihood -1.412079
[ Info: iteration 5, average log likelihood -1.412000
[ Info: iteration 6, average log likelihood -1.411903
[ Info: iteration 7, average log likelihood -1.411791
[ Info: iteration 8, average log likelihood -1.411665
[ Info: iteration 9, average log likelihood -1.411535
[ Info: iteration 10, average log likelihood -1.411406
[ Info: iteration 11, average log likelihood -1.411285
[ Info: iteration 12, average log likelihood -1.411176
[ Info: iteration 13, average log likelihood -1.411080
[ Info: iteration 14, average log likelihood -1.410995
[ Info: iteration 15, average log likelihood -1.410921
[ Info: iteration 16, average log likelihood -1.410857
[ Info: iteration 17, average log likelihood -1.410799
[ Info: iteration 18, average log likelihood -1.410749
[ Info: iteration 19, average log likelihood -1.410704
[ Info: iteration 20, average log likelihood -1.410664
[ Info: iteration 21, average log likelihood -1.410628
[ Info: iteration 22, average log likelihood -1.410596
[ Info: iteration 23, average log likelihood -1.410567
[ Info: iteration 24, average log likelihood -1.410540
[ Info: iteration 25, average log likelihood -1.410516
[ Info: iteration 26, average log likelihood -1.410494
[ Info: iteration 27, average log likelihood -1.410472
[ Info: iteration 28, average log likelihood -1.410453
[ Info: iteration 29, average log likelihood -1.410434
[ Info: iteration 30, average log likelihood -1.410416
[ Info: iteration 31, average log likelihood -1.410399
[ Info: iteration 32, average log likelihood -1.410382
[ Info: iteration 33, average log likelihood -1.410367
[ Info: iteration 34, average log likelihood -1.410351
[ Info: iteration 35, average log likelihood -1.410337
[ Info: iteration 36, average log likelihood -1.410323
[ Info: iteration 37, average log likelihood -1.410310
[ Info: iteration 38, average log likelihood -1.410297
[ Info: iteration 39, average log likelihood -1.410284
[ Info: iteration 40, average log likelihood -1.410273
[ Info: iteration 41, average log likelihood -1.410261
[ Info: iteration 42, average log likelihood -1.410250
[ Info: iteration 43, average log likelihood -1.410240
[ Info: iteration 44, average log likelihood -1.410230
[ Info: iteration 45, average log likelihood -1.410220
[ Info: iteration 46, average log likelihood -1.410211
[ Info: iteration 47, average log likelihood -1.410202
[ Info: iteration 48, average log likelihood -1.410194
[ Info: iteration 49, average log likelihood -1.410186
[ Info: iteration 50, average log likelihood -1.410178
┌ Info: EM with 100000 data points 50 iterations avll -1.410178
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4122590203863372
│     -1.412199611876724
│      ⋮
└     -1.4101782258016466
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410179
[ Info: iteration 2, average log likelihood -1.410114
[ Info: iteration 3, average log likelihood -1.410052
[ Info: iteration 4, average log likelihood -1.409982
[ Info: iteration 5, average log likelihood -1.409895
[ Info: iteration 6, average log likelihood -1.409789
[ Info: iteration 7, average log likelihood -1.409662
[ Info: iteration 8, average log likelihood -1.409519
[ Info: iteration 9, average log likelihood -1.409365
[ Info: iteration 10, average log likelihood -1.409209
[ Info: iteration 11, average log likelihood -1.409058
[ Info: iteration 12, average log likelihood -1.408917
[ Info: iteration 13, average log likelihood -1.408788
[ Info: iteration 14, average log likelihood -1.408674
[ Info: iteration 15, average log likelihood -1.408573
[ Info: iteration 16, average log likelihood -1.408484
[ Info: iteration 17, average log likelihood -1.408406
[ Info: iteration 18, average log likelihood -1.408337
[ Info: iteration 19, average log likelihood -1.408276
[ Info: iteration 20, average log likelihood -1.408223
[ Info: iteration 21, average log likelihood -1.408175
[ Info: iteration 22, average log likelihood -1.408132
[ Info: iteration 23, average log likelihood -1.408094
[ Info: iteration 24, average log likelihood -1.408059
[ Info: iteration 25, average log likelihood -1.408028
[ Info: iteration 26, average log likelihood -1.407999
[ Info: iteration 27, average log likelihood -1.407972
[ Info: iteration 28, average log likelihood -1.407947
[ Info: iteration 29, average log likelihood -1.407924
[ Info: iteration 30, average log likelihood -1.407903
[ Info: iteration 31, average log likelihood -1.407882
[ Info: iteration 32, average log likelihood -1.407863
[ Info: iteration 33, average log likelihood -1.407845
[ Info: iteration 34, average log likelihood -1.407827
[ Info: iteration 35, average log likelihood -1.407811
[ Info: iteration 36, average log likelihood -1.407795
[ Info: iteration 37, average log likelihood -1.407780
[ Info: iteration 38, average log likelihood -1.407765
[ Info: iteration 39, average log likelihood -1.407751
[ Info: iteration 40, average log likelihood -1.407738
[ Info: iteration 41, average log likelihood -1.407725
[ Info: iteration 42, average log likelihood -1.407712
[ Info: iteration 43, average log likelihood -1.407700
[ Info: iteration 44, average log likelihood -1.407688
[ Info: iteration 45, average log likelihood -1.407677
[ Info: iteration 46, average log likelihood -1.407666
[ Info: iteration 47, average log likelihood -1.407655
[ Info: iteration 48, average log likelihood -1.407644
[ Info: iteration 49, average log likelihood -1.407634
[ Info: iteration 50, average log likelihood -1.407624
┌ Info: EM with 100000 data points 50 iterations avll -1.407624
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4101789160241254
│     -1.4101136593837313
│      ⋮
└     -1.4076236973519096
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.420001680535428
│     -1.4200202393048968
│     -1.4199622473677034
│     -1.4199207725047434
│      ⋮
│     -1.4076442616179823
│     -1.407633875001336
└     -1.4076236973519096
32×26 Array{Float64,2}:
 -0.0824806   -0.160134   -0.355875   -0.516195    0.23317     0.00662706   -0.494115     0.262568   -0.015109    0.559502   -0.514733     -0.0209078    0.400918   -0.434836    0.179101     0.671541    0.525796    0.503803    0.138273   -0.0244726     0.517262     0.0269968   -0.0514883   -0.0872085   0.697921   -0.071321
 -0.414375     0.150026   -0.393709    0.182716    0.450706    0.0226606     0.744448     0.09232     0.159572    0.119122    0.0274198    -0.0712186    0.158713   -0.13751    -0.0355598    0.055691   -0.657918    0.289522    0.205124    0.331406      0.493537     0.0504125   -0.192382    -0.0172812   0.561597    0.328614
  0.538054     0.464704   -0.12844    -0.231137   -0.424926   -0.147937      0.111892     0.454596    0.264147    0.626027   -0.000862015   0.103416    -0.302982   -0.565993   -0.666083    -0.0952347  -0.364571    0.0208922   0.276078   -0.568635     -0.0669117   -0.0778393    0.282213    -0.519724   -0.04144     0.356321
  0.641524     0.24242     0.263637   -0.140526   -0.0536432   0.0163721     0.175238    -0.263685   -0.0257565  -0.300344    0.107621      0.10183      0.437497   -0.470493   -0.745226     0.706524   -0.393212    0.262232    0.0580233   0.0395194     0.520965     0.0358881   -0.335454    -0.157765   -0.14095    -0.332423
 -0.0268106    0.285427    0.0658663   0.538139    0.509188    0.324429     -0.383433     0.0484117   0.136361    0.545506   -0.180134      0.143135    -0.736191    0.194676   -0.0458966    0.349113   -0.331684   -0.509492    0.747576   -0.0439489     0.638416    -0.101536     0.239644     0.658492    0.297801   -0.465913
 -0.00130203  -0.0427225  -0.0334274   0.216694    0.401618    0.568968     -0.3129       0.0729007   0.330504    0.278368    0.375147      0.0587916   -0.676052    0.542569    0.37289     -0.168197    0.240226    0.632971    0.5727      0.41804       0.379493     0.237518    -0.122836    -0.179115    0.15056     0.165686
 -0.356507    -0.473975    0.266846    0.443483    0.938338    0.425959     -0.481445    -0.128764   -0.0136825  -0.495524   -0.203865     -0.277714     0.432995    0.474627    0.141277     0.135968    0.156873   -0.12083    -0.749843    0.377649     -0.0262843    0.420377     0.094404     0.750686    0.221987   -0.405618
 -0.0387338    0.116495    0.257254   -0.0682549   0.573849    0.00183261    0.119878     0.149439    0.22694     0.228904    0.515314      0.0444772    0.340427    0.487668    0.255402     0.0740535  -0.0695325   0.244704    0.612168    0.704503     -0.119874     0.480918    -0.27982     -0.297566    0.380291   -1.1191
 -0.289085    -0.185446   -0.108906    0.505118    0.0124714   0.379701      0.276321     0.220469   -0.24487    -0.316997    0.600991     -0.0792951   -0.291643    0.490185    0.0167607   -0.519983    0.402598   -0.657326    0.0708633  -0.235147     -0.489039    -0.0188768   -0.232989    -0.207145   -0.743834   -0.217679
 -0.0315614   -0.217173   -0.0299092  -0.445172   -0.569849   -0.398796      0.23381      0.0737892  -0.298374   -0.658791    0.212316      0.223214     0.700263   -0.0885319   0.0541692   -0.327711    0.217767    0.211976   -0.473485    0.000413058  -0.937654     0.239705    -0.123241    -0.529368   -0.372022    0.172823
  0.0171001    0.443741   -1.08576    -0.293977    0.488111    0.121761     -0.523591    -0.0848899  -0.500813   -0.0617606   0.0931177    -0.432909    -0.315113   -0.346182   -0.0344615   -0.246873    0.231976    0.26889    -0.164571    0.245544     -0.0438231    0.392192     0.882418     0.119479   -0.277017    0.170393
 -0.171305     0.487662    0.659158   -0.294518    0.0178659   0.228193     -0.244193    -0.825842    0.252485    0.17736     0.0487966    -0.0175467   -0.346231    0.24605    -0.416326    -0.0141316   0.296357    0.455547    0.374722   -0.204365     -0.110356     0.262353     0.567606     0.41592    -0.377373    0.200887
  0.505446     0.403668    0.280874   -0.523063   -0.0369684  -0.278131     -0.104178     0.367305   -0.0826413  -0.155622   -0.181447     -0.00967993  -0.189346   -0.0933225   0.557802     0.762583   -0.341541   -0.324631   -0.831068   -0.315013     -0.20581     -0.378201    -0.305947     0.385762    0.404541   -0.172734
  0.569461    -0.0896588   0.259585   -0.137913   -0.256257    0.715357     -0.432174     0.50943    -0.205969    0.238364   -0.765592      0.233525     0.0297971   0.308817    0.144135    -0.274344    0.210481   -0.642097   -0.433337   -0.26002       0.0391693   -0.276494     0.0476145    0.39408    -0.0118435   0.115614
 -0.252363    -0.467584    0.414547    0.400164   -0.469134   -0.357606      0.299583     0.652464    0.368325    0.0739653   0.0952344     0.496017    -0.0528025   0.0649124   0.625363    -0.152456   -0.0650327  -0.273879    0.152144   -0.122449      0.251638    -0.567351    -0.673476    -0.443797    0.612688   -0.080212
  0.0229409   -0.108623    0.199995   -0.0685714  -0.351468   -0.180603      0.0947808   -0.100629   -0.110997   -0.315022   -0.191569      0.156717     0.217396   -0.0527233  -0.00137825   0.0425346  -0.106689   -0.292619   -0.175204   -0.179983     -0.162686    -0.272516    -0.0606002    0.157995   -0.255923    0.0692041
 -0.115814    -0.12547    -0.135939    0.310346   -0.322445   -0.372897     -0.180209     0.138365   -0.0178748  -0.25794    -0.899295     -0.231532     0.140654    0.133159    0.275926    -0.435155    0.486747    0.24922     0.248741   -0.188664      0.263024    -0.453984     0.496092     0.017375   -0.0420655   0.136698
 -0.518877    -0.263915   -0.164378   -0.113952    0.167035   -0.575766     -0.29706     -0.309631   -0.0205068   0.613919   -0.400014      0.378164    -0.28353     0.475763    0.123604    -0.424117    0.102259    0.0215424   0.140225   -0.311992     -0.412183     0.461861     0.219003     0.259987    0.255356    0.248988
  0.0366769   -0.005351   -0.214131    0.0424464   0.121312   -0.0670216    -0.00513058  -0.0385931  -0.102319   -0.0723644  -0.0823082    -0.18208      0.0341867  -0.0827486  -0.0723275   -0.0912351   0.215255    0.0529901  -0.104268   -0.177294      0.056489     0.00358737   0.120276    -0.077502   -0.117006    0.293941
  0.0718706    0.120872   -0.142032   -0.030248    0.190876    0.26312      -0.139567     0.157888   -0.0497507   0.222106   -0.206813     -0.135062    -0.051976   -0.0902245  -0.0117728    0.388708   -0.13518     0.264799    0.132447    0.197621      0.301845    -0.0290145    0.207669     0.0789773   0.44949    -0.0738225
  0.0845074   -0.229325   -0.226025   -0.912287   -0.0104496   0.188911     -0.574093    -0.336983   -0.591888   -0.110144   -0.162079      0.0354775    0.0554489  -0.297255   -0.618586     0.286725   -0.120165   -0.275551   -0.231852    0.216543     -0.720459     0.160348     0.00208655   0.347186   -0.66977    -0.178732
  0.123944     0.355788    0.11188     0.573237   -0.258508    0.000366139  -0.12973     -0.0576167  -0.28868    -0.508171   -0.310471      0.21138      0.127248   -0.278563   -0.490449    -0.0386739  -0.134512   -0.256769   -0.296251   -0.191015     -0.00209066  -0.0396736    0.633917     0.416282   -0.53504    -0.268124
  0.257442     0.101417   -0.510529   -0.303725    0.219275   -0.287234     -0.600149    -0.807919    0.35116    -0.106841    0.222006     -0.482193    -0.246518   -0.0455901   0.0674533    0.383336    0.0399181   0.906857    0.19413     0.0467358    -0.265866     0.179842     0.345905    -0.0839139  -0.172939    0.114518
  0.413193     0.292786    0.52065    -0.343272    0.130005   -0.403171     -0.38752     -0.619919   -0.0670825  -0.0169767  -0.465041      0.0480498    0.121259    0.73242     0.274902     0.290221    0.384779    0.479968   -0.307501   -0.101453     -0.48975     -0.160642     0.42129     -0.0786784  -0.247068   -0.365467
 -0.380153    -0.375532   -0.507281   -0.384972   -0.415827   -0.0427076     0.279345     0.0557523  -0.150371   -0.175539    0.0471891    -0.310866     0.352634   -0.574138    0.172367    -0.172797   -0.0168259  -0.229173   -0.110293    0.0251182     0.0527298   -0.435904    -0.151553     0.157213   -0.145857    0.362531
  0.0670128   -0.39944     0.750654   -0.300738   -0.40556     0.080761      0.150583    -0.344733   -0.0371116  -0.262516    0.263412      0.233601     0.12992    -0.394243    0.189819     0.0408359   0.0772114  -0.153603    0.0582317  -0.0269855     0.0824291   -0.415839    -0.496711    -0.222248   -0.0711147   0.370897
  0.475767     0.132101    0.0229078   0.87413     0.260146   -0.00861012    0.327946     0.475124   -0.322476   -0.24365    -0.057427     -0.227166    -0.370114   -0.156867    0.100095    -0.593811   -0.358271    0.0678113   0.0224794  -0.382282      0.373436    -0.290688    -0.140423    -0.343268    0.405129   -0.55582
  0.0656123    0.0498312  -0.156971    0.572307    0.293133    0.10766       0.616426     0.170621    0.0667325  -0.335904    0.360479     -0.524781    -0.111189   -0.228251    0.089021    -0.192652    0.490251    0.0380353  -0.175496   -0.190843      0.567606    -0.221443    -0.126749    -0.614605   -0.0692372   0.777678
 -0.2264       0.284325   -0.0345921  -0.121485    0.254296    0.0890012     0.250314    -0.233489   -0.387641   -0.0394924   0.815825     -0.183861    -0.183319   -0.0154171  -0.171542     0.0586143  -0.0663109  -0.0923848   0.0597717   0.107023     -0.103063     0.392898    -0.139686     0.0417417  -0.469489    0.0364882
 -0.542287     0.105632    0.0602554   0.0492835  -0.127129   -0.297661      0.381013     0.0395436   0.80685     0.234896    0.254763     -0.0701962    0.231667    0.27578    -0.18948     -0.072638   -0.535771   -0.0130935   0.207974    0.0104083    -0.428094     0.242014     0.127612    -0.160069   -0.0253768   0.279327
  0.0601506    0.0196638   0.253659   -0.129627   -0.0149428  -0.0811971    -0.355545    -0.0571054  -0.0137104  -0.0549676  -0.0660678     0.346928    -0.0349512   0.302594    0.119069    -0.0231076  -0.0394556  -0.0586761  -0.051771    0.00208452   -0.271919     0.0634783   -0.0494689    0.0783631  -0.0658458  -0.447704
 -0.273888    -0.0577296   0.385376    0.249615   -0.0493426  -0.080294      0.642457     0.401719   -0.104297   -0.0614652  -0.0237096     0.302353     0.230303    0.266359    0.0388164   -0.150812   -0.125345   -0.541781   -0.0147787  -0.157436      0.0589295   -0.156957    -0.321234     0.193391    0.0470367  -0.185344[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407614
[ Info: iteration 2, average log likelihood -1.407604
[ Info: iteration 3, average log likelihood -1.407594
[ Info: iteration 4, average log likelihood -1.407585
[ Info: iteration 5, average log likelihood -1.407575
[ Info: iteration 6, average log likelihood -1.407566
[ Info: iteration 7, average log likelihood -1.407557
[ Info: iteration 8, average log likelihood -1.407548
[ Info: iteration 9, average log likelihood -1.407538
[ Info: iteration 10, average log likelihood -1.407529
┌ Info: EM with 100000 data points 10 iterations avll -1.407529
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.577877e+05
      1       7.025459e+05      -2.552419e+05 |       32
      2       6.876518e+05      -1.489409e+04 |       32
      3       6.820788e+05      -5.572994e+03 |       32
      4       6.791662e+05      -2.912609e+03 |       32
      5       6.773358e+05      -1.830409e+03 |       32
      6       6.760211e+05      -1.314662e+03 |       32
      7       6.749994e+05      -1.021703e+03 |       32
      8       6.741925e+05      -8.069470e+02 |       32
      9       6.735592e+05      -6.332363e+02 |       32
     10       6.729843e+05      -5.748858e+02 |       32
     11       6.724709e+05      -5.134583e+02 |       32
     12       6.720413e+05      -4.295587e+02 |       32
     13       6.716701e+05      -3.711941e+02 |       32
     14       6.713301e+05      -3.400462e+02 |       32
     15       6.709984e+05      -3.317238e+02 |       32
     16       6.707173e+05      -2.810150e+02 |       32
     17       6.704735e+05      -2.438377e+02 |       32
     18       6.702528e+05      -2.207428e+02 |       32
     19       6.700707e+05      -1.820272e+02 |       32
     20       6.699216e+05      -1.491279e+02 |       32
     21       6.697906e+05      -1.310010e+02 |       32
     22       6.696675e+05      -1.230605e+02 |       32
     23       6.695511e+05      -1.164551e+02 |       32
     24       6.694406e+05      -1.105243e+02 |       32
     25       6.693369e+05      -1.036253e+02 |       32
     26       6.692506e+05      -8.638741e+01 |       32
     27       6.691644e+05      -8.616750e+01 |       32
     28       6.690718e+05      -9.258033e+01 |       32
     29       6.689913e+05      -8.045525e+01 |       32
     30       6.689184e+05      -7.292097e+01 |       32
     31       6.688498e+05      -6.862756e+01 |       32
     32       6.687871e+05      -6.270850e+01 |       32
     33       6.687335e+05      -5.360412e+01 |       32
     34       6.686863e+05      -4.721514e+01 |       32
     35       6.686412e+05      -4.507025e+01 |       32
     36       6.685915e+05      -4.970254e+01 |       32
     37       6.685450e+05      -4.653508e+01 |       32
     38       6.684974e+05      -4.760069e+01 |       32
     39       6.684538e+05      -4.360859e+01 |       32
     40       6.684138e+05      -3.993135e+01 |       32
     41       6.683784e+05      -3.537639e+01 |       32
     42       6.683473e+05      -3.114724e+01 |       32
     43       6.683245e+05      -2.279804e+01 |       32
     44       6.683035e+05      -2.097580e+01 |       32
     45       6.682819e+05      -2.165419e+01 |       32
     46       6.682615e+05      -2.036244e+01 |       32
     47       6.682420e+05      -1.953716e+01 |       32
     48       6.682228e+05      -1.915424e+01 |       32
     49       6.682030e+05      -1.986798e+01 |       32
     50       6.681847e+05      -1.827656e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 668184.6742753256)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419052
[ Info: iteration 2, average log likelihood -1.414058
[ Info: iteration 3, average log likelihood -1.412875
[ Info: iteration 4, average log likelihood -1.412114
[ Info: iteration 5, average log likelihood -1.411266
[ Info: iteration 6, average log likelihood -1.410289
[ Info: iteration 7, average log likelihood -1.409426
[ Info: iteration 8, average log likelihood -1.408868
[ Info: iteration 9, average log likelihood -1.408559
[ Info: iteration 10, average log likelihood -1.408379
[ Info: iteration 11, average log likelihood -1.408257
[ Info: iteration 12, average log likelihood -1.408164
[ Info: iteration 13, average log likelihood -1.408088
[ Info: iteration 14, average log likelihood -1.408023
[ Info: iteration 15, average log likelihood -1.407966
[ Info: iteration 16, average log likelihood -1.407917
[ Info: iteration 17, average log likelihood -1.407872
[ Info: iteration 18, average log likelihood -1.407833
[ Info: iteration 19, average log likelihood -1.407797
[ Info: iteration 20, average log likelihood -1.407764
[ Info: iteration 21, average log likelihood -1.407734
[ Info: iteration 22, average log likelihood -1.407707
[ Info: iteration 23, average log likelihood -1.407681
[ Info: iteration 24, average log likelihood -1.407658
[ Info: iteration 25, average log likelihood -1.407636
[ Info: iteration 26, average log likelihood -1.407616
[ Info: iteration 27, average log likelihood -1.407597
[ Info: iteration 28, average log likelihood -1.407579
[ Info: iteration 29, average log likelihood -1.407562
[ Info: iteration 30, average log likelihood -1.407546
[ Info: iteration 31, average log likelihood -1.407530
[ Info: iteration 32, average log likelihood -1.407516
[ Info: iteration 33, average log likelihood -1.407502
[ Info: iteration 34, average log likelihood -1.407489
[ Info: iteration 35, average log likelihood -1.407476
[ Info: iteration 36, average log likelihood -1.407463
[ Info: iteration 37, average log likelihood -1.407451
[ Info: iteration 38, average log likelihood -1.407440
[ Info: iteration 39, average log likelihood -1.407428
[ Info: iteration 40, average log likelihood -1.407417
[ Info: iteration 41, average log likelihood -1.407406
[ Info: iteration 42, average log likelihood -1.407395
[ Info: iteration 43, average log likelihood -1.407385
[ Info: iteration 44, average log likelihood -1.407375
[ Info: iteration 45, average log likelihood -1.407365
[ Info: iteration 46, average log likelihood -1.407355
[ Info: iteration 47, average log likelihood -1.407345
[ Info: iteration 48, average log likelihood -1.407335
[ Info: iteration 49, average log likelihood -1.407325
[ Info: iteration 50, average log likelihood -1.407316
┌ Info: EM with 100000 data points 50 iterations avll -1.407316
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.162635     0.0661062   -0.489035    -0.345537     0.444666    0.441953    -0.448301    -0.454041   -0.795366     -0.30542     -0.230631    -0.23703     -0.101992   -0.141092    -0.707824    0.123051    -0.128275    -0.13884    -0.171199    0.247144   -0.571653    0.42885      0.254451     0.506442   -0.870929   -0.051557
 -0.50918      0.056649    -0.572569     0.066542     0.320228   -0.16781      0.821714     0.384712   -0.295229      0.410271     0.405104    -0.0126163    0.115313    0.432817     0.145098    0.16073     -0.598459    -0.449172    0.252894   -0.022667   -0.0917515   0.0738671   -0.717027     0.277964    0.36997    -0.0660975
 -0.223581    -0.310237     0.468884     0.470458    -0.462645   -0.460453     0.388475     0.627159    0.626306      0.139697     0.0464969    0.204833     0.0146948   0.347111     0.641491   -0.182279     0.00378109  -0.0527842   0.306672   -0.240975    0.233769   -0.444412    -0.39232     -0.41955     0.693669    0.0302582
  0.466455     0.201855    -0.109867     0.359549     0.218126    0.028953     0.00212219   0.19147    -0.217205     -0.369504     0.0846255   -0.314243    -0.0650766  -0.364604    -0.117616    0.00193943   0.203705    -0.0417381  -0.465884   -0.367873    0.35826    -0.213332     0.109037    -0.31699    -0.147007    0.213358
 -0.686369    -0.581967     0.16761      0.242943     0.692274    0.331179    -0.438357     0.0541101   0.104596     -0.255655    -0.0545322   -0.0151937    0.225483    0.59101      0.42929    -0.157753     0.24859     -0.288892   -0.569434    0.314071   -0.319896    0.249692     0.0923159    0.541783    0.20062    -0.258471
 -0.193214    -0.204924     0.0558767   -0.650767    -0.658556   -0.251403     0.178074    -0.172716   -0.119807     -0.395125     0.591308     0.0194216    0.571564   -0.0801196   -0.115791   -0.109445     0.253986     0.153072   -0.256144    0.0152211  -0.8782      0.345524    -0.098659    -0.340511   -0.512543    0.45229
  0.319426     0.112265     0.147858     0.361818     0.219419    0.115563    -0.267627     0.460944   -0.188819      0.00853757  -0.852358     0.215636    -0.159948    0.211522     0.18339    -0.146278    -0.110337     0.0498675   0.015276   -0.271301    0.524699   -0.383138    -0.00740389   0.0786529   0.50537    -0.545617
  0.0387712   -0.0519187   -0.0380838   -0.225243     0.171285   -0.187313    -0.380379    -0.485547    0.121746     -0.0992758    0.287715     0.354808    -0.473371    0.212245     0.310254   -0.0076434   -0.0479715    0.132964    0.1021     -0.0134564  -0.54199     0.0725453   -0.219202    -0.0256083  -0.186741   -0.139612
 -0.205466     0.0473935    0.0114891    0.364301    -0.287185   -0.565245     0.239966     0.242164   -0.140669     -0.541733    -0.631604    -0.0164034    0.491964    0.226132     0.0641679  -0.632873     0.0551813   -0.0587282  -0.100163   -0.043518   -0.252333   -0.209221     0.467624    -0.0362116  -0.206893   -0.368571
  0.116839     0.219021    -0.419557     0.0156133   -0.740761    0.272475    -0.28208      0.0776112  -0.0654571    -0.00957058  -0.399066    -0.419536    -0.418715    0.027619     0.583344   -0.41359      0.754653    -0.197831    0.311472    0.0528628   0.127099   -0.420443     0.760385     0.152814   -0.73735     0.527143
  0.586025     0.342991    -0.15482     -0.276964     0.0989515  -0.204937    -0.323868    -0.427826    0.426927     -0.182019     0.103756    -0.589921     0.397111   -0.0278168   -0.06654     0.522932    -0.34935      0.479702    0.0503252   0.513504    0.0295493  -0.00110984   0.033045    -0.0526619  -0.0469694  -0.316983
 -0.225929     0.0160881    0.00889766   0.2882       0.612403    0.24354      0.142553     0.153396    0.226926      0.340554     0.678962     0.0335811   -0.270222    0.508081     0.14776    -0.122494    -0.10872      0.514418    0.701151    0.406534    0.0695975   0.61031      0.0957702   -0.47034     0.266123   -0.318659
  0.0435549    0.054902     0.138302    -0.0144666   -0.0372583  -0.132526     0.00656509  -0.0548822  -0.0360802    -0.13282     -0.239381     0.213079     0.179476    0.00320549   0.0217959   0.237117    -0.192711    -0.0113124  -0.14861    -0.0594967   0.023705   -0.161129    -0.0656758    0.118947    0.0994121  -0.0670005
  0.236524    -0.495045     0.349938    -0.462688     0.40051     0.274524    -0.244616    -0.251123    0.0873155     0.200852     0.185381     0.0248268    0.131144    0.0596862    0.527519    0.130859     0.751843     0.21813     0.403049    0.403108    0.452203    0.163194    -0.955439    -0.178144    0.0713404   0.0852838
 -0.0310748   -0.0157766   -0.202341    -0.0847883    0.0661522  -0.156462    -0.262093    -0.084946   -0.211661      0.149235    -0.199235     0.0259795    0.096801    0.151983    -0.11448    -0.0121677    0.201152     0.0178102  -0.0710309  -0.195719   -0.164068    0.306049     0.250142     0.206898   -0.117386    0.0106204
  0.415529     0.495642    -0.0824526   -0.351931    -0.668099   -0.340485     0.38012      0.144161    0.000532396   0.31159      0.168506     0.208361    -0.244647   -0.781028    -0.319651    0.190459    -0.118145     0.296111    0.481148   -0.485859    0.417662   -0.242568     0.0472747   -0.661045    0.0650555   0.330109
 -0.275756    -0.284052    -0.742308    -0.192811     0.338999   -0.199328    -0.258872     0.0324139   0.0176078     0.317051    -0.616999    -0.416001     0.198064   -0.139079     0.223637    0.147283     0.371969     0.561756    0.0728089  -0.0530524   0.283358   -0.0295542    0.385793     0.0141479   0.559773    0.33388
 -0.403562    -0.0853857    0.276694    -0.0862739    0.302955   -0.243168     0.0636512   -0.574646    0.4921        0.557629    -0.340649     0.23496     -0.713099    0.163675    -0.415604   -0.414136    -0.319599     0.115759    0.323571   -0.510293   -0.335421    0.306015     0.530912     0.445724    0.104752    0.54511
 -0.165081    -0.0924037   -0.258646     0.240607    -0.0209989   0.347521     0.705309     0.825592    0.324744     -0.388017     0.00273411  -0.116689     0.396783   -0.908914     0.0397374  -0.450946    -0.454455    -0.154286    0.0695785   0.104093    0.645938    0.00842589  -0.50071     -0.218544    0.396708    0.310985
 -0.15354     -0.0568324    0.0321063   -0.0594944   -0.0197645   0.0925092    0.207588     0.0558048   0.0340917     0.00938309   0.0908662   -0.0736189    0.013129   -0.0793141    0.0453794   0.0308344   -0.0694419    0.0370108   0.116264    0.0964632   0.139574   -0.140506    -0.0865451   -0.0643464   0.0980802   0.12534
 -0.219468     0.110006    -0.0647364    0.460179     0.348453    0.379606     0.908598    -0.172259   -0.0391413    -0.401229     0.789296    -0.653107    -0.414017   -0.121674    -0.154879   -0.183173    -0.0200123   -0.123804   -0.189481    0.281604    0.126857   -0.458611    -0.405418    -0.481869   -0.374436    0.55591
 -0.21698     -0.293808    -0.147234     0.785614    -0.0568635   0.128671     0.0892399    0.4307     -0.180651     -0.342641     0.389491    -0.00715917  -0.243523    0.408078     0.0629842  -0.879092     0.664245    -0.43797     0.16014    -0.444336   -0.288836    0.0607498    0.0243765   -0.446096   -0.623697   -0.265423
 -0.27383      0.86476      0.203934     0.172799    -0.36538     0.0710168   -0.0749388    0.269698    0.404798      0.410959    -0.0104901    0.171443     0.292899    0.0452537   -0.655809    0.0939751   -0.714886    -0.121648    0.143397    0.112036   -0.333087    0.059849     0.46111     -0.0373995  -0.26126    -0.0915049
  0.172638    -0.00801325   0.572367     0.116341     0.553511   -0.00823735   0.34699     -0.361669   -0.059941     -0.044012     0.272204     0.395366     0.602189   -0.0046538   -0.755301    0.589574    -0.356363     0.210665   -0.141824   -0.164524    0.341015    0.586501    -0.721986     0.052268    0.180131   -0.512295
 -0.123416     0.542541    -0.84731     -0.297245     0.587539    0.0374302   -0.356442    -0.17213    -0.297341     -0.00666917   0.461887    -0.454463    -0.30775    -0.345973    -0.107286    0.103293     0.145711     0.587711   -0.0806114   0.162182    0.211301    0.492997     0.766162     0.113354   -0.0780621   0.115986
  0.06086      0.354082     0.094243     0.380756     0.45027     0.48668     -0.249811     0.0452539   0.0707199     0.466756    -0.130246     0.00934512  -0.663243    0.135022     0.0537183   0.398854    -0.320209    -0.175727    0.433851    0.279035    0.764039   -0.121527     0.206956     0.48786     0.44179    -0.16475
  0.109813    -0.419621     0.0342092   -0.52239     -0.681148   -0.0667784   -0.0616384    0.0160555  -0.359786     -0.121787    -0.278704     0.416563     0.335      -0.418347     0.0113963   0.095095    -0.459415    -0.277823   -0.281561    0.261759   -0.528317   -0.639028    -0.339718    -0.024469   -0.0164949  -0.379036
  0.754074     0.263909     0.478228    -0.741531    -0.206079   -0.00985887  -0.27459      0.623007   -0.0925493    -0.0668673   -0.363083    -0.196726    -0.296879    0.0590158    0.482609    0.383018     0.0285445   -0.775509   -0.702373   -0.643108   -0.236162   -0.36219     -0.30992      0.523896    0.0961325  -0.160447
 -0.200914    -0.408508     0.260277     0.00271194  -0.483522   -0.175296     0.310936    -0.420698   -0.118534     -0.269966    -0.309025     0.105348     0.481737   -0.417064    -0.061223   -0.171655     0.25585     -0.389397   -0.26753    -0.51512     0.170736   -0.587736    -0.144625     0.212052   -0.359508    0.71763
  0.442332     0.426524     0.608435    -0.255188     0.123179   -0.102432    -0.39685     -0.523059   -0.151916      0.122639    -0.579716     0.163832    -0.0344804   0.757291     0.0710202   0.215152     0.464011     0.763501   -0.220777   -0.20989    -0.450541   -0.0490368    0.708342    -0.0492025  -0.20348    -0.276761
 -0.00589211   0.203014     0.566475     0.21941     -0.184016    0.205642     0.380773     0.332835   -0.43099      -0.262287     0.424661     0.339948    -0.106814    0.191725    -0.109339   -0.254419    -0.170924    -0.736823   -0.0878978  -0.14376    -0.157349    0.0826083   -0.289383     0.186042   -0.415276   -0.262279
  0.0561947   -0.116749     0.684844     0.250458    -0.401794   -0.0501932   -0.945503    -0.109429    0.0579327    -0.624927    -0.145074     0.363694     0.113237   -0.410477    -0.420728    0.356183     0.37913     -0.414619    0.0516441  -0.0466946   0.297226    0.525743     0.685144     0.760683   -0.26854    -0.738217[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407307
[ Info: iteration 2, average log likelihood -1.407297
[ Info: iteration 3, average log likelihood -1.407288
[ Info: iteration 4, average log likelihood -1.407280
[ Info: iteration 5, average log likelihood -1.407271
[ Info: iteration 6, average log likelihood -1.407262
[ Info: iteration 7, average log likelihood -1.407254
[ Info: iteration 8, average log likelihood -1.407246
[ Info: iteration 9, average log likelihood -1.407238
[ Info: iteration 10, average log likelihood -1.407230
┌ Info: EM with 100000 data points 10 iterations avll -1.407230
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
