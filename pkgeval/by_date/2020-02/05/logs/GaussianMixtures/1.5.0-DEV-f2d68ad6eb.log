Julia Version 1.5.0-DEV.234
Commit f2d68ad6eb (2020-02-05 16:31 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed GaussianMixtures ─── v0.3.0
  Installed LegacyStrings ────── v0.4.1
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed Rmath ────────────── v0.6.0
  Installed Compat ───────────── v2.2.0
  Installed Blosc ────────────── v0.5.1
  Installed NearestNeighbors ─── v0.4.4
  Installed QuadGK ───────────── v2.3.1
  Installed PDMats ───────────── v0.9.11
  Installed CMake ────────────── v1.1.2
  Installed SpecialFunctions ─── v0.9.0
  Installed SortingAlgorithms ── v0.3.1
  Installed CMakeWrapper ─────── v0.2.3
  Installed Arpack ───────────── v0.4.0
  Installed BinaryProvider ───── v0.5.8
  Installed URIParser ────────── v0.4.0
  Installed Missings ─────────── v0.4.3
  Installed OrderedCollections ─ v1.1.0
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed StaticArrays ─────── v0.12.1
  Installed HDF5 ─────────────── v0.12.5
  Installed Clustering ───────── v0.13.3
  Installed Distributions ────── v0.22.4
  Installed BinDeps ──────────── v1.0.0
  Installed ScikitLearnBase ──── v0.5.0
  Installed DataAPI ──────────── v1.1.0
  Installed Distances ────────── v0.8.2
  Installed FileIO ───────────── v1.2.1
  Installed StatsFuns ────────── v0.9.3
  Installed Parameters ───────── v0.12.0
  Installed StatsBase ────────── v0.32.0
  Installed Arpack_jll ───────── v3.5.0+2
  Installed JLD ──────────────── v0.9.2
  Installed FillArrays ───────── v0.8.4
  Installed DataStructures ───── v0.17.9
#=#=#                                                                         #                                                                          2.6%#####                                                                      8.1%###########                                                               15.4%##################                                                        25.0%#########################                                                 36.0%####################################                                      50.5%#############################################                             63.4%##############################################################            86.9%######################################################################## 100.0%
#=#=#                                                                         ##O#- #                                                                       ##O=#  #                                                                      #=#=-#  #                                                                     -#O#- #   #                                                                   ######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_cLlHw3/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -3.725367004489478e6, [2311.3504316157246, 97688.6495683843], [4397.324668907499 1885.253891009181 1856.0216307333317; -4475.776038485869 -1765.8152088080496 -2449.348981884433], [[8964.570008431207 3294.253324078646 2690.190673101687; 3294.253324078646 3277.188886383504 1269.6248340465324; 2690.190673101687 1269.6248340465324 3511.1632942400265], [91543.45455745235 -3003.859453350577 -2495.2971060644377; -3003.8594533505775 96888.76488880636 -1217.9690240315845; -2495.2971060644377 -1217.9690240315845 96138.19697509456]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.446815e+03
      1       1.141923e+03      -3.048916e+02 |        8
      2       1.002408e+03      -1.395151e+02 |        2
      3       9.721188e+02      -3.028957e+01 |        2
      4       9.615287e+02      -1.059007e+01 |        2
      5       9.413161e+02      -2.021265e+01 |        0
      6       9.413161e+02       0.000000e+00 |        0
K-means converged with 6 iterations (objv = 941.3160778374513)
┌ Info: K-means with 272 data points using 6 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.071869
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.861026
[ Info: iteration 2, lowerbound -3.748887
[ Info: iteration 3, lowerbound -3.624409
[ Info: iteration 4, lowerbound -3.466136
[ Info: iteration 5, lowerbound -3.286668
[ Info: iteration 6, lowerbound -3.115210
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.972044
[ Info: iteration 8, lowerbound -2.874210
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.814984
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.777732
[ Info: iteration 11, lowerbound -2.761216
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.744167
[ Info: iteration 13, lowerbound -2.719016
[ Info: iteration 14, lowerbound -2.685887
[ Info: iteration 15, lowerbound -2.638329
[ Info: iteration 16, lowerbound -2.576956
[ Info: iteration 17, lowerbound -2.508631
[ Info: iteration 18, lowerbound -2.444588
[ Info: iteration 19, lowerbound -2.392798
[ Info: iteration 20, lowerbound -2.353969
[ Info: iteration 21, lowerbound -2.326142
[ Info: iteration 22, lowerbound -2.310229
[ Info: iteration 23, lowerbound -2.308190
[ Info: dropping number of Gaussions to 2
[ Info: iteration 24, lowerbound -2.302916
[ Info: iteration 25, lowerbound -2.299259
[ Info: iteration 26, lowerbound -2.299256
[ Info: iteration 27, lowerbound -2.299254
[ Info: iteration 28, lowerbound -2.299254
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Thu Feb  6 02:08:24 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Thu Feb  6 02:08:31 2020: K-means with 272 data points using 6 iterations
11.3 data points per parameter
, Thu Feb  6 02:08:34 2020: EM with 272 data points 0 iterations avll -2.071869
5.8 data points per parameter
, Thu Feb  6 02:08:36 2020: GMM converted to Variational GMM
, Thu Feb  6 02:08:44 2020: iteration 1, lowerbound -3.861026
, Thu Feb  6 02:08:44 2020: iteration 2, lowerbound -3.748887
, Thu Feb  6 02:08:44 2020: iteration 3, lowerbound -3.624409
, Thu Feb  6 02:08:44 2020: iteration 4, lowerbound -3.466136
, Thu Feb  6 02:08:44 2020: iteration 5, lowerbound -3.286668
, Thu Feb  6 02:08:44 2020: iteration 6, lowerbound -3.115210
, Thu Feb  6 02:08:45 2020: dropping number of Gaussions to 7
, Thu Feb  6 02:08:45 2020: iteration 7, lowerbound -2.972044
, Thu Feb  6 02:08:45 2020: iteration 8, lowerbound -2.874210
, Thu Feb  6 02:08:45 2020: dropping number of Gaussions to 5
, Thu Feb  6 02:08:45 2020: iteration 9, lowerbound -2.814984
, Thu Feb  6 02:08:45 2020: dropping number of Gaussions to 4
, Thu Feb  6 02:08:45 2020: iteration 10, lowerbound -2.777732
, Thu Feb  6 02:08:45 2020: iteration 11, lowerbound -2.761216
, Thu Feb  6 02:08:45 2020: dropping number of Gaussions to 3
, Thu Feb  6 02:08:45 2020: iteration 12, lowerbound -2.744167
, Thu Feb  6 02:08:45 2020: iteration 13, lowerbound -2.719016
, Thu Feb  6 02:08:45 2020: iteration 14, lowerbound -2.685887
, Thu Feb  6 02:08:45 2020: iteration 15, lowerbound -2.638329
, Thu Feb  6 02:08:45 2020: iteration 16, lowerbound -2.576956
, Thu Feb  6 02:08:45 2020: iteration 17, lowerbound -2.508631
, Thu Feb  6 02:08:45 2020: iteration 18, lowerbound -2.444588
, Thu Feb  6 02:08:45 2020: iteration 19, lowerbound -2.392798
, Thu Feb  6 02:08:45 2020: iteration 20, lowerbound -2.353969
, Thu Feb  6 02:08:45 2020: iteration 21, lowerbound -2.326142
, Thu Feb  6 02:08:45 2020: iteration 22, lowerbound -2.310229
, Thu Feb  6 02:08:45 2020: iteration 23, lowerbound -2.308190
, Thu Feb  6 02:08:45 2020: dropping number of Gaussions to 2
, Thu Feb  6 02:08:45 2020: iteration 24, lowerbound -2.302916
, Thu Feb  6 02:08:45 2020: iteration 25, lowerbound -2.299259
, Thu Feb  6 02:08:45 2020: iteration 26, lowerbound -2.299256
, Thu Feb  6 02:08:45 2020: iteration 27, lowerbound -2.299254
, Thu Feb  6 02:08:45 2020: iteration 28, lowerbound -2.299254
, Thu Feb  6 02:08:45 2020: iteration 29, lowerbound -2.299253
, Thu Feb  6 02:08:45 2020: iteration 30, lowerbound -2.299253
, Thu Feb  6 02:08:45 2020: iteration 31, lowerbound -2.299253
, Thu Feb  6 02:08:45 2020: iteration 32, lowerbound -2.299253
, Thu Feb  6 02:08:45 2020: iteration 33, lowerbound -2.299253
, Thu Feb  6 02:08:45 2020: iteration 34, lowerbound -2.299253
, Thu Feb  6 02:08:45 2020: iteration 35, lowerbound -2.299253
, Thu Feb  6 02:08:45 2020: iteration 36, lowerbound -2.299253
, Thu Feb  6 02:08:45 2020: iteration 37, lowerbound -2.299253
, Thu Feb  6 02:08:45 2020: iteration 38, lowerbound -2.299253
, Thu Feb  6 02:08:45 2020: iteration 39, lowerbound -2.299253
, Thu Feb  6 02:08:45 2020: iteration 40, lowerbound -2.299253
, Thu Feb  6 02:08:45 2020: iteration 41, lowerbound -2.299253
, Thu Feb  6 02:08:45 2020: iteration 42, lowerbound -2.299253
, Thu Feb  6 02:08:45 2020: iteration 43, lowerbound -2.299253
, Thu Feb  6 02:08:45 2020: iteration 44, lowerbound -2.299253
, Thu Feb  6 02:08:45 2020: iteration 45, lowerbound -2.299253
, Thu Feb  6 02:08:45 2020: iteration 46, lowerbound -2.299253
, Thu Feb  6 02:08:45 2020: iteration 47, lowerbound -2.299253
, Thu Feb  6 02:08:45 2020: iteration 48, lowerbound -2.299253
, Thu Feb  6 02:08:45 2020: iteration 49, lowerbound -2.299253
, Thu Feb  6 02:08:45 2020: iteration 50, lowerbound -2.299253
, Thu Feb  6 02:08:45 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777397376, 178.04509222602616]
β = [95.95490777397376, 178.04509222602616]
m = [2.0002292577752665 53.851987172460746; 4.250300733269812 79.28686694436038]
ν = [97.95490777397376, 180.04509222602616]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.37587636119501244 -0.00895312382734806; 0.0 0.012748664777409874], [0.1840415554748328 -0.007644049042328394; 0.0 0.008581705166331643]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000009
avll from stats: -1.0053534479400745
avll from llpg:  -1.005353447940077
avll direct:     -1.005353447940077
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0225746315160247
avll from llpg:  -1.0225746315160247
avll direct:     -1.0225746315160247
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
 -0.087829    -0.0330744   -0.0295289   -0.0071923   0.127151    0.0213243    0.0223025   -0.0843085   -0.0401792   -0.0592973    0.00763549  -0.093852     0.0622057    0.0633886    0.0203718   -0.0094827    0.0644738    0.0153656     0.114975    -0.129819     0.114799     0.0674325    -0.187467    -0.0137901    0.217334     0.0191806
  0.0275859   -0.0132644    0.0134722   -0.100197   -0.0398209  -0.0783401   -0.151552    -0.0392577   -0.0895854   -0.109379     0.11757     -0.0477886   -0.169173    -0.0623038    0.0574057    0.0136105   -0.0595843   -0.0197572     0.109277     0.0443806   -0.23525      0.0746775    -0.0968304    0.00546101  -0.0681072   -0.0535544
  0.0810248   -0.040788     0.0872081    0.097192    0.0564823   0.00161568   0.0817505    0.148231     0.0761485    0.31611      0.204589     0.0406694    0.201827    -0.0898376    0.157897     0.0354944   -0.0894903   -0.109439     -0.053508     0.00398107  -0.186089    -0.0420267    -0.0253542    0.0106265    0.0602378    0.039648
 -0.0856039    0.0610496    0.237691    -0.0490164  -0.145979    0.0512653   -0.0628873    0.155324     0.060251    -0.0198092   -0.113515     0.116305     0.0673817   -0.0430646    0.072318    -0.040696    -0.177145     0.054389     -0.042299     0.170335    -0.0980595    0.0222046    -0.00275766   0.0447493   -0.00878169  -0.0241721
  0.0384093    0.0892783   -0.050709     0.149945   -0.174306    0.0301333   -0.0352476    0.00722684   0.0443168    0.0615456   -0.040022    -0.0323865   -0.190256    -0.0835333    0.0970102   -0.0226162   -0.11613     -0.126224     -0.179126    -0.0239255   -0.00224591  -0.0877755    -0.00771892  -0.0494221    0.0366395    0.0672117
  0.103872    -0.180279     0.0256928    0.0509341  -0.0230258   0.00452065  -0.0194948    0.0792493   -0.0938506    0.128345    -0.0400772    0.19217      0.178372     0.0485302    0.20485      0.151233    -0.0254322   -0.047471     -0.108515     0.00641088   0.0716064   -0.0187962    -0.017996    -0.0620101   -0.0856737   -0.00695004
  0.0669002   -0.0202106    0.0689328    0.12179     0.0257372  -0.21375     -0.0695399    0.0175987    0.118509    -0.0172988    0.115862    -0.114633    -0.0978435   -0.0351347    0.136144     0.00244017   0.113344     0.0201572     0.197172    -0.0194323    0.0772959    0.00614406    0.034219    -0.0764231   -0.0610769    0.0386882
  0.0557317    0.0438768    0.0279719   -0.0842643   0.116575   -0.0776457    0.0690845    0.136527    -0.0716085    0.00571947  -0.102933     0.14192     -0.0617824    0.0496421   -0.0206005   -0.0325652   -0.00171213   0.182517      0.0604133    0.136829    -0.0193742    0.100411      0.046695    -0.138279     0.0670714   -0.0256133
 -0.0255909    0.151849    -0.00603947  -0.031911   -0.0544208   0.0726737   -0.125216    -0.0489156    0.0840965    0.00944842  -0.118797    -0.0396019   -0.0662761    0.0263263   -0.157395     0.0704551    0.00249803  -0.0151075     0.0942135    0.136911     0.0928      -0.0497187     0.112802     0.107562    -0.0826488   -0.0166162
 -0.216941     0.0638163   -0.308884     0.102685    0.140195    0.0159716   -0.134075     0.0606435   -0.0469482   -0.00152431  -0.0993595   -0.00119658   0.119087    -0.108712     0.0263262   -0.105773     0.0739503    0.207517     -0.028783     0.0214182    0.00682171  -0.000346059   0.0923634   -0.134496    -0.183289     0.0160431
  0.116173    -0.168354    -0.0461746   -0.176712    0.0227242   0.0467224   -0.183804    -0.0353729   -0.00797966   0.0471056    0.0641469    0.0521294   -0.134957     0.0330378   -0.022771    -0.0924634   -0.171332    -0.0405352     0.0185613   -0.115035    -0.19958      0.0287686     0.113156     0.0291078   -0.204992     0.0391408
 -0.014551     0.00319404  -0.0748058    0.23053     0.0937132   0.198456     0.0437274   -0.0403334    0.0421065    0.0133174   -0.0959618    0.143837     0.0311571    0.0274891    0.0751187   -0.0908752   -0.0175372   -0.0349783     0.0843965   -0.196364    -0.157047    -0.0732843    -0.0682743   -0.0429166    0.0448452   -0.00775352
 -0.0662171    0.0781132    0.0470744    0.116387   -0.112232    0.19421     -0.0138498   -0.0361411    0.0448813    0.151283     0.0396273    0.0486913   -0.0172718    0.00987749   0.221396     0.0456098    0.0765685    0.0331519     0.0213733   -0.0337348   -0.0288812   -0.0176623     0.0221738   -0.00516884  -0.0340767    0.289927
  0.0831484    0.0266079   -0.1072      -0.120369   -0.144944    0.028842    -0.0327099    0.129212     0.11248     -0.0188216   -0.0334287   -0.0830222   -0.0609459   -0.0477709    0.0261755    0.01208      0.0223949   -0.0358613     0.0252054   -0.0559734   -0.0539204    0.0767914    -0.138244     0.137552     0.0685725    0.00626395
  0.049096    -0.162672    -0.0119487   -0.0763362  -0.0988269   0.118038    -0.00437578   0.0714643    0.0591907   -0.0157935    0.0561784    0.0196892    0.00401107   0.0170781    0.152512    -0.00367934  -0.0377138   -0.154165     -0.0899319   -0.154736     0.037544    -0.0211269    -0.130848    -0.151344    -0.00522883  -0.0643729
 -0.135141     0.0817051   -0.105365    -0.193012   -0.0940101  -0.0486674    0.0174642    0.0299838    0.0758048   -0.11862      0.0179449    0.0371      -0.184515    -0.0212959   -0.133526     0.136178    -0.00137985   0.00466389   -0.0637681    0.0609245   -0.0255142   -0.0687596     0.0324116   -0.0266731   -0.0832756   -6.22996e-5
 -0.0755593   -0.0352926    0.223042    -0.0592096   0.0761558   8.47801e-5   0.037085     0.11389     -0.0862636    0.186561    -0.120894     0.0763899    0.0175605   -0.108035    -0.145872     0.109866     0.0341635   -0.131803     -0.044737     0.10799      0.167164    -0.0329444     0.0113581    0.189872     0.0483641    0.0499051
 -0.068524     0.137987     0.134603    -0.0669665  -0.0191738  -0.0796538   -0.1396       0.0480336   -0.135864    -0.12984     -0.0248041   -0.0474143   -0.0469061   -0.00611928   0.0787717   -0.0164202    0.0279251    0.0973759     0.222658     0.0337485   -0.127109    -0.128381     -0.187425     0.101409     0.0611407   -0.0168791
  0.104449     0.157571     0.14605      0.141037    0.0224082  -0.0779262    0.028021     0.00260882  -0.0652202   -0.0344422    0.0194435    0.0742526   -0.232475    -0.129795     0.0953498   -0.0696275   -0.0569303    0.140024      0.129214    -0.164356    -0.0127433    0.161544      0.0213916    0.0305401   -0.117881    -0.157129
  0.0974479    0.206998     0.122587     0.0359493  -0.0815465   0.205664     0.056415     0.00491101  -0.00613723  -0.100788    -0.179403    -0.0357578    0.163517     0.0415054   -0.0989994    0.097617     0.142392    -0.000298802   0.141875    -0.0225157   -0.0572604    0.0994632    -0.0545158    0.0984518   -0.0559595    0.143752
  0.0737505   -0.136546    -0.235043     0.162023    0.0538771   0.0535673   -0.0685215   -0.14824     -0.143137    -0.115744    -0.013819     0.179067    -0.041763     0.0965493    0.263219    -0.105343    -0.0191327   -0.0447582    -0.0261966   -0.167705    -0.0316271   -0.0369397    -0.235939     0.0487667   -0.0200861   -0.0872973
 -0.0342878   -0.0173066    0.193477    -0.037628   -0.115311    0.0428882    0.0649292   -0.0622397   -0.0200699    0.0147648   -0.11323     -0.0613458   -0.214837     0.0926736    0.168984     0.0272695   -0.0362114    0.115689     -0.170072     0.111379     0.0466741   -0.0522139    -0.1013       0.0607394    0.0422004    0.0293359
 -0.00139519  -0.00780365   0.0218704    0.0107914  -0.0723073   0.145698     0.0856085    0.00867567   0.0992856    0.0434146   -0.177983    -0.175969    -0.137843     0.0876872    0.0830963   -0.0520246    0.105129     0.0663201     0.179387     0.271096    -0.177374    -0.104593     -0.0388167    0.068614    -0.0183569   -0.0527348
  0.0571495    0.0576007   -0.093044    -0.0312883   0.144498   -0.0313733   -0.217824     0.0767879    0.0625963   -0.0946841    0.155267     0.0894097   -0.0422194    0.0710692   -0.0621178    0.0103249   -0.0945338   -0.0513821     0.156091     0.126072    -0.215235    -0.236328      0.0495728    0.10451     -0.0467678    0.257848
 -0.0167628   -0.0243634   -0.0870925   -0.0570304  -0.0201677   0.00154084  -0.00515856   0.0540023    0.306047    -0.109696     0.144081     0.104914     0.0390873    0.00489177  -0.175192    -0.08304      0.066785     0.0474864     0.0882579   -0.141268    -0.027612     0.0833541     0.0314643   -0.208502     0.0938567   -0.116021
  0.0482988   -0.153251    -0.152783     0.152067   -0.0597644  -0.132818     0.0595545   -0.0650388   -0.245486    -0.0425389   -0.160464    -0.0538105    0.141764    -0.0953355   -0.0108665    0.0330029   -0.150576    -0.0931152    -0.0891419    0.106647    -0.06759      0.0651591     0.0656423   -0.0437232   -0.0265816    0.0196145
  0.0689201   -0.144355     0.100372     0.171436    0.0102652   0.0389225   -0.100523     0.149627    -0.112994    -0.142078    -0.0883825    0.0985308    0.145747     0.0164872    0.060067     0.00517814   0.00675164   0.0716537     0.00740551  -0.0816385   -0.0451162   -0.129746      0.0873193   -0.136562    -0.0229255    0.0746558
  0.0734305   -0.0906853    0.05898     -0.0257071  -0.0164523  -0.0518789   -0.0561457   -0.0348355   -0.0707158    0.0960181   -0.0905295    0.00969625  -0.0127945   -0.0718231    0.00162645  -0.0990233   -0.0234728   -0.00620401    0.0255192   -0.0164163   -0.037012     0.12194       0.00538935  -0.0413184    0.0579011   -0.00792966
 -0.00830839  -0.13888     -0.0522752    0.155172    0.0874735   0.120522    -0.0278275    0.10791      0.00648276   0.0578363   -0.149299     0.0989015    0.0253193   -0.150174    -0.0193031    0.0955772    0.11229      0.0747955     0.0708186   -0.0232194   -0.0192511    0.0638658     0.0548307   -0.0103376    0.00858962  -0.0597711
  0.163609    -0.1855       0.0232075    0.0763249  -0.0586264   0.00507232  -0.0217541   -0.0340804   -0.157499     0.105391    -0.142053    -0.127983    -0.128162     0.0474537   -0.0319523    0.0934764   -0.0116653   -0.200339      0.117126    -0.0611595   -0.087249    -0.093195      0.135432     0.00774855   0.013683     0.114689
 -0.0135174   -0.106572    -0.0512457    0.0553725   0.107542   -0.00733847   0.0487573    0.128968     0.100645    -0.0239597    0.166194     0.134237    -0.068579     0.13229     -0.00131929  -0.110487    -0.0332523    0.011944      0.0213559    0.00295847   0.0423952   -0.0699852     0.0357171    0.00430007   0.048396    -0.0604165
  0.185443    -0.0264059    0.0568104   -0.0782188   0.0798115  -0.0221153    0.0950308    0.0535195   -0.0274839   -0.169943    -0.133972    -0.0634056    0.018476     0.0461592    0.0777315    0.028981    -0.00887009   0.0102615    -0.0202717   -0.0378366   -0.105338    -0.102502     -0.0833133    0.0985287   -0.0996997    0.139666kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4683313787877048
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.468413
[ Info: iteration 2, average log likelihood -1.468340
[ Info: iteration 3, average log likelihood -1.467750
[ Info: iteration 4, average log likelihood -1.460902
[ Info: iteration 5, average log likelihood -1.444744
[ Info: iteration 6, average log likelihood -1.437759
[ Info: iteration 7, average log likelihood -1.435907
[ Info: iteration 8, average log likelihood -1.434922
[ Info: iteration 9, average log likelihood -1.434386
[ Info: iteration 10, average log likelihood -1.434111
[ Info: iteration 11, average log likelihood -1.433945
[ Info: iteration 12, average log likelihood -1.433822
[ Info: iteration 13, average log likelihood -1.433711
[ Info: iteration 14, average log likelihood -1.433592
[ Info: iteration 15, average log likelihood -1.433443
[ Info: iteration 16, average log likelihood -1.433280
[ Info: iteration 17, average log likelihood -1.433153
[ Info: iteration 18, average log likelihood -1.433055
[ Info: iteration 19, average log likelihood -1.432964
[ Info: iteration 20, average log likelihood -1.432860
[ Info: iteration 21, average log likelihood -1.432723
[ Info: iteration 22, average log likelihood -1.432530
[ Info: iteration 23, average log likelihood -1.432238
[ Info: iteration 24, average log likelihood -1.431849
[ Info: iteration 25, average log likelihood -1.431511
[ Info: iteration 26, average log likelihood -1.431290
[ Info: iteration 27, average log likelihood -1.431155
[ Info: iteration 28, average log likelihood -1.431067
[ Info: iteration 29, average log likelihood -1.431005
[ Info: iteration 30, average log likelihood -1.430960
[ Info: iteration 31, average log likelihood -1.430927
[ Info: iteration 32, average log likelihood -1.430902
[ Info: iteration 33, average log likelihood -1.430885
[ Info: iteration 34, average log likelihood -1.430871
[ Info: iteration 35, average log likelihood -1.430861
[ Info: iteration 36, average log likelihood -1.430853
[ Info: iteration 37, average log likelihood -1.430847
[ Info: iteration 38, average log likelihood -1.430843
[ Info: iteration 39, average log likelihood -1.430839
[ Info: iteration 40, average log likelihood -1.430837
[ Info: iteration 41, average log likelihood -1.430834
[ Info: iteration 42, average log likelihood -1.430833
[ Info: iteration 43, average log likelihood -1.430831
[ Info: iteration 44, average log likelihood -1.430830
[ Info: iteration 45, average log likelihood -1.430828
[ Info: iteration 46, average log likelihood -1.430827
[ Info: iteration 47, average log likelihood -1.430826
[ Info: iteration 48, average log likelihood -1.430825
[ Info: iteration 49, average log likelihood -1.430824
[ Info: iteration 50, average log likelihood -1.430823
┌ Info: EM with 100000 data points 50 iterations avll -1.430823
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4684129558209367
│     -1.4683400295433509
│      ⋮
└     -1.4308231357144334
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.430942
[ Info: iteration 2, average log likelihood -1.430847
[ Info: iteration 3, average log likelihood -1.430418
[ Info: iteration 4, average log likelihood -1.425462
[ Info: iteration 5, average log likelihood -1.408956
[ Info: iteration 6, average log likelihood -1.396716
[ Info: iteration 7, average log likelihood -1.392054
[ Info: iteration 8, average log likelihood -1.389544
[ Info: iteration 9, average log likelihood -1.387921
[ Info: iteration 10, average log likelihood -1.386762
[ Info: iteration 11, average log likelihood -1.385912
[ Info: iteration 12, average log likelihood -1.385241
[ Info: iteration 13, average log likelihood -1.384613
[ Info: iteration 14, average log likelihood -1.383925
[ Info: iteration 15, average log likelihood -1.383106
[ Info: iteration 16, average log likelihood -1.382150
[ Info: iteration 17, average log likelihood -1.381230
[ Info: iteration 18, average log likelihood -1.380427
[ Info: iteration 19, average log likelihood -1.379692
[ Info: iteration 20, average log likelihood -1.379000
[ Info: iteration 21, average log likelihood -1.378423
[ Info: iteration 22, average log likelihood -1.377992
[ Info: iteration 23, average log likelihood -1.377687
[ Info: iteration 24, average log likelihood -1.377477
[ Info: iteration 25, average log likelihood -1.377337
[ Info: iteration 26, average log likelihood -1.377246
[ Info: iteration 27, average log likelihood -1.377188
[ Info: iteration 28, average log likelihood -1.377151
[ Info: iteration 29, average log likelihood -1.377128
[ Info: iteration 30, average log likelihood -1.377112
[ Info: iteration 31, average log likelihood -1.377103
[ Info: iteration 32, average log likelihood -1.377097
[ Info: iteration 33, average log likelihood -1.377093
[ Info: iteration 34, average log likelihood -1.377090
[ Info: iteration 35, average log likelihood -1.377088
[ Info: iteration 36, average log likelihood -1.377087
[ Info: iteration 37, average log likelihood -1.377086
[ Info: iteration 38, average log likelihood -1.377086
[ Info: iteration 39, average log likelihood -1.377085
[ Info: iteration 40, average log likelihood -1.377085
[ Info: iteration 41, average log likelihood -1.377085
[ Info: iteration 42, average log likelihood -1.377085
[ Info: iteration 43, average log likelihood -1.377085
[ Info: iteration 44, average log likelihood -1.377085
[ Info: iteration 45, average log likelihood -1.377084
[ Info: iteration 46, average log likelihood -1.377084
[ Info: iteration 47, average log likelihood -1.377084
[ Info: iteration 48, average log likelihood -1.377084
[ Info: iteration 49, average log likelihood -1.377084
[ Info: iteration 50, average log likelihood -1.377084
┌ Info: EM with 100000 data points 50 iterations avll -1.377084
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4309422057022205
│     -1.4308474119755927
│      ⋮
└     -1.3770843596730693
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.377265
[ Info: iteration 2, average log likelihood -1.377092
[ Info: iteration 3, average log likelihood -1.376322
[ Info: iteration 4, average log likelihood -1.369209
[ Info: iteration 5, average log likelihood -1.350914
[ Info: iteration 6, average log likelihood -1.336747
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.327922
[ Info: iteration 8, average log likelihood -1.336227
[ Info: iteration 9, average log likelihood -1.327966
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.321567
[ Info: iteration 11, average log likelihood -1.332386
[ Info: iteration 12, average log likelihood -1.325165
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.319418
[ Info: iteration 14, average log likelihood -1.330541
[ Info: iteration 15, average log likelihood -1.323505
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.318005
[ Info: iteration 17, average log likelihood -1.329366
[ Info: iteration 18, average log likelihood -1.322522
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.317207
[ Info: iteration 20, average log likelihood -1.328767
[ Info: iteration 21, average log likelihood -1.322058
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.316820
[ Info: iteration 23, average log likelihood -1.328449
[ Info: iteration 24, average log likelihood -1.321793
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.316579
[ Info: iteration 26, average log likelihood -1.328218
[ Info: iteration 27, average log likelihood -1.321607
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.316434
[ Info: iteration 29, average log likelihood -1.328072
[ Info: iteration 30, average log likelihood -1.321489
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.316351
[ Info: iteration 32, average log likelihood -1.327980
[ Info: iteration 33, average log likelihood -1.321409
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.316295
[ Info: iteration 35, average log likelihood -1.327912
[ Info: iteration 36, average log likelihood -1.321346
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.316244
[ Info: iteration 38, average log likelihood -1.327848
[ Info: iteration 39, average log likelihood -1.321279
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.316180
[ Info: iteration 41, average log likelihood -1.327770
[ Info: iteration 42, average log likelihood -1.321195
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.316096
[ Info: iteration 44, average log likelihood -1.327672
[ Info: iteration 45, average log likelihood -1.321083
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.315983
[ Info: iteration 47, average log likelihood -1.327546
[ Info: iteration 48, average log likelihood -1.320939
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.315846
[ Info: iteration 50, average log likelihood -1.327402
┌ Info: EM with 100000 data points 50 iterations avll -1.327402
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3772651967052296
│     -1.3770921288060862
│      ⋮
└     -1.3274017391460606
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.321031
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.315784
[ Info: iteration 3, average log likelihood -1.320005
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.305710
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.284089
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.269436
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.252748
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.244204
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.232215
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.245209
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.233528
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.232414
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.225884
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.223793
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.232870
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.237562
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.225767
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.221576
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.223876
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.234199
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.234295
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.229557
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.221837
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.219505
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.228332
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.233636
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.221863
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.231184
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.219195
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.233283
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.233838
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.228977
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.220858
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.217620
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.225519
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.242718
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.228241
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.225552
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.217787
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.232315
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.219953
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.230222
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.218703
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.228321
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.233550
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.227076
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.218783
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.229767
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.217774
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.231142
┌ Info: EM with 100000 data points 50 iterations avll -1.231142
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3210311755958206
│     -1.3157843327031693
│      ⋮
└     -1.2311419830933361
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.232036
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     17
│     18
│     19
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.215834
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.220253
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     17
│     18
│      ⋮
│     24
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.198146
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     23
│     24
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.175892
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│     10
│     11
│     12
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.147630
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     23
│     24
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.147458
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     17
│     18
│      ⋮
│     24
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.132577
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     10
│     23
│     24
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.129061
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     11
│     12
│     17
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.148632
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     23
│     24
│     25
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.130234
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     10
│     11
│     12
│     17
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.129779
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     23
│     24
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.136479
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     17
│     18
│      ⋮
│     24
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.130114
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     23
│     24
│     25
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.124660
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     11
│     12
│     17
│      ⋮
│     24
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.131588
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     23
│     24
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.130931
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     10
│     11
│     12
│     17
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.120847
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     23
│     24
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.142891
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     17
│     18
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.128553
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     10
│     23
│     24
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.115638
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     11
│     12
│     17
│      ⋮
│     24
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.138557
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     23
│     24
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.133448
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     10
│     11
│     12
│     17
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.123214
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     23
│     24
│     25
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.122011
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     17
│     18
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.139872
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     23
│     24
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.129137
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     11
│     12
│     17
│      ⋮
│     24
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.126882
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     23
│     24
│     25
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.125921
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     10
│     11
│     12
│     17
│      ⋮
│     24
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.129389
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     23
│     24
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.139713
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     11
│     12
│     17
│     18
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.116571
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     10
│     23
│     24
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.125792
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     11
│     12
│     17
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.143301
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     23
│     24
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.129242
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     10
│     11
│     12
│     17
│      ⋮
│     24
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.119111
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     23
│     24
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.130854
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     17
│     18
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.136664
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     10
│     23
│     24
│     25
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.117040
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     11
│     12
│     17
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.137260
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     23
│     24
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.130888
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     10
│     11
│     12
│     17
│      ⋮
│     24
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.125198
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     23
│     24
│     25
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.135217
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     17
│     18
│      ⋮
│     24
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.125082
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     10
│     23
│     24
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.122406
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      9
│     11
│     12
│     17
│      ⋮
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.131217
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     23
│     24
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.139364
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     10
│     11
│     12
│     17
│      ⋮
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.123866
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     23
│     24
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.126471
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     17
│     18
│      ⋮
│     24
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.132440
┌ Info: EM with 100000 data points 50 iterations avll -1.132440
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2320359004907993
│     -1.2158342053645323
│      ⋮
└     -1.1324404930228948
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4683313787877048
│     -1.4684129558209367
│     -1.4683400295433509
│     -1.4677504681174165
│      ⋮
│     -1.1238661213827499
│     -1.126470930250678
└     -1.1324404930228948
32×26 Array{Float64,2}:
  0.11146     -0.128387     0.0435203    0.0359391    -0.0247393  -0.0537726    -0.0290923   -0.0195902   -0.0960318   0.102304    -0.0998161   -0.0363494  -0.0659347   -0.0163749   -0.00913469  -0.0181504   -0.00205462   -0.107058     0.0703716   -0.0129376   -0.0481743    0.0133432    0.0639259   -0.0227329    0.0263616    0.0740961
  0.0110457   -0.0488926   -0.00505679  -0.148482     -0.0160537  -0.0664187    -0.144468    -0.023816    -0.0551608  -0.0946095    0.108511    -0.0387812  -0.177879    -0.0578788    0.0519414    0.00672476  -0.0441798     0.0525485    0.0954523    0.031876    -0.212223     0.0829449   -0.0832014    0.0109451   -0.0626493   -0.0459119
  0.0667115   -0.125975    -0.224878     0.141975      0.0624607   0.0669006    -0.131201    -0.141445    -0.129045   -0.122307    -0.0178505    0.186156   -0.0323996    0.0326327    0.276745    -0.105796    -0.00554486   -0.0458036   -0.0232461   -0.180701    -0.0218646   -0.0547151   -0.260783     0.0425283   -0.0160746   -0.0755765
  0.0113196    0.0346476   -0.031567    -0.0707937     0.0341432   0.0395687    -0.0194239    0.0708244    0.154942   -0.0531103    0.0266397    0.123085   -0.00195003   0.0400009   -0.113894    -0.0645767    0.040694      0.102496     0.094058    -0.00958249  -0.0102293    0.0811669    0.0515021   -0.177001     0.0718168   -0.075659
  0.0176369    0.0978522    0.095771     0.124929     -0.0488436   0.0926631     0.0235392   -0.00369838  -0.0312598   0.0652692    0.0283938    0.0793855  -0.117781    -0.0266373    0.155071    -0.00596442   0.00814251    0.0775922    0.0863703   -0.0557769   -0.0570468    0.106387     0.0893582    0.00376878  -0.0773031    0.0453983
  0.0495861   -0.143369    -0.028269     0.0832382     0.0305355  -0.000982682   0.0147318    0.0997474   -0.0321222   0.0693237    0.0446929    0.157313    0.0655941    0.0609932    0.113542     0.0256848   -0.0313847    -0.0137396   -0.0305624   -0.0122765    0.0655683   -0.031604     0.0191383   -0.0310906   -0.0331698   -0.0260873
  0.068728    -0.0153138    0.0686665    0.087989      0.0307746  -0.21512      -0.0620815    0.0176515    0.112665   -0.00696997   0.126101    -0.115436   -0.103451    -0.0378222    0.143238    -9.57716e-5   0.112733      0.0214862    0.19618      0.00770438   0.120032     0.00442861   0.0337418   -0.0766253   -0.0916726    0.0372996
  0.0480489    0.00950512  -0.0022582    0.0316353     0.0988733  -0.0292187    -0.063433     0.105205     0.056705    0.101059     0.158645     0.0759215   0.0750527   -0.00111358   0.0350288    0.0158037   -0.0866277    -0.0724199    0.0615682    0.0353548   -0.20583     -0.143168     0.0134269    0.043987     0.00692737   0.118687
  0.0143704   -0.128126    -0.157227     0.151744     -0.0636902  -0.0899805     0.0772714   -0.0452091   -0.2561     -0.089671    -0.167041    -0.0484029   0.137178    -0.0553523   -0.0341763    0.0414912   -0.147995     -0.0941064   -0.0963133    0.113862    -0.0696559    0.0631361    0.0741537   -0.0388484   -0.0275424    0.0242671
  0.0492731   -0.159544    -0.00819192  -0.071279     -0.0796486   0.102277     -0.00365064   0.053832     0.0433068  -0.0220467    0.0537645    0.0202163   0.00757408  -0.0266272    0.146785    -0.0106333   -0.0384765    -0.148385    -0.0821268   -0.135976     0.0341387   -0.0337118   -0.117028    -0.135891    -0.00390109  -0.0643514
  0.105139    -0.138843     0.0742155    0.19724      -0.0225607   0.301048     -0.100474     0.141973    -0.135482   -0.111391    -0.0960629    0.0945322   0.145729    -0.167295     0.086571    -0.42789      0.0266109     0.0855246    0.229957    -0.0183919   -0.0567954   -0.254418     0.0179528   -0.146758    -0.0499578    0.0633426
  0.0571326   -0.164073     0.15044      0.124873      0.0143954  -0.47492      -0.100425     0.153965    -0.0304144  -0.150474    -0.042557     0.104248    0.145651     0.49833     -0.148375     0.97366      0.0263242     0.0383966   -0.448703    -0.275496    -0.0371741   -0.00415673   0.228429    -0.259662     0.0433993    0.0973388
 -0.00738871   0.00893262  -0.0732539    0.20703       0.0799463   0.219089      0.0564428   -0.0474134    0.0428772   0.0225636   -0.0903267    0.14613     0.0200615    0.0314989    0.0898251   -0.0931852    0.0173401    -0.0344737    0.0839298   -0.161462    -0.154425    -0.0396598   -0.0668274   -0.0648019    0.0648558    0.00673834
 -0.0529286   -0.0842701    0.105206     0.0373795     0.0875887   0.067586      0.00621926   0.175283    -0.0370583   0.111876    -0.136804     0.0831969   0.0119982   -0.126741    -0.0893779    0.114435     0.0559043    -0.0468598    0.0147582    0.0311569    0.0475474   -0.00531815   0.0298638    0.086099     0.0494918   -0.00662315
 -0.0836507    0.10755     -0.836504    -0.0864937     0.10099     0.0273588     0.00881016  -0.093632    -0.0334454  -0.042276     0.0352079   -0.0962231   0.0798392    0.0414224    0.164993    -0.0430649    0.101317     -0.117117     0.170898    -0.138471     0.0736476    0.061762    -0.346488    -0.00583931   0.308427     0.118751
 -0.0924106   -0.0677276    0.651439     0.0144485     0.218503   -0.060374      0.0317864   -0.0790911    0.0140755  -0.0786201   -0.0272706   -0.0875244   0.0359742    0.0578547   -0.0606788    0.0129113    0.0475958     0.186176     0.0734275   -0.121355     0.134145     0.0694283   -0.0465861   -0.0364686    0.167586    -0.0319025
 -0.120527     0.00151413  -0.0927549   -0.0126612    -0.0713166   0.142371      0.0955424    0.0136136    0.100604    0.0408239   -0.221257    -0.148657   -0.114187     0.0798976    0.080341    -0.0523992   -0.342007      0.0273588    0.179366     0.27195     -0.34928      0.0413297   -0.0390659    0.0652872   -0.0159333   -0.0805687
  0.0982955    0.018543     0.160404    -0.000682994  -0.0714466   0.141421      0.0870919    0.0178138    0.101135    0.0439114   -0.143363    -0.181904   -0.142257     0.096437     0.208627    -0.0505655    0.319388      0.338238     0.179339     0.273589    -0.124514    -0.0354916   -0.0380297    0.0713287   -0.0190323   -0.0514937
  0.283651     0.404106     0.0461021    0.0716571    -0.0735959   0.134476      0.0410562    0.0179111    0.121415    0.0421477   -0.182053    -0.233339    0.0131997    0.0750785    0.0551854   -0.0452234   -0.193954     -1.42556      0.180906     0.277144    -0.99368     -0.182996    -0.0320452    0.0858663    0.0207235   -0.07173
 -0.0234802   -0.13197     -0.0175761    0.0185587    -0.0715261   0.132836      0.0764498   -0.00204021   0.115689    0.0480735   -0.184783    -0.196469   -0.0171226    0.0890832    0.00728001  -0.0562229    0.466016     -0.313336     0.179275     0.27051      0.29382     -0.726609    -0.0342398    0.0691549   -0.012772     0.0273577
  0.0946191    0.0301291   -0.122433    -0.144336     -0.243619   -0.0200941    -0.0358528    0.124821     0.108783    0.0369852   -0.0286232   -0.200202   -0.0605816   -0.0465309    0.0433779   -0.00244663   0.0513744     0.0182232    0.0237365   -0.129136     0.0754621    0.0654407   -0.611847     0.139543     0.00335884   0.0307278
  0.0726056    0.0284358   -0.0956404   -0.0864243    -0.0210482   0.108281     -0.0257904    0.131827     0.115324   -0.115199    -0.0280248   -0.0031008  -0.0986194   -0.0470075    0.0150141    0.0145022    0.00426775   -0.08348      0.0332198    0.0101466   -0.115396     0.0932418    0.474322     0.104874     0.101996    -0.0146519
  0.0459707    0.0906494    0.0496926    0.150126     -0.153283    0.134294     -0.0244665   -0.00122182   0.050016    0.0612532    0.0831943   -0.0630338  -0.234205    -0.109768     0.152607    -0.0231329   -0.00723688   -0.12641     -0.17913      0.0110719   -0.0023176   -0.0277526   -0.172308    -0.0419837    0.0334179   -0.687351
  0.0270446    0.0924766   -0.162966     0.150281     -0.169575   -0.0661579    -0.0323324    0.0132405    0.0259215   0.061401    -0.158622    -0.0124053  -0.188968    -0.0751974    0.0375849   -0.0225406   -0.14141      -0.12678     -0.178938    -0.119685    -0.00720558  -0.141857     0.110835    -0.0361415    0.0372222    0.815637
 -0.0890898    0.0541996    0.264889    -0.0554223    -0.151812    0.0581627    -0.0781586    0.185015     0.0610874  -0.0447845   -0.119706     0.142069    0.0680853   -0.0415271    0.0729886   -0.0271133   -0.185777      0.0564696   -0.0407703    0.174067    -0.0741466    0.0182904   -0.00165137   0.0439799    0.0166864   -0.0140047
 -0.141078     0.159975    -0.00794914  -0.0255149    -0.0411273   0.085017     -0.142254    -0.0604131    0.0821494   0.0219646   -0.119795    -0.0254463  -0.066349     0.0198702   -0.154465     0.0692754    0.000275628  -0.0422425    0.0548851    0.134221     0.0870441   -0.0496506    0.117099     0.107089    -0.0991251   -0.0310774
  0.110994    -0.169206    -0.0599683   -0.181364      0.0260518   0.0585943    -0.230058    -0.0176428   -0.0239949   0.0436748    0.0729398    0.0774366  -0.137863     0.0382805   -0.0239118   -0.0948563   -0.150027     -0.0384605   -0.00583829  -0.099664    -0.201424     0.0287833    0.115911     0.0279101   -0.196229     0.0451302
  0.185299    -0.0259692    0.0157421   -0.0883195     0.0871326  -0.0125435     0.103406     0.0181664   -0.0325715  -0.16617     -0.129527    -0.0574838   0.0278934    0.0445957   -0.0145878    0.0122869   -0.0204718     0.018607    -0.00603008  -0.0367174   -0.11199     -0.0973738   -0.072575     0.0983459   -0.108541     0.136187
 -0.136849     0.0817675   -0.101865    -0.197831     -0.0802125  -0.0460961     0.0336185    0.0138987    0.0746311  -0.122144    -0.00524596   0.0520098  -0.17733     -0.00562159  -0.121756     0.102069    -0.00185219    0.00950628  -0.0849493    0.0588988   -0.0179233   -0.07083     -0.00467032  -0.0151686   -0.0757358   -0.0115504
 -0.0333697   -0.015538     0.173297    -0.0387289    -0.100301    0.0477551     0.0652487   -0.0609862   -0.0233011   0.0182858   -0.14585     -0.0321243  -0.215153     0.107726     0.170858    -0.0101922   -0.0460583     0.118368    -0.161525     0.107463     0.0248418   -0.0974372   -0.101964     0.00301257   0.0428562    0.0256096
 -0.153272     0.0867819   -0.0809164    0.024262      0.0617514  -0.039882     -0.141803     0.0667279   -0.0886433  -0.0705334   -0.0716718   -0.0515507   0.0311766   -0.057491     0.061565    -0.0557268    0.0391384     0.156047     0.102144     0.00662287  -0.0586147   -0.0635057   -0.0539684   -0.00567104  -0.0693428   -0.00473874
  0.092106     0.200627     0.0995608    0.0743046    -0.0821329   0.219981      0.101574    -0.00834732   0.0114836  -0.10365     -0.180942    -0.0431939   0.162551     0.0373505   -0.102151     0.0748772    0.154599      0.00236079   0.0901876   -0.0133778   -0.0469854    0.0944721   -0.0591188    0.114283    -0.0528864    0.172711[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     23
│     24
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.125854
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     10
│     11
│     12
│     17
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.106513
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│     10
│     23
│     24
│     25
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.110501
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     10
│     11
│     12
│     17
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.114056
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     23
│     24
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.117546
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│     10
│     11
│     12
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.098479
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     23
│     24
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.125858
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     10
│     11
│     12
│     17
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.106084
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│     10
│     23
│     24
│     25
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.110164
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     10
│     11
│     12
│     17
│      ⋮
│     26
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.114062
┌ Info: EM with 100000 data points 10 iterations avll -1.114062
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.813072e+05
      1       7.648386e+05      -2.164686e+05 |       32
      2       7.305432e+05      -3.429543e+04 |       32
      3       7.122206e+05      -1.832255e+04 |       32
      4       7.034359e+05      -8.784733e+03 |       32
      5       6.985753e+05      -4.860583e+03 |       32
      6       6.954721e+05      -3.103198e+03 |       32
      7       6.934112e+05      -2.060908e+03 |       32
      8       6.917979e+05      -1.613274e+03 |       32
      9       6.902631e+05      -1.534842e+03 |       32
     10       6.888869e+05      -1.376200e+03 |       32
     11       6.880771e+05      -8.097472e+02 |       32
     12       6.875424e+05      -5.347173e+02 |       32
     13       6.871544e+05      -3.879826e+02 |       32
     14       6.869106e+05      -2.437861e+02 |       32
     15       6.867354e+05      -1.752916e+02 |       32
     16       6.865800e+05      -1.553874e+02 |       32
     17       6.864334e+05      -1.465570e+02 |       32
     18       6.862909e+05      -1.424933e+02 |       32
     19       6.861399e+05      -1.510509e+02 |       32
     20       6.860049e+05      -1.349830e+02 |       32
     21       6.858851e+05      -1.198189e+02 |       32
     22       6.857488e+05      -1.362244e+02 |       32
     23       6.855627e+05      -1.861841e+02 |       32
     24       6.852586e+05      -3.040187e+02 |       32
     25       6.847441e+05      -5.145561e+02 |       32
     26       6.839735e+05      -7.705679e+02 |       32
     27       6.831026e+05      -8.708837e+02 |       32
     28       6.823029e+05      -7.996984e+02 |       32
     29       6.816084e+05      -6.945250e+02 |       32
     30       6.810959e+05      -5.125284e+02 |       32
     31       6.807826e+05      -3.132676e+02 |       32
     32       6.806307e+05      -1.518694e+02 |       32
     33       6.805617e+05      -6.900000e+01 |       32
     34       6.805248e+05      -3.692217e+01 |       32
     35       6.805001e+05      -2.476079e+01 |       29
     36       6.804826e+05      -1.743008e+01 |       31
     37       6.804671e+05      -1.549174e+01 |       29
     38       6.804559e+05      -1.126926e+01 |       30
     39       6.804456e+05      -1.025089e+01 |       32
     40       6.804360e+05      -9.618991e+00 |       29
     41       6.804301e+05      -5.939174e+00 |       27
     42       6.804260e+05      -4.059761e+00 |       23
     43       6.804231e+05      -2.911682e+00 |       27
     44       6.804204e+05      -2.728705e+00 |       23
     45       6.804175e+05      -2.854237e+00 |       25
     46       6.804142e+05      -3.336465e+00 |       22
     47       6.804102e+05      -3.921106e+00 |       17
     48       6.804080e+05      -2.268302e+00 |       17
     49       6.804063e+05      -1.693713e+00 |       14
     50       6.804050e+05      -1.255013e+00 |       18
K-means terminated without convergence after 50 iterations (objv = 680405.026356168)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.382499
[ Info: iteration 2, average log likelihood -1.350147
[ Info: iteration 3, average log likelihood -1.317532
[ Info: iteration 4, average log likelihood -1.279896
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.234536
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.205600
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.181710
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.174568
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│      9
│     10
│     12
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.125770
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.157512
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.148185
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     19
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.129441
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     10
│     17
│     21
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.112099
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.161328
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.139393
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      5
│     17
│     23
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.111379
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     19
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.163097
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.148677
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     12
│     17
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.104621
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.135982
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.118858
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     17
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.122926
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     19
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.134806
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.136923
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     10
│     17
│     21
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.084523
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.147941
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     12
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.129036
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     17
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.120976
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     21
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.114962
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.121834
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      9
│     12
│     17
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.122946
[ Info: iteration 32, average log likelihood -1.142345
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     10
│     19
│     21
│     25
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.069241
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.156160
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.144589
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     19
│     23
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.096813
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     10
│     17
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.115269
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.158831
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     19
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.121289
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     17
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.116582
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      9
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.137474
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     19
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.112436
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     12
│     17
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.115503
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.136704
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     21
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.110119
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      9
│     10
│     17
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.099891
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     12
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.130670
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.120214
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     17
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.126275
[ Info: iteration 50, average log likelihood -1.147566
┌ Info: EM with 100000 data points 50 iterations avll -1.147566
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0135038   -0.0201164    -0.0790633   -0.061268    -0.0394582    0.02033      -0.0183551    0.0201869    0.300903    -0.139407     0.172779     0.08705     0.0324862   -0.000528668  -0.150837    -0.0779273    0.0689945     0.0208602    0.118071    -0.120521    -0.0211385   0.0887166     0.0336345   -0.204524     0.0345457   -0.113415
  0.0912365   -0.152684      0.102393     0.17161     -0.00510212   0.0443878    -0.0995238    0.144991    -0.102709    -0.127052    -0.0743927    0.0964089   0.144894     0.0471009     0.0109419    0.0344749    0.0262519     0.0726138    0.00427854  -0.109522    -0.0511696  -0.176122      0.0859076   -0.187153    -0.0201753    0.0729177
  0.0687468   -0.0153462     0.0686729    0.0880449    0.0309325   -0.21518      -0.0620453    0.0174866    0.112627    -0.00721355   0.126124    -0.115433   -0.103425    -0.0378206     0.14323     -0.00011363   0.112761      0.0215214    0.196219     0.00783889   0.12006     0.00440737    0.0337645   -0.0768152   -0.0917552    0.0373513
  0.109214    -0.169207     -0.0589133   -0.179987     0.0257582    0.0584711    -0.226413    -0.0159219   -0.0252893    0.0430142    0.0722262    0.0774688  -0.137064     0.0381053    -0.0231327   -0.0945147   -0.147769     -0.0375843   -0.00729694  -0.0992015   -0.201794    0.0286543     0.115827     0.0277349   -0.193464     0.0449628
  0.0400695    0.0653563    -0.0441004    0.132431    -0.150745     0.0224308    -0.0208703    0.00811753   0.0427588    0.0675983   -0.0444335   -0.0569403  -0.218305    -0.083059      0.089065    -0.0144528   -0.106452     -0.131748    -0.144588    -0.0386662    0.0107524  -0.0826012     0.0253959   -0.038768     0.0257103    0.130228
 -0.0336742   -0.0163995     0.169707    -0.0381172   -0.0990925    0.0499546     0.0657091   -0.0605933   -0.0207456    0.0182601   -0.145906    -0.0345078  -0.215482     0.107626      0.168899    -0.0121799   -0.0454324     0.11762     -0.155028     0.111057     0.0282277  -0.0986274    -0.100723     0.00478305   0.0425571    0.0263749
 -0.0179817   -0.102862     -0.0606743    0.081875     0.0908336   -0.0100013     0.0333181    0.126971     0.0808253   -0.00408022   0.152834     0.149093   -0.0373796    0.142828      0.0061548   -0.0926669   -0.0369478     0.0035943    0.0388521   -0.0306091    0.0370311  -0.0648876     0.0402547    0.00448894   0.00216014  -0.0548
  0.0499695    0.00570527   -0.00430218   0.0336642    0.0967548   -0.028285     -0.0625985    0.104301     0.0497421    0.101415     0.151031     0.0789897   0.0761284   -0.00207763    0.0383092    0.0224458   -0.0859358    -0.0726944    0.0592347    0.0383377   -0.197608   -0.141759      0.0136549    0.043411     0.00350169   0.120815
 -0.0840472    0.0565938     0.25527     -0.051911    -0.147278     0.057834     -0.0719722    0.175289     0.0607951   -0.0423056   -0.118474     0.13966     0.0678961   -0.0396432     0.0696585   -0.0264573   -0.187578      0.0552187   -0.0400185    0.165816    -0.072487    0.018072     -0.00266798   0.0462156    0.0146296   -0.013658
 -0.11267      0.126288      0.123082    -0.045981    -0.0485296   -0.0361929    -0.0749819    0.0200229   -0.069394    -0.0955867   -0.0908576   -0.0736656  -0.0419962    0.0132758     0.0838748   -0.0654698    0.0698416     0.109555     0.210167     0.0983302   -0.125502   -0.124492     -0.150965     0.100089     0.0644669   -0.0253224
  0.00684495   0.0169806    -0.118623    -0.00379359   0.113662    -0.000725456  -0.0022674    0.0423131   -0.0372485   -0.0958405   -0.112614    -0.0655307   0.0727714   -0.0194946     0.0205154   -0.0413949    0.0161695     0.103542    -0.020067    -0.0169693   -0.0541537  -0.0598522    -0.00211003   0.00662342  -0.15748      0.0874601
  0.0482235   -0.163515     -0.00893479  -0.0717684   -0.084493     0.100717     -0.00773622   0.0529861    0.0440115   -0.0172906    0.0555353    0.0227873   0.00746146  -0.0249945     0.14765     -0.00558974  -0.0386432    -0.152756    -0.0903925   -0.140555     0.0366848  -0.0315935    -0.113846    -0.137618    -0.00553262  -0.0646393
 -0.00628114   0.00474098   -0.0694181    0.184813     0.058914     0.209822      0.0582641   -0.042043     0.0459808    0.0236587   -0.093261     0.122774    0.0082228    0.0374559     0.0916753   -0.0876547    0.0275316    -0.0313143    0.0884004   -0.113792    -0.152306   -0.0604304    -0.0651253   -0.0485537    0.0580473    0.00765607
  0.0981205    0.156582      0.150056     0.135723     0.0159331   -0.023782      0.0486338    0.0313414   -0.105669    -0.0335167    0.0215563    0.125055   -0.238075    -0.0672563     0.0979044   -0.0726444   -0.0561191     0.138182     0.129098    -0.1143      -0.0525429   0.191701      0.0387497    0.0298862   -0.128254    -0.163672
 -0.0592024    0.0660932     0.035793     0.120771    -0.112496     0.212021      0.00688123  -0.0327982    0.0498756    0.16523      0.0482595    0.0389271  -0.0161712    0.0143921     0.215857     0.0490334    0.0765057     0.00413261   0.0222383    0.015556    -0.037719    0.0165735     0.135831    -0.0213678   -0.0289479    0.264577
  0.0615594   -0.107244     -0.22692      0.145932     0.0519817    0.0686921    -0.124722    -0.128366    -0.117117    -0.103819    -0.0170038    0.189589   -0.0306664    0.0176595     0.267896    -0.0959817    0.000126337  -0.0552567   -0.0400595   -0.182764    -0.0202823  -0.0679692    -0.274911     0.039342    -0.00983027  -0.0943015
  0.00918137  -0.0293492     0.00133862  -0.192683    -0.0457188   -0.0831223    -0.130723    -0.0480159   -0.0583853   -0.114575     0.104528    -0.101405   -0.182379    -0.0895148     0.0725642    0.0316303   -0.0548616     0.159355     0.147261     0.0429694   -0.24825     0.0806563    -0.103688     0.0161252   -0.0615705   -0.0573867
  0.0740814   -0.100656      0.0557193    0.0164762   -0.0128605   -0.0853449    -0.0450712   -0.0425748   -0.0859966    0.0806582   -0.0521045    0.0143646  -0.0131534   -0.103098      0.00889933  -0.10655     -0.0364785    -0.028682     0.0176972   -0.0138751   -0.0488109   0.0907778     0.00763996  -0.0280394    0.0249797   -0.0302971
 -0.148022     0.0794446    -0.118833    -0.17991     -0.0777749   -0.0464174     0.0272642    0.0303118    0.0650099   -0.115793    -0.00302465   0.0670224  -0.162555    -0.0183573    -0.119694     0.108794     0.0017432     0.016786    -0.0674627    0.0577635   -0.0292506  -0.0687612    -0.00503039  -0.0459506   -0.0790084   -0.00661441
  0.0892008    0.200883      0.0967515    0.070341    -0.0810614    0.213131      0.0973442   -0.00325939   0.00513744  -0.105247    -0.18363     -0.0432533   0.159071     0.0361166    -0.0965436    0.07134      0.153837      0.00130753   0.0912715   -0.0140725   -0.0494263   0.0947606    -0.061036     0.114797    -0.057497     0.163955
  0.11616     -0.215225      0.00691462   0.0968026   -0.0306528    0.0284882    -0.0422991    0.0952777   -0.200222     0.189683    -0.0184713    0.281189    0.172006     0.0609761     0.20889      0.116717    -0.0365182    -0.138575    -0.165696     0.00691856   0.134596   -0.000565285   0.00250646  -0.0556305   -0.0767109    0.0161739
 -0.0267511   -0.139142     -0.0290855    0.145774     0.104746     0.13049      -0.0172743    0.125423    -0.00222785   0.0524624   -0.154117     0.066698    0.011742    -0.14824      -0.012684     0.0776144    0.111254      0.060919     0.0759538   -0.0398105   -0.0939362   0.0757113     0.0479645   -0.0105949    0.0386278   -0.056374
 -0.0623523    0.114932      0.128624    -0.055561     0.00299373  -0.0795062    -0.167742     0.0387044   -0.152292    -0.113641    -0.0402049   -0.0402076  -0.0688953   -0.0134183     0.068393     0.0229724   -0.0489904     0.0951432    0.226142    -0.0211521   -0.111157   -0.129167     -0.23253      0.157191     0.0697922   -0.017782
  0.0526449    0.000736909   0.0322021   -0.0712609    0.123211     0.0980905    -0.17437      0.130543    -0.0510788    0.00248272  -0.0323239    0.127801   -0.0541048    0.0484652    -0.00426808   0.0250702    0.00166733    0.166392     0.0194981    0.123947    -0.0174073   0.0795286     0.0160034   -0.112117     0.0450059   -0.0465643
  0.0546151    0.0740898     0.0287243   -0.0800567    0.11003      0.0202646    -0.0163569    0.130752    -0.0384206    0.0113364   -0.175535     0.150951   -0.0641418    0.0679427    -0.0443821   -0.0354179    0.00545779    0.182811     0.0494861    0.122038    -0.014392    0.0970361     0.0536536   -0.12636      0.0659044   -0.0105445
 -0.0887237    0.0177028    -0.0383656   -0.0324762    0.164798    -0.0198225     0.0214239   -0.0879349   -0.00553971  -0.0623064    0.00165162  -0.0924779   0.0572478    0.0494324     0.0439401   -0.0119699    0.0724262     0.0517768    0.117974    -0.128582     0.106484    0.065685     -0.186716    -0.0213358    0.231151     0.0369427
  0.014227    -0.135491     -0.154039     0.151544    -0.0612686   -0.0893317     0.0761574   -0.0440842   -0.265692    -0.0832302   -0.166199    -0.0542599   0.141393    -0.0627204    -0.0355058    0.0417179   -0.149935     -0.0949405   -0.0995456    0.120283    -0.0668564   0.0657307     0.074138    -0.03962     -0.0219941    0.0237525
 -0.0756248   -0.0318942     0.220159    -0.0612287    0.0731525    0.00983585    0.0267307    0.21568     -0.0664511    0.165926    -0.122737     0.0932243   0.0168043   -0.107998     -0.144943     0.141375     0.00792981   -0.14196     -0.039055     0.106076     0.172102   -0.0914033     0.0085613    0.180864     0.0692007    0.0389429
  0.00978801  -0.0353519     0.0230743    0.0228739   -0.060586     0.128947      0.0686083    0.0189102    0.102603     0.0467714   -0.196411    -0.217367   -0.0766738    0.0911845     0.132171    -0.0432542    0.124723      0.0542045    0.162492     0.234886    -0.21361    -0.143513     -0.027969     0.0455246   -0.0235931   -0.0597081
  0.0836778    0.0295625    -0.10921     -0.114281    -0.137745     0.0424342    -0.0316793    0.12714      0.11137     -0.0340216   -0.0288948   -0.11066    -0.0814839   -0.0463399     0.0306299    0.00552464   0.0350662    -0.0299188    0.0273441   -0.0584513   -0.0205852   0.0783516    -0.0973264    0.121547     0.0498528    0.00884399
 -0.136761     0.15249      -0.00770714  -0.0276032   -0.0406607    0.083541     -0.142933    -0.0636478    0.081214     0.0242765   -0.118904    -0.0275401  -0.0619042    0.0231457    -0.151612     0.0702887   -0.0028351    -0.0463959    0.0570422    0.140126     0.0850902  -0.0469422     0.117417     0.104518    -0.0938888   -0.0310409
  0.153812    -0.183835      0.0296439    0.0607546   -0.0583437   -0.0146208    -0.00663932  -0.0102477   -0.102896     0.13302     -0.158814    -0.122546   -0.107266     0.0597934    -0.0187353    0.0942329    0.0112553    -0.252822     0.132019    -0.0293969   -0.0535487  -0.068273      0.12039     -0.00552636   0.0134301    0.136765[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      9
│     12
│     19
│     24
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.080294
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     25
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.044939
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      9
│     12
│     19
│      ⋮
│     24
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.064097
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     25
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.053254
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      9
│     12
│     19
│     23
│     24
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.070160
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     25
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.040484
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      9
│     12
│     19
│     23
│     24
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.077875
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     25
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.046882
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      9
│     12
│     19
│      ⋮
│     24
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.067014
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     25
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.050821
┌ Info: EM with 100000 data points 10 iterations avll -1.050821
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.00756762  -0.114994      0.0646709   -0.119885     0.0089062    0.0429564     0.214124    -0.0739639    0.0964704   -0.0315391   0.0494631   -0.0300615    -0.0298814    -0.00271759   0.0123618   0.0134912   -0.0998063   -0.0252734    0.119919     0.0238907    0.030572    -0.113801   -0.300773     0.0267154   -0.0056109   -0.0450415
 -0.114224    -0.11926       0.113877    -0.0839159   -0.0927427   -0.00978202   -0.0695299   -0.0911235    0.0490919   -0.0268574  -0.087101     0.165476      0.00206259    0.129501    -0.0300881  -0.0678726    0.285057    -0.0289234    0.0850837    0.137348     0.0764756   -0.0305727  -0.0816236   -0.00262896   0.0367496    0.0148785
 -0.0617624   -0.0278481    -0.111512    -0.132489     0.0527938    0.0151849    -0.123976    -0.00216757  -0.0584606   -0.0547619  -0.0898335   -0.000985678  -0.0914763    -0.0556641    0.112383    0.0157905    0.102578    -0.037445    -0.0617421    0.179728     0.20513     -0.0287867  -0.0367735    0.073991     0.0863566   -0.0579032
 -0.0727729    0.0971132    -0.0756999    0.0671508    0.00932073  -0.12123       0.11606     -0.00604779   0.107233    -0.270784   -0.0225859   -0.060675      0.0617216     0.105413    -0.0370172   0.0538232   -0.0689529    0.0339281    0.0240982    0.00815803  -0.174006    -0.0132763   0.0647208    0.00265221   0.0221645    0.123934
 -0.027222     0.180053      0.0843185   -0.0417074   -0.00103341  -0.207863      0.0756023   -0.112656     0.115613    -0.0249867  -0.107063    -0.16755       0.0456934    -0.0588595   -0.13481    -0.00553019  -0.0513069   -0.0858049   -0.00609873  -0.197051    -0.0778231    0.13621     0.0244896   -0.125472    -0.169626     0.0919911
 -0.07047     -0.17299       0.0620151   -0.164249    -0.176069     0.0997397    -0.199016     0.0500117   -0.12884     -0.0542657   0.0509417    0.0583443     0.00189085   -0.0242259   -0.0213735  -0.017892     0.0807868    0.00828231  -0.0277559   -0.0972331   -0.166155    -0.0215063  -0.147328     0.0386493    0.0452956    0.158834
 -0.096652    -0.21535      -0.170311    -0.0276804    0.134554    -0.135531     -0.0740841   -0.0268813    0.11357     -0.0533917  -0.0747775   -0.130634     -0.0554232     0.0972458    0.0126227  -0.0942333   -0.159532    -0.0569321   -0.043464     0.0827567   -0.0968536   -0.164222    0.145879     0.0714102    0.0143532    0.0758103
 -0.0115316    0.0435366    -0.0752187   -0.0427676   -0.0648767    0.0432212    -0.00694312   0.0149117   -0.129326     0.089898    0.132851     0.0659238     0.0555951    -0.0587127   -0.100874   -0.101724    -0.0660922   -0.205397     0.04416     -0.111234    -0.122493     0.0677132  -0.118873     0.0136711    0.0929686   -0.111904
  0.049541     0.0200734     0.0696958    0.0960007   -0.0348116   -0.0967147    -0.0779816    0.0516997   -0.0914105    0.0174592  -0.00832694  -0.117788      0.146166     -0.00929332  -0.173956   -0.0781504    0.0310732   -0.0755738    0.280078     0.0948527    0.0518081   -0.0222383   0.00913254  -0.0339293   -0.0732234   -0.141589
 -0.0932954   -0.0981157     0.0266361   -0.0647478   -0.199528    -0.0285644     0.0100837   -0.0259406   -0.0505027   -0.0356104  -0.0313357    0.0158095     0.0104243    -0.117764     0.131965    0.07699     -0.0242915   -0.0725844   -0.0951359   -0.177371     0.189649    -0.175065   -0.0535844   -0.01792     -0.0914053    0.104447
 -0.0478145    0.00236763   -0.0442388   -0.0286815    0.0647315    0.240333      0.135054    -0.0347917    0.0893341    0.116667   -0.103318     0.05542       0.0270912    -0.0385183   -0.0547765  -0.061774    -0.0624282   -0.0183136   -0.153027     0.197785     0.0781949   -0.0666929   0.090053    -0.0100446   -0.10847      0.0674425
  0.0538276   -0.0471605     0.107112    -0.0391193   -0.0848363   -0.0798782    -0.181518     0.0541799    0.051781    -0.0430516   0.19396     -0.0511055     0.0298058     0.0345117    0.0357141   0.0399914    0.132114    -0.103081    -0.129944    -0.0503524    0.0497026    0.0459154  -0.0721816    0.228805    -0.038423     0.110418
  0.0580673   -0.118616     -0.0130375    0.189166    -0.0411944   -0.197822      0.0598989    0.0619199    0.147903    -0.0445783   0.0193063   -0.162564      0.0321883     0.0286261   -0.0380308   0.0644411   -0.0299266   -0.0340234   -0.304169     0.0179247   -0.133029     0.113409   -0.242188     0.0330622   -0.110821     0.0427008
  0.00674836  -0.110658     -0.0410142   -0.112648    -0.152613    -0.0696771    -0.0328917   -0.0490416   -0.0522868    0.121172    0.0926184   -0.0728072     0.167935     -0.0690236   -0.0239689   0.0796961   -0.0193995   -0.155759     0.0926953   -0.0440114    0.163004     0.0906053  -0.0600074   -0.200992     0.00332556   0.231677
  0.107244     0.139305     -0.0189347   -0.258918     0.124672     0.0454016     0.114218    -0.164765     0.0375916   -0.118653   -0.0519243   -0.0876056    -0.0426531    -0.0450593    0.153232   -0.144663    -0.158712    -0.0423318    0.156115     0.05345      0.101117    -0.0210128   0.027292    -0.214406     0.0829821    0.0314185
  0.0832081   -0.0613357     0.0827158   -0.0232438   -0.124859     0.000481155  -0.0127536   -0.102171     0.171086     0.108623   -0.236448    -0.170624     -0.0564645    -0.145763     0.0671348   0.109716     0.230786     0.205914    -0.0330482    0.0330183   -0.0225867   -0.131531    0.112994     0.0615614    0.12283     -0.0375369
  0.103349    -0.0324957    -0.126419     0.0953659    0.167935     0.0783865     0.0438202    0.0150879    0.138186    -0.0198668  -0.0709288    0.0024662    -0.0389486    -0.0269653    0.0715457   0.186021    -0.103265     0.0101204   -0.0864369    0.0744646    0.191663    -0.0441933  -0.0684091    0.0917046   -0.111387    -0.0423895
 -0.0339892   -0.0233885     0.00907843   0.0149598    0.0606391    0.062903      0.0212772   -0.0483104   -0.0514958   -0.0779473  -0.0790681   -0.128223     -0.0394763    -0.0320761   -0.107049   -0.00254802  -0.199428     0.257348     0.118121     0.121587     0.0559931   -0.0865109   0.0330421   -0.0918532   -0.0389726    0.0675123
  0.0561159   -0.116173     -0.12924      0.194217    -0.00269736   0.141165     -0.0439366    0.0877055    0.0967909    0.112201   -0.167091     0.101219      0.0895309    -0.152484    -0.0896235   0.0434667    0.154678    -0.0355212   -0.0548151   -0.00200513   0.0128565    0.0149206  -0.0886715   -0.0716851    0.078638    -0.0768249
 -0.0330564   -0.0253796     0.0128783    0.0771521   -0.0723901   -0.203303      0.0124144    0.0625639    0.084517     0.0548147  -0.062012     0.0901885     0.0361817    -0.166216     0.0135277  -0.072856     0.0456362   -0.0542956    0.00956067  -0.0666861    0.0442719   -0.15639     0.083419     0.116012    -0.215008    -0.00907131
 -0.0794592   -0.0350181    -0.0111628    0.0684422   -0.0497755    0.0986997    -0.157805    -0.102146     0.00779046   0.245453   -0.0911847    0.0506948    -0.000852502  -0.081945    -0.0196723   0.0813207    0.0242329    0.0174697   -0.066497     0.0976406   -0.119678    -0.116442   -0.195797    -0.01384      0.0248631    0.0529565
  0.01013     -0.0213517     0.0792565   -0.0590694    0.0982444   -0.0760336     0.114442     0.279498    -0.00536118   0.0473908  -0.04156      0.0237206     0.0648159     0.126516     0.015185   -0.0295991   -0.125532    -0.0873401    0.0233402    0.122762    -0.054319     0.0258945  -0.0200406   -0.153677     0.0423654    0.0468035
 -0.134509     0.0438223    -0.00782931  -0.0770006    0.00533919  -0.240932     -0.0627086    0.0301569   -0.120645    -0.235461   -0.0213506   -0.00623165    0.210383      0.111281     0.0787742  -0.124459    -0.055893     0.130023    -0.139325    -0.15084     -0.127795     0.134378   -0.0445557    0.0416398    0.22404     -0.0366844
 -0.0254508    0.0637501     0.0593465    0.0366381    0.0360354    0.104283     -0.0808445    0.0263688   -0.254692    -0.0469051   0.126611     0.0638611    -0.123781     -0.12529     -0.164796   -0.154529     0.00471721   0.163354    -0.127635     0.196303    -0.0289695    0.140727   -0.0407455    0.116786    -0.185434     0.16263
 -0.12891     -0.161976     -0.147102    -0.162979     0.0538218   -0.0226174     0.0842728   -0.164446     0.0555651   -0.01512    -0.200253    -0.064161     -0.132204     -0.0918273    0.202335   -0.0506465    0.191128     0.150185     0.177583     0.00937786   0.127989    -0.0274194  -0.0192219    0.0516771   -0.0485855    0.0776271
  0.00167672   0.0576075    -0.0249863    0.00461209   0.00733336  -0.0101278     0.128656     0.0626198    0.0546747   -0.0936004   0.0600153   -0.0240098     0.170721     -0.0344076   -0.0968446   0.140687    -0.105042    -0.119755     0.0478445    0.112093     0.0712576   -0.0316855   0.0156075   -0.0757351    0.0497502   -0.220973
 -0.177807    -0.143233      0.14849     -0.110741     0.151632    -0.150286     -0.0696068   -0.0917706   -0.0946657    0.0550921  -0.202046     0.100948     -0.0611465    -0.070608     0.0534006  -0.129084     0.0559549   -0.0596208    0.0566373    0.17673     -0.0718197    0.150136    0.0210359    0.204734     0.12637      0.0953418
 -0.0270153    0.0730383     0.0660293   -0.00952026   0.0577519   -0.0964057     0.141199    -0.100443     0.0786874    0.0223684   0.118412     0.0277236    -0.324858     -0.116273     0.0341484   0.0991197    0.0725966    0.205753     0.0548227   -0.0511701   -0.00241562  -0.10044     0.122566    -0.0609253   -0.0335701    0.172718
 -0.204041    -0.000949254   0.044376    -0.0889216   -0.170396     0.0349149    -0.136852    -0.0787935   -0.118183     0.0582186   0.00394723  -0.0242662    -0.131562      0.0422883   -0.0405489  -0.0528765    0.170436     0.0488884   -0.0242532   -0.0851583    0.0610998    0.0342379  -0.11558      0.0190731   -0.0406718    0.0551092
  0.120716     0.0444929    -0.0652794   -0.00318156   0.111817     0.0891751     0.052994     0.131451    -0.014062     0.114301   -0.0845017    0.0656904    -0.0240999    -0.0858732    0.0259082  -0.12331     -0.0186634    0.200933    -0.120447     0.0420965    0.0766172    0.0774755  -0.13862     -0.0071525    0.00155773   0.271233
 -0.0760412    0.0465252    -0.132991    -0.219063    -0.0671892    0.117129      0.0302917   -0.0178033    0.128343     0.136651    0.143284    -0.0693977    -0.0603233     0.0935114    0.137071    0.146466    -0.0175784   -0.0997324   -0.114574     0.0277389   -0.132412     0.0871671  -0.00725856   0.0412183    0.127556     0.00924922
 -0.00787693   0.033627      0.153742     0.0119252    0.0155627    0.153838      0.0547927   -0.128802    -0.12417      0.0703541   0.200789    -0.0534989     0.223776      0.0997501   -0.139506    0.07131     -0.0541784    0.0301038    0.0805101   -0.0582471   -0.0591656    0.0888392  -0.13536     -0.0126893   -0.0790007    0.150913kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4221851099995118
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422205
[ Info: iteration 2, average log likelihood -1.422128
[ Info: iteration 3, average log likelihood -1.422061
[ Info: iteration 4, average log likelihood -1.421977
[ Info: iteration 5, average log likelihood -1.421875
[ Info: iteration 6, average log likelihood -1.421758
[ Info: iteration 7, average log likelihood -1.421632
[ Info: iteration 8, average log likelihood -1.421496
[ Info: iteration 9, average log likelihood -1.421329
[ Info: iteration 10, average log likelihood -1.421073
[ Info: iteration 11, average log likelihood -1.420634
[ Info: iteration 12, average log likelihood -1.419919
[ Info: iteration 13, average log likelihood -1.418956
[ Info: iteration 14, average log likelihood -1.417991
[ Info: iteration 15, average log likelihood -1.417301
[ Info: iteration 16, average log likelihood -1.416931
[ Info: iteration 17, average log likelihood -1.416764
[ Info: iteration 18, average log likelihood -1.416693
[ Info: iteration 19, average log likelihood -1.416663
[ Info: iteration 20, average log likelihood -1.416651
[ Info: iteration 21, average log likelihood -1.416645
[ Info: iteration 22, average log likelihood -1.416643
[ Info: iteration 23, average log likelihood -1.416641
[ Info: iteration 24, average log likelihood -1.416641
[ Info: iteration 25, average log likelihood -1.416640
[ Info: iteration 26, average log likelihood -1.416640
[ Info: iteration 27, average log likelihood -1.416640
[ Info: iteration 28, average log likelihood -1.416639
[ Info: iteration 29, average log likelihood -1.416639
[ Info: iteration 30, average log likelihood -1.416639
[ Info: iteration 31, average log likelihood -1.416639
[ Info: iteration 32, average log likelihood -1.416639
[ Info: iteration 33, average log likelihood -1.416638
[ Info: iteration 34, average log likelihood -1.416638
[ Info: iteration 35, average log likelihood -1.416638
[ Info: iteration 36, average log likelihood -1.416638
[ Info: iteration 37, average log likelihood -1.416638
[ Info: iteration 38, average log likelihood -1.416638
[ Info: iteration 39, average log likelihood -1.416638
[ Info: iteration 40, average log likelihood -1.416638
[ Info: iteration 41, average log likelihood -1.416638
[ Info: iteration 42, average log likelihood -1.416638
[ Info: iteration 43, average log likelihood -1.416638
[ Info: iteration 44, average log likelihood -1.416638
[ Info: iteration 45, average log likelihood -1.416638
[ Info: iteration 46, average log likelihood -1.416638
[ Info: iteration 47, average log likelihood -1.416638
[ Info: iteration 48, average log likelihood -1.416638
[ Info: iteration 49, average log likelihood -1.416638
[ Info: iteration 50, average log likelihood -1.416638
┌ Info: EM with 100000 data points 50 iterations avll -1.416638
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4222049762839204
│     -1.422127922820899
│      ⋮
└     -1.4166375585789899
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416657
[ Info: iteration 2, average log likelihood -1.416577
[ Info: iteration 3, average log likelihood -1.416506
[ Info: iteration 4, average log likelihood -1.416417
[ Info: iteration 5, average log likelihood -1.416310
[ Info: iteration 6, average log likelihood -1.416194
[ Info: iteration 7, average log likelihood -1.416083
[ Info: iteration 8, average log likelihood -1.415992
[ Info: iteration 9, average log likelihood -1.415925
[ Info: iteration 10, average log likelihood -1.415878
[ Info: iteration 11, average log likelihood -1.415844
[ Info: iteration 12, average log likelihood -1.415817
[ Info: iteration 13, average log likelihood -1.415795
[ Info: iteration 14, average log likelihood -1.415775
[ Info: iteration 15, average log likelihood -1.415757
[ Info: iteration 16, average log likelihood -1.415740
[ Info: iteration 17, average log likelihood -1.415723
[ Info: iteration 18, average log likelihood -1.415707
[ Info: iteration 19, average log likelihood -1.415690
[ Info: iteration 20, average log likelihood -1.415673
[ Info: iteration 21, average log likelihood -1.415656
[ Info: iteration 22, average log likelihood -1.415638
[ Info: iteration 23, average log likelihood -1.415621
[ Info: iteration 24, average log likelihood -1.415604
[ Info: iteration 25, average log likelihood -1.415587
[ Info: iteration 26, average log likelihood -1.415570
[ Info: iteration 27, average log likelihood -1.415554
[ Info: iteration 28, average log likelihood -1.415538
[ Info: iteration 29, average log likelihood -1.415524
[ Info: iteration 30, average log likelihood -1.415510
[ Info: iteration 31, average log likelihood -1.415497
[ Info: iteration 32, average log likelihood -1.415485
[ Info: iteration 33, average log likelihood -1.415474
[ Info: iteration 34, average log likelihood -1.415464
[ Info: iteration 35, average log likelihood -1.415455
[ Info: iteration 36, average log likelihood -1.415446
[ Info: iteration 37, average log likelihood -1.415438
[ Info: iteration 38, average log likelihood -1.415430
[ Info: iteration 39, average log likelihood -1.415423
[ Info: iteration 40, average log likelihood -1.415417
[ Info: iteration 41, average log likelihood -1.415411
[ Info: iteration 42, average log likelihood -1.415406
[ Info: iteration 43, average log likelihood -1.415401
[ Info: iteration 44, average log likelihood -1.415396
[ Info: iteration 45, average log likelihood -1.415392
[ Info: iteration 46, average log likelihood -1.415388
[ Info: iteration 47, average log likelihood -1.415384
[ Info: iteration 48, average log likelihood -1.415381
[ Info: iteration 49, average log likelihood -1.415378
[ Info: iteration 50, average log likelihood -1.415375
┌ Info: EM with 100000 data points 50 iterations avll -1.415375
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.41665716416237
│     -1.4165768818177376
│      ⋮
└     -1.4153752465604852
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415387
[ Info: iteration 2, average log likelihood -1.415326
[ Info: iteration 3, average log likelihood -1.415273
[ Info: iteration 4, average log likelihood -1.415209
[ Info: iteration 5, average log likelihood -1.415127
[ Info: iteration 6, average log likelihood -1.415028
[ Info: iteration 7, average log likelihood -1.414914
[ Info: iteration 8, average log likelihood -1.414792
[ Info: iteration 9, average log likelihood -1.414672
[ Info: iteration 10, average log likelihood -1.414560
[ Info: iteration 11, average log likelihood -1.414459
[ Info: iteration 12, average log likelihood -1.414369
[ Info: iteration 13, average log likelihood -1.414289
[ Info: iteration 14, average log likelihood -1.414218
[ Info: iteration 15, average log likelihood -1.414154
[ Info: iteration 16, average log likelihood -1.414097
[ Info: iteration 17, average log likelihood -1.414045
[ Info: iteration 18, average log likelihood -1.413998
[ Info: iteration 19, average log likelihood -1.413956
[ Info: iteration 20, average log likelihood -1.413918
[ Info: iteration 21, average log likelihood -1.413883
[ Info: iteration 22, average log likelihood -1.413852
[ Info: iteration 23, average log likelihood -1.413823
[ Info: iteration 24, average log likelihood -1.413798
[ Info: iteration 25, average log likelihood -1.413775
[ Info: iteration 26, average log likelihood -1.413754
[ Info: iteration 27, average log likelihood -1.413736
[ Info: iteration 28, average log likelihood -1.413719
[ Info: iteration 29, average log likelihood -1.413704
[ Info: iteration 30, average log likelihood -1.413691
[ Info: iteration 31, average log likelihood -1.413679
[ Info: iteration 32, average log likelihood -1.413668
[ Info: iteration 33, average log likelihood -1.413658
[ Info: iteration 34, average log likelihood -1.413650
[ Info: iteration 35, average log likelihood -1.413642
[ Info: iteration 36, average log likelihood -1.413634
[ Info: iteration 37, average log likelihood -1.413628
[ Info: iteration 38, average log likelihood -1.413622
[ Info: iteration 39, average log likelihood -1.413617
[ Info: iteration 40, average log likelihood -1.413612
[ Info: iteration 41, average log likelihood -1.413608
[ Info: iteration 42, average log likelihood -1.413604
[ Info: iteration 43, average log likelihood -1.413601
[ Info: iteration 44, average log likelihood -1.413598
[ Info: iteration 45, average log likelihood -1.413595
[ Info: iteration 46, average log likelihood -1.413592
[ Info: iteration 47, average log likelihood -1.413590
[ Info: iteration 48, average log likelihood -1.413588
[ Info: iteration 49, average log likelihood -1.413585
[ Info: iteration 50, average log likelihood -1.413584
┌ Info: EM with 100000 data points 50 iterations avll -1.413584
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4153866635289036
│     -1.4153259529314943
│      ⋮
└     -1.4135835388163063
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413593
[ Info: iteration 2, average log likelihood -1.413523
[ Info: iteration 3, average log likelihood -1.413459
[ Info: iteration 4, average log likelihood -1.413380
[ Info: iteration 5, average log likelihood -1.413281
[ Info: iteration 6, average log likelihood -1.413162
[ Info: iteration 7, average log likelihood -1.413029
[ Info: iteration 8, average log likelihood -1.412889
[ Info: iteration 9, average log likelihood -1.412751
[ Info: iteration 10, average log likelihood -1.412620
[ Info: iteration 11, average log likelihood -1.412499
[ Info: iteration 12, average log likelihood -1.412387
[ Info: iteration 13, average log likelihood -1.412285
[ Info: iteration 14, average log likelihood -1.412191
[ Info: iteration 15, average log likelihood -1.412107
[ Info: iteration 16, average log likelihood -1.412032
[ Info: iteration 17, average log likelihood -1.411966
[ Info: iteration 18, average log likelihood -1.411906
[ Info: iteration 19, average log likelihood -1.411854
[ Info: iteration 20, average log likelihood -1.411806
[ Info: iteration 21, average log likelihood -1.411764
[ Info: iteration 22, average log likelihood -1.411725
[ Info: iteration 23, average log likelihood -1.411689
[ Info: iteration 24, average log likelihood -1.411656
[ Info: iteration 25, average log likelihood -1.411626
[ Info: iteration 26, average log likelihood -1.411597
[ Info: iteration 27, average log likelihood -1.411570
[ Info: iteration 28, average log likelihood -1.411544
[ Info: iteration 29, average log likelihood -1.411520
[ Info: iteration 30, average log likelihood -1.411496
[ Info: iteration 31, average log likelihood -1.411474
[ Info: iteration 32, average log likelihood -1.411452
[ Info: iteration 33, average log likelihood -1.411431
[ Info: iteration 34, average log likelihood -1.411411
[ Info: iteration 35, average log likelihood -1.411391
[ Info: iteration 36, average log likelihood -1.411372
[ Info: iteration 37, average log likelihood -1.411353
[ Info: iteration 38, average log likelihood -1.411335
[ Info: iteration 39, average log likelihood -1.411318
[ Info: iteration 40, average log likelihood -1.411302
[ Info: iteration 41, average log likelihood -1.411286
[ Info: iteration 42, average log likelihood -1.411270
[ Info: iteration 43, average log likelihood -1.411255
[ Info: iteration 44, average log likelihood -1.411241
[ Info: iteration 45, average log likelihood -1.411227
[ Info: iteration 46, average log likelihood -1.411214
[ Info: iteration 47, average log likelihood -1.411202
[ Info: iteration 48, average log likelihood -1.411190
[ Info: iteration 49, average log likelihood -1.411179
[ Info: iteration 50, average log likelihood -1.411168
┌ Info: EM with 100000 data points 50 iterations avll -1.411168
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4135931199734852
│     -1.4135234784977098
│      ⋮
└     -1.4111678570712676
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411167
[ Info: iteration 2, average log likelihood -1.411097
[ Info: iteration 3, average log likelihood -1.411030
[ Info: iteration 4, average log likelihood -1.410949
[ Info: iteration 5, average log likelihood -1.410845
[ Info: iteration 6, average log likelihood -1.410713
[ Info: iteration 7, average log likelihood -1.410552
[ Info: iteration 8, average log likelihood -1.410369
[ Info: iteration 9, average log likelihood -1.410173
[ Info: iteration 10, average log likelihood -1.409977
[ Info: iteration 11, average log likelihood -1.409793
[ Info: iteration 12, average log likelihood -1.409629
[ Info: iteration 13, average log likelihood -1.409486
[ Info: iteration 14, average log likelihood -1.409365
[ Info: iteration 15, average log likelihood -1.409262
[ Info: iteration 16, average log likelihood -1.409176
[ Info: iteration 17, average log likelihood -1.409103
[ Info: iteration 18, average log likelihood -1.409040
[ Info: iteration 19, average log likelihood -1.408987
[ Info: iteration 20, average log likelihood -1.408940
[ Info: iteration 21, average log likelihood -1.408899
[ Info: iteration 22, average log likelihood -1.408862
[ Info: iteration 23, average log likelihood -1.408829
[ Info: iteration 24, average log likelihood -1.408798
[ Info: iteration 25, average log likelihood -1.408770
[ Info: iteration 26, average log likelihood -1.408744
[ Info: iteration 27, average log likelihood -1.408719
[ Info: iteration 28, average log likelihood -1.408696
[ Info: iteration 29, average log likelihood -1.408674
[ Info: iteration 30, average log likelihood -1.408653
[ Info: iteration 31, average log likelihood -1.408633
[ Info: iteration 32, average log likelihood -1.408614
[ Info: iteration 33, average log likelihood -1.408595
[ Info: iteration 34, average log likelihood -1.408577
[ Info: iteration 35, average log likelihood -1.408560
[ Info: iteration 36, average log likelihood -1.408542
[ Info: iteration 37, average log likelihood -1.408526
[ Info: iteration 38, average log likelihood -1.408509
[ Info: iteration 39, average log likelihood -1.408493
[ Info: iteration 40, average log likelihood -1.408478
[ Info: iteration 41, average log likelihood -1.408462
[ Info: iteration 42, average log likelihood -1.408447
[ Info: iteration 43, average log likelihood -1.408433
[ Info: iteration 44, average log likelihood -1.408419
[ Info: iteration 45, average log likelihood -1.408405
[ Info: iteration 46, average log likelihood -1.408391
[ Info: iteration 47, average log likelihood -1.408378
[ Info: iteration 48, average log likelihood -1.408365
[ Info: iteration 49, average log likelihood -1.408353
[ Info: iteration 50, average log likelihood -1.408341
┌ Info: EM with 100000 data points 50 iterations avll -1.408341
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4111666727585657
│     -1.4110973379787732
│      ⋮
└     -1.4083413239073153
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4221851099995118
│     -1.4222049762839204
│     -1.422127922820899
│     -1.4220607765058726
│      ⋮
│     -1.408365483748053
│     -1.408353204050409
└     -1.4083413239073153
32×26 Array{Float64,2}:
 -0.0618281  -0.066375    0.405702     0.176085     0.00911797  -0.27751     -0.637326     0.0208461   0.36137    -0.221628   -0.172512    0.586465     0.323988    0.0346921   -0.0862084   0.0389221    0.108625   -0.257024    0.073099   -0.083297     -0.034632    0.0198138   -0.163155     0.166385     0.387547   -0.213895
  0.22045     0.0642768  -0.279217    -0.126017    -0.025193     0.643762    -0.337242    -0.0192274   0.218064   -0.255408    0.092061   -0.29423      0.0748306   0.28139      0.162402   -0.0888689   -0.342617    0.169786   -0.549142    0.10009      -0.051818   -0.607996     0.0191305   -0.214197    -0.193049   -0.135624
 -0.090291    0.165539   -0.0650635   -0.43991     -0.382589    -0.596729     0.702119    -0.0986168  -0.34612     0.56637     0.0818835  -0.552684    -0.0351534  -0.444617    -0.273492   -0.110471     0.237849    0.028127    0.199964   -0.0440428    -0.191953    0.434129     0.273256    -0.370182    -0.195618    0.130114
 -0.0346465   0.333181   -0.425895     0.579998     0.300393    -0.531752     0.0814844    0.379994    0.213906    0.729477    0.419475    0.215429    -0.514668   -0.105901     0.116392   -0.0622596    0.0766083   0.51316     0.419963   -0.0279205    -0.252857    0.0309087    0.0168728    0.333437    -0.305515    0.265068
 -0.539744    0.286239   -0.446565     0.0910112    0.374562    -0.375835     0.0141093   -0.126461   -1.12182    -0.303282    0.238819   -0.269592     0.246289    0.0149179    0.105412   -0.0368798   -0.137485   -0.377009    0.371801   -0.224956      0.0449602   0.120765     0.113248     0.0412084   -0.050245    0.896115
  0.32925     0.270094    0.099542     0.0671767    0.623314     0.355319     0.259289     0.178472   -0.650564   -0.188348   -0.266839   -0.382954    -0.333998   -0.0787562    0.257075   -0.174597     0.412391   -0.392903    0.473828    0.0650567    -0.135296    0.368843    -0.229222    -0.599562     0.642985    0.240309
  0.0364263   0.186659   -0.300128     1.08301      0.498693     0.785258    -0.545938     1.38022    -0.986686    0.440263   -0.103329    0.0644111    0.0213502   0.00965675   0.100125   -0.171185    -0.0642296   1.12039    -0.622105    0.298842      0.2294      1.07056     -0.578813     0.326207     0.907537    0.877214
  0.127739    0.543951    0.0289703    0.207869    -0.0316166    0.169831    -0.202445     0.728419   -0.302572    0.241598    0.074278    0.033086     0.284361    0.170129     0.98069     0.458106    -0.169354    0.305631   -0.20957     0.00977387    0.0111571  -0.468785    -0.0143008   -0.138269     0.500094    0.418095
  0.295786   -0.151574    0.38314     -0.54149      0.810252    -0.564464    -0.666013    -0.442816   -0.201893    0.251166   -0.237514   -0.663123    -0.485462   -0.0285307   -0.171182   -0.286025    -0.23299     0.32803     0.0221395  -0.311452      0.522179    0.218028     0.266489     0.236612     0.210346   -0.255476
  0.102191   -0.61428     0.405925    -0.269067    -0.138898     0.478961     0.377559    -0.229755    0.484081    0.317266   -0.677844   -0.65984     -0.582896   -0.0222631   -0.0542193   0.00956765   0.26964     0.510438   -0.299073   -0.600554      0.125343    0.163642     0.19687     -0.323625     0.124557   -0.520018
 -0.12161    -0.757474   -0.136768     0.174355     0.80704     -0.152439     0.301841     0.0239909  -0.301243   -0.352151   -0.629561    0.0551302   -0.363625   -0.0588822    0.351713   -0.172573     0.288446   -0.0289043  -0.485265    0.240841      0.0692622   0.294313    -0.25385      0.482834    -0.270487    0.0217762
 -0.0513963  -0.221934    0.31289      0.61458      0.0800191   -0.262744     0.126625    -0.114246    0.634468   -0.254903   -0.53343     0.506343    -0.179316   -0.147771     0.322872   -0.220932    -0.15895    -0.092116    0.520907    0.137608     -0.278826    0.403794    -0.0550061    0.15701     -0.220565   -0.507283
 -0.536928   -0.240161    0.30037     -0.196256    -0.465874     0.0984625   -0.335392    -0.317421   -0.630042   -0.567988   -0.0169047  -0.159031     0.600675   -0.4205       0.356169    0.212996     0.134198    0.13994    -0.486522    0.266621     -0.314173    0.269728    -0.443205    -0.309843    -0.149412    0.171993
 -0.713113   -0.303291    0.290717    -0.00719418  -0.363481     0.458329    -0.928791     0.177506    0.0488836  -0.728919    0.207674    0.136359     0.183496   -0.191568     0.20076     0.0919503    0.0782992  -0.350043   -0.463938    0.233319      0.314892    0.00674786   0.240014     0.141547     0.463674   -0.590589
 -0.460622   -0.417049   -0.25148     -0.0700861   -0.483688     0.51265      1.06353      0.25426     0.293236   -0.092244   -0.554014    0.393657     0.232763    0.21711      0.132712    0.228556     0.248528   -0.331394   -0.562159    0.933443     -0.308017   -0.434817    -0.445614     0.131666    -0.320995    0.128284
  0.642717    0.03903    -0.410195    -0.771513    -0.456427     0.842197     1.44129     -0.281344    0.417699   -0.132626    0.387715    0.0229928    0.0624858   0.00963656   0.148005   -0.230843    -0.0958784   0.0713936   0.605755    1.01715      -0.253452    0.415148    -0.19285      0.209493     0.220995    0.77695
 -0.101897    0.686798    0.0318464    0.251724     0.395627    -0.837265    -0.60777     -0.0936395  -0.389983    0.113242    0.287701    0.108063     0.0923719  -0.220372    -0.0031046  -0.202422    -0.263603    0.306626    0.508401   -0.357863      0.0636697   0.274135    -0.0405366    0.451695     0.0211292  -0.0538832
 -0.351578   -0.0180206   0.00333868   0.129177     0.216706    -0.941775     0.436829    -0.463463   -0.345248    0.419782    0.241055   -0.440831    -0.38349    -0.513224     0.419792    0.507502    -0.110018    0.142198    0.083818    0.251329     -0.405459   -0.16583     -0.240397    -0.12261     -0.593789   -0.225832
 -0.0921954  -0.233953    0.0904531   -0.0752511    0.284338    -0.0342918    0.00392172  -0.0379244  -0.114506    0.0274664  -0.22161    -0.114788    -0.391789   -0.04882     -0.0424586   0.0177978   -0.0324257  -0.0192564   0.0135793  -0.167851      0.0565612  -0.0764864   -0.0296838    0.241633     0.0524218  -0.00758615
 -0.0474749   0.174034    0.0234331    0.0653397   -0.119269     0.0307654   -0.0726581    0.0184649  -0.0689895  -0.0621443   0.0779155   0.0800043    0.29092    -0.0205276    0.0394661   0.0173834    0.0233898  -0.0494609   0.0217944   0.0689402    -0.0584791   0.0796632   -0.0335032   -0.0868991   -0.0272591   0.147221
 -0.196124   -0.479705    0.276559    -0.697149    -0.225931    -0.250777     0.283956    -0.923924    0.488679   -0.279978    0.135568    0.270161    -0.137897   -0.151157    -0.746674   -0.371275     0.282382   -0.679147    0.283309   -0.000839519  -0.0416387  -0.12165      0.210577     0.135693    -0.589048   -0.309713
  0.0353616  -0.585752    0.464822    -0.518452    -0.475836     0.0506555    0.64748     -0.427557   -0.393051   -0.237327   -0.0430854  -0.342711     0.334684   -0.326471    -0.5027      0.462941    -0.123453   -0.964326    0.075185   -0.162619      0.495332    0.171739    -0.204532     0.201969    -0.0136984   0.620929
 -0.0208648   0.35386     0.0893454   -0.171917    -0.45882      0.00205506  -0.57448     -0.328193    0.0414391   0.0937722   0.216092   -0.459639     0.216179    0.0574817   -0.339518   -0.231845     0.120212    0.14832     0.193482   -0.639903     -0.0903437   0.0762624    0.105353    -0.767032     0.300774   -0.00105564
  0.308132    0.371212   -0.323967    -0.353302     0.0426326   -0.0799805    0.343571     0.0261064  -0.132552    0.532537    0.0984917  -0.45167     -0.110271    0.0817574   -0.193675   -0.0736129    0.0452554   0.189695    0.247456   -0.225082      0.0208232  -0.151163     0.00891193  -0.315841    -0.0401092   0.531418
 -0.815017    0.173287    0.250792    -0.247959    -0.488045    -0.237108    -0.160632     0.0947003   0.685831    0.216353    0.212317    0.358921     0.15901     0.0316818   -0.658283    0.342848    -0.251085    0.504888   -0.0327445  -0.614315      0.0545117  -0.242289     0.0822845    0.521605    -0.542406   -0.0275168
  0.379718    0.0226504   0.111275     0.28856     -0.106639    -0.157443    -0.522869    -0.22831     0.505713    0.0425265   0.0694061   0.379155     0.0637256   0.432427     0.0386385   0.733788    -0.374969    0.120624   -0.113957   -0.375293      0.38566    -0.00354091   0.151286    -0.00718808  -0.313532    0.192366
  0.0345174   0.482316    0.0597536   -0.20307     -0.00282557   0.133009    -0.275989     0.442663   -0.158796   -0.20008     0.377539    0.469439     0.027832    0.201735    -0.508976   -0.275466     0.0790664  -0.180444    0.35293     0.0941124     0.394988   -0.591892    -0.364447     0.681766     0.137663    0.192569
  0.485284   -0.120468    0.157543    -0.299118     0.0277806    0.996032    -0.291721     0.411782    0.475812   -0.0816578  -0.157362    0.411068     0.481852    0.293975    -0.641807   -0.379076    -0.133584   -0.228562   -0.0025535  -0.288704      0.305145    0.0319938   -0.0760775   -0.0241765    0.605348    0.168883
  0.269647   -0.0537966  -0.23167      0.33777     -0.348549     0.186554    -0.322542     0.29376     0.744219    0.432676   -0.0522485   0.217609     0.0526057  -0.0843576    0.129689   -0.107484     0.141932    0.734657   -0.382532    0.374126     -0.30053     0.00795457  -0.281703    -0.406977    -0.0108513  -0.556745
  0.0878273  -0.601744    0.0676156   -0.356239    -0.25658      0.454957     0.44673     -0.0554135   0.353782   -0.191616   -0.364736   -0.215639    -0.0422404   0.00955454   0.0915691  -0.0682288    0.224106   -0.363009   -0.601034    0.581598      0.0131024  -0.247217    -0.165304    -0.316762     0.0803444  -0.316317
 -0.419971   -0.287378   -0.572342     0.0376654   -0.428793    -0.364161     0.365472    -0.159456    0.121416    0.141776    0.454881   -0.00143785   0.0137528  -0.164484    -0.240581    0.0975368    0.0412116   0.245813   -0.401829    0.575511      0.0568762  -0.220629     0.55004      0.519675    -0.194297    0.0335013
  0.308146    0.0440525  -0.718027     0.129945    -0.0830176    0.113531     0.333959     0.019436   -0.0626972  -0.0514198   0.281699    0.286093     0.44607     0.00466753   0.44139    -0.186962    -0.290731   -0.320163    0.0694471   1.00412      -0.15246    -0.0436692    0.0352888   -0.181913    -0.136638    0.190347[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408330
[ Info: iteration 2, average log likelihood -1.408319
[ Info: iteration 3, average log likelihood -1.408308
[ Info: iteration 4, average log likelihood -1.408298
[ Info: iteration 5, average log likelihood -1.408288
[ Info: iteration 6, average log likelihood -1.408278
[ Info: iteration 7, average log likelihood -1.408269
[ Info: iteration 8, average log likelihood -1.408260
[ Info: iteration 9, average log likelihood -1.408251
[ Info: iteration 10, average log likelihood -1.408243
┌ Info: EM with 100000 data points 10 iterations avll -1.408243
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.146647e+05
      1       7.021822e+05      -2.124825e+05 |       32
      2       6.886088e+05      -1.357343e+04 |       32
      3       6.833406e+05      -5.268149e+03 |       32
      4       6.807039e+05      -2.636719e+03 |       32
      5       6.790683e+05      -1.635547e+03 |       32
      6       6.779440e+05      -1.124350e+03 |       32
      7       6.770360e+05      -9.079974e+02 |       32
      8       6.763116e+05      -7.244413e+02 |       32
      9       6.756788e+05      -6.327460e+02 |       32
     10       6.751591e+05      -5.196670e+02 |       32
     11       6.747572e+05      -4.019864e+02 |       32
     12       6.743955e+05      -3.616129e+02 |       32
     13       6.740812e+05      -3.143098e+02 |       32
     14       6.738076e+05      -2.735946e+02 |       32
     15       6.735523e+05      -2.553066e+02 |       32
     16       6.733117e+05      -2.406573e+02 |       32
     17       6.730895e+05      -2.221263e+02 |       32
     18       6.728863e+05      -2.032777e+02 |       32
     19       6.726953e+05      -1.909419e+02 |       32
     20       6.724973e+05      -1.979933e+02 |       32
     21       6.723071e+05      -1.901882e+02 |       32
     22       6.721336e+05      -1.735602e+02 |       32
     23       6.719844e+05      -1.491641e+02 |       32
     24       6.718498e+05      -1.345783e+02 |       32
     25       6.716986e+05      -1.512570e+02 |       32
     26       6.715417e+05      -1.569197e+02 |       32
     27       6.713879e+05      -1.537426e+02 |       32
     28       6.712456e+05      -1.423495e+02 |       32
     29       6.711113e+05      -1.342647e+02 |       32
     30       6.709924e+05      -1.188649e+02 |       32
     31       6.708890e+05      -1.034935e+02 |       32
     32       6.708084e+05      -8.054033e+01 |       32
     33       6.707383e+05      -7.010747e+01 |       32
     34       6.706779e+05      -6.042469e+01 |       32
     35       6.706136e+05      -6.426200e+01 |       32
     36       6.705505e+05      -6.312073e+01 |       32
     37       6.704881e+05      -6.235584e+01 |       32
     38       6.704262e+05      -6.195079e+01 |       32
     39       6.703745e+05      -5.170235e+01 |       32
     40       6.703257e+05      -4.876409e+01 |       32
     41       6.702843e+05      -4.138564e+01 |       32
     42       6.702470e+05      -3.737702e+01 |       32
     43       6.702097e+05      -3.726301e+01 |       32
     44       6.701668e+05      -4.293080e+01 |       32
     45       6.701208e+05      -4.598528e+01 |       32
     46       6.700742e+05      -4.653311e+01 |       32
     47       6.700239e+05      -5.035147e+01 |       32
     48       6.699728e+05      -5.109216e+01 |       32
     49       6.699211e+05      -5.171104e+01 |       32
     50       6.698758e+05      -4.528803e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 669875.8061383893)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420565
[ Info: iteration 2, average log likelihood -1.415682
[ Info: iteration 3, average log likelihood -1.414468
[ Info: iteration 4, average log likelihood -1.413657
[ Info: iteration 5, average log likelihood -1.412781
[ Info: iteration 6, average log likelihood -1.411813
[ Info: iteration 7, average log likelihood -1.410953
[ Info: iteration 8, average log likelihood -1.410363
[ Info: iteration 9, average log likelihood -1.410014
[ Info: iteration 10, average log likelihood -1.409804
[ Info: iteration 11, average log likelihood -1.409663
[ Info: iteration 12, average log likelihood -1.409559
[ Info: iteration 13, average log likelihood -1.409476
[ Info: iteration 14, average log likelihood -1.409406
[ Info: iteration 15, average log likelihood -1.409346
[ Info: iteration 16, average log likelihood -1.409292
[ Info: iteration 17, average log likelihood -1.409244
[ Info: iteration 18, average log likelihood -1.409199
[ Info: iteration 19, average log likelihood -1.409157
[ Info: iteration 20, average log likelihood -1.409118
[ Info: iteration 21, average log likelihood -1.409081
[ Info: iteration 22, average log likelihood -1.409046
[ Info: iteration 23, average log likelihood -1.409013
[ Info: iteration 24, average log likelihood -1.408981
[ Info: iteration 25, average log likelihood -1.408951
[ Info: iteration 26, average log likelihood -1.408922
[ Info: iteration 27, average log likelihood -1.408895
[ Info: iteration 28, average log likelihood -1.408869
[ Info: iteration 29, average log likelihood -1.408844
[ Info: iteration 30, average log likelihood -1.408820
[ Info: iteration 31, average log likelihood -1.408797
[ Info: iteration 32, average log likelihood -1.408776
[ Info: iteration 33, average log likelihood -1.408755
[ Info: iteration 34, average log likelihood -1.408735
[ Info: iteration 35, average log likelihood -1.408716
[ Info: iteration 36, average log likelihood -1.408698
[ Info: iteration 37, average log likelihood -1.408680
[ Info: iteration 38, average log likelihood -1.408663
[ Info: iteration 39, average log likelihood -1.408647
[ Info: iteration 40, average log likelihood -1.408631
[ Info: iteration 41, average log likelihood -1.408616
[ Info: iteration 42, average log likelihood -1.408601
[ Info: iteration 43, average log likelihood -1.408586
[ Info: iteration 44, average log likelihood -1.408573
[ Info: iteration 45, average log likelihood -1.408559
[ Info: iteration 46, average log likelihood -1.408546
[ Info: iteration 47, average log likelihood -1.408533
[ Info: iteration 48, average log likelihood -1.408521
[ Info: iteration 49, average log likelihood -1.408509
[ Info: iteration 50, average log likelihood -1.408498
┌ Info: EM with 100000 data points 50 iterations avll -1.408498
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0978197    0.667755   -0.318564     0.280011   -0.00638401   0.00997833  -0.51856     0.126208    0.0679366    0.0935375    0.471877    -0.0260909   0.135775     0.076283      0.287587   -0.0974553  -0.313692     0.427624    -0.0344015   -0.0688908  -0.27067      -0.268586   -0.0344351    -0.267251   -0.0454752   0.0336231
 -0.537352    -0.104728   -0.498844    -0.269472    0.130764     0.375267     1.13235     0.163945   -0.185505     0.00655011  -0.198606     0.194544    0.335907    -0.127479      0.0411817  -0.132687   -0.0546445   -0.537553     0.0541566    0.685332   -0.641469     -0.539      -0.119109      0.418434   -0.261637    0.131873
 -0.0287923    0.334048    0.789639    -0.285668    0.378539     0.179492    -0.0217613   0.208475   -0.342386    -0.351994    -0.260911    -0.18339    -0.186323    -0.316977     -0.40034    -0.259199    0.0891739   -0.117391     0.479166    -0.579203    0.299516      0.223417   -0.61543      -0.166618    0.0867834   0.0645999
  0.243826     0.20662    -0.412902     0.0833853   0.490456     0.228587     0.450574    0.259701   -0.785117     0.0457512   -0.0928269   -0.422532   -0.261791    -0.122596      0.195042   -0.23648     0.484149    -0.329688     0.43193      0.177546   -0.212832      0.437061    0.0270176    -0.667814    0.551021    0.456233
 -0.768883    -0.136657    0.328625     0.202434    0.0033907   -0.461624    -1.03589     0.550706    0.0517151   -0.254305    -0.151909     0.267117    0.138121    -0.0736066    -0.261873    0.388989   -0.0737281   -0.21646     -0.309226    -0.660292    0.171117     -0.0730972   0.313329     -0.109238    0.340441   -0.905258
  0.144433    -0.372693   -0.282669     0.122617   -0.48485      0.330275     0.0451261   0.289775    0.827901     0.174296    -0.178221     0.520379    0.129672     0.0504133     0.1079      0.115656   -0.0203818    0.0763419   -0.456854     0.694176   -0.187997     -0.176595   -0.235776     -0.0879781  -0.122572   -0.320705
  0.00570322  -0.63651     0.458178    -0.458263   -0.644639    -0.0853318    0.868656   -0.469328   -0.646292    -0.170725     0.00414833  -0.223441    0.351308    -0.584638     -0.567455    0.358305   -0.0122245   -0.978616     0.167249     0.1078      0.783144      0.456769   -0.298577      0.260539   -0.0134138   0.672673
  0.614449     0.0165552  -0.467242    -0.56571    -0.404708     0.852179     1.24623    -0.270961    0.360233    -0.26292      0.298909     0.134402    0.133783    -0.000554451   0.123593   -0.280271   -0.158007     0.0385365    0.590962     0.957231   -0.223074      0.500905   -0.14015       0.0520579   0.193979    0.684555
 -0.356317     0.304638   -0.0110565    0.140841    0.47725     -0.649379    -0.150635   -0.341111   -0.778477    -0.179726     0.233373    -0.329591    0.0217081    0.04935       0.0405624   0.0705559  -0.0433408   -0.306469     0.29029     -0.192538    0.000236326   0.109415    0.0707781     0.35965    -0.0782045   0.480169
 -0.284748    -0.169298    0.537191    -0.161668   -0.631367    -0.3787      -0.146803   -0.447036    0.952704    -0.0571396    0.244585     0.583321    0.205846     0.0289312    -0.539341    0.3806     -0.216527    -0.0403826    0.190949    -0.34107     0.1738       -0.305193    0.201633      0.459484   -0.557701   -0.206228
 -0.14496      0.0646182   0.121155    -0.0540483  -0.178941    -0.0344431   -0.188763   -0.0828265   0.11253     -0.0293295    0.138611     0.119965    0.104864    -0.0457015    -0.154625    0.0572888  -0.0786314   -0.00239682   0.00454553  -0.0859985   0.0727717    -0.0663692   0.000614813   0.0793256  -0.044294    0.0178053
 -0.435253    -0.0802181   0.140969     0.126458   -0.384584    -0.260234     0.0141656  -0.319236   -0.551754    -0.00890126   0.384768    -0.145052    0.314484    -0.594204      0.58372     0.307711    0.202401     0.04356     -0.292059     0.552957   -0.350209      0.0335561  -0.352467     -0.495939   -0.219918    0.161858
 -0.07181      0.353972    0.157313    -0.231541   -0.477205     0.328928    -0.049925    0.570181   -0.243944    -0.080162     0.554104    -0.0628263   0.273979     0.0486136     0.332761    0.301147    0.156042    -0.0852465   -0.44182      0.366611    0.370281     -0.558741    0.409085      0.191493    0.258304    0.332037
  0.185575     0.2763     -0.446346     0.358075   -0.184107    -0.142567    -0.054548   -0.0359933  -0.0628208    0.299192     0.0146025   -0.105819    0.152494     0.240576      0.405588   -0.0738518  -0.18088      0.448863     0.0181437    0.0940086   0.114482      0.276581    0.227337     -0.477638   -0.148837   -0.0651596
  0.510711     0.43529     0.213523     0.169754    0.340585     0.208474    -0.2011      0.266253   -0.0715737    0.225176    -0.108408    -0.109196   -0.00848985   0.057916      0.324439    0.068741   -0.0795746    0.0850904    0.297723    -0.146136   -0.181606     -0.177082   -0.196014     -0.401632    0.394578    0.199544
  0.0126076   -0.580799    0.135006    -0.453494    0.676744     0.0383113   -0.0360074  -0.0903573  -0.210576    -0.229836    -0.471889    -0.227123   -0.667455     0.113485      0.394703    0.0813766   0.00205334   0.187717    -0.414294    -0.0975561   0.648266     -0.12524     0.0468102     0.348783    0.20788    -0.193967
  0.0962922    0.149706    0.222312    -0.23905     0.394783    -0.6726      -0.187221   -0.369204   -0.219113     0.369103    -0.170794    -0.418004   -0.289647    -0.131959     -0.229275   -0.294602   -0.111363     0.0653127    0.440365    -0.49635     0.189971      0.470062    0.31233       0.122259    0.126195    0.0631905
 -0.137189     0.349456    0.0204651   -0.0459284  -0.624511    -0.0703431   -0.991763   -0.307923   -0.00713839  -0.0762106    0.121676    -0.209519    0.601698     0.133152     -0.328365   -0.119479    0.257591     0.151036     0.215702    -0.5416     -0.145919      0.387926    0.125406     -0.747571    0.498984    0.0799224
  0.280868     0.333491   -0.2739      -0.0536689   0.347035     0.390695    -0.23907     0.202698    0.49266     -0.118868    -0.216768    -0.095509   -0.124207     0.647338     -0.513338   -0.142222   -0.379694     0.332878     0.331833    -0.551101    0.020856     -0.329862    0.195897      0.339211   -0.0622332  -0.105972
 -0.168176    -0.472712    0.00427617  -0.499988   -0.268996    -0.304614     0.38122    -0.736453    0.249474     0.129225     0.139744    -0.0358088  -0.341727    -0.116129     -0.798339   -0.299884    0.462658    -0.289125     0.220306     0.0377304  -0.0740941     0.122881    0.13471       0.12212    -0.376241   -0.00863759
  0.0638987    0.183204   -0.00322269   1.07354     0.373207     0.60737     -0.656465    1.11567    -0.680651     0.315883    -0.135107     0.125472    0.12855      0.0668492     0.357896   -0.0177118  -0.083815     0.874136    -0.454987     0.188677    0.165068      0.673924   -0.540281      0.385243    0.835447    0.721849
  0.189433    -0.267824    0.510583    -0.215915   -0.344936     0.385825     0.0112828  -0.222799    0.787924     0.463517    -0.284129    -0.62863    -0.435551    -0.232829     -0.203803   -0.119422    0.396074     0.673144    -0.372815    -0.405315   -0.0998786     0.0676583   0.0186297    -0.525953    0.138429   -0.638082
  0.50099      0.238174   -0.22148     -0.157144   -0.289933    -0.0986811    0.759924    0.255644    0.187871     0.853666    -0.059611     0.0957653   0.179954     0.783386      0.126396    0.286622    0.265402    -0.171362    -0.0891508    0.343089   -0.0478455    -0.538061   -0.169049     -0.117297   -0.0305523   0.83121
 -0.0603945   -0.518931    0.293097     0.65946     0.438702    -0.178843     0.0235192  -0.201624    0.286747    -0.358415    -0.745838     0.393941   -0.206071    -0.0576262     0.456673   -0.234803    0.0253113   -0.160924     0.098662     0.046642   -0.272666      0.410865   -0.103522      0.238986   -0.152552   -0.349744
 -0.0260868   -0.346905    0.402954    -0.482661   -0.401954     0.655585     0.225599   -0.572536    0.188931    -0.580667    -0.307544    -0.368426    0.498416     0.065144     -0.114984   -0.294467   -0.0450168   -0.722429    -0.620754     0.151801    0.180361     -0.233783    0.0831667    -0.534969   -0.014291   -0.452735
 -0.0375951    0.399999   -0.515283    -0.624573   -0.145325    -0.159786     0.0702198   0.014181   -0.349284     0.458554     0.325272    -0.792604   -0.0682079   -0.13253      -0.428541    0.0161016  -0.100837     0.269001    -0.105797    -0.422706    0.114457     -0.351273   -0.000391317  -0.213443   -0.0428304   0.537726
 -0.244607     0.26488    -0.362807     0.360403    0.285314    -0.713169    -0.0201843   0.522537    0.0940869    0.676424     0.307015     0.532111   -0.340436    -0.251316      0.016977    0.0763988  -0.0180855    0.644465     0.401423    -0.102678   -0.036681      0.0712001   0.0396617     0.58712    -0.345843    0.214807
 -0.0489575   -0.427156   -0.13546      0.0119593   0.184969    -0.0236174    0.354299    0.0455912  -0.128661    -0.0516137   -0.307633    -0.0756917  -0.169849    -0.106059      0.0901039  -0.0689366   0.190782    -0.120754    -0.189375     0.319417   -0.0800638     0.104788   -0.0937899     0.214966   -0.0752999   0.0125233
  0.140904    -0.654143    0.102037    -0.340416   -0.107554     0.463648    -0.108015    0.0508293   0.0365325   -0.197807    -0.19619     -0.121319    0.31534      0.25668      -0.0228396   0.586449   -0.501893    -0.424916    -0.0894857   -0.684369    0.112328     -0.0423201   0.0169345    -0.326704    0.295276    0.769749
 -0.340857    -0.733212   -0.0805337    0.0112645  -0.0325281    0.477966     0.0564115   0.201695   -0.00754543  -0.711483    -0.305183     0.116972    0.0779153   -0.0523672     0.20779     0.115274    0.339535    -0.125176    -0.703448     0.6839      0.0540513    -0.0470632  -0.377611      0.150502   -0.0862518  -0.142359
  0.0530153    0.387669    0.0634765   -0.127115    0.0334483    0.24953     -0.629937    0.229453    0.02785     -0.439846     0.36075      0.85617     0.422253     0.127087     -0.29507    -0.45587    -0.00588968  -0.331734     0.202247     0.254972    0.250295     -0.267777   -0.382972      0.578017    0.277736    0.0705716
 -0.327128    -0.0950366  -0.0749133    0.126514    0.0719206   -0.910669     0.647715   -0.627303    0.0379235    0.169466     0.171466    -0.381933   -0.41294     -0.757769      0.421996    0.261835   -0.479934     0.242143     0.317658     0.421959   -0.452485      0.0126181  -0.0331499     0.120051   -0.706607   -0.474537[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408487
[ Info: iteration 2, average log likelihood -1.408476
[ Info: iteration 3, average log likelihood -1.408465
[ Info: iteration 4, average log likelihood -1.408455
[ Info: iteration 5, average log likelihood -1.408446
[ Info: iteration 6, average log likelihood -1.408436
[ Info: iteration 7, average log likelihood -1.408427
[ Info: iteration 8, average log likelihood -1.408418
[ Info: iteration 9, average log likelihood -1.408410
[ Info: iteration 10, average log likelihood -1.408402
┌ Info: EM with 100000 data points 10 iterations avll -1.408402
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
