Julia Version 1.5.0-DEV.267
Commit 592ada160b (2020-02-13 16:56 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed GaussianMixtures ─── v0.3.0
  Installed Arpack_jll ───────── v3.5.0+2
  Installed CMakeWrapper ─────── v0.2.3
  Installed Blosc ────────────── v0.5.1
  Installed OrderedCollections ─ v1.1.0
  Installed NearestNeighbors ─── v0.4.4
  Installed StatsFuns ────────── v0.9.3
  Installed FileIO ───────────── v1.2.2
  Installed Arpack ───────────── v0.4.0
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed URIParser ────────── v0.4.0
  Installed DataAPI ──────────── v1.1.0
  Installed Missings ─────────── v0.4.3
  Installed QuadGK ───────────── v2.3.1
  Installed FillArrays ───────── v0.8.4
  Installed Distances ────────── v0.8.2
  Installed Compat ───────────── v2.2.0
  Installed Distributions ────── v0.22.4
  Installed BinDeps ──────────── v1.0.0
  Installed Parameters ───────── v0.12.0
  Installed SpecialFunctions ─── v0.9.0
  Installed DataStructures ───── v0.17.9
  Installed BinaryProvider ───── v0.5.8
  Installed StatsBase ────────── v0.32.0
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed HDF5 ─────────────── v0.12.5
  Installed PDMats ───────────── v0.9.11
  Installed SortingAlgorithms ── v0.3.1
  Installed CMake ────────────── v1.2.0
  Installed ScikitLearnBase ──── v0.5.0
  Installed LegacyStrings ────── v0.4.1
  Installed JLD ──────────────── v0.9.2
  Installed StaticArrays ─────── v0.12.1
  Installed Rmath ────────────── v0.6.0
  Installed Clustering ───────── v0.13.3
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                         ##O#- #                                                                       ##O=#  #                                                                      #=#=-#  #                                                                     -#O#- #   #                                                                   -=#=#   #   #                                                                 -=O#- #  #    #                                                               -=O=#  #   #   #                                                              ######################################################################## 100.0%
#=#=#                                                                         #                                                                          2.1%####                                                                       5.7%#######                                                                   10.2%############                                                              16.7%#################                                                         24.1%########################                                                  33.9%##################################                                        47.7%############################################                              62.4%############################################################              84.1%######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.2.0
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.2
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building CMake → `~/.julia/packages/CMake/ULbyn/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_aGB2Vb/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.2.0
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.2
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -984303.7048118857, [82155.64364665945, 17844.356353340576], [-22230.527129907765 3562.785166293743 11443.954526486155; 21908.23908516664 -3736.7550122995285 -11422.296328165217], [[65630.18983715001 1597.843296265731 8666.366149283058; 1597.843296265731 75063.60578503096 -1438.39260664577; 8666.366149283058 -1438.3926066457702 74333.77996957007], [34237.47613615974 -1354.753960200578 -8263.104371682937; -1354.753960200578 25475.881468643624 1248.8717623363812; -8263.104371682935 1248.8717623363814 25353.491175144292]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.485035e+03
      1       9.340384e+02      -5.509962e+02 |        7
      2       9.072307e+02      -2.680772e+01 |        2
      3       9.057135e+02      -1.517132e+00 |        0
      4       9.057135e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 905.7135331957816)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.073516
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.774826
[ Info: iteration 2, lowerbound -3.637691
[ Info: iteration 3, lowerbound -3.489116
[ Info: iteration 4, lowerbound -3.316855
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.135694
[ Info: iteration 6, lowerbound -2.974477
[ Info: iteration 7, lowerbound -2.866930
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.815067
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.796854
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.782768
[ Info: iteration 11, lowerbound -2.771163
[ Info: iteration 12, lowerbound -2.764951
[ Info: iteration 13, lowerbound -2.756044
[ Info: iteration 14, lowerbound -2.743465
[ Info: iteration 15, lowerbound -2.726158
[ Info: iteration 16, lowerbound -2.703174
[ Info: iteration 17, lowerbound -2.673955
[ Info: iteration 18, lowerbound -2.638628
[ Info: iteration 19, lowerbound -2.598217
[ Info: iteration 20, lowerbound -2.554679
[ Info: iteration 21, lowerbound -2.510610
[ Info: iteration 22, lowerbound -2.468516
[ Info: iteration 23, lowerbound -2.429897
[ Info: iteration 24, lowerbound -2.394870
[ Info: iteration 25, lowerbound -2.362924
[ Info: iteration 26, lowerbound -2.334899
[ Info: iteration 27, lowerbound -2.314747
[ Info: iteration 28, lowerbound -2.307411
[ Info: dropping number of Gaussions to 2
[ Info: iteration 29, lowerbound -2.302944
[ Info: iteration 30, lowerbound -2.299261
[ Info: iteration 31, lowerbound -2.299256
[ Info: iteration 32, lowerbound -2.299255
[ Info: iteration 33, lowerbound -2.299254
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Fri Feb 14 05:40:07 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Fri Feb 14 05:40:15 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Fri Feb 14 05:40:18 2020: EM with 272 data points 0 iterations avll -2.073516
5.8 data points per parameter
, Fri Feb 14 05:40:20 2020: GMM converted to Variational GMM
, Fri Feb 14 05:40:28 2020: iteration 1, lowerbound -3.774826
, Fri Feb 14 05:40:28 2020: iteration 2, lowerbound -3.637691
, Fri Feb 14 05:40:28 2020: iteration 3, lowerbound -3.489116
, Fri Feb 14 05:40:28 2020: iteration 4, lowerbound -3.316855
, Fri Feb 14 05:40:29 2020: dropping number of Gaussions to 7
, Fri Feb 14 05:40:29 2020: iteration 5, lowerbound -3.135694
, Fri Feb 14 05:40:29 2020: iteration 6, lowerbound -2.974477
, Fri Feb 14 05:40:29 2020: iteration 7, lowerbound -2.866930
, Fri Feb 14 05:40:29 2020: dropping number of Gaussions to 6
, Fri Feb 14 05:40:29 2020: iteration 8, lowerbound -2.815067
, Fri Feb 14 05:40:29 2020: dropping number of Gaussions to 5
, Fri Feb 14 05:40:29 2020: iteration 9, lowerbound -2.796854
, Fri Feb 14 05:40:29 2020: dropping number of Gaussions to 3
, Fri Feb 14 05:40:29 2020: iteration 10, lowerbound -2.782768
, Fri Feb 14 05:40:29 2020: iteration 11, lowerbound -2.771163
, Fri Feb 14 05:40:29 2020: iteration 12, lowerbound -2.764951
, Fri Feb 14 05:40:29 2020: iteration 13, lowerbound -2.756044
, Fri Feb 14 05:40:29 2020: iteration 14, lowerbound -2.743465
, Fri Feb 14 05:40:29 2020: iteration 15, lowerbound -2.726158
, Fri Feb 14 05:40:29 2020: iteration 16, lowerbound -2.703174
, Fri Feb 14 05:40:29 2020: iteration 17, lowerbound -2.673955
, Fri Feb 14 05:40:29 2020: iteration 18, lowerbound -2.638628
, Fri Feb 14 05:40:29 2020: iteration 19, lowerbound -2.598217
, Fri Feb 14 05:40:29 2020: iteration 20, lowerbound -2.554679
, Fri Feb 14 05:40:29 2020: iteration 21, lowerbound -2.510610
, Fri Feb 14 05:40:29 2020: iteration 22, lowerbound -2.468516
, Fri Feb 14 05:40:29 2020: iteration 23, lowerbound -2.429897
, Fri Feb 14 05:40:29 2020: iteration 24, lowerbound -2.394870
, Fri Feb 14 05:40:29 2020: iteration 25, lowerbound -2.362924
, Fri Feb 14 05:40:29 2020: iteration 26, lowerbound -2.334899
, Fri Feb 14 05:40:29 2020: iteration 27, lowerbound -2.314747
, Fri Feb 14 05:40:29 2020: iteration 28, lowerbound -2.307411
, Fri Feb 14 05:40:29 2020: dropping number of Gaussions to 2
, Fri Feb 14 05:40:29 2020: iteration 29, lowerbound -2.302944
, Fri Feb 14 05:40:29 2020: iteration 30, lowerbound -2.299261
, Fri Feb 14 05:40:29 2020: iteration 31, lowerbound -2.299256
, Fri Feb 14 05:40:29 2020: iteration 32, lowerbound -2.299255
, Fri Feb 14 05:40:29 2020: iteration 33, lowerbound -2.299254
, Fri Feb 14 05:40:29 2020: iteration 34, lowerbound -2.299253
, Fri Feb 14 05:40:29 2020: iteration 35, lowerbound -2.299253
, Fri Feb 14 05:40:29 2020: iteration 36, lowerbound -2.299253
, Fri Feb 14 05:40:29 2020: iteration 37, lowerbound -2.299253
, Fri Feb 14 05:40:29 2020: iteration 38, lowerbound -2.299253
, Fri Feb 14 05:40:29 2020: iteration 39, lowerbound -2.299253
, Fri Feb 14 05:40:29 2020: iteration 40, lowerbound -2.299253
, Fri Feb 14 05:40:29 2020: iteration 41, lowerbound -2.299253
, Fri Feb 14 05:40:29 2020: iteration 42, lowerbound -2.299253
, Fri Feb 14 05:40:29 2020: iteration 43, lowerbound -2.299253
, Fri Feb 14 05:40:29 2020: iteration 44, lowerbound -2.299253
, Fri Feb 14 05:40:29 2020: iteration 45, lowerbound -2.299253
, Fri Feb 14 05:40:29 2020: iteration 46, lowerbound -2.299253
, Fri Feb 14 05:40:29 2020: iteration 47, lowerbound -2.299253
, Fri Feb 14 05:40:29 2020: iteration 48, lowerbound -2.299253
, Fri Feb 14 05:40:29 2020: iteration 49, lowerbound -2.299253
, Fri Feb 14 05:40:29 2020: iteration 50, lowerbound -2.299253
, Fri Feb 14 05:40:29 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.9549077731216, 178.0450922268784]
β = [95.9549077731216, 178.0450922268784]
m = [2.000229257768109 53.851987172423485; 4.250300733262897 79.2868669442587]
ν = [97.9549077731216, 180.0450922268784]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763612069149 -0.008953123827489725; 0.0 0.012748664777446201], [0.18404155547388815 -0.007644049042420107; 0.0 0.008581705166203869]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999994
avll from stats: -0.9771954053026957
avll from llpg:  -0.9771954053026477
avll direct:     -0.9771954053026477
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9892445188816592
avll from llpg:  -0.9892445188816592
avll direct:     -0.9892445188816592
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
  0.117425    -0.00362369   0.126349     0.0228192    0.0723449    0.25026      -0.166622     0.0497296   -0.112075     0.0556339   -0.0637558     0.00374962   0.182505    -0.174643    0.040891    -0.126719     0.0533482   -0.0510177   -0.0889466    0.0551078    0.018644     0.13965     -0.0114026    0.0356023     0.0327642    0.0320965
  0.178535     0.20626     -0.0505809    0.113332     0.106353     0.0467601    -0.0348896   -0.05183     -0.110099     0.17018     -0.134705      0.0225566   -0.0887219   -0.0673191   0.00565803  -0.081704     0.0242401    0.0933102   -0.0223657    0.0248897   -0.0690358    0.138122     0.0156632   -0.00434723   -0.11721      0.165883
 -0.195986     0.0554473    0.106071     0.0110859    0.140749     0.00866288   -0.107157     0.0939594   -0.0858698    0.0488837    0.00692604   -0.0521309   -0.00859102  -0.102994   -0.00949521  -0.00232827   0.143015     0.138001    -0.0852814    0.221989    -0.239685     0.01167     -0.130696    -0.0787955    -0.0470882   -0.103752
  0.0741035   -0.0950655   -0.0255431    0.180346    -0.119407    -0.0832517    -0.106392    -0.0299865   -0.0166149   -0.0954022    0.0617283     0.0369362    0.0271149    0.111796    0.0433044    0.120787    -0.0130859    0.0581399    0.0230326   -0.00243991   0.0849547   -0.0706051   -0.0697242   -0.201299     -0.0192367    0.0584726
 -0.323236     0.00547372   0.00900315   0.0415296   -0.0329856   -0.153669     -0.0109047   -0.0379674   -0.124237     0.0883238    0.131967     -0.0402398   -0.108751    -0.0426545  -0.0906659    0.0983306    0.0219872    0.135649     0.125411     0.172674    -0.0428171   -0.056099    -0.138122    -0.090157     -0.0982654    0.077541
  0.060934     0.0853095    0.0720401   -0.135334     0.116106     0.0505404    -0.0581687    0.119535     0.154759    -0.1545       0.00888101   -0.0199133   -0.0174997    0.116014    0.090993    -0.0809833   -0.0272285   -0.0410652    0.114799    -0.0292323    0.116217    -0.22296      0.0393518   -0.0384527     0.0205371   -0.142831
 -0.0623185    0.0828813   -0.0098885   -0.159892    -0.0933122   -0.0314276     0.125925    -0.00290939  -0.0644811   -0.0321377    0.0334205     0.0109711    0.0460156   -0.117644   -0.0437779   -0.0181832   -0.055821     0.0628448   -0.216448     0.132497     0.0952486   -0.0123672   -0.123909    -0.139437     -0.0697748   -0.0763088
  0.0737142   -0.0377826    0.145366    -0.079078    -0.0557007    0.00750177   -0.0349057   -0.0958725    0.0466728   -0.0370992    0.0256889    -0.0165108    0.0687121    0.0276957   0.0491724   -0.0568175   -0.182098    -0.121998     0.00919304  -0.0260501   -0.0465438    0.106163     0.0385134    0.0469575     0.117883     0.0869772
  0.0604167   -0.0902458   -0.0586452   -0.0754427    0.0822406    0.167346      0.0562886   -0.054209     0.0430079   -0.0439879   -0.0598993     0.140865     0.104573    -0.112514   -0.00566609  -0.0642201   -0.0455285   -0.012885     0.0410079   -0.0698245    0.029699    -0.0790462    0.0604213    0.204307      0.109156     0.0823706
 -0.0509971   -0.235954     0.050311     0.163834    -0.164426     0.0927238     0.0279938    0.142911    -0.0289623   -0.131991     0.201011      0.200027    -0.076696    -0.0402882  -0.203671     0.0144087    0.0362052   -0.0442165    0.184905     0.0679218   -0.0117916    0.0259972    0.0325388   -0.00110698    0.0295875    0.0103495
 -0.034917     0.169826    -0.0538478   -0.0635649   -0.0951605   -0.148607      0.0706665   -0.054253     0.0318843   -0.00295628  -0.0718459     0.0918607   -0.00476683   0.0404868  -0.0267954    0.0788467   -0.0678591    0.00695084   0.0845936   -0.134228     0.185971    -0.0364616   -0.0430451    0.0243666    -0.0349574    0.00600191
  0.141179    -0.0664214   -0.353045     0.0489097   -0.1127       0.0797437     0.08305      0.0118663   -0.0333931    0.0444483    0.0451835     0.00455419  -0.170514    -0.0479219  -0.115842     0.00701877   0.108989    -0.0539189    0.0177106    0.0863387   -0.0873886   -0.114667    -0.152218    -0.159675      0.063495    -0.0982528
  0.0917976   -0.0171469    0.151692    -0.140826    -0.0774671   -0.0851336     0.186976     0.187609     0.0419853   -0.00558044  -0.079009      0.0468614   -0.0890422    0.109652   -0.0842421    0.0801492   -0.189793     0.0310482   -0.0632155    0.106526    -0.0331411   -0.118825     0.113827    -0.0523956    -0.0338664   -0.0688372
 -0.0117608   -0.0519384   -0.17791      0.0410534   -0.183538     0.137165      0.111768    -0.0195711   -0.030204     0.0378395   -0.000137557  -0.30257     -0.0580529   -0.23351     0.0611033   -0.0770762   -0.166679    -0.0759832   -0.141047     0.0278086    0.0445403   -0.0283399   -0.0928895    0.0740248    -0.00956783   0.0425428
 -0.0278843    0.132214    -0.00569124  -0.0379433    0.0122273   -0.0356691     0.19651      0.0513176    0.0526253    0.03111      0.241177      0.0727345    0.0976905    0.1374      0.108255     0.0773827    0.14995     -0.0469169   -0.100691     0.0675148   -0.0108606    0.0931084    0.188626     0.0568765     0.030034     0.0207984
 -0.105549     0.0273966   -0.0317376    0.133922     0.164717    -0.0304983     0.0751885   -0.0454859    0.132986     0.00842806   0.10868      -0.0312765   -0.0633371   -0.0563517  -0.0330823   -0.0345675    0.0241497   -0.0923138   -0.0439034   -0.0480197    0.0355769   -0.239969     0.030261    -0.000251632  -0.0818489   -0.115396
 -0.0872417   -0.0583656    0.0349095   -0.00106793   0.0224644    0.152179     -0.00328204   0.211848     0.201724     0.0176397   -0.19854      -0.094918    -0.0794427    0.104364    0.106819    -0.0963177   -0.0225799   -0.247088    -0.0500499    0.148676     0.185125     0.051923    -0.289823    -0.0554385    -0.130967     0.138136
  0.136882     0.00159641   0.0274424   -0.157373     0.0143044    0.0976861    -0.242737    -0.0273424   -0.0471684   -0.210598     0.0877051    -0.0426909   -0.118809    -0.0513924  -0.0833431   -0.0270998   -0.0309191    0.0954244    0.0331395    0.138832    -0.0359409   -0.0903947    0.121259     0.013949     -0.00365956  -0.172484
 -0.0228583   -0.0937817    0.157545    -0.111117    -0.00668618  -0.00722554    0.00716279   0.0346603    0.0366515   -0.0479847    0.0410078    -0.00275803   0.0202427   -0.150626    0.0751685   -0.0837897    0.109247    -0.00220211   0.141669     0.0519359    0.0179574   -0.0457697   -0.133611    -0.11823      -0.0376698    0.161348
  0.0134534    0.109518    -0.105675     0.0277446    0.0502644    0.0932669    -0.0505172   -0.113859    -0.149268     0.0373931    0.0373959     0.144463    -0.328656    -0.0317533   0.085626    -0.0408536   -0.0226805    0.00631135   0.120982     0.00620578  -0.0486078   -0.0260643    0.0419032    0.0843821     0.164562     0.13766
  0.0763909   -0.0302473   -0.0800505    0.123366     0.2252       0.03019      -0.0628049    0.00572135  -0.0848555    0.034499     0.0306066    -0.0314278    0.211558    -0.14958     0.0914559    0.11904      0.131194     0.0364514    0.0448181   -0.031526    -0.139862    -0.136895    -0.148863     0.0954353    -0.0701722   -0.053437
 -0.0429184   -0.0715786    0.115044     0.0170395    0.017325     0.0373806    -0.0688584    0.0966873    0.216216     0.0974002   -0.0536542    -0.183087     0.186974     0.0883074   0.0626244   -0.0457007    0.0829577   -0.249473     0.120548     0.0114857    0.105509     0.00572275   0.0812741   -0.158591      0.11892     -0.155395
  0.00849674   0.0429333   -0.118315     0.061857    -0.0598001   -0.170134      0.0762411   -0.0957973    0.113142     0.0854457    0.00678889   -0.102623    -0.0884138   -0.0805062   0.115962     0.0167939   -0.00251845  -0.0158363    0.0334501    0.0924502   -0.196906    -0.0507821    0.124991     0.0505821    -0.0392844   -0.115311
 -0.0829111   -0.0457338   -0.21391      0.0242127    0.0609859   -0.0127949     0.0285883   -0.104238    -0.0228633    0.252315    -0.0282837     0.182096    -0.0783464    0.361705   -0.0714699   -0.0256688   -0.149489    -0.0984832    0.0646574   -0.118703    -0.115239     0.115472    -0.206318    -0.0180868     0.0538905    0.184324
  0.0284935    0.0171831   -0.0741587   -0.0118053   -0.106633     0.124263     -0.152287    -0.0686542    0.0309051    0.0638678   -0.0374382    -0.182177     0.0401767   -0.0487182  -0.0921826   -0.0391166    0.0635275   -0.121332    -0.0894024    0.125002    -0.0548394    0.0608814   -0.00113522   0.10815      -0.146107    -0.0773135
 -0.0646687    0.126988     0.0136036   -0.115838     0.0101438    0.0593366    -0.0588766    0.0456607    0.0973903   -0.14558     -0.0808685     0.0245263   -0.0558809    0.0638261   0.0252642    0.0219473    0.148859    -0.0124176   -0.0793673   -0.0138062   -0.112008    -0.0303534   -0.175252    -0.0977132    -0.0110941   -0.0430672
 -0.0214479   -0.0740291    0.0723999   -0.132292     0.073136    -0.0401861     0.137368    -0.028392    -0.0523192    0.0400103   -0.0636452    -0.180523     0.16694      0.0223093  -0.212683     0.116284    -0.156621     0.0486049   -0.0752917   -0.107958    -0.163488     0.15247     -0.0965899   -0.037378     -0.100399    -0.117855
  0.0030488    0.00407194  -0.117982     0.0572269    0.00536595  -0.00932576    0.175899    -0.0400803   -0.0749104    0.142479    -0.0571284    -0.110873     0.118278     0.109595   -0.104189     0.362745     0.212203     0.126513    -0.17554     -0.0234405   -0.185784    -0.0727699   -0.0629063    0.15569       0.0806936   -0.0579454
 -0.0499252   -0.0598027   -0.0973606   -0.110852    -0.0167654    0.341951     -0.0640871   -0.0583463   -0.02333      0.117783    -0.128564      0.0593932   -0.12925      0.110505    0.031829     0.0299774    0.262844     0.0307551   -0.0554005   -0.0436988   -0.00456216  -0.0594626    0.0185253    0.0804504     0.0463607   -0.132378
 -0.110687    -0.122182    -0.11919     -0.110107     0.148963     0.033069     -0.0683171    0.140449     0.103768    -0.0285676    0.103448     -0.0105034    0.00450859  -0.0850279  -0.103137    -0.0194365    0.128489     0.112595    -0.12475      0.107049    -0.119113    -0.0430875   -0.0824349    0.0789553    -0.14453      0.0323591
 -0.289335    -0.172006    -0.00188179  -0.0350508   -0.162598     0.000133366  -0.0624192    0.0548394    0.00900726   0.0417165    0.122546      0.15728     -0.172178     0.13673     0.0257848    0.0201859   -0.0638022    0.112977    -0.072146    -0.0821709    0.114762     0.1467       0.139772    -0.0667954    -0.0670127    0.125959
 -0.0391609   -0.0349735   -0.115423    -0.0933785   -0.100023     0.211609      0.237381    -0.07486     -0.00518937   0.0146188   -0.067159     -0.164665     0.106275     0.0308426   0.0542474    0.00594515   0.0394742   -0.0681153    0.142572    -0.08302     -0.047408     0.0253332   -0.0291589   -0.124691     -0.0790164    0.0617532kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.435574664367544
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.435709
[ Info: iteration 2, average log likelihood -1.435597
[ Info: iteration 3, average log likelihood -1.434770
[ Info: iteration 4, average log likelihood -1.425051
[ Info: iteration 5, average log likelihood -1.401185
[ Info: iteration 6, average log likelihood -1.392907
[ Info: iteration 7, average log likelihood -1.391740
[ Info: iteration 8, average log likelihood -1.391349
[ Info: iteration 9, average log likelihood -1.391150
[ Info: iteration 10, average log likelihood -1.391029
[ Info: iteration 11, average log likelihood -1.390950
[ Info: iteration 12, average log likelihood -1.390898
[ Info: iteration 13, average log likelihood -1.390865
[ Info: iteration 14, average log likelihood -1.390843
[ Info: iteration 15, average log likelihood -1.390830
[ Info: iteration 16, average log likelihood -1.390821
[ Info: iteration 17, average log likelihood -1.390816
[ Info: iteration 18, average log likelihood -1.390813
[ Info: iteration 19, average log likelihood -1.390811
[ Info: iteration 20, average log likelihood -1.390809
[ Info: iteration 21, average log likelihood -1.390808
[ Info: iteration 22, average log likelihood -1.390808
[ Info: iteration 23, average log likelihood -1.390808
[ Info: iteration 24, average log likelihood -1.390807
[ Info: iteration 25, average log likelihood -1.390807
[ Info: iteration 26, average log likelihood -1.390807
[ Info: iteration 27, average log likelihood -1.390807
[ Info: iteration 28, average log likelihood -1.390807
[ Info: iteration 29, average log likelihood -1.390807
[ Info: iteration 30, average log likelihood -1.390807
[ Info: iteration 31, average log likelihood -1.390807
[ Info: iteration 32, average log likelihood -1.390807
[ Info: iteration 33, average log likelihood -1.390807
[ Info: iteration 34, average log likelihood -1.390807
[ Info: iteration 35, average log likelihood -1.390807
[ Info: iteration 36, average log likelihood -1.390807
[ Info: iteration 37, average log likelihood -1.390807
[ Info: iteration 38, average log likelihood -1.390807
[ Info: iteration 39, average log likelihood -1.390807
[ Info: iteration 40, average log likelihood -1.390807
[ Info: iteration 41, average log likelihood -1.390807
[ Info: iteration 42, average log likelihood -1.390807
[ Info: iteration 43, average log likelihood -1.390807
[ Info: iteration 44, average log likelihood -1.390807
[ Info: iteration 45, average log likelihood -1.390807
[ Info: iteration 46, average log likelihood -1.390807
[ Info: iteration 47, average log likelihood -1.390807
[ Info: iteration 48, average log likelihood -1.390807
[ Info: iteration 49, average log likelihood -1.390807
[ Info: iteration 50, average log likelihood -1.390807
┌ Info: EM with 100000 data points 50 iterations avll -1.390807
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4357088650072614
│     -1.4355971065250108
│      ⋮
└     -1.3908069495198319
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.390986
[ Info: iteration 2, average log likelihood -1.390842
[ Info: iteration 3, average log likelihood -1.390572
[ Info: iteration 4, average log likelihood -1.388213
[ Info: iteration 5, average log likelihood -1.377847
[ Info: iteration 6, average log likelihood -1.366188
[ Info: iteration 7, average log likelihood -1.361180
[ Info: iteration 8, average log likelihood -1.358150
[ Info: iteration 9, average log likelihood -1.355615
[ Info: iteration 10, average log likelihood -1.353531
[ Info: iteration 11, average log likelihood -1.351916
[ Info: iteration 12, average log likelihood -1.350735
[ Info: iteration 13, average log likelihood -1.349888
[ Info: iteration 14, average log likelihood -1.349296
[ Info: iteration 15, average log likelihood -1.348858
[ Info: iteration 16, average log likelihood -1.348502
[ Info: iteration 17, average log likelihood -1.348210
[ Info: iteration 18, average log likelihood -1.347968
[ Info: iteration 19, average log likelihood -1.347749
[ Info: iteration 20, average log likelihood -1.347522
[ Info: iteration 21, average log likelihood -1.347276
[ Info: iteration 22, average log likelihood -1.347016
[ Info: iteration 23, average log likelihood -1.346773
[ Info: iteration 24, average log likelihood -1.346542
[ Info: iteration 25, average log likelihood -1.346323
[ Info: iteration 26, average log likelihood -1.346112
[ Info: iteration 27, average log likelihood -1.345910
[ Info: iteration 28, average log likelihood -1.345705
[ Info: iteration 29, average log likelihood -1.345495
[ Info: iteration 30, average log likelihood -1.345287
[ Info: iteration 31, average log likelihood -1.345096
[ Info: iteration 32, average log likelihood -1.344919
[ Info: iteration 33, average log likelihood -1.344764
[ Info: iteration 34, average log likelihood -1.344629
[ Info: iteration 35, average log likelihood -1.344510
[ Info: iteration 36, average log likelihood -1.344404
[ Info: iteration 37, average log likelihood -1.344305
[ Info: iteration 38, average log likelihood -1.344208
[ Info: iteration 39, average log likelihood -1.344107
[ Info: iteration 40, average log likelihood -1.344001
[ Info: iteration 41, average log likelihood -1.343890
[ Info: iteration 42, average log likelihood -1.343778
[ Info: iteration 43, average log likelihood -1.343667
[ Info: iteration 44, average log likelihood -1.343560
[ Info: iteration 45, average log likelihood -1.343462
[ Info: iteration 46, average log likelihood -1.343374
[ Info: iteration 47, average log likelihood -1.343297
[ Info: iteration 48, average log likelihood -1.343230
[ Info: iteration 49, average log likelihood -1.343174
[ Info: iteration 50, average log likelihood -1.343126
┌ Info: EM with 100000 data points 50 iterations avll -1.343126
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3909861033322017
│     -1.390841605881378
│      ⋮
└     -1.3431257439133315
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.343317
[ Info: iteration 2, average log likelihood -1.343066
[ Info: iteration 3, average log likelihood -1.342292
[ Info: iteration 4, average log likelihood -1.335228
[ Info: iteration 5, average log likelihood -1.315793
[ Info: iteration 6, average log likelihood -1.303137
[ Info: iteration 7, average log likelihood -1.297276
[ Info: iteration 8, average log likelihood -1.293214
[ Info: iteration 9, average log likelihood -1.290378
[ Info: iteration 10, average log likelihood -1.288688
[ Info: iteration 11, average log likelihood -1.287556
[ Info: iteration 12, average log likelihood -1.286529
[ Info: iteration 13, average log likelihood -1.285496
[ Info: iteration 14, average log likelihood -1.284544
[ Info: iteration 15, average log likelihood -1.283774
[ Info: iteration 16, average log likelihood -1.283251
[ Info: iteration 17, average log likelihood -1.282939
[ Info: iteration 18, average log likelihood -1.282749
[ Info: iteration 19, average log likelihood -1.282622
[ Info: iteration 20, average log likelihood -1.282529
[ Info: iteration 21, average log likelihood -1.282458
[ Info: iteration 22, average log likelihood -1.282400
[ Info: iteration 23, average log likelihood -1.282352
[ Info: iteration 24, average log likelihood -1.282309
[ Info: iteration 25, average log likelihood -1.282269
[ Info: iteration 26, average log likelihood -1.282230
[ Info: iteration 27, average log likelihood -1.282191
[ Info: iteration 28, average log likelihood -1.282150
[ Info: iteration 29, average log likelihood -1.282103
[ Info: iteration 30, average log likelihood -1.282048
[ Info: iteration 31, average log likelihood -1.281981
[ Info: iteration 32, average log likelihood -1.281897
[ Info: iteration 33, average log likelihood -1.281785
[ Info: iteration 34, average log likelihood -1.281625
[ Info: iteration 35, average log likelihood -1.281404
[ Info: iteration 36, average log likelihood -1.281143
[ Info: iteration 37, average log likelihood -1.280894
[ Info: iteration 38, average log likelihood -1.280670
[ Info: iteration 39, average log likelihood -1.280472
[ Info: iteration 40, average log likelihood -1.280298
[ Info: iteration 41, average log likelihood -1.280151
[ Info: iteration 42, average log likelihood -1.280028
[ Info: iteration 43, average log likelihood -1.279926
[ Info: iteration 44, average log likelihood -1.279839
[ Info: iteration 45, average log likelihood -1.279764
[ Info: iteration 46, average log likelihood -1.279699
[ Info: iteration 47, average log likelihood -1.279638
[ Info: iteration 48, average log likelihood -1.279574
[ Info: iteration 49, average log likelihood -1.279506
[ Info: iteration 50, average log likelihood -1.279433
┌ Info: EM with 100000 data points 50 iterations avll -1.279433
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3433167211481343
│     -1.3430664460225454
│      ⋮
└     -1.2794327400486358
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.279697
[ Info: iteration 2, average log likelihood -1.279271
[ Info: iteration 3, average log likelihood -1.278060
[ Info: iteration 4, average log likelihood -1.266189
[ Info: iteration 5, average log likelihood -1.228369
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.198800
[ Info: iteration 7, average log likelihood -1.216830
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.191647
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      4
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.186208
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.214618
[ Info: iteration 11, average log likelihood -1.200236
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.182224
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.205350
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.191374
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.199121
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.207644
[ Info: iteration 17, average log likelihood -1.197588
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.182377
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.207164
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.193036
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      4
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.186275
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.210987
[ Info: iteration 23, average log likelihood -1.196801
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.181017
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.206373
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.193398
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.189570
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.203387
[ Info: iteration 29, average log likelihood -1.194747
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.180245
[ Info: iteration 31, average log likelihood -1.206407
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.183186
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.192366
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.204606
[ Info: iteration 35, average log likelihood -1.195430
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.181136
[ Info: iteration 37, average log likelihood -1.208140
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.185913
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      6
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.182319
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.207417
[ Info: iteration 41, average log likelihood -1.196981
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.182129
[ Info: iteration 43, average log likelihood -1.209080
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.187740
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.185191
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.197775
[ Info: iteration 47, average log likelihood -1.199504
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.183139
[ Info: iteration 49, average log likelihood -1.209638
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.188434
┌ Info: EM with 100000 data points 50 iterations avll -1.188434
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2796965690156146
│     -1.2792708936812962
│      ⋮
└     -1.1884338870618278
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.186951
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│     19
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.178225
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.183621
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.158107
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     19
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.133429
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.105680
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.130339
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.102826
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     19
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.103123
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.100801
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     19
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.113788
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.101528
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.116003
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.087345
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     19
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.113187
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.114464
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     19
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.103212
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.086835
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.126244
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.101358
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     19
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.102760
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.100286
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     19
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.113442
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.101133
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.115800
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.087152
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     19
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.113019
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.114312
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     19
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.103149
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.086721
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.126197
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.101301
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     19
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.102719
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.100241
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     19
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.113419
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.101097
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.115774
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.087124
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     19
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.112996
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.114285
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     19
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.103125
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.086696
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.126173
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│      ⋮
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.101276
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     19
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.102694
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.100215
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     19
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.113395
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.101072
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.115748
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.087099
┌ Info: EM with 100000 data points 50 iterations avll -1.087099
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1869507392381278
│     -1.1782248691330497
│      ⋮
└     -1.0870991128353664
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.435574664367544
│     -1.4357088650072614
│     -1.4355971065250108
│     -1.4347698696372244
│      ⋮
│     -1.1010723594131213
│     -1.1157479836432171
└     -1.0870991128353664
32×26 Array{Float64,2}:
 -0.0631244   -0.197446      0.160105    -0.193997      0.139556     0.0340867  -0.0448142    0.146978     0.102656     -0.0296763    0.154313     5.92884e-5   -0.0779266   -0.0847764   -0.102516    0.0118697    0.0906435    0.118614    -0.12163      0.103076     -0.196699     -0.15952    -0.0821667   -0.340185    -0.14594      0.0514882
 -0.144757    -0.0792143    -0.352981    -0.114339      0.178119     0.0391451  -0.0992746    0.129451     0.102537     -0.0314796    0.0229096   -0.0464727     0.0508634   -0.0847768   -0.100482   -0.033383     0.176531     0.105907    -0.127919     0.156716     -0.0787745     0.0870201  -0.081884     0.471033    -0.136718     0.0256195
  0.211071     0.117774     -0.52114      0.126435      0.0160553    0.0630296  -0.00207719  -0.0507573   -0.104208      0.10247     -0.140125    -0.0494198    -0.103627    -0.044111     0.0232351  -0.104379    -0.0632543    0.19586     -0.0161827    0.0240627     0.0844392     0.207478   -0.0281882    0.0165848   -0.0951876    0.147802
  0.120973     0.314527      0.449944     0.113326      0.046119     0.0275867  -0.0700908   -0.0498417   -0.106616      0.211842    -0.142326     0.0442984    -0.122538    -0.0857627   -0.0175203  -0.0634061    0.23926     -0.0380723   -0.0251001    0.0277919    -0.250262      0.0967673   0.0728776    0.00585812  -0.0865085    0.180489
  0.121596     0.000301752   0.163108    -0.118246     -0.0753694   -0.0830306   0.179916     0.174412     0.0533006    -0.00195873  -0.0605782    0.0486461    -0.0965457    0.123412    -0.084795    0.078352    -0.214029    -0.0252542   -0.0623615    0.108048     -0.0270641    -0.117       0.107737    -0.0435872   -0.0344376   -0.0521009
 -0.0388166   -0.230581      0.0349379    0.162308     -0.15949      0.114709    0.0178171    0.135356    -0.0376937    -0.11859      0.21543      0.193184     -0.111458    -0.0262141   -0.202251    0.0167461    0.00841116  -0.0446044    0.183102     0.0683117    -0.000526022   0.0529668   0.0462321   -0.0263285    0.0321236   -0.00240063
 -0.0192347   -0.0769452     0.0727065   -0.138303      0.0772052   -0.0485091   0.12888     -0.0236845   -0.0575129     0.0379522   -0.0944674   -0.176998      0.165281     0.0226607   -0.209084    0.123973    -0.136562     0.0347567   -0.0754842   -0.10124      -0.156496      0.131589   -0.0974605   -0.0330691   -0.0983793   -0.0686206
  0.0509352   -0.0376412     0.150068    -0.0867321    -0.0378572    0.0517653  -0.0380063   -0.101179     0.0461487    -0.0147522    0.0257318   -0.0161906     0.0479692    0.0194016    0.053005   -0.0770754   -0.181539    -0.0894967    0.00638245  -0.0245757    -0.0523451     0.109661    0.04273      0.0521809    0.148112     0.0991642
  0.0750324   -0.0314839    -0.0819062    0.130835      0.206161     0.0210563  -0.0554314    0.0022123   -0.0808508     0.0253515   -0.00752121  -0.0313396     0.22033     -0.1368       0.128251    0.0680812    0.131305     0.0552706    0.0835255   -0.0382218    -0.147246     -0.134391   -0.17055      0.0937682   -0.069993    -0.0613799
  0.0615218    0.0776406     0.0728905   -0.162987      0.132183     0.0389634  -0.0562596    0.121108     0.120337     -0.128438     0.0120006   -0.0191578     0.0114681    0.111646     0.0816258  -0.099974    -0.0269878   -0.0360412    0.115999    -0.0185693     0.122385     -0.216647    0.0409698   -0.0917783    0.0213932   -0.13466
 -0.0660784    0.0827891     0.00335979  -0.13833      -0.111586    -0.0429872   0.0861655    0.0562457   -0.068364     -0.28705      0.0207712   -0.000187867  -0.158989    -0.0879364   -0.043207    0.0173197   -0.0115805    0.0788143   -0.281929     0.131425      0.07162      -0.0144963   0.0455107   -0.22067     -0.10688     -0.0917399
 -0.0669821    0.0828839    -0.074595    -0.200178     -0.0969414   -0.0289353   0.169477    -0.0862764   -0.044883      0.423263     0.0303812    0.0518839     0.352633    -0.135009    -0.0392989  -0.0333571   -0.113528     0.0867644    0.033421     0.132618      0.13334      -0.0154253  -0.441954    -0.0607235   -0.00532067   0.00214413
 -0.0741282   -0.0277782     0.0028342   -0.0250455     0.0209544    0.14673    -0.027867     0.213731     0.214948      0.0198397   -0.153642    -0.0996638    -0.0732815    0.105633     0.147402   -0.104391    -0.0201524   -0.246475    -0.0703651    0.140177      0.202498      0.0471929  -0.287362    -0.0489797   -0.132549     0.111694
 -0.0901257    0.125265      0.0125735   -0.178917      0.00805085   0.0488349  -0.0551416    0.0518673    0.0985279    -0.165136    -0.153199     0.0234539    -0.0414398    0.0456961    0.0103957   0.0195412    0.151927    -0.00249363  -0.032516     0.000387369  -0.125688     -0.0280405  -0.176146    -0.0894829   -0.0120095   -0.0330983
  0.0129693    0.0154915     0.0485709   -0.0972979    -0.0150168   -0.0131175  -0.063437    -0.00402791   0.000651095  -0.0479189    0.0261764    0.00594427   -0.0277622   -0.056692    -0.0204711  -0.0228777    0.0107908    0.0221939    0.0611512    0.0512984     0.0348172    -0.0566562  -0.0325795   -0.0205819   -0.0344286   -0.00520748
 -0.0677238    0.0418776    -0.0231302    0.0179316     0.0715573    0.0902079  -0.0531768   -0.0507227   -0.0975609     0.0778142   -0.00596983   0.0718149    -0.0746737    0.00620263   0.021712   -0.0524781    0.00506454   0.0124119    0.012501     0.0340613    -0.0999171     0.0605463  -0.060711     0.0195781    0.0618134    0.0882141
  0.0173081    0.0249164    -0.1369       0.109634     -0.0276268   -0.165315    0.0635844   -0.0932349    0.145357      0.0972412    0.0291755   -0.0738496    -0.107871    -0.0550352    0.114341    0.00940136   0.0881302    0.146927    -0.0172293    0.136311     -0.58955      -0.0484642   0.124889     0.117906    -0.0396761   -0.130412
 -0.0239728   -0.0164511    -0.103084    -0.0601039    -0.0858941    0.0862861   0.166508    -0.109525     0.0555376     0.0407778   -0.062109    -0.144957      0.054452     0.0398756    0.0751729   0.0243258    0.0553788   -0.0570613    0.104942    -0.0562656    -0.00221316    0.0132602   0.0325778   -0.0808697   -0.0720173    0.0267376
  0.00252032   0.00516878   -0.114581     0.0581773     0.00544898  -0.0389917   0.145257    -0.0415085   -0.351273     -0.00124009  -0.13059     -0.193536      0.0459989    0.0441607   -0.147386    0.37457      0.286777     0.118995    -0.176706    -0.181666     -0.185487     -0.0928185  -0.0717481    0.152736     0.104822     0.0762749
  0.0032514    0.0139489    -0.129168     0.056936      0.00523981   0.0419722   0.206733    -0.0233205    0.0691795     0.301171     0.0961266    0.00732891    0.114359     0.128949    -0.102518    0.35645      0.18999      0.128046    -0.176623     0.170717     -0.185487     -0.0475989  -0.064227     0.160004     0.0505379   -0.21349
  0.0449198   -0.0467864    -0.218633    -0.024312     -0.0596927    0.212022    0.0220801   -0.0314109   -0.0135774     0.065703    -0.0319917    0.0307789    -0.141617     0.0275803   -0.0515534   0.0178159    0.178865    -0.0162477   -0.00741619   0.0299418    -0.0341107    -0.0809058  -0.0667863   -0.0445472    0.0544521   -0.118477
 -0.163019    -0.114683      0.0935188   -0.000582326  -0.0638549    0.0165988  -0.0714605    0.0826041    0.117509      0.0705333    0.0268852   -0.0184581     0.00975495   0.105795     0.0448707  -0.0146656    0.0123148   -0.0800325    0.0479548   -0.0186064     0.107647      0.0533392   0.109545    -0.101675     0.0309144   -0.0218917
 -0.0130106    0.0956094     0.295033    -0.0309988     0.0115189   -0.0588966   0.198215     0.137623     0.144784      0.0149822    0.239156     0.0679541    -0.120308     0.0786041    0.0135328   0.0806027    0.166684    -0.0886452   -0.127442    -0.0582514    -0.138165      0.109614    0.304312     0.0557149    0.0348455    0.0725777
 -0.0632688    0.174231     -0.247336    -0.0383216    -0.0796653    0.0103245   0.196438    -0.0546542   -0.0141052     0.0590726    0.222673     0.0535365     0.448927     0.180514     0.20088     0.0987205    0.127236     0.0101614   -0.0862822    0.222263      0.0930657     0.0788729   0.0738784    0.0551071    0.0790169   -0.0332479
 -0.00983415  -0.0982206    -0.180475     0.0445286    -0.200635     0.13662     0.0985033   -0.00964167  -0.0265561     0.0367453    0.00665573  -0.304775     -0.0702038   -0.242295     0.0404032  -0.086345    -0.166521    -0.0713312   -0.147228     0.0310877     0.0444905    -0.0257246  -0.0772825    0.0787073    0.045949     0.0402988
  0.0727452   -0.0880021    -0.0302668    0.160982     -0.119584    -0.0911277  -0.103225    -0.0293981    0.0122512    -0.0953594    0.0540758    0.041004      0.0258234    0.11231      0.025051    0.12394     -0.0251039    0.0549099    0.0316583   -0.0169864     0.0908595    -0.0539738  -0.0477877   -0.214565    -0.0079906    0.0474821
 -0.317691     0.00468082    0.00237261   0.0339652    -0.0345468   -0.142707    0.0489557   -0.0426009   -0.123917      0.0809924    0.131813    -0.0630803    -0.134191    -0.0572867   -0.0939168   0.106081     0.0195957    0.132481     0.131457     0.207933     -0.0482535    -0.0572699  -0.140406    -0.0739171   -0.115443     0.0783666
  0.057271    -0.136325     -0.0599629   -0.0994807     0.0875084    0.169033    0.0885141   -0.0267828    0.0310762    -0.0391678   -0.0622112    0.126746      0.0984068   -0.0893171   -0.0269439  -0.0549288   -0.0583639   -0.0160988    0.0511859   -0.051869      0.0340211    -0.0723345   0.0644972    0.182502     0.133021     0.0963638
 -0.106188    -0.0313638    -0.032444     0.0820029     0.166517    -0.0310341   0.0752796   -0.046837     0.218578      0.0139424    0.0595926   -0.0621208     0.49609     -0.0671542   -0.0550911  -0.0165793    0.0189602   -0.0875914   -0.0273515   -0.0619471     0.0249313    -0.23978     0.0372609    0.00683999  -0.199418    -0.136316
 -0.102804     0.0958898    -0.0316992    0.117644      0.169992    -0.0250698   0.0767831   -0.0454259   -0.102237     -0.023487     0.0956663   -0.0599184    -0.987258    -0.049093    -0.187586   -0.0364841    0.0033174   -0.0804172   -0.176297     3.7934e-5     0.0373374    -0.240063    0.0353165    0.0152457    0.171994    -0.123786
  0.139705    -0.768878     -0.0322705   -0.0465051    -0.108339     0.123415   -0.109632    -0.048206    -0.00620797    0.0946853    0.0619788   -0.184031      0.0443423   -0.0841494   -0.0922936  -0.0107057    0.0374832   -0.122438    -0.0905793    0.178829     -0.0420282     0.0596356  -0.00976178   0.0680732   -0.144272    -0.0406898
 -0.0714761    0.847315     -0.0970492   -0.0683609    -0.103382     0.130936   -0.152747    -0.0960491    0.0354031     0.0184708   -0.152096    -0.17757       0.0293832   -0.0625739   -0.0887219   0.0228512    0.025196    -0.109809    -0.0864563    0.110022     -0.0587784     0.0624306   0.019902     0.14474     -0.146734    -0.107505[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     19
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.112972
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.093979
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.093106
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.086488
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     20
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.105866
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.091308
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     20
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.102364
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.079757
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.103659
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.100652
┌ Info: EM with 100000 data points 10 iterations avll -1.100652
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.520206e+05
      1       7.067849e+05      -2.452357e+05 |       32
      2       6.785988e+05      -2.818609e+04 |       32
      3       6.632161e+05      -1.538271e+04 |       32
      4       6.524140e+05      -1.080207e+04 |       32
      5       6.460260e+05      -6.387979e+03 |       32
      6       6.428179e+05      -3.208131e+03 |       32
      7       6.413900e+05      -1.427877e+03 |       32
      8       6.406978e+05      -6.922319e+02 |       32
      9       6.403066e+05      -3.911449e+02 |       32
     10       6.400446e+05      -2.619911e+02 |       32
     11       6.397825e+05      -2.621757e+02 |       32
     12       6.394721e+05      -3.103900e+02 |       32
     13       6.390586e+05      -4.134828e+02 |       32
     14       6.385809e+05      -4.776384e+02 |       32
     15       6.379836e+05      -5.973900e+02 |       32
     16       6.373470e+05      -6.365832e+02 |       32
     17       6.367341e+05      -6.128654e+02 |       32
     18       6.360945e+05      -6.396376e+02 |       32
     19       6.354068e+05      -6.876164e+02 |       32
     20       6.347589e+05      -6.478989e+02 |       32
     21       6.343216e+05      -4.373672e+02 |       32
     22       6.340584e+05      -2.631468e+02 |       32
     23       6.339364e+05      -1.220048e+02 |       32
     24       6.338645e+05      -7.193856e+01 |       31
     25       6.338041e+05      -6.041441e+01 |       31
     26       6.337318e+05      -7.225428e+01 |       30
     27       6.336352e+05      -9.665639e+01 |       31
     28       6.335037e+05      -1.314857e+02 |       32
     29       6.333189e+05      -1.848266e+02 |       32
     30       6.331592e+05      -1.596583e+02 |       31
     31       6.330605e+05      -9.871709e+01 |       31
     32       6.330021e+05      -5.842751e+01 |       30
     33       6.329760e+05      -2.609163e+01 |       29
     34       6.329648e+05      -1.111365e+01 |       26
     35       6.329573e+05      -7.533582e+00 |       26
     36       6.329521e+05      -5.163417e+00 |       31
     37       6.329478e+05      -4.321109e+00 |       22
     38       6.329452e+05      -2.602171e+00 |       19
     39       6.329445e+05      -7.250117e-01 |       14
     40       6.329440e+05      -4.696197e-01 |       10
     41       6.329432e+05      -8.062681e-01 |       18
     42       6.329422e+05      -1.034509e+00 |       14
     43       6.329416e+05      -6.258227e-01 |       11
     44       6.329412e+05      -3.615273e-01 |        8
     45       6.329410e+05      -2.490374e-01 |        6
     46       6.329408e+05      -1.452637e-01 |        3
     47       6.329408e+05      -5.415657e-02 |        2
     48       6.329407e+05      -2.785446e-02 |        0
     49       6.329407e+05       0.000000e+00 |        0
K-means converged with 49 iterations (objv = 632940.7271646254)
┌ Info: K-means with 32000 data points using 49 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.335178
[ Info: iteration 2, average log likelihood -1.300837
[ Info: iteration 3, average log likelihood -1.263958
[ Info: iteration 4, average log likelihood -1.218872
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.173826
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.121525
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     14
│     18
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.090501
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      9
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.112042
[ Info: iteration 9, average log likelihood -1.117903
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     12
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.065400
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      9
│     14
│     18
│     19
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.078947
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.136034
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.113798
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.078563
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      7
│      9
│     18
│     19
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.045703
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.113156
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.117193
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.083508
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      7
│     18
│     19
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.041351
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      9
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.104270
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.115079
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.076619
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      7
│      9
│     18
│     19
│     23
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.048560
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.127078
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.091401
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.076222
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      7
│      9
│     18
│     19
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.042428
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.128686
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.100554
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     20
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.059225
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      7
│     18
│     19
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.050254
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      9
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.125943
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.123170
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     14
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.062907
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      7
│      9
│     12
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.035378
[ Info: iteration 36, average log likelihood -1.170281
[ Info: iteration 37, average log likelihood -1.115213
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     14
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.050245
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      4
│      7
│      9
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.045995
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.156477
[ Info: iteration 41, average log likelihood -1.113052
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     14
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.058993
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      9
│     18
│     19
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.060961
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      4
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.115196
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.109789
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     14
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.054685
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      9
│     18
│     19
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.070010
[ Info: iteration 48, average log likelihood -1.130920
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│     12
│     14
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.067477
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      9
│     18
│     20
│     22
│     24
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.065706
┌ Info: EM with 100000 data points 50 iterations avll -1.065706
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0750699   -0.0311051   -0.0818392    0.131176    0.205456      0.0199357    -0.0574288     0.00129381  -0.0811497    0.0252518   -0.00865743  -0.031663      0.222815    -0.136913     0.128593     0.0673974    0.130742     0.0542946     0.0795823   -0.0410557   -0.148446    -0.135729     -0.171016     0.0939071   -0.070285   -0.0610846
 -0.048663     0.00357265  -0.020674    -0.103115   -0.116336     -0.015808      0.125054      0.0175905   -0.0910409   -0.0511711    0.0224503    0.011177      0.0304257   -0.111014    -0.0465822   -0.0056279   -0.0770563    0.0801474    -0.123538     0.120425     0.0646579   -0.00230623   -0.144198    -0.181197    -0.062562   -0.0855651
 -0.289936    -0.166005    -0.0107453   -0.0192543  -0.163983     -0.000423591  -0.0710537     0.0461625    0.00902195   0.0453789    0.116294     0.147347     -0.181237     0.137565     0.0242989    0.017529    -0.0614183    0.109489     -0.0427172   -0.062006     0.108724     0.0651441     0.139419    -0.0630696   -0.0712507   0.122408
 -0.0464862   -0.0579697   -0.0733593   -0.0866651  -0.102926      0.280391      0.268882     -0.117801     0.0507811    0.0151942   -0.0476595   -0.165237      0.28371      0.0657979    0.0146139   -0.00436397   0.0673012   -0.0412252     0.14962     -0.0453478   -0.0299769    0.0336191    -0.00142446  -0.117459    -0.0923716   0.109773
  0.0104297    0.0910596   -0.0890458   -0.0131374   0.0110269     0.0905072    -0.021844     -0.164152    -0.14203     -0.0200087    0.0866031    0.140296     -0.329355    -0.0312142    0.0814408   -0.0595657   -0.00960407  -0.000959096   0.12796      0.00846831  -0.0471508   -0.0254038     0.0491997    0.0738461    0.16197     0.179493
  0.12106     -0.0655346   -0.330125     0.0456042  -0.112609      0.10505       0.113123      0.00298217   0.00732961   0.0228187    0.0415259   -0.00116455   -0.161287    -0.0488743   -0.120713     0.018157     0.106667    -0.0527402     0.0207609    0.0631902   -0.0817777   -0.0942887    -0.12936     -0.15722      0.0593076  -0.098217
  0.0493983   -0.0373887    0.150559    -0.0902299  -0.0391083     0.0530421    -0.0374909    -0.101156     0.0462855   -0.0157608    0.0260055   -0.0153978     0.0462543    0.017921     0.0515768   -0.0785226   -0.181093    -0.0890122     0.00753067  -0.0236227   -0.0513487    0.108402      0.0449733    0.0516071    0.147675    0.099236
 -0.0981458   -0.0252033   -0.207968     0.0302514   0.0452035    -0.000555245   0.0433966    -0.103716    -0.0295952    0.246373    -0.0383646    0.193638     -0.0897597    0.362458    -0.0672586   -0.0408951   -0.150073    -0.0763965     0.0625112   -0.112263    -0.112595     0.117086     -0.226185    -0.00584333   0.0390236   0.213592
 -0.102354     0.0126205   -0.032833     0.0981962   0.163016     -0.0289368     0.0739155    -0.0464161    0.0869039   -0.00215178   0.0719554   -0.0572413    -0.0549484   -0.0656528   -0.111368    -0.0218114    0.013754    -0.0827313    -0.0752726   -0.0364307    0.0306829   -0.239389      0.0345611    0.00833694  -0.0582359  -0.135119
  0.0591937    0.0776551    0.0715204   -0.161678    0.114594      0.028516     -0.0445598     0.121865     0.107885    -0.125378     0.0132551   -0.0194402    -0.00150818   0.106553     0.073944    -0.0947797   -0.0273745   -0.0305463     0.0930036   -0.0141616    0.121702    -0.202098      0.0373762   -0.0947705    0.0172576  -0.136447
  0.166967     0.211604    -0.0557119    0.119986    0.02949       0.0461429    -0.0342898    -0.0504593   -0.105879     0.153212    -0.140447    -0.00439396   -0.112385    -0.0643705    0.00273796  -0.0848369    0.0758584    0.0847611    -0.0199952    0.0259492   -0.072888     0.155411      0.0185997    0.0117767   -0.0914701   0.164492
 -0.00402865   0.0198247   -0.0862184    0.046805   -0.0624974    -0.136528      0.0787849    -0.12692      0.115246     0.0530408   -0.00585922  -0.106699     -0.126173    -0.00313916   0.0635555    0.0134131    0.0534451    0.0172564     0.056011     0.0220118   -0.155963    -0.0365299     0.108703     0.0221734   -0.0399091  -0.115049
 -0.0756549   -0.0299926    0.00444074  -0.0236556   0.0188272     0.148701     -0.024402      0.218364     0.216144     0.0171127   -0.148969    -0.101201     -0.0740575    0.101194     0.145232    -0.104148    -0.0248264   -0.246516     -0.0683255    0.139958     0.204474     0.0426692    -0.290232    -0.0493664   -0.132056    0.109837
 -0.0375446   -0.0657328    0.0955666   -0.107724   -0.0290696    -0.0486223    -0.000773057   0.0635397    0.0135684   -0.0364627    0.0690691   -0.0155718     0.0455488   -0.152539     0.0576826   -0.0743248    0.116413    -0.141687      0.0854275    0.0684824    0.0173197   -0.0441867    -0.143365    -0.11664     -0.0319994   0.193783
 -0.0692702    0.00868646   0.115274     0.0132962   0.0702626     0.248256     -0.159213      0.0538229   -0.120431     0.0746952   -0.0663936   -0.000361697   0.189563    -0.180598     0.0428303   -0.105901     0.0361964   -0.0391458    -0.0920735    0.0697799    0.0221727    0.162945      0.0355397    0.0348296    0.0367471   0.033136
 -0.0402224    0.173147    -0.0527802   -0.0642499  -0.111913     -0.158177      0.0664005    -0.00534919   0.0270938   -0.00610523  -0.0455866    0.0717346    -0.022281     0.02603     -0.0714678    0.0760091   -0.0548069    0.00871711    0.055535    -0.114688     0.180311    -0.0617459    -0.0234114    0.03948     -0.0354304  -0.00744859
  0.0557208   -0.145702    -0.0580915   -0.103761    0.0824472     0.170312      0.107801     -0.0296743    0.0341693   -0.0445203   -0.0621862    0.117976      0.118886    -0.0946655   -0.0243121   -0.0548357   -0.0570582   -0.010581      0.0501391   -0.0433313    0.0305065   -0.0730585     0.0653093    0.18325      0.130083    0.0939771
 -0.00992866  -0.0969823   -0.180515     0.0425691  -0.198654      0.137009      0.0982769    -0.0106201   -0.0265332    0.0358193    0.00769588  -0.304134     -0.0711944   -0.241364     0.0412598   -0.0873169   -0.16661     -0.0699522    -0.147333     0.0322765    0.0448221   -0.0256904    -0.0777284    0.0772467    0.0438086   0.0404249
  0.0707354   -0.0891011   -0.0268036    0.158757   -0.121553     -0.0861708    -0.106025     -0.0295351    0.0127414   -0.0958549    0.0587653    0.0437733     0.0265126    0.110673     0.0314987    0.123333    -0.0293503    0.0529327     0.02739     -0.0124831    0.0904483   -0.0456924    -0.0481632   -0.216094    -0.0115792   0.0577656
 -0.0437152   -0.0282772   -0.0619957   -0.122475   -6.9599e-5     0.339939     -0.06324      -0.0537282   -0.0307019    0.117444    -0.11941      0.0579627    -0.114131     0.101462     0.0340095    0.0268496    0.265518     0.0302518    -0.0374752    0.00125206  -0.00740393  -0.0616348     0.0110187    0.080459     0.0498108  -0.13593
 -0.314844     0.00531741   0.00207681   0.0333568  -0.0353291    -0.147208      0.0494686    -0.0450317   -0.123872     0.0799505    0.130532    -0.0640824    -0.13156     -0.0632082   -0.0932106    0.10524      0.0201567    0.130515      0.137172     0.20862     -0.0492366   -0.0581262    -0.141696    -0.0719186   -0.116576    0.0785071
  0.00194017   0.00994999  -0.118911     0.0519678   0.000604846   0.0213776     0.169695     -0.0347544   -0.130542     0.136848    -0.0202471   -0.100103      0.0735565    0.0749738   -0.10966      0.354119     0.223686     0.116214     -0.16972     -0.0126866   -0.179942    -0.0660123    -0.0674647    0.143006     0.0713378  -0.0492961
 -0.0458465   -0.0623407    0.17667      0.0276783   0.0213083     0.0292116    -0.0672705     0.109312     0.21754      0.0916087   -0.0528361   -0.173262      0.180032     0.0746656    0.0621304   -0.0416328    0.0731022   -0.249158      0.127424     0.0181341    0.111904     0.0326367     0.0811806   -0.143097     0.121095   -0.15046
 -0.10599     -0.137496    -0.0966872   -0.152068    0.156845      0.0378451    -0.0720739     0.138407     0.102871    -0.0311906    0.0871857   -0.0240849    -0.0123451   -0.0848628   -0.102118    -0.00987393   0.13424      0.112451     -0.12302      0.129653    -0.136758    -0.0332621    -0.0825709    0.0666442   -0.139946    0.0410838
 -0.0919762    0.123527     0.011       -0.171621    0.00756451    0.0503347    -0.0538549     0.0589503    0.0989777   -0.167859    -0.153088     0.0243639    -0.0359834    0.0451688    0.0096653    0.0185298    0.15228     -0.000736164  -0.038885     0.00190903  -0.130444    -0.0267841    -0.175299    -0.0926881   -0.0117275  -0.0310287
 -0.156973     0.0717597    0.112301     0.0286942   0.145409      0.0116151    -0.0913527     0.0340278   -0.076545     0.0604489   -0.0130499   -0.0609645    -0.00715485  -0.106654    -0.0159478    0.00742051   0.141597     0.194758     -0.0806545    0.212314    -0.234064    -0.000114124  -0.135076    -0.0859179   -0.0367619  -0.105302
  0.0312672    0.0732569   -0.0651741   -0.0573017  -0.106503      0.12729      -0.133211     -0.0753711    0.016898     0.0573528   -0.0484728   -0.182307      0.0375988   -0.0735757   -0.0906691    0.00831293   0.0318186   -0.116283     -0.0886566    0.144854    -0.050837     0.0612652     0.00606854   0.107072    -0.145407   -0.0769851
 -0.0155497   -0.0773702    0.0725372   -0.133843    0.0726661    -0.0469952     0.131808     -0.020278    -0.0548092    0.0356987   -0.0920708   -0.176269      0.168536     0.0216213   -0.20871      0.124197    -0.133301     0.0330513    -0.074155    -0.0971709   -0.153758     0.129872     -0.10022     -0.0376237   -0.0996192  -0.0737043
  0.128308    -0.00633146   0.170489    -0.119896   -0.0707371    -0.0751734     0.186666      0.176502     0.0523073   -0.00713138  -0.055829     0.0426852    -0.096661     0.12533     -0.0884802    0.0800156   -0.21434     -0.0230282    -0.062204     0.108315    -0.0308286   -0.114383      0.117201    -0.0476344   -0.0339231  -0.0503037
 -0.0466111   -0.243939     0.038717     0.124998   -0.139095      0.141494      0.0139845     0.151945    -0.0424875   -0.106772     0.196371     0.297011     -0.118482    -0.0557862   -0.085135    -0.00411485   0.0110183   -0.0305728     0.193414     0.0753802   -0.00203953   0.0526113     0.0226084   -0.0312467   -0.0066178   0.00253495
  0.17401     -0.027042     0.0252861   -0.164994    0.030748      0.11094      -0.235951     -0.0304021   -0.0379525   -0.19507      0.0923778   -0.0506787    -0.141548    -0.0474626   -0.091394    -0.0339676   -0.0282065    0.130557      0.0459879    0.17022     -0.034167    -0.070918      0.12351      0.0294574   -0.0196856  -0.175992
 -0.0351871    0.135049     0.0332907   -0.0343676  -0.0341326    -0.0221686     0.197082      0.04967      0.0676025    0.0324848    0.234632     0.0580429     0.156237     0.128134     0.109959     0.0917071    0.150979    -0.046926     -0.112929     0.0815171   -0.0298142    0.0953109     0.190982     0.0558101    0.0507249   0.0140021[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.148672
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.100033
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     12
│     14
│     19
│     20
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.041967
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│      7
│     18
│     19
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.059715
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     23
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.087445
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     12
│     14
│     19
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.064019
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      7
│     19
│     20
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.044106
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     12
│     18
│     19
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.078292
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     14
│     19
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.076326
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│     12
│     19
│     20
│      ⋮
│     24
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.037185
┌ Info: EM with 100000 data points 10 iterations avll -1.037185
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0244406    0.160641    -0.298722     -0.120802     0.14521      0.158437    -0.0677963   -0.172228     -0.0646137   -0.020742    -0.127233      0.00466587  -0.0904377     0.0486812     0.0446244   -0.0357085   -0.0186916  -0.0469283   -0.101388     0.127019    -0.151663     0.101738    -0.130263     0.0280136    0.0334538    0.0940539
  0.138721     0.00808156   0.00241953   -0.0677257   -0.0639596   -0.106076    -0.142089    -0.195107      0.049106    -0.0805565   -0.055397      0.0474432   -0.0514539    -0.154528      0.0378654   -0.0906865   -0.0177819   0.118809    -0.071303    -0.157257     0.158851    -0.0411784   -0.076944     0.0284032   -0.178835    -0.0413966
 -0.0566796   -0.103501     0.000694402  -0.150912     0.0469696   -0.0506209   -0.103806     0.12055       0.0188248   -0.10757      0.154679      0.0978773   -0.0619774     0.00941804   -0.0368627    0.00865225  -0.0265645   0.0808828    0.0910401   -0.0589352   -0.125895     0.0651561    0.0645716   -0.14461      0.00455071   0.0546438
  0.0196855    0.13871      0.0479606     0.0840727   -0.0507335   -0.136149     0.0336496    0.0374929     0.0718125    0.102372    -0.0508114     0.22722     -0.0197979     0.296153      0.160915     0.0736767   -0.0603725   0.0872176   -0.00256915  -0.111728     0.0624901    0.0638176   -0.0458422    0.0736031   -0.0141483   -0.184223
 -0.171032    -0.0704144    0.115357      0.115853    -0.226671     0.116794    -0.094748     0.0748596    -0.11569      0.247716     0.0560106    -0.173403     0.0128976     0.148667     -0.0381141    0.0640851   -0.037066    0.00024935   0.0922166    0.0207803    0.139215     0.159386     0.00482357  -0.14729      0.00628724  -0.116121
 -0.00108174   0.0463112   -0.0927735    -0.209487     0.161138     0.0512392   -0.0256758    0.17487      -0.15422     -0.277409     0.024862      0.186867    -0.071702     -0.23582      -0.00175214   0.0253543   -0.0337282   0.0260889   -0.11996     -0.0929476   -0.218325    -0.0774271    0.0371562   -0.125403     0.0422323    0.0723663
 -0.0597327   -0.0188731   -0.0604875     0.0893759    0.14719     -0.0399404    0.0967153   -0.0401156    -0.152623     0.0248964    0.219388      0.101303    -0.00574001   -0.0984082     0.0491776   -0.0541159    0.106468    0.15168     -0.0417503   -0.14741      0.119885    -0.0331957   -0.0297237   -0.00892598  -0.00391296   0.124178
 -0.131853    -0.0289106   -0.0258555    -0.0626179   -0.0110739   -0.08         0.0572823    0.0484186     0.14584     -0.0235363    0.0792102     0.0278893   -0.0112466    -0.14714      -0.0718322   -0.100579     0.0900678  -0.162231     0.0663697    0.0409876   -0.0271313    0.057159    -0.0904104    0.114256    -0.0203439   -0.0902777
 -0.0595471   -0.0615927    0.00595743   -0.0673646    0.0078335    0.0271447   -0.0755198   -0.151302      0.00917062   0.169536     0.118335     -0.118215    -0.0735732     0.0845156    -0.262509    -0.16163      0.0222125  -0.0497153   -0.0799995    0.168823     0.00344974   0.0199739   -0.0970481   -0.21434      0.0049113   -0.129552
  0.00838899  -0.056223    -0.0514514    -0.0433797   -0.0511635   -0.114982    -0.0346937   -0.0464459     0.0195998   -0.0153223   -0.0266538    -0.0406582   -0.00783786    0.0481472    -0.00400666  -0.0101495    0.0942721  -0.029191     0.0795971   -0.0129937    0.061221    -0.0141379    0.114647     0.117975     0.0643607   -0.048301
 -0.142258    -0.0414221   -0.0162702     0.00534251   0.0487373   -0.0350124   -0.0277066   -0.0101582     0.0305219   -0.176426    -0.0230069    -0.0429668    0.0917604    -0.0984128    -0.15497      0.0993346   -0.0696689   0.258172    -0.106803    -0.0850641   -0.215815     0.0535017    0.020226     0.0170354    0.146617    -0.0796878
  0.0148712   -0.0233526   -0.106185     -0.0977702   -0.117779    -0.103622    -0.0437159    0.0746592    -0.0133285    0.167419     0.102552      0.00996105   0.110149      0.0970878    -0.00682278  -0.0519226    0.04573     0.0282033    0.0471393   -0.0951566    0.197083    -0.0502713    0.0490814    0.0990723   -0.0116518   -0.0612355
 -0.00443065   0.0200526    0.123847      0.0763828    0.00275098   0.00660713  -0.16581     -0.11371       0.00605745  -0.120652    -0.0524884    -0.0662767    0.0448915    -0.0301258     0.126036    -0.00463502  -0.0669406  -0.199856     0.0307541   -0.0132813   -0.0881306   -0.0500293   -0.00216261  -0.0758131   -0.0551036   -0.0312003
  0.100359    -0.108737    -0.102905     -0.0186822   -0.029625     0.141101    -0.120098     0.0283616     0.165674    -0.126552     0.000413067   0.100266    -0.0127403     0.0359242    -0.0626667    0.0666886    0.111989    0.142617    -0.10968     -0.00747332   0.00484347   0.155318    -0.0687928    0.0830344   -0.152893     0.0717151
  0.0974411    0.103589     0.0875708    -0.0082078   -0.0307505    0.284803    -0.036464    -0.0725495     0.263751    -0.0335042    0.0823484    -0.0788589    0.204607     -0.000324368  -0.0855633    0.00938094  -0.031837   -0.154992    -0.134604     0.00680821  -0.212938    -0.0182512   -0.0259487   -0.129185    -0.0341071   -0.11558
 -0.119253     0.162337    -0.0779345     0.0811822    0.0261418    0.0680966   -0.13788     -0.0247903     0.126128     0.0593245   -0.101616     -0.155594    -0.0516575     0.10345       0.00157882   0.0371742    0.0119854  -0.228595    -0.133257    -0.00399679   0.114961     0.024391    -0.00237385   0.00384611  -0.182304     0.144011
 -0.105316    -0.0571341    0.166259      0.0456107    0.0127659    0.189219     0.154831    -0.0129133     0.0281885    0.0818231    0.117416     -0.0704745   -0.0787092     0.126634      0.146177    -0.00999711  -0.0724108   0.130495     0.0959672    0.00388939  -0.0926164   -0.140882     0.263755     0.0904906    0.0423375   -0.0415155
 -0.0834536    0.0665838   -0.0579405     0.0227882    0.00211004   0.0761924   -0.263813    -0.116811     -0.00852705  -0.16996     -0.0650408    -0.0428374    0.056324     -0.235596      0.034364     0.0641528   -0.0550849  -0.0429792    0.0455534    0.0220227   -0.186203     0.0451518   -0.0631945   -0.0526566    0.0599425    0.0147814
  0.00198378   0.130285     0.13316       0.0194959    0.00705857   0.0271927   -0.0775378    0.0655501     0.134424     0.132945    -0.139021     -0.0707029    0.0585068    -0.0401616    -0.0140321   -0.230488    -0.0574804  -0.202651     0.0531959    0.0052148    0.081785     0.0792834    0.00367212  -0.0774739   -0.0926677    0.0333247
  0.148321    -0.0751762   -0.0785942    -0.0342563   -0.108852     0.112542     0.079731    -0.067793      0.0237296    0.158598     0.00357816    0.266727    -0.0617337    -0.0190858    -0.0264769    0.0494431   -0.0067418  -0.0940163   -0.0678495    0.0218516    0.0636876   -0.0953171   -0.218126     0.0790285   -0.0169643   -0.115502
 -0.0181003    0.00567744   0.0775303    -0.148953    -0.00719101   0.0285777   -0.11142     -0.0702577     0.11988      0.110554     0.0402856     0.0884572    0.022422     -0.0293239    -0.171237    -0.131507    -0.140868   -0.105393     0.0437728    0.0317231    0.0149128   -0.00344647   0.00678041  -0.0659851    0.188915    -0.208264
  0.0227388    0.00564734  -0.0169272     0.0216135   -0.0253314   -0.0823491    0.00627522   0.103622     -0.0184766   -0.229822     0.0259652    -0.00939341  -0.000670383   0.0322015     0.204903    -0.056495     0.146481    0.120561    -0.0351565    0.0404476    0.110678     0.13096     -0.0150293   -0.119049     0.0718121   -0.176177
  0.107347     0.160582    -0.0333097    -0.0593661   -0.137812     0.127595     0.0396637   -0.0675756    -0.0199339   -0.0881034    0.124816      0.0854316   -0.0579257    -0.0165891    -0.0208315    0.0049617    0.0916275   0.0634825   -0.048103     0.1692      -0.183658     0.120182     0.0235791    0.0675687    0.207343     0.080073
  0.267913     0.0307353   -0.10663       0.166555    -0.116701    -0.0134622    0.145365    -0.00726767   -0.22565     -0.184167     0.0002261     0.0173742   -0.130721      0.024712      0.0597827    0.146412     0.126444    0.0650319   -0.108052    -0.00781924   0.107112     0.0234681   -0.0275899   -0.0429437   -0.0805493   -0.0191532
  0.0349131    0.122876    -0.1717        0.00887266   0.121845     0.0370993   -0.0744128    0.0229424    -0.190412    -0.108456     0.08835       0.0848948    0.107328      0.0672373     0.0455227   -0.0478524    0.0204828   0.104838    -0.0909907   -0.106095     0.0331914   -0.181861    -0.0509157    0.0219495    0.112618    -0.0346548
 -0.0511437   -0.0373182   -0.037166     -0.0232441   -0.0845284    0.145024     0.191292     0.0718462    -0.0515434    0.0382818   -0.18223       0.0129699    0.0362877    -0.0906404    -0.182409     0.248511    -0.0502358  -0.118417     0.161108     0.0176209    0.0674133    0.23303      0.00388046  -0.100986    -0.0182641   -0.0891939
  0.10011     -0.0378936    0.344706     -0.0388329    0.0801017    0.149917    -0.217963     0.000869233  -0.15755      0.00471193   0.219694     -0.130479     0.106622     -0.109468      0.0340979    0.0170988   -0.0405003  -0.0590928    0.00528395   0.0824881    0.0712579   -0.24615      0.00895449  -0.0424347   -0.0666154    0.000738994
 -0.0624845   -0.137284    -0.114336     -0.186912     0.10109      0.0158948    0.0104847   -0.0210327    -0.00331516   0.0828507    0.105981     -0.104977    -0.00504702   -0.0726504    -0.197384     0.165129     0.0358219   0.0790014    0.120337     0.0659177    0.107324     0.0729144   -0.0973457   -0.0396933    0.214642    -0.0159827
  0.0341785   -0.208298    -0.000343889   0.108776     0.219789    -0.0665669   -0.0917591    0.153795      0.122412     0.128262    -0.0224915    -0.118544    -0.0829909     0.0663261    -0.0118489   -0.09895     -0.0247553  -0.197706    -0.0414636    0.00504334   0.0768886   -0.114179    -0.168261     0.172699    -0.0932035   -0.0173638
  0.0686127   -0.161367    -0.199429     -0.130552     0.0247438    0.188213     0.102441     0.0469133     0.120256     0.132612     0.0413775    -0.0120853   -0.0810076    -0.0654213    -0.0130101    0.0691382   -0.0638871  -0.183348     0.0121696    0.0221287    0.110475    -0.0979231    0.111995     0.169669     0.0142523    0.00387625
  0.0651855    0.0257889   -0.0364805     0.0404797    0.151454     0.205073     0.0641515    0.126651      0.089114     0.0359955    0.09502       0.156714    -0.0132141    -0.109079      0.0686081    0.127862     0.257303   -0.0547087   -0.241046    -0.0389025    0.0563581   -0.00598597  -0.0329458   -0.0740273   -0.0251778    0.0210216
 -0.0587742    0.156063    -0.0923469    -0.0425397   -0.16395      0.0327826   -0.106857    -0.226861     -0.209582    -0.0730378    0.128002     -0.0123621   -0.0305767     0.0690452     0.24337     -0.101584     0.181479   -0.165118    -0.0358779    0.0469104    0.0374158    0.0794009    0.0336038    0.0847268   -0.0280773    0.0832939kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.424619804949466
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.424639
[ Info: iteration 2, average log likelihood -1.424592
[ Info: iteration 3, average log likelihood -1.424563
[ Info: iteration 4, average log likelihood -1.424532
[ Info: iteration 5, average log likelihood -1.424496
[ Info: iteration 6, average log likelihood -1.424455
[ Info: iteration 7, average log likelihood -1.424411
[ Info: iteration 8, average log likelihood -1.424364
[ Info: iteration 9, average log likelihood -1.424315
[ Info: iteration 10, average log likelihood -1.424261
[ Info: iteration 11, average log likelihood -1.424188
[ Info: iteration 12, average log likelihood -1.424058
[ Info: iteration 13, average log likelihood -1.423787
[ Info: iteration 14, average log likelihood -1.423229
[ Info: iteration 15, average log likelihood -1.422263
[ Info: iteration 16, average log likelihood -1.421057
[ Info: iteration 17, average log likelihood -1.420084
[ Info: iteration 18, average log likelihood -1.419568
[ Info: iteration 19, average log likelihood -1.419359
[ Info: iteration 20, average log likelihood -1.419282
[ Info: iteration 21, average log likelihood -1.419254
[ Info: iteration 22, average log likelihood -1.419243
[ Info: iteration 23, average log likelihood -1.419238
[ Info: iteration 24, average log likelihood -1.419236
[ Info: iteration 25, average log likelihood -1.419235
[ Info: iteration 26, average log likelihood -1.419235
[ Info: iteration 27, average log likelihood -1.419234
[ Info: iteration 28, average log likelihood -1.419234
[ Info: iteration 29, average log likelihood -1.419233
[ Info: iteration 30, average log likelihood -1.419233
[ Info: iteration 31, average log likelihood -1.419233
[ Info: iteration 32, average log likelihood -1.419233
[ Info: iteration 33, average log likelihood -1.419233
[ Info: iteration 34, average log likelihood -1.419232
[ Info: iteration 35, average log likelihood -1.419232
[ Info: iteration 36, average log likelihood -1.419232
[ Info: iteration 37, average log likelihood -1.419232
[ Info: iteration 38, average log likelihood -1.419232
[ Info: iteration 39, average log likelihood -1.419232
[ Info: iteration 40, average log likelihood -1.419232
[ Info: iteration 41, average log likelihood -1.419231
[ Info: iteration 42, average log likelihood -1.419231
[ Info: iteration 43, average log likelihood -1.419231
[ Info: iteration 44, average log likelihood -1.419231
[ Info: iteration 45, average log likelihood -1.419231
[ Info: iteration 46, average log likelihood -1.419231
[ Info: iteration 47, average log likelihood -1.419231
[ Info: iteration 48, average log likelihood -1.419231
[ Info: iteration 49, average log likelihood -1.419231
[ Info: iteration 50, average log likelihood -1.419231
┌ Info: EM with 100000 data points 50 iterations avll -1.419231
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4246386710578414
│     -1.4245922597733967
│      ⋮
└     -1.4192309540273413
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419246
[ Info: iteration 2, average log likelihood -1.419195
[ Info: iteration 3, average log likelihood -1.419156
[ Info: iteration 4, average log likelihood -1.419110
[ Info: iteration 5, average log likelihood -1.419054
[ Info: iteration 6, average log likelihood -1.418985
[ Info: iteration 7, average log likelihood -1.418901
[ Info: iteration 8, average log likelihood -1.418806
[ Info: iteration 9, average log likelihood -1.418705
[ Info: iteration 10, average log likelihood -1.418607
[ Info: iteration 11, average log likelihood -1.418519
[ Info: iteration 12, average log likelihood -1.418446
[ Info: iteration 13, average log likelihood -1.418391
[ Info: iteration 14, average log likelihood -1.418350
[ Info: iteration 15, average log likelihood -1.418320
[ Info: iteration 16, average log likelihood -1.418297
[ Info: iteration 17, average log likelihood -1.418278
[ Info: iteration 18, average log likelihood -1.418262
[ Info: iteration 19, average log likelihood -1.418248
[ Info: iteration 20, average log likelihood -1.418234
[ Info: iteration 21, average log likelihood -1.418222
[ Info: iteration 22, average log likelihood -1.418210
[ Info: iteration 23, average log likelihood -1.418199
[ Info: iteration 24, average log likelihood -1.418189
[ Info: iteration 25, average log likelihood -1.418179
[ Info: iteration 26, average log likelihood -1.418170
[ Info: iteration 27, average log likelihood -1.418161
[ Info: iteration 28, average log likelihood -1.418152
[ Info: iteration 29, average log likelihood -1.418145
[ Info: iteration 30, average log likelihood -1.418137
[ Info: iteration 31, average log likelihood -1.418130
[ Info: iteration 32, average log likelihood -1.418123
[ Info: iteration 33, average log likelihood -1.418117
[ Info: iteration 34, average log likelihood -1.418111
[ Info: iteration 35, average log likelihood -1.418105
[ Info: iteration 36, average log likelihood -1.418099
[ Info: iteration 37, average log likelihood -1.418094
[ Info: iteration 38, average log likelihood -1.418089
[ Info: iteration 39, average log likelihood -1.418084
[ Info: iteration 40, average log likelihood -1.418079
[ Info: iteration 41, average log likelihood -1.418074
[ Info: iteration 42, average log likelihood -1.418070
[ Info: iteration 43, average log likelihood -1.418065
[ Info: iteration 44, average log likelihood -1.418061
[ Info: iteration 45, average log likelihood -1.418057
[ Info: iteration 46, average log likelihood -1.418053
[ Info: iteration 47, average log likelihood -1.418049
[ Info: iteration 48, average log likelihood -1.418045
[ Info: iteration 49, average log likelihood -1.418042
[ Info: iteration 50, average log likelihood -1.418038
┌ Info: EM with 100000 data points 50 iterations avll -1.418038
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4192458312498115
│     -1.4191952181183924
│      ⋮
└     -1.418038442932601
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418046
[ Info: iteration 2, average log likelihood -1.418002
[ Info: iteration 3, average log likelihood -1.417965
[ Info: iteration 4, average log likelihood -1.417923
[ Info: iteration 5, average log likelihood -1.417872
[ Info: iteration 6, average log likelihood -1.417810
[ Info: iteration 7, average log likelihood -1.417737
[ Info: iteration 8, average log likelihood -1.417655
[ Info: iteration 9, average log likelihood -1.417566
[ Info: iteration 10, average log likelihood -1.417476
[ Info: iteration 11, average log likelihood -1.417390
[ Info: iteration 12, average log likelihood -1.417312
[ Info: iteration 13, average log likelihood -1.417241
[ Info: iteration 14, average log likelihood -1.417178
[ Info: iteration 15, average log likelihood -1.417123
[ Info: iteration 16, average log likelihood -1.417073
[ Info: iteration 17, average log likelihood -1.417029
[ Info: iteration 18, average log likelihood -1.416990
[ Info: iteration 19, average log likelihood -1.416954
[ Info: iteration 20, average log likelihood -1.416922
[ Info: iteration 21, average log likelihood -1.416893
[ Info: iteration 22, average log likelihood -1.416866
[ Info: iteration 23, average log likelihood -1.416843
[ Info: iteration 24, average log likelihood -1.416821
[ Info: iteration 25, average log likelihood -1.416802
[ Info: iteration 26, average log likelihood -1.416785
[ Info: iteration 27, average log likelihood -1.416770
[ Info: iteration 28, average log likelihood -1.416756
[ Info: iteration 29, average log likelihood -1.416744
[ Info: iteration 30, average log likelihood -1.416733
[ Info: iteration 31, average log likelihood -1.416724
[ Info: iteration 32, average log likelihood -1.416715
[ Info: iteration 33, average log likelihood -1.416707
[ Info: iteration 34, average log likelihood -1.416700
[ Info: iteration 35, average log likelihood -1.416693
[ Info: iteration 36, average log likelihood -1.416687
[ Info: iteration 37, average log likelihood -1.416682
[ Info: iteration 38, average log likelihood -1.416676
[ Info: iteration 39, average log likelihood -1.416672
[ Info: iteration 40, average log likelihood -1.416667
[ Info: iteration 41, average log likelihood -1.416663
[ Info: iteration 42, average log likelihood -1.416659
[ Info: iteration 43, average log likelihood -1.416655
[ Info: iteration 44, average log likelihood -1.416651
[ Info: iteration 45, average log likelihood -1.416648
[ Info: iteration 46, average log likelihood -1.416644
[ Info: iteration 47, average log likelihood -1.416641
[ Info: iteration 48, average log likelihood -1.416638
[ Info: iteration 49, average log likelihood -1.416634
[ Info: iteration 50, average log likelihood -1.416631
┌ Info: EM with 100000 data points 50 iterations avll -1.416631
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4180463785468647
│     -1.4180015887446706
│      ⋮
└     -1.4166314527349775
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416637
[ Info: iteration 2, average log likelihood -1.416586
[ Info: iteration 3, average log likelihood -1.416539
[ Info: iteration 4, average log likelihood -1.416485
[ Info: iteration 5, average log likelihood -1.416419
[ Info: iteration 6, average log likelihood -1.416337
[ Info: iteration 7, average log likelihood -1.416239
[ Info: iteration 8, average log likelihood -1.416130
[ Info: iteration 9, average log likelihood -1.416014
[ Info: iteration 10, average log likelihood -1.415898
[ Info: iteration 11, average log likelihood -1.415789
[ Info: iteration 12, average log likelihood -1.415688
[ Info: iteration 13, average log likelihood -1.415597
[ Info: iteration 14, average log likelihood -1.415517
[ Info: iteration 15, average log likelihood -1.415446
[ Info: iteration 16, average log likelihood -1.415385
[ Info: iteration 17, average log likelihood -1.415332
[ Info: iteration 18, average log likelihood -1.415286
[ Info: iteration 19, average log likelihood -1.415246
[ Info: iteration 20, average log likelihood -1.415210
[ Info: iteration 21, average log likelihood -1.415179
[ Info: iteration 22, average log likelihood -1.415152
[ Info: iteration 23, average log likelihood -1.415126
[ Info: iteration 24, average log likelihood -1.415103
[ Info: iteration 25, average log likelihood -1.415081
[ Info: iteration 26, average log likelihood -1.415060
[ Info: iteration 27, average log likelihood -1.415041
[ Info: iteration 28, average log likelihood -1.415022
[ Info: iteration 29, average log likelihood -1.415003
[ Info: iteration 30, average log likelihood -1.414985
[ Info: iteration 31, average log likelihood -1.414967
[ Info: iteration 32, average log likelihood -1.414949
[ Info: iteration 33, average log likelihood -1.414932
[ Info: iteration 34, average log likelihood -1.414914
[ Info: iteration 35, average log likelihood -1.414897
[ Info: iteration 36, average log likelihood -1.414879
[ Info: iteration 37, average log likelihood -1.414862
[ Info: iteration 38, average log likelihood -1.414844
[ Info: iteration 39, average log likelihood -1.414827
[ Info: iteration 40, average log likelihood -1.414810
[ Info: iteration 41, average log likelihood -1.414793
[ Info: iteration 42, average log likelihood -1.414776
[ Info: iteration 43, average log likelihood -1.414759
[ Info: iteration 44, average log likelihood -1.414743
[ Info: iteration 45, average log likelihood -1.414727
[ Info: iteration 46, average log likelihood -1.414711
[ Info: iteration 47, average log likelihood -1.414696
[ Info: iteration 48, average log likelihood -1.414681
[ Info: iteration 49, average log likelihood -1.414666
[ Info: iteration 50, average log likelihood -1.414652
┌ Info: EM with 100000 data points 50 iterations avll -1.414652
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4166371239155005
│     -1.4165861195262202
│      ⋮
└     -1.4146522150624834
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414647
[ Info: iteration 2, average log likelihood -1.414578
[ Info: iteration 3, average log likelihood -1.414511
[ Info: iteration 4, average log likelihood -1.414433
[ Info: iteration 5, average log likelihood -1.414338
[ Info: iteration 6, average log likelihood -1.414221
[ Info: iteration 7, average log likelihood -1.414083
[ Info: iteration 8, average log likelihood -1.413926
[ Info: iteration 9, average log likelihood -1.413759
[ Info: iteration 10, average log likelihood -1.413590
[ Info: iteration 11, average log likelihood -1.413427
[ Info: iteration 12, average log likelihood -1.413277
[ Info: iteration 13, average log likelihood -1.413142
[ Info: iteration 14, average log likelihood -1.413022
[ Info: iteration 15, average log likelihood -1.412918
[ Info: iteration 16, average log likelihood -1.412826
[ Info: iteration 17, average log likelihood -1.412745
[ Info: iteration 18, average log likelihood -1.412674
[ Info: iteration 19, average log likelihood -1.412612
[ Info: iteration 20, average log likelihood -1.412557
[ Info: iteration 21, average log likelihood -1.412508
[ Info: iteration 22, average log likelihood -1.412463
[ Info: iteration 23, average log likelihood -1.412423
[ Info: iteration 24, average log likelihood -1.412386
[ Info: iteration 25, average log likelihood -1.412351
[ Info: iteration 26, average log likelihood -1.412319
[ Info: iteration 27, average log likelihood -1.412289
[ Info: iteration 28, average log likelihood -1.412260
[ Info: iteration 29, average log likelihood -1.412233
[ Info: iteration 30, average log likelihood -1.412207
[ Info: iteration 31, average log likelihood -1.412182
[ Info: iteration 32, average log likelihood -1.412158
[ Info: iteration 33, average log likelihood -1.412135
[ Info: iteration 34, average log likelihood -1.412112
[ Info: iteration 35, average log likelihood -1.412091
[ Info: iteration 36, average log likelihood -1.412070
[ Info: iteration 37, average log likelihood -1.412050
[ Info: iteration 38, average log likelihood -1.412030
[ Info: iteration 39, average log likelihood -1.412012
[ Info: iteration 40, average log likelihood -1.411993
[ Info: iteration 41, average log likelihood -1.411976
[ Info: iteration 42, average log likelihood -1.411959
[ Info: iteration 43, average log likelihood -1.411942
[ Info: iteration 44, average log likelihood -1.411927
[ Info: iteration 45, average log likelihood -1.411911
[ Info: iteration 46, average log likelihood -1.411896
[ Info: iteration 47, average log likelihood -1.411882
[ Info: iteration 48, average log likelihood -1.411868
[ Info: iteration 49, average log likelihood -1.411854
[ Info: iteration 50, average log likelihood -1.411840
┌ Info: EM with 100000 data points 50 iterations avll -1.411840
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4146472400883334
│     -1.4145777954816865
│      ⋮
└     -1.4118404940224825
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.424619804949466
│     -1.4246386710578414
│     -1.4245922597733967
│     -1.4245633613502018
│      ⋮
│     -1.4118675941688639
│     -1.4118538676286951
└     -1.4118404940224825
32×26 Array{Float64,2}:
 -0.554404    -0.054465   -0.651322    -0.213881     0.157471   -0.642592   -0.550819     0.63757     0.176823   -0.243094    0.129598     0.330062     -0.507603    -0.115832     0.412206     0.00835906   0.383655     0.0373213    -0.222985    0.107525    0.609971    0.257942   -0.117406   -0.322898    -0.514754    -0.604183
  0.0600507    0.040426   -0.271919    -0.267499    -0.0922281  -0.577173    0.853967     0.589066   -0.395134    0.153373   -0.0975096    0.062184     -0.272221    -0.351948     0.0370973    0.0426182    0.12191     -0.0769229    -0.144943   -0.0915909  -0.166038    0.464386    0.108456   -0.434781    -0.390545     0.0019532
  0.00912939  -0.399951   -0.100041    -0.140642     0.179969   -0.147229   -0.190188    -0.126782    0.0632969   0.0404264   0.113803     0.00994194   -0.112834    -0.14456     -0.0713882   -0.00751662  -0.164596    -0.246579      0.272577   -0.501745    0.0834601   0.160481   -0.0667741  -0.136411    -0.0658115    0.107626
 -0.0167664    0.0189463  -0.0184182   -0.0807705    0.0922229   0.0392393   0.0123479    0.0627583   0.0438828   0.101545    0.00226661  -0.029424     -0.0553301   -0.00139637   0.019741     0.0690338    0.0557665    0.0584259    -0.1022      0.139244   -0.0513861   0.10015     0.0189841  -0.0484246   -0.0877059   -0.0429554
 -0.522355    -0.0393009  -0.48283      0.4596      -0.125257   -0.229222    0.0934473   -0.0316725   0.340499   -0.173824   -0.148074     0.0583729     0.244846    -0.147252     0.221258     0.264113     0.0239693   -0.354125     -0.186073   -0.101067   -0.47414    -0.479611   -0.192776   -0.0565817   -0.525758     0.00341846
 -0.436104     0.0823152  -0.406825     0.0603198   -0.299597   -0.319578    0.219224     0.105097    0.426193    0.206976    0.231071    -0.179648      0.370962    -0.48204     -0.200186    -0.211057     0.308615     0.860321      0.20759    -0.695429    0.105742   -0.232882   -0.209137    0.334891    -0.17944     -0.306399
 -0.157334     0.528456    0.0439167    0.01434      0.141444    0.109434    0.092628     0.45939     0.252639    0.261706    0.036032    -0.0267091    -0.288771     0.716988     0.335804    -0.108769     0.412716    -0.313685      0.656739   -0.229448   -0.130985    0.116762   -0.29818     0.435621     0.137705    -0.151269
 -0.0803532   -0.168972    0.613356     0.585873     0.291851   -0.0679258  -0.0205128    0.125779    0.629158    0.263911    0.0267991   -0.0579718     0.00514316   0.273318    -0.25017     -0.128041    -0.239013     0.0578396     0.550369   -0.268395   -0.0339845  -0.37689     0.268896    0.331381    -0.017848     0.288439
 -0.0862992   -0.148033   -0.630161     0.0357915    0.610815    0.225437    0.547604    -0.516243   -0.0366572   0.184108    0.0597751   -0.622241     -0.637257    -0.286304    -0.0699774    0.164086     0.103922     0.161699     -0.152161    0.057014    0.432418    0.438954    0.119844    0.620233     0.599011     0.34829
  0.206082    -0.0763959   0.788935    -0.242932     0.52804     0.627565    0.221346     0.131886    0.0404031   0.0466831   0.290707    -0.38135      -0.400164     0.292608     0.161252    -0.748718     0.125607    -0.30256      -0.538177    0.692751    0.184416    0.363501    0.357371    0.532676    -0.308676     0.291585
  0.564366     0.0748093   0.342875    -0.154459     0.298275    0.139792   -0.45539     -0.0828259  -0.56136    -0.254311   -0.410202    -0.0571097    -0.361436     0.363134     0.310894     0.505535    -0.158023    -0.408822     -0.263226    0.431954    0.219873    0.117948    0.216145   -0.360633     0.137993     0.209484
  0.3928       0.356141    0.117999     0.461934     0.268268    0.182989    0.0228773   -0.0193798  -0.136902    0.48522     0.548408     0.0436373    -0.293154     0.374229     0.334858     0.162779    -0.118501    -0.000247472  -0.0698401   0.46646    -0.0402083   0.0694101   0.140713   -0.197184     0.202016    -0.435847
 -0.167298    -0.28709     0.182432    -0.639086    -0.619155    0.202214   -0.50177     -0.0613215   0.188054   -0.35064    -0.0574947    0.311271      0.566763    -0.0334319   -0.173387    -0.0985661    0.0138765    0.0338781    -0.153005    0.380871   -0.0853135   0.0553993   0.139319   -0.175902     0.00596455   0.0868899
 -0.243106    -0.0696889   0.177277    -0.173045    -0.458417    0.107105    0.175207    -0.181535   -0.300351   -0.322753    0.173385     0.120614     -0.131026    -0.332173     0.447356    -0.363111    -0.208106     0.308059     -0.529228    0.494131   -0.294136   -0.0518892   0.239862   -0.0221241   -0.00800396  -0.369266
  0.309188     0.360194    0.0374836    0.243044    -0.236779    0.169698    0.107741    -0.195586   -0.533946   -0.116695   -0.0144787   -0.000655363   0.0579183   -0.00799771   0.00854261   0.0113826   -0.08311      0.000452027  -0.0139028  -0.0699985   0.234483   -0.232481   -0.169477    0.201895     0.544591    -0.110781
  0.284603     0.52824    -0.0205953    0.134216    -0.0037107   0.563506   -0.366222    -0.259165    0.478323   -0.14515    -0.0636696   -0.153783      0.535674    -0.0898615   -0.348856    -0.268744     0.0792677   -0.0195448    -0.418105   -0.0435189   0.186731   -0.374173   -0.0789882   0.158713     0.179715    -0.059026
 -0.0199059   -0.0762974  -0.228072    -0.122097    -0.135689    0.659683    0.0689103   -0.0164243  -0.245328   -0.344953    0.223215     0.649215      0.0459539   -0.141088    -0.826568    -0.355061     0.351275    -0.0485627     0.0454516   0.116131    0.312691    0.627851   -0.788364   -0.00943966   0.303319     0.326163
 -0.247325    -0.510058   -0.277225    -0.326592    -0.374971    0.326482    0.0635669    0.416491    0.607883    0.350507   -0.41609      0.295665      0.0112367   -0.0374721   -0.891225     0.332632    -0.10585      0.0878744     0.888006    0.533557    0.20365     0.439096   -0.400634   -0.0408319    0.504594    -0.101399
  0.538017    -0.573635    0.0840914   -0.289034    -0.11877    -0.159961   -0.168249    -0.505147   -0.0157046   0.147689   -0.142893     0.0453936     0.315644    -0.66515     -0.405417    -0.313581    -0.558884     0.274437     -0.565391   -0.157298    0.781186    0.118012    0.218982   -0.216092     0.138173    -0.156552
  0.444172    -0.223273    0.0964045    0.02107      0.788211    0.369487   -0.0721312   -0.269855   -0.10044     0.161286    0.593476     0.262924     -0.0694735   -0.535331    -0.748702     0.407244     0.00208963   0.381206     -0.276409    0.336093    0.195553   -0.143792    0.271892   -0.337452    -0.050415     0.528945
 -0.165476    -0.426763   -0.0493735   -0.120569     0.308756   -0.491986    0.00179155   0.17026     0.215102    0.198566    0.0980954   -0.012614     -0.437761     0.00793542  -0.137675    -0.269462    -0.0778363   -0.022786      0.782668   -0.626009    0.173101    0.330566   -0.0921068   0.206224     0.0325965    0.28727
 -0.523627    -0.598399   -0.0826568   -0.646824     0.511065    0.0784292  -0.402136     0.19411     0.210833    0.273663   -0.167249    -0.414864      0.308766     0.0127144   -0.248015     0.392805     0.179527    -0.0717744     0.29472    -0.30448    -0.482059    0.287969   -0.308854   -0.345387    -0.277445     0.490391
 -0.0421834    0.163861   -0.36354      0.48276      0.809921   -0.0399929   0.205601    -0.390445    0.293674    0.271407   -0.0545756   -0.41243       0.0445241   -0.0310677    0.472591     0.427339     0.142685    -0.33721       0.157548   -0.311143   -0.0100956  -0.857558   -0.13303     0.731584    -0.480177     0.155493
 -0.202886     0.284923   -0.325469     0.595477     0.622219   -0.286231    0.0101108   -0.167553    0.395847   -0.29134     0.0417288    0.035433      0.459446     0.569581    -0.575701     0.199483     0.255328    -1.11222       0.0446356  -0.658671   -0.0416725   0.525846    0.199016   -0.226736     0.00424056   0.562862
 -0.853951     0.313518   -0.211429     0.689811    -1.12439    -0.468852    0.473465     0.207887   -0.378391    0.127776   -0.372219    -0.136859      0.17652      0.565996     1.2096      -0.693299    -0.289877    -0.204336     -0.0673905  -0.569924   -0.615088    0.43597    -1.20628     0.644635     0.379948    -0.331331
 -0.143959    -0.137928    0.00358301  -0.322324    -0.692658   -0.896097   -0.254528     0.311901    0.0511374  -0.353739   -0.283026    -0.186243     -0.174102     0.64259      0.402505    -0.140453    -0.171306    -0.00489351    0.235006   -0.401819   -0.125517   -0.181987    0.549457    0.216616    -0.0966908   -0.531825
 -0.0872431   -0.0199235  -0.305899    -0.447653    -0.162697    0.619804   -0.11161      0.473678   -0.380049    0.412348   -0.249501     0.0835515    -0.195504     0.158452     0.720724     0.229502     0.334301     0.55998       0.0562983   0.940061   -0.390712   -0.240595   -0.544009    0.0175019   -0.134894    -0.357029
  0.157771     0.305799    0.0448854    0.0403297   -0.284803    0.401782    0.212497    -0.0445479  -0.217493   -0.123999    0.25814      0.200004     -0.262098     0.153946     0.105532    -0.118012     0.175212     0.138126     -0.396155    0.650535    0.194445    0.1941      0.0815782  -0.159957     0.287973    -0.281628
 -0.0815972    0.0628169  -0.25838      0.146692    -0.736764   -0.310543   -0.397025    -0.0249155  -0.179136   -0.0727808   0.0126745    0.534641      0.514474    -0.104277     0.162851     0.112707    -0.25697     -0.026232      0.0305013  -0.428859   -0.593347   -0.596795   -0.226339   -0.837372    -0.178643    -0.530226
  0.125771     0.828319    1.62271      0.51232     -0.960689    0.36509    -0.730549     0.898039   -0.457414    0.358054    0.133398     0.308014      0.55922      0.191528     0.180677     0.412318     0.0475816   -0.129686     -0.0558527  -0.135739   -0.0648419  -0.326621    0.329978   -0.812915    -0.680455    -0.253593
  0.490358     0.283899    0.183872    -0.00943889  -0.186744    0.320798    0.00783082  -0.513601   -0.269409   -0.056034   -0.390906    -0.525334      0.635937     0.303048    -0.290223    -0.0622048   -0.554835    -0.0233393    -0.154561    0.0952708  -0.73092    -0.298928    0.345057    0.276032     0.260104     0.255879
  0.0306694    0.227102    0.40365     -0.188618    -0.120556    0.248157   -0.417795    -0.295811    0.0312319  -1.15052     0.234412     0.0601155    -0.0525904   -0.496942     0.354595     0.101471     0.562401    -0.305752     -0.397438   -0.213321    0.132836   -0.312275    0.0446257   0.154375    -1.39796e-5  -0.251555[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411827
[ Info: iteration 2, average log likelihood -1.411815
[ Info: iteration 3, average log likelihood -1.411802
[ Info: iteration 4, average log likelihood -1.411790
[ Info: iteration 5, average log likelihood -1.411778
[ Info: iteration 6, average log likelihood -1.411766
[ Info: iteration 7, average log likelihood -1.411755
[ Info: iteration 8, average log likelihood -1.411744
[ Info: iteration 9, average log likelihood -1.411733
[ Info: iteration 10, average log likelihood -1.411722
┌ Info: EM with 100000 data points 10 iterations avll -1.411722
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.282783e+05
      1       7.080928e+05      -2.201855e+05 |       32
      2       6.947191e+05      -1.337375e+04 |       32
      3       6.898919e+05      -4.827189e+03 |       32
      4       6.873575e+05      -2.534415e+03 |       32
      5       6.857987e+05      -1.558712e+03 |       32
      6       6.846962e+05      -1.102522e+03 |       32
      7       6.837656e+05      -9.306411e+02 |       32
      8       6.829786e+05      -7.870079e+02 |       32
      9       6.823597e+05      -6.189022e+02 |       32
     10       6.819011e+05      -4.585471e+02 |       32
     11       6.815094e+05      -3.917139e+02 |       32
     12       6.811776e+05      -3.318203e+02 |       32
     13       6.809066e+05      -2.709794e+02 |       32
     14       6.806700e+05      -2.366036e+02 |       32
     15       6.804445e+05      -2.255190e+02 |       32
     16       6.802387e+05      -2.057761e+02 |       32
     17       6.800410e+05      -1.977126e+02 |       32
     18       6.798806e+05      -1.604204e+02 |       32
     19       6.797230e+05      -1.576194e+02 |       32
     20       6.795570e+05      -1.659824e+02 |       32
     21       6.794021e+05      -1.548748e+02 |       32
     22       6.792556e+05      -1.465292e+02 |       32
     23       6.791157e+05      -1.398252e+02 |       32
     24       6.789857e+05      -1.300012e+02 |       32
     25       6.788795e+05      -1.062205e+02 |       32
     26       6.787848e+05      -9.472268e+01 |       32
     27       6.787018e+05      -8.301470e+01 |       32
     28       6.786292e+05      -7.262693e+01 |       32
     29       6.785621e+05      -6.704154e+01 |       32
     30       6.784965e+05      -6.559400e+01 |       32
     31       6.784389e+05      -5.761351e+01 |       32
     32       6.783807e+05      -5.822862e+01 |       32
     33       6.783181e+05      -6.261596e+01 |       32
     34       6.782614e+05      -5.668734e+01 |       32
     35       6.782097e+05      -5.168255e+01 |       32
     36       6.781603e+05      -4.936649e+01 |       32
     37       6.781082e+05      -5.210645e+01 |       32
     38       6.780582e+05      -4.999518e+01 |       32
     39       6.780142e+05      -4.406410e+01 |       32
     40       6.779748e+05      -3.939965e+01 |       32
     41       6.779356e+05      -3.916415e+01 |       32
     42       6.778954e+05      -4.019601e+01 |       32
     43       6.778518e+05      -4.364128e+01 |       32
     44       6.778040e+05      -4.773551e+01 |       32
     45       6.777600e+05      -4.405664e+01 |       32
     46       6.777197e+05      -4.025042e+01 |       32
     47       6.776791e+05      -4.058410e+01 |       32
     48       6.776391e+05      -4.005633e+01 |       32
     49       6.775963e+05      -4.280724e+01 |       32
     50       6.775563e+05      -3.995092e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 677556.3239106643)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423887
[ Info: iteration 2, average log likelihood -1.418825
[ Info: iteration 3, average log likelihood -1.417407
[ Info: iteration 4, average log likelihood -1.416346
[ Info: iteration 5, average log likelihood -1.415258
[ Info: iteration 6, average log likelihood -1.414293
[ Info: iteration 7, average log likelihood -1.413652
[ Info: iteration 8, average log likelihood -1.413302
[ Info: iteration 9, average log likelihood -1.413107
[ Info: iteration 10, average log likelihood -1.412983
[ Info: iteration 11, average log likelihood -1.412891
[ Info: iteration 12, average log likelihood -1.412816
[ Info: iteration 13, average log likelihood -1.412752
[ Info: iteration 14, average log likelihood -1.412695
[ Info: iteration 15, average log likelihood -1.412642
[ Info: iteration 16, average log likelihood -1.412593
[ Info: iteration 17, average log likelihood -1.412545
[ Info: iteration 18, average log likelihood -1.412500
[ Info: iteration 19, average log likelihood -1.412456
[ Info: iteration 20, average log likelihood -1.412413
[ Info: iteration 21, average log likelihood -1.412371
[ Info: iteration 22, average log likelihood -1.412332
[ Info: iteration 23, average log likelihood -1.412294
[ Info: iteration 24, average log likelihood -1.412258
[ Info: iteration 25, average log likelihood -1.412224
[ Info: iteration 26, average log likelihood -1.412191
[ Info: iteration 27, average log likelihood -1.412161
[ Info: iteration 28, average log likelihood -1.412133
[ Info: iteration 29, average log likelihood -1.412106
[ Info: iteration 30, average log likelihood -1.412081
[ Info: iteration 31, average log likelihood -1.412057
[ Info: iteration 32, average log likelihood -1.412034
[ Info: iteration 33, average log likelihood -1.412013
[ Info: iteration 34, average log likelihood -1.411993
[ Info: iteration 35, average log likelihood -1.411973
[ Info: iteration 36, average log likelihood -1.411955
[ Info: iteration 37, average log likelihood -1.411937
[ Info: iteration 38, average log likelihood -1.411920
[ Info: iteration 39, average log likelihood -1.411904
[ Info: iteration 40, average log likelihood -1.411888
[ Info: iteration 41, average log likelihood -1.411873
[ Info: iteration 42, average log likelihood -1.411859
[ Info: iteration 43, average log likelihood -1.411845
[ Info: iteration 44, average log likelihood -1.411831
[ Info: iteration 45, average log likelihood -1.411819
[ Info: iteration 46, average log likelihood -1.411806
[ Info: iteration 47, average log likelihood -1.411794
[ Info: iteration 48, average log likelihood -1.411783
[ Info: iteration 49, average log likelihood -1.411772
[ Info: iteration 50, average log likelihood -1.411761
┌ Info: EM with 100000 data points 50 iterations avll -1.411761
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.16118       0.129553    0.191204    -0.017044   -0.334703    0.0241347   -0.0119444  -0.316579   -0.100933    -0.754838     0.507099    0.540627   -0.194228   -0.47738      0.411678   -0.110188    0.129811    -0.106353   -0.310304      0.0168689    -0.116828     -0.336736     0.194349   -0.0924443    0.0845869   -0.346311
 -0.133378      0.157375    0.0634939    0.272974    0.48658     0.00812316  -0.151821   -0.256696    0.589968    -0.137975    -0.260005   -0.331725    0.573037    0.808059    -0.545102    0.165129    0.222383    -0.954561    0.401646     -0.498557     -0.306566      0.314352     0.187891   -0.0692705    0.0136739    0.580454
 -0.10017      -0.170859   -0.876975     0.175152    0.681072    0.0853686    0.657432   -0.84865    -0.0273261    0.208103     0.075126   -0.659435   -0.682557   -0.298248    -0.0759441   0.18787    -0.053851     0.0385134  -0.300598     -0.0230074     0.578632      0.517411     0.251368    0.629983     0.717568     0.392252
  0.25079       0.316956    0.363313     0.425227   -0.0732913  -0.217625    -0.554133   -0.110025   -0.0544844    0.0981436   -0.173804   -0.506524   -0.041595    0.386011     0.801794    0.391061   -0.247226    -0.421177   -0.113657     -0.144658     -0.153469     -0.917842     0.567123    0.0675367   -0.176065    -0.0990083
  0.798426      0.245568    0.214359     0.102542   -0.586577    0.177966     0.0141756   0.0954748  -0.557507     0.235826     0.476542   -0.0298178  -0.679352    0.304308     0.199496   -0.0662192  -0.092566     0.42702    -0.00746529    0.56967       0.432992      0.466415     0.362342   -0.0914599    0.705017    -0.695862
  0.408425      0.780774   -0.0163798    0.281253   -0.107784    0.458314     0.0724122  -0.358832   -0.229084     0.00953307  -0.0569799   0.0969184   0.154911    0.501305     0.0780724  -0.208098   -0.253089     0.0475395  -0.157523      0.335755      0.0133528    -0.243173    -0.151082    0.207153     0.511865    -0.11119
 -0.0552208     0.19826    -0.153967     0.0814086  -0.205148    0.101552     0.156359   -0.0688308   0.18015     -0.0348691    0.11451    -0.397576    0.377449   -0.446935    -0.270866   -0.242989    0.139062     0.468738   -0.212765     -0.223782     -0.0987465    -0.335346     0.0189679   0.344996     0.0276369   -0.150123
 -0.413407     -0.648488    0.00554256  -0.364307   -0.07576    -0.0507848    0.0173989   0.504079    0.327517     0.338978    -0.404884   -0.0851157  -0.142692    0.406006    -0.0458472   0.231874    0.00702356   0.3593      0.79419       0.627521     -0.0983797    -0.0215917   -0.170842    0.256617     0.260843    -0.035614
  0.570175      0.0385974   0.0383757   -0.739401    0.833675   -0.00810251  -0.142837   -0.167896   -0.0937804   -0.152201     0.228934    0.0415961  -0.0306431  -0.0919162   -0.35901     0.708892    0.0871934    0.628346   -0.277924      0.549741      0.0980983     0.0368197    1.08297    -0.46308     -0.0444438    0.309642
 -0.575048     -0.315874   -0.608594    -0.2681      0.105283   -0.626241    -0.590742    0.423041    0.456329    -0.00837336   0.511984    0.27621    -0.703595   -0.136365     0.384558   -0.0513997   0.618695     0.204425   -0.137851      0.0283402     0.81552       0.35548      0.0595584  -0.313845    -0.416462    -0.727844
  0.0420392     0.174989    0.0661753    0.0521776  -0.117127    0.23329      0.0362607   0.0295177  -0.105193    -0.0970748    0.0233969   0.0703527  -0.081578    0.0497511    0.174025    0.020673    0.155       -0.0211665  -0.123168      0.20704      -0.106346     -0.107275    -0.0842122  -0.00998826  -0.0337234   -0.149492
  0.349491     -0.190348    0.153101    -0.232315   -0.329816    0.095837    -0.342318   -0.614872    0.141495    -0.250995    -0.0953927   0.0105421   0.607191   -0.523228    -0.47231    -0.210379   -0.417824     0.0313891  -0.701689     -0.0975653     0.252898     -0.0152556    0.30505    -0.179998     0.106741    -0.0847866
  0.140618     -0.102061   -0.0654871   -0.168942    0.257356   -0.3152       0.207468    0.276409   -0.16937      0.166085    -0.0696475  -0.497026   -0.425505   -0.00392359   0.0304686   0.29723     0.138567    -0.19668     0.000974502  -0.108052     -0.324345      0.375889     0.264562   -0.297966    -0.178146     0.126531
  0.152422     -0.178691    0.556105    -0.471827    0.279728    0.456519    -0.223322   -0.220212   -0.762387    -0.400668     0.320045    0.443462   -0.389372   -0.00103537  -0.0144787  -0.130743    0.0698067   -0.383232   -0.192758      0.397696      0.525869      0.501134    -0.346707    0.0180105    0.281606     0.582138
 -0.375446     -0.52671    -0.468195    -0.111275    0.262441   -0.44212      0.0590596  -0.212484    0.161414     0.362571     0.102022   -0.21682     0.0511586  -0.574957    -0.0808799   0.0704334  -0.170465     0.320076    0.588649     -0.886838      0.000277433   0.0189773   -0.475185    0.0834823    0.0943522    0.189264
 -0.0845352    -0.252327   -0.0592214   -0.286169   -0.151067    0.0536723   -0.237492   -0.220552    0.10875     -0.142004    -0.124496    0.0904297   0.242429   -0.0747446   -0.164894   -0.139365   -0.0969803   -0.0569804  -0.0589805    -0.000389693   0.0741526     0.170771     0.0269385  -0.0651441   -0.0543161    0.0952021
 -0.122521     -0.176431   -0.44954     -0.158632   -0.235088    0.278781     0.521744    0.358454    0.171285     0.0706964   -0.136149    0.500648    0.030044   -0.422779    -0.970529   -0.279905    0.0977086    0.079341    0.288201      0.212343      0.372522      0.874188    -0.66197    -0.236926     0.294495     0.0823615
  0.000746549  -0.27018     0.490648     0.090014    0.51673     0.493302    -0.130455   -0.0703661   0.486061     0.576158     0.541489    0.179168   -0.0207545   0.0556697   -0.579332    0.12413    -0.398944     0.185857    0.531917     -0.288473     -0.016457      0.0551399    0.392887    0.226094     0.0951504    0.229027
 -0.11847       0.0830822   0.656106    -0.194538    0.260169    0.479219     0.287107    0.216739    0.219209    -0.0552338    0.348242   -0.312099   -0.31802     0.29633      0.348536   -0.7647      0.10993      0.0224854  -0.591285      1.00566      -0.0961651     0.229613     0.594926    0.389537    -0.462899     0.00737629
 -0.0140277     0.408226   -0.199989     0.0939687   0.61016     0.405297     0.165146    0.162632    0.0999662    0.359098     0.223736    0.100554   -0.523363    0.731073     0.538513   -0.152327    0.720956    -0.443427    0.630147     -0.0814932    -0.169671      0.0010594   -0.44856     0.594735    -0.00837543   0.224305
  0.0230902     0.079681   -0.0520842    0.11687     0.135611   -0.0370893    0.0536564   0.113897   -0.00315938   0.156653     0.128514    0.0545017  -0.168891    0.041264     0.119041    0.138772    0.0343367   -0.0620574   0.0511463    -0.0169191     0.0252901     0.00801375  -0.104671   -0.0550031   -0.00861956  -0.0856577
  0.189321      0.421487   -0.354461    -0.380124   -0.432828   -0.374555     0.112621    0.116919   -0.49118     -0.405826    -0.790188   -0.335496    0.314153    0.212923     0.831831   -0.0242779   0.397837     0.192977   -0.438971      0.205955      0.442062     -0.139995    -0.16315     0.190256    -0.021826    -0.402191
  0.59405      -0.553983    0.570081    -0.116562    0.26271     0.168709    -0.32276    -0.176108   -0.313192     0.0206738   -0.42485    -0.403669   -0.169434    0.00346744   0.0902402   0.0249408  -0.455163    -0.305081   -0.207948      0.281569     -0.0150022     0.106483     0.324546    0.0730162    0.159911     0.15359
 -0.803104     -0.358951   -0.630655     0.289449    0.275109   -0.45126      0.265164   -0.0787916   0.479042    -0.0880695   -0.143387    0.120374    0.3588     -0.297105     0.181015    0.392024    0.0567676   -0.349035   -0.170352     -0.309878     -0.478664     -0.403445    -0.187794    0.122562    -0.869223     0.185956
  0.0292986     0.11112    -0.204039    -0.31607    -0.218398   -0.596237     0.176976    0.822523   -0.599474    -0.0926829   -0.17659     0.382596   -0.208406   -0.430124     0.337144   -0.0834718  -0.0112791   -0.139879   -0.365283     -0.0737739     0.00169547    0.194997    -0.17055    -0.603866    -0.515201    -0.138738
  0.195035     -0.140583    0.212821     0.148676    0.129585   -0.847088    -0.0187595   0.301173    0.381199    -0.0673992    0.0417361  -0.0474029  -0.332738    0.234698    -0.335826   -0.483764    0.00291965  -0.305472    0.501051     -0.980798      0.570569     -0.00382092   0.209533    0.363155    -0.111312     0.233308
 -0.979505      0.720614    0.0136318    0.178244   -0.248869   -0.294509    -0.0529944   1.0382      0.44916     -0.0516343   -0.287047   -0.14912    -0.0102737   0.337999     0.279576    0.0663548  -0.0171668    0.0166958   0.549424     -0.384701     -0.110374      0.136837    -0.0518631   0.113713    -0.0714371   -0.699965
 -0.952565      0.11465    -0.21398      0.622302   -1.02771    -0.54101      0.345377    0.163611   -0.379022     0.119351    -0.208685   -0.150551    0.0145384   0.627806     1.07965    -0.61472    -0.347629    -0.0898717   0.101227     -0.523978     -0.869858      0.489036    -0.780085    0.58018      0.32395     -0.165728
  0.129064      0.0341935   0.2266      -0.0467794  -0.761424   -0.414883    -0.316017    0.158792   -0.0782433    0.18049      0.0646075   0.689236    0.673694    0.369336     0.19878    -0.0952158  -0.211586    -0.0702219   0.308744     -0.406155     -0.463449     -0.500671    -0.0493955  -0.605661    -0.330167    -0.654333
 -0.402137     -0.119294   -0.33973     -0.179319   -0.128237    0.709857    -0.332439    0.0943667  -0.261275     0.087159     0.174673    0.27542     0.147788    0.082203    -0.0681928   0.360381   -0.0512744    0.228125   -0.354001      0.710959     -0.841181      0.135021    -0.170539   -0.603831    -0.252319     0.0302795
  0.773429      0.0768905   0.157182     0.516994    0.698628    0.590601     0.0973442  -0.283149   -0.178377     0.328649     0.457107    0.105956    0.0559094  -0.548712    -0.549918    0.367285    0.164753     0.084666   -0.452878      0.184462      0.451888     -0.409573    -0.150242   -0.172509    -0.0328822    0.292926
 -0.146515     -0.0427506  -0.00993966   0.0651056  -0.2039      0.726441    -0.737076    0.0138971   0.271896    -0.51133     -0.141329    0.0723272   0.195114   -0.00741293  -0.340988    0.323732    0.377844    -0.266844    0.2294       -0.135137      0.181314     -0.204206    -0.716427   -0.0959542    0.203232    -0.016638[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411751
[ Info: iteration 2, average log likelihood -1.411741
[ Info: iteration 3, average log likelihood -1.411732
[ Info: iteration 4, average log likelihood -1.411723
[ Info: iteration 5, average log likelihood -1.411714
[ Info: iteration 6, average log likelihood -1.411706
[ Info: iteration 7, average log likelihood -1.411698
[ Info: iteration 8, average log likelihood -1.411690
[ Info: iteration 9, average log likelihood -1.411682
[ Info: iteration 10, average log likelihood -1.411675
┌ Info: EM with 100000 data points 10 iterations avll -1.411675
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
