Julia Version 1.5.0-DEV.225
Commit 2c43528f39 (2020-02-03 15:22 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed SortingAlgorithms ── v0.3.1
  Installed GaussianMixtures ─── v0.3.0
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed URIParser ────────── v0.4.0
  Installed Distances ────────── v0.8.2
  Installed Compat ───────────── v2.2.0
  Installed CMake ────────────── v1.1.2
  Installed FileIO ───────────── v1.2.1
  Installed PDMats ───────────── v0.9.11
  Installed Rmath ────────────── v0.6.0
  Installed QuadGK ───────────── v2.3.1
  Installed CMakeWrapper ─────── v0.2.3
  Installed Parameters ───────── v0.12.0
  Installed JLD ──────────────── v0.9.2
  Installed NearestNeighbors ─── v0.4.4
  Installed Arpack ───────────── v0.4.0
  Installed ScikitLearnBase ──── v0.5.0
  Installed BinDeps ──────────── v1.0.0
  Installed Arpack_jll ───────── v3.5.0+2
  Installed LegacyStrings ────── v0.4.1
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed Missings ─────────── v0.4.3
  Installed HDF5 ─────────────── v0.12.5
  Installed StatsBase ────────── v0.32.0
  Installed Clustering ───────── v0.13.3
  Installed StatsFuns ────────── v0.9.3
  Installed Blosc ────────────── v0.5.1
  Installed StaticArrays ─────── v0.12.1
  Installed DataAPI ──────────── v1.1.0
  Installed BinaryProvider ───── v0.5.8
  Installed FillArrays ───────── v0.8.4
  Installed OrderedCollections ─ v1.1.0
  Installed DataStructures ───── v0.17.9
  Installed Distributions ────── v0.22.4
  Installed SpecialFunctions ─── v0.9.0
#=#=#                                                                         ##O#- #                                                                       ##O=#  #                                                                      #=#=-#  #                                                                     ######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                         #                                                                          2.1%####                                                                       5.9%#######                                                                   10.3%###########                                                               16.5%#################                                                         23.8%####################                                                      29.1%############################                                              39.8%#######################################                                   54.7%##################################################                        69.8%###################################################################       94.4%######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_PJpOyo/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -1.9710433819560788e6, [90878.67264544652, 9121.327354553487], [3575.1875480271783 1192.2768380694686 -962.70121063615; -3555.840757816579 -957.5955289676175 246.10727064357593], [[96766.79832658813 -3128.096651817874 -905.628960843825; -3128.096651817874 92382.46382705135 672.011501042246; -905.6289608438251 672.011501042246 91604.91587800224], [2674.40573440285 3077.6492702083565 1078.2577283360133; 3077.6492702083565 7488.853817711879 -769.4219885381983; 1078.2577283360133 -769.4219885381981 8980.95659701588]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.052641e+03
      1       9.194051e+02      -1.332358e+02 |        2
      2       9.027017e+02      -1.670338e+01 |        0
      3       9.027017e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 902.7017376438957)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.072343
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.788576
[ Info: iteration 2, lowerbound -3.631565
[ Info: iteration 3, lowerbound -3.454042
[ Info: iteration 4, lowerbound -3.254548
[ Info: iteration 5, lowerbound -3.061239
[ Info: iteration 6, lowerbound -2.893696
[ Info: dropping number of Gaussions to 6
[ Info: iteration 7, lowerbound -2.744453
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.606789
[ Info: iteration 9, lowerbound -2.507221
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.437285
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.382836
[ Info: iteration 12, lowerbound -2.344256
[ Info: iteration 13, lowerbound -2.319903
[ Info: iteration 14, lowerbound -2.308161
[ Info: dropping number of Gaussions to 2
[ Info: iteration 15, lowerbound -2.303081
[ Info: iteration 16, lowerbound -2.299264
[ Info: iteration 17, lowerbound -2.299258
[ Info: iteration 18, lowerbound -2.299255
[ Info: iteration 19, lowerbound -2.299254
[ Info: iteration 20, lowerbound -2.299253
[ Info: iteration 21, lowerbound -2.299253
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: 49 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Wed Feb  5 04:52:52 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Wed Feb  5 04:53:00 2020: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Wed Feb  5 04:53:02 2020: EM with 272 data points 0 iterations avll -2.072343
5.8 data points per parameter
, Wed Feb  5 04:53:04 2020: GMM converted to Variational GMM
, Wed Feb  5 04:53:12 2020: iteration 1, lowerbound -3.788576
, Wed Feb  5 04:53:12 2020: iteration 2, lowerbound -3.631565
, Wed Feb  5 04:53:12 2020: iteration 3, lowerbound -3.454042
, Wed Feb  5 04:53:12 2020: iteration 4, lowerbound -3.254548
, Wed Feb  5 04:53:12 2020: iteration 5, lowerbound -3.061239
, Wed Feb  5 04:53:12 2020: iteration 6, lowerbound -2.893696
, Wed Feb  5 04:53:13 2020: dropping number of Gaussions to 6
, Wed Feb  5 04:53:13 2020: iteration 7, lowerbound -2.744453
, Wed Feb  5 04:53:13 2020: dropping number of Gaussions to 5
, Wed Feb  5 04:53:13 2020: iteration 8, lowerbound -2.606789
, Wed Feb  5 04:53:13 2020: iteration 9, lowerbound -2.507221
, Wed Feb  5 04:53:13 2020: dropping number of Gaussions to 4
, Wed Feb  5 04:53:13 2020: iteration 10, lowerbound -2.437285
, Wed Feb  5 04:53:13 2020: dropping number of Gaussions to 3
, Wed Feb  5 04:53:13 2020: iteration 11, lowerbound -2.382836
, Wed Feb  5 04:53:13 2020: iteration 12, lowerbound -2.344256
, Wed Feb  5 04:53:13 2020: iteration 13, lowerbound -2.319903
, Wed Feb  5 04:53:13 2020: iteration 14, lowerbound -2.308161
, Wed Feb  5 04:53:13 2020: dropping number of Gaussions to 2
, Wed Feb  5 04:53:13 2020: iteration 15, lowerbound -2.303081
, Wed Feb  5 04:53:13 2020: iteration 16, lowerbound -2.299264
, Wed Feb  5 04:53:13 2020: iteration 17, lowerbound -2.299258
, Wed Feb  5 04:53:13 2020: iteration 18, lowerbound -2.299255
, Wed Feb  5 04:53:13 2020: iteration 19, lowerbound -2.299254
, Wed Feb  5 04:53:13 2020: iteration 20, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 21, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 22, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 23, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 24, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 25, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 26, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 27, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 28, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 29, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 30, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 31, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 32, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 33, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 34, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 35, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 36, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 37, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 38, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 39, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 40, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 41, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 42, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 43, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 44, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 45, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 46, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 47, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: iteration 48, lowerbound -2.299253
, Wed Feb  5 04:53:13 2020: 49 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601382, 95.95490777398618]
β = [178.04509222601382, 95.95490777398618]
m = [4.25030073326991 79.28686694436183; 2.000229257775371 53.8519871724613]
ν = [180.04509222601382, 97.95490777398618]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484627 -0.0076440490423273525; 0.0 0.008581705166333357], [0.3758763611948421 -0.00895312382734608; 0.0 0.012748664777409381]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999993
avll from stats: -1.0004279413777937
avll from llpg:  -1.000427941377964
avll direct:     -1.000427941377964
sum posterior: 99999.99999999999
Kind: full, size16
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -0.9922970212335545
avll from llpg:  -0.9922970212335542
avll direct:     -0.9922970212335543
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
  0.167657    -0.0695781    0.229486     -0.104127      0.0426801    0.00140515   -0.0801255    -0.0860105  -0.160454   -0.0838951   -0.090812     -0.14638      0.0978451   -0.159329     -0.111451    -0.0451732  -0.197009    -0.113637    -0.0850861   -0.0807479   -0.00654461  -0.0556766    -0.0113899   -0.157058      0.0588074   -0.0387999
 -0.0938981    0.0782145    0.0856747     0.0165013    -0.027634    -0.00791939   -0.0564954    -0.0128614   0.124818    0.0853407    0.226578      0.0740736    0.0122404    0.0357298    -0.0205378    0.0712288   0.019849     0.143123     0.123337    -0.241149     0.0249734    0.0123072    -0.0343918   -0.0484239     0.0106191    0.00378909
 -0.0366649   -0.00121334   0.165993     -0.0852973    -0.0582674   -0.0635613     0.140543     -0.0277987  -0.173939    0.0565534   -0.14725      -0.154003    -0.00140829   0.0268996     0.191932    -0.164104   -0.0596513    0.166658     0.0832686   -0.0837521    0.13502     -0.00690832    0.0185016    0.0584855     0.0451082    0.068982
  0.0365753    0.0615568   -0.0997663    -0.0515583     0.0331024    0.174789     -0.0185679     0.0386957   0.127488   -0.0625385    0.0942214    -0.0285308   -0.0456685    0.205841     -0.105064    -0.0727863   0.0555126    0.0575042   -0.0859292   -0.0840068   -0.0769182    0.037107      0.226373     0.125812      0.0522179   -0.00715137
  0.00591611   0.286236    -0.0738173     0.06968       0.151378     0.0260136     0.0467864     0.0503989   0.0928347  -0.056388     0.161151     -0.160993    -0.00773108  -0.00777819    0.0211364    0.0674246   0.176788    -0.132416    -0.0145401    0.146426     0.0619244    0.072793     -0.0261082    0.0353628    -0.0213815    0.114047
  0.165225     0.0368222   -0.0319756    -0.0168961    -0.00116886  -0.0143569    -0.0851079     0.0640387   0.0961914   0.121876     0.0594413     0.111873    -0.0146788    0.0659072    -0.0318949   -0.279887   -0.205715    -0.0537142   -0.203038     0.107527    -0.017657    -0.110048      0.010085    -0.0880956    -0.0380937    0.00268885
  0.0356237    0.0618684   -0.0299735     0.0530247    -0.00551397   0.115808      0.00637018    0.0448023  -0.241166    0.0207959    0.139049      0.0579407    0.187567    -0.00271965   -0.23236      0.0589007   0.170461    -0.0490264   -0.169734    -0.00456109  -0.00567755   0.0986769     0.0809493    0.0370666     0.0374154    0.116173
 -0.0930961   -0.124773    -0.00502777   -0.0556033     0.017019    -0.0135713    -0.0938692    -0.0197103   0.103495   -0.104144    -0.282413     -0.0565722   -0.19346     -0.0116607     0.140569    -0.105344    0.182899    -0.10573      0.0802387   -0.0554815   -0.0705804   -0.000106972  -0.0388312   -0.160389     -0.059102    -0.040945
  0.189217     0.113211     0.119103     -0.0703961    -0.0428423    0.157146     -0.170081     -0.0715332   0.251759   -0.0572358    0.0224294    -0.0432524    0.013241     0.219639      0.040714     0.148801    0.198833     0.098833    -0.0479911    0.210982     0.158077    -0.102801      0.0220031    0.257569      0.0926531   -0.0331776
 -0.216973    -0.174654    -0.105518     -0.0034486     0.154177     0.0041422    -0.105099      0.0246162  -0.139352   -0.00583222   0.0907892     0.108247    -0.115682    -0.0229279    -0.00743957  -0.0984566  -0.0596277    0.0915207   -0.0229551   -0.112818     0.00442928   0.00701505    0.176952     0.124813     -0.00321968   0.112778
 -0.232713     0.0805198    0.0577102     0.0826501    -0.0442702   -0.0558329    -0.022617      0.0714845   0.174137   -0.0569423    0.00676072   -0.0196709   -0.0370417   -0.0872788     0.0395184   -0.0118962  -0.0101912    0.0403158    0.0774163   -0.114572     0.0393626   -0.0328385     0.13591      0.111238      0.0571088   -0.237338
 -0.128177    -0.0079038   -0.01348       0.000870922   0.137162    -0.131225      0.0470386    -0.0534358   0.159221   -0.139532    -0.000522184   0.0240282    0.117596     0.0669125    -0.237612     0.0472737  -0.0436555   -0.0118096   -0.048343    -0.0946115    0.0229741   -0.0428952    -0.0254733   -0.057879      0.04037      0.00156439
  0.0510944   -0.17885     -0.0178139     0.0504509     0.0362975   -0.0390556    -0.137121     -0.0413266  -0.0826352  -0.0421732   -0.0230692     0.112397    -0.0912112   -0.0152879    -0.132776    -0.0656929   0.110486     0.0179932   -0.0400315    0.1754       0.0545765    0.0728008    -0.0535546    0.000198804   0.0429664   -0.0653567
  0.0432342    0.0706845   -0.000426592  -0.112236     -0.108538    -0.0726581     0.127605     -0.191689    0.200608   -0.071194    -0.0416035     0.0496085   -0.119467    -0.0431706     0.0707953    0.0423118   0.0776128   -0.0912521   -0.0700045    0.0600561    0.0488538    0.0708233     0.0605055    0.15213      -0.147872    -0.0444416
 -0.0593848    0.221152    -0.0821141    -0.0591794     0.152929     0.139438     -0.160974     -0.0628749   0.0222478   0.0344809   -0.235237     -0.0236886    0.326385    -0.000628894   0.0265848   -0.185869    0.103658     0.0236583    0.0818849    0.00813164  -0.149764     0.00486269    0.0692406    0.0710137     0.19492      0.00697623
 -0.0841113   -0.0181739   -0.0844489    -0.0761284     0.09084     -0.116933     -0.034319     -0.120227    0.138794    0.14767     -0.0883673    -0.0810102    0.017294     0.134497     -0.198032    -0.0821676  -0.102743     0.00931091  -0.0712332    0.127785    -0.0813677    0.0103833    -0.17901      0.00123387   -0.0335385   -0.00831493
 -0.0709789    0.134297     0.0236451     0.0125485     0.113975    -0.0771388    -0.153687     -0.0369246   0.127035    0.065276     0.134287      0.0448547    0.275257    -0.146492      0.0752282   -0.166171    0.104202    -0.0648526   -0.0271391    0.116596     0.158323    -0.166367     -0.156294    -0.095189     -0.0736461   -0.104055
  0.0444568    0.113227     0.130666     -0.0220303     0.174677    -0.0576062    -0.162502      0.193792    0.0522214   0.122762    -0.176828      0.088495     0.0706444   -0.0359219     0.117477    -0.0923347   0.0336646    0.0344578   -0.0886814    0.188523    -0.0816289   -0.000298199   0.100764    -0.140441     -0.0755447   -0.0127836
  0.0082806    0.013196    -0.203207      0.0112341     0.142545     0.0553948    -0.154358     -0.288822   -0.101579   -0.0175456    0.00780386   -0.00657328   0.00707124   0.129308     -0.0188363    0.0192342   0.0134871   -0.100625    -0.0554759   -0.14464     -0.204913     0.168924      0.0491318    0.0899983     0.0791481   -0.0343486
  0.0995916   -0.1497      -0.0872898    -0.10647       0.00890184   0.0553083    -0.11112       0.115675   -0.0215832  -0.0763835    0.00226628    0.108544    -0.0754135   -0.00800501   -0.160823    -0.0402044  -0.151663    -0.10087      0.107165    -0.0726948    0.00730861  -0.0651542     0.212767    -0.00739833    0.0222419   -0.00728331
 -0.0280832    0.078192    -0.00862863   -0.0941549    -0.106866     0.0315741    -0.0451397    -0.10052     0.0219239  -0.173534    -0.0555948     0.0717636    0.0438481   -0.0541461    -0.076278    -0.0646809   0.124368     0.0745668    0.0929284   -0.138612    -0.150063     0.0880945    -0.140403    -0.0172815    -0.08483      0.0433318
  0.100521    -0.142734     0.231126     -0.00669393    0.0402923    0.0889558     0.00136347    0.112939    0.0657112  -0.029873    -0.0470974     0.14627      0.01354     -0.0261602     0.12731      0.0158965  -0.00833817  -0.0255468   -0.0680318   -0.0716837    0.113696    -0.0283941     0.00131307   0.0992106     0.0650682   -0.031796
 -0.002547    -0.0152282    0.0768737    -0.084976      0.211039    -0.00920768   -0.000308958   0.0269562   0.0485826   0.0118822   -0.0368426     0.197431    -0.042657     0.0287127     0.0174858    0.0817567  -0.132641     0.0475152    0.0183957    0.100263     0.0354216    0.0302033    -0.0631036   -0.0113345    -0.0860315    0.107931
  0.121582     0.0999271    0.0159454     0.0694597    -0.0892451    0.0175807     0.00140996    0.0902369   0.115669    0.104961    -0.135516      0.187239     0.176538     0.0806064     0.0636991    0.107794   -0.00383781  -0.272992    -0.0881984    0.0417365   -0.249286     0.00724102    0.0440589   -0.113192     -0.0203782    0.00603213
  0.00389277  -0.0228055   -0.0681842     0.0806444     0.0749931   -0.000313543   0.0766255     0.161726    0.073441   -0.108987    -0.0400533    -0.0815614    0.0179316   -0.115334      0.0979503    0.0751564  -0.0996822    0.0802857   -0.0993013    0.0434832    0.109198     0.0559061     0.108655    -0.0465381    -0.0677486   -0.0279506
  0.0206306   -0.0971915   -0.03987       0.0262627     0.118673     0.0104056    -0.0708044     0.144499    0.271469    0.150767     0.0537037     0.0669781   -0.123084     0.00420208    0.0175688   -0.204488   -0.0887669    0.0871536    0.282732    -0.0452593   -0.0182671    0.0107897    -0.0649717    0.144987     -0.117038    -0.105814
  0.0395603    0.0140939   -0.0566433    -0.0891095     0.0281595   -0.0165403     0.241413      0.113763   -0.124119   -0.0487921   -0.00981106   -0.0541625   -0.128251    -0.10244      -0.190252     0.0253912  -0.191594    -0.0883942   -0.281788    -0.254565     0.115183     0.00647704    0.034505     0.0563963     0.0344462    0.10798
 -0.144686     0.0894308    0.189829     -0.158294     -0.12225     -0.130361     -0.0950148     0.0985521  -0.0147035   0.0236186   -0.106262     -0.0346831   -0.137906     0.11068      -0.0299774   -0.0510671  -0.0491367   -0.0323136    0.00794073   0.0522192    0.0388272    0.0981216     0.0579953   -0.070644      0.116205    -0.0830344
 -0.0394734    0.00808265  -0.154476      0.170625     -0.056911     0.112983      0.110584      0.0482122   0.0446667  -0.036654     0.00193185    0.091082    -0.0627282   -0.0386901     0.0608758   -0.0657441   0.130104    -0.0369163    0.0201531    0.0736253   -0.097926    -0.0139075    -0.0638701    0.0526712     0.0642908    0.00629776
 -0.137465     0.0652691    0.0918801    -0.215829      0.0609947    0.0613207     0.109812      0.085394   -0.0169217  -0.108534    -0.0028722     0.0414829   -0.138675    -0.100466      0.0499343   -0.183715   -0.122914     0.019002     0.0382175    0.109689    -0.0346722    0.0945046    -0.0494126   -0.0241301    -0.142294     0.155557
 -0.0595839    0.0379419    0.12533       0.119828     -0.0113067   -0.0785907     0.0334529    -0.0559129   0.0240275   0.0646406   -0.121372     -0.0688723   -0.154937    -0.072194     -0.00310949  -0.183122   -0.0844715    0.00719914   0.172937    -0.0723827    0.0330201    0.106413     -0.010293     0.0209174    -0.114559     0.123556
  0.163949    -0.0640646    0.0211081     0.0231262    -0.00509588   0.122255     -0.225679     -0.026563    0.0598255   0.0470073    0.00716772    0.25768     -0.0988498   -0.0400735     0.129519    -0.0578512  -0.0300543   -0.0413565   -0.128402    -0.0344203   -0.125114    -0.0561394     0.174131    -0.0272072     0.0359025    0.0595877kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.434264946449972
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.434337
[ Info: iteration 2, average log likelihood -1.434272
[ Info: iteration 3, average log likelihood -1.433834
[ Info: iteration 4, average log likelihood -1.428053
[ Info: iteration 5, average log likelihood -1.408961
[ Info: iteration 6, average log likelihood -1.398881
[ Info: iteration 7, average log likelihood -1.396910
[ Info: iteration 8, average log likelihood -1.395834
[ Info: iteration 9, average log likelihood -1.394985
[ Info: iteration 10, average log likelihood -1.394316
[ Info: iteration 11, average log likelihood -1.393810
[ Info: iteration 12, average log likelihood -1.393444
[ Info: iteration 13, average log likelihood -1.393194
[ Info: iteration 14, average log likelihood -1.393028
[ Info: iteration 15, average log likelihood -1.392917
[ Info: iteration 16, average log likelihood -1.392842
[ Info: iteration 17, average log likelihood -1.392789
[ Info: iteration 18, average log likelihood -1.392753
[ Info: iteration 19, average log likelihood -1.392727
[ Info: iteration 20, average log likelihood -1.392710
[ Info: iteration 21, average log likelihood -1.392698
[ Info: iteration 22, average log likelihood -1.392689
[ Info: iteration 23, average log likelihood -1.392684
[ Info: iteration 24, average log likelihood -1.392679
[ Info: iteration 25, average log likelihood -1.392676
[ Info: iteration 26, average log likelihood -1.392674
[ Info: iteration 27, average log likelihood -1.392673
[ Info: iteration 28, average log likelihood -1.392672
[ Info: iteration 29, average log likelihood -1.392671
[ Info: iteration 30, average log likelihood -1.392670
[ Info: iteration 31, average log likelihood -1.392670
[ Info: iteration 32, average log likelihood -1.392669
[ Info: iteration 33, average log likelihood -1.392669
[ Info: iteration 34, average log likelihood -1.392669
[ Info: iteration 35, average log likelihood -1.392669
[ Info: iteration 36, average log likelihood -1.392668
[ Info: iteration 37, average log likelihood -1.392668
[ Info: iteration 38, average log likelihood -1.392668
[ Info: iteration 39, average log likelihood -1.392668
[ Info: iteration 40, average log likelihood -1.392668
[ Info: iteration 41, average log likelihood -1.392668
[ Info: iteration 42, average log likelihood -1.392668
[ Info: iteration 43, average log likelihood -1.392668
[ Info: iteration 44, average log likelihood -1.392668
[ Info: iteration 45, average log likelihood -1.392668
[ Info: iteration 46, average log likelihood -1.392668
[ Info: iteration 47, average log likelihood -1.392668
[ Info: iteration 48, average log likelihood -1.392668
[ Info: iteration 49, average log likelihood -1.392668
[ Info: iteration 50, average log likelihood -1.392668
┌ Info: EM with 100000 data points 50 iterations avll -1.392668
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.434337178106501
│     -1.4342722952128808
│      ⋮
└     -1.3926676237487812
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.392791
[ Info: iteration 2, average log likelihood -1.392694
[ Info: iteration 3, average log likelihood -1.392406
[ Info: iteration 4, average log likelihood -1.388483
[ Info: iteration 5, average log likelihood -1.372107
[ Info: iteration 6, average log likelihood -1.357790
[ Info: iteration 7, average log likelihood -1.352550
[ Info: iteration 8, average log likelihood -1.349791
[ Info: iteration 9, average log likelihood -1.347529
[ Info: iteration 10, average log likelihood -1.345478
[ Info: iteration 11, average log likelihood -1.343961
[ Info: iteration 12, average log likelihood -1.343307
[ Info: iteration 13, average log likelihood -1.342960
[ Info: iteration 14, average log likelihood -1.342776
[ Info: iteration 15, average log likelihood -1.342678
[ Info: iteration 16, average log likelihood -1.342620
[ Info: iteration 17, average log likelihood -1.342576
[ Info: iteration 18, average log likelihood -1.342536
[ Info: iteration 19, average log likelihood -1.342492
[ Info: iteration 20, average log likelihood -1.342441
[ Info: iteration 21, average log likelihood -1.342385
[ Info: iteration 22, average log likelihood -1.342328
[ Info: iteration 23, average log likelihood -1.342275
[ Info: iteration 24, average log likelihood -1.342226
[ Info: iteration 25, average log likelihood -1.342180
[ Info: iteration 26, average log likelihood -1.342139
[ Info: iteration 27, average log likelihood -1.342106
[ Info: iteration 28, average log likelihood -1.342082
[ Info: iteration 29, average log likelihood -1.342064
[ Info: iteration 30, average log likelihood -1.342049
[ Info: iteration 31, average log likelihood -1.342039
[ Info: iteration 32, average log likelihood -1.342031
[ Info: iteration 33, average log likelihood -1.342026
[ Info: iteration 34, average log likelihood -1.342022
[ Info: iteration 35, average log likelihood -1.342020
[ Info: iteration 36, average log likelihood -1.342018
[ Info: iteration 37, average log likelihood -1.342017
[ Info: iteration 38, average log likelihood -1.342017
[ Info: iteration 39, average log likelihood -1.342016
[ Info: iteration 40, average log likelihood -1.342016
[ Info: iteration 41, average log likelihood -1.342016
[ Info: iteration 42, average log likelihood -1.342016
[ Info: iteration 43, average log likelihood -1.342016
[ Info: iteration 44, average log likelihood -1.342015
[ Info: iteration 45, average log likelihood -1.342015
[ Info: iteration 46, average log likelihood -1.342015
[ Info: iteration 47, average log likelihood -1.342015
[ Info: iteration 48, average log likelihood -1.342015
[ Info: iteration 49, average log likelihood -1.342015
[ Info: iteration 50, average log likelihood -1.342015
┌ Info: EM with 100000 data points 50 iterations avll -1.342015
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3927914745890055
│     -1.3926940834224566
│      ⋮
└     -1.3420151272139353
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.342168
[ Info: iteration 2, average log likelihood -1.341992
[ Info: iteration 3, average log likelihood -1.341088
[ Info: iteration 4, average log likelihood -1.332894
[ Info: iteration 5, average log likelihood -1.310187
[ Info: iteration 6, average log likelihood -1.296286
[ Info: iteration 7, average log likelihood -1.290227
[ Info: iteration 8, average log likelihood -1.287756
[ Info: iteration 9, average log likelihood -1.286822
[ Info: iteration 10, average log likelihood -1.286187
[ Info: iteration 11, average log likelihood -1.285675
[ Info: iteration 12, average log likelihood -1.285267
[ Info: iteration 13, average log likelihood -1.284947
[ Info: iteration 14, average log likelihood -1.284694
[ Info: iteration 15, average log likelihood -1.284481
[ Info: iteration 16, average log likelihood -1.284296
[ Info: iteration 17, average log likelihood -1.284135
[ Info: iteration 18, average log likelihood -1.283994
[ Info: iteration 19, average log likelihood -1.283869
[ Info: iteration 20, average log likelihood -1.283756
[ Info: iteration 21, average log likelihood -1.283655
[ Info: iteration 22, average log likelihood -1.283565
[ Info: iteration 23, average log likelihood -1.283485
[ Info: iteration 24, average log likelihood -1.283414
[ Info: iteration 25, average log likelihood -1.283350
[ Info: iteration 26, average log likelihood -1.283291
[ Info: iteration 27, average log likelihood -1.283236
[ Info: iteration 28, average log likelihood -1.283186
[ Info: iteration 29, average log likelihood -1.283140
[ Info: iteration 30, average log likelihood -1.283101
[ Info: iteration 31, average log likelihood -1.283067
[ Info: iteration 32, average log likelihood -1.283039
[ Info: iteration 33, average log likelihood -1.283014
[ Info: iteration 34, average log likelihood -1.282992
[ Info: iteration 35, average log likelihood -1.282972
[ Info: iteration 36, average log likelihood -1.282955
[ Info: iteration 37, average log likelihood -1.282938
[ Info: iteration 38, average log likelihood -1.282923
[ Info: iteration 39, average log likelihood -1.282908
[ Info: iteration 40, average log likelihood -1.282893
[ Info: iteration 41, average log likelihood -1.282878
[ Info: iteration 42, average log likelihood -1.282861
[ Info: iteration 43, average log likelihood -1.282843
[ Info: iteration 44, average log likelihood -1.282822
[ Info: iteration 45, average log likelihood -1.282796
[ Info: iteration 46, average log likelihood -1.282763
[ Info: iteration 47, average log likelihood -1.282718
[ Info: iteration 48, average log likelihood -1.282654
[ Info: iteration 49, average log likelihood -1.282559
[ Info: iteration 50, average log likelihood -1.282418
┌ Info: EM with 100000 data points 50 iterations avll -1.282418
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.342167911620506
│     -1.3419922008032878
│      ⋮
└     -1.2824175705618444
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.282458
[ Info: iteration 2, average log likelihood -1.281926
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.279643
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.262652
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.242846
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.241278
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.225127
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.217354
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.229012
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.216337
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.208733
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.219297
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.204922
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.209334
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.217238
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.204750
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.198654
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.211291
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.198844
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.192196
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.218096
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.203310
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.197735
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.211371
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.199723
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.192840
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.217522
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.199825
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.191688
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.218502
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.203179
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.196984
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.209793
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.197325
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.191044
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.217840
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.202587
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.196849
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.210611
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.199064
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.192624
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.204594
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.202176
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.205541
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.214807
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.201978
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.196398
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.210013
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.198051
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.190871
┌ Info: EM with 100000 data points 50 iterations avll -1.190871
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2824579017351192
│     -1.2819263472936524
│      ⋮
└     -1.190871329475532
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.212715
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     19
│     20
│     23
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.197759
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.191985
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     19
│     20
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.196357
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     19
│     20
│     23
│     24
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.159439
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      9
│     17
│     18
│     19
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.126241
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     19
│     20
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.153079
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│     19
│     20
│     23
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.119944
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      9
│     17
│     18
│     19
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.119678
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     19
│     20
│     27
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.136578
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     19
│     20
│     23
│     24
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.123255
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      6
│      9
│     17
│     18
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.103955
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     19
│     20
│     26
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.139895
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     19
│     20
│     22
│     23
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.118207
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     17
│     19
│     20
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.114814
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│     17
│     18
│     19
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.128310
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     19
│     20
│     21
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.122424
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      9
│     17
│     19
│     20
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.111266
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.131009
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│     17
│     19
│     20
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.132700
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     17
│     19
│     20
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.117460
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.115022
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│     17
│     19
│     20
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.127989
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     17
│     19
│     20
│     23
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.131438
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.110072
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│     17
│     19
│     20
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.123004
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     17
│     19
│     20
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.122189
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.111923
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│     17
│     19
│     20
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.117693
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     17
│     19
│     20
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.133098
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.110677
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      6
│     17
│     19
│     20
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.109210
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     17
│     19
│     20
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.121371
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.120779
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      6
│     17
│     19
│     20
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.106596
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     17
│     19
│     20
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.129274
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.108094
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│     17
│     19
│     20
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.107997
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     17
│     19
│     20
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.128443
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│     23
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.120802
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      6
│     17
│     19
│     20
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.109614
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     17
│     19
│     20
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.121438
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.111771
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│     17
│     19
│     20
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.119006
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     17
│     19
│     20
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.116381
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.112461
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│     17
│     19
│     20
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.111054
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     17
│     19
│     20
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.112782
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.123671
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│     17
│     19
│     20
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.115893
┌ Info: EM with 100000 data points 50 iterations avll -1.115893
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2127146257857941
│     -1.1977593812634497
│      ⋮
└     -1.1158933857777171
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.434264946449972
│     -1.434337178106501
│     -1.4342722952128808
│     -1.4338342954270875
│      ⋮
│     -1.1127820110535782
│     -1.123670560248483
└     -1.1158933857777171
32×26 Array{Float64,2}:
 -0.0895429   -0.1119      -0.0031802    -0.04566      -0.0208402   -0.0118514   -0.101196    -0.0166787    0.13167    -0.104781    -0.30126      -0.0864197   -0.125843    -0.0273487    0.16263     -0.103971     0.18355     -0.0788408    0.0813698    -0.0373678   -0.0608901   -0.000251516  -0.0394209   -0.177285    -0.0818762    -0.0397522
 -0.0326452    0.0338246    0.144404      0.120893     -0.0325668   -0.0792547    0.0330959   -0.0467784    0.0253401   0.0564733   -0.117487     -0.0746135   -0.134064    -0.0756694   -0.00712313  -0.16612     -0.108694     0.0264169    0.172278     -0.0828813    0.0538343    0.107301     -0.00647605   0.00830401  -0.118987      0.125701
  0.00926326   0.109883    -0.100686     -0.0691795     0.0804754    0.0773138    0.0205903    0.0230981   -0.050101    0.00506529  -0.106804     -0.0334377    0.129582    -0.0457564   -0.0773028   -0.0901783   -0.0276985   -0.0260603   -0.0875004    -0.102815    -0.0258773    0.00270178    0.0562993    0.0755586    0.121915      0.0493679
 -0.026984    -0.00304704  -0.166224      0.153276     -0.0483845    0.084647     0.120339     0.0446325    0.0296519  -0.0341585    0.0568298     0.0784912   -0.0606082   -0.0281626    0.00886736  -0.0562647    0.12335     -0.0411515    0.0943186     0.0563119   -0.0882989   -0.00992484   -0.0330163    0.08102      0.0623265     0.00539915
 -0.0848359    0.141135     0.0436543    -0.00510583    0.0931678   -0.0697102   -0.153258    -0.0140277    0.130366    0.0680745    0.137774      0.0104972    0.274374    -0.112076     0.142163    -0.177513     0.111813    -0.070382    -0.0439404     0.116185     0.158752    -0.166932     -0.134441    -0.115315    -0.100675     -0.114207
  0.156114     0.0424441   -0.0449857    -0.0284678     0.00797001  -0.00322878  -0.0784667    0.0817383    0.0963776   0.0872457    0.0294207     0.0841973    0.0272412    0.065389    -0.0721419   -0.278886    -0.209359    -0.0554877   -0.200258      0.0973961   -0.013048    -0.109447     -0.00806764  -0.0581709   -0.0386905     0.000108511
  0.174056     0.112259     0.193431     -0.0661952    -0.0718206    0.105134    -0.147737    -0.0462274    0.251895   -0.0608862    0.0041099    -0.0307984    0.0295448    0.20981      0.0543282    0.149358     0.191009     0.086922    -0.0349841     0.146859     0.155783    -0.0965402     0.0239354    0.28478      0.083746     -0.110232
  0.130022    -0.0488231    0.0171374     0.0240872    -0.0213686    0.11893     -0.196707    -0.0269849    0.0479709   0.0507959    0.0217799     0.221995    -0.0941564   -0.0369491    0.0873322   -0.0426292   -0.0420586   -0.0321726   -0.121262     -0.049979    -0.147626    -0.0519008     0.163945    -0.0299836    0.0394052     0.0643347
  0.156756    -0.0736574    0.227573     -0.101098      0.0396287   -7.06047e-5  -0.0927341   -0.0616704   -0.157924   -0.0375507   -0.0898786    -0.145709     0.0919048   -0.12762     -0.113417    -0.0500607   -0.197068    -0.0690643   -0.0621208    -0.042334    -0.00269266  -0.0545535    -0.00178825  -0.129017     0.113395     -0.00526614
  0.0461304    0.0128501    0.00371403   -0.117482     -0.1035      -0.0689595    0.112119    -0.165892     0.201444   -0.0793552   -0.0393234     0.046111    -0.0964177   -0.0579215    0.071539     0.0216649    0.0788566   -0.111905    -0.069017      0.0553959    0.0539979    0.087034      0.0643428    0.15347     -0.157868     -0.0435286
 -0.0841845    0.0456704    0.0041276    -0.0308164     0.0161006    0.0773719    0.00261434   0.0590143    0.0859485  -0.0572415    0.0751522     0.00806868  -0.0758422    0.0104165   -0.0427524   -0.0671922   -0.00888619   0.0343968    0.000700639  -0.0418806   -0.0497401    0.0610383     0.108864     0.07646     -0.0149046    -0.00886335
 -0.00297598   0.0771452    0.118004     -0.0443614     0.0154409    0.0045784   -0.00580694   0.0852011    0.0141185  -0.0272035    0.000949791  -0.00296058  -0.0229765    0.0184241    0.00455098   0.0099265    0.058015    -0.0666089   -0.0497266     0.0439119    0.0670805    0.0559781     0.0152591    0.0425638    0.0419114     0.0260791
  0.100462     0.133558     0.173566     -0.0600657     0.240168    -0.193847    -0.166071    -0.0144674    0.131943    0.030143    -0.177975      0.100132     0.0647443   -0.0584947    0.133536    -0.0911673    0.019821     0.0333109   -0.162652      0.289363    -0.0448316    0.108928      0.105582    -0.132276    -0.079233      0.0111665
 -0.0543339    0.0650768    0.0586653     0.0464999     0.138357     0.122738    -0.209763     0.458984    -0.0241743   0.189623    -0.173306      0.0888594    0.081475    -0.0176777    0.100167    -0.0970515    0.0989088    0.0406053    0.0619895     0.0648403   -0.0669225   -0.151237      0.0916929   -0.110654    -0.0575529    -0.0600691
 -0.190072     0.269307     0.0905011     0.0431943     0.0211306   -0.622352    -0.105926    -0.00597594   0.0661955   0.0323475    0.206744      0.083089     0.0419096    0.0611519   -0.0113776   -0.00929139   0.0219102    0.154668     0.0795696    -0.284772     0.177091    -0.00605175    0.0205446   -0.0514801    0.0215772    -0.0101664
 -0.00629952  -0.121033    -0.000293695  -0.0221114    -0.0414955    0.617967    -0.0334831   -0.0209537    0.193562    0.127212     0.228104      0.0581681   -0.0265616    0.0284057   -0.0130999    0.267758     0.0186604    0.129834     0.134707     -0.200361    -0.0525961    0.0263877    -0.10022     -0.0778543    0.00827012    0.0264347
 -0.233556    -0.105806    -0.159831     -0.37748       0.0496967   -0.0560361   -0.113386    -0.041148     0.261105    0.166808     0.0560918     0.0648897   -0.10392      0.0785366    0.0121631   -0.218456    -0.0939164   -0.526752     0.281372      0.00940754   0.163351    -0.0570734    -0.0774302    0.152933    -0.116148     -0.144194
  0.00283026  -0.0032693    0.0709204    -0.0545225     0.195746     0.00551372  -0.00896817   0.0286246    0.0455382   0.00505176  -0.0331685     0.197989    -0.045585     0.0217752    0.0173409    0.0897859   -0.119216     0.0516607    0.0219744     0.0987143    0.0328291    0.0481629    -0.0601932   -0.00413634  -0.0867406     0.110685
  0.129802    -0.102613     0.454968     -1.62692       0.164402    -0.0642294   -0.0507107    0.232398     0.260796    0.242221     0.0560023     0.0672003   -0.121334    -0.149386     0.0184483   -0.212643    -0.0826485    0.40189      0.285852     -0.0434172   -0.15193     -0.00777369   -0.0350837    0.145807    -0.116861     -0.0961092
  0.125206    -0.09477     -0.493652      2.18052       0.14941      0.212873     0.0276303    0.242587     0.273521    0.0714869    0.0527612     0.0667912   -0.188168     0.115354     0.0236653   -0.210606    -0.069214     0.202936     0.198545     -0.108697    -0.014039    -0.0176696    -0.0703965    0.149233    -0.117006     -0.0992898
  0.063468    -0.166975     0.0124684     0.0472292     0.0722858   -0.0372947   -0.151921    -0.0363909   -0.0815185  -0.0458822   -0.0235305     0.11702     -0.0707414   -0.0211352   -0.132618    -0.0752572    0.122058     0.0198154   -0.0445832     0.176005     0.054742     0.081777     -0.0669645    6.90908e-5   0.0422864    -0.0620221
 -0.119312    -0.0133956   -0.0104484    -0.00493282    0.0545729   -0.130635     0.0379792   -0.0395424    0.130044   -0.136707    -0.00509363    0.0536856    0.109656     0.108597    -0.167878     0.0694882   -0.0454027   -0.00219426  -0.0540505    -0.0955318    0.0103589    0.0390113    -0.0271929   -0.081888     0.0378686     0.000243481
 -0.119547     0.0637842   -0.390648     -0.00725195    0.1011      -0.13033     -0.00579855  -0.261369     0.106732   -0.135665    -0.00583603    0.034171     0.107474     0.0975169   -0.0969302    0.0245415   -0.0467475    0.00872734  -0.0497536    -0.0848215    0.0109401   -0.257699     -0.0272542   -0.0687197    0.00263891    0.00793861
 -0.132757     0.0207298    0.0955302     0.000396396   0.177454    -0.129627     0.0186344   -0.00830569   0.177401   -0.138084     0.00798783    0.00532096   0.114059     0.0511775   -0.365869     0.0764762   -0.0428761   -0.0217589   -0.0540501    -0.0816212    0.0172316   -0.135818     -0.0207532   -0.0442191    0.070859      0.00107145
 -0.0266963    0.0804807    0.00921062   -0.112268     -0.163908     0.0272781   -0.0439897   -0.0152244    0.0177798  -0.173119    -0.0522358     0.0775541    0.0476731   -0.0671538   -0.0779681   -0.0933536    0.117707     0.076488     0.0864336    -0.135736    -0.170666     0.132024     -0.128755    -0.0113342   -0.0774197     0.0518409
 -0.0116247   -0.00973672  -0.0750391     0.107026      0.0881844    0.00848832   0.0794791    0.205468     0.0794549  -0.112604     0.0214715    -0.0690956    0.00495208  -0.110589     0.0655041    0.0493482   -0.0885008    0.0855043   -0.121871      0.0508713    0.118397     0.0511152     0.0779242   -0.044397    -0.0747273    -0.0107859
 -0.0509291   -0.0495376   -0.0348528     0.0535637     0.0267811    0.0110981   -0.0682684    0.0646968   -0.0115313   0.0709306   -0.00688078    0.144204     0.0255712   -0.00548477   0.0229705   -0.0366741   -0.0173175   -0.0868311   -0.0378985    -0.0430098   -0.111038     0.0127642     0.1088       0.0117626   -0.000208503   0.076731
 -0.0326103    0.00943096  -0.194346      0.00692886    0.175997     0.0560641   -0.147106    -0.268321    -0.106537    0.00227179  -0.0311601     0.0455401    0.0392619    0.129631    -0.0305744    0.0240944    0.0172552   -0.128425    -0.0348719    -0.148043    -0.204734     0.196715      0.0322349    0.0923323    0.0755864    -0.0458295
  0.140089    -0.016982    -0.100405     -0.0230288     0.0904595   -0.0977899   -0.104091    -0.107031     0.138256    0.148292    -0.0724262    -0.0776664   -0.0179228   -0.126425    -0.156299    -0.209198    -0.0332712    0.0418263    0.0161682     0.107953    -0.116976    -0.0117069    -0.138772     0.00117116   0.165927     -0.19127
 -0.31442     -0.0173219   -0.0882262    -0.0955892     0.0908403   -0.112401     0.0270033   -0.119247     0.138536    0.147945    -0.0848835    -0.0593301    0.0775946    0.467608    -0.251811     0.00874424  -0.138076    -0.0413175   -0.171829      0.141073    -0.054314    -0.00583219   -0.21855      0.00123649  -0.245267      0.148633
 -0.0397691   -0.0115018    0.16749      -0.0831112    -0.0607907   -0.0513686    0.137581    -0.0269309   -0.171397    0.0548157   -0.156245     -0.153477     0.00241494   0.037709     0.182426    -0.163507    -0.0541209    0.146397     0.0833468    -0.0805981    0.146449     0.00587003   -0.0104054    0.0598403    0.0388014     0.0686356
  0.132318    -0.128851    -0.0481448    -0.0957141     0.0128388    0.0385989   -0.104444     0.133334    -0.0220116  -0.0773411    0.00294812    0.152077    -0.0743173   -0.0349736   -0.150111    -0.00029454  -0.138058    -0.0983227    0.0962961    -0.0744258    0.019387    -0.0658999     0.181165    -0.00890991   0.0243757    -0.0185283[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     17
│     19
│     20
│     24
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.126615
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      9
│     17
│     18
│     19
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.096114
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      6
│      9
│     17
│     19
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.102789
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      9
│     17
│     18
│     19
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.112601
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     17
│     19
│     20
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.111661
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      6
│      9
│     17
│     18
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.088935
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     17
│     19
│     20
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.125589
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      9
│     17
│     18
│     19
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.096888
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│      9
│     17
│     19
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.103872
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     17
│     18
│     19
│      ⋮
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.110408
┌ Info: EM with 100000 data points 10 iterations avll -1.110408
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.714843e+05
      1       7.125858e+05      -1.588985e+05 |       32
      2       6.818716e+05      -3.071416e+04 |       32
      3       6.643033e+05      -1.756828e+04 |       32
      4       6.540540e+05      -1.024936e+04 |       32
      5       6.469024e+05      -7.151572e+03 |       32
      6       6.425068e+05      -4.395628e+03 |       32
      7       6.401542e+05      -2.352575e+03 |       32
      8       6.385522e+05      -1.602046e+03 |       32
      9       6.374521e+05      -1.100106e+03 |       32
     10       6.368517e+05      -6.003907e+02 |       32
     11       6.365307e+05      -3.209550e+02 |       32
     12       6.363240e+05      -2.067220e+02 |       32
     13       6.361763e+05      -1.477351e+02 |       32
     14       6.360567e+05      -1.195723e+02 |       32
     15       6.359756e+05      -8.103673e+01 |       32
     16       6.359147e+05      -6.098041e+01 |       32
     17       6.358650e+05      -4.966801e+01 |       31
     18       6.358206e+05      -4.444197e+01 |       31
     19       6.357785e+05      -4.207739e+01 |       31
     20       6.357241e+05      -5.435179e+01 |       30
     21       6.355726e+05      -1.515070e+02 |       31
     22       6.353099e+05      -2.626838e+02 |       32
     23       6.349309e+05      -3.790464e+02 |       32
     24       6.345846e+05      -3.462740e+02 |       32
     25       6.343229e+05      -2.616749e+02 |       31
     26       6.341798e+05      -1.431922e+02 |       31
     27       6.341095e+05      -7.020846e+01 |       32
     28       6.340684e+05      -4.116004e+01 |       32
     29       6.340420e+05      -2.636056e+01 |       30
     30       6.340225e+05      -1.947367e+01 |       29
     31       6.340148e+05      -7.771742e+00 |       23
     32       6.340113e+05      -3.511027e+00 |       24
     33       6.340076e+05      -3.645876e+00 |       25
     34       6.340042e+05      -3.410783e+00 |       23
     35       6.340018e+05      -2.377492e+00 |       22
     36       6.340001e+05      -1.728904e+00 |       18
     37       6.339987e+05      -1.404678e+00 |       16
     38       6.339979e+05      -8.417868e-01 |       12
     39       6.339972e+05      -7.016507e-01 |       14
     40       6.339965e+05      -6.248705e-01 |        6
     41       6.339962e+05      -3.558373e-01 |       11
     42       6.339952e+05      -9.646891e-01 |       19
     43       6.339933e+05      -1.952096e+00 |       20
     44       6.339913e+05      -1.960743e+00 |       24
     45       6.339883e+05      -2.986759e+00 |       20
     46       6.339840e+05      -4.346605e+00 |       25
     47       6.339815e+05      -2.505849e+00 |       25
     48       6.339794e+05      -2.020926e+00 |       22
     49       6.339777e+05      -1.746958e+00 |       19
     50       6.339758e+05      -1.850120e+00 |       25
K-means terminated without convergence after 50 iterations (objv = 633975.8389108758)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.346854
[ Info: iteration 2, average log likelihood -1.312904
[ Info: iteration 3, average log likelihood -1.283982
[ Info: iteration 4, average log likelihood -1.251167
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.212116
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.180793
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     20
│     21
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.138285
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.148105
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      7
│     12
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.118163
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.138453
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.123470
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     21
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.097456
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      7
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.107052
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     20
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.116021
[ Info: iteration 15, average log likelihood -1.128972
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     12
│     17
│     23
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.069155
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      7
│     20
│     21
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.116071
[ Info: iteration 18, average log likelihood -1.175724
[ Info: iteration 19, average log likelihood -1.113633
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     12
│     20
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.054695
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      7
│     17
│     21
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.097996
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.138745
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.109878
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      7
│     12
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.069234
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     17
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.103700
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     21
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.108834
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.120099
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.095388
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      7
│     17
│     21
│     23
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.071204
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.144014
[ Info: iteration 31, average log likelihood -1.126165
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      7
│     20
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.061000
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     12
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.099918
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.112223
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.122959
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     12
│     20
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.076653
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      7
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.106510
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     21
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.099212
[ Info: iteration 39, average log likelihood -1.130757
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      7
│     12
│     20
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.068477
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.121303
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.106415
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.089264
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     12
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.088840
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.104004
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.098149
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.091636
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      7
│     12
│     20
│     23
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.051907
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.130984
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.114774
┌ Info: EM with 100000 data points 50 iterations avll -1.114774
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.141251      0.0973459    0.195119    -0.15594     -0.108309    -0.126155     -0.0937574    0.118703   -0.0235725   0.0461101   -0.103753     -0.0200573   -0.134963     0.10144     -0.032812    -0.0595385  -0.0284547   -0.0392638   0.0203989   0.112369     0.0396537    0.0878334     0.0683337   -0.088508     0.113234    -0.0524401
  0.0129422     0.281703    -0.0720525    0.0718328    0.153038     0.0291271     0.0464727    0.0421117   0.0880642  -0.119419     0.14132      -0.193676    -0.00737997  -0.0160141   -0.00574854   0.0522843   0.183976    -0.128032   -0.0120291   0.160467     0.0707586    0.0947115    -0.0342447    0.0118639   -0.00147808   0.128773
  0.0611296    -0.0345819   -0.0644414   -0.098191     0.00880448   0.181313      0.0158727    0.0420269   0.200474   -0.0495114    0.135094     -0.0376385   -0.0476609    0.19388     -0.0814028   -0.0735511   0.0741313    0.0543595  -0.0739654  -0.0759052   -0.0824602    0.0641306     0.331335     0.234181     0.0813892    0.0100287
  0.0365396     0.0924639   -0.030077     0.0532311   -0.00920823   0.10019       4.11135e-5   0.045227   -0.204251    0.0254085    0.1493        0.0522068    0.172236     0.00718774  -0.248173     0.0547393   0.157778    -0.0590301  -0.17525    -0.00644902   0.0192561    0.0889457     0.0846578    0.0393629    0.0129057    0.111558
 -0.0894925    -0.112212    -0.00373157  -0.0466148   -0.0212464   -0.0113234    -0.100926    -0.0166116   0.132177   -0.104962    -0.301341     -0.0871847   -0.127679    -0.0271196    0.163286    -0.103067    0.183557    -0.0782238   0.0814322  -0.0376753   -0.0619464   -0.000237164  -0.0394218   -0.17856     -0.0827151   -0.0397511
 -0.00764791   -0.0133674   -0.0653831    0.0906086    0.0741062    0.00769341    0.073787     0.189732    0.0695119  -0.112762     0.00145166   -0.0769764    0.00880131  -0.116601     0.0741603    0.024696   -0.100676     0.0963993  -0.0903252   0.0508088    0.111657     0.0498846     0.0729317   -0.0349655   -0.070104    -0.0296403
  0.0394817    -0.0826864   -0.0392563   -0.0237633    0.126235     0.0639561    -0.0663364    0.132172    0.261916    0.11468      0.0646697     0.0513284   -0.118484     0.0414286    0.0122734   -0.193164   -0.052442     0.0803851   0.191335   -0.0539403   -0.0294874   -0.0028505    -0.0364136    0.137894    -0.0863398   -0.102463
 -0.0313012    -0.00242246  -0.165418     0.162249    -0.0551549    0.0837748     0.116725     0.0480429   0.0281452  -0.0303841    0.0407692     0.0872452   -0.0636218   -0.018371     0.0133862   -0.0570503   0.125506    -0.0413374   0.0995254   0.057361    -0.0950876   -0.0147357    -0.0325095    0.0825521    0.0654879    0.00412616
 -0.0320134     0.0345199    0.145269     0.121177    -0.0327031   -0.0790817     0.0330221   -0.0475367   0.0268494   0.0567597   -0.117755     -0.0724851   -0.136103    -0.074062    -0.00734899  -0.168727   -0.110673     0.0275924   0.17229    -0.0816402    0.0531578    0.107099     -0.00609921   0.00883937  -0.118333     0.125241
 -0.0860218     0.140098     0.044571    -0.00673681   0.0936228   -0.0719636    -0.153414    -0.015633    0.131618    0.0669585    0.137512      0.0111107    0.27647     -0.112767     0.142864    -0.178282    0.110644    -0.0701486  -0.0447764   0.116195     0.158713    -0.166809     -0.136146    -0.114087    -0.0944479   -0.114358
 -0.0982078     0.073946     0.0463134    0.0110463   -0.00867132   0.000890467  -0.0691373   -0.0137515   0.130583    0.0817938    0.217537      0.0708521    0.00789551   0.0463859   -0.0124687    0.13296     0.0205825    0.141867    0.104837   -0.245875     0.0626241    0.00973757   -0.0445894   -0.0673521    0.0154598    0.00816492
  0.159536     -0.0898919    0.227081    -0.0873815    0.0472006    0.0211746    -0.0987642   -0.0572287  -0.134981   -0.0520896   -0.0849944    -0.138204     0.0982698   -0.131486    -0.0876107   -0.044442   -0.168238    -0.0725252  -0.060231   -0.0833001   -0.00760829  -0.067948     -0.0111383   -0.133364     0.118612    -0.0227051
  0.0450089     0.00835448  -0.0613069   -0.0853863    0.015952    -0.0233627     0.242752     0.133531   -0.108535   -0.0598075    0.023853     -0.0596637   -0.119553    -0.125536    -0.183555     0.0407208  -0.20653     -0.0816656  -0.257937   -0.253299     0.0903959    0.00227093    0.0353454    0.0418497    0.0258815    0.108064
  0.0488149     0.0109315    0.00187844  -0.11608     -0.104576    -0.0710266     0.11094     -0.163414    0.2015     -0.0781954   -0.0383759     0.0467683   -0.0952345   -0.0574641    0.0706068    0.0211209   0.0787004   -0.112145   -0.0701725   0.0570692    0.0509539    0.0835476     0.0642498    0.154519    -0.1593      -0.0450581
  0.045009      0.104853     0.131071    -0.0245266    0.203125    -0.0697433    -0.184312     0.177696    0.0711083   0.101822    -0.174823      0.0962177    0.0707626   -0.0439676    0.1217      -0.0947249   0.0518072    0.0360396  -0.0730849   0.206743    -0.0587498    0.00923501    0.0986586   -0.127441    -0.0721319   -0.0142327
 -0.0300011     0.00934977  -0.196329     0.00899285   0.177547     0.0541994    -0.147385    -0.263245   -0.105448    0.00509606  -0.0310368     0.048457     0.0393743    0.132411    -0.0297037    0.0234612   0.0163264   -0.129588   -0.0320233  -0.148199    -0.205085     0.196635      0.0324928    0.0902944    0.0733817   -0.0425352
 -0.000853592  -0.00674585   0.0749805   -0.079259     0.187966     0.000232794  -0.00914811   0.0344804   0.0320808   0.00444272  -0.0331983     0.194513    -0.0496571    0.021509     0.0102186    0.0842422  -0.111462     0.0373757   0.0215606   0.100568     0.0299768    0.0362392    -0.0549665   -0.00150737  -0.0787823    0.0958648
  0.170713      0.101942     0.605051    -0.0193996   -0.0863148    0.0931793    -0.139798    -0.0171894   0.175685   -0.0477334   -0.0325929     0.0989389    0.0197592    0.18137      0.0644196    0.133108    0.158386    -0.0115033  -0.0623264   0.236887     0.0450755   -0.0941856     0.0349738    0.101396     0.00817177  -0.160245
 -0.033349     -0.013328     0.16304     -0.0823737   -0.0622673   -0.0514489     0.137683    -0.026001   -0.164531    0.0588708   -0.154125     -0.146728     0.00325474   0.0309048    0.178374    -0.16205    -0.0557941    0.141839    0.0819609  -0.078238     0.142848     0.0038031    -0.0125664    0.0563174    0.0396441    0.0684681
 -0.0759228    -0.0164219   -0.103594    -0.0508625    0.0811705   -0.0918921    -0.0292606   -0.105712    0.126097    0.139232    -0.0808374    -0.0492759    0.0328143    0.173089    -0.181464    -0.0911089  -0.0674332   -0.0227785  -0.0652158   0.111801    -0.0878168   -0.00580291   -0.167438    -0.0015859   -0.0303816   -0.0216889
 -0.126411      0.00527004   0.0079543   -0.0012683    0.102756    -0.129335      0.0295904   -0.0398067   0.153006   -0.138508     0.000140352   0.0284431    0.11747      0.0901241   -0.241453     0.0652494  -0.0447885   -0.0130814  -0.0556259  -0.0935047    0.0168931   -0.0472258    -0.0226397   -0.0649931    0.051031     0.000456314
 -0.129509      0.0769194    0.106632    -0.213499     0.0596167    0.0674152     0.0775567    0.0763007   0.0200577  -0.124264    -0.000431718   0.0742969   -0.138246    -0.100213     0.0351575   -0.168932   -0.143825     0.0253856   0.0372064   0.0838426   -0.117778     0.122478     -0.047234    -0.0247434   -0.192471     0.170364
  0.0657614    -0.157529     0.0177725    0.0479288    0.0475382   -0.0315807    -0.161467    -0.0354565  -0.0704404  -0.0479678   -0.0226206     0.106814    -0.0634127   -0.0182946   -0.131924    -0.0703891   0.129316     0.0130308  -0.0501257   0.165448     0.054227     0.0761671    -0.0913515    0.00234703   0.0379864   -0.0592081
 -0.0164333     0.178823    -0.112245    -0.0669556    0.144693     0.170164     -0.160544    -0.0676299   0.0187979   0.0464977   -0.238254      0.00619206   0.32285      0.00108028   0.0359046   -0.204002    0.104858     0.0147924   0.0587359   0.00339661  -0.131382     0.00394268    0.0737902    0.10205      0.193671     0.0055716
  0.17887       0.117509    -0.220145    -0.0815623   -0.0587708    0.115653     -0.173452    -0.063642    0.34374    -0.0438659    0.0359253    -0.123396     0.0811399    0.245565     0.0519458    0.187485    0.212833     0.124967   -0.0223076   0.0457883    0.207682    -0.0996413     0.0166153    0.404722     0.144116    -0.0117375
  0.107528     -0.14954      0.20945     -0.00761527   0.0171283    0.085198      0.0293706    0.101631    0.0539152  -0.0372136   -0.0655773     0.200714     0.0164468    0.00653959   0.186048     0.0450416   0.00310524  -0.0412221  -0.0104328  -0.137621     0.142295    -0.0195011    -0.0755858    0.233041     0.0544113   -0.0497041
  0.0974289     0.0809506    0.0420007    0.0630082   -0.102998     0.0273547     0.00590464   0.0760077   0.075661    0.112016    -0.195519      0.171218     0.134346     0.0145653    0.0616004    0.133866   -0.00197815  -0.246836   -0.0785453   0.0232598   -0.227608     0.0186611     0.0113406   -0.11442     -0.022982     0.0123528
 -0.105528     -0.0600035   -0.0395116   -0.0237667   -0.00795904   0.0129201    -0.0817688    0.0377293  -0.0426586  -0.0407785    0.016198      0.0939608   -0.025873    -0.0540909   -0.0286695   -0.134787    0.0295969    0.0730055   0.0333018  -0.11749     -0.0959715    0.0582231     0.0425009    0.0550694   -0.0347781    0.0821772
  0.149426     -0.115001    -0.0453775   -0.0785582    0.00762095   0.0349011    -0.103989     0.144175   -0.0101925  -0.0813224    0.0056713     0.161816    -0.0517688   -0.0671946   -0.128293     0.0141288  -0.150814    -0.111377    0.0821724  -0.0651256    0.00897016  -0.0597583     0.190101    -0.0154127    0.0168458   -0.0208234
  0.146669     -0.0415861    0.0092904    0.0277524   -0.0244505    0.118939     -0.198224    -0.0287902   0.0541787   0.0636334   -0.00372038    0.235009    -0.0678737   -0.0236255    0.0923304   -0.0421195  -0.0396458   -0.0482336  -0.118927   -0.0349487   -0.171822    -0.0503096     0.156533    -0.0393836    0.0349933    0.06972
  0.16087       0.0383085   -0.0407956   -0.0345648    0.0109871   -0.00318351   -0.0779252    0.0811544   0.0901621   0.0997779    0.0358906     0.0980645    0.0161009    0.0668308   -0.0749757   -0.27752    -0.214128    -0.0537899  -0.208049    0.0909777   -0.0179169   -0.107134      0.00132499  -0.0617898   -0.0399072    0.00252421
 -0.22428       0.0682925    0.0545921    0.111502    -0.048446    -0.0523972    -0.025438     0.0662901   0.192737   -0.0369578    0.0443674    -0.0174799   -0.105906    -0.0900847    0.0122956   -0.011025   -0.0161645    0.0399856   0.0709701  -0.129151     0.0452374   -0.0283528     0.134094     0.104116     0.0611553   -0.239898[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.096707
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      7
│     12
│     17
│     20
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.043308
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     20
│     21
│     23
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.057354
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      6
│      7
│     12
│     20
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.055152
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.078463
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      7
│     12
│     17
│      ⋮
│     27
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.023950
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.086394
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      6
│      7
│     12
│      ⋮
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.041381
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     21
│     23
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.066520
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      7
│     12
│     20
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.054944
┌ Info: EM with 100000 data points 10 iterations avll -1.054944
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0228602  -0.0193631    0.0807811   -0.169484    -0.177573    0.0770432   -0.117637    -0.118066    -0.00522127    0.156897      0.13351      0.30645      0.0866521   -0.00795425   0.0292089    0.0624057   -0.0559489     0.0960215   -0.00940868   0.02712     -0.157606    0.0736724    0.0289329    0.12084     -0.113322     -0.0556152
 -0.0226654  -0.00241688   0.0396271    0.0370071   -0.0498164  -0.164068    -0.061877     0.0879335   -0.150443     -0.0660051     0.0142125    0.0242523   -0.0862515   -0.0460948    0.0712866    0.101525    -0.0982291     0.080943     0.145455     0.0265692    0.0191809   0.0446091    0.0798049   -0.117512     0.0270485     0.0224305
  0.0768333   0.161409    -0.10735      0.0424836    0.106325    0.0303162    0.113309    -0.0773481   -0.0804894    -0.0116754    -0.165389    -0.075823     0.014336     0.00614065  -0.011657    -0.0842765   -0.108397     -0.0211033   -0.0192336    0.0345347   -0.0223253   0.0579582    0.153152    -0.163999     0.105661      0.00337191
 -0.152657    0.0454267    0.059435    -0.0112534   -0.0852919   0.125546    -0.159857    -0.00937681   0.134908     -0.0307304     0.0897192   -0.00585151   0.0363961    0.22925     -0.238049     0.0424842   -0.000559488  -0.00558601  -0.135851     0.0654929   -0.0688376   0.0634541    0.0718726    0.022563     0.0618384    -0.0416943
  0.144871   -0.0339441    0.0599612   -0.0766552    0.0599884  -0.0166362   -0.0583132   -0.0581788   -0.181553      0.0972956    -0.231911    -0.0222487   -0.127041     0.0632311    0.109795     0.0129281   -0.0770947     0.185107     0.10813     -0.201208     0.0956753  -0.0619497   -0.0931356    0.0281699    0.0865326     0.072417
 -0.214851   -0.0869011    0.010801    -0.0536231    0.0300239  -0.00628106  -0.132745     0.0815555    0.15825      -0.0110375    -0.210039    -0.0664992   -0.0141832    0.130655     0.114489     0.0166867   -0.000611093  -0.0147502   -0.0937773   -0.0498606   -0.0128866   0.292724    -0.113747     0.0828959    0.0528408     0.0446425
  0.10391     0.0481192   -0.0881467   -0.184685     0.0629608  -0.1984       0.0137227    0.0456726    0.130948     -0.0590758    -0.03335     -0.0305141   -0.156467     0.158173    -0.0405217    0.00283012   0.046334     -0.0139088    0.196718    -0.0383865   -0.110894   -0.0853634    0.0417949    0.0502893    0.144939      0.0616488
  0.162388    0.0864263    0.10164      0.105798     0.0850908   0.0339019    0.230661    -0.0228292   -0.125277     -0.196237      0.216612     0.0056994   -0.0459405   -0.0336859    0.0618701    0.0325774   -0.0392749     0.0665714   -0.0374654   -0.276938     0.12197    -0.047794     0.0315653   -0.0650589    0.0758391    -0.0172342
 -0.11417    -0.0709613    0.0414561   -0.100782     0.185319    0.0666965   -0.122944    -0.0623402   -0.000940389   0.103271      0.0502096   -0.0254671   -0.0836846   -0.0430652   -0.0988736   -0.0279835    0.0493803    -0.0425862    0.0253364   -0.0945046   -0.0343364   0.0293924    0.0590713   -0.107369    -0.0252232     0.0614936
  0.141825    0.0662257    0.0209496   -0.0233193    0.102386   -0.0673698   -0.0452224    0.0114166    0.0160042     0.0103645    -0.053689    -0.0979802    0.130777    -0.102223     0.00492477   0.0726751   -0.0352576     0.018904    -0.079486     0.0291993    0.034267    0.247793    -0.0346634   -0.0579355    0.0934625     0.075096
  0.0563379  -0.0718803   -0.00764413  -0.0283916    0.0381752   0.135741    -0.0167527   -0.194213     0.0993677     0.155866      0.0331483   -0.0956306    0.0799904   -0.122617     0.110921    -0.0109521    0.165574     -0.0868984    0.00553649  -0.0317371    0.245505   -0.0312591    0.0434973    0.0244035    0.00555394    0.150908
  0.163135    0.164135     0.0122672    0.0412216    0.144317    0.0194989   -0.0667167    0.0592034    0.042598      0.0874644     0.0259515    0.0198642    0.0324667    0.128808    -0.0552475    0.104541     0.00746643   -0.0207674    0.268597    -0.113785     0.196567   -0.147062    -0.115589     0.0765903    0.162122     -0.123148
  0.0845633   0.11204      0.0899738   -0.0528013   -0.203606    0.06883     -0.133694    -0.3582       0.0991379    -0.275868      0.194857     0.0374683   -0.0186688    0.0256271   -0.161034    -0.0883238    0.249744      0.063613    -0.0659397   -0.0593229   -0.0115269   0.0406189   -0.094307    -0.0533373   -0.14069      -0.0726459
 -0.0675923   0.0137632   -0.148554    -0.0747577   -0.0857859  -0.122071    -0.115514     0.300833    -0.063294     -0.0250752     0.0477639   -0.0251231    0.0168236   -0.0194342    0.0180615    0.0331398   -0.0813163    -0.0722696    0.00198696  -0.0856135   -0.111794    0.0913423   -0.108899    -0.0824735    0.00253363   -0.0233093
 -0.0192835  -0.143798     0.109769    -0.0564364    0.102396    0.002375    -0.0491       0.131758     0.0300047     0.104038     -0.0851046    0.0567745    0.0900862   -0.0415941    0.0822465   -0.317961     0.0989462     0.0203511    0.191487    -0.148822     0.108483   -0.0134582   -0.0135069   -0.0947639   -0.0350213     0.106109
  0.0533997  -0.00195316   0.0372053   -0.0953383   -0.0142943   0.145454    -0.0941758   -0.23735      0.0795391    -0.0418623    -0.0110061    0.0183443    0.0264507   -0.237162     0.0199222   -0.0106481    0.0385329     0.0998539   -0.140131     0.187075     0.224815    0.0280311   -0.0299048   -0.0773745   -0.0110136     0.0970426
  0.0446501  -0.0580955    0.0446292    0.0787881    0.148195    0.0938894    0.103949     3.48798e-6  -0.170437     -0.112461      0.146182     0.193385     0.00621558   0.066525    -0.0498144    0.118871    -0.0594411    -0.0385683    0.118414     0.0975434   -0.0969417   0.0806709   -0.108593    -0.118691    -0.0961257    -0.0958833
 -0.165739   -0.0318191   -0.128082    -0.0760038   -0.251823   -0.0305107   -0.035578    -0.261101    -0.0154827    -0.000958625  -0.104572    -0.203099    -0.0564408   -0.0389116    0.0667735   -0.0723995   -0.0407712     0.123524     0.0183704   -0.0300046    0.0820962   0.0169424    0.0835515    0.0246002   -0.117194     -0.112717
  0.210628   -0.113047     0.0380129   -0.041447    -0.0369557   0.0636918   -0.107265    -0.0815859   -0.0248182    -0.112411     -0.141884    -0.0385723   -0.155237     0.0867726    0.11337      0.116468     0.103926     -0.104641    -0.0238997   -0.143489     0.158067    0.0224999    0.0247019    0.0430121    0.122095     -0.178101
 -0.14038    -0.114586     0.0660263   -0.0271781   -0.127389    0.0510096    0.0380401    0.107109     0.165434     -0.0694682    -0.029628     0.0897268   -0.0223691    0.100732    -0.0611787    0.109102     0.151104      0.0357611   -0.0868974    0.0322889    0.237601   -0.146392     0.123274     0.0805599   -0.0230934     0.0304866
  0.12528    -0.0528069   -0.121137     0.0634445   -0.0539395   0.0973702    0.0742139    0.10366     -0.0458295    -0.133642     -0.00458041   0.318188    -0.0158685    0.0476387   -0.0262678    0.0194953   -0.0530998     0.0793795    0.0763377    0.106776     0.0937019  -0.0861127    0.225569    -0.0339976   -0.0331308    -0.261607
 -0.0661067  -0.143281     0.2167       0.0728103    0.18473     0.0386346   -0.138849    -0.058455    -0.0928874     0.0526941     0.169524    -0.0115591   -0.051561    -0.041232    -0.10179      0.098673     0.207756     -0.0132327   -0.0430154   -0.016669    -0.0253794   0.0780111    0.0446019    0.15649     -0.0464671    -0.0439658
  0.0864756  -0.0493069   -0.179788    -0.0342435    0.112614   -0.0597172    0.144239     0.155338     0.26711      -0.0791075     0.0704803    0.0163091    0.04767      0.0393929    0.0343775   -0.0998307   -0.107961      0.0920583    0.110785     0.121858     0.0585429   0.0411726   -0.00798687   0.0645464    0.190495     -0.00290837
 -0.041909   -0.00317477   0.0641433   -0.00951613   0.0440246  -0.195066    -0.00342456   0.00423853   0.0766403     0.143581      0.0311587    0.163013    -0.00262114  -0.00789295   0.0343305    0.0323865   -0.191219     -0.13837      0.23723     -0.00967384   0.0425975   0.0448806    0.0046419    0.0754705   -0.0129439     0.0999804
  0.182939   -0.0201399   -0.00338083   0.0228377    0.120153   -0.0586966   -0.127079    -0.0321997   -0.053216      0.0430792     0.00238477  -0.0577601   -0.0530766    0.0476402    0.0734883    0.00918524   0.0582942     0.0921999   -0.0423572   -0.0293779   -0.0634365  -0.05617     -0.00670582   0.107087    -0.0607095    -0.00662354
  0.0163245  -0.0458139   -0.0954441   -0.0373373   -0.0361684   0.0316986   -0.186319     0.0431341    0.0731831     0.00379724    0.0913634   -0.0197393   -0.0789592    0.0793434   -0.0598482    0.0216848   -0.0151221    -0.0471916    0.095705     0.0429934    0.0523099  -0.0524981    0.164559    -0.00333606   0.000966687   0.176156
 -0.136211    0.0457553    0.234977    -0.0376256    0.0540128   0.0263199   -0.0376306   -0.00778161   0.00855763   -0.0220208    -0.242297    -0.286742     0.022106     0.0355509   -0.0400175    0.0941072    0.125719      0.0599381    0.00512004   0.00850232  -0.0760751   0.0514344    0.0529643   -0.154561    -0.149462      0.168917
 -0.105359    0.167208    -0.109951     0.0282846   -0.193298   -0.185031    -0.124115     0.257742     0.0424007    -0.124994      0.130668     0.0810653   -0.0758853   -0.111517     0.082843    -0.317272    -0.0457836     0.051865    -0.167458     0.0259541   -0.0212439   5.56932e-5  -0.00240804   0.137761     0.0596422    -0.0348273
  0.130932    0.00949361   0.0131507    0.149971    -0.0662335   0.006764    -0.0223289   -0.122504     0.035202     -0.112675      0.0618898    0.117878     0.0444136   -0.00163058  -0.0661627    0.00443566   0.100466      0.0221528   -0.0188556   -0.0365591    0.11094    -0.02089     -0.0488832   -0.0453151    0.0831302     0.091485
  0.256283   -0.118988    -0.0118294    0.0814893    0.0719652  -0.0222508   -0.0796285    0.015464     0.0372345    -0.00815939   -0.0874481   -0.143517    -0.198147     0.0744986    0.0593607    0.0860686    0.158726     -0.0857873    0.0297732   -0.0237671    0.0307818   0.0995052   -0.0376073   -0.0839379    0.0207265     0.0523446
 -0.0431296  -0.209717     0.0137105   -0.1977      -0.0573334  -0.0427397    0.159437    -0.00734092  -0.126138      0.105202      0.0844191    0.0483249    0.0703681   -0.120096     0.0675711   -0.11596     -0.0983913     0.0746223    0.125627     0.212454    -0.0170084  -0.130247    -0.0632388   -0.0744634   -0.090552     -0.122474
  0.0612015  -0.0293312   -0.180219     0.0647933    0.0507797  -0.0971444   -0.184596     0.132189    -0.00373292    0.113312      0.185537    -0.0608247   -0.0520092   -0.0259306   -0.0521326   -0.186234     0.112647     -0.0277936   -0.0609341    0.107442     0.0179228   0.131395    -0.096397    -0.00888342  -0.00896028    0.000483365kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4207359906858201
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420755
[ Info: iteration 2, average log likelihood -1.420687
[ Info: iteration 3, average log likelihood -1.420637
[ Info: iteration 4, average log likelihood -1.420580
[ Info: iteration 5, average log likelihood -1.420512
[ Info: iteration 6, average log likelihood -1.420432
[ Info: iteration 7, average log likelihood -1.420335
[ Info: iteration 8, average log likelihood -1.420210
[ Info: iteration 9, average log likelihood -1.420019
[ Info: iteration 10, average log likelihood -1.419685
[ Info: iteration 11, average log likelihood -1.419088
[ Info: iteration 12, average log likelihood -1.418168
[ Info: iteration 13, average log likelihood -1.417101
[ Info: iteration 14, average log likelihood -1.416252
[ Info: iteration 15, average log likelihood -1.415777
[ Info: iteration 16, average log likelihood -1.415565
[ Info: iteration 17, average log likelihood -1.415479
[ Info: iteration 18, average log likelihood -1.415443
[ Info: iteration 19, average log likelihood -1.415428
[ Info: iteration 20, average log likelihood -1.415422
[ Info: iteration 21, average log likelihood -1.415419
[ Info: iteration 22, average log likelihood -1.415418
[ Info: iteration 23, average log likelihood -1.415417
[ Info: iteration 24, average log likelihood -1.415416
[ Info: iteration 25, average log likelihood -1.415416
[ Info: iteration 26, average log likelihood -1.415416
[ Info: iteration 27, average log likelihood -1.415415
[ Info: iteration 28, average log likelihood -1.415415
[ Info: iteration 29, average log likelihood -1.415415
[ Info: iteration 30, average log likelihood -1.415415
[ Info: iteration 31, average log likelihood -1.415414
[ Info: iteration 32, average log likelihood -1.415414
[ Info: iteration 33, average log likelihood -1.415414
[ Info: iteration 34, average log likelihood -1.415414
[ Info: iteration 35, average log likelihood -1.415414
[ Info: iteration 36, average log likelihood -1.415414
[ Info: iteration 37, average log likelihood -1.415414
[ Info: iteration 38, average log likelihood -1.415414
[ Info: iteration 39, average log likelihood -1.415414
[ Info: iteration 40, average log likelihood -1.415414
[ Info: iteration 41, average log likelihood -1.415413
[ Info: iteration 42, average log likelihood -1.415413
[ Info: iteration 43, average log likelihood -1.415413
[ Info: iteration 44, average log likelihood -1.415413
[ Info: iteration 45, average log likelihood -1.415413
[ Info: iteration 46, average log likelihood -1.415413
[ Info: iteration 47, average log likelihood -1.415413
[ Info: iteration 48, average log likelihood -1.415413
[ Info: iteration 49, average log likelihood -1.415413
[ Info: iteration 50, average log likelihood -1.415413
┌ Info: EM with 100000 data points 50 iterations avll -1.415413
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4207547421970208
│     -1.4206874208285687
│      ⋮
└     -1.4154131131080208
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415428
[ Info: iteration 2, average log likelihood -1.415363
[ Info: iteration 3, average log likelihood -1.415308
[ Info: iteration 4, average log likelihood -1.415244
[ Info: iteration 5, average log likelihood -1.415167
[ Info: iteration 6, average log likelihood -1.415077
[ Info: iteration 7, average log likelihood -1.414978
[ Info: iteration 8, average log likelihood -1.414879
[ Info: iteration 9, average log likelihood -1.414788
[ Info: iteration 10, average log likelihood -1.414710
[ Info: iteration 11, average log likelihood -1.414646
[ Info: iteration 12, average log likelihood -1.414597
[ Info: iteration 13, average log likelihood -1.414560
[ Info: iteration 14, average log likelihood -1.414532
[ Info: iteration 15, average log likelihood -1.414511
[ Info: iteration 16, average log likelihood -1.414495
[ Info: iteration 17, average log likelihood -1.414482
[ Info: iteration 18, average log likelihood -1.414470
[ Info: iteration 19, average log likelihood -1.414459
[ Info: iteration 20, average log likelihood -1.414449
[ Info: iteration 21, average log likelihood -1.414438
[ Info: iteration 22, average log likelihood -1.414428
[ Info: iteration 23, average log likelihood -1.414418
[ Info: iteration 24, average log likelihood -1.414407
[ Info: iteration 25, average log likelihood -1.414397
[ Info: iteration 26, average log likelihood -1.414387
[ Info: iteration 27, average log likelihood -1.414377
[ Info: iteration 28, average log likelihood -1.414367
[ Info: iteration 29, average log likelihood -1.414357
[ Info: iteration 30, average log likelihood -1.414348
[ Info: iteration 31, average log likelihood -1.414339
[ Info: iteration 32, average log likelihood -1.414330
[ Info: iteration 33, average log likelihood -1.414322
[ Info: iteration 34, average log likelihood -1.414315
[ Info: iteration 35, average log likelihood -1.414308
[ Info: iteration 36, average log likelihood -1.414302
[ Info: iteration 37, average log likelihood -1.414297
[ Info: iteration 38, average log likelihood -1.414292
[ Info: iteration 39, average log likelihood -1.414287
[ Info: iteration 40, average log likelihood -1.414283
[ Info: iteration 41, average log likelihood -1.414280
[ Info: iteration 42, average log likelihood -1.414277
[ Info: iteration 43, average log likelihood -1.414274
[ Info: iteration 44, average log likelihood -1.414271
[ Info: iteration 45, average log likelihood -1.414269
[ Info: iteration 46, average log likelihood -1.414267
[ Info: iteration 47, average log likelihood -1.414265
[ Info: iteration 48, average log likelihood -1.414263
[ Info: iteration 49, average log likelihood -1.414262
[ Info: iteration 50, average log likelihood -1.414260
┌ Info: EM with 100000 data points 50 iterations avll -1.414260
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4154279927937212
│     -1.415362714005791
│      ⋮
└     -1.4142604141571022
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414269
[ Info: iteration 2, average log likelihood -1.414217
[ Info: iteration 3, average log likelihood -1.414173
[ Info: iteration 4, average log likelihood -1.414124
[ Info: iteration 5, average log likelihood -1.414067
[ Info: iteration 6, average log likelihood -1.413997
[ Info: iteration 7, average log likelihood -1.413917
[ Info: iteration 8, average log likelihood -1.413827
[ Info: iteration 9, average log likelihood -1.413732
[ Info: iteration 10, average log likelihood -1.413638
[ Info: iteration 11, average log likelihood -1.413548
[ Info: iteration 12, average log likelihood -1.413468
[ Info: iteration 13, average log likelihood -1.413397
[ Info: iteration 14, average log likelihood -1.413338
[ Info: iteration 15, average log likelihood -1.413291
[ Info: iteration 16, average log likelihood -1.413253
[ Info: iteration 17, average log likelihood -1.413223
[ Info: iteration 18, average log likelihood -1.413201
[ Info: iteration 19, average log likelihood -1.413183
[ Info: iteration 20, average log likelihood -1.413168
[ Info: iteration 21, average log likelihood -1.413156
[ Info: iteration 22, average log likelihood -1.413146
[ Info: iteration 23, average log likelihood -1.413137
[ Info: iteration 24, average log likelihood -1.413129
[ Info: iteration 25, average log likelihood -1.413122
[ Info: iteration 26, average log likelihood -1.413115
[ Info: iteration 27, average log likelihood -1.413108
[ Info: iteration 28, average log likelihood -1.413102
[ Info: iteration 29, average log likelihood -1.413096
[ Info: iteration 30, average log likelihood -1.413090
[ Info: iteration 31, average log likelihood -1.413084
[ Info: iteration 32, average log likelihood -1.413078
[ Info: iteration 33, average log likelihood -1.413073
[ Info: iteration 34, average log likelihood -1.413068
[ Info: iteration 35, average log likelihood -1.413062
[ Info: iteration 36, average log likelihood -1.413057
[ Info: iteration 37, average log likelihood -1.413052
[ Info: iteration 38, average log likelihood -1.413047
[ Info: iteration 39, average log likelihood -1.413042
[ Info: iteration 40, average log likelihood -1.413037
[ Info: iteration 41, average log likelihood -1.413032
[ Info: iteration 42, average log likelihood -1.413027
[ Info: iteration 43, average log likelihood -1.413022
[ Info: iteration 44, average log likelihood -1.413018
[ Info: iteration 45, average log likelihood -1.413013
[ Info: iteration 46, average log likelihood -1.413008
[ Info: iteration 47, average log likelihood -1.413003
[ Info: iteration 48, average log likelihood -1.412998
[ Info: iteration 49, average log likelihood -1.412994
[ Info: iteration 50, average log likelihood -1.412989
┌ Info: EM with 100000 data points 50 iterations avll -1.412989
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.41426912729387
│     -1.4142171219558477
│      ⋮
└     -1.4129887843047686
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412994
[ Info: iteration 2, average log likelihood -1.412938
[ Info: iteration 3, average log likelihood -1.412888
[ Info: iteration 4, average log likelihood -1.412831
[ Info: iteration 5, average log likelihood -1.412762
[ Info: iteration 6, average log likelihood -1.412680
[ Info: iteration 7, average log likelihood -1.412584
[ Info: iteration 8, average log likelihood -1.412478
[ Info: iteration 9, average log likelihood -1.412369
[ Info: iteration 10, average log likelihood -1.412260
[ Info: iteration 11, average log likelihood -1.412156
[ Info: iteration 12, average log likelihood -1.412059
[ Info: iteration 13, average log likelihood -1.411968
[ Info: iteration 14, average log likelihood -1.411885
[ Info: iteration 15, average log likelihood -1.411809
[ Info: iteration 16, average log likelihood -1.411740
[ Info: iteration 17, average log likelihood -1.411678
[ Info: iteration 18, average log likelihood -1.411622
[ Info: iteration 19, average log likelihood -1.411571
[ Info: iteration 20, average log likelihood -1.411526
[ Info: iteration 21, average log likelihood -1.411485
[ Info: iteration 22, average log likelihood -1.411447
[ Info: iteration 23, average log likelihood -1.411413
[ Info: iteration 24, average log likelihood -1.411382
[ Info: iteration 25, average log likelihood -1.411353
[ Info: iteration 26, average log likelihood -1.411327
[ Info: iteration 27, average log likelihood -1.411302
[ Info: iteration 28, average log likelihood -1.411279
[ Info: iteration 29, average log likelihood -1.411258
[ Info: iteration 30, average log likelihood -1.411238
[ Info: iteration 31, average log likelihood -1.411220
[ Info: iteration 32, average log likelihood -1.411202
[ Info: iteration 33, average log likelihood -1.411186
[ Info: iteration 34, average log likelihood -1.411170
[ Info: iteration 35, average log likelihood -1.411156
[ Info: iteration 36, average log likelihood -1.411142
[ Info: iteration 37, average log likelihood -1.411129
[ Info: iteration 38, average log likelihood -1.411116
[ Info: iteration 39, average log likelihood -1.411105
[ Info: iteration 40, average log likelihood -1.411093
[ Info: iteration 41, average log likelihood -1.411083
[ Info: iteration 42, average log likelihood -1.411072
[ Info: iteration 43, average log likelihood -1.411063
[ Info: iteration 44, average log likelihood -1.411053
[ Info: iteration 45, average log likelihood -1.411044
[ Info: iteration 46, average log likelihood -1.411036
[ Info: iteration 47, average log likelihood -1.411027
[ Info: iteration 48, average log likelihood -1.411020
[ Info: iteration 49, average log likelihood -1.411012
[ Info: iteration 50, average log likelihood -1.411005
┌ Info: EM with 100000 data points 50 iterations avll -1.411005
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.412994367204799
│     -1.4129377604868425
│      ⋮
└     -1.4110046693334004
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411006
[ Info: iteration 2, average log likelihood -1.410941
[ Info: iteration 3, average log likelihood -1.410880
[ Info: iteration 4, average log likelihood -1.410808
[ Info: iteration 5, average log likelihood -1.410718
[ Info: iteration 6, average log likelihood -1.410608
[ Info: iteration 7, average log likelihood -1.410475
[ Info: iteration 8, average log likelihood -1.410325
[ Info: iteration 9, average log likelihood -1.410166
[ Info: iteration 10, average log likelihood -1.410007
[ Info: iteration 11, average log likelihood -1.409855
[ Info: iteration 12, average log likelihood -1.409715
[ Info: iteration 13, average log likelihood -1.409589
[ Info: iteration 14, average log likelihood -1.409477
[ Info: iteration 15, average log likelihood -1.409379
[ Info: iteration 16, average log likelihood -1.409292
[ Info: iteration 17, average log likelihood -1.409215
[ Info: iteration 18, average log likelihood -1.409146
[ Info: iteration 19, average log likelihood -1.409085
[ Info: iteration 20, average log likelihood -1.409029
[ Info: iteration 21, average log likelihood -1.408979
[ Info: iteration 22, average log likelihood -1.408933
[ Info: iteration 23, average log likelihood -1.408891
[ Info: iteration 24, average log likelihood -1.408852
[ Info: iteration 25, average log likelihood -1.408816
[ Info: iteration 26, average log likelihood -1.408783
[ Info: iteration 27, average log likelihood -1.408752
[ Info: iteration 28, average log likelihood -1.408724
[ Info: iteration 29, average log likelihood -1.408697
[ Info: iteration 30, average log likelihood -1.408672
[ Info: iteration 31, average log likelihood -1.408648
[ Info: iteration 32, average log likelihood -1.408626
[ Info: iteration 33, average log likelihood -1.408605
[ Info: iteration 34, average log likelihood -1.408585
[ Info: iteration 35, average log likelihood -1.408566
[ Info: iteration 36, average log likelihood -1.408547
[ Info: iteration 37, average log likelihood -1.408530
[ Info: iteration 38, average log likelihood -1.408513
[ Info: iteration 39, average log likelihood -1.408497
[ Info: iteration 40, average log likelihood -1.408481
[ Info: iteration 41, average log likelihood -1.408466
[ Info: iteration 42, average log likelihood -1.408451
[ Info: iteration 43, average log likelihood -1.408437
[ Info: iteration 44, average log likelihood -1.408424
[ Info: iteration 45, average log likelihood -1.408410
[ Info: iteration 46, average log likelihood -1.408398
[ Info: iteration 47, average log likelihood -1.408385
[ Info: iteration 48, average log likelihood -1.408373
[ Info: iteration 49, average log likelihood -1.408361
[ Info: iteration 50, average log likelihood -1.408350
┌ Info: EM with 100000 data points 50 iterations avll -1.408350
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4110055442548097
│     -1.410941295293295
│      ⋮
└     -1.4083496064624113
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4207359906858201
│     -1.4207547421970208
│     -1.4206874208285687
│     -1.4206370651799276
│      ⋮
│     -1.4083729145626245
│     -1.4083611097563433
└     -1.4083496064624113
32×26 Array{Float64,2}:
  0.284176   -0.59537      0.0551512    0.711328     0.42717     0.570123   -0.0470919  -0.187088    -0.0263554   -0.0820958   0.248876     0.121048    -0.281775    0.151828    -0.981555   -0.663244    0.380604   -0.0323569  -0.455818    0.327667     0.173821    0.290862   -0.878981    -0.00411335   0.110763   -0.158003
  0.490358    0.0818923   -0.349922     0.276195     0.702447    0.2027      0.293882   -0.125378    -0.135642     0.215061   -0.0115471   -0.403729    -0.126387    0.556996     0.399071   -0.753894    0.0759643  -0.101279   -0.0174426   0.625305     0.322023   -0.35362     0.0106155    0.0247671   -0.23283     0.121404
  0.509992   -0.00821944  -0.230806     0.560321     0.0138849   0.555507   -0.63278    -0.00391163  -0.160577    -0.576748    0.179835    -0.35495      0.18645    -0.175317     0.129404    0.0555144  -0.318178   -0.303863   -0.313643   -0.134367     1.00659    -0.391495   -0.100045    -0.510607     0.331521   -0.246062
  0.386429    0.040003    -0.365047     0.173966    -0.111303    0.372718    0.581738   -0.0303921   -0.319487     0.112998   -0.600078     0.0225605   -0.656514   -0.0890474    0.617584    0.243827   -1.04251    -0.639172   -0.144985   -0.195232    -0.0159796  -0.208234   -0.249575    -0.133438     0.504006   -0.734197
 -0.746711   -0.798081    -0.215533    -0.199293     0.51203     0.354045    0.31346     0.353895     0.181466     0.152398    0.101087    -0.00922824   0.214426   -0.566318    -0.349521    0.231378   -0.352095    0.0523602  -0.229054   -0.291723    -0.0221017  -0.415415   -0.578501    -0.018067    -0.846866    0.0459538
  0.0782735  -0.36561      0.108271    -0.275433     0.255515   -0.104803   -0.366622    0.475871    -0.224815     0.0711792  -0.457993    -0.268194    -0.0496097  -0.461018    -0.672727   -0.0675811   0.223219    0.176451    0.327165   -0.170763     0.429494   -0.132538   -0.401098    -0.468688    -0.732305    0.757642
 -0.168546    0.019295     0.0691124   -0.208965     0.309471   -0.2685     -0.38191     0.465267     0.582911    -0.111575    0.422315    -0.256993     0.141854   -0.178666     0.392577   -0.55342    -0.388993    0.225518   -0.440577   -0.0474886    0.517513   -0.115211    0.00582741  -0.0573731   -0.567485    0.238888
 -0.756571    0.0158782    0.183446     0.133442    -0.259854   -0.0376463   0.228947    0.195318    -0.112678    -0.207457    0.313327    -0.338207     0.319241   -0.827206     0.319044    0.470118    0.300111    0.391849   -0.376151    0.358586     0.234492   -0.143094    0.321116     0.535269    -0.16424     0.0181007
  0.99432    -0.252623    -0.294367    -0.422813     0.396146   -0.0212171  -0.333817    0.0332428    0.0858063    0.346645   -0.343989     0.249257    -0.505786    0.651392    -0.183355   -0.279264   -0.44487    -0.390899    0.410556   -0.481511     0.059788    0.270109   -0.250721    -0.716855     0.238293   -0.0884327
  0.691246    0.201741    -0.175723    -0.523796     0.166455   -0.379273   -0.407002    0.0105645    0.419647    -0.381491   -0.428879    -0.0390825   -0.190116   -0.216695     0.0175687   0.068887   -0.328534   -0.972645    0.284745   -0.217937    -0.212903    0.113074    0.223909     0.26532     -0.266433   -0.328084
  0.369361    0.607583     0.390908    -0.80548     -0.770827   -0.119556   -0.0649835   0.025746    -0.0560719   -0.112486    0.428571     0.608769    -0.0578617   0.342638    -0.108317    0.362206   -0.132226   -0.0557223  -0.14694     0.356465     0.0747123   0.544506   -0.0304924   -0.161055    -0.0270891  -0.922876
 -0.0221169  -0.267443     0.124467    -0.289527     0.178326   -0.459455    0.0994351  -0.125368     0.172713     0.25777     0.495589     0.279983    -0.213644    0.32495     -0.304477   -0.272169   -0.267589    0.0157725  -0.374735    0.203337     0.0657329   0.303286   -0.116412     0.0676252   -0.3058     -0.550763
  0.132363   -0.466483     0.0837298    0.130914    -0.221843    0.19593    -0.13046    -0.133256    -0.1397      -0.179217   -0.142719    -0.125855     0.317555    0.134863    -0.11123     0.605249    0.24412     0.199582    0.503811    0.0871353   -0.332727    0.199736   -0.155959     0.11444      0.93835    -0.230558
 -0.0217266  -0.206399    -0.389048    -0.0192125   -0.554396    0.292049    0.616947   -0.425727    -0.514567    -0.0265189  -0.633292     0.39618      0.0794859  -0.232409    -0.535848    0.276059    0.412766    0.294424    0.678758    0.122733    -0.316805    0.0593519   0.162281     0.132128     0.158406    0.388137
  0.0901974   0.700493     0.135673    -0.062704    -0.0627741   0.113967   -0.0218436   0.0304719   -0.043286    -0.0825417  -0.261246     0.00990512   0.0872255   0.122338     0.648326    0.119737    0.230897    0.0336727   0.473282   -0.398826    -0.20242    -0.0217503   0.319705    -0.0906626    0.042045    0.446106
 -0.422597    0.241198    -0.0500493    0.793382    -0.203039   -0.16043    -0.128127   -0.465591     0.155133    -0.435139    0.499664    -0.124153    -0.172654    0.158474     0.297405   -0.359583   -0.0483345  -0.19427    -0.292809    0.288334    -0.379894   -0.540494    0.594248     0.774818     1.00694    -0.255604
  0.0542321  -0.0701872   -0.378815    -0.00110099   0.167551    0.296844   -0.181931   -0.0621014    0.0543558   -0.326382   -0.458884    -0.113616     0.441586   -0.116872     0.131191    0.0290439  -0.556823   -0.104145    0.182984   -0.250843     0.0772676  -0.146137    0.0256565   -0.357116    -0.0380459   0.125421
  0.326554    0.136519    -0.087524     0.1775       0.376892    0.0225134  -0.216788   -0.013956    -0.0632243    0.0653932  -0.537872    -0.450153     0.0531915  -0.319106     0.140894   -0.0732491   0.698204    0.0202702   0.0588321  -0.253173    -0.019111   -0.0160971   0.222142     0.088379    -0.17855     0.659085
  0.0162152   0.0116889   -0.0563511   -0.0168968   -0.0187392  -0.0475533   0.106      -0.121977     0.0355103    0.0658324  -0.066553     0.0586254   -0.145952    0.0145918   -0.0172008   0.0103663   0.0981579  -0.031426    0.0053659   0.0370946   -0.0169241   0.0175811   0.0650002   -0.0282817    0.0131769   0.0122531
  0.0619305  -0.114491     0.0776897   -0.00533555   0.0669281   0.0658765  -0.296992    0.373341    -0.0447534   -0.047105    0.417904    -0.115082    -0.0650944  -0.0747356    0.0200462  -0.0865895  -0.0151517   0.12151    -0.253047   -0.00227053   0.315699   -0.0254467  -0.127332     0.0474008   -0.247606    0.00887584
 -0.681572   -0.157221     0.318789    -0.109993    -0.83436    -0.0963364  -0.364986   -0.0704412   -0.061269    -0.0656282   0.189577     0.32956     -0.378587    0.00841618  -0.440919    0.586287   -0.307383    0.168927    0.170554   -0.443624    -0.198517    0.111924   -0.0902673   -0.331098     0.422597   -0.208682
 -0.0373107  -0.240196     0.306198     0.145384     0.308941   -0.0753448  -0.433767    0.0411545   -0.0857345   -0.218421   -0.0342957   -0.0712992    0.545217   -0.220793    -0.475224    0.365791    0.13764    -0.19524     0.397718   -0.0926216   -0.151901    0.237117   -0.395947    -0.0517457    0.51773    -0.545867
  0.256012   -0.0279698    0.130152    -0.0427946   -0.374979   -0.0116648  -0.184382   -0.124195     0.00702703  -0.100814    0.15375     -0.0790007   -0.224327    0.772691     0.0396776  -0.0732472   0.198031   -0.0241633   0.605859    0.19798     -0.493102   -0.129287    0.0372187    0.29973      0.576487    0.0715101
 -0.010947    0.0920285   -0.00711667  -0.566156    -0.603485   -0.280723    0.95604     0.00391958   0.0667581    0.13582     0.252451    -0.162996    -0.196086    0.229957     0.552666    0.214862    0.105284    0.129883    0.457279   -0.0457737   -0.0206231  -0.0554481   0.23193      0.0570521   -0.114146   -0.0385264
 -0.0967364  -0.478221    -0.839757    -0.176267     0.1449     -0.542945    0.0580628  -0.40516     -0.204218     0.29231    -0.105485     0.264996    -0.356207   -0.308133    -0.176434   -0.0083719  -0.38436     0.483898   -0.382156    0.207778     0.115928    0.120559    0.286242    -0.232193    -0.126014   -0.0047897
  0.457325    0.317205    -0.0667274   -0.311826    -0.365598    0.0962067  -0.320088   -0.572706    -0.0832707    0.0432617  -0.024937     0.638503    -0.889766   -0.118135     0.257085   -0.0709794   0.554377    0.355966   -0.588492   -0.252923     0.252422    0.0591808   0.163747    -0.256977    -0.290379    0.463477
  0.0249516   0.361106     0.0307198    0.424243    -0.0170901  -0.0948344   0.196936    0.331865    -0.664053     0.739047    0.0566376    0.148426    -0.122584    0.0945432    0.0876624   0.0492104   0.160589    0.379002   -0.109005   -0.0639783    0.506559    0.426337   -0.0744899   -0.272193     0.37478     0.231063
  0.396932   -0.517934    -0.301258    -0.266928     0.186569   -0.118361   -0.0979951   0.382648    -0.609095     0.237258    0.207942    -0.0975209   -0.25002    -0.136609     0.0400563  -0.0418667   0.140833    0.615475    0.092939    0.321908     0.073031    0.716984   -0.650209     0.91881      0.177187   -0.138099
 -0.261511    0.0716473    0.309237     0.362957     0.203753   -0.181914    0.220743   -0.143744     0.417204     0.138754    0.128471     0.29152      0.542092    0.442534     0.0645591  -0.11153    -0.178759    0.161081   -0.178068    0.492174    -0.135463    0.317705   -0.0894939    0.355122     0.233257   -0.475319
 -0.293326   -0.161551     0.577949    -0.258202     0.197376   -0.62481    -0.0321371   0.111793     0.546085     0.248052    0.00523671   0.318621     0.0746769   0.0108859   -0.134724    0.0368571   0.802089    0.317278    0.132554    0.0742556   -0.57305     0.364995    0.322012     0.400779    -0.0571714   0.397162
 -0.321539    0.671034     0.235547     0.358131    -0.0339302  -0.182881    0.0933176  -0.469617     0.486676    -0.0102083  -0.00981517   0.00216683   0.176737    0.17397     -0.103966   -0.407633   -0.195237   -0.694032   -0.207229   -0.249723    -0.246032   -0.189759    0.41756     -0.38746     -0.335912   -0.134988
 -0.244755    0.30517      0.650897    -0.0168824   -0.284154    1.11217    -0.185273   -0.221901     0.221961    -0.4885      0.248188    -0.0924868    0.117563    0.336283    -0.301002   -0.12475     0.394758   -0.191761    0.220848   -0.298505    -0.0366953  -0.455538    0.197267    -0.140453    -0.0526702   0.391008[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408338
[ Info: iteration 2, average log likelihood -1.408327
[ Info: iteration 3, average log likelihood -1.408317
[ Info: iteration 4, average log likelihood -1.408306
[ Info: iteration 5, average log likelihood -1.408296
[ Info: iteration 6, average log likelihood -1.408286
[ Info: iteration 7, average log likelihood -1.408276
[ Info: iteration 8, average log likelihood -1.408266
[ Info: iteration 9, average log likelihood -1.408257
[ Info: iteration 10, average log likelihood -1.408247
┌ Info: EM with 100000 data points 10 iterations avll -1.408247
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.325874e+05
      1       7.003771e+05      -2.322102e+05 |       32
      2       6.894333e+05      -1.094383e+04 |       32
      3       6.846772e+05      -4.756072e+03 |       32
      4       6.820778e+05      -2.599410e+03 |       32
      5       6.803676e+05      -1.710270e+03 |       32
      6       6.790526e+05      -1.314995e+03 |       32
      7       6.780468e+05      -1.005776e+03 |       32
      8       6.772593e+05      -7.875166e+02 |       32
      9       6.765875e+05      -6.717412e+02 |       32
     10       6.760142e+05      -5.733495e+02 |       32
     11       6.754815e+05      -5.326838e+02 |       32
     12       6.750436e+05      -4.379471e+02 |       32
     13       6.746915e+05      -3.520787e+02 |       32
     14       6.743990e+05      -2.925084e+02 |       32
     15       6.741435e+05      -2.554343e+02 |       32
     16       6.739088e+05      -2.347232e+02 |       32
     17       6.736970e+05      -2.118265e+02 |       32
     18       6.734995e+05      -1.975042e+02 |       32
     19       6.733030e+05      -1.964370e+02 |       32
     20       6.731264e+05      -1.766814e+02 |       32
     21       6.729790e+05      -1.474044e+02 |       32
     22       6.728622e+05      -1.167748e+02 |       32
     23       6.727578e+05      -1.044157e+02 |       32
     24       6.726569e+05      -1.008437e+02 |       32
     25       6.725601e+05      -9.683653e+01 |       32
     26       6.724786e+05      -8.153010e+01 |       32
     27       6.724041e+05      -7.441818e+01 |       32
     28       6.723303e+05      -7.384322e+01 |       32
     29       6.722528e+05      -7.748250e+01 |       32
     30       6.721825e+05      -7.033023e+01 |       32
     31       6.721157e+05      -6.682574e+01 |       32
     32       6.720588e+05      -5.688414e+01 |       32
     33       6.720047e+05      -5.405119e+01 |       32
     34       6.719551e+05      -4.966133e+01 |       32
     35       6.719095e+05      -4.555095e+01 |       32
     36       6.718659e+05      -4.363804e+01 |       32
     37       6.718232e+05      -4.264445e+01 |       32
     38       6.717810e+05      -4.219338e+01 |       32
     39       6.717454e+05      -3.564875e+01 |       32
     40       6.717107e+05      -3.471814e+01 |       32
     41       6.716757e+05      -3.499656e+01 |       32
     42       6.716358e+05      -3.989897e+01 |       32
     43       6.715945e+05      -4.123813e+01 |       32
     44       6.715599e+05      -3.465921e+01 |       32
     45       6.715267e+05      -3.315620e+01 |       32
     46       6.714939e+05      -3.278691e+01 |       32
     47       6.714625e+05      -3.147980e+01 |       32
     48       6.714264e+05      -3.609187e+01 |       32
     49       6.713900e+05      -3.639617e+01 |       32
     50       6.713522e+05      -3.777867e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 671352.1853615746)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420394
[ Info: iteration 2, average log likelihood -1.415372
[ Info: iteration 3, average log likelihood -1.414090
[ Info: iteration 4, average log likelihood -1.413174
[ Info: iteration 5, average log likelihood -1.412152
[ Info: iteration 6, average log likelihood -1.411087
[ Info: iteration 7, average log likelihood -1.410265
[ Info: iteration 8, average log likelihood -1.409785
[ Info: iteration 9, average log likelihood -1.409527
[ Info: iteration 10, average log likelihood -1.409371
[ Info: iteration 11, average log likelihood -1.409261
[ Info: iteration 12, average log likelihood -1.409175
[ Info: iteration 13, average log likelihood -1.409103
[ Info: iteration 14, average log likelihood -1.409041
[ Info: iteration 15, average log likelihood -1.408986
[ Info: iteration 16, average log likelihood -1.408936
[ Info: iteration 17, average log likelihood -1.408891
[ Info: iteration 18, average log likelihood -1.408850
[ Info: iteration 19, average log likelihood -1.408813
[ Info: iteration 20, average log likelihood -1.408778
[ Info: iteration 21, average log likelihood -1.408745
[ Info: iteration 22, average log likelihood -1.408714
[ Info: iteration 23, average log likelihood -1.408685
[ Info: iteration 24, average log likelihood -1.408658
[ Info: iteration 25, average log likelihood -1.408632
[ Info: iteration 26, average log likelihood -1.408607
[ Info: iteration 27, average log likelihood -1.408583
[ Info: iteration 28, average log likelihood -1.408561
[ Info: iteration 29, average log likelihood -1.408540
[ Info: iteration 30, average log likelihood -1.408519
[ Info: iteration 31, average log likelihood -1.408499
[ Info: iteration 32, average log likelihood -1.408481
[ Info: iteration 33, average log likelihood -1.408462
[ Info: iteration 34, average log likelihood -1.408445
[ Info: iteration 35, average log likelihood -1.408428
[ Info: iteration 36, average log likelihood -1.408412
[ Info: iteration 37, average log likelihood -1.408396
[ Info: iteration 38, average log likelihood -1.408380
[ Info: iteration 39, average log likelihood -1.408365
[ Info: iteration 40, average log likelihood -1.408351
[ Info: iteration 41, average log likelihood -1.408336
[ Info: iteration 42, average log likelihood -1.408322
[ Info: iteration 43, average log likelihood -1.408309
[ Info: iteration 44, average log likelihood -1.408296
[ Info: iteration 45, average log likelihood -1.408283
[ Info: iteration 46, average log likelihood -1.408271
[ Info: iteration 47, average log likelihood -1.408260
[ Info: iteration 48, average log likelihood -1.408249
[ Info: iteration 49, average log likelihood -1.408238
[ Info: iteration 50, average log likelihood -1.408228
┌ Info: EM with 100000 data points 50 iterations avll -1.408228
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.172306    0.280617    0.121041    -1.03314     -0.546547   -0.187886      0.652614     0.17963     0.203357     0.271919     0.00376971   0.188135    -0.0517585   0.293607     0.503041    0.462299    0.180204    0.326272    0.992532    -0.368229    -0.321909     -0.0153768    0.319646   -0.0951241    -0.523597    0.490359
  0.520655   -0.0978516  -0.407262     0.139665     0.532951    0.202011      0.0169491   -0.134453   -0.0373721    0.0242133   -0.537159    -0.602051     0.297609    0.168702     0.255026   -0.38892     0.41016     0.227329    0.486912     0.159698     0.000858298  -0.11071      0.0552175   0.161004      0.0158981   0.612363
 -0.0530719   0.588824   -0.396467     0.411546     0.0314587   0.409571      0.619506    -0.302869   -0.313578     0.327549    -0.368201    -0.156811    -0.166957    0.284049     0.348053   -0.293194   -0.575484   -0.448547   -0.0886007    0.0129088    0.104773     -0.569392     0.212308   -0.356784     -0.108516    0.0337732
 -1.00166    -0.120418   -0.0913876   -0.0655822   -0.400794   -0.150815      0.323741     0.203063    0.165803    -0.454467     0.481836    -0.325758     0.214162   -0.356056     0.619976    0.224953   -0.16072     0.174262   -0.226427     0.322605     0.167695     -0.459701     0.247814    0.465073     -0.154971   -0.210688
  0.755511   -0.259691   -0.417281    -0.479739     0.109812   -0.0024635    -0.0825211   -0.0513113   0.180023     0.099153    -0.273095     0.218887    -0.525307    0.516351    -0.0739937  -0.124862   -0.704617   -0.543255    0.445005    -0.440026    -0.027157      0.0644122   -0.145414   -0.475192      0.33978    -0.509964
  0.0241431  -0.557018   -0.905144    -0.253054    -0.0249169  -0.401272      0.0809421   -0.44742    -0.0657434   -0.00732685  -0.347057     0.37177     -0.256388   -0.445426    -0.48291     0.225518   -0.23687     0.585038   -0.151378     0.549908    -0.0101904     0.249014     0.132956    0.140753      0.0958013  -0.269957
 -0.255563   -0.26156     0.416047    -0.0827968    0.577305   -0.107525     -0.311124     0.0629956   0.461838    -0.220598     0.382696    -0.0605833    0.897255   -0.275924    -0.353314   -0.0721748   0.540839    0.453263   -0.174842     0.381016    -0.175704      0.282527     0.365935    0.346166     -0.179535    0.207025
 -0.226192    0.213603    0.150266     0.270008     0.323435   -0.731933     -0.377315     0.158911    0.0186316    0.276736    -0.691596     0.168571     0.162216   -0.0337865   -0.150318    0.49498     0.215879   -0.286482    0.452751    -0.2697       0.00779421    0.77449      0.133953   -0.134991      0.305569    0.660343
 -0.0256265  -0.0504024  -0.0269367    0.0678376   -0.184403    0.400879      0.244008     0.0180405  -0.537796     0.0697281   -0.42062      0.0908807    0.0999863  -0.16445     -0.150504    0.303026    0.490337    0.477812    0.298399    -0.190557    -0.10978       0.215508    -0.0220103  -0.0552514     0.105609    0.331521
 -0.0523132  -0.0205447  -0.0723931   -0.0105971    0.0765847   0.0643117    -0.112463    -0.0200642   0.0117494   -0.0683393   -0.184691     0.0201844    0.0197172  -0.0955573   -0.0871447   0.0667095  -0.019446   -0.0913374   0.0329513   -0.145175     0.0206802    -0.0436823   -0.0154788  -0.222251     -0.0776615   0.073465
  0.33942     0.490279    0.0593697   -0.192634    -0.396776    0.182856     -0.401972    -0.865402    0.0138179   -0.0322593   -0.13453      0.738204    -0.780176    0.00137207   0.196128   -0.110263    0.519387    0.190192   -0.476692    -0.41033      0.285435      0.00298186   0.250908   -0.724102     -0.310601    0.555889
  0.108992   -0.164444    0.00499546  -0.411479     0.355394   -0.348449     -0.519145     0.448983    0.203546     0.0254976    0.0849308   -0.103448    -0.0542344  -0.230211    -0.0968748  -0.24765    -0.291752    0.0549588   0.00490557  -0.173736     0.487411     -0.020903    -0.209179   -0.285139     -0.592686    0.136077
  0.146759   -0.254213    0.219413    -0.0977547   -0.20301     0.000405133  -0.118118    -0.0829061  -0.526693    -0.00399194   0.00685042  -0.00102935   0.217936    0.180222    -0.19919     0.567716    0.234698   -0.0787129   0.646203     0.0574612   -0.490105      0.561889    -0.599499    0.1763        0.860754   -0.621328
 -0.412048    0.249379    0.414769    -0.0118195    0.0148455  -0.215498      0.352057    -0.0983298   0.601336     0.306472     0.239871     0.575281     0.527402    0.699093    -0.0660932   0.0451015  -0.185258    0.0458931  -0.17095      0.504832    -0.181857      0.389328     0.13823     0.0913531     0.148628   -0.679375
  0.771249   -0.0338927  -0.116882     0.272493     0.507528    0.199105      0.193028     0.13793     0.258836    -0.380301    -0.666781     0.114813     0.189239   -0.198492     0.481919    0.464981   -0.629057   -0.650052   -0.390468     0.540793     0.344332      0.0868599   -0.538593   -0.25593      -0.0453773  -0.512876
  1.03833     0.18326    -0.240918    -0.186835     0.115206   -0.0623591    -0.414755     0.299862   -0.290265    -0.131314    -0.884767    -0.359527    -0.41669    -0.572911     0.30514     0.184668   -0.0408757  -0.703286    0.130384    -0.609514    -0.102767     -0.317697     0.33281     0.160548     -0.295378    0.137508
  0.399883   -0.240961    0.0204076    0.154397     0.329961   -0.223267      0.30971     -0.325166   -0.131681     0.32279      0.465863    -0.0100402   -0.620407    0.576114    -0.37081    -0.900998    0.0553698   0.0228246  -0.414558     0.55568      0.161112      0.209441    -0.388237    0.201127     -0.200327   -0.223269
 -0.794583   -0.883637   -0.237991    -0.0992584    0.540607    0.293575      0.289083     0.271549    0.154123     0.230389     0.0152236   -0.00566663   0.285519   -0.598485    -0.384623    0.241836   -0.257764    0.0900002  -0.135992    -0.256394    -0.07462      -0.328919    -0.537628    0.000347005  -0.724235    0.100586
 -0.211177   -0.196887   -0.21426     -0.21088     -0.453449    0.356098     -0.103674    -0.4961     -0.192672    -0.116087     0.0622522    0.184341    -0.235022    0.378282    -0.293843    0.0894009   0.235978    0.134264    0.475633    -0.356629    -0.611006     -0.201858     0.380814    0.0381995     0.468014    0.305161
 -0.543739   -0.0225744   0.544659    -0.223124    -0.862256   -0.260568     -0.284988     0.0588232  -0.00826474  -0.11813      0.278076     0.382707    -0.369025   -0.118569    -0.404452    0.512341   -0.472836    0.123342   -0.130955    -0.347834     0.00780899    0.243368    -0.310492   -0.298735      0.139417   -0.424912
  0.587831    0.711163    0.250297    -0.0993836   -0.442206   -0.429461     -0.0586334   -0.367037    0.204229    -0.263745     0.197146     0.230552    -0.651799    0.569063     0.628963   -0.0411128   0.161651   -0.398287    0.404389     0.44227     -0.383362      0.225727     0.685199    0.255791      0.79669    -0.114508
 -0.663066    0.215639    0.578801     0.623818    -0.251103   -0.090138      0.156491     0.0714849  -0.192749     0.403002     0.214293    -0.126814    -0.0702745  -0.128378     0.151       0.0219089   0.652249    0.510469   -0.0669736    0.0549886   -0.090247     -0.123713     0.105929    0.295312      0.264651    0.509216
  0.207315    0.0743578  -0.241076    -0.00318126   0.0384548  -0.212648      0.191334     0.367154   -0.491253     0.76788      0.179264     0.0139073   -0.261209   -0.0770429    0.29877     0.0435099  -0.0270172   0.544801   -0.366196    -0.117836     0.508371      0.625199    -0.126276   -0.0419793     0.200685   -0.0656639
 -0.0331195   0.456977    0.0888764    0.580896    -0.743817    0.580003     -0.386363    -0.076303    0.107931    -0.704933    -0.117378    -0.104283     0.713277   -0.161126    -0.0311457   0.320624   -0.146439    0.276373    0.250902    -0.225145     0.358447     -0.154505     0.477443   -0.0854207     0.456624   -0.182915
 -0.107972    0.0950624   0.491019     0.0341746    0.0411222   0.351022     -0.237249    -0.0303609   0.494114    -0.516322    -0.064264    -0.0775412    0.290879    0.402883    -0.271312   -0.122714    0.127835   -0.578412    0.828761     0.188581    -0.0673397    -0.772934    -0.177254   -0.217097     -0.0606277   0.176274
  0.110586   -0.0813418   0.124029     0.0146875   -0.0420532  -0.181149      0.119974     0.0106957   0.0878942    0.0786786    0.214621    -0.0233887   -0.0192999   0.284581     0.094466   -0.138252    0.0597039   0.0878377   0.0802251    0.289326    -0.128876      0.136044    -0.0800548   0.318689      0.173904   -0.149836
 -0.018639   -0.0111501  -0.192382    -0.0651814    0.308535   -0.0310401    -0.155466     0.331478    0.246474    -0.00493942   0.0799333   -0.198859    -0.125012   -0.233558     0.202979   -0.528135   -0.212389    0.355367   -0.498297     0.00625738   0.633375     -0.329243     0.127295   -0.201426     -0.718406    0.549367
  0.378957    0.198011   -0.138989    -0.322253    -0.0310563  -0.0269224    -0.259705    -0.0525074  -0.0221258   -0.300577     0.500718    -0.2604       0.328767   -0.369888     0.235355    0.375481   -0.126319   -0.352654   -0.240875    -0.194337     0.609972      0.321258     0.253202   -0.0733595    -0.264985   -0.266961
  0.22799    -0.154812    0.436735    -0.580274    -0.172813   -0.435546     -0.00937226   0.352286    0.0504585    0.388065     0.257237     0.275188    -0.77082    -0.186964     0.0961599   0.107252    0.763719    0.221288   -0.179756     0.0857519   -0.198239      0.00045658   0.122009    0.459555     -0.374485    0.156059
  0.355918   -0.244498   -0.0863639    0.619332     0.385574    0.607306     -0.58109      0.178555   -0.422527    -0.264624     0.271451    -0.0659201   -0.0751399   0.0554965   -0.317324   -0.319209   -0.0389476  -0.0323776  -0.267359    -0.0842146    0.509553     -0.0415541   -0.497116   -0.214487      0.240564   -0.0702927
 -0.103917    0.546252    0.3905       0.0520744    0.078087   -0.0641107    -0.209681    -0.279834    0.735643    -0.347829     0.107014    -0.445481     0.329116   -0.0492114    0.119077   -0.72645    -0.0551648  -0.604158   -0.499564    -0.787962    -0.41283       0.284615     0.153884    0.104036     -0.421252   -0.257747
 -0.24572    -0.059149   -0.29766      0.464083    -0.196266    0.0910243    -0.119965    -0.429298   -0.00134004  -0.384491     0.310774    -0.266026    -0.0783116  -0.0711205    0.216225   -0.055123   -0.30549    -0.272154   -0.349861     0.0819751   -0.104257     -0.753759     0.484372    0.235831      0.823161   -0.278917[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408218
[ Info: iteration 2, average log likelihood -1.408209
[ Info: iteration 3, average log likelihood -1.408201
[ Info: iteration 4, average log likelihood -1.408192
[ Info: iteration 5, average log likelihood -1.408184
[ Info: iteration 6, average log likelihood -1.408177
[ Info: iteration 7, average log likelihood -1.408169
[ Info: iteration 8, average log likelihood -1.408162
[ Info: iteration 9, average log likelihood -1.408155
[ Info: iteration 10, average log likelihood -1.408148
┌ Info: EM with 100000 data points 10 iterations avll -1.408148
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
