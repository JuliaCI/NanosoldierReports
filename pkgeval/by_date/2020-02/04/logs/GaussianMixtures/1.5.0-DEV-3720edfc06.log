Julia Version 1.5.0-DEV.230
Commit 3720edfc06 (2020-02-03 20:02 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed Missings ─────────── v0.4.3
  Installed GaussianMixtures ─── v0.3.0
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed CMakeWrapper ─────── v0.2.3
  Installed JLD ──────────────── v0.9.2
  Installed NearestNeighbors ─── v0.4.4
  Installed SpecialFunctions ─── v0.9.0
  Installed Distances ────────── v0.8.2
  Installed Rmath ────────────── v0.6.0
  Installed Arpack_jll ───────── v3.5.0+2
  Installed StatsFuns ────────── v0.9.3
  Installed BinDeps ──────────── v1.0.0
  Installed StatsBase ────────── v0.32.0
  Installed BinaryProvider ───── v0.5.8
  Installed HDF5 ─────────────── v0.12.5
  Installed FileIO ───────────── v1.2.1
  Installed Blosc ────────────── v0.5.1
  Installed LegacyStrings ────── v0.4.1
  Installed OrderedCollections ─ v1.1.0
  Installed PDMats ───────────── v0.9.11
  Installed DataAPI ──────────── v1.1.0
  Installed DataStructures ───── v0.17.9
  Installed StaticArrays ─────── v0.12.1
  Installed Clustering ───────── v0.13.3
  Installed Compat ───────────── v2.2.0
  Installed QuadGK ───────────── v2.3.1
  Installed Parameters ───────── v0.12.0
  Installed CMake ────────────── v1.1.2
  Installed ScikitLearnBase ──── v0.5.0
  Installed URIParser ────────── v0.4.0
  Installed Arpack ───────────── v0.4.0
  Installed SortingAlgorithms ── v0.3.1
  Installed FillArrays ───────── v0.8.4
  Installed Distributions ────── v0.22.4
#=#=#                                                                         ###################################                                       49.6%######################################################################## 100.0%
#=#=#                                                                         #                                                                          1.9%####                                                                       5.8%#######                                                                   11.0%############                                                              17.7%##################                                                        25.4%##########################                                                36.4%###########################                                               37.6%#####################################                                     51.6%################################################                          67.5%################################################################          89.6%######################################################################## 100.0%
#=#=#                                                                         #######                                                                   10.8%######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_w7GLSk/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -4.143452162446067e6, [99784.7636837887, 215.23631621128283], [-108.42460416069305 -1084.7648299573582 -968.8673294430497; 91.71562931633648 528.4688734281633 400.6936063882044], [[100270.0676527927 -131.68335862058132 -236.37213477443547; -131.68335862058132 98778.00679909732 -953.7740637628332; -236.37213477443547 -953.7740637628332 99860.37094196827], [310.8599031196944 198.76078326020487 111.04591103262746; 198.76078326020487 1389.7207654704737 884.795348294215; 111.04591103262747 884.795348294215 909.3021978476468]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.339416e+03
      1       8.780964e+02      -4.613198e+02 |        6
      2       8.093954e+02      -6.870099e+01 |        2
      3       8.065897e+02      -2.805673e+00 |        0
      4       8.065897e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 806.5897107667392)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.058432
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.765080
[ Info: iteration 2, lowerbound -3.622619
[ Info: iteration 3, lowerbound -3.477987
[ Info: iteration 4, lowerbound -3.330461
[ Info: iteration 5, lowerbound -3.204179
[ Info: iteration 6, lowerbound -3.121762
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -3.086530
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -3.071250
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -3.052053
[ Info: iteration 10, lowerbound -3.037556
[ Info: iteration 11, lowerbound -3.021793
[ Info: iteration 12, lowerbound -2.999417
[ Info: iteration 13, lowerbound -2.968421
[ Info: iteration 14, lowerbound -2.926589
[ Info: iteration 15, lowerbound -2.871640
[ Info: iteration 16, lowerbound -2.801719
[ Info: iteration 17, lowerbound -2.716956
[ Info: iteration 18, lowerbound -2.622586
[ Info: iteration 19, lowerbound -2.530897
[ Info: iteration 20, lowerbound -2.454787
[ Info: iteration 21, lowerbound -2.398687
[ Info: iteration 22, lowerbound -2.361992
[ Info: dropping number of Gaussions to 3
[ Info: iteration 23, lowerbound -2.331832
[ Info: iteration 24, lowerbound -2.311239
[ Info: iteration 25, lowerbound -2.307862
[ Info: dropping number of Gaussions to 2
[ Info: iteration 26, lowerbound -2.302917
[ Info: iteration 27, lowerbound -2.299260
[ Info: iteration 28, lowerbound -2.299256
[ Info: iteration 29, lowerbound -2.299254
[ Info: iteration 30, lowerbound -2.299254
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Wed Feb  5 00:47:16 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Wed Feb  5 00:47:24 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Wed Feb  5 00:47:27 2020: EM with 272 data points 0 iterations avll -2.058432
5.8 data points per parameter
, Wed Feb  5 00:47:29 2020: GMM converted to Variational GMM
, Wed Feb  5 00:47:38 2020: iteration 1, lowerbound -3.765080
, Wed Feb  5 00:47:38 2020: iteration 2, lowerbound -3.622619
, Wed Feb  5 00:47:38 2020: iteration 3, lowerbound -3.477987
, Wed Feb  5 00:47:38 2020: iteration 4, lowerbound -3.330461
, Wed Feb  5 00:47:38 2020: iteration 5, lowerbound -3.204179
, Wed Feb  5 00:47:38 2020: iteration 6, lowerbound -3.121762
, Wed Feb  5 00:47:38 2020: dropping number of Gaussions to 7
, Wed Feb  5 00:47:38 2020: iteration 7, lowerbound -3.086530
, Wed Feb  5 00:47:38 2020: dropping number of Gaussions to 5
, Wed Feb  5 00:47:38 2020: iteration 8, lowerbound -3.071250
, Wed Feb  5 00:47:38 2020: dropping number of Gaussions to 4
, Wed Feb  5 00:47:38 2020: iteration 9, lowerbound -3.052053
, Wed Feb  5 00:47:38 2020: iteration 10, lowerbound -3.037556
, Wed Feb  5 00:47:38 2020: iteration 11, lowerbound -3.021793
, Wed Feb  5 00:47:38 2020: iteration 12, lowerbound -2.999417
, Wed Feb  5 00:47:38 2020: iteration 13, lowerbound -2.968421
, Wed Feb  5 00:47:38 2020: iteration 14, lowerbound -2.926589
, Wed Feb  5 00:47:38 2020: iteration 15, lowerbound -2.871640
, Wed Feb  5 00:47:38 2020: iteration 16, lowerbound -2.801719
, Wed Feb  5 00:47:38 2020: iteration 17, lowerbound -2.716956
, Wed Feb  5 00:47:38 2020: iteration 18, lowerbound -2.622586
, Wed Feb  5 00:47:38 2020: iteration 19, lowerbound -2.530897
, Wed Feb  5 00:47:38 2020: iteration 20, lowerbound -2.454787
, Wed Feb  5 00:47:38 2020: iteration 21, lowerbound -2.398687
, Wed Feb  5 00:47:38 2020: iteration 22, lowerbound -2.361992
, Wed Feb  5 00:47:38 2020: dropping number of Gaussions to 3
, Wed Feb  5 00:47:38 2020: iteration 23, lowerbound -2.331832
, Wed Feb  5 00:47:38 2020: iteration 24, lowerbound -2.311239
, Wed Feb  5 00:47:38 2020: iteration 25, lowerbound -2.307862
, Wed Feb  5 00:47:38 2020: dropping number of Gaussions to 2
, Wed Feb  5 00:47:38 2020: iteration 26, lowerbound -2.302917
, Wed Feb  5 00:47:38 2020: iteration 27, lowerbound -2.299260
, Wed Feb  5 00:47:38 2020: iteration 28, lowerbound -2.299256
, Wed Feb  5 00:47:38 2020: iteration 29, lowerbound -2.299254
, Wed Feb  5 00:47:38 2020: iteration 30, lowerbound -2.299254
, Wed Feb  5 00:47:38 2020: iteration 31, lowerbound -2.299253
, Wed Feb  5 00:47:38 2020: iteration 32, lowerbound -2.299253
, Wed Feb  5 00:47:38 2020: iteration 33, lowerbound -2.299253
, Wed Feb  5 00:47:38 2020: iteration 34, lowerbound -2.299253
, Wed Feb  5 00:47:38 2020: iteration 35, lowerbound -2.299253
, Wed Feb  5 00:47:38 2020: iteration 36, lowerbound -2.299253
, Wed Feb  5 00:47:38 2020: iteration 37, lowerbound -2.299253
, Wed Feb  5 00:47:38 2020: iteration 38, lowerbound -2.299253
, Wed Feb  5 00:47:38 2020: iteration 39, lowerbound -2.299253
, Wed Feb  5 00:47:38 2020: iteration 40, lowerbound -2.299253
, Wed Feb  5 00:47:38 2020: iteration 41, lowerbound -2.299253
, Wed Feb  5 00:47:38 2020: iteration 42, lowerbound -2.299253
, Wed Feb  5 00:47:38 2020: iteration 43, lowerbound -2.299253
, Wed Feb  5 00:47:38 2020: iteration 44, lowerbound -2.299253
, Wed Feb  5 00:47:38 2020: iteration 45, lowerbound -2.299253
, Wed Feb  5 00:47:38 2020: iteration 46, lowerbound -2.299253
, Wed Feb  5 00:47:38 2020: iteration 47, lowerbound -2.299253
, Wed Feb  5 00:47:38 2020: iteration 48, lowerbound -2.299253
, Wed Feb  5 00:47:38 2020: iteration 49, lowerbound -2.299253
, Wed Feb  5 00:47:38 2020: iteration 50, lowerbound -2.299253
, Wed Feb  5 00:47:38 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222607922, 95.95490777392088]
β = [178.04509222607922, 95.95490777392088]
m = [4.250300733269379 79.28686694435399; 2.0002292577748215 53.85198717245844]
ν = [180.04509222607922, 97.95490777392088]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547477566 -0.007644049042334176; 0.0 0.008581705166323396], [0.37587636119574686 -0.008953123827356784; 0.0 0.01274866477741211]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999997
avll from stats: -1.0249090687618623
avll from llpg:  -1.0249090687618623
avll direct:     -1.0249090687618623
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -0.9777600201195439
avll from llpg:  -0.9777600201195442
avll direct:     -0.9777600201195443
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
 -0.00786318  -0.0667008     0.155548    -0.139443     -0.120345    0.0341627    0.114102    -0.109347    -0.001912     -0.00859611   0.0162844     0.0623912   -0.19224      0.0122417    -0.146282    -0.178652    -0.112811   -0.129151     0.113152    -0.122085    -0.138628    -0.140033     0.00432352   0.0109527   0.118966     -0.026386
 -0.125906     0.138991      0.114289     0.0816251     0.105799    0.122075     0.0118731    0.062058     0.162057      0.0346388   -0.0794132    -0.053621    -0.0520146   -0.19165      -0.0228304   -0.0184695   -0.11828    -0.103797     0.2217      -0.0378102    0.115583    -0.0181337    0.121286     0.0688337  -0.0288899     0.0406318
  0.00767043  -0.118385     -0.136365    -0.0540435     0.0509346   0.11085     -0.0245466   -0.127989     0.154412     -0.0628166   -0.0300964    -0.0809801   -0.0144552    0.000486388   0.0454307    0.0964929   -0.068949   -0.0210938    0.0790981    0.0869739   -0.0956073    0.0525506    0.177631    -0.0707416   0.000836511  -0.0645918
 -0.00651429  -0.0572881    -0.00738793  -0.00421874   -0.0287159   0.222547     0.00500799   0.0723489   -0.163013     -0.14378     -0.129832      0.0624379   -0.0209229    0.318265      0.053553     0.0887514   -0.0848805   0.0525858   -0.0315601    0.240921    -0.0805024    0.0306871    0.241647     0.0923469   0.187229      0.0954817
 -0.056427     0.27838      -0.0350078   -0.196517      0.0655361   0.0239064    0.147807     0.0907684   -0.105578      0.0639115   -0.0631588     0.114645     0.0882812   -0.0705369    -0.273596     0.0936248    0.0155732  -0.0358462    0.00104798   0.0838484   -0.0276227   -0.140507     0.113733     0.114555   -0.0312501    -0.058925
  0.155426    -0.149677     -0.0337835   -0.0297798     0.160782    0.0511793   -0.106246     0.152978    -0.146424     -0.0144853    0.126388     -0.0357154    0.0755104    0.0623893     0.0362554   -0.00911443  -0.225588    0.0443264   -0.0631246    0.106669    -0.0470859   -0.180997     0.0746083    0.162802   -0.0219976    -0.0769392
  0.0247427    0.127206      0.0943432    0.0267813    -0.0352163   0.0487309   -0.0937872   -0.00767566  -0.00313336   -0.125435    -0.122927     -0.200312     0.0320347   -0.107448      0.13158      0.230087    -0.0526027  -0.0496566   -0.0170994    0.2677       0.0551446    0.113185     0.0414394    0.144916   -0.0274249     0.0155644
  0.0803148   -0.0761091     0.0113343    0.179073     -0.0355813   0.10225      0.0369052    0.187693    -0.0210812     0.0286046   -0.000741517   0.077897     0.0128501    0.102501     -0.0251707   -0.0577158    0.0867109   0.14033     -0.0122358    0.0492956    0.0150312   -0.0923915   -0.126193     0.138296   -0.0688551     0.0476245
  0.030774     0.09089       0.00854876   0.0314471    -0.0951652   0.250883    -0.049247    -0.0910813   -0.135784     -0.0176344    0.00254266   -0.00376853  -0.0166808    0.00630041   -0.00625427   0.0001983    0.11976     0.193568    -0.121137     0.0777892   -0.0670625    0.0342876   -0.015888    -0.177571   -0.153817     -0.0889541
 -0.0515747    0.0793413     0.0113156   -0.0753153    -0.208227   -0.147009     0.0635533    0.0475477    0.133217      0.0230618   -0.0164207    -0.0782052    0.0742674   -0.0663983     0.0190236   -0.129106    -0.12898    -0.253977     0.162699    -0.143231     0.170664     0.0593191    0.00768567   0.113484    0.111416     -0.0663215
  0.0735693    0.159444      0.0396073   -0.0258842     0.0288885   0.0553615    0.0115251   -0.203031    -0.0309294    -0.0997609    0.0861493     0.0326039    0.00459823  -0.15095       0.0234248    0.0624488   -0.0289047  -0.110506    -0.0925994    0.0142641    0.0041543   -0.248962     0.0342364   -0.064128    0.0178875     0.0583489
  0.073774     0.0110786     0.092066     0.0100741     0.0371228  -0.165933    -0.0778284    0.0121907   -0.00861875   -0.205055     0.0527538    -0.0411763    0.0906851   -0.0842673     0.0631861    0.18602     -0.142537    0.10683     -0.0309334   -0.105076    -0.00313938   0.0765052    0.137826     0.0416644  -0.059505     -0.0815304
  0.0551729    0.0983889     0.0393586    0.126522     -0.0436781  -0.0671271   -0.0785188   -0.0706748   -0.109304      0.100591     0.0566455    -0.023725    -0.153494    -0.0211037    -0.117759    -0.173728     0.115085   -0.0284436   -0.0939585   -0.00287117  -0.0573297    0.117949     0.191855     0.0910641   0.0351066     0.0686993
  0.131763     0.122993     -0.0783975   -0.0977011    -0.231155   -0.0303627    0.130267     0.0625262    0.0853967    -0.0473446    0.080237      0.00147238   0.078521    -0.156865      0.0293981    0.022834    -0.0579953   0.0102701    0.0931694    0.160389    -0.072744     0.00267308   0.0405361   -0.144222   -0.113784     -0.0305408
  0.0899263   -0.0282041    -0.13754      0.00417509    0.016349   -0.0197597    0.00806806   0.0110771    0.0146787    -0.169313    -0.0753147     0.0499188    0.0592827    0.0073622    -0.100973     0.0662347   -0.018399   -0.00813199  -0.0610259   -0.0380279    0.0160144    0.236167    -0.0373036    0.0697215  -0.0961398    -0.0931239
  0.0499062    0.0456842     0.121073     0.151747     -0.0942224  -0.178772     0.0303051    0.14432     -0.00644359   -0.177847    -0.0273313    -0.0919073   -0.0041996   -0.165933     -0.212832    -0.112044     0.0399962   0.0895236   -0.00902096   0.101124     0.00228787  -0.244836    -0.0111674    0.0775064   0.18423      -0.0613601
 -0.0372636    0.0167797     0.141645    -0.0676706    -0.0921892   0.106503    -0.189694    -0.0247972    0.139997      0.0562522    0.0572948     0.0605748   -0.0172355    0.0115354     0.0395309   -0.0435877    0.085238    0.0582933   -0.0928907    0.0242158   -0.0875232    0.0461696    0.0368599    0.0257723   0.0326926    -0.0788635
  0.0308881    0.0817131     0.0451118   -0.0879894    -0.024061    0.0528296    0.0217074   -0.0736275    0.033248     -0.0752711    0.0718713     0.0617019    0.008203    -0.104454     -0.00513779   0.076997    -0.0520882   0.107648    -0.0244354    0.0364715    0.0977928    0.00570445   0.0721367    0.0750856   0.11767       0.0243131
  0.00192929  -0.180157      0.125082     0.050964     -0.031197    0.0605362    0.0739288    0.14071      0.103759      0.0638313    0.138012     -0.100179     0.0896283   -0.0279298    -0.0559235   -0.00268316  -0.120666   -0.0389677    0.108601     0.146788     0.11224      0.105421    -0.0594434   -0.0401824  -0.0281185    -0.0403825
 -0.0571023   -0.123357      0.07223     -0.229805      0.0645575   0.0999575   -0.0328333    0.0822341    0.044204      0.0582361    0.12785      -0.0602167    0.135216     0.0191482    -0.00528444  -0.103652     0.0793131   0.0486553    0.00846242  -0.11119     -0.0134136   -0.0284362   -0.0350769   -0.0964813   0.021802      0.0543315
  0.0071921    0.0127215    -0.180612     0.000561039   0.0619431   0.0826471   -0.12088      0.0670035   -0.0675004    -0.183487    -0.0867474    -0.0355596    0.0231001   -0.0154252    -0.0118601    0.188616     0.0770949   0.030525     0.0670911    0.020686     0.156068    -0.0326989    0.227685    -0.0359393  -0.0827054    -0.112777
  0.208819    -0.0307805     0.0386078    0.0197959     0.173022   -0.0261756   -0.0937393   -0.0152088    0.133234      0.0622857    0.159925      0.0199034    0.055493    -0.0659425    -0.0924594    0.0352933   -0.166549    0.0834925    0.111483     0.0453355    0.00991042   0.146358    -0.0778356   -0.0493289  -0.161591     -0.1222
 -0.0558581    0.104318     -0.0505086   -0.135259     -0.0770301   0.0491878    0.0514973    0.0996311    0.0786714    -0.00974368   0.104433      0.0574327   -0.111081     0.0616875     0.11872     -0.019664    -0.040934   -0.271248    -0.0537102   -0.0254889    0.143834    -0.174588     0.0410943    0.123856    0.0278098    -0.0629544
 -0.0863914   -0.146752      0.154991     0.0399622     0.0592964  -0.150119     0.100019     0.151605     0.177773     -0.0937722    0.0298371     0.134221    -0.00639769   0.0762355    -0.0708628    0.0741816   -0.0749143  -0.09561      0.0231884   -0.071078     0.0948069   -0.0758087    0.0858239    0.128622   -0.228894      0.0526688
 -0.109063    -0.0511878    -0.00514502   0.0914874    -0.072117    0.0554028    0.146608    -0.114981    -0.131795     -0.0924208    0.102016     -0.105881     0.0112727    0.118807      0.0168785    0.118326    -0.0458573  -0.0220236    0.0212894   -0.0514024   -0.159736     0.225744    -0.094391     0.0405187  -0.0442874    -0.129919
  0.0115219   -0.000675033   0.185281    -0.0275273     0.0436718   0.00850654  -0.0674563   -0.0568058    0.0121472    -0.0683342    0.013357     -0.0869578   -0.177854    -0.00690494    0.214811     0.0935837   -0.0238878   0.239125     0.0867855    0.0576294   -0.0803381    0.00481316  -0.0556663    0.0593098   0.0724126    -0.0817468
  0.0561746   -0.153921      0.0560865    0.0385669    -0.0922264   0.09393     -0.172454     0.0275077    0.142834      0.0451673   -0.0608562     0.0054717   -0.137858     0.113187      0.00398186   0.126853     0.0846582  -0.113877    -0.0542077   -0.0999726   -0.0380602   -0.14305      0.108742     0.0721591   0.183414      0.0630241
 -0.169258     0.0367695     0.0501287   -0.0290484     0.128688   -0.220133    -0.0703325   -0.181438    -0.0280835     0.114136     0.0454798    -0.154004     0.0647004    0.0380238    -0.0782198    0.086137     0.0724167   0.012167    -0.0176395    0.0706764    0.0139296   -0.0278892    0.0697142    0.0455011  -0.216343     -0.141893
 -0.173783    -0.0998785    -0.211748    -0.0700614    -0.0687235   0.0366656    0.0888443    0.0330902   -0.000372239   0.27605      0.19186       0.0729931   -0.170149    -0.23136       0.0480254    0.0703617   -0.0457302  -0.0461514   -0.197304     0.233191     0.0210712   -0.043822     0.183003    -0.0408801   0.0340341    -0.0583662
 -0.038962     0.04837       0.0455764   -0.152476      0.131353   -0.0454646   -0.201666     0.0232676    0.0668861    -0.153956     0.106869     -0.21505     -0.0316651    0.117861     -0.0940757    0.205451     0.160813   -0.0681932   -0.145788    -0.0193532    0.0868228   -0.0820663    0.0310897   -0.0699951   0.0592586    -0.0267231
  0.140473     0.106174     -0.0550086    0.0520955    -0.067943   -0.334855    -0.0673784   -0.0277546   -0.178447      0.0160123   -0.0604547    -0.0160588    0.102236    -0.0989569     0.261824    -0.182911     0.0614203   0.0525239   -0.0877227   -0.105212    -0.0247869    0.0162413    0.198413    -0.154364   -0.0192664    -0.0445893
  0.0290288   -0.0342598    -0.0341825   -0.054754      0.0318975   0.0609427    0.0964338    0.125187     0.0173672    -0.0167105   -0.077576     -0.0239954    0.128933    -0.00338752    0.038682    -0.229804    -0.0294365  -0.00943804   0.0824192   -0.0527684    0.0424382    0.0251672    0.0618569   -0.0888122   0.0855115     0.0900842kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4352815874194012
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.435341
[ Info: iteration 2, average log likelihood -1.435271
[ Info: iteration 3, average log likelihood -1.434741
[ Info: iteration 4, average log likelihood -1.428504
[ Info: iteration 5, average log likelihood -1.410784
[ Info: iteration 6, average log likelihood -1.401376
[ Info: iteration 7, average log likelihood -1.398468
[ Info: iteration 8, average log likelihood -1.396647
[ Info: iteration 9, average log likelihood -1.395519
[ Info: iteration 10, average log likelihood -1.394882
[ Info: iteration 11, average log likelihood -1.394543
[ Info: iteration 12, average log likelihood -1.394375
[ Info: iteration 13, average log likelihood -1.394286
[ Info: iteration 14, average log likelihood -1.394233
[ Info: iteration 15, average log likelihood -1.394198
[ Info: iteration 16, average log likelihood -1.394172
[ Info: iteration 17, average log likelihood -1.394151
[ Info: iteration 18, average log likelihood -1.394133
[ Info: iteration 19, average log likelihood -1.394117
[ Info: iteration 20, average log likelihood -1.394104
[ Info: iteration 21, average log likelihood -1.394092
[ Info: iteration 22, average log likelihood -1.394083
[ Info: iteration 23, average log likelihood -1.394074
[ Info: iteration 24, average log likelihood -1.394065
[ Info: iteration 25, average log likelihood -1.394057
[ Info: iteration 26, average log likelihood -1.394048
[ Info: iteration 27, average log likelihood -1.394040
[ Info: iteration 28, average log likelihood -1.394030
[ Info: iteration 29, average log likelihood -1.394021
[ Info: iteration 30, average log likelihood -1.394011
[ Info: iteration 31, average log likelihood -1.393999
[ Info: iteration 32, average log likelihood -1.393987
[ Info: iteration 33, average log likelihood -1.393975
[ Info: iteration 34, average log likelihood -1.393961
[ Info: iteration 35, average log likelihood -1.393948
[ Info: iteration 36, average log likelihood -1.393933
[ Info: iteration 37, average log likelihood -1.393918
[ Info: iteration 38, average log likelihood -1.393902
[ Info: iteration 39, average log likelihood -1.393886
[ Info: iteration 40, average log likelihood -1.393869
[ Info: iteration 41, average log likelihood -1.393853
[ Info: iteration 42, average log likelihood -1.393838
[ Info: iteration 43, average log likelihood -1.393825
[ Info: iteration 44, average log likelihood -1.393814
[ Info: iteration 45, average log likelihood -1.393804
[ Info: iteration 46, average log likelihood -1.393796
[ Info: iteration 47, average log likelihood -1.393789
[ Info: iteration 48, average log likelihood -1.393783
[ Info: iteration 49, average log likelihood -1.393779
[ Info: iteration 50, average log likelihood -1.393774
┌ Info: EM with 100000 data points 50 iterations avll -1.393774
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.435341148075847
│     -1.4352712008255297
│      ⋮
└     -1.393774432376279
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.393904
[ Info: iteration 2, average log likelihood -1.393754
[ Info: iteration 3, average log likelihood -1.392974
[ Info: iteration 4, average log likelihood -1.386647
[ Info: iteration 5, average log likelihood -1.371548
[ Info: iteration 6, average log likelihood -1.363347
[ Info: iteration 7, average log likelihood -1.360747
[ Info: iteration 8, average log likelihood -1.359307
[ Info: iteration 9, average log likelihood -1.358305
[ Info: iteration 10, average log likelihood -1.357593
[ Info: iteration 11, average log likelihood -1.357103
[ Info: iteration 12, average log likelihood -1.356780
[ Info: iteration 13, average log likelihood -1.356575
[ Info: iteration 14, average log likelihood -1.356442
[ Info: iteration 15, average log likelihood -1.356349
[ Info: iteration 16, average log likelihood -1.356279
[ Info: iteration 17, average log likelihood -1.356218
[ Info: iteration 18, average log likelihood -1.356159
[ Info: iteration 19, average log likelihood -1.356093
[ Info: iteration 20, average log likelihood -1.356012
[ Info: iteration 21, average log likelihood -1.355912
[ Info: iteration 22, average log likelihood -1.355792
[ Info: iteration 23, average log likelihood -1.355655
[ Info: iteration 24, average log likelihood -1.355499
[ Info: iteration 25, average log likelihood -1.355317
[ Info: iteration 26, average log likelihood -1.355107
[ Info: iteration 27, average log likelihood -1.354872
[ Info: iteration 28, average log likelihood -1.354605
[ Info: iteration 29, average log likelihood -1.354276
[ Info: iteration 30, average log likelihood -1.353881
[ Info: iteration 31, average log likelihood -1.353458
[ Info: iteration 32, average log likelihood -1.353077
[ Info: iteration 33, average log likelihood -1.352785
[ Info: iteration 34, average log likelihood -1.352583
[ Info: iteration 35, average log likelihood -1.352444
[ Info: iteration 36, average log likelihood -1.352341
[ Info: iteration 37, average log likelihood -1.352257
[ Info: iteration 38, average log likelihood -1.352183
[ Info: iteration 39, average log likelihood -1.352111
[ Info: iteration 40, average log likelihood -1.352038
[ Info: iteration 41, average log likelihood -1.351962
[ Info: iteration 42, average log likelihood -1.351876
[ Info: iteration 43, average log likelihood -1.351779
[ Info: iteration 44, average log likelihood -1.351666
[ Info: iteration 45, average log likelihood -1.351536
[ Info: iteration 46, average log likelihood -1.351398
[ Info: iteration 47, average log likelihood -1.351262
[ Info: iteration 48, average log likelihood -1.351144
[ Info: iteration 49, average log likelihood -1.351048
[ Info: iteration 50, average log likelihood -1.350978
┌ Info: EM with 100000 data points 50 iterations avll -1.350978
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3939035333046426
│     -1.3937540944815616
│      ⋮
└     -1.350978311172002
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.351110
[ Info: iteration 2, average log likelihood -1.350899
[ Info: iteration 3, average log likelihood -1.350246
[ Info: iteration 4, average log likelihood -1.344749
[ Info: iteration 5, average log likelihood -1.329704
[ Info: iteration 6, average log likelihood -1.317230
[ Info: iteration 7, average log likelihood -1.310519
[ Info: iteration 8, average log likelihood -1.307224
[ Info: iteration 9, average log likelihood -1.305039
[ Info: iteration 10, average log likelihood -1.302906
[ Info: iteration 11, average log likelihood -1.300574
[ Info: iteration 12, average log likelihood -1.298595
[ Info: iteration 13, average log likelihood -1.297420
[ Info: iteration 14, average log likelihood -1.296780
[ Info: iteration 15, average log likelihood -1.296314
[ Info: iteration 16, average log likelihood -1.295914
[ Info: iteration 17, average log likelihood -1.295599
[ Info: iteration 18, average log likelihood -1.295356
[ Info: iteration 19, average log likelihood -1.295144
[ Info: iteration 20, average log likelihood -1.294927
[ Info: iteration 21, average log likelihood -1.294675
[ Info: iteration 22, average log likelihood -1.294351
[ Info: iteration 23, average log likelihood -1.293977
[ Info: iteration 24, average log likelihood -1.293603
[ Info: iteration 25, average log likelihood -1.293276
[ Info: iteration 26, average log likelihood -1.293018
[ Info: iteration 27, average log likelihood -1.292844
[ Info: iteration 28, average log likelihood -1.292740
[ Info: iteration 29, average log likelihood -1.292676
[ Info: iteration 30, average log likelihood -1.292631
[ Info: iteration 31, average log likelihood -1.292599
[ Info: iteration 32, average log likelihood -1.292573
[ Info: iteration 33, average log likelihood -1.292553
[ Info: iteration 34, average log likelihood -1.292537
[ Info: iteration 35, average log likelihood -1.292524
[ Info: iteration 36, average log likelihood -1.292514
[ Info: iteration 37, average log likelihood -1.292505
[ Info: iteration 38, average log likelihood -1.292498
[ Info: iteration 39, average log likelihood -1.292492
[ Info: iteration 40, average log likelihood -1.292487
[ Info: iteration 41, average log likelihood -1.292483
[ Info: iteration 42, average log likelihood -1.292480
[ Info: iteration 43, average log likelihood -1.292477
[ Info: iteration 44, average log likelihood -1.292475
[ Info: iteration 45, average log likelihood -1.292473
[ Info: iteration 46, average log likelihood -1.292472
[ Info: iteration 47, average log likelihood -1.292471
[ Info: iteration 48, average log likelihood -1.292470
[ Info: iteration 49, average log likelihood -1.292469
[ Info: iteration 50, average log likelihood -1.292469
┌ Info: EM with 100000 data points 50 iterations avll -1.292469
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.351110038794982
│     -1.35089934427002
│      ⋮
└     -1.2924685667442122
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.292680
[ Info: iteration 2, average log likelihood -1.292411
[ Info: iteration 3, average log likelihood -1.290621
[ Info: iteration 4, average log likelihood -1.272675
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.238795
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.228864
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.214541
[ Info: iteration 8, average log likelihood -1.209010
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.192463
[ Info: iteration 10, average log likelihood -1.210371
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.196477
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.195121
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.200065
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.196836
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.195859
[ Info: iteration 16, average log likelihood -1.202291
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.186070
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.190376
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.186584
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.199728
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.194844
[ Info: iteration 22, average log likelihood -1.200976
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.185620
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.190306
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.196695
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.199883
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.194097
[ Info: iteration 28, average log likelihood -1.200324
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.185633
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.201038
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.191993
[ Info: iteration 32, average log likelihood -1.191643
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      9
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.180845
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.203457
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.196888
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.196465
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.190518
[ Info: iteration 38, average log likelihood -1.189678
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      9
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.176942
[ Info: iteration 40, average log likelihood -1.212276
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.193821
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.201917
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.191669
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.191976
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.190519
[ Info: iteration 46, average log likelihood -1.210237
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.187408
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.190044
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.185911
[ Info: iteration 50, average log likelihood -1.209479
┌ Info: EM with 100000 data points 50 iterations avll -1.209479
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.292679988570018
│     -1.2924114378561484
│      ⋮
└     -1.2094792336151334
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.189848
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.185894
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.180900
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     17
│     18
│     19
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.162875
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      3
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.139719
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     18
│     21
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.117653
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      4
│      7
│      ⋮
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.104478
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     18
│     21
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.127554
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.108730
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      7
│     17
│     18
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.092956
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      4
│      8
│     17
│     18
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.104050
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     17
│     18
│     21
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.108989
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      7
│      8
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.096773
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│     17
│     18
│     21
│     25
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.102672
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.108875
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      7
│      ⋮
│     21
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.094488
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     18
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.113966
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      4
│     17
│     18
│     21
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.093416
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      8
│     17
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.105096
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     18
│     21
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.110189
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      4
│     17
│     18
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.090617
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      7
│      8
│     17
│      ⋮
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.098686
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.118399
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      4
│     17
│     18
│     21
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.090145
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      7
│      8
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.103472
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     18
│     21
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.108417
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      4
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.097426
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      7
│      8
│     17
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.094708
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.117178
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      4
│     17
│     18
│     21
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.088399
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      7
│      8
│     17
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.102464
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     18
│     21
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.115530
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      4
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.093686
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      3
│      7
│      8
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.090060
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     16
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.119026
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     17
│     18
│     21
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.103301
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      7
│      8
│     17
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.088702
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     17
│     18
│     21
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.113671
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.101473
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     21
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.078396
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     18
│     25
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.115157
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     18
│     21
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.113484
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     20
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.092790
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     17
│     18
│     21
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.100748
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     16
│     17
│     18
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.099591
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│      ⋮
│     21
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.097164
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.100099
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     18
│     21
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.112292
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│      ⋮
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.099295
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│     21
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.106977
┌ Info: EM with 100000 data points 50 iterations avll -1.106977
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1898478691198942
│     -1.1858936498408752
│      ⋮
└     -1.1069766389262623
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4352815874194012
│     -1.435341148075847
│     -1.4352712008255297
│     -1.4347413657344703
│      ⋮
│     -1.1122917102494245
│     -1.0992949754567223
└     -1.1069766389262623
32×26 Array{Float64,2}:
  0.0892586   -0.0238589   -0.136476     0.0241241    0.0125875   -0.0287052     0.0811178    0.0302181    0.0158992   -0.166956    -0.103457     0.0318136    0.0617837   -0.0310819    -0.0784974     0.0794376    -0.139673   -0.0385545   -0.00616163  -0.10619       0.0169875    0.135143    -0.0441709    0.209671    -0.131212    -0.0355299
  0.0895628   -0.0789604   -0.137348    -0.0606381   -0.00446272  -0.00989982   -0.145602     0.0253538    0.0132814   -0.162954     0.0220902    0.405489     0.017729     0.106852     -0.0500365     0.00553284    0.459415   -0.00495574  -0.0279388    0.144946      0.0183781    0.407054    -0.015111    -0.557805    -0.0801465   -0.377584
  0.0671139    0.148518     0.0419158   -0.0282466    0.0250565    0.132443     -0.0355351   -0.202405    -0.0332909   -0.103069     0.0852896    0.0321622   -0.0114808   -0.163561      0.050148      0.0598436    -0.0516752  -0.129454    -0.0912682    0.0252578     0.0206627   -0.266893    -0.0114967   -0.0908924    0.0288319    0.104161
  0.0368531    0.0941928    0.0118677    0.0270599   -0.107771     0.248255     -0.027239    -0.0831019   -0.138292    -0.00554225   0.0406736    0.0407114   -0.0265065    0.00989189    0.0168026    -0.0067956     0.102815    0.130307    -0.145848     0.0909597    -0.0474484    0.0183355   -0.00832374  -0.147222    -0.210668    -0.130447
 -0.0517641    0.10037      0.0431019   -0.154546    -0.0242624    0.00174753    0.0766914    0.00784594  -0.0226308    0.0284823    0.00683171   0.045942    -0.0702677    0.000144907  -0.126157     -0.0166838    -0.0548859  -0.134051     0.00100347   0.000172412  -0.0262355   -0.161438     0.0412976    0.0764554    0.00908962  -0.0644813
  0.0428061    0.0294475    0.0656621   -0.0361752    0.00503288  -0.0575163    -0.0377761   -0.0480249    0.00729122  -0.123847     0.0614668    0.0104725    0.0445691   -0.0913569     0.0348992     0.130141     -0.0972302   0.120474    -0.0315092   -0.0322696     0.0292232    0.0353161    0.0983756    0.0723629    0.036361    -0.0322402
  0.00392559  -0.162907     0.13945      0.0664128   -0.0342286    0.076723      0.0724424    0.152159     0.123713     0.0637613    0.147224    -0.136424     0.0713048   -0.025355     -0.047961     -0.00427885   -0.105386   -0.048898     0.108244     0.139094      0.114289     0.120736     0.0240254   -0.00862458  -0.00907887  -0.0613662
 -0.053755     0.0665895   -0.00187803  -0.0936858   -0.206152    -0.17977       0.0691765    0.0413036    0.126922     0.0258166   -0.0115216   -0.068175     0.0821272   -0.0862586     0.0225829    -0.117932     -0.116597   -0.245729     0.170067    -0.145329      0.167186     0.041644    -0.0103882    0.122096     0.0938746   -0.0641041
 -0.0513549   -0.053832     0.00404407   0.102917    -0.0705038    0.0516525     0.143702    -0.121688    -0.13267     -0.0940677    0.0973623   -0.126141     0.0112797    0.12351      -0.000881401   0.0871342    -0.0219377  -0.0579891    0.0226016   -0.0538796    -0.170307     0.22358     -0.0948784    0.0752211   -0.0608729   -0.14379
  0.0069974    0.00461881   0.041918     0.0707708   -0.028553    -0.0380435    -0.152824    -0.043002     0.00600542   0.0851851    0.0184139   -0.015685    -0.102697     0.0404261    -0.0403788    -0.000766984   0.101585   -0.0665403   -0.0639259   -0.0297166    -0.0423939   -0.0131763    0.145853     0.0544668    0.0451606    0.0110015
 -0.154462    -0.0805426   -0.218143     0.0355066   -0.24414     -0.804451      0.118837    -0.0724262   -0.0260525    0.27998      0.205311     0.0926787   -0.107782    -0.152591      0.0362887     0.0716683    -0.0491912  -0.0324469   -0.211451     0.23328       0.0800178    0.00816372   0.130718    -0.0383899    0.00171159  -0.0661949
 -0.103284    -0.110056    -0.201586    -0.186958    -0.0346251    0.854148      0.00096231   0.10367     -0.0154156    0.273003     0.191173     0.0574161   -0.185995    -0.322271      0.00818989    0.060606     -0.0410941  -0.0484893   -0.189249     0.232463     -0.122965    -0.0968518    0.258237    -0.0814545    0.0504028   -0.073287
  0.137509     0.126977    -0.102113    -0.0942647   -0.267559    -0.0686472     0.12114      0.0643136    0.0863428   -0.0484208    0.117135     0.00869682   0.0709372   -0.142224      0.0393943     0.035102     -0.0818183  -0.014848     0.0927032    0.159322     -0.0709289    0.0185493    0.0264604   -0.135089    -0.0998809   -0.0312593
 -0.0257532   -0.0356579    0.183643    -0.0810557    0.0333003    0.000699209  -0.0647332   -0.063023     0.0119936   -0.0681081    0.051729    -0.0792082   -0.179992    -0.0243528     0.204705      0.0837199    -0.0107268   0.178212     0.0854869    0.0579638    -0.07215     -0.0102718   -0.0351138    0.0643671    0.0649111   -0.0684063
 -0.131443     0.15038      0.132051     0.0748519    0.123703     0.101018      0.0138939    0.112572     0.196099     0.0196399   -0.105001    -0.0766653   -0.0724039   -0.185875     -0.0114022    -0.00905489   -0.158071   -0.139911     0.210446    -0.0514499     0.134692    -0.0295974    0.129022     0.135957     0.0113196   -0.00982259
 -0.010002     0.0289925    0.01974      0.0570566   -0.0623461    0.171193     -0.0336267   -0.0217419   -0.11351      0.00202005  -0.0277095   -0.024095     0.00320573  -0.0135322     0.0135635     0.00301627    0.112855    0.0592602    0.036816     0.0410985    -0.0361738    0.0251796    0.0450029   -0.169488    -0.165656    -0.0257423
  0.138326     0.120926    -0.0518901    0.0621788    0.02902     -0.281957     -0.0728315   -0.0226965   -0.0916801   -0.0237816   -0.55984     -0.406129     0.101434     0.27391       0.174849     -0.0567886     0.0208334   0.0476365   -0.0772793   -0.134425     -0.028502     0.0029589    0.279674    -0.155843    -0.0114315    0.0588854
  0.141529     0.0976239   -0.0377467    0.0297698   -0.170541    -0.354634     -0.034551    -0.00951972  -0.252296     0.114313     0.461524     0.323376     0.101803    -0.400606      0.345891     -0.239455      0.0633271   0.038003    -0.0868054   -0.0799686    -0.033508     0.0239827    0.167548    -0.152201    -0.0290924   -0.129896
  0.0623549   -0.0664598    0.00714947   0.201523    -0.0447496    0.101894      0.0374872    0.185789    -0.0307608    0.0262558    0.129445     0.00710039   0.0166794    0.129731     -0.0185576    -0.0408041    -0.728553    0.0995599    0.180003    -0.0271938     0.015796     0.0980257   -0.120956     0.183936    -0.0963057    0.0418328
  0.078556    -0.0736397    0.0200524    0.127743    -0.0246711    0.102144      0.0394644    0.185825    -0.0300461    0.0160175   -0.0618983    0.086142     0.0160146    0.124192     -0.015026     -0.042512      0.820479    0.134261    -0.10408      0.124936      0.0143717   -0.27502     -0.1113       0.138947    -0.0580774    0.0358684
 -0.0625392    0.0045994    0.159131    -0.0685321   -0.0921508    0.133607     -0.162264    -0.00945631   0.137997     0.0482553    0.0605593    0.0424795   -0.016868     0.0182728     0.0448066    -0.0641651     0.121584   -0.00447432  -0.0641033    0.0125753    -0.0583249    0.0469953    0.0377811    0.0288572    0.0706629   -0.0785934
  0.209363    -0.0308321    0.0264885    0.0195983    0.18746     -0.0236977    -0.139238    -0.0415716    0.144505     0.0546602    0.142591     0.0082906    0.0538566   -0.0639502    -0.0914718     0.0280364    -0.171335    0.0845336    0.111087     0.0300393     0.0363307    0.152055    -0.0876471    0.00548962  -0.187767    -0.127292
  0.0923774   -0.108226    -0.0284488   -0.0524899    0.0939248    0.0440383    -0.00659958   0.139648    -0.0560511   -0.0227724    0.0271698   -0.0498811    0.102851     0.0285805     0.0401991    -0.108695     -0.134108    0.0213699    0.0199876    0.0223487    -0.00178562  -0.0812538    0.0670624    0.034568     0.0132934    0.00735588
 -0.0479175   -0.0766636    0.0743732    0.00533428   0.00309783   0.0411111     0.0693825    0.101783     0.00405709  -0.113739    -0.0410432    0.119088    -0.0110152    0.183986     -0.0137414     0.0941665    -0.0808465  -0.0309111    0.00824108   0.084518      0.0182321   -0.0273677    0.165925     0.1099      -0.0184353    0.0657872
 -0.0122579   -0.15504     -0.136585    -0.042388     0.0580655    0.0551115    -0.0344945   -0.132826     0.13384     -0.0745847   -0.0407352   -0.0819007   -0.0112785   -0.00117171    0.0424753     0.10123      -0.056442    0.0115882    0.0764789    0.0503406    -0.118097     0.0331403    0.175791    -0.0685966    0.02147     -0.0776687
  0.0068774    0.0237579   -0.17991     -0.0176193    0.0292578    0.100542     -0.121877     0.0718824   -0.0890034   -0.160554    -0.079719    -0.029449     0.0475089   -0.0117283    -0.0235266     0.146535      0.0954877  -0.014657     0.0737431   -0.00274896    0.139259    -0.0717178    0.230308    -0.0309803   -0.0841494   -0.110049
 -0.053181    -0.110185     0.0690674   -0.226704     0.0748501    0.110773     -0.021678     0.0446658    0.0282353    0.0460267    0.136794    -0.0493828    0.112204     0.0214698     3.53166e-5   -0.156148      0.0750637   0.0563793    0.0170529   -0.120324     -0.0182084   -0.0303174   -0.0115712   -0.0786673    0.0249691    0.0603355
 -0.0419175    0.0528238    0.0494026   -0.152696     0.130633    -0.0709023    -0.190228     0.0238377    0.0816981   -0.154252     0.100621    -0.213261    -0.0382877    0.115454     -0.087414      0.149113      0.147777   -0.0708888   -0.138202    -0.015428      0.0772015   -0.0880795    0.031756    -0.0664841    0.0589314   -0.0171978
  0.0475047   -0.131365     0.121        0.13555     -0.093824    -0.176057      0.0279205    0.144653    -0.090658    -0.191331    -0.0856091   -0.306059    -0.0165678   -0.130413     -0.271353     -0.111207      0.0168527   0.0752501    0.0422911   -0.225988      0.032784    -0.248191    -0.168987     0.0834766    0.176524    -0.0595449
  0.0508307    0.215927     0.0761279    0.16404     -0.0940077   -0.178466      0.0276354    0.142957     0.099935    -0.322108     0.0451394    0.140453    -0.00475278  -0.206131     -0.236672     -0.111125      0.0477872   0.117243    -0.0907231    0.460005      0.00932681  -0.225894     0.148631     0.0717704    0.181914    -0.0589983
  0.141836     0.171115     0.101834     0.0571328   -0.0363374    0.0378705    -0.156607    -0.0935476    0.158383    -0.14439     -0.123677    -0.191849    -0.0364968   -0.104184      0.20791       0.377053     -0.100201    0.0993143   -0.012501    -0.503303      0.0436126    0.0758478    0.0215731    0.147195     0.0156469    0.0366718
 -0.113756     0.129698     0.0911207   -0.00886093  -0.0339304    0.0538081    -0.0631524    0.071951    -0.168999    -0.120226    -0.128359    -0.177228     0.0633792   -0.107557      0.00375768    0.129546     -0.0774656  -0.161122    -0.0563841    1.01677       0.0357717    0.142341     0.0502255    0.142386    -0.0521486    0.00102852[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     17
│     18
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.104682
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     21
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.079411
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     17
│     18
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.095503
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.078615
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     17
│     18
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.102204
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     21
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.080867
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     17
│     18
│     25
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.096099
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     21
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.084924
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     17
│     18
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.094391
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.069362
┌ Info: EM with 100000 data points 10 iterations avll -1.069362
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.635669e+05
      1       7.216195e+05      -2.419473e+05 |       32
      2       6.968208e+05      -2.479875e+04 |       32
      3       6.820310e+05      -1.478976e+04 |       32
      4       6.691508e+05      -1.288023e+04 |       32
      5       6.583936e+05      -1.075718e+04 |       32
      6       6.512759e+05      -7.117762e+03 |       32
      7       6.473365e+05      -3.939371e+03 |       32
      8       6.448489e+05      -2.487570e+03 |       32
      9       6.433750e+05      -1.473957e+03 |       32
     10       6.426240e+05      -7.509616e+02 |       32
     11       6.422642e+05      -3.598357e+02 |       32
     12       6.420472e+05      -2.169799e+02 |       32
     13       6.418689e+05      -1.783258e+02 |       32
     14       6.417064e+05      -1.624734e+02 |       32
     15       6.415286e+05      -1.777668e+02 |       32
     16       6.412952e+05      -2.334109e+02 |       32
     17       6.409333e+05      -3.619231e+02 |       32
     18       6.404528e+05      -4.804978e+02 |       32
     19       6.399254e+05      -5.273525e+02 |       32
     20       6.396234e+05      -3.020747e+02 |       32
     21       6.394575e+05      -1.658968e+02 |       32
     22       6.393515e+05      -1.059462e+02 |       32
     23       6.392442e+05      -1.073431e+02 |       32
     24       6.391387e+05      -1.054707e+02 |       32
     25       6.390464e+05      -9.233685e+01 |       32
     26       6.389712e+05      -7.520320e+01 |       31
     27       6.389109e+05      -6.029235e+01 |       32
     28       6.388618e+05      -4.901293e+01 |       31
     29       6.388295e+05      -3.238126e+01 |       32
     30       6.388065e+05      -2.298487e+01 |       32
     31       6.387889e+05      -1.756445e+01 |       32
     32       6.387773e+05      -1.158831e+01 |       29
     33       6.387675e+05      -9.782509e+00 |       27
     34       6.387610e+05      -6.529225e+00 |       30
     35       6.387535e+05      -7.509661e+00 |       31
     36       6.387442e+05      -9.311043e+00 |       28
     37       6.387323e+05      -1.187362e+01 |       28
     38       6.387170e+05      -1.530357e+01 |       30
     39       6.387028e+05      -1.421017e+01 |       30
     40       6.386912e+05      -1.157856e+01 |       27
     41       6.386826e+05      -8.623954e+00 |       29
     42       6.386706e+05      -1.204102e+01 |       27
     43       6.386570e+05      -1.357957e+01 |       30
     44       6.386422e+05      -1.474747e+01 |       29
     45       6.386270e+05      -1.526901e+01 |       27
     46       6.386139e+05      -1.304632e+01 |       31
     47       6.385999e+05      -1.406939e+01 |       29
     48       6.385870e+05      -1.285515e+01 |       29
     49       6.385717e+05      -1.534805e+01 |       31
     50       6.385559e+05      -1.574730e+01 |       30
K-means terminated without convergence after 50 iterations (objv = 638555.9046470867)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.350682
[ Info: iteration 2, average log likelihood -1.315505
[ Info: iteration 3, average log likelihood -1.283855
[ Info: iteration 4, average log likelihood -1.254060
[ Info: iteration 5, average log likelihood -1.219882
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.180153
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.146160
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.131972
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      9
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.132487
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     18
│     19
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.127970
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.149822
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.127198
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     11
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.089453
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      8
│     13
│      ⋮
│     19
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.078456
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.162543
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.124487
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.089843
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      8
│     17
│     19
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.081350
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     11
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.119030
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.120029
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     13
│     15
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.082456
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      8
│     17
│     19
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.104476
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.139930
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.104508
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     11
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.084166
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      8
│     18
│     19
│     22
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.082978
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     17
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.133538
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.128760
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.110001
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     19
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.097199
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     17
│     18
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.101159
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.107348
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     11
│     13
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.091416
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     19
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.116332
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     17
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.121742
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     12
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.103992
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.096857
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     13
│     19
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.087760
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     15
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.112892
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     17
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.110753
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.113816
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     13
│     18
│     19
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.088324
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│      8
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.107580
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     12
│     15
│     16
│     17
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.109464
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.129110
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     19
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.089650
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      8
│     11
│     18
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.096374
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     12
│     17
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.101663
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.115815
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     19
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.110368
┌ Info: EM with 100000 data points 50 iterations avll -1.110368
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0810904   -0.0488516   -0.126072     0.000949938   0.0147766  -0.0309305    0.0560521    0.0426562    0.0162261    -0.145722     -0.0764493    0.120551     0.0558816    -7.29306e-5  -0.0758445    0.0594866   -0.0242217  -0.0777757    0.0235176  -0.105218     0.0220762   0.245041     -0.0437554    0.122893    -0.112337   -0.112223
  0.0472281   -0.145124     0.0423711    0.0378751    -0.0913529   0.0912902   -0.225305     0.116559     0.141326      0.044924     -0.0605695    0.0521444   -0.124887      0.126845     0.0598269    0.134565     0.064899   -0.124189    -0.0523511  -0.0989513   -0.0703634  -0.1373        0.118104     0.0710097    0.19434     0.028671
 -0.0531479   -0.110445     0.0699981   -0.222816      0.0762321   0.11873     -0.0310387    0.0414216    0.0198812     0.0436635     0.134299    -0.0529602    0.112742      0.022143    -0.00161879  -0.156584     0.0785213   0.0675968    0.0171963  -0.116111    -0.0234319  -0.0243629    -0.0119997   -0.0844234    0.0186243   0.0502677
  0.16237     -0.15429     -0.0293245   -0.0297554     0.159207    0.0495034   -0.11192      0.150607    -0.123766     -0.0239799     0.128257    -0.0643668    0.072956      0.0368196    0.0438729   -0.00332852  -0.227802    0.0543499   -0.0611461   0.0979905   -0.0495314  -0.185857      0.073519     0.150513    -0.0465855  -0.0773762
 -0.0539485   -0.0535142    0.00521847   0.101029     -0.0705641   0.0512463    0.143852    -0.120523    -0.13414      -0.0938491     0.0956526   -0.126095     0.0111477     0.123676    -0.00178625   0.0855625   -0.0221179  -0.0574882    0.0224349  -0.0541109   -0.16828     0.224281     -0.0953292    0.0752424   -0.0617839  -0.145487
  0.00698871  -0.0165101   -0.162166    -0.0272402     0.0294159   0.120281    -0.104463    -0.0124072   -0.0308878    -0.139361     -0.065248    -0.0485401    0.0232776    -0.00670039  -0.0150907    0.129227     0.0464024   0.0142509    0.0768373   0.0235078    0.0543386  -0.0393058     0.200973    -0.0443757   -0.0512231  -0.0850552
  0.213621    -0.0305447    0.0276351    0.0233684     0.1887     -0.023841    -0.142078    -0.0427462    0.143259      0.0555187     0.146171     0.00818548   0.0551597    -0.0649707   -0.0916227    0.0294054   -0.172605    0.0867093    0.112433    0.0284184    0.0353204   0.154651     -0.0883769    0.00928705  -0.187101   -0.129363
  0.067787     0.142808     0.0405133   -0.0260821     0.0239678   0.141508    -0.0356647   -0.199985    -0.0374053    -0.101749      0.0871031    0.0302651   -0.000857679  -0.163863     0.0514562    0.0631074   -0.0531901  -0.123484    -0.0871035   0.0318962    0.0160429  -0.259208     -0.0211765   -0.0974961    0.0316709   0.102164
 -0.0708984   -0.00105432   0.151601    -0.0924238    -0.0957899   0.131985    -0.164968    -0.0272119    0.140377      0.0979702     0.0638994    0.0339065   -0.0240129     0.00363036   0.0451572   -0.0938548    0.144376   -0.0157073   -0.0631101   0.0136747   -0.0715297   0.0530797     0.0448077    0.0276193    0.09024    -0.0824497
 -0.0237472    0.119015    -0.0451106   -0.141958     -0.0661186   0.0484621    0.0551697    0.0910913    0.0742002    -0.0138624     0.109522     0.0626672   -0.120546      0.0602421    0.0781646   -0.0163378   -0.0457357  -0.27401     -0.0529484  -0.0469979    0.145974   -0.173238      0.0451841    0.123865     0.0316677  -0.0613076
 -0.00866354   0.0280108    0.0795582    0.0253878     0.0810989  -0.188105    -0.0975319   -0.0596392   -0.0162174    -0.056153      0.0548531   -0.0867481    0.0963529    -0.040086     0.0254926    0.176379    -0.0754648   0.113689    -0.027612   -0.0717832   -0.013499    0.0514384     0.119317     0.0516923   -0.140572   -0.105092
  0.0515182    0.0579942   -0.0295845    0.0345624    -0.0929514   0.200205    -0.0358785   -0.0485088   -0.0989197    -0.0549417     0.00973784   0.0280164    0.00820433    0.00440317   4.45817e-5   0.0122806    0.106083    0.20844     -0.143298    0.114474    -0.0427899   0.0441307    -0.0270234   -0.206233    -0.227214   -0.121363
  0.0494719    0.110517     0.0395004    0.116645     -0.0457863  -0.0735117   -0.125555    -0.0931067   -0.0922307     0.100398      0.0584718   -0.0403717   -0.149766     -0.0273268   -0.122195    -0.18179      0.111238   -0.061634    -0.0830066   0.00327181  -0.0424628   0.140982      0.186867     0.0645925    0.0166223   0.0604576
 -0.112468     0.111813     0.108997     0.0593525     0.0546287   0.121545     0.0024265    0.0446324    0.112405      0.0121968    -0.0649679   -0.0397045   -0.0462798    -0.132381     0.00597705  -0.0145318   -0.047186   -0.113472     0.146687   -0.0305594    0.0848203  -0.00451305    0.105039     0.050303    -0.0224205  -0.0091462
 -0.0122851   -0.103304     0.180577     0.12658      -0.0698235   0.108702     0.0726187    0.145098     0.119497      0.0552659     0.110744    -0.153458     0.0810635    -0.0376524   -0.0382504   -0.0207462   -0.131905   -0.0961033    0.113093    0.111895     0.121362    0.133878      0.011591    -0.0165843   -0.0208329  -0.0735429
 -0.0491819    0.0252844   -0.0853545   -0.20828      -0.171567   -0.301368     0.0635785    0.0528876    0.127044      0.0368087     0.00354198  -0.0591055    0.0960754    -0.126512     0.019739    -0.138679    -0.174096   -0.21777      0.192072   -0.155549     0.14995     0.0389301     0.0464369    0.1524       0.138343   -0.0606598
  0.0710347   -0.0609033    0.0248626    0.19872      -0.0485709   0.08715      0.0352964    0.178454    -0.0223526     0.0229325     0.0172725    0.0414164    0.018943      0.137809    -0.00401882  -0.0465441    0.126215    0.119024     0.0338495   0.0515556    0.0224113  -0.112887     -0.122487     0.159712    -0.0693953   0.0319908
 -0.00532796  -0.241467    -0.0972123   -0.0499928     0.0672363  -0.0669259    0.00444203  -0.141949     0.223418     -0.106739     -0.0325357   -0.0746098   -0.00331855   -0.0171974    0.0859951    0.109243    -0.128616    0.0117002    0.0630177   0.0218745   -0.183616    0.0913485     0.219314    -0.0571013    0.0648451  -0.104782
 -0.0426317    0.0518978    0.0500266   -0.152827      0.131297   -0.0798848   -0.193032     0.0241447    0.0778481    -0.158333      0.098925    -0.225048    -0.037143      0.118447    -0.0920623    0.161932     0.157775   -0.0606343   -0.143375   -0.0140425    0.0772772  -0.085197      0.0360235   -0.0699341    0.0597187  -0.0206759
 -0.0243257   -0.0592192    0.144586    -0.129354     -0.110218    0.0147922    0.0661261   -0.0904275   -0.00622645    0.000270092   0.0131611    0.0461953   -0.181709      0.0045652   -0.140694    -0.137423    -0.112453   -0.1179       0.115971   -0.0339286   -0.129642   -0.14525       0.00165503  -0.00487586   0.0562821  -0.054305
  0.0257767    0.0386155    0.0508463   -0.0829818    -0.0234905   0.0294946    0.00794544  -0.0769238    0.0186958    -0.0989268     0.0659178    0.0498716    0.00383512   -0.112056     0.00281566   0.0923936   -0.0661098   0.109576    -0.0327203   0.0351072    0.0687962   0.00289458    0.065336     0.0894591    0.122527    0.00839983
 -0.0444183   -0.129978     0.147272     0.0426312     0.063014   -0.144638     0.105623     0.147574     0.1817       -0.0920263     0.031098     0.194237    -0.00820591    0.0922404   -0.0844932    0.0793571   -0.079466   -0.106826     0.0630395  -0.0747755    0.112168   -0.0773381     0.0821817    0.132387    -0.230361    0.0481583
  0.00156215   0.145728     0.0968545    0.023924     -0.0347186   0.0455572   -0.110068    -0.00516683  -0.0155249    -0.132625     -0.126274    -0.187346     0.0195664    -0.107021     0.0933116    0.245866    -0.0887088  -0.0398211   -0.0364203   0.322533     0.0366265   0.113128      0.0367709    0.144698    -0.0254784   0.0156058
  0.146888     0.125177    -0.104312    -0.0968288    -0.288254   -0.062569     0.12351      0.0641762    0.0880119    -0.050048      0.113799     0.00403503   0.0700429    -0.144942     0.03908      0.0328221   -0.088993   -0.00954764   0.101172    0.159461    -0.0698398   0.0203047     0.0178528   -0.140155    -0.100837   -0.0314355
 -0.0534965    0.266392    -0.0245971   -0.191839      0.102423    0.00622407   0.146501     0.103666    -0.109491      0.0634085    -0.0587038    0.103616     0.0843907    -0.0500834   -0.28738      0.0972598    0.0100035  -0.0376058   -0.0894705   0.0866991   -0.020413   -0.14242       0.115536     0.115475    -0.0366253  -0.0598748
  0.0229      -0.0488268   -0.0307462   -0.0753963     0.0278497   0.0360773    0.107057     0.125821     0.00948691   -0.0261689    -0.0731703   -0.0380885    0.133651      0.0245038    0.0399693   -0.221277    -0.0343693  -0.0134493    0.106391   -0.0581315    0.0457457   0.025887      0.0602923   -0.0820313    0.0808616   0.0964754
 -0.049261    -0.0603919    0.0182628    0.00190962   -0.0759851   0.222917     0.00785723   0.0561018   -0.162723     -0.14843      -0.108372     0.0488326   -0.0207658     0.300213     0.087669     0.105281    -0.0963572   0.0500809   -0.0331664   0.23992     -0.0837651   0.0294371     0.244743     0.0903999    0.186708    0.0897334
  0.138197     0.108539    -0.0464594    0.0450238    -0.0706102  -0.319417    -0.0531985   -0.0133273   -0.175108      0.046772     -0.0532961   -0.0421109    0.0998926    -0.0653782    0.26166     -0.147937     0.0431018   0.0551831   -0.0815643  -0.102955    -0.0316132   0.0158497     0.219948    -0.154448    -0.0196339  -0.0378996
  0.0479906    0.0373307    0.102123     0.151761     -0.0940195  -0.178544     0.0286702    0.144096     0.000819859  -0.261412     -0.0216075   -0.0886328   -0.00920155   -0.170114    -0.252973    -0.112662     0.0330337   0.0995229   -0.022825    0.108864     0.0197278  -0.238561     -0.0134718    0.0772095    0.180135   -0.0593969
 -0.193966     0.0359732    0.044963    -0.0289431     0.132242   -0.214696    -0.0409137   -0.218417    -0.0173703     0.0961716     0.0489373   -0.134945     0.0712467     0.0575507   -0.0517996    0.184794     0.208106   -0.110038     0.0109454   0.0648785    0.0675176  -0.226667     -0.00283361   0.0413641   -0.229731   -0.140124
 -0.13003     -0.095644    -0.209048    -0.0744015    -0.143939    0.00772699   0.0623924    0.0142369   -0.0207378     0.276828      0.198607     0.0770885   -0.146892     -0.237441     0.0214558    0.0671833   -0.044405   -0.0408591   -0.200325    0.233256    -0.0197505  -0.0423419     0.192375    -0.0613778    0.0269751  -0.0699135
 -0.0235574   -0.0371729    0.188542    -0.0805253     0.0251577   0.00128326  -0.0598907   -0.0634849    0.0142838    -0.0638918     0.0558254   -0.0797945   -0.176931     -0.026755     0.195291     0.0793666   -0.0120928   0.165724     0.0853475   0.0543836   -0.0627743   0.000441046  -0.0527195    0.0590338    0.0650496  -0.0550946[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      8
│     12
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.110591
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     18
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.052945
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      8
│     12
│      ⋮
│     22
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.044894
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      8
│      9
│     11
│      ⋮
│     18
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.079804
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│      8
│     12
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.070659
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.026391
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      8
│     11
│     12
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.102868
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│      ⋮
│     18
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.053793
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      8
│     12
│      ⋮
│     22
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.044790
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      8
│      9
│     11
│      ⋮
│     18
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.079837
┌ Info: EM with 100000 data points 10 iterations avll -1.079837
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.145302     0.0350012    -0.0309446  -0.120432     0.0480067    -0.00418207   -0.0220109     0.00567288   0.084345    -0.0937243     0.175427     0.0101874    0.0346831    0.0124766     0.0677671     0.0321595    0.0326871    0.0790542    0.014119      0.00437468  -0.159952     -0.0369391    0.0571536    0.177377     0.101497    -0.0880993
  0.096699     0.0204545     0.0342162  -0.0391073    0.109146     -0.152278     -0.032396      0.138831    -0.00908745  -0.000561533  -0.11455     -0.117944     0.144572    -0.123587      0.0386956    -0.121365    -0.061756     0.117105     0.228864     -0.0110376    0.0236947     0.0113269    0.152236    -0.0655001   -0.0934096   -0.148521
 -0.206473     0.0962048    -0.17738    -0.0561222   -0.0949222     0.151276      0.00496312   -0.0934119   -0.0761951    0.0967191    -0.0285117   -0.0451313    0.0942057   -0.0749172     0.00528995    0.0151286    0.164362     0.0607224    0.0894841    -0.00559709   0.235418      0.0586519    0.105041    -0.0374657   -0.123709    -0.13389
 -0.167981    -0.0361659     0.0154825   0.150859     0.174264      0.152538      0.0119371     0.00204546  -0.0838791    0.0145442     0.0277326    0.0512943    0.139403     0.132293      0.0572891    -0.0684404   -0.0374946   -0.192321     0.0629502     0.00113351  -0.0389617     0.119904     0.0713831    0.0969172    0.00162122  -0.113957
  0.0166962    0.0466157    -0.166229    0.0567657   -0.0543451     0.0524336     0.1292       -0.0144317    0.00629112  -0.177053     -0.0375861   -0.104748     0.0180007    0.00735967   -0.0784183     0.20834      0.0436937   -0.302243    -0.147843     -0.0996214   -0.0840171    -0.107125    -0.0549955    0.0450953    0.164931    -0.147658
  0.0302698   -0.132125     -0.344266   -0.169755    -0.0510006    -0.0812372    -0.061902     -0.189083    -0.0726836    0.0102764     0.0106417    0.00952481  -0.013406     0.086957     -0.0272974     0.208618    -0.0576573   -0.0936502   -0.00339054    0.117382    -0.000216752  -0.0354362   -0.0403936    0.0612486    0.170726     0.0600161
 -0.0978033    0.000473797  -0.045757    0.0194894    0.0401148     0.145782      0.0939178     0.18347      0.112571     0.00867269   -0.0764967    0.0147104   -0.113032    -0.160157      0.126431     -0.236192     0.0578483   -0.201938     0.115637     -0.0894913    0.0324203    -0.201283    -0.0536566   -0.0621292   -0.0788297   -0.102498
 -0.0610988    0.124658     -0.0853329   0.0995799   -3.2504e-5    -0.0562735     0.00102933    0.0710029   -0.112724     0.0962519     0.101376    -0.024817    -0.0581623   -0.140686      0.0969488    -0.00184698  -0.0156167    0.184027     0.123913      0.101564     0.0189536    -0.00227888  -0.119026    -0.00275109   0.283202     0.125002
 -0.178886    -0.0649323    -0.0594439   0.0468763    0.00272224    0.077925      0.0455672    -0.0896256   -0.231262     0.024749     -0.0708405    0.00453691  -0.0435267   -0.000914177   0.0534297     0.134505    -0.0153656   -0.0159154   -0.0377802     0.153144    -0.0768632     0.0472605    0.00084608   0.0635619   -0.00236009  -0.00262132
  0.0228251   -0.00993578    0.120069    0.028682     0.0331525    -0.0462208     0.0125051     0.223245    -0.119261    -0.0487882    -0.00863198   0.0287781   -0.153934    -0.195274     -0.0567119    -0.0636349    0.0537065    0.146664     0.141177      0.137142     0.131522     -0.142559     0.086933     0.274482    -0.0120736    0.0201451
 -0.0291536   -0.00367035   -0.140253    0.044317    -0.179068      0.0753939    -0.0389411    -0.090607    -0.0780313   -0.0255893    -0.138123    -0.0884926   -0.186904    -0.0239945    -0.00898755    0.0449946    0.00190206   0.100233    -0.00300936    0.027204     0.0296719    -0.011617    -0.0500585   -0.0597533   -0.106287     0.0408647
  0.0562075   -0.040699     -0.0609175   0.0661029    0.124505     -0.0878322     0.109712     -0.135805    -0.00175909   0.00522579   -0.0372113    0.0812155    0.0485441    0.0108281    -0.108194     -0.0620233    0.0491964   -0.0426482   -0.0328733    -0.133279    -0.126014     -0.051021     0.0170641   -0.116411    -0.152878     0.02121
 -0.0644493   -0.0280962    -0.0377505  -0.180763    -0.0925483    -0.00437341   -0.0658618     0.199469     0.148964     0.0326897     0.0310016   -0.0649089    0.0412876   -0.0523052    -0.0870755     0.0203905   -0.0416803   -0.00973614   0.0273153    -0.220444     0.081056     -0.0786303   -0.0295993    0.143442    -0.0638319   -0.180494
  0.133523    -0.024289      0.159927    0.0842948    0.148612     -0.149524      0.129403      0.14363      0.0668447    0.0516658    -0.0305208    0.1791      -0.00102378   0.0293714     0.0518924    -0.179295    -0.0171029    0.0782745    0.0980925    -0.0562195    0.158088     -0.0360458   -0.0614691    0.201129     0.114035     0.178434
  0.0731337   -0.0373836    -0.0113464   0.0517926    0.0933817     0.0588042    -0.0380749     0.065722    -0.0750854    0.00220855    0.00615363  -0.152343    -0.0956922   -0.0702971     0.131039     -0.0520502    0.0524193    0.0703239   -0.00154202   -0.00319203   0.171697     -0.235254     0.0665479    0.032696     0.0838308   -0.0782044
 -0.00967561   0.0839517    -0.0386454   0.0140629   -0.00419335   -0.00583569   -0.0489495    -0.157345    -0.117611    -0.00457746    0.147385     0.107889     0.0623877    0.0478064    -0.134369     -0.0264947    0.130036     0.0629084   -0.0406887     0.0811721    0.0690111     0.196155    -0.099814     0.0180836   -0.0544702    0.0157729
  0.186011     0.0222969     0.0161385  -0.0845839   -0.0263156    -0.0395102     0.0862531     0.0491382   -0.0494815   -0.0893123     0.0577278   -0.0271672   -0.036535     0.142338      0.009442      0.0846738   -0.0735802    0.0735459    0.00974776    0.0277123    0.100362     -0.0751134   -0.0493237    0.0607679   -0.115754    -0.0482605
  0.0619472    0.0665383    -0.0788169   0.0795157   -0.0596873    -0.0418244     0.0584105    -0.0782807    0.0767886    0.137878     -0.110251    -0.0677804    0.0856034    0.0090075     0.323398     -0.0873971    0.141655    -0.0951955   -0.00330591   -0.102012     0.103826      0.0915102    0.0214278    0.0965564    0.0324063    0.184132
  0.12716     -0.0165066    -0.0191358   0.091415     0.187682     -0.0474935     0.118152      0.124103     0.0104226    0.019697      0.0519157    0.0268139    0.0767749   -0.0547104     0.0993589     0.193821    -0.159165    -0.0399013   -0.138963     -0.0423629   -0.0355878     0.140676     0.179286     0.119267    -0.0449373   -0.0749076
  0.00308928  -0.0415122    -0.0149092   0.0484788   -0.0728519    -0.0429303    -0.0280453    -0.090532    -0.252414    -0.0292833     0.0531986    0.0411597   -0.160417    -0.0405341     0.000208175  -0.00250306  -0.0873064    0.13066     -0.0652793    -0.0552355    0.126405      0.0727355   -0.109905     0.130742     0.0383486   -0.0213123
 -0.100544     0.147485      0.0302364   0.168212    -0.0383257    -0.201662     -0.0876358    -0.0204241    0.103921     0.193132     -0.0804328   -0.0746952   -0.111399     0.0332163    -0.0140073     0.0114328   -0.0802931    0.031253     0.0522439     0.0939704    0.0151338    -0.0928457   -0.0496587    0.0401042   -0.0553332   -0.0688763
  0.109501     0.0331151     0.184663   -0.0405943   -0.00263659    0.0464982    -0.099464      0.031903     0.0492296   -0.0234556    -0.044081    -0.114538    -0.07675      0.0631024    -0.106471     -0.0548875   -0.152079    -0.0347855    0.128867     -0.0627149    0.133953     -0.0442649    0.0381921    0.0376223    0.00667301   0.0690444
 -0.103495     0.0628985    -0.0178599   0.0165334    0.186371     -0.0346027    -0.0832528     0.0900357    0.0713505   -0.0396449     0.07089     -0.0895999    0.127842     0.109511     -0.0308825    -0.0273392   -0.00204389   0.064103    -0.143759     -0.127202    -0.0185379     0.0908738    0.0782207    0.205697    -0.0958205   -0.0313136
  0.0687151    0.148637      0.02915     0.114973     0.227673     -0.149335     -0.0145928     0.0552486    0.0499626    0.0371104     0.0658603   -0.155811    -0.134441     0.014733      0.0356429     0.0307465   -0.239344     0.153468     0.139828     -0.0879107   -0.0508261     0.0145727   -0.0927767   -0.0724041   -0.0212454    0.111952
  0.0272165    0.0315156    -0.043881    0.0332395   -0.0554873     0.127446     -0.100154      0.0794654   -0.0161855    0.175585      0.291445    -0.0512439   -0.00826898   0.021718      0.0154915    -0.0897953   -0.0453922    0.136066     0.196873     -0.0748545    0.0298425     0.0754656   -0.0362166   -0.0791295   -0.150714     0.0165747
 -0.076291    -0.0665499     0.0382457  -0.0704782   -0.000544814   0.000786028  -0.0180372    -0.0422655   -0.0431765    0.0786738     0.145702    -0.00366668  -0.081358    -0.00795243   -0.103646     -0.00489295  -0.00436723   0.00282329   0.0452948     0.189602     0.216465     -0.138654     0.15198     -0.00938831  -0.108833     0.0703977
  0.169376     0.0607116     0.0275737  -0.00808727   0.0425255     0.0485234     0.0119125    -0.104497    -0.172918     0.046588      0.0290473    0.234987    -0.132988    -0.0375799     0.138324      0.091422     0.0757026    0.0725514    0.0343759    -0.227929     0.0711848     0.113644    -0.214474     0.114353     0.0579561   -0.1745
  0.00549798   0.045927      0.0899107   0.0201205   -0.0660592    -0.145564      0.142643      0.160896    -0.0538962   -0.0107917    -0.17641     -0.202896    -0.0764022    0.0201861    -0.0919317     0.117033    -0.0350994   -0.0956221    0.16134      -0.233679    -0.0979811     0.180311    -0.0990329    0.138549    -0.0356024   -0.145664
  0.0515486   -0.068476      0.0144177   0.00503752  -0.199599     -0.195449      0.132228      0.179282     0.0206123    0.109733      0.145182     0.00442515  -0.104612    -0.111659      0.0955683     0.0547411   -0.0804252    0.0432934   -0.00713302   -0.19674     -0.128648     -0.0149001    0.121246     0.165444     0.0544504   -0.0388418
 -0.0563557   -0.0559439    -0.0301319   0.121159    -0.038516     -0.0659843    -0.00910984   -0.184373     0.130766    -0.0690445    -0.00254978   0.0579884    0.115749     0.118441      0.00206485    0.0446832   -0.0440835   -0.0264033    0.0873921    -0.0414244   -0.0574206    -0.0577273    0.137146     0.189835     0.0484925   -0.0302072
  0.0799217    0.053189     -0.0283533   0.0414838   -0.0549429    -0.0643315     0.000417028   0.0902526    0.0184804   -0.0757108     0.10192     -0.117427     0.0847364    0.0390353     0.208826      0.149227     0.0593547   -0.0157927   -0.0772268     0.225246     0.0504943    -0.0802039   -0.0926273   -0.0183313    0.0904758   -0.14088
 -0.0904098    0.0815015     0.18232     0.00508455   0.122735      0.0925254    -0.0892163    -0.071799     0.0708323    0.0101776     0.0762042   -0.0860162   -0.115925     0.0258466     0.0631848     0.0519595    0.112546     0.00808644   0.000578149   0.0771511   -0.0842838     0.0837018    0.192602     0.0805358   -0.00700523   0.0522097kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4183396397397092
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418358
[ Info: iteration 2, average log likelihood -1.418295
[ Info: iteration 3, average log likelihood -1.418250
[ Info: iteration 4, average log likelihood -1.418199
[ Info: iteration 5, average log likelihood -1.418140
[ Info: iteration 6, average log likelihood -1.418072
[ Info: iteration 7, average log likelihood -1.417994
[ Info: iteration 8, average log likelihood -1.417902
[ Info: iteration 9, average log likelihood -1.417780
[ Info: iteration 10, average log likelihood -1.417578
[ Info: iteration 11, average log likelihood -1.417202
[ Info: iteration 12, average log likelihood -1.416531
[ Info: iteration 13, average log likelihood -1.415549
[ Info: iteration 14, average log likelihood -1.414504
[ Info: iteration 15, average log likelihood -1.413747
[ Info: iteration 16, average log likelihood -1.413352
[ Info: iteration 17, average log likelihood -1.413181
[ Info: iteration 18, average log likelihood -1.413111
[ Info: iteration 19, average log likelihood -1.413083
[ Info: iteration 20, average log likelihood -1.413072
[ Info: iteration 21, average log likelihood -1.413067
[ Info: iteration 22, average log likelihood -1.413064
[ Info: iteration 23, average log likelihood -1.413063
[ Info: iteration 24, average log likelihood -1.413062
[ Info: iteration 25, average log likelihood -1.413062
[ Info: iteration 26, average log likelihood -1.413062
[ Info: iteration 27, average log likelihood -1.413061
[ Info: iteration 28, average log likelihood -1.413061
[ Info: iteration 29, average log likelihood -1.413061
[ Info: iteration 30, average log likelihood -1.413061
[ Info: iteration 31, average log likelihood -1.413060
[ Info: iteration 32, average log likelihood -1.413060
[ Info: iteration 33, average log likelihood -1.413060
[ Info: iteration 34, average log likelihood -1.413060
[ Info: iteration 35, average log likelihood -1.413060
[ Info: iteration 36, average log likelihood -1.413060
[ Info: iteration 37, average log likelihood -1.413060
[ Info: iteration 38, average log likelihood -1.413060
[ Info: iteration 39, average log likelihood -1.413059
[ Info: iteration 40, average log likelihood -1.413059
[ Info: iteration 41, average log likelihood -1.413059
[ Info: iteration 42, average log likelihood -1.413059
[ Info: iteration 43, average log likelihood -1.413059
[ Info: iteration 44, average log likelihood -1.413059
[ Info: iteration 45, average log likelihood -1.413059
[ Info: iteration 46, average log likelihood -1.413059
[ Info: iteration 47, average log likelihood -1.413059
[ Info: iteration 48, average log likelihood -1.413059
[ Info: iteration 49, average log likelihood -1.413059
[ Info: iteration 50, average log likelihood -1.413059
┌ Info: EM with 100000 data points 50 iterations avll -1.413059
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4183581171183806
│     -1.418294667213438
│      ⋮
└     -1.4130590001738932
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413074
[ Info: iteration 2, average log likelihood -1.413008
[ Info: iteration 3, average log likelihood -1.412956
[ Info: iteration 4, average log likelihood -1.412897
[ Info: iteration 5, average log likelihood -1.412826
[ Info: iteration 6, average log likelihood -1.412742
[ Info: iteration 7, average log likelihood -1.412648
[ Info: iteration 8, average log likelihood -1.412551
[ Info: iteration 9, average log likelihood -1.412458
[ Info: iteration 10, average log likelihood -1.412376
[ Info: iteration 11, average log likelihood -1.412308
[ Info: iteration 12, average log likelihood -1.412256
[ Info: iteration 13, average log likelihood -1.412218
[ Info: iteration 14, average log likelihood -1.412192
[ Info: iteration 15, average log likelihood -1.412175
[ Info: iteration 16, average log likelihood -1.412163
[ Info: iteration 17, average log likelihood -1.412154
[ Info: iteration 18, average log likelihood -1.412148
[ Info: iteration 19, average log likelihood -1.412143
[ Info: iteration 20, average log likelihood -1.412139
[ Info: iteration 21, average log likelihood -1.412135
[ Info: iteration 22, average log likelihood -1.412131
[ Info: iteration 23, average log likelihood -1.412127
[ Info: iteration 24, average log likelihood -1.412124
[ Info: iteration 25, average log likelihood -1.412121
[ Info: iteration 26, average log likelihood -1.412117
[ Info: iteration 27, average log likelihood -1.412114
[ Info: iteration 28, average log likelihood -1.412111
[ Info: iteration 29, average log likelihood -1.412108
[ Info: iteration 30, average log likelihood -1.412105
[ Info: iteration 31, average log likelihood -1.412102
[ Info: iteration 32, average log likelihood -1.412099
[ Info: iteration 33, average log likelihood -1.412096
[ Info: iteration 34, average log likelihood -1.412094
[ Info: iteration 35, average log likelihood -1.412091
[ Info: iteration 36, average log likelihood -1.412088
[ Info: iteration 37, average log likelihood -1.412085
[ Info: iteration 38, average log likelihood -1.412083
[ Info: iteration 39, average log likelihood -1.412080
[ Info: iteration 40, average log likelihood -1.412078
[ Info: iteration 41, average log likelihood -1.412075
[ Info: iteration 42, average log likelihood -1.412073
[ Info: iteration 43, average log likelihood -1.412071
[ Info: iteration 44, average log likelihood -1.412068
[ Info: iteration 45, average log likelihood -1.412066
[ Info: iteration 46, average log likelihood -1.412064
[ Info: iteration 47, average log likelihood -1.412062
[ Info: iteration 48, average log likelihood -1.412060
[ Info: iteration 49, average log likelihood -1.412058
[ Info: iteration 50, average log likelihood -1.412057
┌ Info: EM with 100000 data points 50 iterations avll -1.412057
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4130736240632047
│     -1.413007809535235
│      ⋮
└     -1.4120565966167198
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412066
[ Info: iteration 2, average log likelihood -1.412004
[ Info: iteration 3, average log likelihood -1.411953
[ Info: iteration 4, average log likelihood -1.411898
[ Info: iteration 5, average log likelihood -1.411834
[ Info: iteration 6, average log likelihood -1.411759
[ Info: iteration 7, average log likelihood -1.411675
[ Info: iteration 8, average log likelihood -1.411585
[ Info: iteration 9, average log likelihood -1.411496
[ Info: iteration 10, average log likelihood -1.411412
[ Info: iteration 11, average log likelihood -1.411338
[ Info: iteration 12, average log likelihood -1.411274
[ Info: iteration 13, average log likelihood -1.411221
[ Info: iteration 14, average log likelihood -1.411178
[ Info: iteration 15, average log likelihood -1.411143
[ Info: iteration 16, average log likelihood -1.411114
[ Info: iteration 17, average log likelihood -1.411091
[ Info: iteration 18, average log likelihood -1.411070
[ Info: iteration 19, average log likelihood -1.411053
[ Info: iteration 20, average log likelihood -1.411037
[ Info: iteration 21, average log likelihood -1.411023
[ Info: iteration 22, average log likelihood -1.411010
[ Info: iteration 23, average log likelihood -1.410997
[ Info: iteration 24, average log likelihood -1.410985
[ Info: iteration 25, average log likelihood -1.410973
[ Info: iteration 26, average log likelihood -1.410962
[ Info: iteration 27, average log likelihood -1.410950
[ Info: iteration 28, average log likelihood -1.410939
[ Info: iteration 29, average log likelihood -1.410928
[ Info: iteration 30, average log likelihood -1.410918
[ Info: iteration 31, average log likelihood -1.410907
[ Info: iteration 32, average log likelihood -1.410897
[ Info: iteration 33, average log likelihood -1.410888
[ Info: iteration 34, average log likelihood -1.410878
[ Info: iteration 35, average log likelihood -1.410870
[ Info: iteration 36, average log likelihood -1.410861
[ Info: iteration 37, average log likelihood -1.410853
[ Info: iteration 38, average log likelihood -1.410845
[ Info: iteration 39, average log likelihood -1.410838
[ Info: iteration 40, average log likelihood -1.410831
[ Info: iteration 41, average log likelihood -1.410824
[ Info: iteration 42, average log likelihood -1.410818
[ Info: iteration 43, average log likelihood -1.410812
[ Info: iteration 44, average log likelihood -1.410806
[ Info: iteration 45, average log likelihood -1.410801
[ Info: iteration 46, average log likelihood -1.410796
[ Info: iteration 47, average log likelihood -1.410791
[ Info: iteration 48, average log likelihood -1.410787
[ Info: iteration 49, average log likelihood -1.410783
[ Info: iteration 50, average log likelihood -1.410778
┌ Info: EM with 100000 data points 50 iterations avll -1.410778
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4120657064785547
│     -1.4120039228442935
│      ⋮
└     -1.4107782820317005
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410784
[ Info: iteration 2, average log likelihood -1.410728
[ Info: iteration 3, average log likelihood -1.410680
[ Info: iteration 4, average log likelihood -1.410627
[ Info: iteration 5, average log likelihood -1.410565
[ Info: iteration 6, average log likelihood -1.410490
[ Info: iteration 7, average log likelihood -1.410403
[ Info: iteration 8, average log likelihood -1.410305
[ Info: iteration 9, average log likelihood -1.410201
[ Info: iteration 10, average log likelihood -1.410095
[ Info: iteration 11, average log likelihood -1.409991
[ Info: iteration 12, average log likelihood -1.409892
[ Info: iteration 13, average log likelihood -1.409800
[ Info: iteration 14, average log likelihood -1.409716
[ Info: iteration 15, average log likelihood -1.409640
[ Info: iteration 16, average log likelihood -1.409572
[ Info: iteration 17, average log likelihood -1.409511
[ Info: iteration 18, average log likelihood -1.409457
[ Info: iteration 19, average log likelihood -1.409410
[ Info: iteration 20, average log likelihood -1.409367
[ Info: iteration 21, average log likelihood -1.409330
[ Info: iteration 22, average log likelihood -1.409296
[ Info: iteration 23, average log likelihood -1.409265
[ Info: iteration 24, average log likelihood -1.409237
[ Info: iteration 25, average log likelihood -1.409212
[ Info: iteration 26, average log likelihood -1.409189
[ Info: iteration 27, average log likelihood -1.409168
[ Info: iteration 28, average log likelihood -1.409148
[ Info: iteration 29, average log likelihood -1.409129
[ Info: iteration 30, average log likelihood -1.409112
[ Info: iteration 31, average log likelihood -1.409096
[ Info: iteration 32, average log likelihood -1.409080
[ Info: iteration 33, average log likelihood -1.409065
[ Info: iteration 34, average log likelihood -1.409051
[ Info: iteration 35, average log likelihood -1.409038
[ Info: iteration 36, average log likelihood -1.409025
[ Info: iteration 37, average log likelihood -1.409012
[ Info: iteration 38, average log likelihood -1.409000
[ Info: iteration 39, average log likelihood -1.408988
[ Info: iteration 40, average log likelihood -1.408977
[ Info: iteration 41, average log likelihood -1.408965
[ Info: iteration 42, average log likelihood -1.408954
[ Info: iteration 43, average log likelihood -1.408943
[ Info: iteration 44, average log likelihood -1.408932
[ Info: iteration 45, average log likelihood -1.408921
[ Info: iteration 46, average log likelihood -1.408910
[ Info: iteration 47, average log likelihood -1.408899
[ Info: iteration 48, average log likelihood -1.408888
[ Info: iteration 49, average log likelihood -1.408878
[ Info: iteration 50, average log likelihood -1.408867
┌ Info: EM with 100000 data points 50 iterations avll -1.408867
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.410784167716747
│     -1.4107279450626553
│      ⋮
└     -1.4088670729871156
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408864
[ Info: iteration 2, average log likelihood -1.408791
[ Info: iteration 3, average log likelihood -1.408722
[ Info: iteration 4, average log likelihood -1.408642
[ Info: iteration 5, average log likelihood -1.408543
[ Info: iteration 6, average log likelihood -1.408420
[ Info: iteration 7, average log likelihood -1.408273
[ Info: iteration 8, average log likelihood -1.408105
[ Info: iteration 9, average log likelihood -1.407924
[ Info: iteration 10, average log likelihood -1.407739
[ Info: iteration 11, average log likelihood -1.407560
[ Info: iteration 12, average log likelihood -1.407394
[ Info: iteration 13, average log likelihood -1.407245
[ Info: iteration 14, average log likelihood -1.407115
[ Info: iteration 15, average log likelihood -1.407002
[ Info: iteration 16, average log likelihood -1.406905
[ Info: iteration 17, average log likelihood -1.406820
[ Info: iteration 18, average log likelihood -1.406747
[ Info: iteration 19, average log likelihood -1.406682
[ Info: iteration 20, average log likelihood -1.406624
[ Info: iteration 21, average log likelihood -1.406573
[ Info: iteration 22, average log likelihood -1.406526
[ Info: iteration 23, average log likelihood -1.406484
[ Info: iteration 24, average log likelihood -1.406445
[ Info: iteration 25, average log likelihood -1.406409
[ Info: iteration 26, average log likelihood -1.406375
[ Info: iteration 27, average log likelihood -1.406343
[ Info: iteration 28, average log likelihood -1.406314
[ Info: iteration 29, average log likelihood -1.406286
[ Info: iteration 30, average log likelihood -1.406259
[ Info: iteration 31, average log likelihood -1.406233
[ Info: iteration 32, average log likelihood -1.406209
[ Info: iteration 33, average log likelihood -1.406186
[ Info: iteration 34, average log likelihood -1.406163
[ Info: iteration 35, average log likelihood -1.406142
[ Info: iteration 36, average log likelihood -1.406121
[ Info: iteration 37, average log likelihood -1.406100
[ Info: iteration 38, average log likelihood -1.406081
[ Info: iteration 39, average log likelihood -1.406061
[ Info: iteration 40, average log likelihood -1.406043
[ Info: iteration 41, average log likelihood -1.406024
[ Info: iteration 42, average log likelihood -1.406007
[ Info: iteration 43, average log likelihood -1.405989
[ Info: iteration 44, average log likelihood -1.405972
[ Info: iteration 45, average log likelihood -1.405956
[ Info: iteration 46, average log likelihood -1.405940
[ Info: iteration 47, average log likelihood -1.405924
[ Info: iteration 48, average log likelihood -1.405909
[ Info: iteration 49, average log likelihood -1.405894
[ Info: iteration 50, average log likelihood -1.405879
┌ Info: EM with 100000 data points 50 iterations avll -1.405879
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4088643030459902
│     -1.4087909359116015
│      ⋮
└     -1.4058790761972555
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4183396397397092
│     -1.4183581171183806
│     -1.418294667213438
│     -1.4182498842355846
│      ⋮
│     -1.4059085225154846
│     -1.4058936020152295
└     -1.4058790761972555
32×26 Array{Float64,2}:
  0.0971704  -0.111551     0.341925    0.52133     0.157604    -0.389822     0.168473   -0.00348358  -0.252311    0.0365447   0.00706048   0.235501   -0.24405     0.177528     -0.00776402   0.266542   -0.341435     0.40304     0.145615      0.0409719   0.069146   -0.0810208   0.0128206   -0.796835   -0.588907    0.250562
 -0.178097   -0.0307964    0.182256    0.28186     0.0118994    0.0311429    0.1937     -0.308317    -0.663315   -0.187197   -0.202951     0.0601669  -0.2127     -0.159743     -0.38494     -0.0389703  -0.117314     0.103443    0.313703     -0.110647    0.268948    0.171564   -0.220777     0.375171   -0.791317    0.0269332
  0.133914    0.0148194   -0.0711717  -0.025561   -0.082478    -0.00893959   0.0148502   0.12199     -0.13343     0.14846     0.0174294    0.0661432  -0.0229599   0.0360944    -0.112277     0.0894099   0.0279419    0.0491114  -0.000337333  -0.082883   -0.136556   -0.0907211   0.0145173    0.125444   -0.03014    -0.141101
 -0.319333   -0.00220035   0.101077    0.180609    0.146814     0.0650735   -0.0929255  -0.0585384    0.302189   -0.0998658   0.0755199   -0.130505    0.0450815  -0.112586      0.194034    -0.0199089  -0.112141     0.0996252   0.0111522    -0.0503368   0.307922    0.0667446  -0.0101314   -0.0836774   0.125445    0.125968
  0.0951428   0.254399    -0.18624     0.369557    0.141933    -0.0360955   -0.0738216  -0.23834     -0.0549627  -0.106861   -0.0868632   -0.633383    0.124267    0.601582     -0.148615    -0.366593    0.34029     -0.0178284  -0.277209      0.546219    0.113223    0.574991   -0.0549434   -0.208386   -0.211013    0.0457083
  0.0644438   0.766853    -0.114548    0.513476    0.232764     0.0716424    0.193463   -0.154923    -0.396863    0.885812   -0.290712    -0.200303   -0.0664417   0.285778     -0.414054     0.197013    0.146394    -0.193418   -0.417253     -0.0356409  -0.222835    0.0154603   0.587169    -0.202725   -0.295378   -0.0233104
 -0.344471   -0.034895    -0.722791   -0.219135   -0.237638     0.0878063    0.0228659   0.266958    -0.216653    0.123041   -0.38288      0.553183   -0.0928455   0.162148     -0.877277     0.519457   -0.564033    -0.225598   -0.257415      0.0569513  -0.116885    0.154913    0.084517     0.550431   -0.131998    0.31267
 -0.264709   -0.0643935    0.448851   -0.127163    0.226238     0.00591717  -0.0335382   0.318286     0.106132    0.323421    0.313151     1.18521    -0.0562435   0.389462      0.0481194   -0.35967     0.385349     0.251755   -0.391159      0.295051   -0.45753     0.265998   -0.0130656   -0.136534   -0.474717    0.303947
 -0.112005    0.186198    -0.217027    0.292055    0.0161387    0.279774     0.119158   -0.768293    -0.0697341  -0.127059    0.359812    -1.18771     0.0965667  -0.361884      0.289192     0.421991    0.0470864   -0.356216    0.485636      0.0877949   0.130752   -0.273853    0.671499     0.305414    0.451509   -0.276988
 -0.475424    0.401942    -0.11614    -0.0175925  -0.0662651    0.411108    -0.346121    0.385127    -0.0192175   0.0748441   0.033211    -0.190059    0.299001   -0.362435      0.519095    -0.0812906   0.300805    -0.340729    0.285856     -0.103809   -0.240656    0.480451    0.0604561    0.251639    0.176755   -0.664534
  0.0969447   0.49383      0.120477   -0.598298    0.0863574    0.0184774    0.477806   -0.304336    -0.208267   -0.639291    0.254752     0.0520481  -0.449421   -0.220359      0.00282381   0.0326481   0.0637879   -0.174974   -0.295979     -0.184925    0.361811   -0.423937   -0.614015     0.411916    0.411478   -0.147407
 -0.254411   -0.143684    -0.369471   -0.588119    0.475409     0.0109038    0.346337    0.160939    -0.0987528  -0.0155559  -0.0344223   -0.0541077  -0.26379    -0.113586     -0.0266949   -0.239955    0.0389886   -0.106275    0.0395734     0.410615    0.354315   -0.317547    0.484198     0.262023    0.433274    0.126601
  0.938718   -0.0888548    0.291755   -0.0119044   0.0250361   -0.108989    -0.422731    0.260785     0.607665    0.25591     0.209137    -0.0922906  -0.129471   -0.266725      0.23896     -0.047657    0.00641167   0.012145    0.234658     -0.584659    0.150031   -0.574355    0.128434    -0.0262407   0.103699   -0.347704
  0.485022    0.038094    -0.50067    -0.239724    0.0387601   -0.287212    -0.320887    0.468974     0.311249    0.509461   -0.0309866    0.0234449   0.433071    0.296299      0.0716346    0.105998   -0.243374     0.168251   -0.165338      0.288972   -0.0338501  -0.37092     0.563781    -0.679911    0.24878     0.0724914
  0.427678   -0.419105     0.112891   -0.0692868   0.00356876  -0.435077     0.027406    0.455208     0.299247   -0.58138    -0.00442787   0.0344476  -0.122601   -0.280376      0.425705    -0.415414    0.307455    -0.0853607   0.393848      0.0744903  -0.353206    0.127013   -0.353972     0.216802    0.420366   -0.17745
  0.750067   -0.321132    -0.13426    -0.0581171  -0.541225    -0.165914    -0.0456751  -0.174618     0.306657    0.72176     0.0923224   -0.165514    0.329104    0.268603     -0.108164    -0.0719802  -0.0860874   -0.375703   -0.109142      0.0559411  -0.668819    0.11765    -0.00917058   0.78227     0.0546252   0.0557262
  0.450272    0.786147    -0.232642   -0.0814205  -0.601751    -0.474442    -0.20918     0.0683981   -0.886023   -0.394109    0.536325     0.184748    0.217197    0.321021      0.142638     0.132829   -0.328001     0.0508078   0.0170009     0.131739   -0.402786   -0.254314   -0.412206     0.0659465  -0.313233   -0.270581
  0.268173   -0.0590389    0.260389    0.157217   -0.592534    -0.243576    -0.45914    -0.284241     0.381931   -0.385398   -0.15846     -0.0316661   0.0866881   0.138523      0.207501     0.442942    0.00280778  -0.744207   -0.0529657    -0.0953059   0.0787843   0.583887   -0.21503      0.345036   -0.298852    0.0379048
 -0.345475    0.442019    -0.2589      0.347046    0.161945    -0.216285     0.568778    0.260604    -0.254913   -0.145015    0.0225115    0.276051    0.302346   -0.530346     -0.168614     0.226052    0.20897      0.515504   -0.114479     -0.958615   -0.50773     0.20916    -0.147368    -0.0233835   0.772087   -0.0523182
 -0.584213    0.523018    -0.0619979   0.17362    -0.310283    -0.115908     0.364433   -0.195702    -0.57305    -0.362706   -0.166879    -0.142987   -0.21185    -0.101303      0.114755    -0.127783    0.276529    -0.0638124  -0.500596      0.289369   -1.12676     0.615623   -0.795254     0.535       0.352423    0.420096
 -0.798757    0.225803    -0.637319   -0.181147    0.0260372    0.356768    -0.0604638  -0.133693     0.228682   -0.47223     0.182442    -0.221818    0.221055    0.000215035  -0.46188      0.0858511  -0.00806725  -0.50072    -0.0645448     0.202387    0.424096    0.703314    0.218174     0.506838    0.19078    -0.00270907
 -0.704549   -0.623232     0.0199197   0.347741    0.699799     0.363934    -0.0720378   0.266973     0.786413    0.375968   -0.393647    -0.527918   -0.11433    -0.477081     -0.195275    -0.326751    0.476578     0.0683811   0.14105       0.242554    0.473868    0.289478    0.468564    -0.3585      0.345999   -0.0809688
 -0.0780372   0.159058     0.254107    0.533646   -0.116724    -0.0311669    0.105065   -0.0866071   -0.0968454   0.0880247   0.0320312    0.19528     0.0325901   0.189825      0.324798     0.474545    0.0128572   -0.179269    0.136185     -0.171557   -0.219964    0.271733    0.0710204   -0.222802   -0.545119   -0.0690505
  0.640292    0.387161     0.0469456   0.282746   -0.443943    -0.0553854   -0.696617    0.312508     0.141747    0.301144   -0.13697     -0.529305    0.247925   -0.597389      0.0305462   -0.481246    0.238991     0.0389649   0.0634143    -0.0177723  -0.227919   -0.27457    -0.200692     0.162515    0.423451   -0.227803
 -0.230993   -0.00086355   0.412344   -0.197002   -0.176559     0.0883378   -0.413044    0.0828238    0.123553   -0.968362    0.678951     0.231576    0.138354   -0.713013      0.534059    -0.277381   -0.564383     0.114902    0.172846     -0.124804    0.564357   -0.0980586  -0.312508    -0.16801     0.1312      0.309163
 -0.381286    0.0643716    0.665436    0.0699238   0.00872021   0.395044    -0.293865    0.0167511    0.152883    0.434972    0.0218624    0.33594    -0.0410789  -0.276314      0.0797683    0.15137    -0.417543     0.244313   -0.3241       -0.512993    0.711054   -0.376388    0.111814    -0.017005   -0.163247    0.245068
 -0.505742   -0.479788    -0.199177   -0.03282    -0.00916297  -0.0503253    0.392218    0.132543    -0.296158   -0.0646985   0.264157     0.309104   -0.219939    0.0285723    -0.0531516    0.435266    0.0628978    0.387444    0.820119     -0.523112    0.184182    0.121257    0.426195    -0.0026775  -0.0551062  -0.633561
  0.313149   -0.548005    -0.0652745  -0.0835613   0.437556     0.405068     0.50321    -0.163237     0.981902   -0.270407    0.405919    -0.295263    0.148793    0.673847      0.0414684    0.637875   -0.258765    -0.200606   -0.157086     -0.795338    0.0866363  -0.267403   -0.11402      0.0173703   0.274402   -0.182676
  0.352898   -0.364359    -0.12641    -0.300634    0.483558    -0.400379     0.507567    0.00436924  -0.106732    0.195806   -0.17226      0.0753592  -0.365316    0.402954     -0.352558    -0.100768   -0.120651     0.39992    -0.233631      0.24001     0.301874   -0.507107    0.127236    -0.104482    0.0134445   0.237689
 -0.118981   -0.12714     -0.0360537  -0.732293    0.0720105   -0.341403    -0.0498493  -0.168016    -0.186263    0.209926   -0.272004    -0.0336445  -0.0731985   0.585202      0.861579     0.335769   -0.134316    -0.264333    0.278133      0.874235    0.628804   -0.0155464  -0.311408    -0.027935   -0.734095    0.245348
  0.0604669  -0.269017    -0.370897   -0.917772   -0.157705     0.239905    -0.253653   -0.259926     0.0684181   0.0620822   0.0599624   -0.286479    0.0141748  -0.157855      0.215216    -0.952308    0.300437     0.238507    0.475226      0.335254    0.261444   -0.0866817  -0.452642     0.923652    0.219806    0.0157225
  0.124466   -0.409282     0.149762    0.410103    0.227469     0.0124976    0.328128   -0.102455    -0.469507    0.168932   -0.277741    -0.661671   -0.448274   -0.328332      0.192508    -0.696583    0.198738     0.60447     0.333407      0.217954   -0.444495   -0.705319    0.0165916   -0.110365    0.366114   -0.182542[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405865
[ Info: iteration 2, average log likelihood -1.405851
[ Info: iteration 3, average log likelihood -1.405838
[ Info: iteration 4, average log likelihood -1.405825
[ Info: iteration 5, average log likelihood -1.405812
[ Info: iteration 6, average log likelihood -1.405800
[ Info: iteration 7, average log likelihood -1.405788
[ Info: iteration 8, average log likelihood -1.405776
[ Info: iteration 9, average log likelihood -1.405765
[ Info: iteration 10, average log likelihood -1.405754
┌ Info: EM with 100000 data points 10 iterations avll -1.405754
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.358033e+05
      1       6.970192e+05      -2.387841e+05 |       32
      2       6.845255e+05      -1.249373e+04 |       32
      3       6.801715e+05      -4.353996e+03 |       32
      4       6.778675e+05      -2.303963e+03 |       32
      5       6.762935e+05      -1.573980e+03 |       32
      6       6.751463e+05      -1.147200e+03 |       32
      7       6.742224e+05      -9.239056e+02 |       32
      8       6.734524e+05      -7.700245e+02 |       32
      9       6.727457e+05      -7.066955e+02 |       32
     10       6.721468e+05      -5.989434e+02 |       32
     11       6.716485e+05      -4.983083e+02 |       32
     12       6.712190e+05      -4.294680e+02 |       32
     13       6.708695e+05      -3.495171e+02 |       32
     14       6.705657e+05      -3.037659e+02 |       32
     15       6.703144e+05      -2.513522e+02 |       32
     16       6.700779e+05      -2.364527e+02 |       32
     17       6.698547e+05      -2.232269e+02 |       32
     18       6.696506e+05      -2.040511e+02 |       32
     19       6.694973e+05      -1.533050e+02 |       32
     20       6.693564e+05      -1.409096e+02 |       32
     21       6.692310e+05      -1.254028e+02 |       32
     22       6.691264e+05      -1.046325e+02 |       32
     23       6.690318e+05      -9.457386e+01 |       32
     24       6.689278e+05      -1.040175e+02 |       32
     25       6.688172e+05      -1.105671e+02 |       32
     26       6.687082e+05      -1.090727e+02 |       32
     27       6.685991e+05      -1.090289e+02 |       32
     28       6.684955e+05      -1.036618e+02 |       32
     29       6.683874e+05      -1.080803e+02 |       32
     30       6.682731e+05      -1.143088e+02 |       32
     31       6.681750e+05      -9.809821e+01 |       32
     32       6.680813e+05      -9.369387e+01 |       32
     33       6.679971e+05      -8.419354e+01 |       32
     34       6.679201e+05      -7.698233e+01 |       32
     35       6.678557e+05      -6.445268e+01 |       32
     36       6.677993e+05      -5.634869e+01 |       32
     37       6.677519e+05      -4.744202e+01 |       32
     38       6.677051e+05      -4.672921e+01 |       32
     39       6.676560e+05      -4.911957e+01 |       32
     40       6.676050e+05      -5.100693e+01 |       32
     41       6.675547e+05      -5.031675e+01 |       32
     42       6.675164e+05      -3.825666e+01 |       32
     43       6.674780e+05      -3.844178e+01 |       32
     44       6.674391e+05      -3.885231e+01 |       32
     45       6.674040e+05      -3.517577e+01 |       32
     46       6.673673e+05      -3.666384e+01 |       32
     47       6.673280e+05      -3.927589e+01 |       32
     48       6.672947e+05      -3.336147e+01 |       32
     49       6.672640e+05      -3.067138e+01 |       32
     50       6.672351e+05      -2.884808e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 667235.1426175558)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417479
[ Info: iteration 2, average log likelihood -1.412585
[ Info: iteration 3, average log likelihood -1.411373
[ Info: iteration 4, average log likelihood -1.410571
[ Info: iteration 5, average log likelihood -1.409696
[ Info: iteration 6, average log likelihood -1.408721
[ Info: iteration 7, average log likelihood -1.407882
[ Info: iteration 8, average log likelihood -1.407348
[ Info: iteration 9, average log likelihood -1.407059
[ Info: iteration 10, average log likelihood -1.406891
[ Info: iteration 11, average log likelihood -1.406777
[ Info: iteration 12, average log likelihood -1.406687
[ Info: iteration 13, average log likelihood -1.406611
[ Info: iteration 14, average log likelihood -1.406544
[ Info: iteration 15, average log likelihood -1.406483
[ Info: iteration 16, average log likelihood -1.406427
[ Info: iteration 17, average log likelihood -1.406376
[ Info: iteration 18, average log likelihood -1.406329
[ Info: iteration 19, average log likelihood -1.406286
[ Info: iteration 20, average log likelihood -1.406246
[ Info: iteration 21, average log likelihood -1.406209
[ Info: iteration 22, average log likelihood -1.406176
[ Info: iteration 23, average log likelihood -1.406144
[ Info: iteration 24, average log likelihood -1.406115
[ Info: iteration 25, average log likelihood -1.406088
[ Info: iteration 26, average log likelihood -1.406063
[ Info: iteration 27, average log likelihood -1.406040
[ Info: iteration 28, average log likelihood -1.406018
[ Info: iteration 29, average log likelihood -1.405997
[ Info: iteration 30, average log likelihood -1.405977
[ Info: iteration 31, average log likelihood -1.405959
[ Info: iteration 32, average log likelihood -1.405941
[ Info: iteration 33, average log likelihood -1.405924
[ Info: iteration 34, average log likelihood -1.405908
[ Info: iteration 35, average log likelihood -1.405893
[ Info: iteration 36, average log likelihood -1.405878
[ Info: iteration 37, average log likelihood -1.405864
[ Info: iteration 38, average log likelihood -1.405850
[ Info: iteration 39, average log likelihood -1.405837
[ Info: iteration 40, average log likelihood -1.405824
[ Info: iteration 41, average log likelihood -1.405811
[ Info: iteration 42, average log likelihood -1.405799
[ Info: iteration 43, average log likelihood -1.405787
[ Info: iteration 44, average log likelihood -1.405775
[ Info: iteration 45, average log likelihood -1.405763
[ Info: iteration 46, average log likelihood -1.405752
[ Info: iteration 47, average log likelihood -1.405740
[ Info: iteration 48, average log likelihood -1.405729
[ Info: iteration 49, average log likelihood -1.405717
[ Info: iteration 50, average log likelihood -1.405706
┌ Info: EM with 100000 data points 50 iterations avll -1.405706
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.312464    0.250202   -0.00148761   -0.0451351  -0.0877619   0.108046   -0.362755      0.0440004    0.530709     0.0393075    0.257797     -0.532208     0.115677   -0.242375    0.445626     0.0268191    0.108563    -0.218793     0.0317426   -0.285363    -0.0636756   -0.301292    0.267572    -0.00862989   0.728012    -0.182335
 -0.0902007  -0.0471802  -0.281494     -0.848284   -0.47455     0.240993   -0.282152     -0.22956      0.587455     0.183092    -0.000349761  -0.256739     0.609891    0.0629256   0.578924    -0.728341     0.219287     0.286299     0.633511     0.41073      0.102959     0.145863   -0.814366     1.04858      0.22235      0.469488
 -0.605569    0.79597    -0.201359      0.155755    0.134887   -0.183102    0.187295      0.521956    -0.905031     0.129029    -0.431487      0.261372     0.10332    -0.415737    0.0182332    0.052811     0.0888337    0.164064    -0.105265     0.177248    -0.729148     0.134401   -0.243966    -0.174281     0.234713     0.12793
  0.0947503  -0.128485    0.000876163  -0.0418654  -0.0261068  -0.143785    0.0114264    -0.135082     0.176216    -0.0154618   -0.00827507   -0.00130198  -0.108197    0.271827   -0.0379573    0.143593    -0.0568703   -0.10084     -0.0997147    0.0506174    0.161749     0.0245954  -0.0553978    0.0928664   -0.143025     0.167407
  0.0670829   0.187264   -0.379        -0.187214    0.791959   -0.432651    0.190333      0.0836833    0.683851     0.852775    -0.562898     -0.0127002    0.518218    0.51537     0.164082     0.38103      0.00491593  -0.398382    -0.345762     0.0490303   -0.0494777    0.180333    0.211724    -0.0470737    0.112825    -0.0116632
 -0.34957     0.12778     0.274725      0.802737   -0.698348    0.125619    0.0341805    -0.317628     0.154574    -0.119938     0.276851     -0.344854     0.19884    -0.0902204   0.517937     0.452226     0.237562    -0.542474    -0.123887    -0.307164    -0.566136     1.04506     0.109647     0.309192    -0.0566365   -0.0340674
 -0.173784   -0.113319    0.379367     -0.265891   -0.359032    0.181749   -0.604739      0.262725     0.215986    -0.621332     0.791141      0.497247     0.0736253  -0.659154    0.459235    -0.0742576   -0.652694     0.0373817    0.0558831   -0.0595113    0.523437    -0.164354   -0.19747     -0.249977    -0.0688804    0.328986
  0.402125   -0.271038   -0.0351358    -0.631834    0.591393   -0.195264    0.493369      0.18177     -0.00568688   0.321484     0.150756      0.138774    -0.248213    0.287661   -0.0279205   -0.0128522   -0.288842     0.415439    -0.119516     0.00206067   0.561899    -0.812792   -0.0740925   -0.327222    -0.0771846   -0.0844674
 -0.506695    0.166613    0.294448      0.18708     0.297118    0.437714   -0.0812637    -0.177611     0.299283     0.0118087   -0.0865056    -0.0828765    0.0211104  -0.171647   -0.147047    -0.00153488  -0.265751     0.115874    -0.35262     -0.383542     0.928818    -0.0465546   0.228465    -0.0401279   -0.0972467    0.254984
 -0.697281   -0.0636953   0.150454     -0.333775    0.398105    0.165576    0.361732     -0.0580046   -0.250981     0.193972     0.505471      0.633494    -0.154821    0.346433    0.0804631   -0.124848     0.291877     0.00972198  -0.185643     0.532349    -0.343253     0.3745      0.370495    -0.0413856   -0.240181     0.180118
  0.498815    0.553697   -0.572063     -0.370107   -0.40819    -0.881234   -0.000220998   0.101405    -0.485567    -0.456768     0.306645     -0.0631386    0.44048     0.781111    0.4969       0.258247    -0.201137    -0.268672     0.0751322    0.281982    -0.28003      0.0249806  -0.23258     -0.0684557   -0.189562    -0.155626
 -0.258353    0.167747   -0.22606      -0.0258133  -0.0865803  -0.0169295  -0.146818      0.139304     0.0220565   -0.354793    -0.222277     -0.0734528    0.021165   -0.136163    0.0506015   -0.104506     0.26047     -0.446782    -0.0751986    0.421332    -0.00220879   0.427588    0.0183729    0.24076      0.00912435   0.00889418
 -0.583563    0.203916   -0.614341     -0.0970274   0.235016    0.523017   -0.164056     -0.0102898    0.161351    -0.271776     0.31934      -0.633328     0.434237   -0.163565   -0.315269    -0.167067    -0.0322403   -0.635175     0.267277     0.262034     0.131055     0.769106    0.0479485    0.410148     0.339164    -0.655177
  0.524247   -0.268641    0.39274       0.281719    0.0437423  -0.349142   -0.104736     -0.404657     0.214514    -0.080475     0.0636961    -0.109063    -0.349734    0.132471    0.165918     0.209554    -0.0091677   -0.166481     0.488596    -0.349943     0.382337     0.134886   -0.0536906   -0.142678    -0.50681     -0.227388
  0.210566    0.679161    0.499453      0.714928    0.34946    -0.571308    0.164399     -0.0573304   -0.296067     0.158387     0.265127      0.016828     0.471209    0.149148   -0.144452    -0.191169    -0.175562     0.227338    -0.306791     0.491236    -0.13174      0.0285657  -0.272674    -0.486588    -0.702711     0.324976
  0.150707   -0.689453    0.0770186    -0.340525    0.0921526  -0.337958    0.138068      0.557146     0.341996    -0.419986    -0.013568      0.206966    -0.0575442  -0.228472    0.531478    -0.249034     0.0717806    0.1375       0.421291    -0.0869664   -0.178117     0.0124558  -0.451076     0.303784     0.429383    -0.252281
  0.283218    0.0111782   0.306493      0.0169746  -0.279657    0.272476    0.372602      0.0140945   -0.272445     0.442414     0.176688      0.634747     0.16418    -0.0455751   0.431701     0.335712    -0.357749    -0.14901      0.324339    -0.908407    -0.426868    -0.340788    0.243818     0.357931    -0.345993    -0.515672
  0.844876    0.296459    0.14007      -0.027671   -0.57277    -0.259584   -1.07602       0.298976    -0.00149022   0.294488    -0.0718536    -0.143555     0.0954789  -0.49659    -0.121702    -0.31049      0.0522062   -0.00703642   0.0644841   -0.109876    -0.0568725   -0.274721   -0.310156     0.281467     0.00231595  -0.387899
  0.342908    0.570376   -0.177928      0.443932    0.0121033   0.0369513   0.209533     -0.284569    -0.725567     0.522487    -0.337792     -0.491015    -0.370767    0.295538   -0.746238    -0.119241     0.297159    -0.0784684   -0.373631     0.00798064  -0.307152     0.0543605   0.38148     -0.00176862  -0.35366     -0.0265322
  0.0092828   0.0270151   9.88046e-5    0.0306221   0.0475405  -0.012223    0.0492884     0.0406974   -0.0961187    0.0851946    0.0444349     0.00146063  -0.0347356  -0.0333352  -0.0529357    0.0247162   -0.0454751    0.106738     0.030622    -0.0711646    0.0328876   -0.0916267   0.0230327    0.0439547   -0.0212845   -0.0547439
  0.221281   -0.319702   -0.19398       0.404275   -0.040977   -0.251186   -0.112851      0.549616     0.140034     0.69326      0.280671      0.344085     0.0861062   0.186486   -0.331916     0.516867    -0.407838     0.0361554    0.0462684   -0.170058     0.173955    -0.37881     1.44558     -0.730158    -0.0514256   -0.267821
  0.298801   -0.323491   -0.0929909     0.392813   -0.346024    0.259634   -0.472115      0.140943     0.26198      0.522874    -0.0383509     0.0280724    0.195605    0.530692    0.00599774  -0.00603152   0.17681      0.238868    -0.0915044    0.416859    -0.420765     0.216      -0.089285    -0.167889    -0.381817     0.0523037
  0.0513003  -0.260128   -0.37104      -0.855232    0.293463   -0.0847687   0.0297934     0.00892425   0.0397978    0.149227     0.0281401    -0.238236    -0.338488   -0.265972   -0.222637    -0.437965     0.185116    -0.151332     0.00877317   0.452048     0.455167    -0.548325    0.651122     0.498874     0.689879     0.345182
  0.174876   -0.294224    0.780398      0.471593    0.0410919  -0.624613    0.0612089     0.160939     0.161371     0.134626    -0.190699      0.233105    -0.478751   -0.121125    0.606664    -0.396457     0.330936     0.619211     0.138579    -0.0593699   -0.113301    -0.479102   -0.0284701   -0.578516    -0.315267     0.614563
 -0.124476    0.524513    0.20142      -0.4202     -0.0833212   0.150811    0.301698     -0.452942    -0.348978    -0.766529     0.180866      0.0683915   -0.502709   -0.313109    0.145906    -0.188738     0.233322    -0.0188354   -0.155759    -0.236326    -0.0295818   -0.0602277  -1.13811      0.62632      0.265432    -0.0454712
 -0.274255    0.0023734  -0.0120774    -0.185295    0.11877    -0.0850301  -0.0812162    -0.430721    -0.914061    -0.0928593   -0.405799     -0.0192969   -0.31763     0.11228     0.121488     0.202784    -0.226409     0.0319668    0.653315     0.590685     0.860065     0.256427    0.00526535  -0.00926418  -1.06124      0.235166
 -0.193502   -0.426254   -0.164292      0.271175    0.674734    0.728123    0.865436     -0.124964     0.751679    -0.697776     0.203904     -0.410617    -0.101347    0.717354    0.0679735    0.518013    -0.176475    -0.121592    -0.258574    -0.404964     0.0649225    0.0465348   0.045862    -0.0687435   -0.0153866    0.0954883
  0.263743   -0.338349   -0.0341928     0.450596    0.288801    0.173345    0.472786     -0.17559     -0.41811     -0.0515847   -0.0783232    -0.94117     -0.257716   -0.348629    0.27432     -0.611469     0.129286     0.372945     0.471491     0.364918    -0.452855    -0.646729    0.0917474    0.107433     0.516034    -0.317638
  0.270214    0.128729   -0.308056      0.309256   -0.0855797  -0.124047    0.3955        0.214618     0.349615    -0.0964945    0.470079      0.313155     0.113323   -0.439098   -0.690975     0.0639727    0.249857     0.479068    -0.494518    -1.01584     -0.561953    -0.0351658  -0.136531     0.2029       1.28035     -0.257483
 -0.650704   -0.627335   -0.320265     -0.0459452   0.143885    0.273591    0.101914      0.222873     0.120912    -0.00153419  -0.335146     -0.377588    -0.260878   -0.399428   -0.139446    -0.126155     0.558977     0.385783     0.730062    -0.137492     0.54503      0.15039     0.557097     0.116597     0.452907    -0.547417
 -0.787625    0.224655    0.0521151     0.549598    0.185175    0.0830488   0.205581      0.0982652   -0.473454    -0.115609     0.0224015     0.290684     0.173308   -0.16759     0.0673502    0.353141    -0.0877139    0.659483     0.508286    -0.459633     0.0770001    0.0617886  -0.0190248   -0.223851    -0.141882    -0.364293
 -0.154254   -0.172733   -0.386195     -0.128124   -0.403284   -0.0800309   0.169524      0.010723    -0.332942    -0.061688    -0.264749      0.409681    -0.173748    0.166721   -0.815756     0.332593    -0.606763    -0.222477    -0.24137     -0.0269685   -0.106786     0.153042   -0.111469     0.577834    -0.189215     0.381147[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405694
[ Info: iteration 2, average log likelihood -1.405683
[ Info: iteration 3, average log likelihood -1.405671
[ Info: iteration 4, average log likelihood -1.405659
[ Info: iteration 5, average log likelihood -1.405648
[ Info: iteration 6, average log likelihood -1.405636
[ Info: iteration 7, average log likelihood -1.405623
[ Info: iteration 8, average log likelihood -1.405611
[ Info: iteration 9, average log likelihood -1.405599
[ Info: iteration 10, average log likelihood -1.405587
┌ Info: EM with 100000 data points 10 iterations avll -1.405587
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
