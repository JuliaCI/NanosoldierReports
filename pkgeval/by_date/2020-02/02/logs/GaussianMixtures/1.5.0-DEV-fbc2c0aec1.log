Julia Version 1.5.0-DEV.221
Commit fbc2c0aec1 (2020-02-01 18:55 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed DataAPI ──────────── v1.1.0
  Installed GaussianMixtures ─── v0.3.0
  Installed Rmath ────────────── v0.6.0
  Installed ScikitLearnBase ──── v0.5.0
  Installed OrderedCollections ─ v1.1.0
  Installed Parameters ───────── v0.12.0
  Installed DataStructures ───── v0.17.9
  Installed BinaryProvider ───── v0.5.8
  Installed Blosc ────────────── v0.5.1
  Installed URIParser ────────── v0.4.0
  Installed QuadGK ───────────── v2.3.1
  Installed SortingAlgorithms ── v0.3.1
  Installed Arpack_jll ───────── v3.5.0+2
  Installed FillArrays ───────── v0.8.4
  Installed HDF5 ─────────────── v0.12.5
  Installed StatsBase ────────── v0.32.0
  Installed JLD ──────────────── v0.9.2
  Installed Arpack ───────────── v0.4.0
  Installed NearestNeighbors ─── v0.4.4
  Installed StatsFuns ────────── v0.9.3
  Installed PDMats ───────────── v0.9.11
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed StaticArrays ─────── v0.12.1
  Installed Missings ─────────── v0.4.3
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed CMake ────────────── v1.1.2
  Installed Compat ───────────── v2.2.0
  Installed LegacyStrings ────── v0.4.1
  Installed Clustering ───────── v0.13.3
  Installed Distances ────────── v0.8.2
  Installed FileIO ───────────── v1.2.1
  Installed BinDeps ──────────── v1.0.0
  Installed CMakeWrapper ─────── v0.2.3
  Installed SpecialFunctions ─── v0.9.0
  Installed Distributions ────── v0.22.4
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                         ##                                                                         2.8%######                                                                     9.2%############                                                              16.8%###################                                                       27.5%#########################                                                 35.9%#####################################                                     51.6%###################################################                       71.1%#####################################################################     96.8%######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_8CyIOM/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -1.0812000734176235e6, [126.68428600225664, 99873.31571399776], [-188.46326004770356 -50.38485264683023 -350.66320801498983; 343.49839561587817 417.74809616238446 -198.6803591364343], [[383.34651961834163 83.10586862475017 491.9848360996053; 83.10586862475019 124.73431280799481 97.7458981851921; 491.9848360996053 97.74589818519212 1000.4859625088826], [99889.6787615732 291.4470480271032 -475.08978229511496; 291.44704802710316 100426.73921116602 61.519710896285346; -475.08978229511496 61.51971089628532 99172.43346979849]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.454334e+03
      1       1.060542e+03      -3.937920e+02 |        7
      2       1.004135e+03      -5.640666e+01 |        5
      3       9.626110e+02      -4.152396e+01 |        4
      4       9.480092e+02      -1.460187e+01 |        0
      5       9.480092e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 948.0091535685506)
┌ Info: K-means with 272 data points using 5 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.072915
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.687160
[ Info: iteration 2, lowerbound -3.544085
[ Info: iteration 3, lowerbound -3.422273
[ Info: iteration 4, lowerbound -3.303405
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.176075
[ Info: iteration 6, lowerbound -3.043729
[ Info: iteration 7, lowerbound -2.934478
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.853917
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.803115
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.781404
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.767879
[ Info: iteration 12, lowerbound -2.755723
[ Info: iteration 13, lowerbound -2.743794
[ Info: iteration 14, lowerbound -2.727362
[ Info: iteration 15, lowerbound -2.705465
[ Info: iteration 16, lowerbound -2.677482
[ Info: iteration 17, lowerbound -2.643417
[ Info: iteration 18, lowerbound -2.604121
[ Info: iteration 19, lowerbound -2.561355
[ Info: iteration 20, lowerbound -2.517585
[ Info: iteration 21, lowerbound -2.475338
[ Info: iteration 22, lowerbound -2.436307
[ Info: iteration 23, lowerbound -2.400822
[ Info: iteration 24, lowerbound -2.368393
[ Info: iteration 25, lowerbound -2.339485
[ Info: iteration 26, lowerbound -2.317521
[ Info: iteration 27, lowerbound -2.307674
[ Info: dropping number of Gaussions to 2
[ Info: iteration 28, lowerbound -2.303002
[ Info: iteration 29, lowerbound -2.299262
[ Info: iteration 30, lowerbound -2.299257
[ Info: iteration 31, lowerbound -2.299255
[ Info: iteration 32, lowerbound -2.299254
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sun Feb  2 20:49:38 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sun Feb  2 20:49:45 2020: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Sun Feb  2 20:49:47 2020: EM with 272 data points 0 iterations avll -2.072915
5.8 data points per parameter
, Sun Feb  2 20:49:49 2020: GMM converted to Variational GMM
, Sun Feb  2 20:49:55 2020: iteration 1, lowerbound -3.687160
, Sun Feb  2 20:49:55 2020: iteration 2, lowerbound -3.544085
, Sun Feb  2 20:49:55 2020: iteration 3, lowerbound -3.422273
, Sun Feb  2 20:49:55 2020: iteration 4, lowerbound -3.303405
, Sun Feb  2 20:49:55 2020: dropping number of Gaussions to 7
, Sun Feb  2 20:49:55 2020: iteration 5, lowerbound -3.176075
, Sun Feb  2 20:49:55 2020: iteration 6, lowerbound -3.043729
, Sun Feb  2 20:49:56 2020: iteration 7, lowerbound -2.934478
, Sun Feb  2 20:49:56 2020: dropping number of Gaussions to 6
, Sun Feb  2 20:49:56 2020: iteration 8, lowerbound -2.853917
, Sun Feb  2 20:49:56 2020: dropping number of Gaussions to 5
, Sun Feb  2 20:49:56 2020: iteration 9, lowerbound -2.803115
, Sun Feb  2 20:49:56 2020: dropping number of Gaussions to 4
, Sun Feb  2 20:49:56 2020: iteration 10, lowerbound -2.781404
, Sun Feb  2 20:49:56 2020: dropping number of Gaussions to 3
, Sun Feb  2 20:49:56 2020: iteration 11, lowerbound -2.767879
, Sun Feb  2 20:49:56 2020: iteration 12, lowerbound -2.755723
, Sun Feb  2 20:49:56 2020: iteration 13, lowerbound -2.743794
, Sun Feb  2 20:49:56 2020: iteration 14, lowerbound -2.727362
, Sun Feb  2 20:49:56 2020: iteration 15, lowerbound -2.705465
, Sun Feb  2 20:49:56 2020: iteration 16, lowerbound -2.677482
, Sun Feb  2 20:49:56 2020: iteration 17, lowerbound -2.643417
, Sun Feb  2 20:49:56 2020: iteration 18, lowerbound -2.604121
, Sun Feb  2 20:49:56 2020: iteration 19, lowerbound -2.561355
, Sun Feb  2 20:49:56 2020: iteration 20, lowerbound -2.517585
, Sun Feb  2 20:49:56 2020: iteration 21, lowerbound -2.475338
, Sun Feb  2 20:49:56 2020: iteration 22, lowerbound -2.436307
, Sun Feb  2 20:49:56 2020: iteration 23, lowerbound -2.400822
, Sun Feb  2 20:49:56 2020: iteration 24, lowerbound -2.368393
, Sun Feb  2 20:49:56 2020: iteration 25, lowerbound -2.339485
, Sun Feb  2 20:49:56 2020: iteration 26, lowerbound -2.317521
, Sun Feb  2 20:49:56 2020: iteration 27, lowerbound -2.307674
, Sun Feb  2 20:49:56 2020: dropping number of Gaussions to 2
, Sun Feb  2 20:49:56 2020: iteration 28, lowerbound -2.303002
, Sun Feb  2 20:49:56 2020: iteration 29, lowerbound -2.299262
, Sun Feb  2 20:49:56 2020: iteration 30, lowerbound -2.299257
, Sun Feb  2 20:49:56 2020: iteration 31, lowerbound -2.299255
, Sun Feb  2 20:49:56 2020: iteration 32, lowerbound -2.299254
, Sun Feb  2 20:49:56 2020: iteration 33, lowerbound -2.299253
, Sun Feb  2 20:49:56 2020: iteration 34, lowerbound -2.299253
, Sun Feb  2 20:49:56 2020: iteration 35, lowerbound -2.299253
, Sun Feb  2 20:49:56 2020: iteration 36, lowerbound -2.299253
, Sun Feb  2 20:49:56 2020: iteration 37, lowerbound -2.299253
, Sun Feb  2 20:49:56 2020: iteration 38, lowerbound -2.299253
, Sun Feb  2 20:49:56 2020: iteration 39, lowerbound -2.299253
, Sun Feb  2 20:49:56 2020: iteration 40, lowerbound -2.299253
, Sun Feb  2 20:49:56 2020: iteration 41, lowerbound -2.299253
, Sun Feb  2 20:49:56 2020: iteration 42, lowerbound -2.299253
, Sun Feb  2 20:49:56 2020: iteration 43, lowerbound -2.299253
, Sun Feb  2 20:49:56 2020: iteration 44, lowerbound -2.299253
, Sun Feb  2 20:49:56 2020: iteration 45, lowerbound -2.299253
, Sun Feb  2 20:49:56 2020: iteration 46, lowerbound -2.299253
, Sun Feb  2 20:49:56 2020: iteration 47, lowerbound -2.299253
, Sun Feb  2 20:49:56 2020: iteration 48, lowerbound -2.299253
, Sun Feb  2 20:49:56 2020: iteration 49, lowerbound -2.299253
, Sun Feb  2 20:49:56 2020: iteration 50, lowerbound -2.299253
, Sun Feb  2 20:49:56 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222646038, 95.95490777353963]
β = [178.04509222646038, 95.95490777353963]
m = [4.250300733266289 79.28686694430857; 2.0002292577716205 53.85198717244176]
ν = [180.04509222646038, 97.95490777353963]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.1840415554743541 -0.007644049042375045; 0.0 0.008581705166266428], [0.3758763612010775 -0.008953123827420039; 0.0 0.012748664777428427]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -0.9990725826983906
avll from llpg:  -0.9990725826983906
avll direct:     -0.9990725826983906
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -1.008194179329756
avll from llpg:  -1.008194179329756
avll direct:     -1.0081941793297562
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
  0.00945495   0.0787274   -0.0663277   -0.000312621  -0.0165587    0.0070223    0.0535893   -0.00560292  -0.0323204   0.093879     -0.225522    -0.168486     0.111456     -0.190877    -0.011857     0.0543035   0.100563     0.0040757  -0.0463838    0.00312899   0.048557     0.118102    -0.0446852    -0.0311421     0.20137     -0.0198787
 -0.0779583   -0.164587     0.0608393    0.0704456     0.0840946    0.0155671   -0.121413    -0.0177159   -0.0564403   0.0787854     0.0299508   -0.0392116   -0.0570912     0.0785823   -0.0154033   -0.0876189   0.202907    -0.130463   -0.0212901   -0.0835934   -0.0836707   -0.0669894    0.150146      0.0646503    -0.0655651    0.219277
  0.00366359   0.191111     0.0299697    0.018356      0.0287012    0.0795686   -0.0830984   -0.0737197   -0.117802    0.00642775    0.11185     -0.157215     0.0849817     0.0788882    0.124022    -0.191839    0.115461     0.095645    0.0409154    0.10313     -0.0398608    0.0991393    0.01604       0.0648069    -0.125856    -0.0519807
  0.132044    -0.0745277   -0.131538     0.0303063     0.00782065   0.133689    -0.13492     -0.160955    -0.0164945   0.0552591    -0.0489075    0.0502162   -0.0885122    -0.0477431   -0.118347     0.219406    0.0575179   -0.0306801   0.133049    -0.0411929    0.130128     0.116397     0.123602     -0.000295573   0.0534095   -0.0513096
 -0.105634    -0.0816023    0.0129327   -0.00030222    0.0100601    0.0265448   -0.0462184   -0.0212835   -0.108121    0.112694     -0.136873     0.0489509    0.172027     -0.168208    -0.10516      0.140166   -0.0445161   -0.0249797  -0.0146336   -0.0384379   -0.0469974   -0.0756581   -0.00455861   -0.190376     -0.129267     0.0131753
 -0.176191     0.0950377   -0.0159382   -0.00293462   -0.00677421  -0.0408197    0.0314147    0.0861094    0.154943    0.0833181    -0.00680098  -0.0443889    0.102034      0.134437    -0.178145    -0.0956405   0.130225    -0.0580359  -0.0704656   -0.0185226    0.158444    -0.12957     -0.0256956    -0.0320096     0.0630603   -0.12241
 -0.195644     0.0588321    0.0441065   -0.0681641     0.018053    -0.234023    -0.0470355   -0.0515567    0.0284373  -0.122116      0.0575121    0.0031318    0.0987142    -0.0928951    0.0654247    0.160219   -0.0492429    0.0668992  -0.124581     0.0773821   -0.0686552    0.0313547    0.0397241    -0.151708     -0.09595      0.217606
  0.0486009   -0.0221515    0.163321    -0.0604553    -0.167266    -0.107439    -0.00398938   0.12272      0.0529782   0.208111      0.0108841   -0.0411383   -0.11703      -0.0138673    0.07645     -0.13374    -0.0156383    0.0482564  -0.0067601   -0.0261594    0.182182    -0.156455     0.147627      0.00868009   -0.00565447   0.12621
  0.0537832   -0.0821785   -0.136653     0.112658     -0.255995    -0.228215     0.236353     0.0423726   -0.213594   -0.0729856    -0.0809033    0.152909    -0.147219     -0.0807226    0.0282469   -0.129575    0.0313929    0.0856468  -0.121621     0.172576    -0.0316347   -0.0925945    0.106568     -0.0133717    -0.108587    -0.0396218
  0.0124567   -0.155439     0.175644    -0.0769766     0.0235723    0.0853524   -0.0404286   -0.0286829    0.0329208   0.0339056     0.0063932   -0.0424951   -0.206818     -0.0226692    0.0584445   -0.0546945  -0.0463261   -0.0203526   0.0950896    0.0379597    3.66998e-5   0.101319    -0.0423111    -0.11686       0.00712707   0.0799692
 -0.07249      0.0424914    0.0120469   -0.029239     -0.0758929   -0.0709678   -0.0245264    0.194373    -0.0621485  -0.114866     -0.116161    -0.186177     0.0597209     0.013186     0.012905    -0.136838    0.0252354   -0.0508685   0.0690978    0.0635077   -0.0341244    0.025886     0.0923051    -0.0519863    -0.0658755    0.0259589
 -0.108777    -0.0449951    0.146501     0.0643204    -0.108998     0.122359    -0.0628088    0.11829      0.0933412   0.1689        0.0653835    0.00117963   0.0171956    -0.105892    -0.0643508    0.0410468   0.0828505   -0.0527736   0.0175399    0.00393139  -0.172001    -0.00498101   0.00927224   -0.09614       0.107965     0.0625062
 -0.127679     0.115918     0.0344101   -0.132773     -0.154386     0.00703259  -0.127763     0.0328578    0.0241515  -0.0458328     0.17739      0.0172588    0.0702664    -0.0851914    0.10456      0.0910548  -0.00335791   0.0239611   0.0929986    0.0926251   -0.0878738   -0.109365    -0.0572033     0.0119833     0.0398613   -0.0355377
 -0.121323    -0.0161781   -0.126915    -0.0361067     0.0376485    0.0726957    0.0289456   -0.161458    -0.0850048   0.000501047  -0.00491581  -0.100764     0.0251813     0.0421455   -0.153407    -0.238105    0.135667     0.0480238   0.0737027    0.0531597    0.103917     0.0409628    0.0533478    -0.0597345     0.038005     0.0914312
 -0.0320129   -0.08201     -0.0659244    0.132482      0.137057     0.0183685   -0.0399663   -0.100627    -0.1784      0.115735      0.103349     0.00349342   0.085361     -0.0757791    0.0268258    0.105351    0.0509963    0.160954    0.149687     0.00725773   0.034096    -0.0292817    0.0179652    -0.049543     -0.211171    -0.0750811
 -0.166692     0.101434     0.0825294   -0.229136     -0.115158     0.0513625   -0.0897611    0.0313399    0.0059676   0.028999      0.00140939  -0.0870111    0.0262574     0.166262     0.0190036   -0.175322   -0.0831967    0.133945    0.0746294    0.155437     0.0818898   -0.0415608   -0.037707     -0.0608143     0.0633764   -0.0649287
  0.0446293   -0.143211    -0.10337      0.0146145     0.0300345    0.112872     0.132358     0.190512    -0.163331   -0.10297      -0.0845682    0.0587176   -0.101481      0.00300657   0.0315888   -0.0661184   0.0590925    0.113026    0.0591759   -0.197133    -0.0209584    0.0533158    0.153802      0.0790149    -0.111378     0.102992
  0.150799    -0.0243017    0.0320379   -0.120326     -0.0633316    0.0902657   -0.0759288   -0.142684     0.155095   -0.104619      0.0992055   -0.132261    -0.134384     -0.0825084   -0.0948385   -0.0664656   0.018928    -0.117753   -0.127761    -0.023323    -0.0202383   -0.0659147    0.127855      0.0413141    -0.069743     0.0553002
  0.0260791    0.0463005   -0.0253687   -0.0111595    -0.0109928   -0.115002     0.103625    -0.0728812    0.17571    -0.0407163    -0.0661618    0.0647244   -0.0246111    -0.0397218   -0.0702552   -0.201129   -0.0237095   -0.0371807  -0.0136155    0.120641    -0.0220949   -0.129186    -0.0409526    -0.165656      0.0769637   -0.20831
 -0.0244935   -0.0839265    0.162338     0.101778      0.0676826    0.0450986   -0.141724    -0.179674     0.0358282   0.0187741    -0.00590593  -0.0788658    0.169071      0.0904771    0.135064    -0.0304153  -0.108479    -0.0500013  -0.00392913  -0.00203602  -0.0699242    0.057401    -0.0363768    -0.127333      0.0986419   -0.0670411
  0.104383     0.110103     0.122969    -0.0481155     0.0183389    0.0750661   -0.0219641   -0.0688057    0.0667859   0.0556856     0.143136     0.023401    -0.0395457    -0.0360316   -0.0588019    0.0451415  -0.0935048   -0.0382767   0.166236    -0.00324918  -0.0982374   -0.00882172   0.111642     -0.00672244    0.033039     0.0198584
 -0.111538     0.017351     0.0127536   -0.177161     -0.0991458    0.112528    -0.0542116   -0.0294726    0.0637568  -0.0820086    -0.077273    -0.0916073    0.0780468    -0.115149     0.0092542   -0.0653167  -0.00864179   0.166689    0.0270756   -0.0729849    0.0790305   -0.0155113    0.0726075    -0.0588465    -0.0122444   -0.0830022
  0.0126976   -0.0624097    0.0792171   -0.0274451     0.071421     0.0948793   -0.00912563   0.0289353    0.0245958  -0.112565      0.0353881   -0.0435429    0.000748279  -0.126758    -0.00310201   0.0205643  -0.0372579    0.105856   -0.0454652   -0.0507618    0.0392143    0.165028    -0.141556     -0.040777     -0.107584    -0.0141834
  0.132212    -0.0580611    0.00926603   0.00272541    0.0476793   -0.062953     0.0184206    0.0957831   -0.0306902  -0.0572105    -0.194945     0.160668    -0.118285      0.0806441    0.0410142    0.0626654  -0.0638715    0.12556     0.0312872    0.140026     0.0919142   -0.0555434   -0.0241355     0.0161731     0.220377     0.106224
  0.105073    -0.00958093   0.119777     0.0276086    -0.149232    -0.113061     0.0893505    0.115041     0.0605009   0.0134269     0.225358     0.0424643    0.00629077    0.00402216   0.135897    -0.232305    0.014085    -0.153516   -0.0915567   -0.00144232   0.0652313    0.0950511    0.0622154    -0.0508522    -0.0456594   -0.00781328
  0.127277    -0.0117923   -0.17053     -0.0600615     0.0680068   -0.0908288   -0.123866     0.0857509    0.0374749  -0.00198428    0.0645254   -0.0569123    0.203973      0.0907441    0.0414064   -0.209074   -0.0395436    0.0482081   0.0412758    0.139655    -0.0707881    0.0268571   -0.00739794    0.0205065    -0.0869084    0.14142
  0.0133034   -0.0576492    0.150952    -0.0575594     0.0501569   -0.0441218   -0.0605276   -0.156705    -0.168248   -0.0204325     0.113595    -0.083007    -0.0135831     0.00607545   0.130619    -0.122429    0.00726589  -0.0175731  -0.0194332    0.045067     0.0790361    0.276698    -0.0472292     0.0871243     0.147377     0.180127
  0.165564     0.0377222   -0.0749589    0.0697333     0.0725443   -0.0605477   -0.108874    -0.13518     -0.149959    0.0505124    -0.103741    -0.204167    -0.236861      0.0485023   -0.00717857  -0.16643    -0.136186    -0.0242686   0.0311225   -0.0274398   -0.0201821   -0.0719548   -0.000361974   0.101711      0.167814     0.199128
  0.231935     0.0320612    0.0482788   -0.109456     -0.00477428  -0.0682918    0.0232364   -0.0555554    0.0389951   0.220672     -0.0164322   -0.00851115  -0.0233859    -0.186103    -0.0618309    0.21212     0.00313401  -0.0266119  -0.0889603   -0.0601248   -0.14332      0.0461738   -0.0257247    -0.164764     -0.00360963   0.130307
  0.123267     0.0476155    0.0542667    0.171217     -0.0212215   -0.0853353   -0.0301405    0.0871171   -0.0447967  -0.065283     -0.0738862    0.0346248    0.140645      0.0484704    0.0059018    0.0982727  -0.0959463    0.0184732   0.0144785    0.089649     0.222104    -0.0153497   -0.0882125     0.115894      0.0314972   -0.106449
  0.0508656    0.0795433   -0.108676    -0.0914812     0.068276    -0.0497613   -0.0720902    0.0771875   -0.150833   -0.071649      0.237868    -0.0849233   -0.0306292     0.0132569    0.0667568    0.111896   -0.0282604    0.0719003  -0.00259068  -0.0336781   -0.268156     0.0296933    0.0311026    -0.0761328    -0.0678817   -0.0296959
  0.0447685   -0.0324226    0.166172    -0.04603       0.0664477   -0.0991059   -0.0622687    0.0451321   -0.113011    0.0227693    -0.153342     0.00407378  -0.124009      0.0797127    0.00218556  -0.17944    -0.0237517    0.0142904   0.0855995   -0.037504    -0.0369113   -0.174912     0.0125745    -0.168913     -0.0350622   -0.00997503kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.409616517043855
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409682
[ Info: iteration 2, average log likelihood -1.409618
[ Info: iteration 3, average log likelihood -1.409242
[ Info: iteration 4, average log likelihood -1.404847
[ Info: iteration 5, average log likelihood -1.390510
[ Info: iteration 6, average log likelihood -1.382545
[ Info: iteration 7, average log likelihood -1.380871
[ Info: iteration 8, average log likelihood -1.379548
[ Info: iteration 9, average log likelihood -1.378443
[ Info: iteration 10, average log likelihood -1.378038
[ Info: iteration 11, average log likelihood -1.377855
[ Info: iteration 12, average log likelihood -1.377716
[ Info: iteration 13, average log likelihood -1.377606
[ Info: iteration 14, average log likelihood -1.377542
[ Info: iteration 15, average log likelihood -1.377510
[ Info: iteration 16, average log likelihood -1.377496
[ Info: iteration 17, average log likelihood -1.377489
[ Info: iteration 18, average log likelihood -1.377485
[ Info: iteration 19, average log likelihood -1.377483
[ Info: iteration 20, average log likelihood -1.377481
[ Info: iteration 21, average log likelihood -1.377480
[ Info: iteration 22, average log likelihood -1.377479
[ Info: iteration 23, average log likelihood -1.377478
[ Info: iteration 24, average log likelihood -1.377477
[ Info: iteration 25, average log likelihood -1.377477
[ Info: iteration 26, average log likelihood -1.377476
[ Info: iteration 27, average log likelihood -1.377475
[ Info: iteration 28, average log likelihood -1.377475
[ Info: iteration 29, average log likelihood -1.377475
[ Info: iteration 30, average log likelihood -1.377474
[ Info: iteration 31, average log likelihood -1.377474
[ Info: iteration 32, average log likelihood -1.377474
[ Info: iteration 33, average log likelihood -1.377474
[ Info: iteration 34, average log likelihood -1.377473
[ Info: iteration 35, average log likelihood -1.377473
[ Info: iteration 36, average log likelihood -1.377473
[ Info: iteration 37, average log likelihood -1.377473
[ Info: iteration 38, average log likelihood -1.377473
[ Info: iteration 39, average log likelihood -1.377473
[ Info: iteration 40, average log likelihood -1.377473
[ Info: iteration 41, average log likelihood -1.377472
[ Info: iteration 42, average log likelihood -1.377472
[ Info: iteration 43, average log likelihood -1.377472
[ Info: iteration 44, average log likelihood -1.377472
[ Info: iteration 45, average log likelihood -1.377472
[ Info: iteration 46, average log likelihood -1.377472
[ Info: iteration 47, average log likelihood -1.377472
[ Info: iteration 48, average log likelihood -1.377472
[ Info: iteration 49, average log likelihood -1.377472
[ Info: iteration 50, average log likelihood -1.377472
┌ Info: EM with 100000 data points 50 iterations avll -1.377472
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.409682274416448
│     -1.4096180843794228
│      ⋮
└     -1.3774721670419674
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.377565
[ Info: iteration 2, average log likelihood -1.377470
[ Info: iteration 3, average log likelihood -1.377008
[ Info: iteration 4, average log likelihood -1.373439
[ Info: iteration 5, average log likelihood -1.362103
[ Info: iteration 6, average log likelihood -1.350739
[ Info: iteration 7, average log likelihood -1.345094
[ Info: iteration 8, average log likelihood -1.342117
[ Info: iteration 9, average log likelihood -1.340361
[ Info: iteration 10, average log likelihood -1.339082
[ Info: iteration 11, average log likelihood -1.338001
[ Info: iteration 12, average log likelihood -1.337091
[ Info: iteration 13, average log likelihood -1.336340
[ Info: iteration 14, average log likelihood -1.335688
[ Info: iteration 15, average log likelihood -1.335013
[ Info: iteration 16, average log likelihood -1.334127
[ Info: iteration 17, average log likelihood -1.333276
[ Info: iteration 18, average log likelihood -1.332760
[ Info: iteration 19, average log likelihood -1.332444
[ Info: iteration 20, average log likelihood -1.332242
[ Info: iteration 21, average log likelihood -1.332105
[ Info: iteration 22, average log likelihood -1.332009
[ Info: iteration 23, average log likelihood -1.331941
[ Info: iteration 24, average log likelihood -1.331895
[ Info: iteration 25, average log likelihood -1.331864
[ Info: iteration 26, average log likelihood -1.331843
[ Info: iteration 27, average log likelihood -1.331828
[ Info: iteration 28, average log likelihood -1.331817
[ Info: iteration 29, average log likelihood -1.331810
[ Info: iteration 30, average log likelihood -1.331805
[ Info: iteration 31, average log likelihood -1.331802
[ Info: iteration 32, average log likelihood -1.331799
[ Info: iteration 33, average log likelihood -1.331798
[ Info: iteration 34, average log likelihood -1.331796
[ Info: iteration 35, average log likelihood -1.331795
[ Info: iteration 36, average log likelihood -1.331794
[ Info: iteration 37, average log likelihood -1.331794
[ Info: iteration 38, average log likelihood -1.331793
[ Info: iteration 39, average log likelihood -1.331793
[ Info: iteration 40, average log likelihood -1.331792
[ Info: iteration 41, average log likelihood -1.331792
[ Info: iteration 42, average log likelihood -1.331791
[ Info: iteration 43, average log likelihood -1.331791
[ Info: iteration 44, average log likelihood -1.331790
[ Info: iteration 45, average log likelihood -1.331789
[ Info: iteration 46, average log likelihood -1.331789
[ Info: iteration 47, average log likelihood -1.331788
[ Info: iteration 48, average log likelihood -1.331788
[ Info: iteration 49, average log likelihood -1.331787
[ Info: iteration 50, average log likelihood -1.331786
┌ Info: EM with 100000 data points 50 iterations avll -1.331786
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3775652847361666
│     -1.3774699613915027
│      ⋮
└     -1.3317864202913499
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.331919
[ Info: iteration 2, average log likelihood -1.331754
[ Info: iteration 3, average log likelihood -1.330730
[ Info: iteration 4, average log likelihood -1.323664
[ Info: iteration 5, average log likelihood -1.306747
[ Info: iteration 6, average log likelihood -1.295209
[ Info: iteration 7, average log likelihood -1.290722
[ Info: iteration 8, average log likelihood -1.288201
[ Info: iteration 9, average log likelihood -1.286394
[ Info: iteration 10, average log likelihood -1.285144
[ Info: iteration 11, average log likelihood -1.284274
[ Info: iteration 12, average log likelihood -1.283596
[ Info: iteration 13, average log likelihood -1.283026
[ Info: iteration 14, average log likelihood -1.282543
[ Info: iteration 15, average log likelihood -1.282147
[ Info: iteration 16, average log likelihood -1.281806
[ Info: iteration 17, average log likelihood -1.281461
[ Info: iteration 18, average log likelihood -1.281084
[ Info: iteration 19, average log likelihood -1.280632
[ Info: iteration 20, average log likelihood -1.280057
[ Info: iteration 21, average log likelihood -1.279260
[ Info: iteration 22, average log likelihood -1.277933
[ Info: iteration 23, average log likelihood -1.275819
[ Info: iteration 24, average log likelihood -1.273883
[ Info: iteration 25, average log likelihood -1.273127
[ Info: iteration 26, average log likelihood -1.272988
[ Info: iteration 27, average log likelihood -1.272961
[ Info: iteration 28, average log likelihood -1.272950
[ Info: iteration 29, average log likelihood -1.272942
[ Info: iteration 30, average log likelihood -1.272935
[ Info: iteration 31, average log likelihood -1.272928
[ Info: iteration 32, average log likelihood -1.272922
[ Info: iteration 33, average log likelihood -1.272915
[ Info: iteration 34, average log likelihood -1.272907
[ Info: iteration 35, average log likelihood -1.272898
[ Info: iteration 36, average log likelihood -1.272887
[ Info: iteration 37, average log likelihood -1.272874
[ Info: iteration 38, average log likelihood -1.272859
[ Info: iteration 39, average log likelihood -1.272840
[ Info: iteration 40, average log likelihood -1.272819
[ Info: iteration 41, average log likelihood -1.272796
[ Info: iteration 42, average log likelihood -1.272771
[ Info: iteration 43, average log likelihood -1.272744
[ Info: iteration 44, average log likelihood -1.272715
[ Info: iteration 45, average log likelihood -1.272685
[ Info: iteration 46, average log likelihood -1.272654
[ Info: iteration 47, average log likelihood -1.272624
[ Info: iteration 48, average log likelihood -1.272596
[ Info: iteration 49, average log likelihood -1.272570
[ Info: iteration 50, average log likelihood -1.272547
┌ Info: EM with 100000 data points 50 iterations avll -1.272547
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3319186783089154
│     -1.3317543386311554
│      ⋮
└     -1.2725470401558445
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.272725
[ Info: iteration 2, average log likelihood -1.272497
[ Info: iteration 3, average log likelihood -1.271529
[ Info: iteration 4, average log likelihood -1.258853
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.224074
[ Info: iteration 6, average log likelihood -1.212928
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.192232
[ Info: iteration 8, average log likelihood -1.200748
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.183883
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.188188
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.192246
[ Info: iteration 12, average log likelihood -1.185154
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.174638
[ Info: iteration 14, average log likelihood -1.191619
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.177915
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.185273
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.191541
[ Info: iteration 18, average log likelihood -1.184761
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.174314
[ Info: iteration 20, average log likelihood -1.191266
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.177466
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.185297
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.191535
[ Info: iteration 24, average log likelihood -1.184726
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.174249
[ Info: iteration 26, average log likelihood -1.191161
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.177340
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.185305
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.191536
[ Info: iteration 30, average log likelihood -1.184718
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.174231
[ Info: iteration 32, average log likelihood -1.191133
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.177308
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.185308
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.191536
[ Info: iteration 36, average log likelihood -1.184716
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.174227
[ Info: iteration 38, average log likelihood -1.191125
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.177300
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.185308
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.191536
[ Info: iteration 42, average log likelihood -1.184715
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.174226
[ Info: iteration 44, average log likelihood -1.191123
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.177298
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.185308
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.191536
[ Info: iteration 48, average log likelihood -1.184715
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.174225
[ Info: iteration 50, average log likelihood -1.191123
┌ Info: EM with 100000 data points 50 iterations avll -1.191123
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2727252617135627
│     -1.2724966575938255
│      ⋮
└     -1.1911225291198877
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     13
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.177558
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.172377
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.176766
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     13
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.171967
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.148035
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.126997
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.110743
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.099431
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.091604
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.103142
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.089767
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.079794
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      5
│     14
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.082875
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.097911
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.085485
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.077955
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      5
│     14
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.080505
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.097609
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.084506
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.075745
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      5
│     14
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.079373
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.097601
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.084238
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.075318
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      5
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.094328
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.090841
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.078909
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.087480
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      5
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.087620
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.085490
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.091022
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.080763
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      5
│     14
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.082278
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.097582
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.084220
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.075304
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      5
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.094312
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.090830
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.078883
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.087452
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      5
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.087610
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.085478
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.091002
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.080746
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      5
│     14
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.082267
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.097569
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.084206
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.075290
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      5
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.094300
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.090819
┌ Info: EM with 100000 data points 50 iterations avll -1.090819
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1775575613672882
│     -1.172376542963328
│      ⋮
└     -1.0908190325595781
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.409616517043855
│     -1.409682274416448
│     -1.4096180843794228
│     -1.4092415915857828
│      ⋮
│     -1.075289738259854
│     -1.0943003159386786
└     -1.0908190325595781
32×26 Array{Float64,2}:
  0.00937646   0.0452716   -0.0258599   0.197866    -0.111181     0.0380432    0.102729    -0.187164     0.169301    -0.39173     -0.0911729    0.173116    -0.0142213   -0.2126      -0.00434521  -0.279907    -0.00361057  -0.0367463    -0.286899      0.0988978   -0.0215374   -0.203506    -0.0637442   -0.130676     0.218039    -0.206499
  0.0363624    0.0453649   -0.0114716  -0.17918      0.198678    -0.257728     0.104591     0.0949112    0.153314     0.29579     -0.0726851   -0.0877192   -0.0142661    0.118984    -0.143614    -0.120625    -0.0477532   -0.037116      0.231852      0.117561    -0.0314291    0.0123633    0.0101685   -0.195277    -0.150875    -0.195938
  0.0632593   -0.164499     0.181616    0.123848     0.0913075    0.0335019    0.130808     0.166219    -0.216748    -0.0195932   -0.105346     0.145738    -0.103646    -0.0137581    0.0286025   -0.0340076    0.179284     0.112512      0.0420937    -0.204759    -0.0802356   -0.226158     0.151673     0.0305172   -0.0688477    0.0332522
  0.056758    -0.124099    -0.30958    -0.0694068   -0.0340825    0.187814     0.132762     0.164185    -0.161788    -0.153896    -0.0830743   -0.0163036   -0.0386507    0.0225322    0.0400723   -0.0943353    0.00932491   0.114503      0.0539941    -0.188108     0.0558615    0.292971     0.133049     0.0750884   -0.143761     0.115382
  0.152804     0.013279    -0.0804236   0.0583098    0.100729    -0.0191164   -0.097705    -0.151307    -0.129811     0.0514143   -0.129548    -0.177767    -0.227311     0.0446419   -0.0507129   -0.125347    -0.128105    -0.0190175     0.029097     -0.0264278   -0.0171449   -0.0745842   -0.0222152    0.0666918    0.129031     0.183304
  0.0351122   -0.0308123    0.200561   -0.0615093   -0.143569    -0.0951351    0.0173456    0.117738     0.00498336   0.192725    -0.0115273   -0.0520446   -0.103974    -0.0376951    0.104507    -0.10916     -0.011379     0.0390354    -0.0185898    -0.0221591    0.156598    -0.142338     0.144533     0.00264773  -0.0349214    0.134237
 -0.0229709   -0.103209     0.209599    0.0597102    0.0975638    0.0999183   -0.220621    -0.159363     0.0402155   -0.70243      0.0414608   -0.0421998    0.195842     0.00784026   0.206344    -0.14633     -0.11658     -0.0455796    -0.00296358    0.0235831   -0.0673164   -0.0537208   -0.0292516   -0.0781257    0.0948264   -0.0492863
 -0.0262804   -0.0639421    0.0985762   0.0112124    0.0496686   -0.0237525   -0.0280572   -0.202337     0.00370191   0.552737    -0.031263    -0.100414     0.0997957    0.201959     0.0870429   -0.0805812   -0.108121    -0.0586504     0.000809226  -0.0230786   -0.0753982    0.149662    -0.0333379   -0.188878     0.10524     -0.0966867
 -0.165613     0.106725     0.105378   -0.239677    -0.112291     0.0214873   -0.0968084    0.02848      0.00952047   0.029855    -0.00504464  -0.0987473   -0.0093455    0.16708      0.0426005   -0.176981    -0.0732823    0.132205      0.061725      0.123908     0.0932102   -0.0638995   -0.0616316   -0.0666923    0.0735976   -0.0790423
  0.0796733   -0.0459206    0.0140249   0.0256531    0.0365454   -0.0634414    0.0144545    0.0905208   -0.0323483   -0.0357099   -0.16793      0.168806    -0.137225     0.081131     0.0198849    0.0629019   -0.0578428    0.133613      0.0715141     0.122276     0.0726349   -0.0510098   -0.023241     0.00847952   0.218927     0.101161
  0.0554998   -0.0647254    0.0675974   0.0594156    0.00220882   0.00354062  -0.0341445    0.0318322   -0.0213786   -0.01522     -0.0139863   -0.00156006  -0.0334232    0.00468296   0.043312     0.014468    -0.048586    -0.000901098   0.0555869     0.0201218    0.120981     0.043886    -0.0587428   -0.0172764    0.0440175   -0.020428
  0.00233374   0.189511     0.0172823   0.0149363    0.0160292    0.107484    -0.0909293   -0.0748869   -0.119802    -0.0173403    0.0793014   -0.160208     0.0835474    0.0613517    0.133104    -0.18524      0.12292      0.104564      0.0379668     0.115013    -0.0410629    0.0792491    0.0179051    0.0932628   -0.134845    -0.04836
  0.0524717   -0.0449711    0.149622   -0.020369     0.0486605   -0.0940013   -0.0539024    0.0216478   -0.109809     0.0275809   -0.155325     0.00892677  -0.124402     0.0734201   -0.00990551  -0.152405    -0.0214386    0.0133743     0.0856745    -0.0291578   -0.0398942   -0.179472     0.0083778   -0.171358    -0.0331338   -0.0131469
 -0.165974     0.0558925    0.0470292  -0.0675685    0.0194845   -0.218459    -0.0440796   -0.0920516    0.0294145   -0.121405     0.0614733    0.00679449   0.106831    -0.116452     0.0648733    0.163342    -0.0511237    0.0844611    -0.121619      0.0763338   -0.0678646    0.0466254    0.0530124   -0.151692    -0.0926342    0.170116
  0.143664     0.00734968   0.0958844   0.00573415  -0.175991    -0.721392     0.0878152    0.133186     0.040932     0.00379654   0.229014     0.0141236    0.0290533    0.0244956    0.134138    -0.267886     0.166829    -0.197349     -0.0862153    -0.0186234    0.0126751    0.104459     0.072788    -0.056751    -0.129546    -0.0118647
  0.0663666   -0.00706956   0.124221    0.0435034   -0.144551     0.511796     0.0837563    0.104629     0.0725165    0.0244223    0.232868     0.0738951   -0.0219865   -0.0106053    0.138182    -0.222225    -0.152838    -0.0929278    -0.0992101     0.0120288    0.147188     0.0425442    0.0406239   -0.0358036   -0.0740413    0.0182387
 -0.14912     -0.136469     0.115688    0.104433     0.106454     0.0270362   -0.214242     0.00247219  -0.0517271    0.0606944   -0.0166069   -0.0285269   -0.0551489    0.0870386   -0.00266035  -0.0980001    0.285317    -0.145796      0.039259     -0.0827181   -0.102582    -0.0751768    0.14978      0.145263    -0.0625662   -0.533476
  0.00534013  -0.197373     0.03028     0.0392164    0.0785229   -0.00388026  -0.0568802   -0.0220834   -0.067108     0.0936348    0.0577792   -0.0401666   -0.062663     0.073073    -0.0334992   -0.0847751    0.167075    -0.109041     -0.182117     -0.0729718   -0.0980423   -0.0558747    0.162523     0.0211707   -0.0650927    0.707539
 -0.0585865   -0.213738     0.0312272   0.23962     -0.063553     0.113025    -0.0476108   -0.156628     0.219489    -0.0479706    0.0421014   -0.227006    -0.130285    -0.130849    -0.0696231   -0.0665023    0.0001289   -0.108469     -0.679504     -0.0224957   -0.019041    -0.130959     0.108939     0.0490279   -0.0737937    0.0602751
  0.37625      0.140301     0.0314474  -0.629709    -0.0542973    0.0691972   -0.0422171   -0.136382     0.0479553   -0.186198     0.13058     -0.0146456   -0.138282    -0.0231435   -0.101185    -0.0663089    0.0307132   -0.143611      0.672616     -0.0223577    0.00806847  -0.0682145    0.145511     0.0100329   -0.0766768    0.056375
 -0.209706     0.0709257    0.0277419  -0.0440461   -0.0813522   -0.0677764   -0.43914      0.20626     -0.0554265   -0.113166    -0.131008    -0.172203    -0.0654717    0.0543045    0.0632745   -0.222851     0.0229368   -0.118759      0.0493604     0.0325051   -0.0315063    0.043265     0.0879077   -0.0645059   -0.12905      0.0214092
  0.0850695    0.0401411    0.0256077   0.0243139   -0.0669706   -0.0745588    0.353544     0.139112    -0.0662443   -0.127995    -0.093903    -0.207941     0.206997    -0.0537958   -0.0488057   -0.0444462    0.0473107   -0.0517387     0.0982642     0.0937349   -0.0264086    0.0179241    0.0869215   -0.0627116   -0.0328667    0.0238364
  0.0445918    0.0794713   -0.109562   -0.0906834    0.066919    -0.0473813   -0.0670531    0.110663    -0.100287    -0.144067     0.228125    -0.094825    -0.0429086    0.0206125    0.0612052    0.0990366   -0.00414454   0.0680517     0.0153046    -0.0538747   -0.229363     0.0177713    0.0261672   -0.086744    -0.0765503   -0.0151733
 -0.151317     0.00146129  -0.0050444  -0.178634    -0.0960344    0.117447    -0.0544707   -0.0572309    0.0791546   -0.0833382   -0.0794105   -0.0598508    0.0885218   -0.103313     0.00457811  -0.00689271  -0.00625735   0.160376     -0.0142353    -0.0708141    0.113403    -0.0194267    0.0403081    0.00316852  -0.0190596   -0.0796337
  0.0286159   -0.062122     0.101017   -0.0576643    0.0378305   -0.0422632   -0.0581258   -0.156315    -0.16287     -0.0133148    0.106658    -0.0510662   -0.0112493    0.0155998    0.144911    -0.106822    -0.01245      0.0243376    -0.0204751     0.0537618    0.0577715    0.273511    -0.0464211    0.0680912    0.131184     0.182754
  0.0144262   -0.00699075  -0.146162   -0.046714     0.0581428   -0.00573715  -0.0433084   -0.0272602   -0.00682774   0.0446101    0.0293271   -0.0819677    0.119298     0.0817953   -0.0536357   -0.222986     0.0629649    0.0488239     0.0485837     0.110576     0.010092     0.0316927    0.0217505   -0.02409     -0.0524974    0.131243
  0.0238131   -0.00676907  -0.0339981  -0.0110133    0.00268274   0.0158299   -0.0360511   -0.0326624    0.0301625    0.120631    -0.0535758    0.0246651    0.0366845   -0.0673526   -0.12482      0.131837     0.0613645   -0.0435133    -0.00998932   -0.0399598    0.0424083    0.00239226   0.00840957  -0.0921515    0.00257534  -0.0181635
  0.0579416   -0.0722384   -0.136525    0.110928    -0.250866    -0.228747     0.278366     0.0284092   -0.230245    -0.075489    -0.0906498    0.184096    -0.14777     -0.0667868    0.0228921   -0.150551     0.0289119    0.0785647    -0.0884754     0.16778     -0.0339982   -0.0953875    0.103244    -0.00718478  -0.0915684   -0.0166844
 -0.0241216    0.00414677   0.127689    0.0321551   -0.07006      0.0969811   -0.0716211    0.0370098    0.081417     0.149255     0.0987452    0.0125455   -0.0030031   -0.100226    -0.0643534    0.05498      0.0190513   -0.0505687     0.0799272     0.00710474  -0.153734    -0.039228     0.0711882   -0.0650502    0.0827132    0.05015
  0.0220601   -0.0193034    0.0826875  -0.0318434    0.0684789    0.0954235    0.00506285   0.0108111    0.0234576   -0.0992559    0.0303525   -0.0384803   -0.00246386  -0.11756     -0.0345181    0.0241529   -0.0441659    0.0777784    -0.0126844    -0.0503085    0.013628     0.0844153   -0.115109    -0.0327289   -0.128848    -0.0131375
 -0.0156532   -0.0175902   -0.058004    0.0696161    0.0376301    0.0425285    0.0181547   -0.0424944   -0.118258     0.106795    -0.0835549   -0.0751605    0.0920123   -0.13222      0.0144226    0.0905891    0.0893459    0.0777454     0.0649625     0.00981908   0.0376127    0.0490457   -0.0156214   -0.0442298    0.00461331  -0.0392039
 -0.127814     0.0844406    0.0145062  -0.13186     -0.155126     0.00407677  -0.128553     0.0333818    0.0258366   -0.0651978    0.168532     0.0168114    0.0742334   -0.084908     0.117308     0.10242      0.106955     0.0619017     0.0687358     0.0829088   -0.0616232   -0.147632    -0.0222221    0.00715817   0.0507001   -0.0460723[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.078870
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.075304
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      5
│     14
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.075412
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.076641
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.076831
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      5
│     14
│     19
│     20
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.072880
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.078727
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.074706
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      5
│     14
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.074944
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│     20
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.076621
┌ Info: EM with 100000 data points 10 iterations avll -1.076621
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.507245e+05
      1       6.839858e+05      -1.667386e+05 |       32
      2       6.569875e+05      -2.699836e+04 |       32
      3       6.407989e+05      -1.618860e+04 |       32
      4       6.302624e+05      -1.053643e+04 |       32
      5       6.227346e+05      -7.527867e+03 |       32
      6       6.178285e+05      -4.906062e+03 |       32
      7       6.155133e+05      -2.315217e+03 |       32
      8       6.147016e+05      -8.116574e+02 |       32
      9       6.143515e+05      -3.501907e+02 |       32
     10       6.141519e+05      -1.995677e+02 |       32
     11       6.139948e+05      -1.570850e+02 |       32
     12       6.138472e+05      -1.476153e+02 |       32
     13       6.136892e+05      -1.580130e+02 |       32
     14       6.135407e+05      -1.484968e+02 |       32
     15       6.133835e+05      -1.571485e+02 |       32
     16       6.132168e+05      -1.667068e+02 |       32
     17       6.130492e+05      -1.676129e+02 |       32
     18       6.129278e+05      -1.214374e+02 |       31
     19       6.128563e+05      -7.145622e+01 |       32
     20       6.128035e+05      -5.282677e+01 |       32
     21       6.127707e+05      -3.274565e+01 |       32
     22       6.127489e+05      -2.187087e+01 |       31
     23       6.127309e+05      -1.796438e+01 |       31
     24       6.127196e+05      -1.128089e+01 |       32
     25       6.127049e+05      -1.475691e+01 |       28
     26       6.126897e+05      -1.518279e+01 |       30
     27       6.126745e+05      -1.518075e+01 |       27
     28       6.126600e+05      -1.448547e+01 |       29
     29       6.126457e+05      -1.429079e+01 |       30
     30       6.126323e+05      -1.343781e+01 |       31
     31       6.126140e+05      -1.833581e+01 |       31
     32       6.125831e+05      -3.087517e+01 |       29
     33       6.125171e+05      -6.601685e+01 |       31
     34       6.123917e+05      -1.253490e+02 |       32
     35       6.121572e+05      -2.345600e+02 |       32
     36       6.118279e+05      -3.292713e+02 |       32
     37       6.114682e+05      -3.597137e+02 |       32
     38       6.111031e+05      -3.650716e+02 |       32
     39       6.108711e+05      -2.320268e+02 |       32
     40       6.107349e+05      -1.361431e+02 |       32
     41       6.106499e+05      -8.500060e+01 |       32
     42       6.106034e+05      -4.655790e+01 |       31
     43       6.105812e+05      -2.221076e+01 |       31
     44       6.105652e+05      -1.594943e+01 |       31
     45       6.105525e+05      -1.274273e+01 |       31
     46       6.105430e+05      -9.454171e+00 |       31
     47       6.105345e+05      -8.538375e+00 |       28
     48       6.105222e+05      -1.226518e+01 |       29
     49       6.105085e+05      -1.369665e+01 |       30
     50       6.104875e+05      -2.105546e+01 |       30
K-means terminated without convergence after 50 iterations (objv = 610487.453165744)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.331412
[ Info: iteration 2, average log likelihood -1.304162
[ Info: iteration 3, average log likelihood -1.271199
[ Info: iteration 4, average log likelihood -1.231231
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.184829
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.154221
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     15
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.118590
[ Info: iteration 8, average log likelihood -1.150634
[ Info: iteration 9, average log likelihood -1.116298
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.079029
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.081366
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.093172
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.078132
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     23
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.064554
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.087335
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.087012
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.074175
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     15
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.054614
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.091647
[ Info: iteration 20, average log likelihood -1.076783
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     15
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.041922
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.087142
[ Info: iteration 23, average log likelihood -1.087732
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.052044
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     23
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.057795
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.088213
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.066952
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.071162
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.057911
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     15
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.062349
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.088165
[ Info: iteration 32, average log likelihood -1.074429
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     15
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.033389
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.086405
[ Info: iteration 35, average log likelihood -1.092289
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     15
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.048298
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.088805
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.076703
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     15
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.052999
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.096693
[ Info: iteration 41, average log likelihood -1.080057
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     15
│     23
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.037516
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.101750
[ Info: iteration 44, average log likelihood -1.088977
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     15
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.044444
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.086657
[ Info: iteration 47, average log likelihood -1.092279
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     15
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.048322
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.088831
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.076701
┌ Info: EM with 100000 data points 50 iterations avll -1.076701
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0314989   -0.086362     -0.053535     0.00198304   0.0865161   -0.0387489   -0.12066     0.035286    -0.00180824   0.0548642   0.0367432   -0.0491343     0.0620041     0.0875021    0.005699    -0.147337     0.11183     -0.0401286    -0.0175266    0.0305547   -0.0878702   -0.0185773    0.0702933    0.0446468   -0.0904185     0.125817
  0.0490758   -0.0255476     0.200958    -0.0595855   -0.160384    -0.105558     0.0146049   0.120875     0.0151913    0.197151   -0.00632195  -0.0694451    -0.118904     -0.0192285    0.112712    -0.132742    -0.0134359    0.0403662    -0.0186229   -0.0208136    0.168717    -0.1399       0.147216     0.0237737   -0.0176115     0.133511
  0.107979     0.000845174   0.10928      0.0237434   -0.162253    -0.124224     0.0849977   0.119939     0.0550508    0.0133687   0.232282     0.0417052     0.00463911    0.00630997   0.136016    -0.241467     0.0083395   -0.145142     -0.0927369   -0.00352901   0.0761658    0.0743757    0.0581486   -0.047985    -0.106022      0.00556914
  0.00242711   0.189479      0.0174717    0.0158177    0.0170957    0.105788    -0.0913346  -0.0751839   -0.120453    -0.0174489   0.0819788   -0.160237      0.0839539     0.0621533    0.134373    -0.185946     0.123032     0.104684      0.0376987    0.116183    -0.04126      0.0783738    0.0178066    0.0953189   -0.134375     -0.0507793
  0.181411     0.0290276    -0.102054     0.0703003    0.10018     -0.019254    -0.100963   -0.168637    -0.136911     0.0504922  -0.13307     -0.200905     -0.250842      0.0889165   -0.0462212   -0.167161    -0.135237    -0.0238975     0.0332406   -0.0234914   -0.0139922   -0.0740936   -0.0354197    0.109488     0.169633      0.19536
  0.136233    -0.0950214    -0.137302     0.0262915    0.00393034   0.131922    -0.142991   -0.144556    -0.0112591    0.0643818  -0.0695756    0.0481425    -0.086504     -0.0481173   -0.106978     0.262916     0.0816781    0.000381478   0.140194    -0.0415171    0.12965      0.138977     0.0923732    0.00954965   0.0487679    -0.0342332
 -0.0619241    0.053309      0.0267685   -0.00890263  -0.0742825   -0.0708754   -0.0445835   0.175484    -0.0611233   -0.121368   -0.110856    -0.190243      0.0698373     0.00189527   0.0086996   -0.134546     0.0352481   -0.0848618     0.0734503    0.062733    -0.02867      0.0306936    0.0870081   -0.062484    -0.0799316     0.0257214
  0.105968     0.0956856     0.100633    -0.0504212    0.0174737    0.0604219   -0.0184367  -0.0677724    0.0688182    0.0597275   0.112533     0.0396128    -0.0503188    -0.041137    -0.0618492    0.0437918   -0.0942186   -0.0441126     0.172908     0.00614781  -0.104596    -0.0354796    0.0959983   -0.0147236    0.0281908     0.0190995
  0.0538694   -0.0795897    -0.134619     0.108904    -0.245967    -0.225817     0.272374    0.0292786   -0.232339    -0.0787961  -0.0851449    0.181908     -0.149658     -0.0666346    0.0241329   -0.147439     0.0258307    0.0798879    -0.0895887    0.167349    -0.0356085   -0.0942033    0.102239    -0.00822268  -0.0936712    -0.0205193
  0.22916      0.00570395    0.0371136   -0.0734087   -0.00183862  -0.0646256    0.0235456  -0.0468839    0.0284087    0.219526   -0.0266873    0.0432739    -0.0279819    -0.193022    -0.0676241    0.213392     0.0239331   -0.0528197    -0.104468    -0.0591768   -0.134205     0.0458735   -0.0243659   -0.15468     -0.000983095   0.118256
  0.057664    -0.0617623     0.0698136    0.0621225    0.00116292   0.00281883  -0.0349229   0.0385642   -0.02364     -0.0182644  -0.0125153   -0.000198137  -0.031528      0.0117001    0.0502437    0.0147469   -0.0569433   -0.000870404   0.0567209    0.0237567    0.120525     0.0422621   -0.0631407   -0.00549716   0.0450553    -0.0258656
 -0.165788     0.110262      0.109105    -0.24179     -0.113095     0.0190589   -0.0983006   0.0319894    0.00956992   0.0291517  -0.00418092  -0.096243     -0.0134587     0.166501     0.0467617   -0.176808    -0.0734533    0.131917      0.0596122    0.127065     0.0939214   -0.0625967   -0.0604293   -0.0650963    0.0734908    -0.0762856
 -0.111724    -0.0482183     0.144511     0.0645668   -0.136171     0.118751    -0.0922302   0.11262      0.0890465    0.190386    0.0683596   -0.00727158    0.0160091    -0.136072    -0.0463681    0.0565427    0.100029    -0.0507223     0.00819117  -0.00724875  -0.183289    -0.0513147    0.0455023   -0.0915192    0.10495       0.0637053
 -0.131114    -0.0247487    -0.11023     -0.0198265    0.0375846    0.0944791    0.0279281  -0.165012    -0.078561     0.035678   -0.00028846  -0.100373      0.0250189     0.0577202   -0.148869    -0.237159     0.135162     0.043368      0.036146     0.06215      0.124777     0.0400781    0.077638    -0.0728399    0.0193144     0.11127
 -0.179928     0.0528962     0.0387368   -0.066708     0.0216627   -0.235442    -0.0442658  -0.102496     0.0445094   -0.118857    0.0785834    0.00263189    0.0951255    -0.109959     0.0662468    0.147991    -0.0570496    0.0934019    -0.112678     0.0794616   -0.0617014    0.0518253    0.0565001   -0.14797     -0.086421      0.175997
  0.0534542   -0.0425974     0.154203    -0.0189833    0.0509146   -0.0953081   -0.0554616   0.02365     -0.111795     0.0228882  -0.16433      0.00932779   -0.124784      0.0750346   -0.0119713   -0.159458    -0.0227452    0.0146922     0.0845564   -0.0288756   -0.0400594   -0.186237     0.00787295  -0.171548    -0.0312796    -0.0126789
 -0.184454     0.128377     -0.0146649    0.0128768   -0.00151091  -0.0366172    0.0344323   0.0925583    0.155129     0.072114   -0.00507008  -0.0719522     0.0811422     0.128713    -0.175069    -0.1004       0.136585    -0.0797172    -0.0656931   -0.0187495    0.173986    -0.113341    -0.0287353   -0.0756193    0.0732789    -0.123055
  0.062399    -0.147077     -0.0831262    0.0195999    0.0235802    0.121759     0.132817    0.173479    -0.18548     -0.100716   -0.090454     0.0548245    -0.0810111     0.0149173    0.0369793   -0.0691471    0.0849607    0.112788      0.0508641   -0.201691    -0.00870531   0.0621235    0.146663     0.0604437   -0.112528      0.0807602
 -0.0244117   -0.082853      0.155786     0.0549545    0.0882761    0.0709609   -0.104427   -0.198472     0.0236808   -0.0677303  -0.0108494   -0.0687602     0.182271      0.0604734    0.146612    -0.0912771   -0.115768    -0.051174     -0.0224982    0.00288509  -0.0666261    0.0487725   -0.0328709   -0.128634     0.0975037    -0.0729451
 -0.0326342    0.76856      -0.210131    -0.031422    -0.011514     0.0342865    0.063056    0.00040782  -0.0795417    0.100002   -0.201291    -0.122271      0.109624     -0.170299     0.00713318   0.00983665   0.103057     0.00413847   -0.0182842    0.0177084    0.0695479    0.0950272   -0.141399    -0.00794461   0.18681      -0.00871728
 -0.0259199   -0.0888437     0.126084    -0.105415    -0.0278046   -0.207841    -0.248223   -0.0663432    0.0061519    0.0226704   0.108233    -0.116551     -0.0834683     0.434733     0.129462    -0.246875    -0.091316    -0.0605839     0.146288    -0.0156353   -0.103825     0.0556501   -0.0201063   -0.180542     0.120924     -0.0847982
  0.0288489   -0.0621014     0.101465    -0.0577129    0.0378813   -0.0417988   -0.0577382  -0.156246    -0.162898    -0.0131985   0.107395    -0.0523975    -0.0119481     0.0153877    0.144439    -0.106358    -0.0132733    0.0266908    -0.0194684    0.0541713    0.0604669    0.273627    -0.0463162    0.0668454    0.132022      0.182574
  0.0246481    0.0450843    -0.0189273    0.00935487   0.0460407   -0.120968     0.102633   -0.0418151    0.167172    -0.0494655  -0.0815992    0.0447436    -0.0176526    -0.0599956   -0.0668585   -0.199339    -0.0239523   -0.0368198    -0.0298567    0.108381    -0.0280959   -0.101944    -0.0346936   -0.1653       0.0261365    -0.20154
  0.0920525   -0.050185      0.00649942   0.0349582    0.0417837   -0.0648654    0.019786    0.0922329   -0.0270407   -0.0435878  -0.176342     0.172995     -0.133665      0.0819265    0.021491     0.0561545   -0.0655882    0.147119      0.0719254    0.133475     0.0790335   -0.0509527   -0.0287288    0.0181676    0.238246      0.097325
  0.19981     -0.02573       0.0265298   -0.247665    -0.0568852    0.0936689   -0.0585268  -0.134742     0.144352    -0.12555     0.104078    -0.111512     -0.120096     -0.0662013   -0.0990037   -0.0787194    0.00630131  -0.141077      0.0051217   -0.0145614    0.00904271  -0.103916     0.136617     0.030701    -0.0725947     0.0552753
  0.0775167   -1.22157       0.202701     0.0577164   -0.0527557    0.020379     0.0988655   0.0497834   -0.00354315   0.079855   -0.299984    -0.196527      0.0810891    -0.196847    -0.0442225    0.0522943    0.16905     -0.000393032   0.0116541    0.014968    -0.00503844   0.156208     0.089475    -0.111599     0.227185     -0.0274556
 -0.106501    -0.0643462     0.0162965   -0.0144853    0.0225664    0.00545094  -0.048525   -0.0343962   -0.103971     0.0890066  -0.124435     0.0662983     0.152345     -0.170794    -0.0926391    0.145954    -0.0342225   -0.0223316    -0.0335589   -0.0353861   -0.0496052   -0.0907927    0.00593922  -0.186187    -0.118261      0.0503791
 -0.0371806   -0.109515     -0.0515718    0.150135     0.11807      0.0630381   -0.0466737  -0.101158    -0.189071     0.118835    0.0878862   -0.0167245     0.0745658    -0.0734028    0.0374455    0.133818     0.0557494    0.16214       0.150922     0.00245603   0.0364714   -0.0143186    0.0356287   -0.0375153   -0.217395     -0.0666002
 -0.139009    -0.00901731    0.00322688  -0.170941    -0.0918306    0.112752    -0.0593781  -0.0610867    0.0878403   -0.0885849  -0.0660902   -0.0625664     0.0680627    -0.106228     0.0116649   -0.00596468  -0.00788843   0.145734      0.0139053   -0.0673135    0.102285    -0.0229401    0.0392553    0.0144473   -0.0249917    -0.0653034
  0.0137527   -0.0405851     0.0837458   -0.0111451    0.0772821    0.0977919    0.0052936   0.0266364    0.0173258   -0.134519    0.0253318   -0.0511961     0.000189654  -0.134449    -0.035056     0.0236764   -0.0376151    0.104051     -0.0495409   -0.0508177    0.0327199    0.121862    -0.157566    -0.0347517   -0.153356     -0.0146956
 -0.127861     0.085435      0.0144123   -0.131822    -0.154909     0.00487692  -0.128665    0.0335404    0.0272183   -0.0642058   0.169836     0.0167368     0.0735898    -0.0847427    0.118001     0.101484     0.104781     0.0629962     0.0734722    0.0845575   -0.0631529   -0.148974    -0.0233797    0.00732357   0.0503322    -0.0468851
  0.0607049    0.0844492    -0.103438    -0.0921343    0.0681289   -0.0453076   -0.0738834   0.129224    -0.1233      -0.154072    0.233471    -0.106144     -0.0522524     0.0274835    0.0656232    0.104188    -0.0012942    0.073915      0.0148158   -0.0611471   -0.265536     0.00684717   0.0236492   -0.0815394   -0.0826238    -0.0176582[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     15
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.052995
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     15
│     23
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.040961
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     15
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.039510
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     15
│     23
│     25
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.030689
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     15
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.052651
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     15
│     23
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.040973
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     15
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.039313
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     15
│     23
│     25
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.030685
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     15
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.052650
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     15
│     23
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.040972
┌ Info: EM with 100000 data points 10 iterations avll -1.040972
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0741207    0.162133     0.0777996    -0.0659943     0.0240233    0.165212     -0.0885619    0.101594     0.112877     0.224631     -0.0262639   -0.0304403    0.172316     0.046204    -0.0566755    -0.0997899    0.1542      -0.166666      0.103069    -0.0277069   -0.0609364   -0.323823     -0.117402     0.00832539   -0.0426077   -0.022512
  0.167713    -0.0256873   -0.0990879    -0.0154927     0.164801    -0.137615     -0.0890777    0.190227     0.0626992   -0.0483615    -0.028771    -0.109594    -0.131665    -0.180771     0.124736      0.0478628   -0.0998666   -0.0421882    -0.0874951   -0.00309622   0.0905046   -0.0461271     0.0542588    0.0262285    -0.0706407    0.0172272
 -0.230702    -0.0457206    0.03363      -0.0581602     0.0836183    0.0808745    -0.0130911    0.0119936    0.0428047    0.086324     -0.132893    -0.193877    -0.0194283    0.016248     0.0339355    -0.130072     0.00379498   0.00647637    0.0659255    0.111797     0.0610832    0.173984     -0.0771363    0.251371     -0.178013    -0.0570017
  0.0358878    0.0867586    0.0511744     0.0230619    -0.169236    -0.101502      0.0468261   -0.0859286    0.0743038    0.0182471     0.180627     0.112515     0.0957704    0.0555167    0.00940333   -0.243637     0.130514     0.00595456   -0.0732773   -0.0886951    0.0363927   -0.0144077    -0.00697437  -0.108388     -8.96988e-5  -0.0412407
 -0.221795    -0.260513     0.052295      0.0542672    -0.0388998   -0.00164046   -0.149564    -0.0479691   -0.0926678   -0.165397     -0.0429919   -0.0772718    0.0231741   -0.13983     -0.000598699   0.0746312   -0.178984     0.029942      0.260999     0.0526632   -0.0496299   -0.0909589     0.0641626   -0.0437578    -0.0549099    0.121352
  0.0834028    0.0926776   -0.000811667   0.00603673    0.0802714   -0.0079181    -0.22761      0.0300296    0.0961156    0.0129299     0.0916907   -0.131473     0.0300416    0.0244408    0.097479      0.00458881  -0.00904962  -0.220425     -0.0528678    0.0169018   -0.0969623    0.00303149   -0.0914242    0.225173      0.0525473    0.156246
  0.099193     0.0417288   -0.0296078    -0.0345984     0.108726     0.0423477    -0.183613    -0.0177781   -0.00710031  -0.000698937  -0.114607    -0.0911778   -0.17575     -0.0302701    0.0528267     0.129724     0.0686451   -0.138339      0.0707621   -0.0048345   -0.140705     0.0949999    -0.0731523   -0.124244     -0.0340428    0.102746
 -0.138328    -0.175655    -0.063211      0.030508      0.065283     0.0685408    -0.138025    -0.0570712   -0.0673719    0.000836005  -0.0657359    0.0691342    0.0818123   -0.0581364    0.0266871    -0.0173362   -0.0453451    0.130707     -0.0310761   -0.0512041    0.012683     0.0987759    -0.00100692   0.14343       0.0187113   -0.0985553
  0.221958    -0.0890138   -0.111547     -0.000659386   0.00849776   0.0312312    -0.00900685  -0.0546106   -0.0974095    0.0321212    -0.0195175    0.0142283    0.136249     0.235441    -0.0662676    -0.0481112    0.0579103    0.000228927   0.0128928   -0.0938012    0.107688    -0.0745       -0.0110472   -0.168251      0.00643338  -0.0448818
  0.021142     0.0946146   -0.0309396    -0.0955517    -0.0754003   -0.105665     -0.0375595    0.00709982   0.0579156   -0.164406     -0.0449769    0.215568    -0.0176953    0.0404438   -0.0638458    -0.130797     0.0837165   -0.195888      0.0277846   -0.0779379    0.0199068    0.000507258  -0.190509     0.123542     -0.0720018   -0.0437332
 -2.65332e-5  -0.0855872    0.163494      0.0959959    -0.00320707  -0.00703383    0.0323582    0.00901065  -0.00215887  -0.0322922     0.167588     0.0894896    0.0158955   -0.0766207    0.171869      2.46001e-5   0.119708    -0.236833      0.0311251   -0.0536499   -0.0539602    0.0266754    -0.0573078    0.0808754    -0.0207815   -0.106878
  0.0553277    0.250345     0.123147     -0.0420391    -0.0790679   -0.000679252   0.062204     0.0427104    0.0909804    0.194261      0.103736     0.00816038  -0.00192369  -0.028651     0.11994       0.125514    -0.098766    -0.00632843    0.0819955    0.0984962    0.181646     0.166856     -0.0451104    0.0982356    -0.0669411    0.110801
  0.00369617  -0.0322218   -0.144657     -0.061892      0.00390449  -0.0767261     0.0370644    0.114048    -0.0180673   -0.0958288     0.0623708   -0.00495326  -0.220656     0.164723    -0.0836312    -0.142406    -0.0347659    0.110411     -0.104552    -0.0639908    0.159137     0.06369       0.0349477   -0.154263      0.0981997   -0.0880785
 -0.0529497    0.00615923  -0.173567     -0.0535679     0.129984    -0.121566     -0.0428186   -0.260971     0.199419     0.110361      0.0466481   -0.103276     0.0308419    0.0960719    0.184031      0.0178641    0.127366     0.0624631    -0.0930783   -0.0101133   -0.164591     0.138222     -0.0716842    0.104417     -0.143098    -0.124029
 -0.190621    -0.132384    -0.0674969     0.210054     -0.057669     0.0122857     0.154799    -0.146929     0.00513271  -0.0561862    -0.0697447    0.0552527    0.0500897   -0.0236009   -0.00817063   -0.043674     0.00274449  -0.0557586    -0.0376662   -0.217728     0.164125    -0.0794659     0.0560449   -0.0870436     0.0428059   -0.0287226
 -0.0302404    0.0976842    0.0590458    -0.120624      0.0517901    0.156746     -0.0294974   -0.120565     0.0171982    0.0849225    -0.00751403  -0.0294157   -0.00163612  -0.178584     0.00925368   -0.0890104    0.0458025    0.0466067     0.00151659   0.0332312   -0.0210562    0.0559448    -0.00296504   0.0657565     0.158051    -0.000415417
  0.070611     0.028303     0.0561419     0.104748      0.0372242   -0.0818608     0.0137207   -0.182031    -0.0433676    0.0420033     0.061507     0.0537239   -0.0224091    0.0921995   -0.0552782    -0.00251893  -0.113527     0.0233634    -0.108627     0.0783887    0.1634       0.0591885    -0.150003    -0.189102      0.10577     -0.0207257
  0.0015908    0.0142903   -0.0339631     0.0306491    -0.133355    -0.0931288     0.0521845    0.295066     0.0230507    0.0788932    -0.04488      0.0768477   -0.150263     0.129362     0.0904384    -0.0571471    0.0669751    0.012717      0.121376     0.0328163   -0.00402429  -0.00373979    0.00708011  -0.129633      0.0704048    0.0532629
 -0.00173293  -0.101794     0.0162824     0.0477389    -0.085968     0.0116525     0.0580753    0.0384761    0.0515681   -0.0665126    -0.0112193    0.135408    -0.0343497   -0.0551159    0.112064     -0.144158    -0.0185169    0.184756      0.00791271   0.0410411    0.0498288   -0.0919274     0.03524      0.135008      0.00976606   0.00061033
 -0.149678    -0.0810335   -0.147391      0.0168639     0.025982     0.171069      0.097467    -0.0662295   -0.112863     0.0282503    -0.081366     0.00879857   0.00704726   0.0456416   -0.041183      0.109914    -0.0537499    0.236814      0.0973568    0.00917454  -0.00681134  -0.0391469     0.0872726    0.0621312    -0.0185086   -0.104564
  0.0105957   -0.258971    -0.0712976     0.0104201     0.0571528    0.0517254    -0.114671    -0.064397     0.0655494   -0.178029     -0.150688     0.178792     0.0175566    0.0455166    0.0940248    -0.168369     0.176573    -0.136294     -0.0157332   -0.226358     0.162429     0.22104      -0.0218963   -0.0531207     0.135389     0.00709214
 -0.258533    -0.0267674    0.0275403    -0.0326928     0.0297732   -0.0685717     0.0130181   -0.105483     0.0242334   -0.0241117     0.276754    -0.0278389   -0.0674776   -0.0624343   -0.0884571    -0.195849     0.0143422   -0.0705533     0.0849238    0.0923501    0.128157     0.0367064     0.133618    -0.05451      -0.118101    -0.0390067
  0.00054602  -0.0552933   -0.148667     -0.0869345     0.112405     0.0750192    -0.108936     0.178548    -0.138364     0.0914499    -0.0939819   -0.231211    -0.017616    -0.261263    -0.0791445    -0.0488468    0.0466612    0.0462882     0.00580845   0.0374807    0.0436596   -0.146803     -0.0927337    0.150645     -0.00895119  -0.0849785
 -0.107273    -0.0718399   -0.0345919     0.107116     -0.177867    -0.104179     -0.0672515   -0.163911     0.0376403   -0.0511497     0.0542714    0.0729356   -0.0368463   -0.140568     0.0700705     0.0246015   -0.0345088   -0.102445      0.0126328   -0.031054     0.0729445   -0.016115     -0.0313318   -0.000419543   0.107187     0.0439808
 -0.0400242    0.0136462    0.00958923    0.107232      0.203068    -0.100932     -0.0362495    0.0169636    0.0108326    0.105985      0.187167    -0.00675564   0.0424037   -0.0326838    0.0680335     0.120752     0.0429368   -0.135349      0.0441862   -0.0419808    0.0161641   -0.142596     -0.0735891   -0.0364908     0.0115515   -0.0453445
 -0.194632    -0.0705063    0.0267613    -0.0845592     0.0222507   -0.0473691    -0.188481     0.0186157    0.15196     -0.125512     -0.0488595    0.0175224   -0.133164    -0.182817     0.0375905     0.0254875   -0.0867297   -0.191212     -0.0164424   -0.0468937   -0.142737     0.114432      0.0386983    0.0538434     0.235556     0.0728395
  0.121951     0.16988     -0.075499     -0.0390726     0.0514249    0.118328      0.006014    -0.0303976   -0.104878     0.073489      0.0634981    0.0693147    0.069077     0.0291779    0.1543       -0.0285544    0.0204174   -0.0632251    -0.0618718   -0.0514296    0.144551    -0.0486028     0.0450901    0.118774     -0.183049     0.0696877
 -0.174051     0.125761     0.0795152     0.033955     -0.0813429    0.163383     -0.219374     0.0344395    0.11452      0.021422      0.159176    -0.0253331   -0.0455769   -0.0544309    0.0867706    -0.0318638    0.0081258   -0.131781      0.199152    -0.114921    -0.0254514    0.0408194     0.0691404    0.0416534    -0.147123     0.0513042
  0.0626798   -0.0278863    0.0551297     0.0253615     0.238039    -0.167818     -0.120039    -0.140904     0.0781126   -0.101918     -0.239389     0.0487465   -0.187043    -0.00913716  -0.116656      0.115387    -0.0420132   -0.171477      0.11476      0.0699107   -0.228596    -0.0343931    -0.0328623   -0.022867     -0.0870436    0.011707
  0.00171619  -0.0287297    0.141468      0.0334066     0.0635483    0.0111367     0.13116      0.050994     0.0978938    0.0213323     0.214373     0.112658    -0.101643    -0.258553     0.0677025     0.00269731  -0.0433509   -0.195471     -0.00123996   0.0853203    0.0536813   -0.155968      0.116993    -0.0124924    -0.0727533   -0.125472
  0.0925419    0.0860117   -0.100664     -0.0668831    -0.164453     0.148265     -0.151574    -0.0975492    0.0260668   -0.0514326     0.0559847    0.161017     0.020165     0.0963452    0.0507831    -0.0453994   -0.137744    -0.0542541    -0.135652    -0.114253    -0.182742     0.0947094     0.0970315    0.150715      0.0644808   -0.047288
  0.0110014   -0.0102406    0.0404351    -0.143482      0.00954599  -0.01487       0.00466773  -0.0480618    0.0260494    0.0223692    -0.00531714   0.100498    -0.0588186    0.0740858    0.070081      0.0650117   -0.189513    -0.0467124     0.0254909   -0.0266725   -0.197836     0.0548001     0.0605791    0.122499      0.0320395    0.0243717kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4188558858453097
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418873
[ Info: iteration 2, average log likelihood -1.418815
[ Info: iteration 3, average log likelihood -1.418771
[ Info: iteration 4, average log likelihood -1.418719
[ Info: iteration 5, average log likelihood -1.418656
[ Info: iteration 6, average log likelihood -1.418582
[ Info: iteration 7, average log likelihood -1.418501
[ Info: iteration 8, average log likelihood -1.418413
[ Info: iteration 9, average log likelihood -1.418314
[ Info: iteration 10, average log likelihood -1.418173
[ Info: iteration 11, average log likelihood -1.417920
[ Info: iteration 12, average log likelihood -1.417422
[ Info: iteration 13, average log likelihood -1.416545
[ Info: iteration 14, average log likelihood -1.415362
[ Info: iteration 15, average log likelihood -1.414280
[ Info: iteration 16, average log likelihood -1.413619
[ Info: iteration 17, average log likelihood -1.413317
[ Info: iteration 18, average log likelihood -1.413197
[ Info: iteration 19, average log likelihood -1.413151
[ Info: iteration 20, average log likelihood -1.413134
[ Info: iteration 21, average log likelihood -1.413127
[ Info: iteration 22, average log likelihood -1.413124
[ Info: iteration 23, average log likelihood -1.413123
[ Info: iteration 24, average log likelihood -1.413122
[ Info: iteration 25, average log likelihood -1.413122
[ Info: iteration 26, average log likelihood -1.413122
[ Info: iteration 27, average log likelihood -1.413121
[ Info: iteration 28, average log likelihood -1.413121
[ Info: iteration 29, average log likelihood -1.413121
[ Info: iteration 30, average log likelihood -1.413121
[ Info: iteration 31, average log likelihood -1.413121
[ Info: iteration 32, average log likelihood -1.413121
[ Info: iteration 33, average log likelihood -1.413121
[ Info: iteration 34, average log likelihood -1.413121
[ Info: iteration 35, average log likelihood -1.413121
[ Info: iteration 36, average log likelihood -1.413121
[ Info: iteration 37, average log likelihood -1.413121
[ Info: iteration 38, average log likelihood -1.413121
[ Info: iteration 39, average log likelihood -1.413121
[ Info: iteration 40, average log likelihood -1.413121
[ Info: iteration 41, average log likelihood -1.413121
[ Info: iteration 42, average log likelihood -1.413121
[ Info: iteration 43, average log likelihood -1.413121
[ Info: iteration 44, average log likelihood -1.413121
[ Info: iteration 45, average log likelihood -1.413121
[ Info: iteration 46, average log likelihood -1.413121
[ Info: iteration 47, average log likelihood -1.413120
[ Info: iteration 48, average log likelihood -1.413120
[ Info: iteration 49, average log likelihood -1.413120
[ Info: iteration 50, average log likelihood -1.413120
┌ Info: EM with 100000 data points 50 iterations avll -1.413120
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4188733484519573
│     -1.4188153978972573
│      ⋮
└     -1.413120465021568
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413134
[ Info: iteration 2, average log likelihood -1.413075
[ Info: iteration 3, average log likelihood -1.413026
[ Info: iteration 4, average log likelihood -1.412968
[ Info: iteration 5, average log likelihood -1.412898
[ Info: iteration 6, average log likelihood -1.412816
[ Info: iteration 7, average log likelihood -1.412726
[ Info: iteration 8, average log likelihood -1.412636
[ Info: iteration 9, average log likelihood -1.412553
[ Info: iteration 10, average log likelihood -1.412482
[ Info: iteration 11, average log likelihood -1.412424
[ Info: iteration 12, average log likelihood -1.412380
[ Info: iteration 13, average log likelihood -1.412347
[ Info: iteration 14, average log likelihood -1.412323
[ Info: iteration 15, average log likelihood -1.412307
[ Info: iteration 16, average log likelihood -1.412295
[ Info: iteration 17, average log likelihood -1.412286
[ Info: iteration 18, average log likelihood -1.412280
[ Info: iteration 19, average log likelihood -1.412275
[ Info: iteration 20, average log likelihood -1.412271
[ Info: iteration 21, average log likelihood -1.412267
[ Info: iteration 22, average log likelihood -1.412265
[ Info: iteration 23, average log likelihood -1.412262
[ Info: iteration 24, average log likelihood -1.412260
[ Info: iteration 25, average log likelihood -1.412257
[ Info: iteration 26, average log likelihood -1.412255
[ Info: iteration 27, average log likelihood -1.412253
[ Info: iteration 28, average log likelihood -1.412251
[ Info: iteration 29, average log likelihood -1.412249
[ Info: iteration 30, average log likelihood -1.412248
[ Info: iteration 31, average log likelihood -1.412246
[ Info: iteration 32, average log likelihood -1.412244
[ Info: iteration 33, average log likelihood -1.412243
[ Info: iteration 34, average log likelihood -1.412241
[ Info: iteration 35, average log likelihood -1.412239
[ Info: iteration 36, average log likelihood -1.412238
[ Info: iteration 37, average log likelihood -1.412236
[ Info: iteration 38, average log likelihood -1.412235
[ Info: iteration 39, average log likelihood -1.412234
[ Info: iteration 40, average log likelihood -1.412232
[ Info: iteration 41, average log likelihood -1.412231
[ Info: iteration 42, average log likelihood -1.412230
[ Info: iteration 43, average log likelihood -1.412228
[ Info: iteration 44, average log likelihood -1.412227
[ Info: iteration 45, average log likelihood -1.412226
[ Info: iteration 46, average log likelihood -1.412225
[ Info: iteration 47, average log likelihood -1.412224
[ Info: iteration 48, average log likelihood -1.412223
[ Info: iteration 49, average log likelihood -1.412222
[ Info: iteration 50, average log likelihood -1.412221
┌ Info: EM with 100000 data points 50 iterations avll -1.412221
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4131341567233187
│     -1.413075478223693
│      ⋮
└     -1.4122206855516544
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412229
[ Info: iteration 2, average log likelihood -1.412176
[ Info: iteration 3, average log likelihood -1.412125
[ Info: iteration 4, average log likelihood -1.412063
[ Info: iteration 5, average log likelihood -1.411986
[ Info: iteration 6, average log likelihood -1.411889
[ Info: iteration 7, average log likelihood -1.411777
[ Info: iteration 8, average log likelihood -1.411655
[ Info: iteration 9, average log likelihood -1.411534
[ Info: iteration 10, average log likelihood -1.411424
[ Info: iteration 11, average log likelihood -1.411329
[ Info: iteration 12, average log likelihood -1.411249
[ Info: iteration 13, average log likelihood -1.411185
[ Info: iteration 14, average log likelihood -1.411134
[ Info: iteration 15, average log likelihood -1.411093
[ Info: iteration 16, average log likelihood -1.411061
[ Info: iteration 17, average log likelihood -1.411035
[ Info: iteration 18, average log likelihood -1.411014
[ Info: iteration 19, average log likelihood -1.410997
[ Info: iteration 20, average log likelihood -1.410983
[ Info: iteration 21, average log likelihood -1.410971
[ Info: iteration 22, average log likelihood -1.410960
[ Info: iteration 23, average log likelihood -1.410951
[ Info: iteration 24, average log likelihood -1.410943
[ Info: iteration 25, average log likelihood -1.410935
[ Info: iteration 26, average log likelihood -1.410928
[ Info: iteration 27, average log likelihood -1.410921
[ Info: iteration 28, average log likelihood -1.410915
[ Info: iteration 29, average log likelihood -1.410909
[ Info: iteration 30, average log likelihood -1.410903
[ Info: iteration 31, average log likelihood -1.410898
[ Info: iteration 32, average log likelihood -1.410892
[ Info: iteration 33, average log likelihood -1.410887
[ Info: iteration 34, average log likelihood -1.410882
[ Info: iteration 35, average log likelihood -1.410877
[ Info: iteration 36, average log likelihood -1.410872
[ Info: iteration 37, average log likelihood -1.410867
[ Info: iteration 38, average log likelihood -1.410862
[ Info: iteration 39, average log likelihood -1.410857
[ Info: iteration 40, average log likelihood -1.410853
[ Info: iteration 41, average log likelihood -1.410848
[ Info: iteration 42, average log likelihood -1.410844
[ Info: iteration 43, average log likelihood -1.410840
[ Info: iteration 44, average log likelihood -1.410835
[ Info: iteration 45, average log likelihood -1.410831
[ Info: iteration 46, average log likelihood -1.410827
[ Info: iteration 47, average log likelihood -1.410823
[ Info: iteration 48, average log likelihood -1.410819
[ Info: iteration 49, average log likelihood -1.410815
[ Info: iteration 50, average log likelihood -1.410811
┌ Info: EM with 100000 data points 50 iterations avll -1.410811
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4122293442593075
│     -1.41217564685422
│      ⋮
└     -1.4108107916344652
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410815
[ Info: iteration 2, average log likelihood -1.410751
[ Info: iteration 3, average log likelihood -1.410690
[ Info: iteration 4, average log likelihood -1.410618
[ Info: iteration 5, average log likelihood -1.410531
[ Info: iteration 6, average log likelihood -1.410427
[ Info: iteration 7, average log likelihood -1.410309
[ Info: iteration 8, average log likelihood -1.410183
[ Info: iteration 9, average log likelihood -1.410055
[ Info: iteration 10, average log likelihood -1.409930
[ Info: iteration 11, average log likelihood -1.409813
[ Info: iteration 12, average log likelihood -1.409705
[ Info: iteration 13, average log likelihood -1.409607
[ Info: iteration 14, average log likelihood -1.409519
[ Info: iteration 15, average log likelihood -1.409442
[ Info: iteration 16, average log likelihood -1.409373
[ Info: iteration 17, average log likelihood -1.409312
[ Info: iteration 18, average log likelihood -1.409258
[ Info: iteration 19, average log likelihood -1.409209
[ Info: iteration 20, average log likelihood -1.409165
[ Info: iteration 21, average log likelihood -1.409125
[ Info: iteration 22, average log likelihood -1.409088
[ Info: iteration 23, average log likelihood -1.409053
[ Info: iteration 24, average log likelihood -1.409020
[ Info: iteration 25, average log likelihood -1.408990
[ Info: iteration 26, average log likelihood -1.408960
[ Info: iteration 27, average log likelihood -1.408933
[ Info: iteration 28, average log likelihood -1.408906
[ Info: iteration 29, average log likelihood -1.408881
[ Info: iteration 30, average log likelihood -1.408857
[ Info: iteration 31, average log likelihood -1.408834
[ Info: iteration 32, average log likelihood -1.408812
[ Info: iteration 33, average log likelihood -1.408791
[ Info: iteration 34, average log likelihood -1.408771
[ Info: iteration 35, average log likelihood -1.408751
[ Info: iteration 36, average log likelihood -1.408733
[ Info: iteration 37, average log likelihood -1.408715
[ Info: iteration 38, average log likelihood -1.408698
[ Info: iteration 39, average log likelihood -1.408681
[ Info: iteration 40, average log likelihood -1.408666
[ Info: iteration 41, average log likelihood -1.408651
[ Info: iteration 42, average log likelihood -1.408636
[ Info: iteration 43, average log likelihood -1.408622
[ Info: iteration 44, average log likelihood -1.408608
[ Info: iteration 45, average log likelihood -1.408595
[ Info: iteration 46, average log likelihood -1.408583
[ Info: iteration 47, average log likelihood -1.408571
[ Info: iteration 48, average log likelihood -1.408559
[ Info: iteration 49, average log likelihood -1.408547
[ Info: iteration 50, average log likelihood -1.408536
┌ Info: EM with 100000 data points 50 iterations avll -1.408536
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4108146329213729
│     -1.4107511984800738
│      ⋮
└     -1.408536319450461
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408534
[ Info: iteration 2, average log likelihood -1.408456
[ Info: iteration 3, average log likelihood -1.408377
[ Info: iteration 4, average log likelihood -1.408278
[ Info: iteration 5, average log likelihood -1.408151
[ Info: iteration 6, average log likelihood -1.407997
[ Info: iteration 7, average log likelihood -1.407822
[ Info: iteration 8, average log likelihood -1.407637
[ Info: iteration 9, average log likelihood -1.407449
[ Info: iteration 10, average log likelihood -1.407266
[ Info: iteration 11, average log likelihood -1.407095
[ Info: iteration 12, average log likelihood -1.406940
[ Info: iteration 13, average log likelihood -1.406803
[ Info: iteration 14, average log likelihood -1.406683
[ Info: iteration 15, average log likelihood -1.406579
[ Info: iteration 16, average log likelihood -1.406489
[ Info: iteration 17, average log likelihood -1.406410
[ Info: iteration 18, average log likelihood -1.406341
[ Info: iteration 19, average log likelihood -1.406280
[ Info: iteration 20, average log likelihood -1.406226
[ Info: iteration 21, average log likelihood -1.406178
[ Info: iteration 22, average log likelihood -1.406134
[ Info: iteration 23, average log likelihood -1.406095
[ Info: iteration 24, average log likelihood -1.406059
[ Info: iteration 25, average log likelihood -1.406027
[ Info: iteration 26, average log likelihood -1.405996
[ Info: iteration 27, average log likelihood -1.405969
[ Info: iteration 28, average log likelihood -1.405943
[ Info: iteration 29, average log likelihood -1.405918
[ Info: iteration 30, average log likelihood -1.405896
[ Info: iteration 31, average log likelihood -1.405874
[ Info: iteration 32, average log likelihood -1.405854
[ Info: iteration 33, average log likelihood -1.405835
[ Info: iteration 34, average log likelihood -1.405816
[ Info: iteration 35, average log likelihood -1.405799
[ Info: iteration 36, average log likelihood -1.405782
[ Info: iteration 37, average log likelihood -1.405766
[ Info: iteration 38, average log likelihood -1.405751
[ Info: iteration 39, average log likelihood -1.405736
[ Info: iteration 40, average log likelihood -1.405722
[ Info: iteration 41, average log likelihood -1.405708
[ Info: iteration 42, average log likelihood -1.405695
[ Info: iteration 43, average log likelihood -1.405682
[ Info: iteration 44, average log likelihood -1.405669
[ Info: iteration 45, average log likelihood -1.405657
[ Info: iteration 46, average log likelihood -1.405646
[ Info: iteration 47, average log likelihood -1.405635
[ Info: iteration 48, average log likelihood -1.405624
[ Info: iteration 49, average log likelihood -1.405613
[ Info: iteration 50, average log likelihood -1.405603
┌ Info: EM with 100000 data points 50 iterations avll -1.405603
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4085341508256817
│     -1.4084561827147344
│      ⋮
└     -1.4056028531710993
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4188558858453097
│     -1.4188733484519573
│     -1.4188153978972573
│     -1.418770976441747
│      ⋮
│     -1.4056237183656928
│     -1.4056131336223303
└     -1.4056028531710993
32×26 Array{Float64,2}:
 -0.43828    -0.212717    -0.0377365   -0.113573   -0.16627    -0.175103    0.589852   -0.620528    0.217584     0.122785   -0.106749    -0.257707     0.0187186   -0.0412907   -0.204755    0.198761    0.0551796  -0.780028    0.431406    -0.886407    0.323997     0.353652    -0.266821    0.178452   -0.286131    -0.362431
  0.182422   -0.457228     0.0351513   -0.788713    0.542346   -0.0460086   0.395401   -0.7406      0.0870532   -0.063993    0.0556304   -0.601377    -0.193261    -0.702016     0.0326921  -0.417749   -0.162203   -0.286176    0.383991    -0.110432    0.225122     0.713726    -0.447073   -0.183292   -0.117473     0.759882
  0.0695638  -0.067479     0.540258    -0.457384   -0.210722   -0.40574    -0.310682   -0.116369    0.731992    -0.192117   -0.452551    -0.352306    -0.864001     0.290118    -0.368285   -0.534877    0.306766   -0.261972    0.293927     0.115315   -0.286438     0.293375     0.193089    0.264562    0.797635    -0.427942
 -0.914624   -0.137908    -0.309942    -0.271119   -0.178251   -0.133101   -0.451685    0.0260186   0.0960228   -0.144245    0.270576    -0.23431     -0.121924     0.20033     -0.52991    -0.170685    0.354335   -0.428044    0.0457054    0.0425869   0.0684394    0.255953     0.462557   -0.116341    0.700418    -0.568731
 -0.233811   -0.230686     0.0396646    0.0647232   0.112857   -0.192451    0.0402425  -0.063115    0.139518     0.0084203   0.112482    -0.158391     0.221349     0.182182     0.0287378  -0.057262   -0.0487792  -0.340213    0.0356425   -0.40021    -0.119233     0.0366917   -0.131261    0.0173412  -0.183874    -0.104756
 -0.0408816   0.247736     0.0734726    0.218755    0.0437333   0.261467   -0.306036    0.541475   -0.225429     0.165964    0.152066     0.521152    -0.261374    -0.331169     0.150849    0.197579    0.0619032   0.243212    0.00487151   0.68055     0.43836     -0.205051     0.184304    0.287758    0.256733     0.136181
 -0.480924    0.284677     0.174958     1.10778    -0.247846   -0.270244    0.113227    0.453208   -0.566447    -0.260143   -0.463974    -0.00404961  -0.273112    -0.417313    -0.177258   -0.137066   -0.234843   -0.613733    0.297695    -0.247583   -0.774732     0.160546    -0.0341642  -0.0924002   0.00265965  -0.0596249
 -0.290087    0.114972    -0.211803     0.587436    0.808671   -0.474283   -0.329326    0.565396    0.149709    -0.618539   -0.104327     0.433855     0.305828    -0.242493     0.46112     0.155064    0.0279082  -0.419113   -0.168523    -0.414759    0.134851     0.285792    -0.246421   -0.156392    0.0637037    0.159891
 -0.078619   -0.822479    -0.505478    -0.211067    0.0483341  -0.123563    0.263069   -0.0214197  -0.269684    -0.266861   -1.11161     -0.239137    -0.437512    -0.00447561  -0.33703     0.0451368  -0.310897    0.444163   -0.240458    -0.0995614   0.229122    -0.48174      0.492535    0.317224   -0.355494     0.49805
 -0.747617    0.691979    -0.751909     0.410217    0.0731798  -0.168182   -0.176759   -0.47834     0.0112405   -0.0931531  -0.597664     0.069963    -0.183236     0.0724441    0.327305    0.147162   -0.638301    0.669964    0.122276    -0.0256444   0.193012    -0.0626981    0.187667    0.120481    0.335766     0.349424
  0.965065   -0.105764    -0.272417     0.340674    0.133824    0.455109    0.127503    0.176773   -0.527342    -0.41803    -0.0125693    0.315029     0.193621    -0.146104     0.467958   -0.451043   -0.311439    0.0936207  -0.372948    -0.199336   -0.461742    -0.0504375   -0.135176   -0.698722   -0.525262     0.447592
 -0.268793    0.0140265   -0.0138649    0.0571196   0.238984    1.0336      0.399164   -0.0116163  -0.161892    -0.079177   -0.0788661    0.728119     1.54361      0.0336897    0.0373968   0.493692   -0.110405    0.166292   -0.251935    -0.429576   -0.154428    -0.0310923    0.199224    0.56291    -0.782923     0.629082
  0.210626   -0.385314    -0.118559    -0.274159   -1.15813     0.271232   -0.114491   -0.187668   -0.250866     0.719162    0.035295     0.239375     0.301338     0.0951622   -0.193782   -0.510658    0.185971    0.346235   -0.161003     0.197133   -0.208145    -0.450623    -0.0449624   0.123484   -0.332693    -0.2252
  0.64957     0.459389     0.0886547   -0.312085   -0.913446   -0.221179   -0.0865048  -0.529434   -0.183028    -0.0945264  -0.467825    -0.654013    -0.109439     0.490397     0.0264714   0.303613    0.100666    0.192812    0.211844     0.212312   -0.0435915    0.525375     0.32076    -0.0821469  -0.524381    -0.172442
 -0.0357371   0.0307079    0.31545     -0.661511    0.944783    0.0510171  -0.260808    0.170985    0.206657    -0.155273    0.0182226   -0.711836     0.768868     0.0372737    0.319387   -0.371033    0.17496     0.239371    0.195896     0.565815   -1.24529      0.174393    -0.0812262   0.18061     0.0791002    0.303612
  0.415756   -0.121266    -0.370312    -0.778894    0.464384    0.434879    0.204188   -0.315761    0.696704     0.18072     0.66637     -0.082438     0.239944     0.528247     0.599069   -0.12944     0.389734    0.596393   -0.160867     0.53118     0.850348     0.105911     0.33085    -0.0524526  -0.00204649   0.0206348
 -0.478292   -0.36953     -0.103158     0.107916   -0.0682236  -0.704797   -0.252263   -0.177275    0.359555     0.183665   -0.00221523  -0.212902     0.0673376    0.451717    -0.0295209   0.101099   -0.0630086   0.302627    0.0844645    0.255848    0.307587    -0.0122142    0.376698    0.0951263  -0.399203     0.0810437
 -0.452784   -0.461073    -0.1986       0.0700228  -0.310812    0.250986   -0.590351   -0.19964    -0.15914     -0.181031   -0.153182    -0.362812     0.525221     0.0853794    0.232449   -0.111307    0.0439402  -0.549143    0.334732    -0.286049    0.244602     0.4403       0.444084    0.109242   -0.182627     0.137552
 -0.123524   -0.174934     0.00512618   0.0714253   0.0679914  -0.0142648  -0.0011435  -0.0940064  -0.00895567   0.0674399   0.0276439    0.0363842    0.0980585    0.0333451    0.0403124  -0.084156   -0.0540318  -0.0885667  -0.0978978   -0.117666   -0.00495747  -0.0787123   -0.0489723   0.248477   -0.0443978   -0.0317073
 -0.0751238   0.453946    -0.14895      0.0436515  -0.106219   -0.0522172  -0.0975011  -0.0201077   0.110342     0.0993742   0.0535476   -0.0419195   -0.276028    -0.0984732   -0.0400491  -0.0688867   0.0784015  -0.208682    0.179298     0.110392   -0.0468791    0.14454     -0.0407214  -0.140045    0.259513    -0.316602
  0.153086   -0.189475     0.202468     0.146692   -0.568078    0.601142   -0.265073   -0.234316   -0.217371     0.191786    0.437883     0.0661118   -0.654868    -0.344966     0.258284    0.0306324   0.038007   -0.222617   -0.147168    -0.0428737   0.474598     0.529876    -0.0322986   0.558539   -0.208404    -0.129101
  0.212915    0.356988     0.33265     -0.171428   -0.0604303   0.704775   -0.481026   -0.130282   -0.0984611   -0.329837   -0.856431     0.252467     0.0912387   -0.713174     0.301874   -0.583207    0.02936     0.244539    0.390982    -0.0635171   0.226253     0.00521799  -0.332916    0.514059    0.239878     0.0468204
  0.31811    -0.708        0.250298    -0.468094    0.0322409   0.158651    0.327832    0.285524   -0.203965    -0.364376   -0.0488437   -0.112373     0.00918625  -0.107537    -0.176687    0.278928    0.260187   -0.418635   -0.376726    -0.304163   -0.284477    -0.305168    -0.1556      0.0429258   0.0233524    0.0468839
  0.422922    0.00607651   0.0477184   -0.266975   -0.0199442   0.191293    0.015098   -0.0525052  -0.0408656   -0.246447   -0.180833    -0.164194    -0.0659996   -0.00816816   0.166721    0.0876072   0.039783    0.343806   -0.0089976    0.063898   -0.0598946    0.0526531    0.153429   -0.267419   -0.0676377    0.330213
  0.226659    0.544797    -0.0705763   -0.030961    0.288311   -0.673042    0.264539    0.0649856   0.228028    -0.119546    0.0726233    0.329976    -0.601491    -0.296623    -0.442201    0.0697866  -0.286307    0.534233   -0.431705     0.129509   -0.609643    -0.777762    -0.549263   -0.359166    0.465627    -0.025537
  0.138131    0.250047     0.0624446    0.625776    0.0229351  -0.0437081  -0.346779    0.196891   -0.361119    -0.18893     0.185632     0.110177    -0.143821     0.589261     0.132863   -0.225947   -0.029059    0.304728   -0.513258     0.245755   -0.57127     -0.189695     0.162866   -0.151044    0.102684    -0.375794
 -0.207467    0.216952    -0.368306     0.391753   -0.434046    0.238095   -0.0759899   0.40827    -0.166635     0.0433869  -0.499036     0.476432    -0.235668     0.120821    -0.699509    0.509479   -0.246115   -0.0284147   0.102593    -0.136234    0.647228    -0.841709     0.0536641   0.184251    0.0545162   -0.294164
 -0.117879   -0.161774    -0.251524    -0.270097    0.832091    0.0848128   0.639889    0.262352    0.0941204   -0.112893    0.510519     0.0425683   -0.468544    -0.313659    -0.31708     0.13997     0.0339878  -0.380002   -0.21619     -0.273885    0.759452    -0.672525     0.320839   -0.224149    0.381396    -0.190391
 -0.172737   -0.0815604    0.0299177    0.05817     0.333693   -0.14636     0.0800231   0.357123    0.377367     0.493935    0.271017     0.520299     0.137757    -0.273208    -0.0613552  -0.340297   -0.229809   -0.0065648   0.512892     0.241178    0.143516    -0.201271    -0.0839422  -0.135094   -0.0207711    0.270031
  0.723356   -0.103585     0.457695     0.0993626   0.139678   -0.329217    0.121193   -0.122993    0.485729     0.310981    0.0814163    0.217268     0.0379154   -0.230461     0.539938    0.153814   -0.163624    0.109838    0.0820319    0.274711   -0.191976    -0.129873    -0.465307    0.369314   -0.70512      0.285127
  0.216069    0.54451      0.0703017   -0.0157971   0.0181081   0.0932283  -0.228782   -0.0877711   0.0693411    0.731319    1.14433     -0.0356794    0.147728     0.153625     0.304962    0.0140531   0.36592    -0.122976    0.174233     0.0665282  -0.270181     0.280256    -0.355532   -0.855096    0.087828    -0.446432
 -0.170626    0.792624     0.528143    -0.0110208   0.238446    0.174799    0.0167727  -0.0558146   0.0937581    0.426378    0.876362     0.385968    -0.150962    -0.145106     0.259492    0.346505   -0.0532077  -0.321608   -0.240554    -0.0922211   0.0563743    0.165636    -0.590995    0.404587    0.562334    -0.19555[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405593
[ Info: iteration 2, average log likelihood -1.405583
[ Info: iteration 3, average log likelihood -1.405574
[ Info: iteration 4, average log likelihood -1.405564
[ Info: iteration 5, average log likelihood -1.405556
[ Info: iteration 6, average log likelihood -1.405547
[ Info: iteration 7, average log likelihood -1.405538
[ Info: iteration 8, average log likelihood -1.405530
[ Info: iteration 9, average log likelihood -1.405522
[ Info: iteration 10, average log likelihood -1.405514
┌ Info: EM with 100000 data points 10 iterations avll -1.405514
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.243241e+05
      1       6.982855e+05      -2.260387e+05 |       32
      2       6.846727e+05      -1.361280e+04 |       32
      3       6.799555e+05      -4.717177e+03 |       32
      4       6.775114e+05      -2.444048e+03 |       32
      5       6.760016e+05      -1.509862e+03 |       32
      6       6.749099e+05      -1.091676e+03 |       32
      7       6.740200e+05      -8.898701e+02 |       32
      8       6.732564e+05      -7.636609e+02 |       32
      9       6.726250e+05      -6.313432e+02 |       32
     10       6.720924e+05      -5.325959e+02 |       32
     11       6.716424e+05      -4.500669e+02 |       32
     12       6.712676e+05      -3.747071e+02 |       32
     13       6.709502e+05      -3.174654e+02 |       32
     14       6.706545e+05      -2.956478e+02 |       32
     15       6.703849e+05      -2.696060e+02 |       32
     16       6.701493e+05      -2.356014e+02 |       32
     17       6.699273e+05      -2.220062e+02 |       32
     18       6.697002e+05      -2.271345e+02 |       32
     19       6.694857e+05      -2.145171e+02 |       32
     20       6.692980e+05      -1.876856e+02 |       32
     21       6.691317e+05      -1.662344e+02 |       32
     22       6.689952e+05      -1.365675e+02 |       32
     23       6.688619e+05      -1.333176e+02 |       32
     24       6.687379e+05      -1.239894e+02 |       32
     25       6.686265e+05      -1.114072e+02 |       32
     26       6.685251e+05      -1.013918e+02 |       32
     27       6.684389e+05      -8.614909e+01 |       32
     28       6.683647e+05      -7.418356e+01 |       32
     29       6.682817e+05      -8.305364e+01 |       32
     30       6.681948e+05      -8.691411e+01 |       32
     31       6.680995e+05      -9.522510e+01 |       32
     32       6.680069e+05      -9.265218e+01 |       32
     33       6.679192e+05      -8.765245e+01 |       32
     34       6.678400e+05      -7.920190e+01 |       32
     35       6.677575e+05      -8.253819e+01 |       32
     36       6.676862e+05      -7.127009e+01 |       32
     37       6.676205e+05      -6.573428e+01 |       32
     38       6.675551e+05      -6.536686e+01 |       32
     39       6.674950e+05      -6.011364e+01 |       32
     40       6.674479e+05      -4.714478e+01 |       32
     41       6.674004e+05      -4.748697e+01 |       32
     42       6.673530e+05      -4.734215e+01 |       32
     43       6.673077e+05      -4.534829e+01 |       32
     44       6.672655e+05      -4.218833e+01 |       32
     45       6.672264e+05      -3.907668e+01 |       32
     46       6.671868e+05      -3.965586e+01 |       32
     47       6.671476e+05      -3.916213e+01 |       32
     48       6.671097e+05      -3.790344e+01 |       32
     49       6.670747e+05      -3.499247e+01 |       32
     50       6.670428e+05      -3.192758e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 667042.7914052075)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417633
[ Info: iteration 2, average log likelihood -1.412651
[ Info: iteration 3, average log likelihood -1.411351
[ Info: iteration 4, average log likelihood -1.410415
[ Info: iteration 5, average log likelihood -1.409384
[ Info: iteration 6, average log likelihood -1.408322
[ Info: iteration 7, average log likelihood -1.407505
[ Info: iteration 8, average log likelihood -1.407026
[ Info: iteration 9, average log likelihood -1.406765
[ Info: iteration 10, average log likelihood -1.406608
[ Info: iteration 11, average log likelihood -1.406498
[ Info: iteration 12, average log likelihood -1.406412
[ Info: iteration 13, average log likelihood -1.406340
[ Info: iteration 14, average log likelihood -1.406277
[ Info: iteration 15, average log likelihood -1.406222
[ Info: iteration 16, average log likelihood -1.406171
[ Info: iteration 17, average log likelihood -1.406125
[ Info: iteration 18, average log likelihood -1.406082
[ Info: iteration 19, average log likelihood -1.406042
[ Info: iteration 20, average log likelihood -1.406004
[ Info: iteration 21, average log likelihood -1.405969
[ Info: iteration 22, average log likelihood -1.405935
[ Info: iteration 23, average log likelihood -1.405903
[ Info: iteration 24, average log likelihood -1.405872
[ Info: iteration 25, average log likelihood -1.405842
[ Info: iteration 26, average log likelihood -1.405814
[ Info: iteration 27, average log likelihood -1.405787
[ Info: iteration 28, average log likelihood -1.405761
[ Info: iteration 29, average log likelihood -1.405736
[ Info: iteration 30, average log likelihood -1.405712
[ Info: iteration 31, average log likelihood -1.405690
[ Info: iteration 32, average log likelihood -1.405669
[ Info: iteration 33, average log likelihood -1.405649
[ Info: iteration 34, average log likelihood -1.405630
[ Info: iteration 35, average log likelihood -1.405612
[ Info: iteration 36, average log likelihood -1.405595
[ Info: iteration 37, average log likelihood -1.405579
[ Info: iteration 38, average log likelihood -1.405564
[ Info: iteration 39, average log likelihood -1.405550
[ Info: iteration 40, average log likelihood -1.405537
[ Info: iteration 41, average log likelihood -1.405524
[ Info: iteration 42, average log likelihood -1.405512
[ Info: iteration 43, average log likelihood -1.405501
[ Info: iteration 44, average log likelihood -1.405490
[ Info: iteration 45, average log likelihood -1.405479
[ Info: iteration 46, average log likelihood -1.405469
[ Info: iteration 47, average log likelihood -1.405460
[ Info: iteration 48, average log likelihood -1.405451
[ Info: iteration 49, average log likelihood -1.405442
[ Info: iteration 50, average log likelihood -1.405433
┌ Info: EM with 100000 data points 50 iterations avll -1.405433
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0103291  -0.049833     0.466946     0.181247     0.0539903    0.440607    0.00453115  -0.0221446  -0.580756     0.030795    0.662461    -0.0857236   -0.337017    -0.0246444   0.496163     0.480334    0.381382    -0.135765    -0.867478   -0.164885    0.283304    0.165578    -0.0872004   0.359761     0.0670316    0.0168346
 -0.0358836  -0.26972     -0.14955     -0.12649      0.22126     -0.151975    0.3188       0.18361    -0.0339737    0.0354736   0.292745    -0.104467     0.0120402    0.108387   -0.156274    -0.0283528   0.181031    -0.353874    -0.180828   -0.210931   -0.0184586  -0.191982     0.0349915  -0.240995     0.0690903   -0.0503923
 -0.35839    -0.551673    -0.524379    -0.0945183    0.100621    -0.351416    0.0220193   -0.245584   -0.018327    -0.178267   -0.717477    -0.22681     -0.218893     0.354437   -0.148258     0.0699483  -0.297635     0.584026    -0.191717    0.0374595   0.339615   -0.248        0.412072    0.202829    -0.339538     0.549725
  0.378897    0.367256     0.494545    -0.0119045   -0.328076     0.196419   -0.0401704    0.380503    0.0765864    0.26224     0.62989      0.267246    -0.353355    -0.627922    0.270166    -0.160282   -0.0607279   -0.67399      0.283375   -0.0210098  -0.17349     0.246765    -0.235648   -0.0368947    0.204273    -0.647773
  0.157702   -0.229086     0.0147814   -0.510324     0.631984    -0.370964    0.614674    -0.482065    0.119       -0.557805   -0.0225946   -0.508179    -0.216884    -0.358465   -0.221413     0.147419   -0.188584    -0.442463    -0.0193519  -0.378506   -0.0892791   0.45848     -0.400281   -0.280876    -0.0245254    0.250594
 -0.170053   -0.116103     0.0442363    0.00871969   0.251954     0.854144    0.428498     0.063004   -0.143745    -0.147881   -0.126673     0.604314     1.50835      0.0426591   0.0303243    0.524044   -0.168972     0.0416918   -0.158251   -0.430932   -0.147526   -0.0513895    0.151974    0.525754    -0.81067      0.656125
  0.161425   -0.0863581   -0.197912    -0.228018    -0.92978      0.38998    -0.114115    -0.0218139  -0.299826     0.731191    0.144983     0.533749     0.272539    -0.166888   -0.294854    -0.189862    0.167965     0.51207     -0.340374    0.3799      0.0291641  -0.624304    -0.117978    0.0407982   -0.247304    -0.237806
  0.385702    0.229174     0.0903299    0.669648    -0.00366518  -0.025562   -0.132659     0.175937   -0.419254    -0.365742    0.0200383    0.114626     0.00381156   0.457698    0.200531    -0.249675   -0.122775     0.334333    -0.467692    0.14783    -0.785104   -0.0894175    0.0328962  -0.525129    -0.083617    -0.151706
  0.215375   -0.59529      0.250201    -0.146458    -0.377329     0.0851097   0.00246877   0.498028   -0.155065    -0.519877   -0.90975     -0.134173    -0.245878    -0.146633   -0.39072      0.336616   -0.0444138   -0.158561    -0.080478   -0.196223   -0.0561929  -0.794078     0.281474    0.50625     -0.0603828   -0.0932691
  0.177785   -0.18615      0.342448     0.00249762   0.136834    -0.773211   -0.186381     0.219339    0.515972     0.402681    0.622918    -0.445223     0.501432     0.0486241   0.653334    -0.108602   -0.00538537  -0.194542    -0.315689    0.266766   -0.796564    0.240026    -0.312538    0.231122    -0.577225     0.189037
 -0.190918   -0.0728347    0.0644898    0.472709     0.177832    -0.360809   -0.173232     0.558001    0.231334     0.618148    0.0141576    0.541933     0.00301289  -0.113653    0.086083    -0.153968   -0.317278    -0.0599063    0.787404    0.608601    0.316584   -0.101949     0.332023    0.142426    -0.664596     0.0588669
 -0.0977114   0.0527232    0.0195091    0.0463638   -0.141789     0.287741   -0.345921    -0.59086     0.0949893   -0.144038   -0.325292     0.171846     0.0159715   -0.204786    0.330812    -0.336147    0.101234    -0.241043     0.251348   -0.332133    0.297538    0.208657    -0.224774    0.727358     0.0705603   -0.201623
  0.299029    0.180517    -0.166733    -0.323811    -0.440611    -0.683316   -0.475819    -0.0934089   0.327386     0.0171317   0.00267666  -0.549636    -1.23718     -0.0592604  -0.332388    -0.39537     0.033784     0.00592551   0.141071    0.467859   -0.235187   -0.0331375   -0.173455   -0.412886     0.822503    -0.555398
  0.0655332   0.0777811    0.363285    -0.855803     0.825503     0.279068   -0.305568     0.181619    0.110735    -0.301706   -0.379421    -0.66752      0.682144    -0.123792    0.125115    -0.410504    0.130053     0.296974     0.434291    0.446461   -0.952259   -0.0178214   -0.144459    0.261145     0.261112     0.244962
 -0.36328     0.520022    -0.406555    -0.180982     0.1774       0.445825    0.190459     0.351115   -0.0650442    0.0218983  -0.285377    -0.00638691  -0.459666    -0.496278   -0.412597     0.287312   -0.136378    -0.262402     0.304686   -0.161359    0.530125   -0.19142      0.137219   -0.100088     0.512815    -0.0128229
  0.430314   -0.0746599   -0.294734    -0.792753     0.502346     0.235311    0.15426     -0.255927    0.724054     0.143888    0.530666    -0.178616     0.116215     0.368193    0.610858     0.0164258   0.307416     0.61681     -0.128508    0.689623    0.821706    0.13937      0.527142   -0.108609    -0.118629     0.0472178
 -0.215491    0.00104972   1.46948     -0.425417     0.326876    -0.539088   -0.248554     0.307358    1.08314     -0.373256   -0.914323     0.166505    -0.93885      0.781117   -0.489097    -0.515993    1.34607     -0.390578    -0.237706   -0.137613   -0.453447    1.0349       0.363974    0.712459     0.921768     0.0455448
 -0.30318     0.24824     -0.0215807    1.05434     -0.75249     -0.225248   -0.0795704    0.613433   -1.12957      0.0509519  -0.385194     0.14593     -0.371835    -0.248881   -0.546412    -0.212138   -0.143653    -0.729582     0.088417   -0.756321   -0.559062   -0.164745    -0.505392    0.174729     0.211927    -0.126138
 -0.670185   -0.339057    -0.0640332   -0.220291    -0.337026    -0.245738    0.312984    -0.452148    0.409923     0.283409   -0.0179456   -0.329755     0.0318465    0.0140839  -0.381704     0.181295    0.129272    -0.708145     0.613925   -0.692963    0.492735    0.24301      0.0598005   0.172247    -0.211071    -0.413856
  0.407961    0.373423     0.375       -0.0604646    0.278279    -0.231193    0.49171     -0.43047     0.409308     0.614143    0.412769     0.453829    -0.709777     0.0185765  -0.31678      0.243745   -0.203361     0.121678    -0.0539603   0.145887   -0.177372   -0.496567    -0.65942     0.313687     0.00145681   0.14163
  0.678862    0.198181     0.226719    -0.364123    -0.99378      0.0225385  -0.0755669   -0.613693   -0.0812673    0.0695501  -0.492979    -0.5445      -0.0927909    0.453657    0.0625807    0.0458054   0.0986412    0.17553      0.382907    0.0827027  -0.0323957   0.471403     0.254817    0.0269502   -0.525678    -0.0974912
 -0.0307713  -0.0149863   -0.0389545    0.119852     0.188328     0.142897   -0.0721303    0.243731   -0.0847093   -0.0293399   0.0917584    0.183992    -0.0724404   -0.0105007   0.0631841   -0.0182682  -0.0182674    0.00938784  -0.0488993   0.0397062   0.130392   -0.181903     0.054754   -0.00934489   0.0969253   -0.0471519
  0.876005   -0.386699    -0.168832    -0.156167     0.0254266    0.590564    0.176811    -0.110295   -0.400236    -0.381274   -0.497505     0.189384    -0.101511    -0.445436    0.248677    -0.361105   -0.225867     0.164306     0.0620196  -0.355622    0.0282672  -0.0515046   -0.0889112  -0.405087    -0.472685     0.643832
 -0.72606    -0.0121972   -0.237363     0.105708    -0.220265    -0.277912   -0.544943    -0.0387593   0.205489    -0.0166747   0.285741    -0.0686222   -0.0106605    0.627277   -0.372084    -0.0595343   0.142864    -0.0724612    0.0157765   0.133224    0.0408396   0.00689874   0.425408   -0.00596967   0.527029    -0.67367
 -0.026745   -0.68509     -0.128774    -0.491659     0.351275     0.541362    0.168282    -0.328861    0.25386      0.400045    0.683085     0.220365     0.367288    -0.125672    0.3223      -0.755563    0.090714    -0.174432     0.0105985  -0.398676    0.498768   -0.201054    -0.583504    0.0383453    0.260577     0.532208
 -0.270254    0.282914    -0.165149     0.407629     0.74004     -0.414649    0.0609204    0.557098    0.204219    -0.248305    0.187475     0.592145    -0.111035    -0.449225   -0.0438322   -0.0328314  -0.128092     0.00479529  -0.325546    0.0488302   0.0460199  -0.462889    -0.320104   -0.108545     0.35118     -0.0601416
 -0.407133   -0.0311785   -0.123306     0.670958     0.360751    -0.238425   -0.43062      0.464207    0.0391719   -0.648112   -0.399098     0.107824     0.406318    -0.17132     0.645024     0.0425237   0.0056657   -0.678698     0.195683   -0.66467     0.0756775   0.466553     0.0964448  -0.126755    -0.0441248    0.19683
  0.159171    0.0633675    0.0634998   -0.00915477   0.022433    -0.0145542  -0.092156     0.0123073   0.144807    -0.0247037  -0.094995     0.0974035    0.0271695   -0.109062    0.132331    -0.0522107  -0.0347662    0.223202     0.0666738   0.148614   -0.0788715  -0.0502132   -0.0233428  -0.0454225   -0.0442915    0.108516
  0.043378    0.967353     0.091639    -0.0105983    0.312906     0.288414   -0.2957      -0.335624    0.229105     0.627658    0.966483     0.151194     0.322704     0.119078    0.505737     0.148578    0.233493     0.113458     0.321342    0.0337936  -0.183624    0.531627    -0.486127   -0.648707     0.199014    -0.203057
 -0.270607   -0.0840157    0.00154847   0.102032    -0.250001     0.0607935  -0.121658    -0.329179   -0.0986581    0.175249    0.141389    -0.251056    -0.0122547    0.186056   -0.00647936   0.0673202  -0.0745323   -0.258884     0.0212927  -0.130743    0.0965754   0.337595     0.0844327   0.240132    -0.128509    -0.0927766
 -0.494283    0.804622    -0.403659     0.643083    -0.110129    -0.208683   -0.170246    -0.353957   -0.00752737  -0.145147   -0.808065     0.267461    -0.0272083   -0.205831    0.113502     0.103036   -0.673718     0.741262     0.1814      0.220469   -0.139583   -0.0836265    0.120865    0.263168     0.187443     0.405655
 -0.399442   -0.694119    -0.115902    -0.475005    -0.484327     0.508341   -0.53028     -0.103577   -0.473912    -0.34281     0.199897    -0.418049     0.192013    -0.340859   -0.00275969  -0.189966    0.469721    -0.761749     0.307793    0.436625   -0.106411    0.882227     0.622615   -0.232952     8.99028e-5   0.131237[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405425
[ Info: iteration 2, average log likelihood -1.405417
[ Info: iteration 3, average log likelihood -1.405410
[ Info: iteration 4, average log likelihood -1.405402
[ Info: iteration 5, average log likelihood -1.405395
[ Info: iteration 6, average log likelihood -1.405388
[ Info: iteration 7, average log likelihood -1.405381
[ Info: iteration 8, average log likelihood -1.405375
[ Info: iteration 9, average log likelihood -1.405368
[ Info: iteration 10, average log likelihood -1.405362
┌ Info: EM with 100000 data points 10 iterations avll -1.405362
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
