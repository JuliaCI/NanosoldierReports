Julia Version 1.5.0-DEV.256
Commit 4513dda9e3 (2020-02-10 18:52 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed GaussianMixtures ─── v0.3.0
  Installed Arpack_jll ───────── v3.5.0+2
  Installed SortingAlgorithms ── v0.3.1
  Installed SpecialFunctions ─── v0.9.0
  Installed StaticArrays ─────── v0.12.1
  Installed StatsBase ────────── v0.32.0
  Installed Distributions ────── v0.22.4
  Installed Missings ─────────── v0.4.3
  Installed FillArrays ───────── v0.8.4
  Installed JLD ──────────────── v0.9.2
  Installed ScikitLearnBase ──── v0.5.0
  Installed BinDeps ──────────── v1.0.0
  Installed Compat ───────────── v2.2.0
  Installed Distances ────────── v0.8.2
  Installed Rmath ────────────── v0.6.0
  Installed CMakeWrapper ─────── v0.2.3
  Installed FileIO ───────────── v1.2.2
  Installed Blosc ────────────── v0.5.1
  Installed HDF5 ─────────────── v0.12.5
  Installed OrderedCollections ─ v1.1.0
  Installed URIParser ────────── v0.4.0
  Installed Arpack ───────────── v0.4.0
  Installed PDMats ───────────── v0.9.11
  Installed QuadGK ───────────── v2.3.1
  Installed LegacyStrings ────── v0.4.1
  Installed NearestNeighbors ─── v0.4.4
  Installed Parameters ───────── v0.12.0
  Installed DataStructures ───── v0.17.9
  Installed DataAPI ──────────── v1.1.0
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed BinaryProvider ───── v0.5.8
  Installed StatsFuns ────────── v0.9.3
  Installed CMake ────────────── v1.1.2
  Installed Clustering ───────── v0.13.3
#=#=#                                                                         #                                                                          2.1%####                                                                       6.4%########                                                                  12.0%##############                                                            19.5%###################                                                       27.8%############################                                              39.2%#######################################                                   54.4%####################################################                      72.7%#####################################################################     95.9%######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                         #############################################################             85.0%######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.2
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_9ZgXoX/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.2
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -1.2810652153237357e6, [99858.3339561352, 141.666043864797], [132.07710172020631 188.41199310199727 933.0587889267659; -37.70968345424221 193.17442382880185 -364.00930764299426], [[100078.02737079932 -62.109085298315904 -327.59584171810843; -62.10908529831587 99520.4601601613 545.4496670101042; -327.59584171810843 545.4496670101042 99325.32315187147], [99.05400125608477 -34.18518591858791 144.17783196612916; -34.18518591858791 439.76276688693144 -350.0368672503399; 144.1778319661292 -350.0368672503399 1092.2380232332232]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.326146e+03
      1       1.182669e+03      -1.434774e+02 |        4
      2       1.173041e+03      -9.627553e+00 |        2
      3       1.161418e+03      -1.162369e+01 |        0
      4       1.161418e+03       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 1161.4175839928357)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.060302
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.754491
[ Info: iteration 2, lowerbound -3.672187
[ Info: iteration 3, lowerbound -3.575800
[ Info: iteration 4, lowerbound -3.443804
[ Info: iteration 5, lowerbound -3.283020
[ Info: iteration 6, lowerbound -3.113638
[ Info: dropping number of Gaussions to 6
[ Info: iteration 7, lowerbound -2.945401
[ Info: iteration 8, lowerbound -2.793225
[ Info: iteration 9, lowerbound -2.680377
[ Info: iteration 10, lowerbound -2.596558
[ Info: dropping number of Gaussions to 5
[ Info: iteration 11, lowerbound -2.521847
[ Info: iteration 12, lowerbound -2.466295
[ Info: dropping number of Gaussions to 3
[ Info: iteration 13, lowerbound -2.412662
[ Info: iteration 14, lowerbound -2.364627
[ Info: iteration 15, lowerbound -2.332897
[ Info: iteration 16, lowerbound -2.312903
[ Info: iteration 17, lowerbound -2.307641
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.302924
[ Info: iteration 19, lowerbound -2.299261
[ Info: iteration 20, lowerbound -2.299257
[ Info: iteration 21, lowerbound -2.299255
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: 46 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Wed Feb 12 03:37:01 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Wed Feb 12 03:37:08 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Wed Feb 12 03:37:11 2020: EM with 272 data points 0 iterations avll -2.060302
5.8 data points per parameter
, Wed Feb 12 03:37:13 2020: GMM converted to Variational GMM
, Wed Feb 12 03:37:22 2020: iteration 1, lowerbound -3.754491
, Wed Feb 12 03:37:22 2020: iteration 2, lowerbound -3.672187
, Wed Feb 12 03:37:22 2020: iteration 3, lowerbound -3.575800
, Wed Feb 12 03:37:22 2020: iteration 4, lowerbound -3.443804
, Wed Feb 12 03:37:22 2020: iteration 5, lowerbound -3.283020
, Wed Feb 12 03:37:22 2020: iteration 6, lowerbound -3.113638
, Wed Feb 12 03:37:23 2020: dropping number of Gaussions to 6
, Wed Feb 12 03:37:23 2020: iteration 7, lowerbound -2.945401
, Wed Feb 12 03:37:23 2020: iteration 8, lowerbound -2.793225
, Wed Feb 12 03:37:23 2020: iteration 9, lowerbound -2.680377
, Wed Feb 12 03:37:23 2020: iteration 10, lowerbound -2.596558
, Wed Feb 12 03:37:23 2020: dropping number of Gaussions to 5
, Wed Feb 12 03:37:23 2020: iteration 11, lowerbound -2.521847
, Wed Feb 12 03:37:23 2020: iteration 12, lowerbound -2.466295
, Wed Feb 12 03:37:23 2020: dropping number of Gaussions to 3
, Wed Feb 12 03:37:23 2020: iteration 13, lowerbound -2.412662
, Wed Feb 12 03:37:23 2020: iteration 14, lowerbound -2.364627
, Wed Feb 12 03:37:23 2020: iteration 15, lowerbound -2.332897
, Wed Feb 12 03:37:23 2020: iteration 16, lowerbound -2.312903
, Wed Feb 12 03:37:23 2020: iteration 17, lowerbound -2.307641
, Wed Feb 12 03:37:23 2020: dropping number of Gaussions to 2
, Wed Feb 12 03:37:23 2020: iteration 18, lowerbound -2.302924
, Wed Feb 12 03:37:23 2020: iteration 19, lowerbound -2.299261
, Wed Feb 12 03:37:23 2020: iteration 20, lowerbound -2.299257
, Wed Feb 12 03:37:23 2020: iteration 21, lowerbound -2.299255
, Wed Feb 12 03:37:23 2020: iteration 22, lowerbound -2.299254
, Wed Feb 12 03:37:23 2020: iteration 23, lowerbound -2.299253
, Wed Feb 12 03:37:23 2020: iteration 24, lowerbound -2.299253
, Wed Feb 12 03:37:23 2020: iteration 25, lowerbound -2.299253
, Wed Feb 12 03:37:23 2020: iteration 26, lowerbound -2.299253
, Wed Feb 12 03:37:23 2020: iteration 27, lowerbound -2.299253
, Wed Feb 12 03:37:23 2020: iteration 28, lowerbound -2.299253
, Wed Feb 12 03:37:23 2020: iteration 29, lowerbound -2.299253
, Wed Feb 12 03:37:23 2020: iteration 30, lowerbound -2.299253
, Wed Feb 12 03:37:23 2020: iteration 31, lowerbound -2.299253
, Wed Feb 12 03:37:23 2020: iteration 32, lowerbound -2.299253
, Wed Feb 12 03:37:23 2020: iteration 33, lowerbound -2.299253
, Wed Feb 12 03:37:23 2020: iteration 34, lowerbound -2.299253
, Wed Feb 12 03:37:23 2020: iteration 35, lowerbound -2.299253
, Wed Feb 12 03:37:23 2020: iteration 36, lowerbound -2.299253
, Wed Feb 12 03:37:23 2020: iteration 37, lowerbound -2.299253
, Wed Feb 12 03:37:23 2020: iteration 38, lowerbound -2.299253
, Wed Feb 12 03:37:23 2020: iteration 39, lowerbound -2.299253
, Wed Feb 12 03:37:23 2020: iteration 40, lowerbound -2.299253
, Wed Feb 12 03:37:23 2020: iteration 41, lowerbound -2.299253
, Wed Feb 12 03:37:23 2020: iteration 42, lowerbound -2.299253
, Wed Feb 12 03:37:23 2020: iteration 43, lowerbound -2.299253
, Wed Feb 12 03:37:23 2020: iteration 44, lowerbound -2.299253
, Wed Feb 12 03:37:23 2020: iteration 45, lowerbound -2.299253
, Wed Feb 12 03:37:23 2020: 46 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.9549077739831, 178.04509222601686]
β = [95.9549077739831, 178.04509222601686]
m = [2.0002292577753455 53.85198717246117; 4.250300733269886 79.2868669443615]
ν = [97.9549077739831, 180.04509222601686]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.375876361194883 -0.00895312382734658; 0.0 0.012748664777409636], [0.18404155547484327 -0.007644049042327649; 0.0 0.008581705166333132]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999997
avll from stats: -0.9608032610874175
avll from llpg:  -0.9608032610874166
avll direct:     -0.9608032610874166
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -1.0003042984446948
avll from llpg:  -1.0003042984446948
avll direct:     -1.0003042984446948
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
 -0.0394262   -0.085503    -0.0263041   -0.0382147    0.134898     0.00301674  -0.169931     0.113283    -0.134199     0.0606675   -0.165907     0.11531     -0.209515    -0.0422253    0.0444402   0.108173    0.184718    -0.107395   -0.0961352    0.124487    -0.0945728   0.0649356    0.131623      0.190817    -0.123694     0.0859456
 -0.0986274   -0.153055     0.0302349   -0.0910442    0.0495295   -0.128915    -0.0618544    0.0265862    0.0729044   -0.143312     0.0823043   -0.0312339    0.111284    -0.00557844   0.0524353   0.0785401   0.171626     0.194023    0.0673652   -0.0510582    0.062183   -0.0549401    0.0700666     0.0950368   -0.0455338   -0.0694146
 -0.162253    -0.134869     0.209959     0.0165714    0.0358516   -0.120941    -0.140811    -0.0921486    0.0615239   -0.0544967    0.105694    -0.0390612    0.0955828   -0.120541    -0.0141737  -0.0571988  -0.0877024   -0.033909   -0.0319153    0.169301    -0.0932499   0.0173791    0.0480594     0.123013     0.0250999    0.00292659
 -0.0484823   -0.147926     0.0766853    0.00221263  -0.0764744    0.0671409    0.163737     0.0488871    0.00602042   0.177306     0.105466     0.0825414    0.122442     0.0630175   -0.0465873  -0.156015   -0.296287    -0.0602468   0.180266    -0.0211799   -0.0215728   0.0159829    0.0365899    -0.106317    -0.028188     0.0368174
  0.0881699    0.050475     0.0384826    0.00708232   0.0238331   -0.0855108    0.00520598  -0.134665     0.109908    -0.0946009   -0.0312203    0.0038448   -0.0198356    0.177897     0.0947314   0.0773016  -0.0535241    0.079904    0.152883     0.0562268   -0.0164057   0.0824692   -0.0312903    -0.194382     0.0903527    0.0133291
 -0.0669214    0.0344554    0.0397988   -0.243868    -0.175388    -0.066974    -0.154216    -0.0716005    0.0787495   -0.0118852   -0.0552789   -0.0263175   -0.0846132    0.0516222   -0.0133265   0.0722659  -0.0719009   -0.100612   -0.0923632   -0.0930132   -0.0312169   0.0278455    0.0444827     0.0688011    0.0233809    0.119686
 -0.0919123    0.237203     0.108589    -0.0520759    0.0137223   -0.190352     0.103029    -0.0206402   -0.0606072    0.0231628   -0.148336    -0.308975     0.121138     0.102714     0.180512    0.0293967   0.121944     0.12058     0.194422    -0.0762622   -0.048735   -0.153543    -0.0588815     0.144404     0.0111385    0.0809445
  0.0793686   -0.241937    -0.0303221    0.0863508    0.146187     0.103989     0.100834    -0.00729735  -0.0960415   -0.120165     0.0391276   -0.167942    -0.130099    -0.0904054   -0.155006    0.10127     0.106028    -0.0791329   0.0228819   -0.0411352   -0.0772862  -0.0927557   -0.0261033    -0.100607    -0.0674003   -0.0741155
 -0.136573     0.100761     0.0338527    0.0337612    0.0269568   -0.220091    -0.0238094    0.104013    -0.0612121    0.0744423    0.159756     0.06761     -0.0139927    0.0555408    0.1436      0.144062    0.139847    -0.14004    -0.028988     0.112607    -0.0220414  -0.024301     0.000561874   0.130363     0.00661492  -0.0274492
  0.184825    -0.102968     0.0953455   -0.014438     0.0580738   -0.00438669  -0.217775    -0.0420529   -0.21108      0.162672    -0.130777    -0.120436     0.152005    -0.0916602   -0.0938075   0.260361    0.00852214   0.216371    0.0748093   -0.0373326   -0.133107   -0.00335943  -0.0237684     0.00315277   0.154545    -0.0282309
  0.00538321  -0.0775054    0.0921689    0.0258396   -0.0454191    0.0103264   -0.012599    -0.0943486    0.0839178   -0.0093555    0.0771792   -0.13942     -0.102117     0.0179462    0.129255   -0.0338354  -0.0551643    0.0486316  -0.0418885   -0.158823     0.036948   -0.168576     0.00343017   -0.220631     0.103902     0.217815
  0.0277323   -0.00488207  -0.144042     0.191456     0.0750575   -0.0169483    0.0341912    0.0066531    0.108837    -0.0229243    0.00704503   0.0116483    0.141385     0.0234985   -0.0290338  -0.0068631  -0.0675938    0.0387166  -0.0710434   -0.10276     -0.0564001  -0.0419669   -0.0195907    -0.0167658   -0.151567     0.0945439
 -0.107214    -0.243725     0.0415752   -0.121291     0.0424917   -0.00388112   0.0215829    0.0331072   -0.167789     0.112792     0.241176    -0.20552      0.154831    -0.00942225  -0.129216    0.120222    0.110563     0.119679    0.0547347    0.0520465   -0.0529766  -0.0802342   -0.00822605    0.125145    -0.0473753   -0.138246
 -0.0582281    0.0142062    0.0889441    0.130495     0.0981334   -0.320902     0.0592943    0.0852014    0.168266    -0.0355819    0.194386     0.117058    -0.0313109    0.199857    -0.124694   -0.0493766   0.250725     0.110643   -0.0248516   -0.0641825    0.0429435   0.0229296    0.0362964     0.0666815    0.200267     0.0322547
 -0.247274    -0.12037     -0.0323141   -0.194547    -0.00810354  -0.0560205    0.0415251    0.0934412   -0.0311716    0.0628107    0.0434321    0.0753669   -0.0160408   -0.161646     0.13522     0.0128215  -0.105239     0.0731348   0.0213695   -0.0222055   -0.10225    -0.0724461   -0.207562     -0.0539797    0.0838145    0.263432
 -0.00179338  -0.0235631   -0.00228074  -0.168422     0.0852138    0.0277387   -0.0475518   -0.138924    -0.0570918   -0.023376     0.117416     0.0060319    0.0845265   -0.172861     0.0379088  -0.0179527  -0.0954204   -0.0809738  -0.0143492   -0.0772959    0.0227304   0.0397841   -0.109155     -0.141144    -0.0574265   -0.114876
 -0.0232442    0.0772218    0.133822     0.199816    -0.123749     0.0442012   -0.0850438   -0.117446    -0.0160787   -0.0430846   -0.197714    -0.0253637    0.0925981   -0.0802329   -0.0942036   0.208729   -0.126752    -0.0819797   0.0375533   -0.0115319    0.120644   -0.0744527    0.101704     -0.112413    -0.120996     0.0710811
  0.0458749   -0.101507     0.0806368   -0.0575224   -0.0889013   -0.0254913    0.117197    -0.0435908   -0.0215445   -0.0404943   -0.0265765    0.00101978  -0.0652129    0.051623    -0.0311271  -0.0378446   0.0680421   -0.072712    0.0193374   -0.140815     0.0858509   0.127985    -0.138756      0.00445768  -0.0300398   -0.160454
  0.0931394   -0.115583     0.0341382   -0.0682195   -0.0924658    0.0808573    0.0406179    0.0540434    0.0843638    0.260937    -0.0274595   -0.173117     0.128234     0.0164415   -0.0142807   0.0680922   0.119289    -0.0712157  -0.0183022   -0.123265     0.0956394   0.224055     0.0784491     0.161055     0.0166082    0.0324414
 -0.027602    -0.0391887   -0.0693004    0.0303197   -0.099455    -0.0846557    0.193431     0.0354932    0.0588643    0.0212957    0.21978     -0.102505    -0.0129059   -0.0409803   -0.140072   -0.0764325   0.138736     0.0555908   0.0849508   -0.00604911  -0.13083     0.191814     0.0793706     0.0291598   -0.0625264   -0.190212
  0.122813     0.0408905    0.0232253   -0.0781851    0.0505503   -0.101716    -0.21265     -0.011693     0.0647161    0.147675     0.121169    -0.09427     -0.232599    -0.06706      0.110074   -0.0410804   0.0024193    0.0211479   0.181226     0.106439     0.0484216  -0.0408752   -0.127175      0.30037     -0.195614    -0.0187233
  0.0864048   -0.101313     0.0943279    0.013649    -0.153569    -0.00669668  -0.0346113   -0.127628    -0.0922015    0.110936    -0.0658125   -0.00879256   0.0145975    0.00959691   0.02717    -0.0527207   0.0809428    0.0356024   0.00627024  -0.0837127   -0.186367   -0.00131291   0.109142     -0.0551901    0.139005    -0.0851556
  0.025655     0.137397     0.115325    -0.0129599   -0.00900458  -0.0564561   -0.0542361   -0.0603213    0.186851     0.0386439    0.0802181    0.0265259   -0.0593464    0.0387608    0.0637104   0.114771   -0.119322     0.0482893   0.0945576   -0.0151199    0.0799994  -0.202356     0.0888322     0.0100128    0.0188755    0.0834357
  0.0663169    0.14347      0.0305197   -0.222171    -0.0842867    0.123121    -0.0722448    0.056918     0.181312     0.0898873    0.10642      0.0980563    0.0952698    0.091259     0.0566932  -0.0481043  -0.0690133   -0.0545746   0.186125    -0.0087577    0.0141994  -0.00779613  -0.110691     -0.203749     0.110952    -0.00413601
  0.0137973   -0.0946683   -0.186041    -0.0396099   -0.213694     0.0427509   -0.0875997   -0.130108    -0.0138463    0.0870125   -0.0195364    0.0844426    0.0686265    0.0759603   -0.0141314  -0.0329594   0.00514649  -0.017582    0.0156169    0.154195     0.0557019  -0.159715     0.0398461    -0.161308     0.173347    -0.0716475
 -0.0545044   -0.0914464    0.14901     -0.160753     0.0214574    0.0288255   -0.137614     0.0322857    0.10293      0.154928     0.104106     0.0151403    0.0432475   -0.0385207    0.0357997   0.227943    0.0621917   -0.12899    -0.0468866   -0.0736699    0.150508   -0.114271    -0.0025011    -0.0445605   -0.0461532   -0.00383771
  0.11908     -0.00380652   0.0179676    0.0292405    0.0881975    0.0750031    0.108547    -0.149499    -0.0513738    0.00865493   0.0314024   -0.141849     0.0520225    0.0436857    0.0349023  -0.0496749  -0.0352307    0.315745    0.101965    -0.0459759   -0.0440223   0.122268     0.0434285    -0.0434349    0.00480555  -0.104918
  0.0697522   -0.0858984   -0.0317098   -0.0125395    0.00425163  -0.0373491    0.0408218   -0.0933853   -0.0147964   -0.17005      0.0347904   -0.0800401    0.0577639   -0.0536239   -0.15675    -0.0644559  -0.0533777   -0.0813166  -0.140667    -0.0365169   -0.125624   -0.157834    -0.0681083     0.0508841   -0.0332779   -0.0170149
 -0.122992     0.180819     0.090295     0.0646547   -0.0404806    0.0981831   -0.158601     0.138159     0.113188    -0.0848987    0.0240754    0.0479386   -0.00697055   0.10562     -0.0465704   0.176387   -0.0378049    0.0556593  -0.150123    -0.0160857   -0.118044   -0.192577     0.0196305    -0.187646     0.00692083  -0.0463762
 -0.00755685  -0.0717974    0.155532    -0.208474    -0.103348     0.0578709   -0.17763      0.0761568   -0.00286749  -0.0894417   -0.0375485   -0.0974649   -0.0735579   -0.0122787    0.0576357   0.0197433  -0.0859156   -0.0725375  -0.0799272   -0.0921383   -0.0108896   0.0483852    0.0462884     0.13897     -0.137042    -0.148391
  0.136655     0.00526724  -0.0123759    0.107974    -0.00237313   0.0533767    0.00219281  -0.178164     0.0887033    0.0162806   -0.0939663    0.0563618    0.0951989    0.00942965   0.0933828  -0.0939897   0.0236617    0.104631    0.135827    -0.233911     0.031464   -0.0483652   -0.109781     -0.0165044    0.0339095    0.108231
 -0.133755    -0.0772916   -0.00591102   0.0365561    0.0956496    0.0728024    0.15645      0.080363    -0.0651792   -0.0328986    0.0901998    0.100549    -0.0443241    0.0168969    0.0211517   0.0835802  -0.035395     0.205745   -0.0550533   -0.053769    -0.0913534   0.0490044    0.0577088     0.0973722   -0.0155373   -0.0427625kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4076482492173372
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407718
[ Info: iteration 2, average log likelihood -1.407651
[ Info: iteration 3, average log likelihood -1.407080
[ Info: iteration 4, average log likelihood -1.399928
[ Info: iteration 5, average log likelihood -1.380394
[ Info: iteration 6, average log likelihood -1.374044
[ Info: iteration 7, average log likelihood -1.373468
[ Info: iteration 8, average log likelihood -1.373291
[ Info: iteration 9, average log likelihood -1.373200
[ Info: iteration 10, average log likelihood -1.373149
[ Info: iteration 11, average log likelihood -1.373119
[ Info: iteration 12, average log likelihood -1.373099
[ Info: iteration 13, average log likelihood -1.373085
[ Info: iteration 14, average log likelihood -1.373074
[ Info: iteration 15, average log likelihood -1.373064
[ Info: iteration 16, average log likelihood -1.373055
[ Info: iteration 17, average log likelihood -1.373046
[ Info: iteration 18, average log likelihood -1.373038
[ Info: iteration 19, average log likelihood -1.373030
[ Info: iteration 20, average log likelihood -1.373023
[ Info: iteration 21, average log likelihood -1.373016
[ Info: iteration 22, average log likelihood -1.373009
[ Info: iteration 23, average log likelihood -1.373002
[ Info: iteration 24, average log likelihood -1.372995
[ Info: iteration 25, average log likelihood -1.372986
[ Info: iteration 26, average log likelihood -1.372977
[ Info: iteration 27, average log likelihood -1.372967
[ Info: iteration 28, average log likelihood -1.372957
[ Info: iteration 29, average log likelihood -1.372945
[ Info: iteration 30, average log likelihood -1.372932
[ Info: iteration 31, average log likelihood -1.372919
[ Info: iteration 32, average log likelihood -1.372905
[ Info: iteration 33, average log likelihood -1.372890
[ Info: iteration 34, average log likelihood -1.372874
[ Info: iteration 35, average log likelihood -1.372858
[ Info: iteration 36, average log likelihood -1.372841
[ Info: iteration 37, average log likelihood -1.372824
[ Info: iteration 38, average log likelihood -1.372805
[ Info: iteration 39, average log likelihood -1.372785
[ Info: iteration 40, average log likelihood -1.372760
[ Info: iteration 41, average log likelihood -1.372729
[ Info: iteration 42, average log likelihood -1.372686
[ Info: iteration 43, average log likelihood -1.372621
[ Info: iteration 44, average log likelihood -1.372515
[ Info: iteration 45, average log likelihood -1.372358
[ Info: iteration 46, average log likelihood -1.372198
[ Info: iteration 47, average log likelihood -1.372060
[ Info: iteration 48, average log likelihood -1.371922
[ Info: iteration 49, average log likelihood -1.371767
[ Info: iteration 50, average log likelihood -1.371594
┌ Info: EM with 100000 data points 50 iterations avll -1.371594
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4077177098990594
│     -1.4076514994951201
│      ⋮
└     -1.3715938101932703
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.371513
[ Info: iteration 2, average log likelihood -1.371217
[ Info: iteration 3, average log likelihood -1.370639
[ Info: iteration 4, average log likelihood -1.367401
[ Info: iteration 5, average log likelihood -1.355606
[ Info: iteration 6, average log likelihood -1.344255
[ Info: iteration 7, average log likelihood -1.340304
[ Info: iteration 8, average log likelihood -1.337680
[ Info: iteration 9, average log likelihood -1.335328
[ Info: iteration 10, average log likelihood -1.333530
[ Info: iteration 11, average log likelihood -1.332275
[ Info: iteration 12, average log likelihood -1.331360
[ Info: iteration 13, average log likelihood -1.330624
[ Info: iteration 14, average log likelihood -1.329973
[ Info: iteration 15, average log likelihood -1.329358
[ Info: iteration 16, average log likelihood -1.328743
[ Info: iteration 17, average log likelihood -1.328138
[ Info: iteration 18, average log likelihood -1.327592
[ Info: iteration 19, average log likelihood -1.327144
[ Info: iteration 20, average log likelihood -1.326847
[ Info: iteration 21, average log likelihood -1.326694
[ Info: iteration 22, average log likelihood -1.326608
[ Info: iteration 23, average log likelihood -1.326552
[ Info: iteration 24, average log likelihood -1.326513
[ Info: iteration 25, average log likelihood -1.326484
[ Info: iteration 26, average log likelihood -1.326461
[ Info: iteration 27, average log likelihood -1.326443
[ Info: iteration 28, average log likelihood -1.326428
[ Info: iteration 29, average log likelihood -1.326415
[ Info: iteration 30, average log likelihood -1.326404
[ Info: iteration 31, average log likelihood -1.326394
[ Info: iteration 32, average log likelihood -1.326385
[ Info: iteration 33, average log likelihood -1.326375
[ Info: iteration 34, average log likelihood -1.326366
[ Info: iteration 35, average log likelihood -1.326357
[ Info: iteration 36, average log likelihood -1.326347
[ Info: iteration 37, average log likelihood -1.326338
[ Info: iteration 38, average log likelihood -1.326328
[ Info: iteration 39, average log likelihood -1.326318
[ Info: iteration 40, average log likelihood -1.326308
[ Info: iteration 41, average log likelihood -1.326297
[ Info: iteration 42, average log likelihood -1.326285
[ Info: iteration 43, average log likelihood -1.326273
[ Info: iteration 44, average log likelihood -1.326259
[ Info: iteration 45, average log likelihood -1.326244
[ Info: iteration 46, average log likelihood -1.326229
[ Info: iteration 47, average log likelihood -1.326213
[ Info: iteration 48, average log likelihood -1.326197
[ Info: iteration 49, average log likelihood -1.326180
[ Info: iteration 50, average log likelihood -1.326161
┌ Info: EM with 100000 data points 50 iterations avll -1.326161
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3715130804979365
│     -1.371216638785984
│      ⋮
└     -1.3261610479448336
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.326256
[ Info: iteration 2, average log likelihood -1.326083
[ Info: iteration 3, average log likelihood -1.325216
[ Info: iteration 4, average log likelihood -1.318545
[ Info: iteration 5, average log likelihood -1.300751
[ Info: iteration 6, average log likelihood -1.285318
[ Info: iteration 7, average log likelihood -1.278624
[ Info: iteration 8, average log likelihood -1.276073
[ Info: iteration 9, average log likelihood -1.274863
[ Info: iteration 10, average log likelihood -1.274075
[ Info: iteration 11, average log likelihood -1.273390
[ Info: iteration 12, average log likelihood -1.272633
[ Info: iteration 13, average log likelihood -1.271640
[ Info: iteration 14, average log likelihood -1.270554
[ Info: iteration 15, average log likelihood -1.269615
[ Info: iteration 16, average log likelihood -1.268821
[ Info: iteration 17, average log likelihood -1.268134
[ Info: iteration 18, average log likelihood -1.267571
[ Info: iteration 19, average log likelihood -1.267171
[ Info: iteration 20, average log likelihood -1.266895
[ Info: iteration 21, average log likelihood -1.266689
[ Info: iteration 22, average log likelihood -1.266522
[ Info: iteration 23, average log likelihood -1.266378
[ Info: iteration 24, average log likelihood -1.266243
[ Info: iteration 25, average log likelihood -1.266109
[ Info: iteration 26, average log likelihood -1.265983
[ Info: iteration 27, average log likelihood -1.265873
[ Info: iteration 28, average log likelihood -1.265780
[ Info: iteration 29, average log likelihood -1.265703
[ Info: iteration 30, average log likelihood -1.265637
[ Info: iteration 31, average log likelihood -1.265580
[ Info: iteration 32, average log likelihood -1.265527
[ Info: iteration 33, average log likelihood -1.265478
[ Info: iteration 34, average log likelihood -1.265432
[ Info: iteration 35, average log likelihood -1.265388
[ Info: iteration 36, average log likelihood -1.265339
[ Info: iteration 37, average log likelihood -1.265275
[ Info: iteration 38, average log likelihood -1.265177
[ Info: iteration 39, average log likelihood -1.265023
[ Info: iteration 40, average log likelihood -1.264832
[ Info: iteration 41, average log likelihood -1.264647
[ Info: iteration 42, average log likelihood -1.264485
[ Info: iteration 43, average log likelihood -1.264363
[ Info: iteration 44, average log likelihood -1.264275
[ Info: iteration 45, average log likelihood -1.264199
[ Info: iteration 46, average log likelihood -1.264114
[ Info: iteration 47, average log likelihood -1.263991
[ Info: iteration 48, average log likelihood -1.263764
[ Info: iteration 49, average log likelihood -1.263194
[ Info: iteration 50, average log likelihood -1.261599
┌ Info: EM with 100000 data points 50 iterations avll -1.261599
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3262561560121777
│     -1.3260833261871516
│      ⋮
└     -1.2615990009085418
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.258583
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.258317
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.257756
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.251709
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.229847
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.206221
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      6
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.194322
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.196203
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.184339
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.202077
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      6
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.186174
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.187240
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.191130
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      6
│     11
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.173354
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      6
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.197962
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.185608
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│      8
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.172316
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      6
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.183530
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      6
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.177102
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      6
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.183923
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      6
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.180634
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     6
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.177429
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      6
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.175932
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.174759
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.190334
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      6
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.173808
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.175327
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      6
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.181776
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.183906
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.172136
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.183361
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     6
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.173257
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.171182
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      6
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.187942
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.182808
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      6
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.170471
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│      8
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.171207
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      6
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.178584
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      6
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.183839
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.180005
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      6
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.169004
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      6
│      8
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.171889
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.194098
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      6
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.176331
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      6
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.178201
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.174995
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.162522
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.184307
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.188813
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.178240
┌ Info: EM with 100000 data points 50 iterations avll -1.178240
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.258583106514555
│     -1.2583174775858474
│      ⋮
└     -1.1782396692740968
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.167449
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.160172
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     21
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.165878
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.146398
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.094393
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      2
│      6
│      9
│     10
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.085888
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.097538
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      9
│     10
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.090701
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      2
│      5
│      6
│      9
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.066458
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      9
│     10
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.107065
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.084259
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      6
│      9
│     10
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.081575
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.090971
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      7
│      9
│     10
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.085926
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      2
│      5
│      6
│      9
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.067487
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      9
│     10
│     11
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.109088
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      2
│      5
│      7
│      9
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.079111
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      2
│      6
│      9
│     10
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.089416
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.091821
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      7
│      9
│     10
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.084424
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      2
│      5
│      6
│      9
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.069492
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      9
│     10
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.104962
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.085638
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      6
│      7
│      9
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.078633
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.093592
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      9
│     10
│     11
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.088009
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.063514
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      9
│     10
│     11
│      ⋮
│     24
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.108859
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.086189
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      2
│      6
│      7
│      9
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.080747
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.093986
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      9
│     10
│     11
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.090694
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.061846
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      9
│     10
│     11
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.113525
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.084037
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      2
│      6
│      9
│     10
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.077901
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      5
│      7
│      9
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.088797
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      9
│     10
│     11
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.091964
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      2
│      5
│      6
│      9
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.066100
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      7
│      9
│     10
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.096451
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.081243
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      2
│      6
│      9
│     10
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.077041
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      5
│      7
│      9
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.083225
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      9
│     10
│     11
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.083584
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      2
│      5
│      6
│      9
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.057826
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      7
│      9
│     10
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.089594
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.074516
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      6
│      9
│     10
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.081710
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      2
│      5
│      7
│      9
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.086988
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      9
│     10
│     11
│      ⋮
│     22
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.095389
┌ Info: EM with 100000 data points 50 iterations avll -1.095389
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1674486513406672
│     -1.1601716624588247
│      ⋮
└     -1.0953886093464293
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4076482492173372
│     -1.4077177098990594
│     -1.4076514994951201
│     -1.4070800477576357
│      ⋮
│     -1.0817102370902958
│     -1.086988366611817
└     -1.0953886093464293
32×26 Array{Float64,2}:
  0.086795     -0.240333     -0.0292644    0.135194     0.137528      0.105307     0.139341    -0.00511107  -0.11514     -0.112292      0.0361685  -0.199025    -0.117041    -0.058314    -0.154527     0.107239      0.0995123   -0.0792289    0.0185249   -0.0434314   -0.0700487   -0.0901032   -0.0569044    -0.100047    0.00416197  -0.0699165
 -0.10116       0.167751      0.0931201    0.0520419   -0.0486133     0.0928889   -0.158467     0.132848     0.112122    -0.0726236     0.045765    0.0472993   -0.0268134    0.143987    -0.0467052    0.181422     -0.0182742    0.029467    -0.156381    -0.00110234  -0.10153     -0.197385     0.000649491  -0.187142    0.0181601   -0.0341983
  0.0932813    -0.0336148     0.0904372   -0.0150685    0.0594682     0.00686392  -0.286747    -0.0160105   -0.216229     0.152215     -0.229339   -0.0685889    0.099993    -0.0848277   -0.0749482    0.272192      0.0223281    0.232214     0.100185     0.0214052   -0.384469     0.00717329  -0.204013      0.0342945   0.172138    -0.0919022
  0.25573      -0.180204      0.0988885   -0.022274    -0.0153302    -0.0343273   -0.138163    -0.0780775   -0.192193     0.152821     -0.0770289  -0.159275     0.156292    -0.135834    -0.103916     0.246378      0.00205715   0.195789     0.0265815   -0.0853423    0.109878    -0.0459369    0.13419       0.0104513   0.118878     0.0414567
 -0.0766507    -0.0814626    -0.031453    -0.032745     0.136677     -0.00326954  -0.153632     0.126086    -0.116799     0.0606955    -0.141179    0.129593    -0.234309    -0.0429139    0.044081     0.106937      0.175313    -0.0991972   -0.0804499    0.115148    -0.0904177    0.0257665    0.122701      0.192621   -0.125615     0.0897453
  0.000638345  -0.0940176    -0.18114     -0.025005    -0.184935      0.0398657   -0.0965331   -0.125505     0.00267545   0.0877251    -0.105244    0.0731851    0.10075      0.0770875   -0.0187027   -0.0313429    -0.0341554   -0.0419127    0.03674      0.131894     0.0417789   -0.161109     0.0155972    -0.157748    0.173819    -0.0819855
 -0.142992     -0.102567      0.250999     0.0122926    0.0440699    -0.111496    -0.117093    -0.0849649    0.0423771   -0.0515883     0.119273   -0.0423961    0.0774204   -0.131141    -0.0136636   -0.0583629    -0.105285    -0.0153236   -0.019388     0.130967    -0.0759283    0.033021     0.0479041     0.106952    0.00159039   0.00475662
  0.048435      0.0775236    -0.0458001   -0.0194125   -0.0153632     0.0617429   -0.018633     0.0254277    0.132046     0.0412867     0.0460162   0.0552033    0.111508     0.052276     0.0178782   -0.0239933    -0.072808    -0.00684351   0.0654314   -0.0678019   -0.00343533  -0.0430154   -0.0688138    -0.116018   -0.00776704   0.0145498
 -0.252115     -0.166561     -0.00101812  -0.365268     0.131631     -1.65132      0.010897     0.0111383    0.0352614    0.00314279    0.0433017   0.063854     0.0125114    0.0562499    0.148087     0.411068     -0.103781     0.0744562    0.0221395   -0.207463    -0.102265    -0.0439972   -0.212564     -0.0543953   0.0874129    0.229336
 -0.249729     -0.120281     -0.0135329   -0.201893    -0.168419      0.214632     0.00624687   0.064059     0.00683292   0.159488      0.0425601   0.121553    -0.0232535    0.747199     0.132989    -0.408584     -0.105986     0.073946     0.0160862    0.259251    -0.102084     0.0553932   -0.206353     -0.0555219   0.0725779    0.0712019
 -0.259121     -0.109039     -0.0252688   -0.0289992   -0.0972546     0.0227717    0.0726479    0.107873    -0.0656116   -0.0693929     0.0437686   0.0299328   -0.0187286   -1.04151      0.170205    -0.794108     -0.0957744    0.0735423    0.0445227    0.276658    -0.102655    -0.341569    -0.211615     -0.0556877   0.083537    -0.040815
 -0.251377     -0.0717776    -0.028115    -0.178042     0.0363292     0.83941      0.00706454   0.168368    -0.0315526    0.108919      0.0445298   0.127365    -0.0505709   -0.424525     0.0812921    0.988738     -0.105896     0.0745717   -0.00852187  -0.398402    -0.102724     0.0256381   -0.209388     -0.0543042   0.0798328    0.839355
  0.0415924    -0.0820587    -0.0165036   -0.00894877   0.0329799    -0.0376486    0.049443    -0.0951826   -0.0185341   -0.177355      0.0222961  -0.0768884    0.05489     -0.0479934   -0.136203    -0.0778585    -0.0444782   -0.0786128   -0.13379     -0.0255994   -0.129283    -0.148694    -0.0694808     0.0630346  -0.0410861   -0.0125958
  0.159788      0.0400446     0.0374281   -0.0766665    0.0616977    -0.0809352   -0.210791    -0.0209369    0.0683279    0.146912      0.120778   -0.0695565   -0.23282     -0.0517671    0.104518    -0.0418331     0.00570501   0.0149654    0.173755     0.104802     0.047092    -0.0462194   -0.134492      0.300011   -0.197499    -0.021782
 -0.0405678    -0.147468     -0.0230443   -0.11259      0.0450353    -0.119995    -0.0584209   -0.0254251    0.0212364   -0.153008      0.0239956  -0.0430993    0.144039    -0.0635245   -0.0374258    0.22992       0.137575     0.167126     0.0630364   -0.0434598    0.0420069   -0.807967     0.0716809     0.104945   -0.0611856   -0.0701208
 -0.14106      -0.146362      0.0579542   -0.0696566    0.0373391    -0.0470021   -0.0298468    0.0435797    0.152801    -0.128441      0.0870102  -0.021921     0.0587495    0.0826301    0.090122    -0.0994842     0.168442     0.241883     0.0621771   -0.062902     0.0860172    0.769153     0.0357944     0.0660532  -0.0391906   -0.0728971
 -0.00792773   -0.0639226     0.1529      -0.232162    -0.0980342     0.0750418   -0.181365     0.0489587   -0.0140321   -0.106601     -0.0271542  -0.0933254   -0.0582089   -0.0116925    0.0567472    0.000711451  -0.0713947   -0.0897034   -0.0768593   -0.122151    -0.0325027    0.0322447    0.0418357     0.134613   -0.131774    -0.157065
 -0.0245956     0.0825935     0.134843     0.220729    -0.123229      0.0455567   -0.0920578   -0.112391    -0.0153228   -0.0395001    -0.200328   -0.0142768    0.0946572   -0.0785977   -0.0926477    0.189899     -0.224132    -0.0834716   -0.00587718  -0.0766557    0.1258      -0.0613956    0.135441     -0.114006   -0.119035     0.109477
 -0.0328057     0.0109561     0.0828272    0.120076     0.0816774    -0.291584     0.0662628    0.071372     0.14348     -0.0453716     0.185653    0.111765    -0.0525022    0.169747    -0.121908    -0.00621876    0.234288     0.111245    -0.065478    -0.0608357    0.0504072    0.0265619    0.00182096    0.0587258   0.186873     0.0362752
 -0.0829414    -0.235356      0.0140262   -0.116412     0.0161788    -0.00439018   0.0223848    0.0117871   -0.165469     0.111106      0.24127    -0.209645     0.134633    -0.0141538   -0.120243     0.110648      0.104672     0.118478     0.0611622    0.0346062   -0.0537474   -0.0823319   -0.0506236     0.125693   -0.0567047   -0.14593
 -0.0871042     0.245936      0.136394    -0.297818     0.0126446    -0.220024     0.104664    -0.0213522   -0.0562546   -0.241631     -0.475434   -0.308527     0.108011     0.102061     0.220425    -0.394328      0.150452     0.131696     0.190577    -0.224754    -0.0443162   -0.157234    -0.0578354     0.127603    0.0635538    0.0798668
 -0.0906048     0.219382      0.101548     0.15728      0.0128562    -0.124595     0.102565    -0.021436    -0.0554323    0.334727      0.131284   -0.309422     0.114298     0.101949     0.174203     0.349697      0.1111       0.121589     0.190548     0.0107742   -0.0483275   -0.153384    -0.057699      0.15483    -0.0184956    0.0831215
 -0.0268422    -0.000510248  -0.0336788    0.0266606   -0.0858889    -0.0861324    0.141658     0.0137471    0.0517453    0.017928      0.185885   -0.080759    -0.0247877   -0.0289996   -0.0882381   -0.0156796     0.0789562    0.0433488    0.0825164   -0.0123785   -0.0886736    0.131262     0.0977008     0.0268098  -0.0221449   -0.10986
  0.0969814     0.0348232     0.0182051    0.0465792    0.000986586   0.040907    -0.00981602  -0.163232     0.121335     0.0340803    -0.0645769   0.046255     0.0527602    0.011387     0.10262     -0.0323206    -0.019927     0.0931851    0.133864    -0.178408     0.0453105   -0.120114    -0.0792125    -0.0137224   0.0381585    0.107162
  0.0915688    -0.108298      0.0505322   -0.0495856   -0.0921227     0.104496     0.0264811    0.0801371    0.0936721    0.382051     -0.0271468  -0.208327     0.151563    -0.00179328  -0.0108146    0.0620215     0.124534    -0.0756818   -0.0150187   -0.11792      0.0923123    0.207157     0.114356      0.211202    0.0435214    0.114247
  0.097857     -0.0640695     0.0907694   -0.0481522   -0.0725545     0.0129174    0.0219111   -0.0018996    0.0359311    0.0804755    -0.0253067  -0.0727915    0.0101549    0.0184912   -0.0282382    0.0247702     0.019259    -0.0775103   -0.00660394  -0.121362     0.0918883    0.151868    -0.0275093     0.0841008   0.0305509   -0.079425
 -0.0343279    -0.14696      -0.0173799    0.130124    -0.0755433     0.0983643   -0.832296     0.206112     0.00675874  -0.0077409     0.105648    0.0823227    0.173208     0.053468    -0.00959355  -0.132254     -0.310653    -0.173905     0.161316    -0.017543     0.117173    -0.22574     -0.073189     -0.109795   -0.158377     0.0200603
 -0.0922403    -0.149675      0.249808    -0.104393    -0.0755485     0.0197311    0.807282    -0.0687718    0.0278679    0.306956      0.106042    0.081976     0.0939164    0.0531553   -0.0807024   -0.154228     -0.338243    -0.0206322    0.15777     -0.0246966   -0.137489     0.287196     0.1081       -0.0954274   0.0955817    0.0290882
 -0.0304199    -0.0282899     0.0763459   -0.10881     -0.0385895    -0.0104531   -0.0748021   -0.0617385    0.0533791    0.00813875    0.0262761  -0.0305954   -0.048154    -0.0268489    0.0393628    0.0662695    -0.0336918   -0.0764781   -0.0446007   -0.10264      0.0522449   -0.0409293   -0.0346634    -0.0701631   0.00363159   0.0469813
  0.049738     -0.00402817    0.0339193    0.0283928   -0.00475911   -0.036781     0.019728    -0.0568351   -0.0572469    0.0617942     0.0507854  -0.0340311    0.00696969   0.0297316    0.0625007    0.00286959    0.0434921    0.0777958    0.0144113   -0.0321812   -0.0606944    0.0288522    0.0325773    -0.0153836   0.0528678   -0.0699293
  0.086173      0.0410833     0.0409559    0.0160016    0.00236819   -0.0616855    0.0070105   -0.128582     0.106473    -0.0913122    -0.0386484   0.00699818  -0.0260107    0.177801     0.0694013    0.0780505    -0.010859     0.0869277    0.148575     0.0868894   -0.0168498    0.0580159   -0.0384593    -0.183902    0.0852414    0.0139272
 -0.13905      -0.0728473     0.0016818    0.0192721    0.087761      0.0415381    0.13466      0.0821217   -0.0552803    0.000731846   0.0906079   0.106765    -0.0418109    0.0234847    0.0310635    0.103434      0.0496627    0.196217    -0.0666028   -0.046597    -0.124201     0.0708138    0.0512251     0.0856357  -0.0302283   -0.0461195[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      2
│      5
│      6
│      9
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.063421
┌ Warning: Variances had to be floored 
│   ind =
│    20-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.061371
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      2
│      5
│      6
│      9
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.063174
┌ Warning: Variances had to be floored 
│   ind =
│    20-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.060785
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      2
│      5
│      6
│      9
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.063123
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.060665
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      2
│      5
│      6
│      9
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.062170
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.060584
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      2
│      5
│      6
│      9
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.061984
┌ Warning: Variances had to be floored 
│   ind =
│    20-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.060960
┌ Info: EM with 100000 data points 10 iterations avll -1.060960
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.118339e+05
      1       6.789210e+05      -2.329129e+05 |       32
      2       6.502628e+05      -2.865814e+04 |       32
      3       6.350620e+05      -1.520080e+04 |       32
      4       6.254642e+05      -9.597874e+03 |       32
      5       6.203435e+05      -5.120707e+03 |       32
      6       6.174219e+05      -2.921524e+03 |       32
      7       6.152656e+05      -2.156308e+03 |       32
      8       6.130520e+05      -2.213662e+03 |       32
      9       6.104788e+05      -2.573209e+03 |       32
     10       6.081985e+05      -2.280223e+03 |       32
     11       6.068905e+05      -1.308077e+03 |       32
     12       6.062429e+05      -6.475320e+02 |       32
     13       6.057392e+05      -5.037049e+02 |       32
     14       6.053100e+05      -4.292155e+02 |       32
     15       6.048749e+05      -4.350916e+02 |       32
     16       6.044906e+05      -3.842866e+02 |       32
     17       6.041145e+05      -3.761323e+02 |       32
     18       6.037342e+05      -3.802630e+02 |       32
     19       6.034261e+05      -3.080914e+02 |       32
     20       6.032378e+05      -1.883760e+02 |       32
     21       6.031021e+05      -1.356252e+02 |       32
     22       6.029932e+05      -1.089664e+02 |       32
     23       6.028892e+05      -1.039536e+02 |       32
     24       6.028201e+05      -6.910169e+01 |       32
     25       6.027843e+05      -3.578737e+01 |       30
     26       6.027642e+05      -2.014804e+01 |       31
     27       6.027515e+05      -1.272478e+01 |       30
     28       6.027451e+05      -6.373565e+00 |       29
     29       6.027413e+05      -3.742126e+00 |       26
     30       6.027392e+05      -2.174142e+00 |       16
     31       6.027376e+05      -1.578650e+00 |       17
     32       6.027366e+05      -9.458080e-01 |       13
     33       6.027358e+05      -8.814400e-01 |       14
     34       6.027349e+05      -8.729728e-01 |       11
     35       6.027342e+05      -6.662847e-01 |       13
     36       6.027336e+05      -6.054333e-01 |       15
     37       6.027330e+05      -6.204897e-01 |       11
     38       6.027326e+05      -3.600462e-01 |       13
     39       6.027323e+05      -2.961195e-01 |       11
     40       6.027319e+05      -4.105340e-01 |       11
     41       6.027316e+05      -2.924423e-01 |        7
     42       6.027315e+05      -1.383809e-01 |        0
     43       6.027315e+05       0.000000e+00 |        0
K-means converged with 43 iterations (objv = 602731.5028822187)
┌ Info: K-means with 32000 data points using 43 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.318488
[ Info: iteration 2, average log likelihood -1.284761
[ Info: iteration 3, average log likelihood -1.250696
[ Info: iteration 4, average log likelihood -1.214846
[ Info: iteration 5, average log likelihood -1.173979
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     23
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.125345
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     18
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.128419
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.122287
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.086173
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     23
│     24
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.066863
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     18
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.097836
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.110515
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.069630
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     26
│     27
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.046609
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     18
│     23
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.090160
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.103669
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      6
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.051589
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     13
│     14
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.046459
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.110023
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      8
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.078984
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.073782
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│     14
│     26
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.032274
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.122353
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.093492
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.064991
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│     14
│     24
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.039802
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.119709
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.093215
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.067180
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.024218
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.121765
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.105053
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.077308
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     28
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.023279
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.132033
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.099729
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.050784
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      6
│      7
│     14
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.030754
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     23
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.116819
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.108632
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.052773
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.026220
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     23
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.131975
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.109019
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.053642
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.011714
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     23
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.135225
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.104216
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.055483
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      4
│      5
│      6
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.021505
┌ Info: EM with 100000 data points 50 iterations avll -1.021505
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.00616719  -0.00758    -0.000241642  -0.17123      0.112829     0.0290358   -0.0646925   -0.128479    -0.0556464    -0.0390335   0.0944603   0.00567296    0.0551174    -0.186237      0.0357285   -0.0174495   -0.0997915   -0.0599359   -0.0170853   -0.0798139    0.0229138    0.0609367    -0.100564    -0.132339    -0.0490864    -0.0984722
  0.0280545   -0.0305113  -0.14869       0.199025     0.0523429   -0.00157695   0.0370134    0.00102294   0.0851452    -0.0626545  -0.0141045   0.0120272     0.137807      0.0219079    -0.0280125   -0.0101953   -0.0738967    0.0387438   -0.069895    -0.102962    -0.0147493   -0.067386     -0.0181191   -0.0140102   -0.128081      0.0731401
  0.0859178   -0.239097   -0.0288727     0.133748     0.131102     0.106428     0.135365    -0.00165005  -0.112548     -0.107357    0.0364449  -0.191827     -0.115319     -0.0615172    -0.153279     0.10898      0.100983    -0.0791869    0.0209203   -0.0425525   -0.0745498   -0.0911347    -0.0505551   -0.101451     0.00218645   -0.0691315
 -0.0908216    0.227746    0.116845     -0.0563016    0.0123002   -0.169042     0.101774    -0.0221408   -0.0590803     0.0590464  -0.160686   -0.307534      0.112578      0.100994      0.19334     -0.00277817   0.137674     0.126722     0.190443    -0.0978814   -0.0488006   -0.152498     -0.0589944    0.143921     0.0135016     0.078565
 -0.00913243  -0.0636286   0.155789     -0.245978    -0.102135     0.082237    -0.19223      0.0581106   -0.0124443    -0.120476   -0.0322667  -0.0966966    -0.060484     -0.01116       0.0564409    0.00836048  -0.0740276   -0.0875072   -0.0871905   -0.124606    -0.0384625    0.039728      0.0517986    0.139964    -0.134366     -0.162444
  0.0667182    0.173739    0.0552267    -0.212803    -0.0807065    0.112853    -0.0708794    0.0450584    0.184098      0.136376    0.0877006   0.0962467     0.0896343     0.0888969     0.0596958   -0.0417412   -0.0721098   -0.0553035    0.187575    -0.0280487   -1.13035e-6  -0.0169047    -0.110742    -0.200621     0.112923     -0.0297015
 -0.0679801    0.119088    0.121481     -0.10384     -0.0444438   -0.0160575    0.0886264   -0.019534     0.00378384    0.0401328  -0.0772035  -0.0751161     0.0550767     0.0803879     0.0746577   -0.110505     0.039923     0.0561277    0.0274149   -0.213162    -0.0401411   -0.102208     -0.0438452    0.00957652   0.0336415    -0.0387692
 -0.0704235   -0.081976   -0.0358984    -0.037765     0.138231    -0.00697918  -0.152311     0.133051    -0.120034      0.0609452  -0.148514    0.129354     -0.229027     -0.042787      0.0459062    0.109716     0.184789    -0.106137    -0.0806526    0.118503    -0.0901093    0.0202516     0.126572     0.192147    -0.134967      0.089011
 -0.0950126    0.0298102   0.0362698    -0.206425    -0.176495    -0.0676547   -0.170207    -0.0694471    0.0793497    -0.0124448  -0.0632597  -0.016639     -0.0828803     0.0457709     0.00071737   0.0704057   -0.0292991   -0.0906216   -0.0929103   -0.0875064   -0.0326791    0.0193173     0.0446821    0.063754     0.00465913    0.128979
  0.164939    -0.0985805   0.0949384    -0.0177478    0.0303454   -0.010194    -0.215235    -0.040228    -0.205841      0.150813   -0.157932   -0.111932      0.128308     -0.108846     -0.0901544    0.263684     0.012066     0.219407     0.0682705   -0.0253138   -0.161401    -0.0185591    -0.0453273    0.023796     0.144612     -0.034671
  0.034503     0.131539    0.11818      -0.0177215   -0.00784696  -0.060304    -0.0668515   -0.0353772    0.204499      0.0611111   0.0710719   0.0153492    -0.0473914     0.0375379     0.105546     0.114321    -0.118713     0.0363892    0.0931066   -0.0206898    0.0783547   -0.216248      0.0842751    0.0145564    0.0297075     0.0900195
 -0.0348695   -0.0355395   0.145481     -0.158449     0.0236424    0.0277229   -0.139745     0.0366888    0.109045      0.131458    0.100907    0.0166525     0.0380294    -0.0523517     0.0312224    0.235001     0.0139995   -0.142864    -0.0654293   -0.0804999    0.118832    -0.134207     -0.0140348   -0.0459987   -0.0352226     0.0140941
  0.0374892   -0.0153211  -0.0458715     0.0619877   -0.0507      -0.00928191   0.106146    -0.0842814    0.053264      0.0219863   0.0580224  -0.0328015     0.0340164    -0.0210082    -0.0317261   -0.0760309    0.077279     0.0802098    0.107868    -0.121597    -0.0541136    0.0848521    -0.0101668    0.00534638   0.000765478  -0.0309157
  0.0449097   -0.10136     0.0803214    -0.0450803   -0.0858304   -0.0245289    0.114605    -0.0420746   -0.0209842    -0.0482817  -0.0195979   0.000913714  -0.0869485     0.0255712    -0.0468608   -0.0212224    0.0507954   -0.0364047    0.0177139   -0.139305     0.0803302    0.12521      -0.137207     0.00993969  -0.0351538    -0.154436
  0.087346     0.0391391   0.0391771     0.0224167    0.00859267  -0.0574591    0.00850047  -0.131625     0.106505     -0.0915038  -0.0373285   0.00625878   -0.0255214     0.181435      0.0646131    0.0770524   -0.0112672    0.0919266    0.151929     0.0878039   -0.01802      0.0636566    -0.0422678   -0.188251     0.087526      0.0155263
 -0.0712336    0.08729    -0.0182404     0.0369481    0.027414    -0.190917    -0.0310646    0.10097     -0.0733677     0.0645351   0.160208    0.0662293    -0.0330056     0.0481961     0.133197     0.126374     0.131344    -0.130081    -0.0646309    0.123861    -0.00865221  -0.000453079  -0.0118112    0.115244     0.0244902    -0.0246178
  0.159016     0.0392526   0.0378404    -0.0774404    0.0624072   -0.0810885   -0.21119     -0.0225924    0.0666275     0.146984    0.120508   -0.0708182    -0.231198     -0.0513467     0.102787    -0.0410673    0.00316997   0.0140729    0.175972     0.104846     0.0459585   -0.0443966    -0.133698     0.298398    -0.198056     -0.0209431
 -0.100476    -0.149286    0.000663192  -0.086782     0.0527269   -0.0969212   -0.0606861    0.0168569    0.100129     -0.151098    0.0661453  -0.0388979     0.108345      0.00698759    0.0313564    0.0853059    0.159233     0.186765     0.066406    -0.0447482    0.056111    -0.0628839     0.0709132    0.086981    -0.0528026    -0.0669589
 -0.0805532   -0.234635    0.0127979    -0.116781     0.0139      -0.00464474   0.0262828    0.00881967  -0.164725      0.110011    0.240163   -0.209441      0.133793     -0.0155754    -0.122181     0.110639     0.101646     0.116083     0.0615656    0.0329161   -0.054077    -0.0824467    -0.0519557    0.125942    -0.0575419    -0.143895
 -0.030832     0.0134408   0.0866068     0.126379     0.0857035   -0.298857     0.062365     0.0765292    0.149428     -0.0545385   0.195119    0.114375     -0.0436528     0.171676     -0.131815    -0.0113504    0.23673      0.10387     -0.0793692   -0.0573773    0.0418813    0.0215359     0.00139321   0.0560503    0.203151      0.0523494
 -0.0229388    0.0814331   0.135454      0.220237    -0.123046     0.045033    -0.0918055   -0.109857    -0.0150737    -0.0451211  -0.199979   -0.0145829     0.0939357    -0.0797268    -0.0911869    0.18772     -0.22155     -0.0835136   -0.0096474   -0.0755816    0.124607    -0.0631441     0.134258    -0.11362     -0.118802      0.109683
 -0.0393105   -0.0763555   0.0977405     0.035844    -0.033102    -0.00264137  -0.00736781  -0.113905     0.084387     -0.0293099   0.0620766  -0.140933     -0.14081       0.0118241     0.118204    -0.0309227   -0.0735577    0.0322897   -0.0434322   -0.148619     0.0634388   -0.170036     -0.0184452   -0.20474      0.0981559     0.211746
 -0.143643    -0.0735061  -0.000346655   0.0296119    0.0966038    0.045937     0.149584     0.0868886   -0.0611678    -0.014061    0.0890269   0.112689     -0.0378657     0.0256235     0.0259614    0.0948841    0.0485444    0.192233    -0.0757274   -0.0383401   -0.138183     0.0676613     0.0542344    0.0895004   -0.0278706    -0.041862
  0.0788977   -0.0564343  -0.011491     -0.0149474    0.067261    -0.0495877    0.104152    -0.12343      0.0112604    -0.207451    0.0175512  -0.117698      0.0545034    -0.0873206    -0.145625    -0.131643    -0.0886581   -0.119979    -0.122093    -0.0495307   -0.10432     -0.162361     -0.0732841    0.0493201   -0.060544      0.00191306
  0.108484    -0.104498    0.087659      0.0288805   -0.158827     0.00597235  -0.0311934   -0.128607    -0.0720283     0.110222   -0.0391523  -0.00520962    0.0178167     0.0123419     0.0310251   -0.0616759    0.0791024    0.0372205   -0.00877735  -0.0842134   -0.170067    -0.0283563     0.0784201   -0.084798     0.133129     -0.0865757
  0.00227656  -0.0948735  -0.183305     -0.0235459   -0.181203     0.0403246   -0.0852198   -0.125021     0.000176783   0.087281   -0.11109     0.0711116     0.10011       0.0756796    -0.0202448   -0.0327868   -0.0272407   -0.0499234    0.0371773    0.136776     0.0372049   -0.161683      0.0181123   -0.157183     0.171816     -0.0805529
 -0.254728    -0.117453   -0.0173737    -0.196107    -0.0353796   -0.118259     0.0235945    0.0851161   -0.0131643     0.0558247   0.0441797   0.0892973    -0.0198653    -0.115455      0.133299     0.0233212   -0.10366      0.0745496    0.0185591   -0.00205721  -0.102522    -0.0682373    -0.211057    -0.0547168    0.0799055     0.269076
  0.110497    -0.0113746   0.0244981     0.0300834    0.101725     0.0708543    0.102271    -0.145042    -0.064244      0.0369861   0.027811   -0.155099      0.0390352     0.0242027     0.0104174   -0.0569454   -0.0674555    0.321842     0.119148    -0.103758    -0.0246719    0.12255       0.0355053   -0.0475636    0.0107557    -0.102723
 -0.159813    -0.122667    0.255713      0.024926     0.0280575   -0.117292    -0.103059    -0.0884356    0.0450751    -0.0776355   0.0849021  -0.0644158     0.0697959    -0.129524     -0.0194326   -0.0542732   -0.100931    -0.0156649   -0.0339525    0.166588    -0.10487      0.0113444     0.0480996    0.11863      0.000750129   0.000574916
  0.103145    -0.11116     0.0551803    -0.0504694   -0.0924335    0.0818654    0.0261935    0.0544297    0.0563808     0.296474   -0.0275554  -0.175643      0.121519     -0.000971759  -0.0183431    0.0456014    0.110368    -0.076669    -0.0179068   -0.120842     0.0907064    0.211056      0.0661561    0.181654     0.0419519     0.0521006
 -0.066552    -0.151187    0.121545      0.00978238  -0.0759214    0.0608246    0.024475     0.065212     0.0173633     0.162661    0.105602    0.082496      0.136918      0.0532553    -0.0466531   -0.14766     -0.33352     -0.0947883    0.165704    -0.021032    -0.0178549    0.0405705     0.0237382   -0.102863    -0.0249396     0.0269733
 -0.076725     0.109509    0.0616922     0.0345744   -0.031738     0.0565094   -0.146531     0.1023       0.079465     -0.108675    0.0476304   0.0292071     0.000528696   0.122041     -0.0726532    0.145376    -0.0218589    0.00249911  -0.168179    -0.0163005   -0.110127    -0.191633     -0.0275821   -0.119475     0.00757576   -0.0256751[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     23
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.137162
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     18
│     23
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.062585
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      6
│      7
│      8
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.996056
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     14
│     18
│     23
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.087630
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     18
│     23
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.069530
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      6
│      8
│     18
│     23
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.010786
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      4
│      5
│      7
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.056517
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     18
│     23
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.087229
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      8
│     18
│     23
│     24
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.025801
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     18
│     23
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.063965
┌ Info: EM with 100000 data points 10 iterations avll -1.063965
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0286925    0.0785342    0.0679791  -0.119456    -0.0152226    0.0803912   -0.0571801    0.0757801     0.120397      0.179373    -0.0966029   -0.233618     0.118101    -0.0536929   0.0847278   -0.0490086    0.155077    -0.09559     -0.0631631    0.0858441   0.0137743     0.111177    -0.0834862   -0.0038409   -0.0958709     0.0436902
  0.0276218    0.136436     0.0536238   0.115074     0.0148782   -0.0696531   -0.0158775   -0.142604     -0.0873046     0.0973662   -0.059118     0.0198687    0.0852464   -0.225624   -0.0206323    0.0129441   -0.0378707    0.0328257   -0.0259436    0.0121216  -0.0229031    -0.035508    -0.0986328   -0.022793     0.0073706     0.224568
 -0.214337     0.0698295   -0.0383225   0.0825412   -0.0508968   -0.0338572   -0.0572959    0.0413686     0.162254     -0.0882202   -0.202728     0.14962     -0.123101     0.0827586  -0.00176816   0.0694692   -0.0216267    0.0867779   -0.0962213    0.16348     0.114004     -0.0352327   -0.0415758   -0.0522214   -0.0199402    -0.0718167
  0.117048     0.0988383    0.0944953   0.0634146   -0.0565118    0.0197032    0.0933621    0.0979313     0.06142      -0.124547     0.0892152    0.118141    -0.0932244   -0.193854    0.01694      0.180873     0.14998      0.0525181   -0.109331     0.0781641  -0.00478693   -0.0666989    0.0296561    0.0262728   -0.0131761    -0.0415719
  0.116198     0.0780281   -0.0306186  -0.140778     0.0832743    0.125452    -0.0159215   -0.0370371    -0.0547994    -0.0111181    0.0530388   -0.0441199   -0.11454      0.101397    0.0227898    0.117969    -0.070597    -0.262869    -0.150583    -0.0730607   0.0804569     0.0533744    0.0716533    0.0908888   -0.0219216    -0.0628841
 -0.0197877   -0.0117211   -0.0952463   0.0325261    0.10852     -0.0612358    0.0266593    0.0922501     0.0229572    -0.0322312   -0.0435498   -0.116837     0.149925     0.0611381  -0.0880488    0.0493535    0.047552    -0.0792704    0.00369944  -0.0403969   0.000932894  -0.148687     0.0197498   -0.130073    -0.0537732     0.119686
  0.141036     0.0227337   -0.0330252   0.0815305   -0.11203     -0.0814578   -0.0577087    0.11311       0.0632207     0.0722413   -0.0472938   -0.237966     0.168031    -0.0660806  -0.137411     0.080161     0.0127303   -0.0388763   -0.00822715   0.106      -0.0119162    -0.0686831    0.035473    -0.00854333  -0.0766558    -0.103252
  0.0275328    0.0655076   -0.0336601  -0.0323026    0.0565104    0.0687963   -0.0440686   -0.125373      0.028045      0.0287061   -0.0575094   -0.231982    -0.0872508    0.214062   -0.0289768   -0.00751879  -0.197314    -0.00132739  -0.0770235   -0.0486686  -0.116835     -0.0600672   -0.0706545    0.102145     0.102317      0.0788464
 -0.0215608   -0.0779389    0.110213    0.0776123    0.0468051   -0.0902826    0.154731    -0.0504904     0.0742838    -0.0689009   -0.0283099   -0.0819403   -0.137304     0.193831   -0.0600972   -0.167556    -0.180951    -0.0280887    0.0929106   -0.16569     0.0776289    -0.0349092   -0.10893     -0.0531934   -0.0980733    -0.129703
  0.280631     0.0104099   -0.150205    0.050473    -0.065621    -0.0039915    0.011013     0.107365     -0.0492468     0.0356015   -0.259619     0.044539    -0.00917282  -0.0734512  -0.0106474    0.107183     0.0149956    0.138361     0.0581153    0.0985518  -0.122495      0.0538716    0.00093082  -0.0460095    0.273708      0.0738648
  0.00155227   0.0614066   -0.194135    0.0679878   -0.0729881   -0.0657103   -0.105418     0.0635265     0.000790382   0.00467358   0.0436216   -0.175868    -0.127862    -0.0849563   0.0311528   -0.0630776   -0.00507985  -0.00212642  -0.0383444    0.141959    0.085469      0.00117915  -0.0283664    0.119708    -0.0200253    -0.12337
  0.00142671  -0.0703692   -0.0114766  -0.144377    -0.0581666   -0.086019    -0.00998687  -0.000632006   0.0391409     0.0458879   -0.0662523   -0.0334331   -0.0687259   -0.177377   -0.0319026   -0.065268    -0.0135576    0.0298       0.142169    -0.150756    0.0473094    -0.0344306    0.0215985   -0.090922    -0.011372      0.100494
  0.0500813   -0.034582     0.0105944   0.0727938    0.143085    -0.164046    -0.0634852   -0.0311851    -0.0898215     0.038106     0.0578451   -0.062        0.0418884   -0.0825125  -0.103928     0.0128628    0.094806    -0.0963209    0.119976     0.0238736  -0.0392311    -0.0531686    0.0579208   -0.0511476    0.227482      0.0523743
 -0.0970864   -0.063837     0.0458654   0.00939043  -0.0278243   -0.0190093    0.0856055    0.042632     -0.0886189    -0.0205627    0.0541453   -0.237588     0.0186036    0.0545533  -0.0408986    0.0635328    0.141979     0.163927     0.20135      0.0576409  -0.00711027   -0.0627114   -0.138894    -0.0407484   -0.0682638     0.0697974
  0.0619862    0.155065    -0.056352   -0.041173     0.130649     0.0496943    0.0934647   -0.0990616     0.0627111     0.0450878    0.102825    -0.0443535    0.0584727    0.016243   -0.183111    -0.017026     0.0973819    0.0512058   -0.0467363   -0.134536   -0.0571427    -0.0399609    0.00457903  -0.048816    -0.0385435    -0.0203415
  0.00974905  -0.0349545    0.143054    0.148717    -0.025418    -0.00397019   0.128074    -0.0140902    -0.156288      0.0486886   -0.0347077    0.0728493   -0.0536094   -0.15846    -0.111386    -0.1261      -0.00229691  -0.0978532    0.10971     -0.0462014  -0.0701031    -0.0649143   -0.00171847   0.0845636    0.168619      0.00421811
 -0.0929409    0.16943     -0.0950525  -0.133357    -0.0915713    0.113726     0.0913137   -0.0129767     0.0155712     0.0245688   -0.0168839   -0.237356     0.172127     0.0171082  -0.074729     0.00226238   0.0752691    0.0593618   -0.0320986    0.193185   -0.0447382     0.00620632   0.0183078   -0.0690054   -0.139534      0.0692698
  0.161757    -0.197275    -0.165366   -0.20038     -0.102529     0.1474       0.130969     0.117143      0.0337962     0.115751    -0.112763     0.0214178    0.0801289    0.169567   -0.0399944   -0.111955    -0.0207174   -0.14661     -0.0163762    0.0795203  -0.123658      0.114589    -0.0905189    0.0103277    0.0667426    -0.00966308
  0.155763    -0.0552041   -0.101504   -0.25697      0.165438     0.0637581    0.01709     -0.0156837     0.0600342    -0.0694674    0.0485004    0.0577857    0.083053    -0.0888821  -0.0479058   -0.0406536    0.0240454   -0.0882556    0.111539    -0.0209829  -0.060251     -0.0832768   -0.149691    -0.0225578   -0.0104947     0.212237
  0.20618      0.0119545   -0.0721674  -0.0318835   -0.0609567    0.00262728  -0.0557628    0.0769549    -0.0510891    -0.0402093    0.141407     0.10744      0.0585351   -0.0656777   0.034656    -0.264171     0.0764358    0.13385      0.0691516    0.0104592   0.0770389    -0.0408789   -0.0305739    0.0926126   -0.0846806    -0.0263942
 -0.0784401   -0.00904153   0.0790663  -0.0848329    0.0649285    0.113531     0.00553837  -0.119937      0.0463886    -0.158978     0.059909    -0.138708    -0.0347657   -0.0489942  -0.0520143    0.0221197    0.17293     -0.190991     0.105643    -0.0767539  -0.0757459    -0.125292     0.0692946   -0.110389    -0.000477512  -0.0137431
  0.102959    -0.133937     0.0644074  -0.118577     0.00487893   0.0762828   -0.0547107   -0.0112498    -0.0608398    -0.0597069   -0.172595    -0.0110864   -0.132179     0.13022     0.0928425   -0.0302748   -0.0257945   -0.193696    -0.0633095   -0.116942    0.0694358    -0.0232734    0.00716995   0.0707955    0.0210503    -0.00537819
 -0.0585872    0.13253     -0.0235491  -0.0769759   -0.156579    -0.0344066    0.176319     0.101662     -0.0559816    -0.124815    -0.0862907   -0.0751288   -0.140363    -0.0513528  -0.267396    -0.0332115   -0.0215259   -0.148178     0.0268797   -0.117601   -0.208321      0.0508584    0.0389266   -0.0898751   -0.222674     -0.155901
  0.0376023    0.0631832    0.0617748   0.138551     0.019704     0.0208636    0.0185864    0.0676848     0.214056      0.00852115  -0.0123748    0.191177    -0.0375839    0.0330919   0.181408    -0.0494658   -0.00106006   0.114158    -0.0157616   -0.12154    -0.108683     -0.0265618    0.0924448    0.0287384    0.0966251    -0.0613015
  0.0336214   -0.116217     0.0454237   0.0157166   -0.0408653    0.0159632   -0.156985     0.107357      0.0587573    -0.00643326   0.112177    -0.144158    -0.146588     0.075077   -0.0432773    0.168655    -0.156514     0.0996164    0.127222    -0.184628    0.0701166     0.171114    -0.052959     0.100606     0.151225     -0.0331609
  0.185471     0.0987206    0.0406536  -0.0952079    0.0312321    0.0879927    0.0794231   -0.0781359     0.066836     -0.0585312   -0.148125     0.00870845   0.0204576   -0.119036    0.00641483   0.00799454  -0.0804226   -0.231232    -0.115749     0.151257    0.0997759     0.00742939   0.150379    -0.0585836    0.217563     -0.0313
  0.0168168   -0.0303718    0.0854967   0.224814    -0.0842158    0.0122709    0.0891481   -0.17872      -0.0573934     0.171793     0.0807286    0.0166236   -0.0892029    0.205394   -0.116523    -0.0913382   -0.208857    -0.112348     0.0204389   -0.07516     0.00862493    0.0337558   -0.0717704    0.0138772   -0.292493     -0.00039331
 -0.0908085   -0.134858     0.180229    0.158595    -0.113344     0.0282081   -0.0656933   -0.0292683     0.00715881    0.199214    -0.0650845    0.185014     0.126004     0.143425   -0.0389643    0.102567     0.31955      0.174358    -0.0212921   -0.0464182   0.13588      -0.0151711   -0.121843     0.00624904  -0.0432979     0.0323787
  0.0925928   -0.0675175   -0.0908527  -0.0265192    0.0495141   -0.0471701   -0.0139428   -0.0906367     0.107515     -0.0660739   -0.265181    -0.10079     -0.0426921   -0.0245375   0.0697438    0.0910781   -0.00668984   0.0818595    0.132425     0.169031    0.0516077     0.0601425    0.0840042   -0.0169747   -0.0757612     0.0180898
  0.0890471   -0.0625479    0.0322821   0.0430943   -0.0266312    0.116337    -0.0414658    0.0765666    -0.0337292     0.117613     0.192606     0.00230882  -0.326869    -0.0870021   0.0164769    0.12797     -0.115057     0.0533582   -0.0229287   -0.0374879   0.11996       0.0182586   -0.120532    -0.00861189  -0.00165173    0.16538
 -0.0558515   -0.0470732   -0.179155   -0.0110276    0.023676     0.0847047   -0.0428015   -0.0964165    -0.0889696     0.0227912   -0.024424     0.0342854    0.00635055   0.0184632  -0.065095    -0.00991666   0.0272018    0.136317    -0.022261    -0.159367   -0.101887     -0.00832721  -0.0998117   -0.0134819    0.075207      0.0651806
 -0.122626     0.0141045   -0.045425   -0.0812296   -0.104675    -0.0598137    0.123607     0.101987     -0.095178      0.0220339    0.00989553  -0.0157673    0.0925538   -0.0996821  -0.0446652   -0.0284461   -0.0104278    0.0854128   -0.205049    -0.0248972   0.0313141    -0.0859086   -0.093836     0.0127894    0.107144     -0.13695kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4210673252366535
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421085
[ Info: iteration 2, average log likelihood -1.421029
[ Info: iteration 3, average log likelihood -1.420993
[ Info: iteration 4, average log likelihood -1.420953
[ Info: iteration 5, average log likelihood -1.420904
[ Info: iteration 6, average log likelihood -1.420845
[ Info: iteration 7, average log likelihood -1.420775
[ Info: iteration 8, average log likelihood -1.420695
[ Info: iteration 9, average log likelihood -1.420604
[ Info: iteration 10, average log likelihood -1.420485
[ Info: iteration 11, average log likelihood -1.420298
[ Info: iteration 12, average log likelihood -1.419957
[ Info: iteration 13, average log likelihood -1.419349
[ Info: iteration 14, average log likelihood -1.418430
[ Info: iteration 15, average log likelihood -1.417395
[ Info: iteration 16, average log likelihood -1.416584
[ Info: iteration 17, average log likelihood -1.416129
[ Info: iteration 18, average log likelihood -1.415921
[ Info: iteration 19, average log likelihood -1.415834
[ Info: iteration 20, average log likelihood -1.415798
[ Info: iteration 21, average log likelihood -1.415783
[ Info: iteration 22, average log likelihood -1.415777
[ Info: iteration 23, average log likelihood -1.415774
[ Info: iteration 24, average log likelihood -1.415773
[ Info: iteration 25, average log likelihood -1.415772
[ Info: iteration 26, average log likelihood -1.415771
[ Info: iteration 27, average log likelihood -1.415771
[ Info: iteration 28, average log likelihood -1.415771
[ Info: iteration 29, average log likelihood -1.415771
[ Info: iteration 30, average log likelihood -1.415770
[ Info: iteration 31, average log likelihood -1.415770
[ Info: iteration 32, average log likelihood -1.415770
[ Info: iteration 33, average log likelihood -1.415770
[ Info: iteration 34, average log likelihood -1.415770
[ Info: iteration 35, average log likelihood -1.415770
[ Info: iteration 36, average log likelihood -1.415770
[ Info: iteration 37, average log likelihood -1.415769
[ Info: iteration 38, average log likelihood -1.415769
[ Info: iteration 39, average log likelihood -1.415769
[ Info: iteration 40, average log likelihood -1.415769
[ Info: iteration 41, average log likelihood -1.415769
[ Info: iteration 42, average log likelihood -1.415769
[ Info: iteration 43, average log likelihood -1.415769
[ Info: iteration 44, average log likelihood -1.415769
[ Info: iteration 45, average log likelihood -1.415769
[ Info: iteration 46, average log likelihood -1.415769
[ Info: iteration 47, average log likelihood -1.415769
[ Info: iteration 48, average log likelihood -1.415769
[ Info: iteration 49, average log likelihood -1.415769
[ Info: iteration 50, average log likelihood -1.415769
┌ Info: EM with 100000 data points 50 iterations avll -1.415769
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.421085048169358
│     -1.4210293805983158
│      ⋮
└     -1.4157687471758218
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415783
[ Info: iteration 2, average log likelihood -1.415720
[ Info: iteration 3, average log likelihood -1.415671
[ Info: iteration 4, average log likelihood -1.415613
[ Info: iteration 5, average log likelihood -1.415541
[ Info: iteration 6, average log likelihood -1.415450
[ Info: iteration 7, average log likelihood -1.415343
[ Info: iteration 8, average log likelihood -1.415226
[ Info: iteration 9, average log likelihood -1.415111
[ Info: iteration 10, average log likelihood -1.415008
[ Info: iteration 11, average log likelihood -1.414926
[ Info: iteration 12, average log likelihood -1.414864
[ Info: iteration 13, average log likelihood -1.414821
[ Info: iteration 14, average log likelihood -1.414790
[ Info: iteration 15, average log likelihood -1.414769
[ Info: iteration 16, average log likelihood -1.414753
[ Info: iteration 17, average log likelihood -1.414741
[ Info: iteration 18, average log likelihood -1.414731
[ Info: iteration 19, average log likelihood -1.414723
[ Info: iteration 20, average log likelihood -1.414716
[ Info: iteration 21, average log likelihood -1.414710
[ Info: iteration 22, average log likelihood -1.414705
[ Info: iteration 23, average log likelihood -1.414700
[ Info: iteration 24, average log likelihood -1.414696
[ Info: iteration 25, average log likelihood -1.414693
[ Info: iteration 26, average log likelihood -1.414690
[ Info: iteration 27, average log likelihood -1.414687
[ Info: iteration 28, average log likelihood -1.414684
[ Info: iteration 29, average log likelihood -1.414682
[ Info: iteration 30, average log likelihood -1.414680
[ Info: iteration 31, average log likelihood -1.414678
[ Info: iteration 32, average log likelihood -1.414677
[ Info: iteration 33, average log likelihood -1.414675
[ Info: iteration 34, average log likelihood -1.414674
[ Info: iteration 35, average log likelihood -1.414672
[ Info: iteration 36, average log likelihood -1.414671
[ Info: iteration 37, average log likelihood -1.414670
[ Info: iteration 38, average log likelihood -1.414668
[ Info: iteration 39, average log likelihood -1.414667
[ Info: iteration 40, average log likelihood -1.414666
[ Info: iteration 41, average log likelihood -1.414665
[ Info: iteration 42, average log likelihood -1.414664
[ Info: iteration 43, average log likelihood -1.414663
[ Info: iteration 44, average log likelihood -1.414662
[ Info: iteration 45, average log likelihood -1.414661
[ Info: iteration 46, average log likelihood -1.414660
[ Info: iteration 47, average log likelihood -1.414659
[ Info: iteration 48, average log likelihood -1.414658
[ Info: iteration 49, average log likelihood -1.414657
[ Info: iteration 50, average log likelihood -1.414656
┌ Info: EM with 100000 data points 50 iterations avll -1.414656
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4157829156857529
│     -1.4157204153569545
│      ⋮
└     -1.4146558802578395
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414668
[ Info: iteration 2, average log likelihood -1.414605
[ Info: iteration 3, average log likelihood -1.414555
[ Info: iteration 4, average log likelihood -1.414498
[ Info: iteration 5, average log likelihood -1.414432
[ Info: iteration 6, average log likelihood -1.414357
[ Info: iteration 7, average log likelihood -1.414276
[ Info: iteration 8, average log likelihood -1.414195
[ Info: iteration 9, average log likelihood -1.414118
[ Info: iteration 10, average log likelihood -1.414048
[ Info: iteration 11, average log likelihood -1.413983
[ Info: iteration 12, average log likelihood -1.413925
[ Info: iteration 13, average log likelihood -1.413871
[ Info: iteration 14, average log likelihood -1.413823
[ Info: iteration 15, average log likelihood -1.413781
[ Info: iteration 16, average log likelihood -1.413745
[ Info: iteration 17, average log likelihood -1.413714
[ Info: iteration 18, average log likelihood -1.413688
[ Info: iteration 19, average log likelihood -1.413666
[ Info: iteration 20, average log likelihood -1.413647
[ Info: iteration 21, average log likelihood -1.413630
[ Info: iteration 22, average log likelihood -1.413615
[ Info: iteration 23, average log likelihood -1.413601
[ Info: iteration 24, average log likelihood -1.413587
[ Info: iteration 25, average log likelihood -1.413574
[ Info: iteration 26, average log likelihood -1.413561
[ Info: iteration 27, average log likelihood -1.413547
[ Info: iteration 28, average log likelihood -1.413533
[ Info: iteration 29, average log likelihood -1.413519
[ Info: iteration 30, average log likelihood -1.413504
[ Info: iteration 31, average log likelihood -1.413488
[ Info: iteration 32, average log likelihood -1.413472
[ Info: iteration 33, average log likelihood -1.413455
[ Info: iteration 34, average log likelihood -1.413438
[ Info: iteration 35, average log likelihood -1.413421
[ Info: iteration 36, average log likelihood -1.413403
[ Info: iteration 37, average log likelihood -1.413386
[ Info: iteration 38, average log likelihood -1.413370
[ Info: iteration 39, average log likelihood -1.413354
[ Info: iteration 40, average log likelihood -1.413340
[ Info: iteration 41, average log likelihood -1.413327
[ Info: iteration 42, average log likelihood -1.413315
[ Info: iteration 43, average log likelihood -1.413304
[ Info: iteration 44, average log likelihood -1.413295
[ Info: iteration 45, average log likelihood -1.413286
[ Info: iteration 46, average log likelihood -1.413279
[ Info: iteration 47, average log likelihood -1.413273
[ Info: iteration 48, average log likelihood -1.413268
[ Info: iteration 49, average log likelihood -1.413263
[ Info: iteration 50, average log likelihood -1.413258
┌ Info: EM with 100000 data points 50 iterations avll -1.413258
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4146676047292814
│     -1.4146054509433545
│      ⋮
└     -1.4132583753708239
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413263
[ Info: iteration 2, average log likelihood -1.413204
[ Info: iteration 3, average log likelihood -1.413153
[ Info: iteration 4, average log likelihood -1.413094
[ Info: iteration 5, average log likelihood -1.413024
[ Info: iteration 6, average log likelihood -1.412938
[ Info: iteration 7, average log likelihood -1.412837
[ Info: iteration 8, average log likelihood -1.412725
[ Info: iteration 9, average log likelihood -1.412607
[ Info: iteration 10, average log likelihood -1.412488
[ Info: iteration 11, average log likelihood -1.412375
[ Info: iteration 12, average log likelihood -1.412270
[ Info: iteration 13, average log likelihood -1.412173
[ Info: iteration 14, average log likelihood -1.412087
[ Info: iteration 15, average log likelihood -1.412011
[ Info: iteration 16, average log likelihood -1.411944
[ Info: iteration 17, average log likelihood -1.411886
[ Info: iteration 18, average log likelihood -1.411836
[ Info: iteration 19, average log likelihood -1.411793
[ Info: iteration 20, average log likelihood -1.411756
[ Info: iteration 21, average log likelihood -1.411724
[ Info: iteration 22, average log likelihood -1.411696
[ Info: iteration 23, average log likelihood -1.411671
[ Info: iteration 24, average log likelihood -1.411648
[ Info: iteration 25, average log likelihood -1.411628
[ Info: iteration 26, average log likelihood -1.411609
[ Info: iteration 27, average log likelihood -1.411591
[ Info: iteration 28, average log likelihood -1.411574
[ Info: iteration 29, average log likelihood -1.411558
[ Info: iteration 30, average log likelihood -1.411543
[ Info: iteration 31, average log likelihood -1.411528
[ Info: iteration 32, average log likelihood -1.411514
[ Info: iteration 33, average log likelihood -1.411500
[ Info: iteration 34, average log likelihood -1.411486
[ Info: iteration 35, average log likelihood -1.411472
[ Info: iteration 36, average log likelihood -1.411458
[ Info: iteration 37, average log likelihood -1.411445
[ Info: iteration 38, average log likelihood -1.411431
[ Info: iteration 39, average log likelihood -1.411418
[ Info: iteration 40, average log likelihood -1.411405
[ Info: iteration 41, average log likelihood -1.411391
[ Info: iteration 42, average log likelihood -1.411378
[ Info: iteration 43, average log likelihood -1.411364
[ Info: iteration 44, average log likelihood -1.411351
[ Info: iteration 45, average log likelihood -1.411337
[ Info: iteration 46, average log likelihood -1.411324
[ Info: iteration 47, average log likelihood -1.411310
[ Info: iteration 48, average log likelihood -1.411297
[ Info: iteration 49, average log likelihood -1.411284
[ Info: iteration 50, average log likelihood -1.411270
┌ Info: EM with 100000 data points 50 iterations avll -1.411270
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4132631760578485
│     -1.4132042993614464
│      ⋮
└     -1.4112704051770255
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411266
[ Info: iteration 2, average log likelihood -1.411196
[ Info: iteration 3, average log likelihood -1.411129
[ Info: iteration 4, average log likelihood -1.411053
[ Info: iteration 5, average log likelihood -1.410961
[ Info: iteration 6, average log likelihood -1.410849
[ Info: iteration 7, average log likelihood -1.410718
[ Info: iteration 8, average log likelihood -1.410572
[ Info: iteration 9, average log likelihood -1.410417
[ Info: iteration 10, average log likelihood -1.410258
[ Info: iteration 11, average log likelihood -1.410101
[ Info: iteration 12, average log likelihood -1.409951
[ Info: iteration 13, average log likelihood -1.409812
[ Info: iteration 14, average log likelihood -1.409685
[ Info: iteration 15, average log likelihood -1.409572
[ Info: iteration 16, average log likelihood -1.409472
[ Info: iteration 17, average log likelihood -1.409383
[ Info: iteration 18, average log likelihood -1.409305
[ Info: iteration 19, average log likelihood -1.409237
[ Info: iteration 20, average log likelihood -1.409176
[ Info: iteration 21, average log likelihood -1.409122
[ Info: iteration 22, average log likelihood -1.409074
[ Info: iteration 23, average log likelihood -1.409030
[ Info: iteration 24, average log likelihood -1.408991
[ Info: iteration 25, average log likelihood -1.408955
[ Info: iteration 26, average log likelihood -1.408922
[ Info: iteration 27, average log likelihood -1.408892
[ Info: iteration 28, average log likelihood -1.408864
[ Info: iteration 29, average log likelihood -1.408837
[ Info: iteration 30, average log likelihood -1.408812
[ Info: iteration 31, average log likelihood -1.408788
[ Info: iteration 32, average log likelihood -1.408766
[ Info: iteration 33, average log likelihood -1.408744
[ Info: iteration 34, average log likelihood -1.408723
[ Info: iteration 35, average log likelihood -1.408703
[ Info: iteration 36, average log likelihood -1.408683
[ Info: iteration 37, average log likelihood -1.408664
[ Info: iteration 38, average log likelihood -1.408645
[ Info: iteration 39, average log likelihood -1.408626
[ Info: iteration 40, average log likelihood -1.408608
[ Info: iteration 41, average log likelihood -1.408591
[ Info: iteration 42, average log likelihood -1.408573
[ Info: iteration 43, average log likelihood -1.408556
[ Info: iteration 44, average log likelihood -1.408539
[ Info: iteration 45, average log likelihood -1.408522
[ Info: iteration 46, average log likelihood -1.408506
[ Info: iteration 47, average log likelihood -1.408490
[ Info: iteration 48, average log likelihood -1.408473
[ Info: iteration 49, average log likelihood -1.408457
[ Info: iteration 50, average log likelihood -1.408442
┌ Info: EM with 100000 data points 50 iterations avll -1.408442
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.411266223701003
│     -1.4111957899060368
│      ⋮
└     -1.4084415254491947
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4210673252366535
│     -1.421085048169358
│     -1.4210293805983158
│     -1.4209931022964468
│      ⋮
│     -1.4084733712496686
│     -1.4084573619902
└     -1.4084415254491947
32×26 Array{Float64,2}:
  0.164052     0.52949      0.149791   -0.399679    0.418866     0.173413   -0.656584     0.310752    0.0954916     0.0991173    0.0576104    0.376313     0.100982   -0.54829    -0.535558   -0.282821    -0.0826571   0.443911   -0.0820659   -0.165852   -0.291876    0.102415   -0.358111    -0.120425    -0.0873731  -0.24356
 -0.470749     0.342302     0.372977    0.15257     0.376588     0.426653   -0.308874    -0.24484     0.17126      -0.599425    -0.230962     0.054595     0.337248   -0.620698   -0.221149   -0.702006    -0.418136    0.620954    0.546171     0.174126    0.0977384   0.175531   -0.166194     0.530801    -0.243677    0.0224335
 -0.168177     0.409908    -0.149623   -0.546379   -0.165314     0.143233   -0.0300907   -0.263124    0.214646      0.0850174    0.110208    -0.434065    -0.0704969   0.348326   -0.662254    0.228283     0.0727937   0.705851   -0.471861    -0.167327    0.178995    0.287324   -0.271349     0.161403     0.0295711  -0.150862
 -0.434653     0.250134    -0.620796    0.757641   -0.129641    -0.176767    0.291435    -0.116997    0.240906      0.145919    -0.202655     0.0605394   -0.179921    0.479379   -0.730706    0.227108    -0.179287    0.531676   -0.271534     0.309431   -0.233218   -0.0499039   0.0715637    0.126275     0.159177    0.0716455
  0.35686     -0.0786268    0.096015   -0.585739    0.300498    -0.175738   -0.509689    -0.445053    0.135149     -0.401623    -0.778672    -0.403456    -0.413918   -0.323677    0.151012   -0.11101      0.0381616  -0.100097    0.187355    -0.542002   -0.0411126  -0.172363    0.653073    -0.42969      0.161153   -0.0713045
 -0.264948    -0.0212529   -0.370326    0.0896462   0.162685    -0.0190332   0.223793    -0.356357    0.060878     -0.593578    -0.268084    -0.298597    -0.445248   -0.16343    -0.559316    0.178724    -0.116771    0.0862993   0.158442    -0.546642   -0.78237    -0.864814    0.256177    -0.00531867   0.34971     0.0680304
 -0.259592    -0.184236    -0.0811275   0.184523    0.126625     0.107844   -0.429186    -0.269072   -0.343787     -0.358981    -0.758483    -0.350246    -0.0138632   0.287231   -0.191785    0.136768     0.102415    0.466839   -0.00155079   0.31469     0.0204709   0.101778    0.12125      0.0280013    0.146178    0.491121
  0.608793    -0.0807765    0.176453   -0.136466   -0.108049     0.350853   -0.213706    -0.208168    0.0128584    -0.469855    -0.712269     0.0840077   -0.581447    0.554208   -0.0752511   0.148602     0.0754147  -0.122503   -0.0688959    0.449405    0.460185    0.413101   -0.0193619    0.0594417    0.116442   -0.240909
  0.182306    -0.117476    -0.193602   -0.0429679   0.142425     0.216457   -0.0219516   -0.228741    0.379167     -0.0855075    0.55358     -0.656322    -0.0321232   0.0426904   0.141954   -0.345991     0.717238   -0.243356   -0.0457332   -0.140273   -0.20422    -0.375599    0.14149     -0.423111     0.0973225  -0.199677
  0.139729    -0.289771    -0.148307    0.198643   -0.274741     0.248344    0.278048    -0.67603     0.61936       0.357089     0.343069     0.726325    -0.28749     0.0113857   0.592891   -0.24343      0.26988     0.234846   -0.262553    -0.0859837  -0.258741    0.249693    0.186004     0.106603    -0.0778544  -0.280372
 -0.0335227   -0.00582708   0.140181    0.0795517  -0.136678    -0.0697151   0.218934     0.110302   -0.0338547     0.123733    -0.00194159  -0.0488785   -0.0753043   0.0648686  -0.0974713   0.00107368  -0.0873573  -0.144152   -0.017155    -0.0768178  -0.135357   -0.0320642   0.00776755  -0.0966853   -0.352427   -0.202264
  0.0782334   -0.017493    -0.155837   -0.0751836   0.0646326    0.0815817  -0.0494161    0.0231953  -0.000166715  -0.0261409    0.0458381    0.0332279    0.0634848  -0.160976    0.0399742  -0.0314413   -0.0194983   0.0224983  -0.0159138   -0.0497175   0.0457885  -0.0771028  -0.0464787    0.0477493    0.332775    0.202503
  0.268309     0.0596783    0.561282   -0.193088    0.326097     0.0915709   0.0558751    0.197236   -0.405103      0.126952    -0.108544     0.0841682   -0.406789    0.0862434   0.156444    0.0651201   -0.456016   -0.858       0.334848     0.117815    0.472493    0.0161193  -0.140693     0.217639    -0.332938   -0.469152
  0.318677    -0.0747543    0.650797   -0.187954    0.037939    -0.53863    -0.307032     0.0864759  -0.336234      0.618166     0.0917373    0.338007    -0.105549    0.114562    0.222358    0.279084     0.0565728  -0.157706    0.476292    -0.0129405   0.444302   -0.144032   -0.155281     0.0190205   -0.144829    0.747249
  0.0548804   -0.0443673   -0.0760342  -0.0289153  -0.00560298   0.0218011  -0.171881     0.170648    0.145842      0.568235     0.215273    -0.0159257    0.376568    0.0488448   0.643506   -0.204207     0.20627     0.103344   -0.274337     0.353133    0.703291    0.456166   -0.0825698    0.0205911    0.0414429   0.0480072
  0.681352     0.113637    -0.473673   -0.269277   -0.553028    -0.0310445   0.890556     0.369895   -0.158952      0.217103     0.251563     0.246329     0.303349    0.938941    0.0353487   0.250883     0.0133215  -0.161911   -0.122494     0.360529    0.579621    0.581617    0.00719925   0.119183    -0.144274    0.387489
  0.259782     0.345385     0.256811   -0.0340066   0.368164     0.4384     -0.822587    -0.205564    0.00737905    0.221708    -0.254648    -0.00784499  -0.201537    0.257072   -0.241943    0.193635    -0.2066      0.321905    0.0190443    0.447463    0.396403    0.134559   -0.00848597   0.243075     0.275959    0.22958
 -0.206335    -0.121273    -0.192188    0.23096    -0.174936    -0.0412847   0.476902    -0.13637     0.117679      0.0125582   -0.0119263   -0.102363    -0.0481166   0.252878   -0.0559612  -0.17227      0.0211254   0.0242123  -0.173029    -0.0247346  -0.0416081   0.128901    0.0128886   -0.0713704   -0.077428   -0.00712727
 -0.779374    -0.193469    -0.195579    0.714326   -0.253796     0.083392    0.549214    -0.248594   -0.395178     -0.116907     0.196678    -0.499166     0.273114    0.137417    0.273653   -0.0961807   -0.129281   -0.161029    0.0428533   -0.11136    -0.0626339  -0.127963   -0.332095    -0.230232     0.0722933   0.0419833
 -0.196148     0.270434    -0.296427    0.527317   -1.2757      -0.302487    0.685563    -0.13894     0.242184     -0.280915    -0.178246    -0.158076     0.0477769   0.0995144  -0.198351    0.0820044   -0.64919    -0.309793    0.314134     0.279041    0.151019   -0.0976669  -0.534526     0.381871     0.80875    -0.203986
 -0.622656    -0.320489     0.978222   -0.151162   -0.380773    -0.315458    0.00100597   0.130952   -0.537694     -0.223016    -0.731612     0.405227    -0.0139347   0.241873   -0.26376    -0.0318259    0.203048    0.148523   -0.131703    -0.539256   -0.111252   -0.33831    -0.730991     0.0218456   -0.353154   -0.410407
  0.0162413    0.136269     0.180732    0.26965    -0.351935     0.29588    -0.132233     0.827893   -0.262176      0.0198746    0.0832436    0.106808     0.448851   -0.0135446  -0.814938    0.334484    -0.0737205   0.325398   -0.0602327    0.46598    -0.535514   -0.251385   -0.523401    -0.0164619   -0.138464   -0.11859
 -0.086628    -0.0344256   -0.054854   -0.208784   -0.336578     0.249453    0.41711      0.541983    0.0391958    -0.544589    -0.0761321    0.154381     0.47545     0.123332   -0.93265     0.0564696   -1.00252    -0.388176   -0.150733    -0.085293    0.173564    0.796944    0.20534      0.995092    -0.0999215  -0.42946
  0.0981398    0.491312    -0.265395   -0.146691    0.36881     -0.336166   -0.105082     0.962615   -0.305902     -0.0896789   -0.60699     -0.47516      0.191378   -0.38167    -0.433532    0.572129    -0.403288   -0.199276    0.339398     0.106624    0.647949    0.0496983   0.222916    -0.142152     0.283952    0.986562
 -0.136112    -0.131795     0.186416   -0.428882    0.327703    -0.165425    0.355908     0.0174939   0.542702     -0.00141448   0.27254     -0.0734387   -0.236113   -0.490986    0.663835   -0.250648    -0.114902   -0.77732    -0.0731287   -0.589275    0.232336   -0.0191428  -0.115861    -0.243285     0.0961498  -0.361466
  0.30214      0.171082     0.308479    0.323445    0.764317     0.164843    0.559492    -0.161977    0.712814      0.0266445    0.289909     0.738739     0.0218282  -0.276692   -0.35008    -0.00940933  -0.47025    -0.674178    0.0989458    0.140955   -0.24678    -0.0481801   0.143294     0.309383     0.274806   -0.214921
  0.667744    -0.505117    -0.218881    0.675292   -0.152955     0.063473    0.246424    -0.367877   -0.503782     -0.242502    -0.14198      0.621085     0.0165953   0.0348731   0.277512   -0.18397      0.0270356  -0.229109    0.692611     0.533165   -0.91379     0.270325    0.200925     0.507728    -0.611438    0.366311
  0.292198    -0.279353    -0.652973   -0.0745885  -0.386578    -0.325684    0.389914     0.496377   -0.131714      0.43979      0.34479     -0.0796296    0.0654939  -0.150356    0.296267    0.229887     0.125077   -0.645449    0.231941    -0.495672   -0.671193   -0.64226     0.562306    -0.199774    -0.105916   -0.0979877
  0.204886    -0.0914662    0.0828879  -0.70189    -0.474862    -0.213785   -0.457611     0.258012   -0.477738      0.0318777    0.43274     -0.807673     0.445835   -0.128725    0.670059    0.023667     0.883867   -0.0252359   0.134662    -0.402215    0.411275    0.625037   -0.540611     0.125299    -0.626043   -0.301521
  0.298144    -0.239882     0.425283   -0.358593    0.387872    -0.167232   -0.224921     0.55911    -0.00759987    0.253502     0.115711    -0.258856     0.219157   -0.371862   -0.0436341   0.0672948    0.602804   -0.0392226  -0.294418    -0.20696    -0.444049   -0.0806271   0.54113     -0.258313    -1.1612      0.0230281
  0.00839773  -0.130857    -0.422038   -0.370856   -0.13052      0.137964   -0.415799     0.290289    0.153928     -0.215828     0.159439    -0.102469     0.338109   -1.06478     0.294316   -0.510822    -0.0890702   0.455612   -0.0571197   -0.0850573  -0.215314   -0.129906   -0.0997175   -0.301934     0.688896    0.234648
  0.311799     0.116255    -0.183681    0.219086    0.0597531   -0.331256   -0.489038    -0.46036    -0.284455      0.349603    -0.0286745   -0.1936      -0.524819    0.0346269   0.679958    0.303678     1.04231     0.349088    0.141721     0.203984    0.0427331  -0.69034     0.0883923   -0.636712     0.308339    0.650625[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408426
[ Info: iteration 2, average log likelihood -1.408410
[ Info: iteration 3, average log likelihood -1.408395
[ Info: iteration 4, average log likelihood -1.408380
[ Info: iteration 5, average log likelihood -1.408366
[ Info: iteration 6, average log likelihood -1.408351
[ Info: iteration 7, average log likelihood -1.408337
[ Info: iteration 8, average log likelihood -1.408323
[ Info: iteration 9, average log likelihood -1.408310
[ Info: iteration 10, average log likelihood -1.408296
┌ Info: EM with 100000 data points 10 iterations avll -1.408296
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.533478e+05
      1       7.024166e+05      -2.509312e+05 |       32
      2       6.889050e+05      -1.351157e+04 |       32
      3       6.839553e+05      -4.949706e+03 |       32
      4       6.813971e+05      -2.558167e+03 |       32
      5       6.797353e+05      -1.661834e+03 |       32
      6       6.785999e+05      -1.135387e+03 |       32
      7       6.777676e+05      -8.322905e+02 |       32
      8       6.771153e+05      -6.523390e+02 |       32
      9       6.765815e+05      -5.337639e+02 |       32
     10       6.761455e+05      -4.360239e+02 |       32
     11       6.757674e+05      -3.780639e+02 |       32
     12       6.754346e+05      -3.328474e+02 |       32
     13       6.751711e+05      -2.635341e+02 |       32
     14       6.749490e+05      -2.220587e+02 |       32
     15       6.747519e+05      -1.971489e+02 |       32
     16       6.745766e+05      -1.752353e+02 |       32
     17       6.744193e+05      -1.573147e+02 |       32
     18       6.742739e+05      -1.453648e+02 |       32
     19       6.741225e+05      -1.514579e+02 |       32
     20       6.739626e+05      -1.598323e+02 |       32
     21       6.738121e+05      -1.505238e+02 |       32
     22       6.736672e+05      -1.448970e+02 |       32
     23       6.735299e+05      -1.373113e+02 |       32
     24       6.733900e+05      -1.398968e+02 |       32
     25       6.732725e+05      -1.174822e+02 |       32
     26       6.731610e+05      -1.114904e+02 |       32
     27       6.730619e+05      -9.913738e+01 |       32
     28       6.729773e+05      -8.459605e+01 |       32
     29       6.728965e+05      -8.085009e+01 |       32
     30       6.728171e+05      -7.938456e+01 |       32
     31       6.727427e+05      -7.441424e+01 |       32
     32       6.726697e+05      -7.298029e+01 |       32
     33       6.725946e+05      -7.503868e+01 |       32
     34       6.725174e+05      -7.724985e+01 |       32
     35       6.724500e+05      -6.737594e+01 |       32
     36       6.723871e+05      -6.293464e+01 |       32
     37       6.723325e+05      -5.461093e+01 |       32
     38       6.722835e+05      -4.893788e+01 |       32
     39       6.722414e+05      -4.213825e+01 |       32
     40       6.722004e+05      -4.098232e+01 |       32
     41       6.721621e+05      -3.832716e+01 |       32
     42       6.721258e+05      -3.627537e+01 |       32
     43       6.720923e+05      -3.349957e+01 |       32
     44       6.720634e+05      -2.894004e+01 |       32
     45       6.720347e+05      -2.862617e+01 |       32
     46       6.720058e+05      -2.898119e+01 |       32
     47       6.719785e+05      -2.730340e+01 |       32
     48       6.719452e+05      -3.326985e+01 |       32
     49       6.719089e+05      -3.629837e+01 |       32
     50       6.718825e+05      -2.640540e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 671882.4898696727)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420260
[ Info: iteration 2, average log likelihood -1.415201
[ Info: iteration 3, average log likelihood -1.413880
[ Info: iteration 4, average log likelihood -1.412929
[ Info: iteration 5, average log likelihood -1.411909
[ Info: iteration 6, average log likelihood -1.410912
[ Info: iteration 7, average log likelihood -1.410189
[ Info: iteration 8, average log likelihood -1.409775
[ Info: iteration 9, average log likelihood -1.409545
[ Info: iteration 10, average log likelihood -1.409399
[ Info: iteration 11, average log likelihood -1.409290
[ Info: iteration 12, average log likelihood -1.409201
[ Info: iteration 13, average log likelihood -1.409125
[ Info: iteration 14, average log likelihood -1.409057
[ Info: iteration 15, average log likelihood -1.408997
[ Info: iteration 16, average log likelihood -1.408941
[ Info: iteration 17, average log likelihood -1.408890
[ Info: iteration 18, average log likelihood -1.408844
[ Info: iteration 19, average log likelihood -1.408801
[ Info: iteration 20, average log likelihood -1.408761
[ Info: iteration 21, average log likelihood -1.408724
[ Info: iteration 22, average log likelihood -1.408690
[ Info: iteration 23, average log likelihood -1.408658
[ Info: iteration 24, average log likelihood -1.408628
[ Info: iteration 25, average log likelihood -1.408600
[ Info: iteration 26, average log likelihood -1.408574
[ Info: iteration 27, average log likelihood -1.408549
[ Info: iteration 28, average log likelihood -1.408526
[ Info: iteration 29, average log likelihood -1.408503
[ Info: iteration 30, average log likelihood -1.408482
[ Info: iteration 31, average log likelihood -1.408461
[ Info: iteration 32, average log likelihood -1.408442
[ Info: iteration 33, average log likelihood -1.408423
[ Info: iteration 34, average log likelihood -1.408405
[ Info: iteration 35, average log likelihood -1.408388
[ Info: iteration 36, average log likelihood -1.408371
[ Info: iteration 37, average log likelihood -1.408354
[ Info: iteration 38, average log likelihood -1.408339
[ Info: iteration 39, average log likelihood -1.408324
[ Info: iteration 40, average log likelihood -1.408309
[ Info: iteration 41, average log likelihood -1.408295
[ Info: iteration 42, average log likelihood -1.408281
[ Info: iteration 43, average log likelihood -1.408267
[ Info: iteration 44, average log likelihood -1.408254
[ Info: iteration 45, average log likelihood -1.408242
[ Info: iteration 46, average log likelihood -1.408229
[ Info: iteration 47, average log likelihood -1.408217
[ Info: iteration 48, average log likelihood -1.408206
[ Info: iteration 49, average log likelihood -1.408194
[ Info: iteration 50, average log likelihood -1.408183
┌ Info: EM with 100000 data points 50 iterations avll -1.408183
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.322015    -0.0403339    -0.173404     0.193038    -0.130189   -0.191267    0.478533   -0.0689173   0.145112      0.477322     0.755308   -0.0923142    0.212725    -0.194115    0.118285    -0.0795973    0.0702358    0.031789     0.0151049  -0.354862   -0.198115   -0.248919    -0.0324929  -0.0989146  -0.215388    0.0203615
  0.287509     0.37366      -0.559858     0.189454     0.263916    0.632216   -0.581622   -0.637714    0.407051     -0.00388423   0.0371149   0.0285557   -0.329203     0.267406    0.0835335    0.106157    -0.058591     0.196493    -0.25444    -0.114428    0.102553    0.268328     0.117753    0.108026    0.838368    0.115182
  0.195986     0.410834     -0.242782    -0.462875     0.573501    0.0121773  -0.596178    0.288452   -0.0552899    -0.165415    -0.5476     -0.641057     0.254535    -0.256287   -0.383723     0.391745    -0.0267825    0.25241      0.409202    0.409769    0.802623    0.0129095    0.267606   -0.0295619   0.575029    0.786358
  0.253799    -0.132157      0.100331    -0.749906     0.476999   -0.0589645  -0.276195   -0.183597   -0.0765125    -0.519021    -0.842971   -0.424903    -0.727371    -0.16969     0.0389454    0.211145     0.0162526   -0.345827     0.236755   -0.738478    0.105969   -0.126319     0.496753   -0.344796   -0.0123204  -0.283589
 -0.138694     0.21134       0.228385     0.0325837    0.129763    0.200621   -0.316318   -0.205253    0.0768716    -0.734371    -0.463799   -0.11885      0.15358     -0.524425   -0.261634    -0.448382    -0.427826     0.289229     0.554214   -0.102442   -0.309552    0.00517644   0.165825    0.302042   -0.0720522  -0.178423
  0.614182    -0.287844     -0.527242     0.0396486   -0.172774   -0.0519691   0.268202   -0.0660589   0.0564805     0.00281258  -0.0681979   0.765035    -0.171798    -0.321627    0.549378    -0.128135    -0.159702    -0.293684     0.346208   -0.268259   -0.910928   -0.0107246    0.752418    0.20842    -0.208621    0.00272664
  0.0315932   -0.233949      0.135371    -0.0137754   -0.0542138   0.367429    0.416559   -0.464475    0.788897      0.0142577    0.152118    0.305927    -0.569981     0.107352    0.181567    -0.41711      0.150364    -0.0360196   -0.428228    0.0277542  -0.264842   -0.0201064    0.149882   -0.0908368  -0.225467   -0.748246
  0.1404      -0.00769766    0.44983     -0.472246    -0.0549977   0.0848656  -0.39042     0.190945   -0.267891     -0.302916    -0.727335    0.397298    -0.289833     0.289344   -0.751838     0.423947    -0.18572      0.308946    -0.249349   -0.0632248   0.0859018   0.108814    -0.221271    0.492486   -0.0816167  -0.022987
  0.130108    -0.532988     -0.239134     0.498228    -0.359293   -0.248165   -0.0543265   0.048454   -0.354943     -0.0729159    0.0636396  -0.0814562    0.455598    -0.0281994   0.398246     0.153022     0.5724       0.238406     0.0976659   0.469285   -0.254488   -0.0970038   -0.0985211   0.174079   -0.0633981   0.87085
 -0.00862041  -0.313567     -0.138234    -0.281346    -0.0187929  -0.199126    0.133746    0.148332    0.0266269     0.0189246    0.398424   -0.172832    -0.112208    -0.421498    1.34221     -0.379996     0.280441    -0.560864     0.255896   -0.169266    0.427771    0.051668    -0.190945   -0.521956    0.234869   -0.0828669
  0.451259     0.0267944     0.491059    -0.123769     0.74532     0.0158899   0.587969   -0.0739664   0.466085     -0.107367     0.369609    0.448432     0.104389    -0.233476   -0.272828     0.271358    -0.376973    -0.957462     0.135764    0.045355    0.147217    0.0992326   -0.0880237   0.595935    0.141993   -0.337288
 -0.551252     0.0321829    -0.386791     0.654612    -0.911261   -0.0576608   0.691041    0.0176319   0.0968954    -0.22225      0.194405   -0.320617     0.306102     0.0745124   0.102875     0.163597    -0.576206    -0.584196     0.264252   -0.0657554  -0.132506   -0.105179    -0.397324    0.239224    0.564756   -0.270299
 -0.248653     0.297537     -0.302883     0.340697     0.199262   -0.436663    0.17023    -0.942008    0.0352706     0.172666    -0.102794   -0.238443    -0.753192     0.100354    0.523871     0.214173     0.367254     0.119138     0.372666   -0.102129    0.136486   -0.721137     0.330963   -0.250536    0.324294    0.520264
 -0.174174     0.287035      0.388583     0.235182     0.294272   -0.179687    0.0796804   0.833043   -0.255162      0.405961    -0.280369    0.290102    -0.0149857   -0.465246   -0.195922     0.257339    -0.660742    -0.530429     0.0541353  -0.0945883   0.0855726  -0.151702    -0.0131686  -0.227037   -0.195811    0.424993
 -0.434179    -0.0955534    -0.321056    -0.233906    -0.265214    0.169133   -0.661633    0.0202194  -0.20183       0.0434749   -0.534318   -0.522032    -0.0485399   -0.101133    0.300209    -0.317541     0.307285     0.796055    -0.669908   -0.262273   -0.0532422   0.062145     0.255707   -0.528827   -0.217102    0.244017
 -0.19389      0.0142405    -0.29182      0.576993     0.0774676   0.0819986   0.166176    0.284366    0.104755     -0.212265    -0.293399   -0.00782643  -0.121373    -0.0432814  -1.0692       0.444548    -0.25406      0.307861    -0.197655    0.318355   -0.867617   -0.62626      0.277314   -0.120092    0.112489   -0.003222
  0.290477    -0.119332     -0.00968104  -0.0618902    0.289914    0.100934   -0.238343    0.25001     0.0731342     0.02168      0.477075   -0.698613     0.0676743   -0.226236    0.0792617    0.0030777    0.877059    -0.670865     0.0812595  -0.487837   -0.726634   -0.733983     0.282086   -0.616377   -0.282522   -0.42399
  0.331559     0.290999     -0.339835    -0.202514    -0.638865    0.0437964   0.579606    0.645844   -0.322715      0.0362676    0.201444    0.221486     0.470912     0.504523   -0.403101     0.129924    -0.520668    -0.237676    -0.075587    0.145853    0.189352    0.497457    -0.14832     0.457781   -0.200255   -0.121931
  0.253623    -0.133159     -0.697247    -0.89347     -0.172348   -0.828227   -0.0620366  -0.254287    0.394006     -0.328818    -0.0827697  -0.0762119   -0.0815154   -0.322128   -0.309895    -0.154143    -0.19229      0.530334    -0.181987   -0.6355     -0.477552   -0.476688     0.0769033  -0.476187    1.14325     0.36085
 -0.0822464    0.141106      0.0647658   -0.0779601    0.374473    0.429622   -0.365384    0.282467    0.1974        0.021931     0.543453    0.141847     0.614096    -0.679722   -0.0827756   -0.576152    -0.0404791    0.385325    -0.0993688   0.161346    0.0147486   0.0250425   -0.448071    0.0249595   0.215487   -0.0651478
 -0.240686     0.42762       0.461124     0.0497514    0.0614943  -0.17471    -0.15076     0.0197497  -0.193364      0.487842    -0.280828   -0.135521    -0.573958     0.30335     0.291374    -0.00465565  -0.616315    -0.494842     0.396671    0.315637    0.431607    0.0828377   -0.107941    0.255114   -0.359565   -0.0787364
  0.484015    -0.0742654     0.234085    -0.963168    -0.136804   -0.198514   -0.468552    0.0476135  -0.116494      0.175922     0.196068   -0.468535     0.133379    -0.0795896   0.34884     -0.0851761    0.551024    -0.0972676    0.0876873  -0.31495     0.370211    0.477456    -0.0719846   0.24326    -0.574825   -0.140055
 -0.0845632   -0.0812174    -0.203144     0.48306     -0.207664   -0.0405296   0.249024   -0.106229   -0.0977891    -0.123878    -0.267925   -0.180444    -0.110576     0.337704   -0.111812     0.162362    -0.0878923   -0.0948625    0.0307664   0.129901   -0.147026   -0.0530052    0.124102   -0.0453368   0.0948515   0.0162616
 -0.367505    -0.36407       1.0834      -0.242828    -0.787793   -0.664473    0.0355589   0.311845   -0.318425      0.228002    -0.236144    0.237863     0.481294     0.0144192   0.0773896    0.228121     0.265326     0.193669     0.0376136  -0.384657    0.155762   -0.32245     -0.520766   -0.042024   -0.366807   -0.231701
  0.797446     0.00609556    0.63267     -0.0178595    0.286574   -0.244945   -0.480803   -0.068454   -0.32951       0.711035     0.133257    0.502315    -0.288392     0.201024    0.0891918    0.218646     0.30527      0.0598335    0.367732    0.172965    0.233431   -0.276377     0.113649   -0.214654   -0.181629    0.611678
  0.108774     0.000603433   0.0486959   -0.194072     0.0810555   0.0660724  -0.0830767   0.0508496   0.000347738   0.0407179   -0.0148972   0.0205982   -0.00132541  -0.097165   -0.00375385  -0.0661589    0.010043    -0.00726303  -0.0411569  -0.0436578   0.102304   -0.0224839   -0.0588199  -0.0131007   0.061611    0.0234096
 -0.366758     0.412162     -0.25086      0.484311    -0.511886    0.171565    0.232231   -0.587033    0.0884756     0.1201      -0.167678    0.155714    -0.103473     0.687343   -0.630537    -0.0183928   -0.528498     0.933492    -0.11387     0.630496    0.374576    0.416703    -0.46147     0.665833    0.1239      0.0890013
 -0.650816    -0.482769     -0.01083      0.594364     0.0561207   0.175032    0.684865   -0.404122   -0.514142     -0.730097    -0.362379   -0.416195    -0.191187     0.208843   -0.350706    -0.542585     0.237058    -0.325559    -0.107891   -0.567141   -0.150846   -0.143981    -0.512923   -0.295785    0.127614   -0.131486
 -0.363743     0.563734     -0.13848     -0.342067    -0.0995734   0.0840692   0.148235    0.110306   -0.0083705     0.00683368   0.289031   -0.572411     0.0120851    0.231702   -1.05778      0.285442     0.330453     0.728763    -0.287153   -0.151401   -0.193049    0.238978    -0.540876   -0.157736   -0.251191   -0.108147
  0.276741    -0.303239      0.699791     0.306746    -0.0999012   0.506719   -0.461494   -0.0911278  -0.201945     -0.370674    -0.924877    0.126205    -0.116072     0.345263    0.0754951   -0.148138     0.164899    -0.139791    -0.0240999   1.27547     0.387662    0.565715    -0.457943   -0.159084   -0.214121   -0.266079
  0.400395    -0.264768     -0.391753    -0.00412711  -0.149936    0.104372    0.442878    0.111624    0.160017      0.474197     0.128045   -0.101835     0.0974504    0.745366    0.384246     0.110356     0.424367    -0.179693    -0.37293     0.4238      0.816499    0.640494     0.0947046  -0.01718    -0.0104432   0.180984
  0.0635169    0.0186767     0.0674781   -0.113228     0.063532    0.0598178  -0.0689114   0.156627    0.0672647     0.131255     0.0392623  -0.0272698    0.0442289   -0.0808089  -0.0496494   -0.0963876   -0.00899201   0.07883     -0.131001   -0.0389541  -0.0636561   0.0772391    0.048904   -0.083835   -0.151614   -0.0363086[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408172
[ Info: iteration 2, average log likelihood -1.408162
[ Info: iteration 3, average log likelihood -1.408151
[ Info: iteration 4, average log likelihood -1.408141
[ Info: iteration 5, average log likelihood -1.408131
[ Info: iteration 6, average log likelihood -1.408121
[ Info: iteration 7, average log likelihood -1.408112
[ Info: iteration 8, average log likelihood -1.408103
[ Info: iteration 9, average log likelihood -1.408094
[ Info: iteration 10, average log likelihood -1.408085
┌ Info: EM with 100000 data points 10 iterations avll -1.408085
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
