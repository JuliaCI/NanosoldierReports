Julia Version 1.5.0-DEV.260
Commit a211abcdfa (2020-02-10 22:01 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed GaussianMixtures ─── v0.3.0
  Installed PDMats ───────────── v0.9.11
  Installed CMake ────────────── v1.1.2
  Installed Blosc ────────────── v0.5.1
  Installed JLD ──────────────── v0.9.2
  Installed Arpack ───────────── v0.4.0
  Installed QuadGK ───────────── v2.3.1
  Installed BinaryProvider ───── v0.5.8
  Installed Missings ─────────── v0.4.3
  Installed HDF5 ─────────────── v0.12.5
  Installed Arpack_jll ───────── v3.5.0+2
  Installed Rmath ────────────── v0.6.0
  Installed DataAPI ──────────── v1.1.0
  Installed LegacyStrings ────── v0.4.1
  Installed OrderedCollections ─ v1.1.0
  Installed Parameters ───────── v0.12.0
  Installed StaticArrays ─────── v0.12.1
  Installed FileIO ───────────── v1.2.2
  Installed StatsBase ────────── v0.32.0
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed URIParser ────────── v0.4.0
  Installed Compat ───────────── v2.2.0
  Installed FillArrays ───────── v0.8.4
  Installed StatsFuns ────────── v0.9.3
  Installed SpecialFunctions ─── v0.9.0
  Installed DataStructures ───── v0.17.9
  Installed Distributions ────── v0.22.4
  Installed BinDeps ──────────── v1.0.0
  Installed CMakeWrapper ─────── v0.2.3
  Installed ScikitLearnBase ──── v0.5.0
  Installed SortingAlgorithms ── v0.3.1
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed Distances ────────── v0.8.2
  Installed NearestNeighbors ─── v0.4.4
  Installed Clustering ───────── v0.13.3
#=#=#                                                                         ##O#- #                                                                       ##O=#  #                                                                      ######################################################################## 100.0%
#=#=#                                                                         ##O#- #                                                                       ##O=#  #                                                                      #=#=-#  #                                                                     #                                                                          2.7%####                                                                       6.5%#######                                                                   10.5%#############                                                             18.7%#################                                                         24.5%#################                                                         24.6%####################                                                      28.4%#########################                                                 35.4%################################                                          44.7%#########################################                                 57.4%#####################################################                     73.8%##################################################################        92.2%######################################################################## 100.0%
#=#=#                                                                         ##O#- #                                                                       ######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.2
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_esMRIL/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.2
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -4.133300497875815e6, [90627.29898398301, 9372.701016017001], [2224.3500333291136 -3802.245984455776 13500.977076244224; -2365.02792489484 3671.6661228732164 -13300.1439126033], [[90463.9511730148 399.2390747276658 -1897.2828454077871; 399.23907472766575 90198.6955965312 2859.3399635855776; -1897.2828454077871 2859.3399635855776 78606.94315566149], [9677.444627012776 -113.99108851125072 1752.9895591404734; -113.99108851125072 9774.998315269464 -2560.483318079903; 1752.9895591404731 -2560.483318079903 20633.824505540862]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.775303e+03
      1       9.445005e+02      -8.308028e+02 |        8
      2       8.822755e+02      -6.222507e+01 |        2
      3       8.559396e+02      -2.633583e+01 |        0
      4       8.559396e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 855.93963093614)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.077058
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.851903
[ Info: iteration 2, lowerbound -3.735076
[ Info: iteration 3, lowerbound -3.593933
[ Info: iteration 4, lowerbound -3.407185
[ Info: iteration 5, lowerbound -3.198676
[ Info: iteration 6, lowerbound -3.008445
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.860371
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.754657
[ Info: iteration 9, lowerbound -2.689445
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.623001
[ Info: iteration 11, lowerbound -2.544797
[ Info: iteration 12, lowerbound -2.476860
[ Info: iteration 13, lowerbound -2.418459
[ Info: iteration 14, lowerbound -2.373381
[ Info: iteration 15, lowerbound -2.339975
[ Info: iteration 16, lowerbound -2.317292
[ Info: iteration 17, lowerbound -2.307629
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.302999
[ Info: iteration 19, lowerbound -2.299262
[ Info: iteration 20, lowerbound -2.299257
[ Info: iteration 21, lowerbound -2.299255
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Wed Feb 12 01:06:54 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Wed Feb 12 01:07:02 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Wed Feb 12 01:07:04 2020: EM with 272 data points 0 iterations avll -2.077058
5.8 data points per parameter
, Wed Feb 12 01:07:06 2020: GMM converted to Variational GMM
, Wed Feb 12 01:07:15 2020: iteration 1, lowerbound -3.851903
, Wed Feb 12 01:07:15 2020: iteration 2, lowerbound -3.735076
, Wed Feb 12 01:07:15 2020: iteration 3, lowerbound -3.593933
, Wed Feb 12 01:07:15 2020: iteration 4, lowerbound -3.407185
, Wed Feb 12 01:07:15 2020: iteration 5, lowerbound -3.198676
, Wed Feb 12 01:07:15 2020: iteration 6, lowerbound -3.008445
, Wed Feb 12 01:07:15 2020: dropping number of Gaussions to 7
, Wed Feb 12 01:07:15 2020: iteration 7, lowerbound -2.860371
, Wed Feb 12 01:07:15 2020: dropping number of Gaussions to 6
, Wed Feb 12 01:07:15 2020: iteration 8, lowerbound -2.754657
, Wed Feb 12 01:07:15 2020: iteration 9, lowerbound -2.689445
, Wed Feb 12 01:07:15 2020: dropping number of Gaussions to 3
, Wed Feb 12 01:07:15 2020: iteration 10, lowerbound -2.623001
, Wed Feb 12 01:07:15 2020: iteration 11, lowerbound -2.544797
, Wed Feb 12 01:07:15 2020: iteration 12, lowerbound -2.476860
, Wed Feb 12 01:07:15 2020: iteration 13, lowerbound -2.418459
, Wed Feb 12 01:07:15 2020: iteration 14, lowerbound -2.373381
, Wed Feb 12 01:07:15 2020: iteration 15, lowerbound -2.339975
, Wed Feb 12 01:07:15 2020: iteration 16, lowerbound -2.317292
, Wed Feb 12 01:07:15 2020: iteration 17, lowerbound -2.307629
, Wed Feb 12 01:07:15 2020: dropping number of Gaussions to 2
, Wed Feb 12 01:07:15 2020: iteration 18, lowerbound -2.302999
, Wed Feb 12 01:07:15 2020: iteration 19, lowerbound -2.299262
, Wed Feb 12 01:07:15 2020: iteration 20, lowerbound -2.299257
, Wed Feb 12 01:07:15 2020: iteration 21, lowerbound -2.299255
, Wed Feb 12 01:07:15 2020: iteration 22, lowerbound -2.299254
, Wed Feb 12 01:07:15 2020: iteration 23, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 24, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 25, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 26, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 27, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 28, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 29, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 30, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 31, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 32, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 33, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 34, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 35, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 36, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 37, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 38, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 39, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 40, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 41, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 42, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 43, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 44, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 45, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 46, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 47, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 48, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 49, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: iteration 50, lowerbound -2.299253
, Wed Feb 12 01:07:15 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601402, 95.95490777398605]
β = [178.04509222601402, 95.95490777398605]
m = [4.250300733269907 79.2868669443618; 2.000229257775369 53.85198717246128]
ν = [180.04509222601402, 97.95490777398605]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484752 -0.00764404904232767; 0.0 0.008581705166333359], [0.37587636119484036 -0.008953123827346032; 0.0 0.01274866477740921]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -1.0106771456945371
avll from llpg:  -1.010677145694537
avll direct:     -1.010677145694537
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9658138222041576
avll from llpg:  -0.9658138222041576
avll direct:     -0.9658138222041577
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
 -0.0138708    0.0535139    0.0475519    0.011581    -0.144432    -0.0129467    0.0195198    0.0187998   -0.0968526   -0.183711     0.0159201   -0.264812    0.199866     0.0147392   -0.152488     -0.124234    -0.0688069   -0.0611814    -0.0663043   -0.0292151    0.0266117   -0.200672     0.0617293    0.00999033  -0.0753123   -0.138205
 -0.108874     0.121019     0.12803     -0.12894     -0.0259723   -0.0244426   -0.106181     0.0398317   -0.0177808    0.0119193    0.0220527   -0.15563    -0.0468516    0.00741902   0.00114573   -0.121666     0.0594746   -0.0480825    -0.0626237   -0.102335     0.155852     0.0796506    0.0257728   -0.00459161  -0.0617664   -0.293728
  0.0636076    0.0256622    0.063772    -0.142029     0.0173956   -0.0389426   -0.0221249   -0.134599     0.00421029   0.0774337   -0.0381497   -0.160308    0.199835    -0.0360681    0.0381688    -0.0568786    0.171708    -0.041829     -0.192077     0.0820051   -0.161562     0.0333552   -0.00657458   0.0401683    0.0375176   -0.0679339
  0.0310605   -0.19708     -0.0215133    0.164125     0.0597607   -0.029157     0.0514073    0.0370651   -0.0360537   -0.0690986    0.0919561    0.0364015   0.0147814    0.113648    -0.0158075     0.00182464  -0.045469    -0.152585     -0.0825752   -0.102764     0.0526163    0.0280168   -0.0263207   -0.00260575  -0.0168049    0.16135
 -0.0975505    0.0805376   -0.0302224   -0.0488474    0.162357     0.0774521   -0.00437411  -0.118993     0.0977936   -0.11887      0.166275    -0.0812749  -0.0809355   -0.050574     0.00128202   -0.0854659   -0.190335    -0.0505346     0.0276076    0.128103    -0.0202531   -0.00283346   0.108362     0.0946562   -0.0746473    0.0228938
 -0.040305    -0.0783301   -0.0286179   -0.0115881    0.0547854   -0.0168432   -0.0755723   -0.170534    -0.0644343    0.0343939   -0.0734878    0.0553869   0.0112103   -0.0648545   -0.0630929     0.130238    -0.192344     0.164553      0.028194     0.0866654   -0.0282428    0.148568    -0.0374792   -0.129536    -0.144031    -0.114559
 -0.088191    -0.28095     -0.101355    -0.13311     -0.226123     0.0726662   -0.110306    -0.00109964  -0.00987204  -0.0393225    0.0568553   -0.101837   -0.139856     0.062729     0.124779     -0.0584002    0.0866394   -0.0849311    -0.0321184    0.0743804   -0.247338    -0.0330332   -0.122621     0.112564    -0.111066     0.0825519
  0.0661364    0.255098     0.173939     0.0512348    0.113818    -0.0962554   -0.222309    -0.0717225   -0.0185693   -0.161586    -0.0180684   -0.0453056   0.00965279   0.115564    -5.39092e-5   -0.0737607    0.0310937   -0.182406     -0.19041      0.135533     0.0174446    0.0812732   -0.0559511   -0.0483833    0.0817009   -0.0458817
  0.108       -0.0624363   -0.0228694   -0.0685167   -0.117539    -0.0979207   -0.151777    -0.0139069   -0.144977     0.106445     0.0709079    0.052239    0.117136    -0.188298     0.175184     -0.00667589  -0.174724    -0.19971      -0.0415685   -0.0172212   -0.00141388   0.113673     0.0445465    0.0697329   -0.117173     0.0544979
 -0.0055023   -0.0826034   -0.0625668   -0.150343     0.0490729   -0.0168395   -0.0616942   -0.00473373  -0.0184836   -0.100664     0.117227     0.0998092  -0.0654793    0.133931    -0.0528531     0.0603898    0.155154    -0.122253     -0.031423     0.042241    -0.096475    -0.0220417   -0.0799384    0.105999    -0.0810929    0.0671527
  0.0655885   -0.184094     0.0931255    0.0726814   -0.302027    -0.0375758    0.0989664   -0.120332     0.106295     0.0414615   -0.0489545   -0.0328632  -0.0474605    0.30537     -0.0188033    -0.0983819    0.0351829   -0.0728899     0.196728     0.0353495   -0.126128     0.0585278   -0.0784029    0.150592    -0.00664137  -0.0159004
  0.0867506   -0.108229     0.19203     -0.0264075    0.081098     0.131754    -0.0358109    0.12348     -0.0152184    0.113362     0.159443    -0.0475065  -0.120431     0.0521213    0.0201374     0.0978605    0.198632     0.000124176   0.0740181   -0.0914444    0.048865    -0.131191     0.0645557   -0.0185755   -0.0913261   -0.00283804
 -0.185126    -0.127637    -0.0745595    0.0447435   -0.055605    -0.117474    -0.18699      0.0225245    0.0256313    0.175456    -0.0597877    0.0221389  -0.0189632    0.113802    -0.0133642    -0.242688     0.0151659   -0.219923      0.0796077   -0.0228442   -0.0210074   -0.0541506   -0.0996331    0.0376227   -0.0196159    0.0275323
  0.142027    -0.146473    -0.10549     -0.0775652   -0.0325847    0.00932492   0.0970219    0.106746     0.0874883    0.0610331    0.064502     0.101501   -0.0296279    0.123153    -0.198449     -0.00367762  -0.0520622   -0.0655278    -0.166547    -0.06155     -0.0908109   -0.191047     0.0604484    0.0617525    0.0207391   -0.0964124
 -0.190847    -0.126378    -0.0447547    0.0809704   -0.127863    -0.0121358    0.0971518    0.0137662    0.113068     0.0904942    0.0579602   -0.203172   -0.0332135    0.181929     0.0750154     0.023049     0.3348      -0.0112026     0.181027    -0.0952281    0.0207402   -0.0388296    0.00134239  -0.145726     0.055179     0.0963685
 -0.01862     -0.00275214  -0.0388494   -0.104088    -0.113789    -0.0785115   -0.131001    -0.0429033   -0.0294202   -0.184896    -0.00610901  -0.144348    0.0549424   -0.0186098    0.011794     -0.091494    -0.139339    -0.19095      -0.142267     0.168639     0.0434237    0.104097    -0.0784899   -0.0777685   -0.120743     0.0604273
  0.236493     0.0926476   -0.101218     0.00434338   0.159525    -0.208147    -0.253826    -0.0573227    0.172843     0.0179248   -0.060514    -0.0889835   0.224689     0.0111967    0.0867413     0.0315358    0.0914357    0.0585014     0.0045127   -0.0768757   -0.0571026   -0.104553    -0.156483    -0.0717273    0.042945     0.152884
  0.120094    -0.0557777   -0.0268158   -0.0578203   -0.190592    -0.0277715    0.0541777    0.0445021    0.0536397    0.04952     -0.108578     0.106398    0.0854275   -0.00502039   0.0749548     0.0101651   -0.0423025    0.0755406     0.132481     0.0226525    0.0578125    0.064299     0.0600747   -0.119874     0.184247     0.00394095
 -0.0189759    0.00619092  -0.195202     0.00204496  -0.176025     0.0181653    0.0285764   -0.0142966   -0.0184148   -0.104153     0.0557156   -0.169502    0.0791607    0.0690737    0.0575416    -0.0636668   -0.0592599    0.0700139     0.088781    -0.145585    -0.0934585   -0.0608795    0.225447     0.0250591    0.00953496  -0.00375566
 -0.141666     0.128711    -0.00740159   0.0213037   -0.0963214   -0.0303468    0.138945    -0.0819081   -0.1583       0.038403    -0.133659    -0.13977    -0.0813209    0.0405166    0.249199      0.0356124    0.106097     0.0293061    -0.0159131    0.00378389   0.051114    -0.0204661    0.0491204   -0.152238     0.0242676   -0.0267923
 -0.113       -0.162209     0.0153089    0.125672    -0.0402399   -0.0574619    0.0771871    0.1908       0.0272648    0.179182     0.126158     0.102721   -0.00262049  -0.0512077   -0.0803743     0.118938     0.04873      0.00479091   -0.245295    -0.256097    -0.0617546   -0.0387892    0.0657322   -0.130716    -0.128055     0.198433
 -0.18612     -0.0353647   -0.0377611   -0.111301    -0.166686    -0.244532    -0.081718     0.0550421    0.0309678   -0.0466784   -0.107038    -0.210173   -0.239445     0.196128     0.103759      0.00186825   0.15192     -0.112073     -0.00377757  -0.0551313    0.0263987   -0.153606    -0.144629     0.100395    -0.0731025    0.0707564
 -0.103736     0.0635638    0.0690733   -0.0072925    0.0279642    0.118123    -0.0546896    0.0275977    0.161684     0.0330806   -0.16319      0.0560172  -0.116797    -0.0376262   -0.0558892    -0.0576344    0.0932434    0.193873     -0.0491249   -0.0343477   -0.0134166   -0.0919903   -0.187222    -0.157262    -0.133355     0.0421859
 -6.77231e-5   0.213213    -0.0974632    0.0253212   -0.0556918    0.0573902   -0.0190853   -0.167802    -0.123348     0.00201969  -0.092109    -0.104459    0.0319527   -0.11898     -0.104222     -0.0342002   -0.0725494   -0.00795793    0.106633    -0.0531274    0.0363923   -0.0650877   -0.0893456    0.0289268    0.143343    -0.125257
  0.0897446   -0.0243496   -0.0738647    0.068624    -0.0176096    0.0442398   -0.220184     0.0644453   -0.210287    -0.115597     0.0465753   -0.124067    0.0525601   -0.0352443   -0.0695478     0.0613032    0.0811538    0.0164963    -0.00911265  -0.0263007    0.0630605   -0.0500209   -0.062189     0.0436952    0.104076     0.209777
  0.0637315    0.00129355   0.0250858   -0.0401958   -0.0226076   -0.231747    -0.092783    -0.0227017   -0.0350009    0.0869751   -0.0329784    0.150829   -0.0479234   -0.0500122   -0.204166     -0.14303     -0.069808     0.170422     -0.174966     0.151655    -0.0416129    0.0806964    0.091427    -0.00792282  -0.0774687   -0.00826133
  0.098381     0.0869802   -0.0674731    0.0258224    0.0966478   -0.13294      0.234111     0.184055    -0.166703     0.0908187    0.135021     0.0951595  -0.106271     0.0405558   -0.0143655     0.139092     0.0105124   -0.0500682    -0.103488     0.0780381    0.139647    -0.0955481    0.089065    -0.0235842    0.0584927   -0.0286982
  0.0663993    0.121436     0.0145018    0.065322     0.0960051   -0.00621777   0.0675882    0.0621203   -0.0566051    0.0709383   -0.018298    -0.154793   -0.0591029   -0.0914321    0.000952014   0.149861     0.00644969   0.00634225    0.0298546    0.0366584   -0.122681     0.0374431    0.0624602   -0.0529159   -0.0145835    0.0642815
 -0.183296    -0.0092165    0.10932      0.0216294    0.249697    -0.0596582   -0.056817     0.0673056    0.0114333    0.123137    -0.135014     0.0815731   0.042603    -0.161582     0.24565      -0.0788105    0.0643048    0.0152349    -0.0034651    0.124957     0.112191     0.10807     -0.0998299    0.119747    -0.0160348   -0.157312
  0.0400983    0.111039     0.0351983   -0.0769338   -0.039298    -0.0688848   -0.111482     0.0260629    0.0746806   -0.0465999   -0.140999     0.0391306  -0.0335765   -0.0497544   -0.0134443     0.111112     0.0743881    0.00227076   -0.172945    -0.00848392  -0.0276099    0.0981974    0.0331164    0.0974792   -0.0774806    0.0806203
  0.0648636   -0.0274246    0.190372     0.0335906   -0.00710353   0.141881    -0.180138    -0.0132795    0.0692242   -0.0210914   -0.208851    -0.0480554  -0.10018     -0.159583     0.0137163    -0.0607532   -0.00525338  -0.143407     -0.0112571   -0.0728398   -0.0244709   -0.120287     0.0907731    0.099853     0.00432459  -0.146941
 -0.0802929   -0.249682    -0.0953487   -0.0401396    0.0315662    0.198563     0.0783367   -0.0559923    0.0404532    0.0278157   -0.0364047   -0.115915   -0.21806     -0.129458    -0.0617566     0.132819     0.110999    -0.17434       0.0911176   -0.143484     0.108502     0.134549     0.0356849   -0.0124108    0.0347481   -0.0541232kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.412512790171455
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412601
[ Info: iteration 2, average log likelihood -1.412519
[ Info: iteration 3, average log likelihood -1.411611
[ Info: iteration 4, average log likelihood -1.400923
[ Info: iteration 5, average log likelihood -1.377872
[ Info: iteration 6, average log likelihood -1.370688
[ Info: iteration 7, average log likelihood -1.369145
[ Info: iteration 8, average log likelihood -1.368209
[ Info: iteration 9, average log likelihood -1.367302
[ Info: iteration 10, average log likelihood -1.366361
[ Info: iteration 11, average log likelihood -1.365734
[ Info: iteration 12, average log likelihood -1.365388
[ Info: iteration 13, average log likelihood -1.365155
[ Info: iteration 14, average log likelihood -1.364963
[ Info: iteration 15, average log likelihood -1.364784
[ Info: iteration 16, average log likelihood -1.364614
[ Info: iteration 17, average log likelihood -1.364435
[ Info: iteration 18, average log likelihood -1.364238
[ Info: iteration 19, average log likelihood -1.364045
[ Info: iteration 20, average log likelihood -1.363868
[ Info: iteration 21, average log likelihood -1.363708
[ Info: iteration 22, average log likelihood -1.363564
[ Info: iteration 23, average log likelihood -1.363433
[ Info: iteration 24, average log likelihood -1.363315
[ Info: iteration 25, average log likelihood -1.363208
[ Info: iteration 26, average log likelihood -1.363111
[ Info: iteration 27, average log likelihood -1.363025
[ Info: iteration 28, average log likelihood -1.362949
[ Info: iteration 29, average log likelihood -1.362880
[ Info: iteration 30, average log likelihood -1.362822
[ Info: iteration 31, average log likelihood -1.362775
[ Info: iteration 32, average log likelihood -1.362740
[ Info: iteration 33, average log likelihood -1.362714
[ Info: iteration 34, average log likelihood -1.362695
[ Info: iteration 35, average log likelihood -1.362682
[ Info: iteration 36, average log likelihood -1.362673
[ Info: iteration 37, average log likelihood -1.362666
[ Info: iteration 38, average log likelihood -1.362662
[ Info: iteration 39, average log likelihood -1.362659
[ Info: iteration 40, average log likelihood -1.362657
[ Info: iteration 41, average log likelihood -1.362655
[ Info: iteration 42, average log likelihood -1.362654
[ Info: iteration 43, average log likelihood -1.362652
[ Info: iteration 44, average log likelihood -1.362650
[ Info: iteration 45, average log likelihood -1.362649
[ Info: iteration 46, average log likelihood -1.362646
[ Info: iteration 47, average log likelihood -1.362644
[ Info: iteration 48, average log likelihood -1.362641
[ Info: iteration 49, average log likelihood -1.362637
[ Info: iteration 50, average log likelihood -1.362633
┌ Info: EM with 100000 data points 50 iterations avll -1.362633
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4126013112878564
│     -1.4125190570957304
│      ⋮
└     -1.3626332376922212
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.362754
[ Info: iteration 2, average log likelihood -1.362616
[ Info: iteration 3, average log likelihood -1.361813
[ Info: iteration 4, average log likelihood -1.354434
[ Info: iteration 5, average log likelihood -1.334065
[ Info: iteration 6, average log likelihood -1.321441
[ Info: iteration 7, average log likelihood -1.318205
[ Info: iteration 8, average log likelihood -1.316715
[ Info: iteration 9, average log likelihood -1.315738
[ Info: iteration 10, average log likelihood -1.314984
[ Info: iteration 11, average log likelihood -1.314355
[ Info: iteration 12, average log likelihood -1.313823
[ Info: iteration 13, average log likelihood -1.313357
[ Info: iteration 14, average log likelihood -1.312934
[ Info: iteration 15, average log likelihood -1.312527
[ Info: iteration 16, average log likelihood -1.312103
[ Info: iteration 17, average log likelihood -1.311620
[ Info: iteration 18, average log likelihood -1.311032
[ Info: iteration 19, average log likelihood -1.310347
[ Info: iteration 20, average log likelihood -1.309649
[ Info: iteration 21, average log likelihood -1.308979
[ Info: iteration 22, average log likelihood -1.308273
[ Info: iteration 23, average log likelihood -1.307448
[ Info: iteration 24, average log likelihood -1.306493
[ Info: iteration 25, average log likelihood -1.305621
[ Info: iteration 26, average log likelihood -1.305145
[ Info: iteration 27, average log likelihood -1.304952
[ Info: iteration 28, average log likelihood -1.304875
[ Info: iteration 29, average log likelihood -1.304839
[ Info: iteration 30, average log likelihood -1.304819
[ Info: iteration 31, average log likelihood -1.304806
[ Info: iteration 32, average log likelihood -1.304797
[ Info: iteration 33, average log likelihood -1.304791
[ Info: iteration 34, average log likelihood -1.304787
[ Info: iteration 35, average log likelihood -1.304783
[ Info: iteration 36, average log likelihood -1.304781
[ Info: iteration 37, average log likelihood -1.304779
[ Info: iteration 38, average log likelihood -1.304778
[ Info: iteration 39, average log likelihood -1.304776
[ Info: iteration 40, average log likelihood -1.304775
[ Info: iteration 41, average log likelihood -1.304775
[ Info: iteration 42, average log likelihood -1.304774
[ Info: iteration 43, average log likelihood -1.304774
[ Info: iteration 44, average log likelihood -1.304773
[ Info: iteration 45, average log likelihood -1.304773
[ Info: iteration 46, average log likelihood -1.304773
[ Info: iteration 47, average log likelihood -1.304772
[ Info: iteration 48, average log likelihood -1.304772
[ Info: iteration 49, average log likelihood -1.304772
[ Info: iteration 50, average log likelihood -1.304772
┌ Info: EM with 100000 data points 50 iterations avll -1.304772
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3627543678485998
│     -1.3626163340322364
│      ⋮
└     -1.3047719057206137
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.304937
[ Info: iteration 2, average log likelihood -1.304758
[ Info: iteration 3, average log likelihood -1.303807
[ Info: iteration 4, average log likelihood -1.294207
[ Info: iteration 5, average log likelihood -1.269712
[ Info: iteration 6, average log likelihood -1.252845
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.245331
[ Info: iteration 8, average log likelihood -1.255249
[ Info: iteration 9, average log likelihood -1.248764
[ Info: iteration 10, average log likelihood -1.245117
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.241823
[ Info: iteration 12, average log likelihood -1.253362
[ Info: iteration 13, average log likelihood -1.247620
[ Info: iteration 14, average log likelihood -1.244361
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.241273
[ Info: iteration 16, average log likelihood -1.252942
[ Info: iteration 17, average log likelihood -1.247224
[ Info: iteration 18, average log likelihood -1.243890
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.240637
[ Info: iteration 20, average log likelihood -1.252138
[ Info: iteration 21, average log likelihood -1.245996
[ Info: iteration 22, average log likelihood -1.242008
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.237913
[ Info: iteration 24, average log likelihood -1.248583
[ Info: iteration 25, average log likelihood -1.241824
[ Info: iteration 26, average log likelihood -1.238065
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.234938
[ Info: iteration 28, average log likelihood -1.246942
[ Info: iteration 29, average log likelihood -1.241252
[ Info: iteration 30, average log likelihood -1.237944
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.234902
[ Info: iteration 32, average log likelihood -1.246921
[ Info: iteration 33, average log likelihood -1.241228
[ Info: iteration 34, average log likelihood -1.237927
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.234893
[ Info: iteration 36, average log likelihood -1.246911
[ Info: iteration 37, average log likelihood -1.241214
[ Info: iteration 38, average log likelihood -1.237918
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.234889
[ Info: iteration 40, average log likelihood -1.246904
[ Info: iteration 41, average log likelihood -1.241206
[ Info: iteration 42, average log likelihood -1.237911
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.234886
[ Info: iteration 44, average log likelihood -1.246899
[ Info: iteration 45, average log likelihood -1.241200
[ Info: iteration 46, average log likelihood -1.237907
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.234883
[ Info: iteration 48, average log likelihood -1.246896
[ Info: iteration 49, average log likelihood -1.241196
[ Info: iteration 50, average log likelihood -1.237903
┌ Info: EM with 100000 data points 50 iterations avll -1.237903
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3049365494441625
│     -1.3047582045217392
│      ⋮
└     -1.2379031970957355
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.235106
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.234830
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.232853
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.214136
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.187456
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.168807
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.170968
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.155912
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.161510
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.150536
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.159376
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.159701
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.157012
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.145375
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.166067
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.156338
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.151925
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.151693
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.162344
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.150960
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.158250
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.148089
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.157594
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.157920
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.155316
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.143592
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.164742
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.155076
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.150907
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.150722
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.161929
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.150705
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.158064
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.147899
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.157542
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.157842
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.155249
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.143508
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.164699
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.155025
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.150865
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.150650
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.161896
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.150664
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.158027
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.147835
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.157517
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.157804
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.155218
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.143452
┌ Info: EM with 100000 data points 50 iterations avll -1.143452
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2351058617124926
│     -1.2348298776159492
│      ⋮
└     -1.1434518844532953
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.164955
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     19
│     20
│     21
│     22
│     23
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.154897
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.148608
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     17
│     18
│     19
│     20
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.124988
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      7
│      8
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.089444
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│     13
│     19
│     20
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.078640
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│     12
│     21
│     22
│     23
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.083560
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.066427
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│     13
│     21
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.071937
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│     19
│     20
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.089530
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     12
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.071190
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│     13
│     18
│     19
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.065040
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      6
│     17
│     19
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.084613
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      7
│      8
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.072035
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│     12
│     13
│     19
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.064413
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      6
│      9
│     17
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.074626
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      7
│      8
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.069054
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│     12
│     13
│     19
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.049216
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      6
│     17
│     20
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.073581
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.048420
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│     12
│     13
│     19
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.062324
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      6
│     17
│     20
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.071602
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      7
│      8
│     19
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.053577
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      9
│     12
│     13
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.045926
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      6
│     17
│     19
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.083638
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      7
│      8
│     20
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.056468
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│     12
│     13
│     19
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.050514
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      6
│      9
│     17
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.066093
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      7
│      8
│     19
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.066790
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│     12
│     13
│     19
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.051752
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      6
│     17
│     20
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.068478
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.052399
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│     12
│     13
│     19
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.060470
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      6
│     17
│     19
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.074190
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      7
│      8
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.057164
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      9
│     12
│     13
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.044254
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      6
│     17
│     20
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.084992
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      7
│      8
│     19
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.053738
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│     12
│     13
│     19
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.050493
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      6
│      9
│     17
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.067432
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      7
│      8
│     20
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.066167
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│     12
│     13
│     19
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.051847
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      6
│     17
│     21
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.072671
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.046878
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│     12
│     13
│     19
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.061737
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      6
│     17
│     20
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.067203
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      7
│      8
│      9
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.054450
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│     12
│     13
│     20
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.042789
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      6
│     17
│     19
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.051198
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      7
│      8
│      9
│      ⋮
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.024823
┌ Info: EM with 100000 data points 50 iterations avll -1.024823
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1649550909608877
│     -1.1548969779699512
│      ⋮
└     -1.0248231363307585
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.412512790171455
│     -1.4126013112878564
│     -1.4125190570957304
│     -1.411610529823559
│      ⋮
│     -1.0427892384757076
│     -1.051197777993003
└     -1.0248231363307585
32×26 Array{Float64,2}:
 -0.0242269   -0.106811    -0.0622643   -0.12564      0.0507316   -0.0154561   -0.0675493   -0.0309357   -0.0165469   -0.114777     0.0816445     0.10126     -0.070252      0.129988    -0.0465083     0.0565998     0.159738    -0.119357    -0.0576991    0.0361549   -0.0884583   -0.034603    -0.0795366    0.105002    -0.0695931    0.0651377
 -0.0971448   -0.284968    -0.0952313   -0.157652    -0.220762     0.0729982   -0.147876    -0.0518488    0.00270637  -0.0456528    0.0515104    -0.122394    -0.11327       0.0687896    0.12187      -0.0531591     0.094335    -0.0843265   -0.0291347    0.0760541   -0.245346    -0.0353149   -0.121649     0.136718    -0.129906     0.0869317
 -0.165171     0.0488651    0.0626154   -0.0968844   -0.0660383   -0.131474    -0.0799158    0.0439332    0.00703151  -0.00826855  -0.0365466    -0.166987    -0.128372      0.091157     0.0557031    -0.041294      0.0882272   -0.0767265   -0.0321275   -0.0722994    0.0870518   -0.029595    -0.0619097    0.0433441   -0.0415613   -0.113761
  0.0687533   -0.117626     0.0216705    0.042135    -0.239374    -0.0375847    0.0776591   -0.0304756    0.0832299    0.0348798   -0.076795      0.0369163    0.0129989     0.151786     0.0319328    -0.0403295     0.0333874    0.00333295   0.183944     0.0277359   -0.026893     0.047098    -0.0132001    0.0065015    0.0790734   -0.00125972
 -0.0216026    0.0540913    0.0252532    0.0120842   -0.147538    -0.0116246   -0.0512346   -0.00495397  -0.0785573   -0.182608     0.0127113    -0.248578     0.189616     -0.00887913  -0.14116      -0.124846     -0.0394503   -0.0567215   -0.0636676   -0.029732     0.0231513   -0.205418     0.0592285    0.0252896   -0.064956    -0.135736
  0.0697617    0.104877     0.0203421    0.0327897    0.0968501   -0.00507186   0.0790066    0.0430665   -0.0626827    0.0686967   -0.024949     -0.181391    -0.0696863    -0.0700516   -0.0402105     0.137541      0.0410432   -0.00213725   0.0659333    0.0310287   -0.075964     0.0163968    0.0541424   -0.0450832   -0.00768462   0.0864778
  0.141796    -0.150015    -0.103588    -0.038009    -0.032197     0.0110255    0.100509     0.110224     0.0902836    0.0703979    0.0659141     0.154421    -0.0345947     0.107829    -0.198501     -0.00338834   -0.0735739   -0.0287255   -0.139612    -0.0567706   -0.0933401   -0.189813     0.0590843    0.0589399    0.00544544  -0.0996025
  0.0346373   -0.206637    -0.0359299    0.181954     0.0746319   -0.0253812    0.0781149    0.0312792   -0.0352429   -0.0603989    0.0904957     0.0359376    0.000929021   0.124539    -0.025645      0.00111833   -0.0447906   -0.147189    -0.0838321   -0.104503     0.0595412    0.0163448   -0.0231262   -0.00185892  -0.046124     0.147306
  0.0586185    0.026547     0.0609822   -0.163799    -0.00255817   0.0250653   -0.0202647   -0.133331     0.0287387    0.0863052   -0.0118804    -0.153098     0.213457     -0.0213985    0.0275431    -0.0559646     0.170015    -0.0416632   -0.191311     0.0767063   -0.168916     0.0293044   -0.0502841    0.0345986    0.0784437   -0.066125
  0.162       -0.00889519  -0.0569536   -0.0386863    0.0145962   -0.160532    -0.175331    -0.0342823    0.014692     0.0658368   -0.000662036  -0.026454     0.160382     -0.0935031    0.132037      0.049934     -0.0250613   -0.0673121   -0.0243066   -0.0445874   -0.0233252    0.00236468  -0.0433309    0.00628827  -0.0324682    0.103584
 -0.0938699    0.0389076   -0.0911522    0.0173756   -0.135209     0.00372856   0.0874382   -0.0216609   -0.0649048   -0.0132145   -0.0216942    -0.161802     0.0140994     0.061803     0.122188     -0.00424328    0.0722579    0.0427219    0.0634285   -0.057978    -0.0350743   -0.0502516    0.112649    -0.0804273    0.0263614   -0.00436016
  0.0477097    0.247383     0.160524     0.0981396    0.0675348   -0.163803    -0.208153    -0.0542035   -0.0200031   -0.161342     0.00287924   -0.0454381    0.0115258     0.113701    -0.05177      -0.088232      0.0177466   -0.165885    -0.189036     0.0737728    0.014901     0.0772326   -0.0442459   -0.04332      0.0729007   -0.0441289
 -0.0461885   -0.0892225   -0.0293324   -0.0349759    0.0635057   -0.0272256   -0.0512365   -0.154199    -0.0633076    0.0365139   -0.0750338     0.0461614    0.000942461  -0.0772898   -0.0353225     0.110008     -0.18964      0.140438     0.00685863   0.0826401   -0.0321251    0.144647    -0.0227877   -0.100161    -0.138125    -0.117447
 -0.073897    -0.262437    -0.0917348   -0.0366768    0.0337911    0.173645     0.0740638   -0.0643066    0.0493001    0.010232    -0.0218244    -0.110423    -0.220288     -0.170738    -0.0533314     0.125317      0.110706    -0.190401     0.093469    -0.143055     0.107734     0.124968     0.0356194    0.017906     0.0367371   -0.0743605
 -0.00538309   0.0121537   -0.0542112   -0.104132    -0.160071    -0.0837663   -0.106625    -0.00767051  -0.0359341   -0.14256     -0.000983913  -0.143257     0.104825     -0.00917591  -0.0234284    -0.102807     -0.123639    -0.212751    -0.157837     0.14283      0.0717289    0.107957    -0.128027    -0.080186    -0.121499     0.06628
  0.0934328    0.148829    -0.0351451    0.0604691    0.0903977   -0.132566     0.233558     0.161567    -0.170228     0.0954238    0.137805      0.116413    -0.0723884     0.0201906   -0.0244208     0.16722      -0.0223467   -0.0536815   -0.0780254    0.0498631    0.140302    -0.0961222    0.113279    -0.0224269    0.0577027   -0.0157353
  0.0722258   -0.019748     0.216717     0.0187471   -0.0130651    0.138642    -0.199646    -0.00161646   0.0610814   -0.015488    -0.221184     -0.0695882   -0.101477     -0.154907     0.0179829    -0.0676484     0.00671361  -0.154514    -0.0501374   -0.0787479   -0.0256596   -0.118691     0.093728     0.102702     0.0184977   -0.14418
  0.0899719   -0.101268     0.167846    -0.0281558    0.116963     0.125897    -0.0332766    0.120385     0.0175204    0.120988     0.141915     -0.0474389   -0.118949      0.051405     0.0262517     0.0388713     0.200016     0.013787     0.0836072   -0.112505     0.0161385   -0.130445     0.0650996   -0.03222     -0.0971548   -0.00267466
 -0.0120475   -0.115025    -0.123001     0.0128213   -0.0910112    0.142388     0.012513    -0.033521     0.0286294    0.0124286   -0.109478     -0.0744571   -0.0298942    -0.0524931   -0.0439665     0.000978539  -0.074597     0.00327194   0.164995    -0.162038     0.0293715   -0.185513    -0.0131292   -0.0136796    0.00614208  -0.156568
  0.00465225   0.273981    -0.0960366    0.0257906   -0.0517105    0.0565804   -0.00942711  -0.183292    -0.153551    -0.0175502   -0.0926614    -0.0969652    0.0318904    -0.122019    -0.10191      -0.0303134    -0.0731182   -0.008857     0.105357    -0.0174747    0.0698548   -0.095661    -0.0989469    0.030148     0.127643    -0.11168
  0.0863521   -0.162003     0.0453792    0.0947509    0.576628     0.0053271    0.0639425    0.202521     0.0124263    0.21424      0.105145      0.103188    -0.00284911   -0.0358447   -0.0289605     0.122096      0.0673991   -0.00436631  -0.245994    -0.702578    -0.228075    -0.032551     0.111457    -0.0836854   -0.159025    -0.68269
 -0.222827    -0.161994    -0.00720576   0.105333     0.0201228    0.104278    -0.227392     0.270249     0.0380426    0.207802     0.0982466     0.10012     -1.36121e-5    0.0233542    0.000452789   0.114199      0.0477981   -0.00999487  -0.245308     0.0174586    0.299429    -0.0247471    0.0371491   -0.0682155   -0.0371099    0.418642
 -0.278321    -0.162082    -0.00782724   0.127228    -0.134438    -0.161435    -0.030009     0.124609     0.0484879    0.0960954    0.180745      0.100452    -0.00640521   -0.143158    -0.183062      0.123582      0.04203      0.0136805   -0.245336     0.103331    -0.291353    -0.0501978    0.0784596   -0.257018    -0.0720978   -0.491097
 -0.0234818   -0.162022     0.0234894    0.145952    -0.590091    -0.20466      0.437342     0.15755      0.0209521    0.168649     0.124869      0.107711    -0.0093703    -0.0679432   -0.147318      0.128064      0.0386173    0.0427087   -0.244967    -0.543329    -0.143718    -0.0324846   -0.0123282   -0.0838905   -0.138617     1.18084
 -0.191158    -0.00860129   0.108235     0.0201685    0.24685     -0.080961    -0.218278     0.0378399    0.0100533    0.127825    -0.632459      0.131373     0.0598361    -0.130477     0.256167     -0.080228      0.0569937   -0.0137139   -0.0512444    0.110644    -0.591856     0.148249    -0.123656     0.11697     -0.348842    -0.142839
 -0.175225    -0.00324174   0.105853     0.0210424    0.247615    -0.045948     0.0519684    0.0897021    0.0369042    0.109273     0.379066      0.124423     0.0343984    -0.214119     0.232257     -0.0761685     0.0582641   -0.0176609    0.0926428    0.131053     0.757001     0.078029    -0.00292169   0.121157     0.275266    -0.220776
 -0.290628     0.0862483   -0.183435    -0.0481701    0.164414     0.0721223   -0.0458995   -0.124282     0.121695    -0.0767394    0.167473      0.130375    -0.0927406    -0.160255    -0.00362657    0.182155      0.0333082   -0.039775     0.0214576    0.137043    -0.016411    -0.0100226    0.100813     0.0928671   -0.0738214    0.0783463
  0.0654977    0.0752305    0.0128471   -0.0482088    0.15959      0.0778395    0.0467792   -0.118572     0.0903202   -0.150655     0.167526     -0.198635    -0.0768878    -0.0184182   -0.00875463   -0.278763     -0.232683    -0.0572485    0.0365456    0.175474    -0.0154264   -0.0198861    0.126335     0.0954647   -0.074057     0.0118909
  0.0501444    0.0357631   -0.0242557    0.00101052  -0.0395731   -0.0139485   -0.14996      0.0242503   -0.0566911   -0.0783564   -0.0483914    -0.0449739    0.0215813    -0.0359401   -0.035553      0.0928285     0.0891026    0.0113798   -0.0849787   -0.010363     0.00263601   0.0203729   -0.0085636    0.0825792    0.0176053    0.155124
  0.0305792   -0.0694574    0.0322627   -0.0238596   -0.0200257   -0.233905    -0.0830899   -0.0200517    0.0558456    0.0838087   -0.0149819     0.109185    -0.0347074    -0.01972     -0.169934     -0.142651     -0.0510972    0.170539    -0.145021     0.107779    -0.0303534    0.0523359    0.0798817   -0.0423123   -0.0545409    0.0272101
 -0.100105     0.0864337    0.074277     0.01312      0.0630601    0.125194    -0.0538956    0.0275009    0.164055     0.0379474   -0.150839      0.109218    -0.13641      -0.0378366   -0.0479542    -0.0582593     0.0952007    0.217501    -0.0481924   -0.0238694   -0.0212704   -0.0900822   -0.202767    -0.171875    -0.127154     0.0393499
 -0.15517     -0.142307    -0.101444     0.0486989   -0.0874888   -0.112224    -0.185818     0.0367181    0.060976     0.177109    -0.0469794     0.00691096  -0.0302498     0.0581727   -0.0157536    -0.244385      0.0168034   -0.208882     0.084331     0.00822464   0.0318692   -0.0541716   -0.0899304    0.0169904   -0.0206154    0.0324204[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│     13
│     20
│     21
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.046196
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      6
│     13
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.014594
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      7
│      8
│     12
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.009799
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      6
│      9
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.016622
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      6
│     12
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.029511
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.011414
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      9
│     12
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.018311
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      6
│     13
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.029698
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.007137
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      9
│     13
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.022618
┌ Info: EM with 100000 data points 10 iterations avll -1.022618
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.485448e+05
      1       6.834738e+05      -1.650710e+05 |       32
      2       6.579920e+05      -2.548171e+04 |       32
      3       6.427021e+05      -1.528995e+04 |       32
      4       6.320174e+05      -1.068468e+04 |       32
      5       6.250929e+05      -6.924562e+03 |       32
      6       6.202805e+05      -4.812321e+03 |       32
      7       6.162728e+05      -4.007724e+03 |       32
      8       6.131173e+05      -3.155545e+03 |       32
      9       6.114590e+05      -1.658303e+03 |       32
     10       6.104290e+05      -1.029981e+03 |       32
     11       6.092658e+05      -1.163168e+03 |       32
     12       6.076791e+05      -1.586685e+03 |       32
     13       6.065400e+05      -1.139083e+03 |       32
     14       6.057556e+05      -7.844730e+02 |       32
     15       6.051582e+05      -5.974024e+02 |       32
     16       6.047345e+05      -4.236647e+02 |       32
     17       6.043789e+05      -3.556313e+02 |       32
     18       6.041123e+05      -2.666082e+02 |       32
     19       6.038910e+05      -2.213036e+02 |       32
     20       6.037139e+05      -1.770216e+02 |       32
     21       6.035832e+05      -1.307163e+02 |       32
     22       6.034769e+05      -1.063386e+02 |       31
     23       6.033952e+05      -8.170668e+01 |       32
     24       6.033397e+05      -5.546932e+01 |       32
     25       6.032968e+05      -4.286842e+01 |       31
     26       6.032758e+05      -2.099634e+01 |       29
     27       6.032650e+05      -1.082038e+01 |       30
     28       6.032569e+05      -8.157249e+00 |       29
     29       6.032521e+05      -4.790100e+00 |       25
     30       6.032474e+05      -4.677349e+00 |       23
     31       6.032439e+05      -3.470498e+00 |       20
     32       6.032416e+05      -2.366221e+00 |       18
     33       6.032394e+05      -2.192702e+00 |       20
     34       6.032378e+05      -1.620610e+00 |        9
     35       6.032369e+05      -8.279023e-01 |       14
     36       6.032362e+05      -7.217347e-01 |        8
     37       6.032354e+05      -7.520619e-01 |       13
     38       6.032345e+05      -9.502374e-01 |        7
     39       6.032341e+05      -3.748519e-01 |        7
     40       6.032329e+05      -1.236180e+00 |       12
     41       6.032300e+05      -2.918400e+00 |       16
     42       6.032264e+05      -3.587457e+00 |       19
     43       6.032228e+05      -3.599134e+00 |       22
     44       6.032198e+05      -2.991857e+00 |       15
     45       6.032179e+05      -1.893540e+00 |       14
     46       6.032171e+05      -8.296832e-01 |       12
     47       6.032162e+05      -8.649140e-01 |       11
     48       6.032157e+05      -5.375150e-01 |       11
     49       6.032152e+05      -4.445146e-01 |       10
     50       6.032149e+05      -2.991463e-01 |        9
K-means terminated without convergence after 50 iterations (objv = 603214.9213308945)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.308717
[ Info: iteration 2, average log likelihood -1.273414
[ Info: iteration 3, average log likelihood -1.235419
[ Info: iteration 4, average log likelihood -1.191332
[ Info: iteration 5, average log likelihood -1.145482
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      8
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.078009
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     13
│     16
│     17
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.075163
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      9
│     10
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.085616
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.089102
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.061535
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     16
│     17
│     18
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.044688
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     10
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.061551
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.076796
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     19
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.049121
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     13
│     16
│     17
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.033882
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      9
│     10
│     18
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.052905
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     21
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.071131
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.045860
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     13
│     16
│     19
│     23
│     25
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.008238
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      9
│     17
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.069391
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     18
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.057279
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     21
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.055379
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      8
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.043304
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      9
│     13
│     16
│     20
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.033513
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     17
│     19
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.048370
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     10
│     18
│     21
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.039980
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.086105
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      9
│     16
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.021988
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      8
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.034654
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     21
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.048809
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.056737
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      9
│     16
│     18
│     20
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.011461
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      8
│     13
│     17
│     21
│     24
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.059046
[ Info: iteration 34, average log likelihood -1.104574
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│     10
│     19
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.018320
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│      9
│     20
│     23
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.021873
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.089361
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.055277
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     10
│     17
│     23
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.009116
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      8
│      9
│     16
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.033077
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     19
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.078010
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.076322
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     10
│     18
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.011308
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      8
│      9
│     13
│     16
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.025708
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.101629
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.050592
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     10
│     23
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.018147
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      8
│      9
│     13
│     17
│     18
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.029005
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     16
│     21
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.085697
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.053590
┌ Info: EM with 100000 data points 50 iterations avll -1.053590
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0551103   -0.033873    -0.0310017   -0.0100037   -0.0988064   0.000589565   0.0223517    0.0534731    0.000505079  -0.0697293   0.0302056   -0.0592152    0.0869169     0.0431052   -0.154436    -0.0656706   -0.0570193   -0.0449705   -0.108832    -0.0369678    -0.0263776   -0.198481    0.0599994    0.0402241   -0.0399639   -0.118357
  0.072312    -0.00644089  -0.16895     -0.0320979   -0.160921   -0.0144927    -0.0127951   -0.00783224  -0.0681535    -0.0218466   0.0718296   -0.0990122    0.104023      0.0260755    0.0977935   -0.0592896   -0.0533824    0.00286378   0.0437451   -0.102169     -0.0836657   -0.0249734   0.228432     0.0291275   -0.0373626    0.0192124
 -0.040665    -0.0911266   -0.0243333   -0.0354588    0.074561   -0.0257255    -0.059285    -0.153523    -0.0628627     0.0337201  -0.0825747    0.0501692   -0.000411286  -0.0892342   -0.0453198    0.100413    -0.185539     0.139345     0.00880583   0.0786594    -0.0296079    0.145907   -0.0201219   -0.0952786   -0.135112    -0.125823
  0.0344412   -0.206692    -0.0370594    0.184501     0.0762444  -0.025753      0.0814765    0.0312668   -0.035575     -0.0592371   0.0908081    0.0365467    0.00341333    0.124147    -0.0244061    0.00120288  -0.04534     -0.146072    -0.0844099   -0.105017      0.059866     0.0173161  -0.0231198   -0.0029791   -0.0411988    0.147844
 -0.147027    -0.135511    -0.0932245    0.0502523   -0.0847558  -0.104469     -0.185334     0.0335913    0.056012      0.176555   -0.0473702    0.00782934  -0.0303423     0.0488471   -0.0157864   -0.240913     0.015656    -0.204021     0.0853565    0.00973089    0.0298775   -0.056091   -0.0839844    0.019862    -0.0169919    0.0170565
  0.0564028    0.0582815   -0.0163244   -0.0156205   -0.0354096  -0.0342083    -0.154205     0.0150324   -0.0501441    -0.0697465  -0.0727208   -0.0201347    0.0149242    -0.046871    -0.0334822    0.0913804    0.0632856    0.0134254   -0.114275    -0.000884789  -0.0105146    0.0471306   0.0105167    0.0955921    0.00155001   0.148555
  0.0939756    0.148463    -0.0348274    0.0600992    0.0901133  -0.132143      0.233618     0.162817    -0.171043      0.0958095   0.138557     0.117152    -0.0721268     0.0198717   -0.0245605    0.167053    -0.0229846   -0.0539708   -0.0781704    0.0493574     0.140302    -0.095765    0.111016    -0.0236589    0.0576787   -0.0155726
  0.118743    -0.174688     0.0858702   -0.0876485   -0.107773   -0.184261     -0.186602    -0.0226342   -0.147978      0.113098    0.0527508    0.0522305    0.131319     -0.410386     0.169744     0.072407    -0.334146    -0.273032    -0.0405263   -0.0163123     0.0240471    0.185765   -0.176388     0.0548012   -0.113392     0.0464523
 -0.0894383   -0.303559    -0.10641     -0.181058    -0.227836    0.0932458    -0.163936    -0.0496107   -0.00120104   -0.0515415   0.0556847   -0.120076    -0.0930617     0.0596636    0.132195    -0.055612     0.0751777   -0.0877827   -0.0346869    0.0759371    -0.269122    -0.0360378  -0.122205     0.156233    -0.158658     0.0817158
  0.0757776    0.11813      0.0226437    0.021387     0.0980219   0.00417775    0.0641866    0.0436444   -0.0644609     0.0651573  -0.027216    -0.175226    -0.0685627    -0.0904794   -0.0469823    0.13544      0.0269205    0.00051124   0.061682     0.0285783    -0.0695617    0.0152769   0.0568994   -0.0403861   -0.00892455   0.0862711
 -0.151471     0.139542    -0.00887507   0.0183656   -0.0968775  -0.0258084     0.134741    -0.0564403   -0.162988      0.0375548  -0.126477    -0.137781    -0.0309373     0.0404986    0.192376     0.0348788    0.106222     0.0181988   -0.0155672    0.0385049     0.0343433   -0.0361113   0.035825    -0.139697     0.0195875   -0.023788
  0.0923052   -0.102079     0.166559    -0.0251693    0.116326    0.128978     -0.0343319    0.12188      0.0163479     0.119216    0.137857    -0.0472498   -0.117983      0.0498557    0.0228071    0.0384419    0.193434     0.0137362    0.081912    -0.113632      0.0152492   -0.128642    0.0650473   -0.0319007   -0.09685     -0.00217066
  0.0915005    0.0104675    0.0534016   -0.183488    -0.0210216  -0.220068     -0.037627    -0.116687     0.0793435     0.0965964   0.109071    -0.00381895   0.184408     -0.0686945   -0.0140402   -0.078111     0.170797    -0.0440258   -0.193405     0.143896     -0.252409     0.212258   -0.133939     0.050814    -0.0790825   -0.0549336
 -0.100008     0.0869803    0.0746888    0.0121612    0.0631667   0.125408     -0.0539617    0.0274655    0.163981      0.0380291  -0.151477     0.10894     -0.13623      -0.0378488   -0.0472775   -0.0582536    0.0951482    0.217329    -0.0482894   -0.0227246    -0.0214518   -0.0896889  -0.202231    -0.17102     -0.126954     0.0398697
 -0.069678    -0.263605    -0.0926382   -0.0385049    0.034487    0.175964      0.0719705   -0.0697443    0.0481554     0.0102389  -0.024751    -0.108934    -0.217852     -0.17378     -0.0539756    0.125662     0.107271    -0.194268     0.0926465   -0.142197      0.107311     0.125496    0.0348911    0.0225126    0.0360537   -0.0760045
  0.0591715    0.0347344    0.0594506   -0.244144     0.0327946   0.0604956     0.0138073   -0.129179     0.0432739     0.0936503   0.00806494  -0.231475     0.308535     -0.025194     0.0381753   -0.0725052    0.156323    -0.0593246   -0.210713     0.106087     -0.212959     0.0556192  -0.00510445   0.0431296    0.0863437   -0.0675263
 -0.0122368   -0.0944239   -0.0755764   -0.10858      0.0114164  -0.00579482   -0.0556052   -0.0341714   -0.0096815    -0.108275    0.033626     0.0709686   -0.0520309     0.101423    -0.0288404    0.0411921    0.121733    -0.0816179   -0.0461438    0.020307     -0.0977084   -0.0378665  -0.0647116    0.0924854   -0.0426855    0.0494108
  0.125943    -0.0541562   -0.0242648    0.0465339   -0.181026   -0.0174478     0.0503022    0.0493651    0.0542485     0.0473114  -0.123905     0.136972     0.0840731    -0.0182604    0.0542935    0.0106472   -0.0193668    0.0946436    0.18381      0.0186031     0.0486469    0.0627959   0.0736275   -0.110174     0.241626    -0.00355837
  0.0489061    0.0923027   -0.0923333    0.0508513   -0.0278691   0.0951498    -0.0711275   -0.103441    -0.178299     -0.103347   -0.0505008   -0.146335     0.0392741    -0.10344     -0.0844106   -0.00904188  -0.0218065    0.00148507   0.0546716   -0.0578433     0.110524    -0.157703   -0.114357     0.0423697    0.0971085    0.0101005
 -0.176213    -0.0396848   -0.025422    -0.119466    -0.170823   -0.22941      -0.0531272    0.0438885    0.0336208    -0.0364256  -0.104767    -0.201581    -0.216683      0.174123     0.106274     0.020811     0.124118    -0.10787     -0.0127916   -0.0463528    -0.00722279  -0.148274   -0.134144     0.0839506   -0.0035938    0.061103
  0.0198136    0.404823    -0.0268887    0.0114898   -0.081996    0.0906529    -0.0107882   -0.173035    -0.169036      0.0385666  -0.0662838   -0.127498     0.0383938    -0.11653     -0.0715722   -0.0284994   -0.00839617  -0.0350404    0.070882    -0.0433027     0.0489875   -0.0966127  -0.114587     0.0442766    0.190308    -0.122647
  0.23055      0.0925519   -0.101513     0.00361601   0.158707   -0.209932     -0.229807    -0.0590511    0.170341      0.0208722  -0.0713253   -0.0774802    0.219043      0.0124395    0.0853445    0.0744419    0.125446     0.0804832   -0.0283988   -0.0749426    -0.0559271   -0.0984609  -0.0924903   -0.0408373    0.0576191    0.153424
  0.044416     0.252503     0.176829     0.0954835    0.0794787  -0.174448     -0.215523    -0.0574034   -0.0211023    -0.160288    0.0126283   -0.0453029    0.0109417     0.114113    -0.053127    -0.0856415    0.0230359   -0.173333    -0.2038       0.082546      0.0173636    0.0794849  -0.0474038   -0.0445898    0.0720819   -0.0452928
 -0.180938    -0.00560036   0.108794     0.0204238    0.248368   -0.060894     -0.0827827    0.0588524    0.0226888     0.114762   -0.119304     0.12928      0.0417524    -0.173329     0.232796    -0.0774353    0.0547395   -0.0139947    0.0226901    0.128498      0.0909914    0.107226   -0.0630786    0.117993    -0.0344121   -0.177923
 -0.0711521   -0.151183     0.0137587    0.0781222   -0.0237733  -0.0997424     0.0180967    0.139726     0.0295661     0.151794    0.110831     0.112273    -0.00317581   -0.0546908   -0.113837     0.0711729    0.0320098    0.0342466   -0.229503    -0.169139     -0.0760396   -0.019063    0.0605869   -0.1105      -0.0777934    0.0800612
 -0.0738551    0.0648927   -0.0661976   -0.0554995    0.147393    0.0806622     0.00205902  -0.115727     0.0963961    -0.10606     0.158811    -0.0362653   -0.0778982    -0.0825881   -0.01108     -0.0784842   -0.12482     -0.0540771    0.0238001    0.15001      -0.0165053   -0.0223848   0.110169     0.0908185   -0.075779     0.0320808
 -0.190525    -0.146446    -0.0459261    0.077432    -0.121361   -0.0239097     0.0889237    0.0220222    0.113837      0.0884851   0.0710039   -0.186897    -0.0236874     0.180064     0.0717526    0.0089289    0.304447    -0.0128317    0.186324    -0.0941393     0.00696655  -0.063644    0.0341473   -0.140174     0.0603781    0.0760961
 -0.129584     0.121372     0.132398    -0.0732211    0.0193132  -0.0170328    -0.102666     0.0351034   -0.0168932     0.0187847   0.0239923   -0.12564     -0.0502073     0.00572548  -0.00452657  -0.0981506    0.0541652   -0.0472687   -0.0500436   -0.0793851     0.142033     0.0770481   0.00920296  -0.00476741  -0.0440081   -0.280861
  0.0662512   -0.179946     0.0907378    0.0717408   -0.304082   -0.0398132     0.0960842   -0.118598     0.0998206     0.0294016  -0.0480103   -0.0262346   -0.0510597     0.303645    -0.0198807   -0.0966838    0.0305744   -0.077558     0.193614     0.0421917    -0.105574     0.0538164  -0.0836696    0.149274    -0.063775    -0.0129047
  0.0715322   -0.0441463    0.140771     0.0217489   -0.0221935   0.153039     -0.175508    -0.0425528    0.0502637    -0.0195638  -0.228932    -0.0682102   -0.0912971    -0.140597    -0.00249726  -0.0535489    0.0173334   -0.124911    -0.0682511   -0.0844748    -0.0598734   -0.174292    0.0774655    0.0782136    0.0166333   -0.179647
 -0.00979265   0.0120403   -0.055315    -0.104613    -0.158533   -0.0850925    -0.111321    -0.00251309  -0.037105     -0.141206   -0.00107438  -0.143283     0.108143     -0.0107      -0.0238118   -0.102289    -0.126778    -0.215051    -0.1582       0.144428      0.0683896    0.109623   -0.128712    -0.0827826   -0.121206     0.0660949
  0.0543734   -0.0265192    0.0561691   -0.0383336   -0.0212074  -0.228583     -0.116194    -0.0364837    0.0666129     0.0853401  -0.0706256    0.158693    -0.0523867    -0.0538563   -0.195752    -0.184282    -0.149429     0.223043    -0.163774     0.144388     -0.0224004    0.092388    0.0779335    0.00439335  -0.0893218    0.00661727[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     10
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.036940
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      8
│      9
│     10
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.966841
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      3
│      9
│     10
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.961941
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      4
│      8
│      9
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.976065
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│     10
│     23
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.004770
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      8
│      9
│     10
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.975192
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      9
│     10
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -0.982764
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      3
│      4
│      8
│      9
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.967237
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      3
│     10
│     23
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.999883
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      8
│      9
│     10
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.983952
┌ Info: EM with 100000 data points 10 iterations avll -0.983952
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.104384     0.204765    -0.0149304   -0.02285      0.0598306    0.124571   -0.117988    -0.0592757     0.0241788   -0.110726      0.0230476   0.189834    -0.0382506     0.196321   -0.00426081  -0.131346    -0.0461331   -0.0911005     0.0990615   -0.120175    -0.0928917    0.0127879    0.0180795   -0.0854112   -0.115446    -0.179906
  0.0461386    0.0385039   -0.080425    -0.0167851    0.0526261   -0.0951046   0.0547959    0.0471687    -0.023957     0.0599988    -0.133992    0.0673323   -0.0744866     0.217872   -0.00720598   0.0945908    0.0142791   -0.0584922    -0.0698601   -0.116377    -0.151592    -0.00201394  -0.0280585   -0.0915488   -0.0752544    0.0970572
  0.120291    -0.0388076    0.0721252   -0.014413     0.0761001    0.0730031   0.0531164   -0.0190153     0.00696797   0.0401097    -0.192583   -0.101698     0.0189291     0.1052      0.0222497    0.0108      -0.111154    -0.00158623   -0.0139154   -0.174669    -0.0540176   -0.0802403    0.0699232    0.0200939    0.1337      -0.123755
 -0.0579288   -0.00591078   0.0576995    0.117331    -0.0166748   -0.135811    0.0492076   -0.00608092    0.0382104   -0.0548272    -0.0626866   0.0275744    0.00615745   -0.0653319   0.0168765    0.0865821   -0.0150782    0.0594903    -0.043092     0.00583206  -0.200384    -0.0223514    0.0310524   -0.130635     0.0227       0.0705643
  0.0241692    0.0636811    0.113077     0.161544    -0.113846     0.147537   -0.126759     0.183194     -0.0182912   -0.141244      0.0547009  -0.00626309  -0.267537      0.0749568  -0.145972     0.0581665    0.0687508   -0.0239665    -0.00884619  -0.0508672    0.0953347    0.0389983   -0.00344083   0.00843601   0.0562189   -0.142198
  0.0680939    0.193393    -0.0582339   -0.143904    -0.227492    -0.0410173  -0.0262172   -0.142502     -0.00286723   0.224656      0.028434   -0.0968282    0.166731      0.100479    0.0306498    0.157748    -0.0811075   -0.00643978    0.0746103    0.0691864    0.195924    -0.10398     -0.235631     0.0831395   -0.049648    -0.0665395
 -0.0001999    0.182747    -0.0187328   -0.0549992   -0.0712555   -0.202922    0.065596    -0.0686829    -0.0720222   -0.0480049     0.044148    0.0663925   -0.00138038    0.0620289  -0.296258     0.10337      0.0645481    0.0798714    -0.0410377   -0.114349    -0.208818    -0.0632953    0.118419    -0.0323884   -0.16847     -0.125685
 -0.00117435  -0.0973032    0.105661     0.0593501   -0.0832408    0.0171023   0.156592    -0.139983      0.0974479   -0.0880675     0.0573619  -0.00518564  -0.167721      0.104975   -0.119361    -0.0106015    0.171199     0.186069     -0.0224617   -0.0184921    0.0529571   -0.0123279   -0.159151    -0.056648    -0.0389041   -0.0191978
 -0.038211    -0.0761188   -0.00866372   0.00930595  -0.147592    -0.0694709  -0.0244292    0.0790063     0.0284407    0.0357108     0.0157179   0.15422      0.0302197    -0.010009    0.00942288   0.116622     0.125184     0.150363     -0.0396196   -0.157809    -0.114196    -0.0155319   -0.199254     0.153648    -0.0304712    0.0625374
 -0.0251578    0.0575343   -0.167058    -0.159213     0.00914462  -0.0882975   0.0446446   -0.0725439     0.0128873    0.0685297     0.0900793   0.0290672    0.0899162    -0.120617   -0.115982    -0.0164298    0.119503     0.0562713    -0.164645    -0.163651     0.0788929   -0.0165601    0.050693    -0.0201399    0.0317646   -0.0778255
 -0.0895048    0.165655     0.108663    -0.0397143    0.00881748   0.0339016  -0.17741      0.0234919    -0.064321    -0.0379809    -0.0515849   0.0785529   -0.00750041   -0.061655    0.0728234    0.0558968    0.0491486   -0.0872243    -0.0881454    0.0357751   -0.19981     -0.228058     0.11153     -0.0286741   -0.0432896   -0.0144537
  0.0532601   -0.0149388   -0.155362    -0.0200114   -0.181435    -0.0534504   0.0603091   -0.0192623     0.240105    -0.0291223    -0.173242   -0.0947017   -0.0585098    -0.127113   -0.111941     0.139739     0.0720876   -0.152701     -0.0682301   -0.0531825   -0.021362     0.0775296   -0.0738792   -0.12288     -0.206618     0.0518597
 -0.0752673    0.0571739    0.0472306   -0.0389434    0.123405     0.0394449   0.233582    -0.0457109     0.0305299    0.055727      0.0771374  -0.014979    -0.110149     -0.149572   -0.120325    -0.109468    -0.0872987   -0.0727048    -0.142624    -0.116173    -0.0725184    0.00277301  -0.17516     -0.046554    -0.133217    -0.0930198
  0.202922     0.04526      0.208042    -0.115818     0.166241     0.0369702  -0.0686654    0.000139401   0.143058    -0.0994211    -0.124549   -0.0376575    0.129786     -0.0698034  -0.0250155   -0.0496036   -0.0597117   -0.170724      0.160872     0.047964     0.0718564   -0.129916     0.0962662    0.00341695   0.111425     0.17841
 -0.159503    -0.0700535    0.00230888  -0.0912474   -0.16774      0.0944253   0.125471     0.0672312     0.0433728    0.000655741   0.0147194  -0.0208447   -0.105484     -0.131133    0.030738     0.0474004   -0.0680421    0.0518395    -0.0231521    0.0683424   -0.0413941   -0.0906839    0.00215184  -0.092225     0.103231     0.0374849
 -0.0191415    0.101108    -0.0913016   -0.0764381    0.0553764    0.0504303  -0.0829301    0.0115571    -0.0347551   -0.0785669    -0.130442    0.100196     0.208124      0.0202176  -0.0448752   -0.24057      0.135827    -0.0687253    -0.112508    -0.0948164   -0.286343    -0.213312     0.0417897   -0.0410461   -0.154282     0.00991774
  0.0521338   -0.0614527   -0.0805824   -0.222511    -0.0510693   -0.0913876   0.0318553    0.035041     -0.113415    -0.113496      0.0523817   0.322817     0.0101407    -0.195574    0.12631     -0.10954     -0.0539038   -0.095386      0.0199932    0.0118304    0.0226594   -0.0118341    0.0581882    0.0642433    0.0571891    0.00305969
 -0.0331917    0.186025    -0.0450883   -0.196572     0.140232    -0.0167647  -0.0568691    0.00358801   -0.137911    -0.0614147     0.0568023   0.0157083   -0.122161     -0.0359758   0.0364808   -0.192587     0.0122984    0.0782191     0.0192934   -0.139937    -0.0963419   -0.0205667    0.0524557   -0.147469     0.0276252    0.122647
  0.0424968    0.163267    -0.136562     0.0307367    0.151772     0.134652   -0.00291445  -0.123584      0.0202173    0.0945001     0.154967    0.134826    -0.0774486     0.0333484   0.164938     0.0221892   -0.0409552    0.0452474     1.68436e-5   0.143029     0.0738095    0.0315767    0.0853981    0.0621491   -0.055112     0.155551
  0.163369     0.0669814   -0.0548262    0.0145402    0.00237149  -0.155678    0.0789862    0.131048     -0.00363816   0.101048      0.156578    0.0296971    0.255214     -0.109458   -0.0426563   -9.48865e-5  -0.0914079   -0.0556182    -0.0390973    0.182276    -0.0654421    0.0564412   -0.171176    -0.0671794   -0.075231    -0.014428
 -0.0640296    0.234236    -0.22236      0.0514659   -0.0214891   -0.029366   -0.0926362    0.135662     -0.065423    -0.101831      0.0921552  -0.0583248   -0.000516673   0.0368024  -0.037344    -0.132783    -0.0301861   -0.0775547    -0.0734776    0.066112     0.170763     0.152818     0.121552    -0.236856     0.0450026    0.0205434
  0.049626     0.0270989   -0.0946787    0.0164395   -0.0659516   -0.0426168   0.168777     0.161136      0.0708908   -0.105341     -0.112115   -0.0467915    0.114483     -0.179504    0.164168    -0.0488023   -0.313849     0.00768931   -0.106697    -0.0602978   -0.0609333   -0.120685    -0.0354597    0.0263057   -0.0383714    0.0854587
 -0.0281235   -0.0308602   -0.139004     0.0276091   -0.00424083  -0.0387304  -0.103259    -3.30292e-5    0.102494     0.020142     -0.109941   -0.148105    -0.152718      0.0959469  -0.0439074    0.0388311   -0.0661318   -0.157742     -0.244218     0.0487373   -0.166415     0.154351    -0.0881469   -0.0573894    0.103304    -0.0730545
 -0.0888887    0.00962931  -0.0581828   -0.209632    -0.00430658   0.0226229  -0.0288796    0.000386867  -0.128184    -0.125918     -0.0204499  -0.0831985   -0.074651      0.0722239  -0.0479061    0.115401    -0.0583482    0.0631043     0.0847943   -0.0995707    0.0588023   -0.102576     0.0286112   -0.0390192    0.00463685  -0.251183
 -0.0704715    0.0518407   -0.0137946   -0.0584644   -0.200538    -0.0299095  -0.00590934   0.0434104     0.0942927   -0.0335822     0.117093    0.158311    -0.000575019   0.0162239   0.112575     0.0768718    0.077205    -0.0722754    -0.095091    -0.026685    -0.043861    -0.11752     -0.0311619    0.0511939    0.0705297    0.090374
 -0.0135581    0.0699647   -0.0968915    0.00155317  -0.0996016    0.0281487  -0.162463     0.126311     -0.108886     0.172395     -0.0131074   0.0415181   -0.0804925    -0.107417    0.0990891   -0.21003      0.0958781    0.202666      0.0676054   -0.0312132    0.092632     0.183545     0.00345852   0.133616    -0.0449366    0.0986718
 -0.060085    -0.0924331   -0.0705715    0.00240789  -0.203369     0.0512816  -0.0366888    0.0465263     0.07586      0.00218282   -0.13345    -4.2776e-5    0.0444976    -0.101257    0.0320787   -0.0914398    0.00719126  -0.0454314     0.138466     0.11909      0.0284687    0.0123695    0.156925     0.0998933   -0.094594    -0.0363408
 -0.0793975    0.0210503   -0.0202582   -0.0320675   -0.0418725    0.11089     0.0717295    0.0275292     0.136063    -0.00286439    0.0911951   0.171056    -0.0023111     0.086153   -0.0246577    0.0631138    0.100778     0.000865792  -0.140366    -0.0127163    0.0292006    0.0298054    0.0390858   -0.0683415   -0.0353594    1.99492e-5
  0.0545783    0.0353512   -0.112333    -0.00427066  -0.0947744    0.017218    0.0413368    0.117397      0.15248     -0.0856941     0.159931    0.0280761   -0.128698     -0.167542    0.220038     0.070754     0.103596     0.00249329    0.205485    -0.0598135   -0.0355763   -0.146025     0.157447    -0.141662    -0.0266788   -0.102452
 -0.0234776    0.0833672   -0.254702    -0.171248    -0.18215      0.0201217  -0.0853878    0.0675415    -0.0436833   -0.126843      0.191798   -0.0571152   -0.00818451    0.0575359  -0.0990335   -0.225621     0.00815222  -0.0896835    -0.0556833    0.108766    -0.110664    -0.215068    -0.0319296   -0.00865689  -0.125075     0.0663701
 -0.10254      0.0392899   -0.0103405   -0.118006    -0.0639431    0.0859376  -0.0433513   -0.228285      0.145766     0.00224042    0.0959407   0.0771129   -0.171882     -0.0302078   0.0245087   -0.0227987   -0.107769    -0.00953218   -0.0823715   -0.0760607   -0.0907731    0.00769847  -0.0154652    0.00625654  -0.0597198    0.0851058
  0.0363289   -0.0701557    0.0540766   -0.0387427   -0.0830204   -0.0433283   0.00195343  -0.176617      0.0126789   -0.0657471    -0.13527     0.097499    -0.0554079    -0.144183    0.100815    -0.102697     0.0490378    0.027385      0.0554854   -0.0493147   -0.00397187   0.0140008    0.217033    -0.155063     0.108717    -0.150838kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4211246132784296
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421143
[ Info: iteration 2, average log likelihood -1.421089
[ Info: iteration 3, average log likelihood -1.421050
[ Info: iteration 4, average log likelihood -1.421002
[ Info: iteration 5, average log likelihood -1.420937
[ Info: iteration 6, average log likelihood -1.420830
[ Info: iteration 7, average log likelihood -1.420609
[ Info: iteration 8, average log likelihood -1.420113
[ Info: iteration 9, average log likelihood -1.419135
[ Info: iteration 10, average log likelihood -1.417770
[ Info: iteration 11, average log likelihood -1.416620
[ Info: iteration 12, average log likelihood -1.416035
[ Info: iteration 13, average log likelihood -1.415818
[ Info: iteration 14, average log likelihood -1.415744
[ Info: iteration 15, average log likelihood -1.415719
[ Info: iteration 16, average log likelihood -1.415709
[ Info: iteration 17, average log likelihood -1.415706
[ Info: iteration 18, average log likelihood -1.415704
[ Info: iteration 19, average log likelihood -1.415703
[ Info: iteration 20, average log likelihood -1.415703
[ Info: iteration 21, average log likelihood -1.415703
[ Info: iteration 22, average log likelihood -1.415702
[ Info: iteration 23, average log likelihood -1.415702
[ Info: iteration 24, average log likelihood -1.415702
[ Info: iteration 25, average log likelihood -1.415702
[ Info: iteration 26, average log likelihood -1.415702
[ Info: iteration 27, average log likelihood -1.415701
[ Info: iteration 28, average log likelihood -1.415701
[ Info: iteration 29, average log likelihood -1.415701
[ Info: iteration 30, average log likelihood -1.415701
[ Info: iteration 31, average log likelihood -1.415701
[ Info: iteration 32, average log likelihood -1.415701
[ Info: iteration 33, average log likelihood -1.415701
[ Info: iteration 34, average log likelihood -1.415701
[ Info: iteration 35, average log likelihood -1.415701
[ Info: iteration 36, average log likelihood -1.415701
[ Info: iteration 37, average log likelihood -1.415700
[ Info: iteration 38, average log likelihood -1.415700
[ Info: iteration 39, average log likelihood -1.415700
[ Info: iteration 40, average log likelihood -1.415700
[ Info: iteration 41, average log likelihood -1.415700
[ Info: iteration 42, average log likelihood -1.415700
[ Info: iteration 43, average log likelihood -1.415700
[ Info: iteration 44, average log likelihood -1.415700
[ Info: iteration 45, average log likelihood -1.415700
[ Info: iteration 46, average log likelihood -1.415700
[ Info: iteration 47, average log likelihood -1.415700
[ Info: iteration 48, average log likelihood -1.415700
[ Info: iteration 49, average log likelihood -1.415700
[ Info: iteration 50, average log likelihood -1.415700
┌ Info: EM with 100000 data points 50 iterations avll -1.415700
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4211428921070046
│     -1.421089484836822
│      ⋮
└     -1.4157001699724439
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415715
[ Info: iteration 2, average log likelihood -1.415666
[ Info: iteration 3, average log likelihood -1.415629
[ Info: iteration 4, average log likelihood -1.415588
[ Info: iteration 5, average log likelihood -1.415540
[ Info: iteration 6, average log likelihood -1.415483
[ Info: iteration 7, average log likelihood -1.415419
[ Info: iteration 8, average log likelihood -1.415351
[ Info: iteration 9, average log likelihood -1.415283
[ Info: iteration 10, average log likelihood -1.415218
[ Info: iteration 11, average log likelihood -1.415160
[ Info: iteration 12, average log likelihood -1.415111
[ Info: iteration 13, average log likelihood -1.415069
[ Info: iteration 14, average log likelihood -1.415035
[ Info: iteration 15, average log likelihood -1.415006
[ Info: iteration 16, average log likelihood -1.414982
[ Info: iteration 17, average log likelihood -1.414962
[ Info: iteration 18, average log likelihood -1.414943
[ Info: iteration 19, average log likelihood -1.414926
[ Info: iteration 20, average log likelihood -1.414909
[ Info: iteration 21, average log likelihood -1.414893
[ Info: iteration 22, average log likelihood -1.414876
[ Info: iteration 23, average log likelihood -1.414859
[ Info: iteration 24, average log likelihood -1.414842
[ Info: iteration 25, average log likelihood -1.414825
[ Info: iteration 26, average log likelihood -1.414807
[ Info: iteration 27, average log likelihood -1.414789
[ Info: iteration 28, average log likelihood -1.414771
[ Info: iteration 29, average log likelihood -1.414752
[ Info: iteration 30, average log likelihood -1.414734
[ Info: iteration 31, average log likelihood -1.414715
[ Info: iteration 32, average log likelihood -1.414698
[ Info: iteration 33, average log likelihood -1.414680
[ Info: iteration 34, average log likelihood -1.414664
[ Info: iteration 35, average log likelihood -1.414648
[ Info: iteration 36, average log likelihood -1.414634
[ Info: iteration 37, average log likelihood -1.414621
[ Info: iteration 38, average log likelihood -1.414609
[ Info: iteration 39, average log likelihood -1.414598
[ Info: iteration 40, average log likelihood -1.414589
[ Info: iteration 41, average log likelihood -1.414581
[ Info: iteration 42, average log likelihood -1.414574
[ Info: iteration 43, average log likelihood -1.414568
[ Info: iteration 44, average log likelihood -1.414563
[ Info: iteration 45, average log likelihood -1.414559
[ Info: iteration 46, average log likelihood -1.414555
[ Info: iteration 47, average log likelihood -1.414552
[ Info: iteration 48, average log likelihood -1.414549
[ Info: iteration 49, average log likelihood -1.414547
[ Info: iteration 50, average log likelihood -1.414545
┌ Info: EM with 100000 data points 50 iterations avll -1.414545
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4157149792675634
│     -1.415666049380412
│      ⋮
└     -1.4145448406737848
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414554
[ Info: iteration 2, average log likelihood -1.414503
[ Info: iteration 3, average log likelihood -1.414457
[ Info: iteration 4, average log likelihood -1.414403
[ Info: iteration 5, average log likelihood -1.414336
[ Info: iteration 6, average log likelihood -1.414256
[ Info: iteration 7, average log likelihood -1.414165
[ Info: iteration 8, average log likelihood -1.414068
[ Info: iteration 9, average log likelihood -1.413974
[ Info: iteration 10, average log likelihood -1.413889
[ Info: iteration 11, average log likelihood -1.413816
[ Info: iteration 12, average log likelihood -1.413755
[ Info: iteration 13, average log likelihood -1.413705
[ Info: iteration 14, average log likelihood -1.413663
[ Info: iteration 15, average log likelihood -1.413628
[ Info: iteration 16, average log likelihood -1.413599
[ Info: iteration 17, average log likelihood -1.413575
[ Info: iteration 18, average log likelihood -1.413554
[ Info: iteration 19, average log likelihood -1.413535
[ Info: iteration 20, average log likelihood -1.413520
[ Info: iteration 21, average log likelihood -1.413506
[ Info: iteration 22, average log likelihood -1.413493
[ Info: iteration 23, average log likelihood -1.413481
[ Info: iteration 24, average log likelihood -1.413471
[ Info: iteration 25, average log likelihood -1.413460
[ Info: iteration 26, average log likelihood -1.413451
[ Info: iteration 27, average log likelihood -1.413442
[ Info: iteration 28, average log likelihood -1.413433
[ Info: iteration 29, average log likelihood -1.413425
[ Info: iteration 30, average log likelihood -1.413416
[ Info: iteration 31, average log likelihood -1.413408
[ Info: iteration 32, average log likelihood -1.413401
[ Info: iteration 33, average log likelihood -1.413393
[ Info: iteration 34, average log likelihood -1.413385
[ Info: iteration 35, average log likelihood -1.413378
[ Info: iteration 36, average log likelihood -1.413371
[ Info: iteration 37, average log likelihood -1.413363
[ Info: iteration 38, average log likelihood -1.413356
[ Info: iteration 39, average log likelihood -1.413349
[ Info: iteration 40, average log likelihood -1.413342
[ Info: iteration 41, average log likelihood -1.413335
[ Info: iteration 42, average log likelihood -1.413329
[ Info: iteration 43, average log likelihood -1.413322
[ Info: iteration 44, average log likelihood -1.413315
[ Info: iteration 45, average log likelihood -1.413309
[ Info: iteration 46, average log likelihood -1.413303
[ Info: iteration 47, average log likelihood -1.413297
[ Info: iteration 48, average log likelihood -1.413291
[ Info: iteration 49, average log likelihood -1.413285
[ Info: iteration 50, average log likelihood -1.413280
┌ Info: EM with 100000 data points 50 iterations avll -1.413280
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4145540765157045
│     -1.4145025440259065
│      ⋮
└     -1.413279610962642
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413283
[ Info: iteration 2, average log likelihood -1.413237
[ Info: iteration 3, average log likelihood -1.413196
[ Info: iteration 4, average log likelihood -1.413150
[ Info: iteration 5, average log likelihood -1.413097
[ Info: iteration 6, average log likelihood -1.413033
[ Info: iteration 7, average log likelihood -1.412957
[ Info: iteration 8, average log likelihood -1.412872
[ Info: iteration 9, average log likelihood -1.412779
[ Info: iteration 10, average log likelihood -1.412683
[ Info: iteration 11, average log likelihood -1.412588
[ Info: iteration 12, average log likelihood -1.412498
[ Info: iteration 13, average log likelihood -1.412415
[ Info: iteration 14, average log likelihood -1.412340
[ Info: iteration 15, average log likelihood -1.412273
[ Info: iteration 16, average log likelihood -1.412215
[ Info: iteration 17, average log likelihood -1.412164
[ Info: iteration 18, average log likelihood -1.412119
[ Info: iteration 19, average log likelihood -1.412080
[ Info: iteration 20, average log likelihood -1.412046
[ Info: iteration 21, average log likelihood -1.412014
[ Info: iteration 22, average log likelihood -1.411986
[ Info: iteration 23, average log likelihood -1.411960
[ Info: iteration 24, average log likelihood -1.411936
[ Info: iteration 25, average log likelihood -1.411913
[ Info: iteration 26, average log likelihood -1.411891
[ Info: iteration 27, average log likelihood -1.411870
[ Info: iteration 28, average log likelihood -1.411849
[ Info: iteration 29, average log likelihood -1.411829
[ Info: iteration 30, average log likelihood -1.411810
[ Info: iteration 31, average log likelihood -1.411791
[ Info: iteration 32, average log likelihood -1.411773
[ Info: iteration 33, average log likelihood -1.411755
[ Info: iteration 34, average log likelihood -1.411737
[ Info: iteration 35, average log likelihood -1.411720
[ Info: iteration 36, average log likelihood -1.411704
[ Info: iteration 37, average log likelihood -1.411688
[ Info: iteration 38, average log likelihood -1.411672
[ Info: iteration 39, average log likelihood -1.411657
[ Info: iteration 40, average log likelihood -1.411642
[ Info: iteration 41, average log likelihood -1.411628
[ Info: iteration 42, average log likelihood -1.411615
[ Info: iteration 43, average log likelihood -1.411602
[ Info: iteration 44, average log likelihood -1.411589
[ Info: iteration 45, average log likelihood -1.411577
[ Info: iteration 46, average log likelihood -1.411565
[ Info: iteration 47, average log likelihood -1.411554
[ Info: iteration 48, average log likelihood -1.411543
[ Info: iteration 49, average log likelihood -1.411532
[ Info: iteration 50, average log likelihood -1.411522
┌ Info: EM with 100000 data points 50 iterations avll -1.411522
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4132830571306185
│     -1.413237140938025
│      ⋮
└     -1.4115219910847832
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411520
[ Info: iteration 2, average log likelihood -1.411468
[ Info: iteration 3, average log likelihood -1.411420
[ Info: iteration 4, average log likelihood -1.411365
[ Info: iteration 5, average log likelihood -1.411300
[ Info: iteration 6, average log likelihood -1.411220
[ Info: iteration 7, average log likelihood -1.411124
[ Info: iteration 8, average log likelihood -1.411012
[ Info: iteration 9, average log likelihood -1.410888
[ Info: iteration 10, average log likelihood -1.410758
[ Info: iteration 11, average log likelihood -1.410628
[ Info: iteration 12, average log likelihood -1.410502
[ Info: iteration 13, average log likelihood -1.410383
[ Info: iteration 14, average log likelihood -1.410272
[ Info: iteration 15, average log likelihood -1.410171
[ Info: iteration 16, average log likelihood -1.410079
[ Info: iteration 17, average log likelihood -1.409995
[ Info: iteration 18, average log likelihood -1.409919
[ Info: iteration 19, average log likelihood -1.409849
[ Info: iteration 20, average log likelihood -1.409785
[ Info: iteration 21, average log likelihood -1.409727
[ Info: iteration 22, average log likelihood -1.409673
[ Info: iteration 23, average log likelihood -1.409623
[ Info: iteration 24, average log likelihood -1.409577
[ Info: iteration 25, average log likelihood -1.409533
[ Info: iteration 26, average log likelihood -1.409492
[ Info: iteration 27, average log likelihood -1.409453
[ Info: iteration 28, average log likelihood -1.409416
[ Info: iteration 29, average log likelihood -1.409380
[ Info: iteration 30, average log likelihood -1.409347
[ Info: iteration 31, average log likelihood -1.409315
[ Info: iteration 32, average log likelihood -1.409284
[ Info: iteration 33, average log likelihood -1.409254
[ Info: iteration 34, average log likelihood -1.409226
[ Info: iteration 35, average log likelihood -1.409199
[ Info: iteration 36, average log likelihood -1.409173
[ Info: iteration 37, average log likelihood -1.409147
[ Info: iteration 38, average log likelihood -1.409123
[ Info: iteration 39, average log likelihood -1.409099
[ Info: iteration 40, average log likelihood -1.409076
[ Info: iteration 41, average log likelihood -1.409053
[ Info: iteration 42, average log likelihood -1.409031
[ Info: iteration 43, average log likelihood -1.409010
[ Info: iteration 44, average log likelihood -1.408989
[ Info: iteration 45, average log likelihood -1.408969
[ Info: iteration 46, average log likelihood -1.408949
[ Info: iteration 47, average log likelihood -1.408930
[ Info: iteration 48, average log likelihood -1.408912
[ Info: iteration 49, average log likelihood -1.408894
[ Info: iteration 50, average log likelihood -1.408877
┌ Info: EM with 100000 data points 50 iterations avll -1.408877
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4115204355438735
│     -1.4114680476395707
│      ⋮
└     -1.4088766881627053
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4211246132784296
│     -1.4211428921070046
│     -1.421089484836822
│     -1.4210498175138124
│      ⋮
│     -1.408911792930386
│     -1.4088939462192749
└     -1.4088766881627053
32×26 Array{Float64,2}:
 -0.115777   -0.368051   -0.932213   -0.166584    0.650323    0.162066     0.194952    -0.182533     0.551125    0.504526    -0.0453823     0.621254    -0.0203089  -0.268924   -0.137663    -0.152982     -0.350569    -0.724002    -0.14958      0.342605    -0.392314    -0.407365    0.372952   -0.405266     0.393849     0.364867
  0.0398032  -0.49054    -1.28286     0.39884     0.861212   -0.507407    -0.0699062    0.00203867   0.164097    0.282216    -0.212633     -0.277799    -0.174095   -0.269268   -0.377065    -0.115852     -0.252611    -0.340606     0.0489155    0.0507141   -0.08386      0.237964    0.239753    0.533229     0.513801    -0.108249
  0.276817   -0.32465    -0.30083     0.298039   -0.126707    0.227252     0.543363    -0.341872     0.20594     0.554506    -0.233041      0.0123452    0.440414    0.0826073  -0.0246665    0.132293      0.164566     0.456409     0.907402     0.21997     -0.415969    -0.0140911   0.586008   -0.174044    -0.0620157    0.197143
  0.594953    0.548231   -0.45399    -0.214782    0.0531554   0.168873    -0.02178     -0.124426    -0.413917    0.396978     0.302616     -0.148684     0.540108    0.107606    0.168047    -0.188646     -0.261778     0.0118134    0.43982      0.181627    -0.0650626   -0.206479    0.435632   -0.340821     0.640001    -0.261646
  0.517525    0.0779451  -0.619615   -0.171012    0.521132   -0.295639     0.636561    -0.371071     0.0270912   0.749612    -0.772349      0.0172394   -0.197641   -0.251721    0.207334    -0.561723     -0.00680445   0.0785091   -0.00926525  -0.292006    -0.172192     0.526415   -0.421685   -0.457128     0.070791     0.240859
  0.143476    0.655148   -0.66446    -0.291973    0.294728   -0.172363     0.461391    -0.254337    -0.177106   -0.145325    -0.613161      0.150316    -0.669872   -0.276119    0.188177     0.151258     -0.456642     0.00236007  -0.302611    -0.0203228    0.164922     0.118      -0.442387   -0.457912     0.00204877  -0.538555
  0.0237674   0.192944   -0.226071   -0.510968   -0.139145   -0.08126      0.126365    -0.389174    -0.21413    -0.130644    -0.512139     -0.00331775  -0.112003    0.456579   -0.0582613   -0.11195       0.442898    -0.535792     0.0584112    0.278874     0.492947     0.30942    -0.295443    0.246537    -0.0832309    0.656845
  0.261982    0.171244   -0.267016   -0.350465    0.131068   -0.347891    -0.423306     0.631719     0.248739   -0.115347    -0.741062     -0.160713    -0.131644   -0.26393     0.141601    -0.547012      0.446359    -0.325437     0.281696     0.313623    -0.245655     0.231866    0.032874    0.189068    -0.739526    -0.586465
  0.152465    0.301366   -0.0606699   0.476726    0.0372631  -0.364784     0.266859    -0.211494    -0.72511    -0.380869    -0.0128991    -0.761893     0.109274   -0.285435   -0.0475465    0.276219     -0.169288     0.647027     0.0302337   -0.253518    -0.584829     0.142177    0.238907   -0.0750535   -0.187103    -0.395806
 -0.100503    0.0216145   0.38913     0.29782    -0.0270825   0.0177791    0.00767938   0.0698034    0.238807   -0.310759     0.855229      0.326553    -0.166244    0.279423    0.203937     0.40791      -0.583803     0.1158      -0.203477    -0.255121    -0.665955    -0.546023    0.386461   -0.311617     0.152764    -0.633794
 -0.0567728   0.134564    0.0196889  -0.0477187  -0.0987131  -0.0202712    0.0447382    0.0974052   -0.169592   -0.128188    -0.0598756    -0.00539159  -0.0908308   0.0327856   0.0113333    0.048007     -0.00523477   0.0607362    0.0932284   -0.0913665    0.0973933    0.0631061  -0.0378542  -0.0491992   -0.0699823   -0.0409054
  0.399079   -0.140068    0.729514   -0.0860359  -0.0347511   0.653065     0.531515    -0.165831    -0.933936   -0.527053    -0.148137      0.361513    -0.0195944  -0.270591   -0.247991     0.474681      0.312635     0.0221103   -0.167777     0.266238     0.127995    -0.515818   -0.455304    0.140244     0.260615     0.293855
 -0.618679   -0.545853    0.226678    0.175543    0.719217   -0.113527    -0.203697     0.106679     0.214645    0.134829    -0.0676625    -0.262995    -0.377489   -0.205045    0.0703717   -0.269609      0.76909      0.104116    -0.505397    -0.443302     0.2645      -0.443104   -0.589466    0.0762578    0.00713368   0.167845
 -0.30508    -0.303861    0.639338    0.188302   -0.43977     0.0354221   -0.642793     0.106732     0.278885   -0.123922     0.819589     -0.271744     0.488163    0.349414   -0.150605    -0.138736      0.332624    -0.0233402    0.208003    -0.145244    -0.401636    -0.186116    0.608453    0.581259     0.025024     0.625244
 -0.634534    0.361408    0.483713   -0.190764   -0.719703   -0.183452    -0.188854     0.572112     0.266695   -0.596122     0.00662818   -0.101559    -0.335734   -0.359931   -0.453324     0.220726      0.100122    -0.0568139   -0.516018    -0.117902     0.244604    -0.261362   -0.222845   -0.0449089   -0.850625    -0.0667361
 -0.516421    0.275369   -0.514533   -0.208935   -0.370245   -0.404058    -0.731227     0.0437869    0.654289    0.151975     0.159943     -0.391428    -0.182045    0.330694    0.385647    -0.581051     -0.41776      0.0200506   -0.0525      -0.406513    -0.0186678    0.408252    0.0551255   0.0164197   -0.276196     0.142785
 -0.286412   -0.647165    0.0336344   0.17113    -0.137485   -0.775375     0.0239631   -0.639172     0.609261   -0.104414     0.26661       0.309266     0.0302536  -0.408992   -0.39575      0.223699      0.417589     0.194284    -0.99495     -0.475589    -0.597979     0.439916    0.0778391   0.617438    -0.198605     0.0515404
  0.760949   -0.682662   -0.0514029   0.0424219  -0.482953   -0.641179    -0.442144     0.0484142    0.280956    0.326485     0.0361624     0.507906     0.488241    0.0495336  -0.615362    -0.109721      0.447328     0.363275    -0.0132226    0.00255518   0.205566     0.469953   -0.363475    0.284998     0.238032    -0.326757
  0.724404   -0.133764    0.66163    -0.100351   -0.212617    0.877924     0.00959744  -0.300607     0.339225    0.270353     0.368057      0.428452    -0.0595617  -0.0778968   0.407582    -0.000596462  -0.0696599    0.28951     -0.399828     0.0630275   -0.381542     0.302694    0.118133   -0.0876511   -0.679936    -0.477273
  0.429779    0.0711582  -0.450806    0.103566    0.034789    0.636321    -0.401299     0.106294     0.195896    0.439109    -0.125034     -0.0443397    0.486193   -0.445381    0.098682    -0.0162809    -0.407299    -0.410341    -0.593101     0.0805121   -0.0785622   -0.184585   -0.278138    0.667809    -0.204224     0.0266203
  0.212901    0.532723    0.627177   -0.28067    -0.56785     0.38062     -0.271793     0.0769011   -0.425453   -0.487338     0.114268     -0.361684     0.0023557   0.402279    0.128868     0.13807      -0.044945     0.221415     0.138718     0.257533     0.248872    -0.0599773  -0.409732   -0.481178    -0.0953034   -0.130365
  0.20098     0.129867    0.591167    0.473229   -0.496233    0.134812    -0.0325923    0.488782    -0.0462625  -0.262657    -0.0199291     0.0963192    0.0623064   0.40822    -0.219408     0.240931      0.114187     0.775715     0.352913    -0.062843     0.58739      0.763528    0.264578    0.342355    -0.20416     -0.261554
  0.166642   -0.203676    0.132113    0.110034   -0.107246    0.068247     0.149096    -0.265368     0.0415037  -0.00967551   0.114997      0.159691     0.147538    0.0227134  -0.123896     0.160695      0.122142     0.0604988   -0.00862027   0.0662301   -0.234276     0.0171207  -0.017726    0.00458709   0.0357029    0.0960903
  0.274959    0.299202   -0.388231   -0.140805   -0.167001   -0.00162972   0.0136139   -0.0220439   -0.0298092   0.0310746   -0.0794058    -0.141134    -0.0355496   0.0667192   0.00136703  -0.212221     -0.153633    -0.0388622    0.142791     0.28941      0.0624042    0.279902    0.104528   -0.138187     0.0681245    0.078108
 -0.0678285  -0.147098   -0.094229   -0.188511   -0.0493702   0.0560017    0.081321     0.341754    -0.269592    0.0214287    0.000664988  -0.182903    -0.270952   -0.519016   -0.751147    -0.0851006     0.135288    -0.338329    -0.241913     0.326135     0.165156    -0.132588   -0.0885121  -0.0907671    0.158079    -0.047809
 -0.586153   -0.253055   -0.0743874  -0.0134042  -0.0919914  -0.0823836    0.212631     0.434132    -0.323825   -0.209542     0.423181     -0.0726121   -0.53989    -0.448507    0.0028068   -0.609984      0.410139     0.185826     0.208372     0.100085    -0.0400072    0.207582    0.271805   -0.439681     0.262596     0.109774
 -0.20922     0.187628   -0.149442   -0.10372     0.269952   -0.195848    -0.15887     -0.0662003    0.237954   -0.00620292  -0.0696886     0.0820198   -0.185586   -0.0432646   0.253351    -0.159831     -0.0286742   -0.0616849   -0.184073    -0.400463    -0.157558    -0.264023   -0.0653184   0.0159676   -0.0788455   -0.246374
 -0.311251   -0.07288    -0.0609816  -0.0209274  -0.200056    0.158222    -0.0729223    0.661596    -0.0158944  -0.00303608   0.0959542     0.0182878    0.0365596  -0.452258    0.12195     -0.0944885    -0.311454     0.0864126    0.010482    -0.245123    -0.0403875   -0.276698    0.416657    0.18788     -0.23605     -0.0888296
 -0.436596    0.630003    0.241027   -0.350174   -0.0818446  -0.140336     0.20691     -0.163218     0.268961   -0.319756    -0.230471      0.384952     0.178825    0.0567155   0.594261    -0.347185      0.170705    -0.32555      0.0650096   -0.135921    -0.255722    -0.431054    0.0601971  -0.414305    -0.148213     0.418583
 -0.251556    0.227179    0.180411    0.031373    0.402668    0.0253167   -0.10926      0.0502164    0.526193    0.126563     0.328375      0.414211     0.391703    0.268392   -0.152428     0.170475      0.0947812   -0.652677    -0.356234    -0.136884     0.368864    -0.335956   -0.0885641  -0.426288     0.233192    -0.0131714
 -0.120494    0.156195    0.185809   -0.258358   -0.324569    0.15849      0.339108    -0.567063    -0.351375   -0.0683232    0.324453      0.260037     0.191763    0.603157    0.0434441    0.728566     -0.527018     0.323585     0.0192358   -0.619625     0.239609    -0.382671   -0.259362    0.0276286    0.255023     0.556304
 -0.252624   -0.278123    0.24505    -0.138308    0.0499907  -0.039772    -0.294676     0.00567895   0.101392   -0.291965    -0.091387      0.187124    -0.472039    0.475089   -0.0120681    0.741488      0.0751506   -0.163924     0.0262818   -0.25175      0.00448237  -0.26014    -0.388708    0.374984     0.0337884   -0.0563874[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408860
[ Info: iteration 2, average log likelihood -1.408844
[ Info: iteration 3, average log likelihood -1.408828
[ Info: iteration 4, average log likelihood -1.408813
[ Info: iteration 5, average log likelihood -1.408799
[ Info: iteration 6, average log likelihood -1.408785
[ Info: iteration 7, average log likelihood -1.408771
[ Info: iteration 8, average log likelihood -1.408758
[ Info: iteration 9, average log likelihood -1.408746
[ Info: iteration 10, average log likelihood -1.408733
┌ Info: EM with 100000 data points 10 iterations avll -1.408733
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.130885e+05
      1       7.114408e+05      -2.016477e+05 |       32
      2       6.903349e+05      -2.110594e+04 |       32
      3       6.844184e+05      -5.916464e+03 |       32
      4       6.817944e+05      -2.624019e+03 |       32
      5       6.802971e+05      -1.497259e+03 |       32
      6       6.792311e+05      -1.066023e+03 |       32
      7       6.784144e+05      -8.166665e+02 |       32
      8       6.777510e+05      -6.634765e+02 |       32
      9       6.772022e+05      -5.487589e+02 |       32
     10       6.767262e+05      -4.760107e+02 |       32
     11       6.763332e+05      -3.930247e+02 |       32
     12       6.760097e+05      -3.234317e+02 |       32
     13       6.757073e+05      -3.024721e+02 |       32
     14       6.754486e+05      -2.586916e+02 |       32
     15       6.752012e+05      -2.473507e+02 |       32
     16       6.749759e+05      -2.252796e+02 |       32
     17       6.747786e+05      -1.973742e+02 |       32
     18       6.745931e+05      -1.854242e+02 |       32
     19       6.744345e+05      -1.586232e+02 |       32
     20       6.742923e+05      -1.422586e+02 |       32
     21       6.741601e+05      -1.321898e+02 |       32
     22       6.740293e+05      -1.307751e+02 |       32
     23       6.739075e+05      -1.218029e+02 |       32
     24       6.738047e+05      -1.028023e+02 |       32
     25       6.737055e+05      -9.919754e+01 |       32
     26       6.736196e+05      -8.585273e+01 |       32
     27       6.735402e+05      -7.941645e+01 |       32
     28       6.734626e+05      -7.766076e+01 |       32
     29       6.733911e+05      -7.149362e+01 |       32
     30       6.733245e+05      -6.652795e+01 |       32
     31       6.732685e+05      -5.604609e+01 |       32
     32       6.732178e+05      -5.070878e+01 |       32
     33       6.731702e+05      -4.762602e+01 |       32
     34       6.731270e+05      -4.317750e+01 |       32
     35       6.730915e+05      -3.544176e+01 |       32
     36       6.730525e+05      -3.901832e+01 |       32
     37       6.730127e+05      -3.984118e+01 |       32
     38       6.729709e+05      -4.175022e+01 |       32
     39       6.729305e+05      -4.045430e+01 |       32
     40       6.728820e+05      -4.850041e+01 |       32
     41       6.728350e+05      -4.698538e+01 |       32
     42       6.727928e+05      -4.221710e+01 |       32
     43       6.727519e+05      -4.083836e+01 |       32
     44       6.727100e+05      -4.193406e+01 |       32
     45       6.726728e+05      -3.718510e+01 |       32
     46       6.726339e+05      -3.890802e+01 |       32
     47       6.725994e+05      -3.452200e+01 |       32
     48       6.725661e+05      -3.326355e+01 |       32
     49       6.725312e+05      -3.494701e+01 |       32
     50       6.724972e+05      -3.399299e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 672497.1764852267)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420916
[ Info: iteration 2, average log likelihood -1.415851
[ Info: iteration 3, average log likelihood -1.414521
[ Info: iteration 4, average log likelihood -1.413563
[ Info: iteration 5, average log likelihood -1.412547
[ Info: iteration 6, average log likelihood -1.411566
[ Info: iteration 7, average log likelihood -1.410854
[ Info: iteration 8, average log likelihood -1.410441
[ Info: iteration 9, average log likelihood -1.410210
[ Info: iteration 10, average log likelihood -1.410064
[ Info: iteration 11, average log likelihood -1.409959
[ Info: iteration 12, average log likelihood -1.409875
[ Info: iteration 13, average log likelihood -1.409805
[ Info: iteration 14, average log likelihood -1.409744
[ Info: iteration 15, average log likelihood -1.409690
[ Info: iteration 16, average log likelihood -1.409641
[ Info: iteration 17, average log likelihood -1.409596
[ Info: iteration 18, average log likelihood -1.409555
[ Info: iteration 19, average log likelihood -1.409516
[ Info: iteration 20, average log likelihood -1.409480
[ Info: iteration 21, average log likelihood -1.409445
[ Info: iteration 22, average log likelihood -1.409413
[ Info: iteration 23, average log likelihood -1.409381
[ Info: iteration 24, average log likelihood -1.409351
[ Info: iteration 25, average log likelihood -1.409322
[ Info: iteration 26, average log likelihood -1.409295
[ Info: iteration 27, average log likelihood -1.409268
[ Info: iteration 28, average log likelihood -1.409242
[ Info: iteration 29, average log likelihood -1.409217
[ Info: iteration 30, average log likelihood -1.409193
[ Info: iteration 31, average log likelihood -1.409170
[ Info: iteration 32, average log likelihood -1.409148
[ Info: iteration 33, average log likelihood -1.409127
[ Info: iteration 34, average log likelihood -1.409106
[ Info: iteration 35, average log likelihood -1.409086
[ Info: iteration 36, average log likelihood -1.409067
[ Info: iteration 37, average log likelihood -1.409048
[ Info: iteration 38, average log likelihood -1.409030
[ Info: iteration 39, average log likelihood -1.409012
[ Info: iteration 40, average log likelihood -1.408995
[ Info: iteration 41, average log likelihood -1.408978
[ Info: iteration 42, average log likelihood -1.408962
[ Info: iteration 43, average log likelihood -1.408946
[ Info: iteration 44, average log likelihood -1.408931
[ Info: iteration 45, average log likelihood -1.408915
[ Info: iteration 46, average log likelihood -1.408901
[ Info: iteration 47, average log likelihood -1.408886
[ Info: iteration 48, average log likelihood -1.408872
[ Info: iteration 49, average log likelihood -1.408857
[ Info: iteration 50, average log likelihood -1.408844
┌ Info: EM with 100000 data points 50 iterations avll -1.408844
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0981239  -0.321816    -1.28369     0.0894512    0.623667    -0.136372    -0.0281355   -0.139794    0.438256    0.440145   -0.0239464   -0.0276367    0.116436   -0.315683    -0.157861   -0.321809    -0.417181   -0.504622    0.0614648    0.159735   -0.377089   -0.126705     0.367932    -0.00214179   0.523758    0.0574282
  0.651022   -0.712308     0.0791293   0.403054    -0.378224    -0.660947    -0.322934     0.151787    0.401609    0.174582   -0.0302344    0.772359     0.295391    0.0039111   -0.389771   -0.111758     0.537143    0.476098   -0.0411705    0.125593    0.213808    0.644631    -0.522755     0.378812     0.251419   -0.415445
 -0.627935    0.132227     0.282469   -0.281638    -0.400747    -0.330478    -0.390065     0.263249    0.486878   -0.205825    0.263757    -0.0143983   -0.150725   -0.00589903   0.0726493  -0.301683     0.149564   -0.18994    -0.111315    -0.269628   -0.165113   -0.0874608    0.00544234   0.101058    -0.374       0.272198
  0.534565    0.64404     -0.402241   -0.507221     0.00426512  -0.00377465   0.215116    -0.220188   -0.716956   -0.17318     0.198745     0.103141     0.22143    -0.201487     0.444443    0.134013    -0.431415    0.109614    0.428888     0.170266   -0.445236   -0.118284     0.37738     -0.613971     0.759485   -0.376818
 -0.124227    0.512275     0.0586579   0.00607194   0.521473    -0.320065     0.249274    -0.917321    0.0599284  -0.0741133   0.16166      0.0214839   -0.114773    0.6481       0.308448   -0.0123339    0.0123434  -0.0924035  -0.205246    -0.265798    0.0362505  -0.174416    -0.400254    -0.156988     0.670818   -0.0139091
 -0.207667    0.206668    -0.0309409  -0.146204    -0.0306477   -0.154508    -0.0986576    0.289302    0.103452   -0.0555325  -0.00514992  -0.102803    -0.141795   -0.387993    -0.168355   -0.107764     0.0306856  -0.241701   -0.203865    -0.161714   -0.0966394  -0.228276     0.0726434   -0.172942    -0.267274   -0.280255
 -0.322338    0.0318272   -0.0796185  -0.549533     0.408686     0.162517    -0.0327257    0.051426    0.408145    0.412913    0.0438002    0.601026     0.0745145   0.243476    -0.0687269  -0.0701323    0.197245   -0.661636   -0.141589     0.0943534   0.396437   -0.188214    -0.12996     -0.428187     0.555061    0.335718
  0.187192   -0.0239022   -0.149269    0.0717648   -0.0328254    0.11761      0.0260066   -0.187292    0.0466806   0.0837748   0.0713936    0.0634822    0.14659     0.0924732   -0.0972826   0.143825    -0.189153    0.0298671  -0.0305403    0.0107121  -0.06949     0.0100799   -0.00727588   0.0912647    0.169732    0.0368888
 -0.205696    0.299623     0.224744   -0.0806101   -0.22074     -0.0796462    0.286458    -0.206914    0.312418   -0.27236    -0.132629     0.326476     0.379556    0.0398628    0.270974   -0.0764477    0.1877     -0.208986    0.209787    -0.0251014  -0.315526   -0.278553     0.21917     -0.33221     -0.296281    0.430983
 -0.674988   -0.184565     0.217088    0.0667853    0.257309     0.0681505   -0.0763195    0.430407    0.0741141  -0.0647988   0.341874     0.11436     -0.372065   -0.530229     0.329621   -0.21927      0.0661896   0.0964989  -0.252115    -0.348878   -0.110197   -0.577033     0.00566649   0.136633     0.215517   -0.0820239
  0.0745958  -0.0157369    0.195546   -0.297154    -0.146757    -0.0430143   -0.192928    -0.240657    0.273903   -0.220033   -0.309053     0.246886    -0.501688    0.526465     0.136342    0.391425     0.0307234  -0.156285   -0.142262    -0.15753     0.0323732  -0.0231236   -0.444338     0.426246    -0.337077   -0.036022
  0.0504684  -0.277245    -0.125695   -0.0884694   -0.542693     0.272991    -0.0829393    1.14191    -0.162134   -0.0321128  -0.193842    -0.00755455   0.225055   -0.746158    -0.0186569  -0.181533    -0.471026    0.228733    0.263209     0.077508    0.108733    0.145288     0.598127     0.137365    -0.595624   -0.158676
  0.457748   -0.158411     0.0211558  -1.06346      0.110782    -0.38462     -0.408462     0.167938   -0.228423    0.0269602  -0.475003    -0.21086      0.204159    0.0378872   -0.677406   -0.0579512    0.836354   -0.407184    0.45096     -0.0294987   0.0474358   0.0470451    0.362403     0.311777    -0.328645   -0.146066
 -0.473731    0.3333      -0.763868    0.307469    -0.0660161   -0.784838     0.360993     0.0392096  -0.573181   -0.264134   -0.0478279   -0.446984     0.0571309   0.260327    -0.64738    -0.0576592    0.115137   -0.253154    0.462516     0.265736    0.571658   -0.1136       0.110858    -0.129592     0.360984    0.109188
 -0.559467    0.359955    -0.429461   -0.167582    -0.337486    -0.297986    -0.305492     0.226617    0.474577   -0.0203794   0.118048    -0.179443    -0.327385    0.719249     0.532415   -0.109496    -0.346499   -0.0503507  -0.0657505   -0.308903   -0.0849855   0.231506     0.273244    -0.0575803   -0.336076    0.115013
 -0.0483347  -0.391884     0.169278   -0.123076    -0.216172     0.130654    -0.0535452   -0.0523006  -0.106579   -0.19301     0.0990884    0.0269812   -0.182864   -0.631727    -0.968166   -0.0304005    0.120651   -0.222168   -0.705006     0.266757    0.0661923  -0.20466     -0.48078      0.127043     0.069933    0.289769
 -0.205951   -0.475449     0.40126     0.517327    -0.250849     0.220683    -0.187966     0.0024711  -0.207692    0.145996    0.658728    -0.418504     0.468521    0.0447162   -0.0078549  -0.302084     0.310305    0.480349    0.546946    -0.187978   -0.529515   -0.174483     0.55099      0.337608     0.46334     0.674219
  0.496593   -0.830233    -0.137845    0.187346     0.089362     0.357033     0.494083    -0.522346    0.234831    0.821973   -0.0941401    0.0603199    0.194826    0.136008    -0.063569    0.229966     0.270455    0.154026    0.479386     0.151353   -0.319572    0.182076     0.209886    -0.0884604   -0.0214601   0.087659
  0.0342804  -0.00748091  -0.148721   -0.0991407   -0.0852121   -0.00346428   0.00892321   0.259642   -0.226686   -0.0829672   0.0618751   -0.0763308   -0.316972   -0.0946375    0.0244038  -0.320829     0.150471    0.157832    0.215138     0.165064    0.0933529   0.344312     0.161717    -0.191159     0.0836098  -0.0461524
 -0.168541   -0.154441     0.661122    0.488989    -0.0812411    0.30384     -0.308177     0.282176    0.25005    -0.405813    0.713764     0.213829     0.334397    0.430901    -0.252529    0.720786    -0.0224771  -0.158413   -0.317842    -0.122398    0.112106   -0.43003      0.356805    -0.111573     0.0566382  -0.285959
  0.265412    0.398716    -0.785593   -0.245738     0.161107    -0.344871     0.585245    -0.315169   -0.152653    0.47951    -0.806379    -0.00773699  -0.462417   -0.450795     0.0966071  -0.531762    -0.262098    0.214175   -0.00739197  -0.101154   -0.0132908   0.624736    -0.267317    -0.325239    -0.127517    0.0398754
  0.357907    0.464027     0.204614   -0.414424    -0.781244     0.152586    -0.462       -0.321598    0.179306    0.116253    0.254165    -0.349777     0.69402     0.674709    -0.110847   -0.174173    -0.0294766   0.324003    0.112464    -0.0902471   0.634963    0.242924    -0.109679    -0.0311252   -0.101643    0.215191
  0.350403    0.734486    -0.354119   -0.0370981    0.117933     0.432717    -0.306631     0.109855    0.28822     0.407434   -0.396685     0.114893     0.527556   -0.41606      0.465135   -0.254648    -0.198889   -0.561055   -0.451094     0.0090423   0.125405   -0.197841    -0.367384     0.0500919   -0.386281   -0.132665
  0.470436    0.0220501    0.684927   -0.0470613   -0.260428     0.798464     0.0177504   -0.554859    0.345152   -0.0836047   0.718509     0.63111     -0.130872   -0.0770238    0.481938    0.00270694  -0.465482    0.387725   -0.379933     0.111615   -0.719719    0.167141     0.211564    -0.165945    -0.518235   -0.677709
 -0.0648231   0.216685     0.631363   -0.311751    -0.314457     0.525029     0.628142    -0.17047    -0.839293   -0.160842    0.218352     0.473519    -0.028095    0.304246     0.0476716   0.947475    -0.360355    0.342219    0.0977647   -0.635453    0.381677   -0.679912    -0.491144     0.0453238    0.168772    0.440259
 -0.363386    0.396984     0.755376    0.262708    -0.353634    -0.373822     0.193334     0.369395   -0.363672   -0.503098   -0.0287352   -0.347645    -0.197054   -0.0740196   -0.40053     0.464212     0.384725    0.964705   -0.133123    -0.608245    0.212316    0.744977    -0.116813    -0.00787947  -0.430203   -0.347751
  0.74226     0.706214     0.0932865   0.69738     -0.29341      0.33442      0.0439634    0.791686   -0.238653    0.139599    0.235552    -0.217207    -0.248655    0.465388     0.0383317  -0.141229    -0.343017    0.394664    0.749433     0.387406   -0.134731   -0.0895571    0.317693    -0.126412    -0.0557792  -0.709983
 -0.348016    0.18048     -0.321309   -0.285556     0.319369    -0.234301    -0.0268651    0.106716   -0.0236945  -0.68239    -0.798418    -0.127588    -0.640711   -0.128444     0.417909   -0.11118      0.170853   -0.305833   -0.125297     0.0562578   0.151356   -0.273905    -0.789091    -0.0623114   -0.224778   -0.098852
  0.284171   -0.0902717   -0.191797    0.434437     0.0718003   -0.546515     0.107631    -0.545765   -0.247574   -0.275638    0.143496    -0.446562     0.205033   -0.145527     0.0919058   0.271183    -0.267993    0.603509   -0.138401    -0.434206   -0.938413   -0.00860228   0.385481     0.121556    -0.241418   -0.378126
  0.418011    0.256777     0.441786   -0.23247     -0.180875     0.51006      0.168989    -0.0944228  -0.938565   -0.474004   -0.314821    -0.287308    -0.116813    0.0963682    0.0384161   0.243228     0.311794    0.0670947  -0.11013      0.664924    0.159736    0.197103    -0.453505    -0.056076     0.0620438   0.274331
 -0.107825   -0.53354     -0.423962    0.505933     0.908074    -0.00406578  -0.232179     0.0511328   0.362514    0.752888   -0.202206    -0.0789081   -0.301065   -0.16387     -0.243888    0.0674694    0.506678   -0.135083   -0.587481    -0.214537    0.231572    0.224583    -0.0780214    0.483294    -0.354079    0.0670301
  0.260804   -0.00897375  -0.111068    0.00578454   0.0951065    0.259666     0.262788    -0.217397   -0.168547    0.016503   -0.0705381    0.21416      0.0470856   0.014155    -0.0288102   0.200512    -0.118276   -0.0376207  -0.0700369    0.0943953  -0.0588049  -0.103017     0.0563238   -0.122194     0.111243   -0.121744[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408830
[ Info: iteration 2, average log likelihood -1.408817
[ Info: iteration 3, average log likelihood -1.408804
[ Info: iteration 4, average log likelihood -1.408791
[ Info: iteration 5, average log likelihood -1.408778
[ Info: iteration 6, average log likelihood -1.408765
[ Info: iteration 7, average log likelihood -1.408753
[ Info: iteration 8, average log likelihood -1.408741
[ Info: iteration 9, average log likelihood -1.408729
[ Info: iteration 10, average log likelihood -1.408718
┌ Info: EM with 100000 data points 10 iterations avll -1.408718
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
