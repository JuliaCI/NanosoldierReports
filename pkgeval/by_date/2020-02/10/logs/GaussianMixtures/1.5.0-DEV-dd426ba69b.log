Julia Version 1.5.0-DEV.255
Commit dd426ba69b (2020-02-09 18:28 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed SortingAlgorithms ── v0.3.1
  Installed LegacyStrings ────── v0.4.1
  Installed GaussianMixtures ─── v0.3.0
  Installed FillArrays ───────── v0.8.4
  Installed ScikitLearnBase ──── v0.5.0
  Installed StatsFuns ────────── v0.9.3
  Installed StatsBase ────────── v0.32.0
  Installed Compat ───────────── v2.2.0
  Installed CMake ────────────── v1.1.2
  Installed Parameters ───────── v0.12.0
  Installed Arpack_jll ───────── v3.5.0+2
  Installed URIParser ────────── v0.4.0
  Installed Distances ────────── v0.8.2
  Installed SpecialFunctions ─── v0.9.0
  Installed HDF5 ─────────────── v0.12.5
  Installed Missings ─────────── v0.4.3
  Installed DataAPI ──────────── v1.1.0
  Installed Blosc ────────────── v0.5.1
  Installed CMakeWrapper ─────── v0.2.3
  Installed Arpack ───────────── v0.4.0
  Installed QuadGK ───────────── v2.3.1
  Installed Clustering ───────── v0.13.3
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed BinaryProvider ───── v0.5.8
  Installed OrderedCollections ─ v1.1.0
  Installed PDMats ───────────── v0.9.11
  Installed Rmath ────────────── v0.6.0
  Installed JLD ──────────────── v0.9.2
  Installed BinDeps ──────────── v1.0.0
  Installed NearestNeighbors ─── v0.4.4
  Installed DataStructures ───── v0.17.9
  Installed StaticArrays ─────── v0.12.1
  Installed FileIO ───────────── v1.2.2
  Installed Distributions ────── v0.22.4
#####                                                                      7.0%######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                                                                                                    0.5%#######                                                                   10.4%###################                                                       26.8%##################################                                        48.3%####################################################                      73.0%######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.2
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_WtHwYj/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.2
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -890297.4538285234, [98285.63781162573, 1714.3621883742812], [-2220.0494064614822 2851.22473773876 -2518.761038824817; 2270.7971316028465 -2296.6350499095756 2702.9948415428207], [[95813.05806232081 3100.115698181882 -3530.375428853365; 3100.1156981818826 95555.09074072867 3174.3717805453207; -3530.375428853365 3174.3717805453207 94802.63124283683], [4155.676730590721 -2635.1448726954613 3082.0165243885563; -2635.1448726954613 4304.610344051222 -3015.0783851770193; 3082.0165243885563 -3015.078385177019 5440.704347523163]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.294000e+03
      1       8.754374e+02      -4.185624e+02 |        2
      2       8.587341e+02      -1.670338e+01 |        0
      3       8.587341e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 858.7340664377357)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.082981
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.827095
[ Info: iteration 2, lowerbound -3.678706
[ Info: iteration 3, lowerbound -3.509387
[ Info: iteration 4, lowerbound -3.305127
[ Info: iteration 5, lowerbound -3.092445
[ Info: iteration 6, lowerbound -2.905147
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.763649
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.657348
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.587671
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.524536
[ Info: iteration 11, lowerbound -2.469281
[ Info: iteration 12, lowerbound -2.426897
[ Info: iteration 13, lowerbound -2.390087
[ Info: iteration 14, lowerbound -2.357858
[ Info: iteration 15, lowerbound -2.330695
[ Info: iteration 16, lowerbound -2.312470
[ Info: iteration 17, lowerbound -2.307566
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.302921
[ Info: iteration 19, lowerbound -2.299260
[ Info: iteration 20, lowerbound -2.299256
[ Info: iteration 21, lowerbound -2.299254
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Mon Feb 10 21:26:53 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Mon Feb 10 21:27:01 2020: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Mon Feb 10 21:27:04 2020: EM with 272 data points 0 iterations avll -2.082981
5.8 data points per parameter
, Mon Feb 10 21:27:06 2020: GMM converted to Variational GMM
, Mon Feb 10 21:27:15 2020: iteration 1, lowerbound -3.827095
, Mon Feb 10 21:27:15 2020: iteration 2, lowerbound -3.678706
, Mon Feb 10 21:27:15 2020: iteration 3, lowerbound -3.509387
, Mon Feb 10 21:27:15 2020: iteration 4, lowerbound -3.305127
, Mon Feb 10 21:27:15 2020: iteration 5, lowerbound -3.092445
, Mon Feb 10 21:27:15 2020: iteration 6, lowerbound -2.905147
, Mon Feb 10 21:27:15 2020: dropping number of Gaussions to 7
, Mon Feb 10 21:27:15 2020: iteration 7, lowerbound -2.763649
, Mon Feb 10 21:27:15 2020: dropping number of Gaussions to 6
, Mon Feb 10 21:27:15 2020: iteration 8, lowerbound -2.657348
, Mon Feb 10 21:27:15 2020: dropping number of Gaussions to 5
, Mon Feb 10 21:27:15 2020: iteration 9, lowerbound -2.587671
, Mon Feb 10 21:27:15 2020: dropping number of Gaussions to 3
, Mon Feb 10 21:27:15 2020: iteration 10, lowerbound -2.524536
, Mon Feb 10 21:27:15 2020: iteration 11, lowerbound -2.469281
, Mon Feb 10 21:27:15 2020: iteration 12, lowerbound -2.426897
, Mon Feb 10 21:27:15 2020: iteration 13, lowerbound -2.390087
, Mon Feb 10 21:27:15 2020: iteration 14, lowerbound -2.357858
, Mon Feb 10 21:27:15 2020: iteration 15, lowerbound -2.330695
, Mon Feb 10 21:27:15 2020: iteration 16, lowerbound -2.312470
, Mon Feb 10 21:27:15 2020: iteration 17, lowerbound -2.307566
, Mon Feb 10 21:27:15 2020: dropping number of Gaussions to 2
, Mon Feb 10 21:27:15 2020: iteration 18, lowerbound -2.302921
, Mon Feb 10 21:27:15 2020: iteration 19, lowerbound -2.299260
, Mon Feb 10 21:27:15 2020: iteration 20, lowerbound -2.299256
, Mon Feb 10 21:27:15 2020: iteration 21, lowerbound -2.299254
, Mon Feb 10 21:27:15 2020: iteration 22, lowerbound -2.299254
, Mon Feb 10 21:27:15 2020: iteration 23, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 24, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 25, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 26, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 27, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 28, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 29, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 30, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 31, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 32, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 33, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 34, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 35, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 36, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 37, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 38, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 39, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 40, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 41, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 42, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 43, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 44, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 45, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 46, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 47, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 48, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 49, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: iteration 50, lowerbound -2.299253
, Mon Feb 10 21:27:15 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398606, 178.04509222601396]
β = [95.95490777398606, 178.04509222601396]
m = [2.000229257775369 53.85198717246127; 4.250300733269909 79.28686694436183]
ν = [97.95490777398606, 180.04509222601396]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763611948396 -0.008953123827345949; 0.0 0.012748664777409166], [0.18404155547484816 -0.007644049042327562; 0.0 0.00858170516633351]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000003
avll from stats: -0.9953667819928778
avll from llpg:  -0.9953667819928801
avll direct:     -0.9953667819928801
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9855633754800611
avll from llpg:  -0.9855633754800608
avll direct:     -0.9855633754800608
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
  0.1067        0.0740086   -0.0835363    -0.00469024   0.110039    -0.180039      0.0298932    0.105654     0.0315573    -0.0182382   -0.0199437    0.185533      0.106655     0.0952562  -0.0646369    0.0809433   0.0060152   -0.0616021   -0.00975949  -0.0607698    0.0163265     0.057888    -0.0727487  -0.100522     0.0805729    0.0026685
 -0.0658865    -0.0314128   -0.144838     -0.0320399   -0.044516    -0.0698761     0.0576375    0.0759787    0.169854      0.10286      0.0206252    0.0332196     0.0177117    0.23119    -0.0393005    0.10674     0.221945    -0.0922005   -0.129876    -0.0648795    0.0498438    -0.09324      0.0582143  -0.0522868   -0.123739     0.101311
  0.0316647     0.0645427   -0.275429      0.108639     0.125336     0.0632675    -0.0243361    0.00937923   0.0699619     0.0855664   -0.0962509   -0.0118174     0.0897757   -0.0231347  -0.0581619    0.0768367   0.182367    -0.141906    -0.0627791    0.0871887   -0.0812085    -0.044912    -0.0267676   0.0646113    0.175607    -0.0493857
 -0.0460534     0.0409467    0.0572069     0.0918656   -0.0545093    0.101873      0.17438      0.0322268   -0.177291     -0.00538266  -0.226047     0.139468      0.0224375    0.11592    -0.140837     0.0128649  -0.0604901    0.16897      0.104373     0.0638749    0.00453894    0.012042    -0.170534   -4.23338e-5   0.327946    -0.159244
 -0.000322267  -0.228018    -0.0796921    -0.140519    -0.00205585  -0.193893     -0.0472863   -0.0555799    0.0720949    -0.204859     0.0683564   -0.217714     -0.110557    -0.196208   -0.219024    -0.128182   -0.00508217  -0.0980778    0.0497214   -0.079036     0.0197646     0.0661889    0.0963746   0.197369    -0.0296956    0.063442
 -0.0293116    -0.0165849    0.0695088     0.0429009    0.178265     0.12291      -0.0879528   -0.0208355   -0.0805333     0.0727993    0.0256793    0.0409621     0.0454849   -0.0947408  -0.0581989   -0.169023    0.0289985    0.115198     0.0380616   -0.124914     0.00960887   -0.109269    -0.0123548  -0.157041     0.12093      0.0273883
  0.010524      0.151893     0.0604351    -0.00454665  -0.011599     0.000923358  -0.0616326   -0.0437807    0.0220189    -0.19358     -0.0782972    0.0358767     0.148627    -0.0546847  -0.0491988    0.110947    0.0344999   -0.0457764    0.00636314  -0.0753336   -0.150471     -0.01539     -0.130813   -0.021276     0.199382    -0.0425704
 -0.230728      0.110827    -0.0160599    -0.0624554    0.0326185    0.0909429    -0.0211755   -0.203516    -0.0334834     0.103076     0.00283712  -0.12465       0.00548895  -0.108731    0.0488582    0.0642502  -0.0203385   -0.070786    -0.0901538    0.0358191    0.0842237     0.0751188    0.0564549   0.0284976   -0.00510536   0.0921118
 -0.137987      0.130058    -0.0740968     0.193485    -0.015977     0.187865      0.0926162    0.0663351   -0.0688743     0.120222    -0.0517418   -0.179183     -0.018297    -0.0158254   0.0191463    0.0339072   0.257869    -0.184793     0.0699032   -0.0443401    0.16566       0.131122    -0.0186811  -0.163058     0.0743473   -0.0911191
  0.00238005    0.0109426    0.0778792     0.0136177    0.167259     0.107154      0.0365024   -0.190486     0.0222379    -0.00322584  -0.018659    -0.046297     -0.0843475   -0.156323    0.0867589    0.0346583   0.0667041   -0.0229322    0.10158      0.024602    -0.149451     -0.0135062    0.138199   -0.0272006    0.0889948   -0.00450054
 -0.0298258    -0.0219331   -0.0751671     0.0489925    0.0384743    0.090123      0.0893684   -0.0192815   -0.0553834    -0.0158897    0.038098     0.0326389     0.0986871    0.0429407   0.00793442   0.109966    0.0362082   -0.0521489   -0.0355254   -0.193398     0.123087     -0.00249313  -0.0503868   0.123683     0.0812565    0.00612507
 -0.0219243    -0.0950237    0.0118498    -0.205447     0.0914182   -0.0260679    -0.0516945   -0.326918     0.0338443    -0.116764     0.171517     0.132089     -0.00218188  -0.0954246   0.121979    -0.0835237   0.0387211    0.215241    -0.112503     0.0390653   -0.0440744     0.0836253   -0.0432426  -0.0500103    0.0454564    0.0437236
  0.0799639     0.112771     0.162339      0.078784    -0.0260702   -0.131653     -0.133382     0.0850092    0.0249692     0.00963872   0.157031    -0.0430317    -0.0831484    0.0358647   0.0349625   -0.0315689  -0.0375059    0.174061    -0.0475786    0.105373     0.130402      0.0786617    0.119236   -0.0889202   -0.013775    -0.00724949
 -0.105774      0.0372383    0.011873      0.109515     0.0552696    0.0520688    -0.0335684   -0.021237    -0.00893383    0.0913214    0.0628287    0.0511525     0.031375     0.016021   -0.0211751   -0.13937    -0.0161144   -0.137468     0.0399352    0.0921012   -0.06311      -0.0495187    0.160841    0.0040996    0.10313     -0.273444
  0.00242302   -0.0606947   -0.20049      -0.0163134   -0.146715    -0.0775981    -0.0214192   -0.0345988   -0.0453046    -0.106459     0.019538    -0.228633      0.114068     0.116782   -0.0222428    0.0216104  -0.0509299   -0.026764     0.0730427    0.00772727  -0.0377616    -0.0556949    0.0308835   0.0595081   -0.0453223    0.141362
 -0.0215882    -0.0381403    0.0630118     0.13448      0.138826    -0.0260412    -0.0151807   -0.0200333    0.00746139   -0.057954     0.00985063   0.0167059     0.0635329   -0.0171857   0.0286717   -0.0409688  -0.303255     0.153507    -0.0558866    0.0313183    0.0460463     0.22524     -0.112974   -0.0587967   -0.151029    -0.104222
 -0.112174      0.0424707   -0.127414      0.0870479   -0.0330743   -0.169954      0.0463956    0.0667897    0.0608805    -0.0560573   -0.0647652    0.0883731     0.171697     0.118105    0.0318012    0.0710279   0.077225     0.0464907    0.00150229   0.174482    -0.110426      0.205968    -0.010698   -0.0752174   -0.0601513    0.149925
  0.0560116     0.078442     0.0335585     0.0522964    0.0284209   -0.0539297     0.109284    -0.146045    -0.140598     -0.0358948    0.0378774   -0.175846      0.211168    -0.0536531   0.0282739   -0.119154   -0.143477     0.00133896   0.112339     0.0649294    0.0588969    -0.0374437   -0.0141338  -0.00641464  -0.0282069    0.0299584
 -0.0376982    -0.0852805   -0.195032     -0.11327     -0.0270289    0.0109765     0.229651    -0.0484516   -0.144277     -0.129468    -0.117027    -0.0189158    -0.0246051    0.177218   -0.0281845   -0.0934209   0.102477    -0.11428     -0.0585804   -0.188502    -0.0857251     0.133108     0.094109   -0.0452923    0.100325     0.0055415
 -0.0938147     0.00958651  -0.0790253    -0.004495    -0.0866503    0.0265056    -0.0522084   -0.0914602    0.140255     -0.0743944    0.00109753  -0.0175632     0.0541054   -0.0538637   0.0641877   -0.231421   -0.0455215   -0.132823     0.0928999   -0.0550986   -0.181377     -0.151485     0.0180947  -0.0501753    0.00347019   0.0253343
 -0.237844      0.0949336   -0.0727742    -0.0531241    0.0927074    0.186173     -0.0986629   -0.124161     0.00670821    0.0162521   -0.0863708    0.07463       0.0191867    0.153749    0.145215    -0.0201493   0.115389    -0.0365097   -0.0551218   -0.0305368   -0.000155838  -0.0566151   -0.174936    0.10956      0.00275585  -0.08921
 -0.0959953     0.0136794    0.0314458     0.0165958    0.00805461   0.227157     -0.0559045    0.219656    -0.15909       0.171013     0.173494     0.0425828     0.0679741   -0.0607188   0.292824     0.0374695   0.170964     0.0954451   -0.0583249   -0.00679578   0.0467797     0.0372946    0.0886979  -0.107856    -0.146768     0.110703
  0.0811437     0.119042     0.0928898     0.00661083  -0.0275062   -0.215794      0.0376149   -0.061565    -0.0798613    -0.131983     0.128275    -0.0819956    -0.0811513    0.177942   -0.0269297    0.0821003   0.131013     0.108248     0.125458    -0.0980963    0.0554289     0.0201358   -0.0622791   0.128548    -0.0741573    0.0828281
  0.00390117   -0.0090917   -0.161232     -0.00285751  -0.0490223    0.143826      0.0227602    0.224407    -0.078434     -0.0116882   -0.167435     0.000653801   0.0437181   -0.05806    -0.0920948   -0.104265    0.118118     0.00492261   0.134849    -0.0316435    0.137227      0.0427482    0.0977189  -0.148307    -0.146938     0.204448
 -0.0579972     0.227649    -0.105632      0.0218756   -0.0603694    0.26649      -0.086638    -0.165245    -0.0948455     0.0534993   -0.0993748   -0.192517      0.0370351   -0.13949     0.0600528    0.0612012   0.0980339   -0.212797     0.200442     0.0210453   -0.147373      0.0223019    0.140791   -0.0750485    0.145721    -0.11073
 -0.0681584     0.0553996    0.00125634   -0.201426    -0.239594    -0.0813252     0.217111     0.0612269   -0.051547      0.00435821  -0.0552577    0.0351887     0.0610468   -0.0303379  -0.0709777    0.0135877  -0.00815894   0.127997     0.150931    -0.0975302   -0.130776      0.00514737   0.0748678   0.108134     0.124063    -0.0513928
 -0.0724873    -0.062329    -0.0828013    -0.018717     0.0478239   -0.0305102     0.0628809    0.0661084    0.0208566     0.128211     0.0179313   -0.119375      0.0837898   -0.0706498  -0.118874    -0.133067    0.143128    -0.104668     0.0892097    0.0244234    0.0298231    -0.146172     0.0340501   0.140244     0.105272    -0.140059
 -0.0122164     0.0260666   -0.236224      0.0511125   -0.157225     0.0644145    -0.0124457    0.0910549    0.142421     -0.0354133   -0.111154     0.178718     -0.118859    -0.102304   -0.0433345   -0.0781654  -0.0556762   -0.114192     0.0747844   -0.0494822   -0.0435647     0.157669    -0.0487457  -0.0642917    0.0778565   -0.0306718
 -0.0665487    -0.0210174   -0.00797531   -0.137011     0.0848402   -0.0172399    -0.073846    -0.0206292   -0.24719      -0.0799167    0.125993     0.0636937    -0.0542473    0.137101   -0.103594    -0.141592   -0.00796312  -0.0313205   -0.087825    -0.0741189    0.180258     -0.0295312   -0.184145   -0.0170139    0.0162812   -0.00286001
  0.0568991     0.0931247   -0.0783301    -0.155334    -0.0421546   -0.0451947    -0.00634125  -0.0686839    0.016536      0.110366     0.00889842  -0.117623     -0.0587135    0.0569492  -0.132072     0.135108    0.139399     0.0365643   -0.0616776   -0.10652      0.0139244     0.128653    -0.0359901  -0.0389318   -0.0749376    0.0180789
 -0.0493836     0.143161     0.000797878  -0.243881    -0.0275079   -0.191832      0.11943     -0.0692187    0.0491009     0.0303616    0.104721    -0.00511211   -0.0870749   -0.0403534   0.0712275    0.132075   -0.0336837   -0.035334     0.128143    -0.0636625    0.20633      -0.0179471   -0.194613   -0.0441122   -0.12158      0.0389032
 -0.0252728     0.163237     0.070033      0.093797    -0.0131919    0.075753     -0.0285332   -0.0276934    0.000919356   0.129983    -0.0587275   -0.176802     -0.00739507  -0.036714   -0.264276     0.0166104  -0.0586399   -0.104382    -0.106624    -0.0410059    0.0957236    -0.0511339    0.136541   -0.0872342   -0.128742     0.0935953kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.416127323502983
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416184
[ Info: iteration 2, average log likelihood -1.416129
[ Info: iteration 3, average log likelihood -1.415654
[ Info: iteration 4, average log likelihood -1.409468
[ Info: iteration 5, average log likelihood -1.394128
[ Info: iteration 6, average log likelihood -1.386510
[ Info: iteration 7, average log likelihood -1.384819
[ Info: iteration 8, average log likelihood -1.384281
[ Info: iteration 9, average log likelihood -1.384063
[ Info: iteration 10, average log likelihood -1.383965
[ Info: iteration 11, average log likelihood -1.383911
[ Info: iteration 12, average log likelihood -1.383875
[ Info: iteration 13, average log likelihood -1.383846
[ Info: iteration 14, average log likelihood -1.383820
[ Info: iteration 15, average log likelihood -1.383793
[ Info: iteration 16, average log likelihood -1.383766
[ Info: iteration 17, average log likelihood -1.383735
[ Info: iteration 18, average log likelihood -1.383700
[ Info: iteration 19, average log likelihood -1.383658
[ Info: iteration 20, average log likelihood -1.383608
[ Info: iteration 21, average log likelihood -1.383546
[ Info: iteration 22, average log likelihood -1.383469
[ Info: iteration 23, average log likelihood -1.383372
[ Info: iteration 24, average log likelihood -1.383252
[ Info: iteration 25, average log likelihood -1.383108
[ Info: iteration 26, average log likelihood -1.382941
[ Info: iteration 27, average log likelihood -1.382745
[ Info: iteration 28, average log likelihood -1.382513
[ Info: iteration 29, average log likelihood -1.382236
[ Info: iteration 30, average log likelihood -1.381932
[ Info: iteration 31, average log likelihood -1.381601
[ Info: iteration 32, average log likelihood -1.381233
[ Info: iteration 33, average log likelihood -1.380815
[ Info: iteration 34, average log likelihood -1.380419
[ Info: iteration 35, average log likelihood -1.380052
[ Info: iteration 36, average log likelihood -1.379765
[ Info: iteration 37, average log likelihood -1.379551
[ Info: iteration 38, average log likelihood -1.379408
[ Info: iteration 39, average log likelihood -1.379318
[ Info: iteration 40, average log likelihood -1.379260
[ Info: iteration 41, average log likelihood -1.379221
[ Info: iteration 42, average log likelihood -1.379192
[ Info: iteration 43, average log likelihood -1.379171
[ Info: iteration 44, average log likelihood -1.379154
[ Info: iteration 45, average log likelihood -1.379139
[ Info: iteration 46, average log likelihood -1.379126
[ Info: iteration 47, average log likelihood -1.379114
[ Info: iteration 48, average log likelihood -1.379101
[ Info: iteration 49, average log likelihood -1.379088
[ Info: iteration 50, average log likelihood -1.379074
┌ Info: EM with 100000 data points 50 iterations avll -1.379074
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.416183885547699
│     -1.4161293349916302
│      ⋮
└     -1.379074228923432
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.379147
[ Info: iteration 2, average log likelihood -1.379033
[ Info: iteration 3, average log likelihood -1.378428
[ Info: iteration 4, average log likelihood -1.372530
[ Info: iteration 5, average log likelihood -1.357529
[ Info: iteration 6, average log likelihood -1.348326
[ Info: iteration 7, average log likelihood -1.345434
[ Info: iteration 8, average log likelihood -1.344099
[ Info: iteration 9, average log likelihood -1.343328
[ Info: iteration 10, average log likelihood -1.342871
[ Info: iteration 11, average log likelihood -1.342562
[ Info: iteration 12, average log likelihood -1.342312
[ Info: iteration 13, average log likelihood -1.342086
[ Info: iteration 14, average log likelihood -1.341877
[ Info: iteration 15, average log likelihood -1.341721
[ Info: iteration 16, average log likelihood -1.341605
[ Info: iteration 17, average log likelihood -1.341505
[ Info: iteration 18, average log likelihood -1.341404
[ Info: iteration 19, average log likelihood -1.341290
[ Info: iteration 20, average log likelihood -1.341150
[ Info: iteration 21, average log likelihood -1.340971
[ Info: iteration 22, average log likelihood -1.340740
[ Info: iteration 23, average log likelihood -1.340473
[ Info: iteration 24, average log likelihood -1.340208
[ Info: iteration 25, average log likelihood -1.339966
[ Info: iteration 26, average log likelihood -1.339747
[ Info: iteration 27, average log likelihood -1.339528
[ Info: iteration 28, average log likelihood -1.339234
[ Info: iteration 29, average log likelihood -1.338760
[ Info: iteration 30, average log likelihood -1.338088
[ Info: iteration 31, average log likelihood -1.337389
[ Info: iteration 32, average log likelihood -1.336818
[ Info: iteration 33, average log likelihood -1.336408
[ Info: iteration 34, average log likelihood -1.336150
[ Info: iteration 35, average log likelihood -1.335993
[ Info: iteration 36, average log likelihood -1.335897
[ Info: iteration 37, average log likelihood -1.335838
[ Info: iteration 38, average log likelihood -1.335801
[ Info: iteration 39, average log likelihood -1.335777
[ Info: iteration 40, average log likelihood -1.335760
[ Info: iteration 41, average log likelihood -1.335748
[ Info: iteration 42, average log likelihood -1.335739
[ Info: iteration 43, average log likelihood -1.335732
[ Info: iteration 44, average log likelihood -1.335726
[ Info: iteration 45, average log likelihood -1.335721
[ Info: iteration 46, average log likelihood -1.335716
[ Info: iteration 47, average log likelihood -1.335712
[ Info: iteration 48, average log likelihood -1.335707
[ Info: iteration 49, average log likelihood -1.335703
[ Info: iteration 50, average log likelihood -1.335699
┌ Info: EM with 100000 data points 50 iterations avll -1.335699
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3791473863778347
│     -1.3790329101069734
│      ⋮
└     -1.335698574498897
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.335866
[ Info: iteration 2, average log likelihood -1.335685
[ Info: iteration 3, average log likelihood -1.334885
[ Info: iteration 4, average log likelihood -1.328767
[ Info: iteration 5, average log likelihood -1.311970
[ Info: iteration 6, average log likelihood -1.297324
[ Info: iteration 7, average log likelihood -1.290992
[ Info: iteration 8, average log likelihood -1.287589
[ Info: iteration 9, average log likelihood -1.285429
[ Info: iteration 10, average log likelihood -1.284103
[ Info: iteration 11, average log likelihood -1.283294
[ Info: iteration 12, average log likelihood -1.282759
[ Info: iteration 13, average log likelihood -1.282355
[ Info: iteration 14, average log likelihood -1.282000
[ Info: iteration 15, average log likelihood -1.281658
[ Info: iteration 16, average log likelihood -1.281334
[ Info: iteration 17, average log likelihood -1.281047
[ Info: iteration 18, average log likelihood -1.280795
[ Info: iteration 19, average log likelihood -1.280570
[ Info: iteration 20, average log likelihood -1.280355
[ Info: iteration 21, average log likelihood -1.280139
[ Info: iteration 22, average log likelihood -1.279915
[ Info: iteration 23, average log likelihood -1.279683
[ Info: iteration 24, average log likelihood -1.279451
[ Info: iteration 25, average log likelihood -1.279223
[ Info: iteration 26, average log likelihood -1.279008
[ Info: iteration 27, average log likelihood -1.278811
[ Info: iteration 28, average log likelihood -1.278633
[ Info: iteration 29, average log likelihood -1.278477
[ Info: iteration 30, average log likelihood -1.278336
[ Info: iteration 31, average log likelihood -1.278206
[ Info: iteration 32, average log likelihood -1.278083
[ Info: iteration 33, average log likelihood -1.277968
[ Info: iteration 34, average log likelihood -1.277860
[ Info: iteration 35, average log likelihood -1.277752
[ Info: iteration 36, average log likelihood -1.277645
[ Info: iteration 37, average log likelihood -1.277540
[ Info: iteration 38, average log likelihood -1.277437
[ Info: iteration 39, average log likelihood -1.277340
[ Info: iteration 40, average log likelihood -1.277244
[ Info: iteration 41, average log likelihood -1.277150
[ Info: iteration 42, average log likelihood -1.277063
[ Info: iteration 43, average log likelihood -1.276986
[ Info: iteration 44, average log likelihood -1.276916
[ Info: iteration 45, average log likelihood -1.276852
[ Info: iteration 46, average log likelihood -1.276794
[ Info: iteration 47, average log likelihood -1.276746
[ Info: iteration 48, average log likelihood -1.276706
[ Info: iteration 49, average log likelihood -1.276674
[ Info: iteration 50, average log likelihood -1.276650
┌ Info: EM with 100000 data points 50 iterations avll -1.276650
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3358655868119997
│     -1.335685373148971
│      ⋮
└     -1.2766504225929496
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.276863
[ Info: iteration 2, average log likelihood -1.276610
[ Info: iteration 3, average log likelihood -1.275941
[ Info: iteration 4, average log likelihood -1.267899
[ Info: iteration 5, average log likelihood -1.231226
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.200115
[ Info: iteration 7, average log likelihood -1.200211
[ Info: iteration 8, average log likelihood -1.187692
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.179393
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.188256
[ Info: iteration 11, average log likelihood -1.199757
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.184925
[ Info: iteration 13, average log likelihood -1.192338
[ Info: iteration 14, average log likelihood -1.183375
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.177427
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.188144
[ Info: iteration 17, average log likelihood -1.191902
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.181731
[ Info: iteration 19, average log likelihood -1.190326
[ Info: iteration 20, average log likelihood -1.181519
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.175330
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.185566
[ Info: iteration 23, average log likelihood -1.188620
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.177580
[ Info: iteration 25, average log likelihood -1.185704
[ Info: iteration 26, average log likelihood -1.176922
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.171150
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.181827
[ Info: iteration 29, average log likelihood -1.186015
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.176173
[ Info: iteration 31, average log likelihood -1.184324
[ Info: iteration 32, average log likelihood -1.175927
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.170401
[ Info: iteration 34, average log likelihood -1.190901
[ Info: iteration 35, average log likelihood -1.179169
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.172486
[ Info: iteration 37, average log likelihood -1.181172
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.173915
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.180236
[ Info: iteration 40, average log likelihood -1.185493
[ Info: iteration 41, average log likelihood -1.176619
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.170625
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.180222
[ Info: iteration 44, average log likelihood -1.184389
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.174947
[ Info: iteration 46, average log likelihood -1.182962
[ Info: iteration 47, average log likelihood -1.174826
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.169727
[ Info: iteration 49, average log likelihood -1.190751
[ Info: iteration 50, average log likelihood -1.179042
┌ Info: EM with 100000 data points 50 iterations avll -1.179042
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2768633510998522
│     -1.276609887560214
│      ⋮
└     -1.1790423635087255
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.172565
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.170374
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.166638
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     15
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.140141
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     15
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.090487
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     10
│     13
│     15
│     17
│     18
│     21
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.077786
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     15
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.077831
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     15
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.071128
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     13
│     15
│     17
│     18
│      ⋮
│     21
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.068000
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.091156
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      6
│      9
│     10
│     15
│      ⋮
│     21
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.053402
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.089870
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     15
│     17
│     18
│     19
│     20
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.069775
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     15
│     21
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.061375
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│     13
│     15
│     17
│      ⋮
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.063268
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.086027
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     10
│     15
│     17
│      ⋮
│     21
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.046019
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     13
│     15
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.074406
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│     15
│     17
│     18
│      ⋮
│     21
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.066547
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     15
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.072579
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     13
│     15
│     17
│     18
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.059293
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     21
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.072280
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│      9
│     10
│     15
│      ⋮
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.056725
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.079158
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     15
│     17
│     18
│     19
│     20
│     21
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.062712
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│      9
│     10
│     15
│     26
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.059898
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     13
│     15
│     17
│     18
│      ⋮
│     21
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.069729
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.086815
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     10
│     15
│     17
│      ⋮
│     21
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.047439
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     13
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.074641
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     15
│     17
│     18
│     19
│     20
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.071348
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     15
│     21
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.056531
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     13
│     15
│     17
│     18
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.063438
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.075975
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     10
│     15
│     17
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.052565
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.082049
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     15
│     17
│     18
│     19
│     20
│     21
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.063194
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      9
│     10
│     15
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.057261
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     13
│     15
│     17
│     18
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.065301
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.089658
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     10
│     15
│     17
│      ⋮
│     21
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.048281
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     13
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.074787
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     15
│     17
│     18
│     19
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.070706
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     15
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.063778
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     13
│     15
│     17
│     18
│      ⋮
│     21
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.057370
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.082386
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      9
│     10
│     15
│     17
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.056089
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.081890
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│     15
│     17
│     18
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.062476
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.075054
┌ Info: EM with 100000 data points 50 iterations avll -1.075054
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1725650965908678
│     -1.1703742182960153
│      ⋮
└     -1.0750541955225301
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.416127323502983
│     -1.416183885547699
│     -1.4161293349916302
│     -1.4156540341829154
│      ⋮
│     -1.0818895734405343
│     -1.0624763677191829
└     -1.0750541955225301
32×26 Array{Float64,2}:
 -0.0365978   -0.0415837  -0.0624348   -0.0801952    0.0553181    0.0192585    0.0282279   -0.0347028   -0.16739     -0.0653837   0.0258323    0.0184529   -0.0112036    0.0800054   -0.0665228   -0.149853    0.0346715   -0.0287065    -0.0357909  -0.119672     0.060312      0.00255452  -0.047491    -0.0432978    0.0610429     0.00666505
  0.0506554    0.139976    0.105834     0.0261141   -0.0186731   -0.0701206   -0.0817403    0.0160199    0.0168905   -0.109728    0.0511024   -0.00224611   0.0305998   -0.00897403  -0.00995199   0.0448096  -0.00478047   0.0648436    -0.0239981   0.0131578    0.00834379    0.0380835   -0.0382917   -0.0295677    0.107531     -0.0270684
 -0.00109548  -0.0311079   0.00318008  -0.0195774    0.00954269  -0.00997083  -0.0390533   -0.0479553    0.042158    -0.0154399   0.00479212  -0.186799    -0.0399557   -0.114593    -0.234132    -0.0517951  -0.0148955   -0.0892793    -0.0402343  -0.056434     0.0643144     0.0137718    0.126059     0.05445     -0.0646432     0.0769291
 -0.00440501   0.0261966   0.0544696    0.0142195    0.156112     0.0944373    0.0310532   -0.187843     0.0193815    0.0106016  -0.0349181   -0.0461979   -0.0808037   -0.151697     0.0801214    0.0306474   0.0677046   -0.0186715     0.0923835   0.0124377   -0.153482     -0.0181132    0.140425    -0.0214854    0.0969593     0.0103651
  0.0141342   -0.0410409  -0.193386    -0.016172    -0.139788    -0.0799972    0.00203678  -0.0694096   -0.0756162   -0.105594    0.0168982   -0.223783     0.13661      0.109454    -0.0196132    0.0443047  -0.0548309   -0.0210811    -0.0827008   0.0166887   -0.0455734    -0.0399746    0.0156411    0.0663169   -0.0446629     0.142501
 -0.0985935    0.0699346   0.00538474   0.104355     0.0329597    0.0456882   -0.0221473    0.0177295   -0.0097686    0.0691994   0.0621095    0.0444985    0.0356393    0.00305299  -0.0348765   -0.141978   -0.0501843   -0.139832      0.0160385   0.0573333   -0.0597248    -0.0528929    0.169322     0.00200389   0.117024     -0.263622
 -0.0842359    0.0604344  -0.0745978    0.00493377  -0.0581504    0.0055512   -0.00926     -0.185467     0.153995    -0.0221091  -0.012787    -0.0171637    0.0908009   -0.0597932    0.0652414   -0.338892   -0.0876598   -0.070606     -0.533857   -0.0372865   -0.119305     -0.149318    -0.0390914   -0.00618986   0.00401695    0.0233173
 -0.0994878   -0.0621885  -0.105708    -0.00137544  -0.122265     0.0649649   -0.0908211   -0.0323802    0.129298    -0.105166   -0.0358118   -0.0084161    0.0152512   -0.0390786    0.0572041   -0.117127   -0.00558589  -0.259679      0.817762   -0.104936    -0.358061     -0.174788     0.0745304   -0.111894     0.00922771    0.0246764
 -0.240103     0.0949829  -0.0820773   -0.0476476    0.094626     0.186769    -0.099322    -0.104476     0.0165464    0.0215467  -0.0874538    0.0726154   -0.0369924    0.155555     0.141808    -0.0184517   0.114565    -0.0443786    -0.0546609  -0.00831187   0.000272374  -0.0532117   -0.175878     0.101543     0.00149362   -0.0968775
  0.0732185    0.121781    0.0810747    0.0630298   -0.00267362  -0.207876     0.0326429   -0.0993251   -0.0703913   -0.128494    0.122482    -0.0819738   -0.0761249    0.178125    -0.0168442    0.0894056   0.133241     0.102446      0.123841   -0.0504891    0.0553886     0.0215982   -0.0853468    0.120479    -0.0753103     0.104925
 -0.0307659   -0.0216057  -0.0760413    0.0487964    0.0357089    0.125662     0.0854951   -0.0276734   -0.0575009   -0.0200747   0.0375737    0.0256005    0.0969386    0.0451298    0.0144115    0.0630131   0.0451343   -0.0597988    -0.0331028  -0.225886     0.131542     -0.00462461  -0.0496036    0.119933     0.0830329     0.00570023
  0.0269721    0.0663701  -0.251177     0.114755     0.0830628    0.0599029    0.00641584   0.0106218    0.0773564    0.0955667  -0.0957508   -0.00890829   0.0872524   -0.0287407   -0.0746919    0.0750981   0.188708    -0.14449      -0.0660242   0.0875451   -0.0786513    -0.0465378   -0.0251741    0.0645981    0.169598     -0.033544
 -0.00664015   0.0276969  -0.231358     0.0350052   -0.160388     0.0625536   -0.0258599    0.0672723    0.129634    -0.0536616  -0.110072     0.154456    -0.125739    -0.0934405   -0.037893    -0.0724012  -0.0517223   -0.111966      0.0569781  -0.0431779   -0.0470501     0.152331    -0.035026    -0.0687998    0.0627704    -0.0363577
 -0.148625     0.0335038  -0.13688      0.084434    -0.0244503   -0.170179     0.0355953    0.0590579    0.0364355   -0.050571   -0.0691785    0.0881438    0.188611     0.117734    -0.00276196   0.0929635   0.0720732    0.0549348    -0.0275893   0.172923    -0.107869      0.152812    -0.00708251  -0.0790275   -0.0637832     0.133175
 -0.227963     0.125103    0.0095764   -0.0620266    0.0263915    0.089588    -0.0210766   -0.244646    -0.0327612    0.103035   -0.0121551   -0.117551     0.00843542  -0.132043     0.0215453    0.0772436  -0.012615    -0.113672     -0.0737322   0.0641478    0.0922917     0.0716492    0.054026    -0.00832379   0.000247912   0.0840457
 -0.0625272    0.239544   -0.113731     0.01622     -0.0629886    0.265218    -0.0523324   -0.183551    -0.094298     0.0527192  -0.105125    -0.19304      0.0402171   -0.128299     0.0537543    0.0582742   0.0925811   -0.205522      0.194035    0.0532233   -0.115914      0.0214879    0.140833    -0.06692      0.128536     -0.0907918
 -0.0485699   -0.775191   -0.0771232    0.0073791   -0.0178948    0.148967    -0.00334459   0.23265     -0.0677096   -0.0170036  -0.156793     0.240083     0.351251    -0.103548    -0.0869927   -0.104322    0.0960317    0.181544      0.132966    0.119023     0.146651      0.051018     0.0840539   -0.145692     0.0306392     0.115497
  0.00748262   0.530309   -0.206802    -0.00685451  -0.0152813    0.163464     0.0222728    0.215283    -0.0657674    0.0129273  -0.160833    -0.169045    -0.192051    -0.00393063  -0.0918223   -0.104395    0.117384    -0.103339      0.132787   -0.124024     0.130399      0.0335222    0.111505    -0.145322    -0.207278      0.225501
 -0.0906484   -0.0350543   0.0514127    0.00116744  -0.00458865   0.216904    -0.0644812    0.232713    -0.159361     0.160724    0.260076     0.0603906    0.0636096   -0.0591323    0.302643     0.02123     0.18497      0.101432     -0.0714533  -0.0175543    0.0386656     0.0346616    0.0915687   -0.105079    -0.135445      0.116226
 -0.1351       0.153077   -0.0810354    0.190185    -0.0199581    0.138516     0.0779663    0.0643612   -0.0718754    0.113586   -0.0678197   -0.204875    -0.0125732   -0.0181326    0.0184248    0.0269431   0.260519    -0.16695       0.051863   -0.0223299    0.165402      0.132131    -0.0125495   -0.164703     0.0557151    -0.0888407
 -0.065479    -0.0293931  -0.129767    -0.0361131   -0.0399203   -0.0736792    0.0562859    0.0537689    0.153669     0.110096    0.00939872   0.017588     0.0122548    0.209969    -0.0603012    0.0924528   0.199009    -0.0860077    -0.130633   -0.0619451    0.0330944    -0.084748     0.0482206   -0.0443305   -0.0977382     0.0909983
 -0.0241566   -0.0206097   0.0622522    0.130862     0.146269    -0.0569088   -0.0165071    0.0021489   -0.0113642   -0.0392919   0.00447361   0.0182858    0.0459671   -0.028077     0.0230794   -0.0696596  -0.249871     0.163063     -0.056846    0.0385029    0.058217      0.261294    -0.117951    -0.110755    -0.103855     -0.0878745
 -0.103563     0.123911   -0.0217343   -0.244942    -0.0688855   -0.113194     0.120015     0.0543175    0.0625704    0.0432681   0.143198    -0.0619076   -0.072867    -0.0740797   -0.217005     0.13629    -0.0713953   -0.000796101   0.0697522  -0.101823     0.189441     -0.0189622   -0.246847    -0.0450534   -0.107516     -0.0419885
 -0.0147928    0.105702   -0.0178015   -0.241202     0.0247645   -0.230398     0.119948    -0.145607     0.0181626    0.002277    0.092719     0.0731186   -0.0907511   -0.00516415   0.452782     0.190534   -0.0177147   -0.0236939     0.14172    -0.0522613    0.22195      -0.0147451   -0.0785046   -0.00917373  -0.128764      0.0335616
 -0.0724931   -0.0619966  -0.0788924   -0.0111128    0.0564066   -0.0358606    0.0669757    0.0624795    0.0159095    0.141071    0.0165389   -0.12396      0.0851533   -0.0629328   -0.128587    -0.125967    0.146361    -0.0918055     0.109929    0.022387     0.015854     -0.163747     0.0346207    0.139606     0.130442     -0.137096
 -0.0411438    0.040444    0.0414399    0.0899133   -0.0808263    0.0556417    0.167881     0.00787328  -0.168446     0.0356547  -0.201321     0.137614    -0.0407285    0.114361    -0.150667    -0.0502232  -0.0137053    0.16552       0.101925    0.0584338   -0.0107007     0.0149721   -0.178075    -0.00365787   0.316299     -0.167071
  0.0654002    0.106728   -0.0765688   -0.168274    -0.0471568   -0.0281947   -0.0100419   -0.055922     0.0177876    0.110625    0.0123957   -0.127487    -0.0560572    0.0117685   -0.123982     0.130493    0.144971     0.0351425    -0.080264   -0.101546     0.00746969    0.143077    -0.0442465   -0.0289526   -0.0625488     0.0216226
 -0.0534575   -0.0229475   0.0407361   -0.198647    -0.0463793   -0.0371711    0.0816667   -0.127373    -0.00774366  -0.0581793   0.0613796    0.144726     0.0274791   -0.0814253    0.027676    -0.0386638   0.014291     0.162978      0.0105091  -0.048885    -0.100231      0.0303717    0.0114108    0.0515948    0.0855465    -0.00266804
 -0.0345581    0.0377247   0.0457746    0.00669717   0.112599     0.0487202   -0.0158219   -0.0977683   -0.10479      0.0337543   0.0682802   -0.0516542    0.162266    -0.113913    -0.0415906   -0.145887   -0.0296516    0.0690951     0.0177171  -0.0419093   -0.0465604    -0.106888    -0.00264625  -0.109014     0.0361955     0.000456351
 -0.00890982   0.119681    0.0302934    0.0490271   -0.00619821  -0.0660771    0.116877    -0.156917    -0.146223    -0.0462675   0.0468183   -0.224053     0.229186    -0.0250751    0.04254     -0.102249   -0.163884    -0.0135697     0.0853362   0.108672     0.0325762    -0.0261991   -0.00785618   0.0134968   -0.0702682    -0.00105976
  0.14444      0.0764358  -0.0834167   -0.00497535  -0.453182    -0.0936689    0.0299641    0.038038     0.0312921    0.142245   -0.00645223   0.322451     0.106783     0.0666216   -0.064692    -0.195974    0.00830251  -0.0289221    -0.0294205  -0.0607828    0.196001     -0.0157275   -0.0548657   -0.0514631    0.0852049    -0.103211
  0.0932842    0.0662561  -0.0831594   -0.00502986   0.531599    -0.213786     0.0296548    0.174616     0.0138301   -0.180641   -0.0241146    0.0704094    0.107471     0.128769    -0.0610119    0.306109    0.00789884  -0.0880201     0.0222312  -0.0607904   -0.146103      0.0827153   -0.0538054   -0.11085      0.0446711     0.1284[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     13
│     15
│     17
│     18
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.058978
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     13
│     15
│     17
│     18
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.048958
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      6
│      9
│     10
│     13
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.041215
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     13
│     15
│     17
│     18
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.057182
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│     13
│     15
│     17
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.041607
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      9
│     10
│     13
│     15
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.044691
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     13
│     15
│     17
│     18
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.055887
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      6
│     13
│     15
│     17
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.047401
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      9
│     10
│     13
│     15
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.039474
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     13
│     15
│     17
│     18
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.056878
┌ Info: EM with 100000 data points 10 iterations avll -1.056878
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.415804e+05
      1       6.925119e+05      -1.490684e+05 |       32
      2       6.655761e+05      -2.693581e+04 |       32
      3       6.503910e+05      -1.518517e+04 |       32
      4       6.416753e+05      -8.715619e+03 |       32
      5       6.353054e+05      -6.369943e+03 |       32
      6       6.302581e+05      -5.047280e+03 |       32
      7       6.268772e+05      -3.380909e+03 |       32
      8       6.250127e+05      -1.864539e+03 |       32
      9       6.237170e+05      -1.295661e+03 |       32
     10       6.222682e+05      -1.448826e+03 |       32
     11       6.206101e+05      -1.658092e+03 |       32
     12       6.192786e+05      -1.331487e+03 |       32
     13       6.184499e+05      -8.287091e+02 |       32
     14       6.179035e+05      -5.463980e+02 |       32
     15       6.175693e+05      -3.341962e+02 |       32
     16       6.173637e+05      -2.056126e+02 |       32
     17       6.172503e+05      -1.134142e+02 |       32
     18       6.171638e+05      -8.648634e+01 |       32
     19       6.170992e+05      -6.455812e+01 |       31
     20       6.170398e+05      -5.942741e+01 |       31
     21       6.169776e+05      -6.224046e+01 |       31
     22       6.169008e+05      -7.679982e+01 |       31
     23       6.168383e+05      -6.251227e+01 |       30
     24       6.167767e+05      -6.155701e+01 |       32
     25       6.167113e+05      -6.540352e+01 |       30
     26       6.166341e+05      -7.715560e+01 |       31
     27       6.165393e+05      -9.487508e+01 |       31
     28       6.164270e+05      -1.122135e+02 |       32
     29       6.163300e+05      -9.704615e+01 |       31
     30       6.162067e+05      -1.232523e+02 |       32
     31       6.160254e+05      -1.813375e+02 |       32
     32       6.157792e+05      -2.461780e+02 |       32
     33       6.155943e+05      -1.849823e+02 |       31
     34       6.155193e+05      -7.493475e+01 |       31
     35       6.154918e+05      -2.747310e+01 |       30
     36       6.154787e+05      -1.318899e+01 |       28
     37       6.154715e+05      -7.129010e+00 |       27
     38       6.154682e+05      -3.340901e+00 |       25
     39       6.154655e+05      -2.683368e+00 |       25
     40       6.154627e+05      -2.813054e+00 |       26
     41       6.154605e+05      -2.152014e+00 |       22
     42       6.154592e+05      -1.344852e+00 |       20
     43       6.154584e+05      -7.882065e-01 |       12
     44       6.154580e+05      -4.048422e-01 |       14
     45       6.154572e+05      -7.731013e-01 |       12
     46       6.154568e+05      -4.315330e-01 |        7
     47       6.154567e+05      -1.059853e-01 |        4
     48       6.154566e+05      -1.000448e-01 |        0
     49       6.154566e+05       0.000000e+00 |        0
K-means converged with 49 iterations (objv = 615456.5874531233)
┌ Info: K-means with 32000 data points using 49 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.336832
[ Info: iteration 2, average log likelihood -1.304471
[ Info: iteration 3, average log likelihood -1.268634
[ Info: iteration 4, average log likelihood -1.238289
[ Info: iteration 5, average log likelihood -1.210183
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.162525
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.119283
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.109209
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     12
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.089305
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.092630
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     16
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.062040
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.090680
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     22
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.052319
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.074521
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      8
│     16
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.061325
[ Info: iteration 16, average log likelihood -1.109794
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.055288
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     10
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.035510
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      5
│      8
│     12
│     16
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.053931
[ Info: iteration 20, average log likelihood -1.122671
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.070244
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     10
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.047729
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      8
│     12
│     14
│     16
│     19
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.039895
[ Info: iteration 24, average log likelihood -1.121962
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.068967
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     10
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.039425
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     19
│     21
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.058915
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     14
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.089012
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.085420
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      8
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.041475
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     10
│     19
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.046800
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     14
│     16
│     21
│     22
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.052645
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.105908
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.065333
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.055412
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     14
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.053883
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     16
│     21
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.040125
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.097438
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.075179
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.082299
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     14
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.037612
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│     12
│     16
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.026338
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.120815
[ Info: iteration 44, average log likelihood -1.109732
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.069166
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      8
│     14
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.043861
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     10
│     12
│     16
│     19
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.054772
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     21
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.108943
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.099902
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.050436
┌ Info: EM with 100000 data points 50 iterations avll -1.050436
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0120999    0.161995     0.0689556    0.0939817    -0.0112926    0.138397    -0.0140311   -0.030867     0.0207203    0.157697    -0.0523835   -0.171301    -0.00743974  -0.0387235   -0.266008    0.0162679  -0.0603108   -0.090121   -0.111718    -0.0365227    0.0950546   -0.0299043    0.132296    -0.0851287   -0.0961471    0.09305
  0.068099     0.103659    -0.0773948   -0.171373     -0.046818    -0.0285013   -0.00879467  -0.0591452    0.0192728    0.110967     0.012388    -0.129257    -0.0568764    0.0158675   -0.126363    0.133644    0.148356     0.0354124  -0.0816894   -0.100742     0.00806706   0.147123    -0.0468487   -0.0279491   -0.066393     0.0206966
  0.0168609   -0.124229     0.131598    -0.196101      0.127158    -0.00936841  -0.104328    -0.369306     0.0487687   -0.123229     0.224984     0.278564     0.0136662   -0.0727288    0.140601   -0.0836752   0.0750499    0.23337    -0.0993408   -0.00821558  -0.0839943    0.110006    -0.0651762    0.0926769    0.0440127    0.0327556
 -0.0672644    0.237361    -0.112935     0.0134449    -0.0607815    0.263035    -0.0536616   -0.184915    -0.094907     0.0533262   -0.101773    -0.192102     0.0410828   -0.126182     0.057308    0.0583085   0.0917536   -0.205647    0.192597     0.0493651   -0.112477     0.0233798    0.140601    -0.0658639    0.126292    -0.0860071
  0.0179518    0.116399     0.0419704    0.047721      0.0142007   -0.146889     0.0242947   -0.11363     -0.0563479   -0.10699      0.0801466   -0.0624018   -0.0852254    0.17555      0.0104942   0.0732124   0.132092     0.0976472   0.0984485   -0.0505372    0.0518432    0.00399638  -0.105495     0.120796    -0.0646721    0.0672917
 -0.0572744    0.117383    -0.0186705   -0.243064     -0.0205883   -0.174704     0.120135    -0.0487505    0.040139     0.0222468    0.118109     0.0064188   -0.0809115   -0.0390514    0.122039    0.163766   -0.0412094   -0.0122741   0.10661     -0.0753149    0.209224    -0.016737    -0.161549    -0.027511    -0.119735    -0.00348221
 -0.106221     0.0725957    0.00446219   0.100943      0.0295515    0.0541568   -0.0137323    0.0181942   -0.00828259   0.073846     0.0627868    0.0530148    0.0221865    0.00502873  -0.0364104  -0.14156    -0.0414064   -0.141847    0.0302446    0.0515115   -0.0635644   -0.0507783    0.164632     0.0051012    0.113066    -0.274517
  0.118196     0.0716355   -0.0834051   -0.00479815    0.0392999   -0.153999     0.0302008    0.106756     0.0230956   -0.0165893   -0.0158252    0.196082     0.107058     0.0975644   -0.062781    0.0553499   0.00811814  -0.0592012  -0.00424925  -0.0607587    0.0250294    0.0332746   -0.0545868   -0.0811919    0.0649967    0.0133894
 -0.0162703    0.100738     0.0335853    0.0430446     0.0139409   -0.0477349    0.0913302   -0.144542    -0.138838    -0.0311292    0.0493931   -0.192727     0.215603    -0.0436478    0.024767   -0.108718   -0.138511     0.0013253   0.06866      0.0814395    0.0210115   -0.0423808   -0.00889431  -0.00837415  -0.0516924   -0.00554413
 -0.0156486    0.0361837   -0.174955    -0.00250904   -0.0219973    0.157324     0.0145717    0.226949    -0.0630844   -0.00632347  -0.163123    -0.0147046    0.0182525   -0.0411682   -0.0901546  -0.103841    0.112038     0.0104182   0.134206    -0.0399474    0.143758     0.0424288    0.0983947   -0.147158    -0.127857     0.191217
  0.0102128   -0.0389778   -0.188869    -0.0096279    -0.131958    -0.0786446   -0.00240714  -0.0646087   -0.0724469   -0.102394     0.0184309   -0.216805     0.133414     0.11005     -0.0197111   0.0359308  -0.0589989   -0.02463    -0.0941352    0.0238704   -0.0450573   -0.0398114    0.018216     0.0667417   -0.0404868    0.134822
 -0.0851179   -0.00173646   0.0235282    0.00616676   -0.00262921   0.159313    -0.0437183    0.197697    -0.138868     0.14003      0.241375     0.0424542    0.0637796   -0.039373     0.283361    0.0300592   0.188582     0.0597849  -0.0714351   -0.0276473    0.0267459    0.0217244    0.076899    -0.101414    -0.137535     0.0946266
 -0.0280965   -0.0205173    0.0606808    0.11413       0.13875     -0.0602174   -0.0132889    0.00243516   0.00102645  -0.0418678    0.00303361   0.0150892    0.0395885   -0.00678995   0.012905   -0.0548049  -0.206983     0.139633   -0.0622589    0.0294011    0.0632036    0.230275    -0.114028    -0.0980081   -0.103412    -0.0707593
 -0.021682     0.00618298   0.0629104    0.0494136     0.174376     0.110348    -0.0820267   -0.0369556   -0.0808076    0.0704943    0.0256764    0.0431715    0.0754655   -0.0987694   -0.0694167  -0.165666    0.0320817    0.107026    0.0165152   -0.100239    -0.0258733   -0.121597    -0.0245624   -0.151828     0.117049     0.0127988
 -0.0729184   -0.0614267   -0.0785726   -0.0120928     0.0553125   -0.0352674    0.0671002    0.0646269    0.0158621    0.140934     0.0159374   -0.126383     0.0868626   -0.0634126   -0.127211   -0.12532     0.145686    -0.092661    0.11098      0.0224043    0.0185975   -0.161517     0.0331125    0.139667     0.129826    -0.136683
 -0.109351     0.0511422   -0.194887    -0.048674      0.00415714   0.121511    -0.0703931   -0.110693     0.0568968   -0.00774786  -0.12966      0.0687627   -0.0359999    0.0798662    0.120695   -0.0370539   0.0141159   -0.0949849  -0.0148767   -0.0256525   -0.0302504    0.0689595   -0.151796     0.16838      0.0249931   -0.12006
 -0.0634675   -0.0213491   -0.0372497   -0.144891      0.0698635    0.0103637   -0.0837325   -0.0274372   -0.231231    -0.0777389    0.134183     0.0621485   -0.0645552    0.13742     -0.10538    -0.152912    0.00276896  -0.0490473  -0.0447859   -0.105015     0.224948    -0.0469783   -0.174954     0.00248559  -0.0014526    0.00406028
 -0.0119095   -0.218751    -0.069185    -0.132013      0.0101662   -0.162337    -0.053366    -0.0732398    0.0712582   -0.190908     0.0621604   -0.215142    -0.091534    -0.180431    -0.200225   -0.123625    0.0317083   -0.105405    0.0364577   -0.0744297    0.0405553    0.0653462    0.11543      0.216867    -0.0420683    0.0614826
 -0.0120391    0.0293683   -0.234264     0.0433689    -0.189489     0.0616912   -0.0283842    0.107077     0.150429    -0.0735521   -0.108925     0.188141    -0.144962    -0.115836    -0.0602699  -0.071585   -0.0507742   -0.115276    0.0644983   -0.0428742   -0.0424819    0.15932     -0.0202008   -0.0985467    0.0624044   -0.0283893
 -0.0770937    0.0551763    0.00164662  -0.194827     -0.217756    -0.0522393    0.219931     0.0753158   -0.0542828    0.00642285  -0.0599772    0.0759178    0.0478959   -0.0321146   -0.0595383   0.0151403  -0.00759198   0.117542    0.13896     -0.100263    -0.155553    -0.0329765    0.076759     0.0960206    0.123416    -0.0519431
 -0.188727     0.0763826    0.00789919  -0.104235      0.0489285    0.0600014   -0.0238868   -0.271607    -0.00633434   0.0286406    0.0331096   -0.022008     0.00966713  -0.122032     0.0600858   0.0246271  -0.00720886  -0.0139809  -0.0932377    0.0531452    0.0641146    0.072814     0.0119891   -0.0130623    0.0101754    0.0658135
 -0.00256704   0.20292      0.0614002   -0.027309     -0.00391209   0.013857    -0.0266615   -0.0391924    0.019651    -0.195894    -0.114165     0.0474053    0.125536    -0.0382345   -0.0301826   0.0884713   0.0299422   -0.0664614   0.00224212  -0.0982201   -0.117497    -0.0249332   -0.244188     0.028764     0.278977    -0.0457584
 -0.0284031    0.0394764    0.0439814    0.0859197    -0.102689     0.0600638    0.174387     0.0128005   -0.172103     0.0375959   -0.224071     0.146852    -0.0624735    0.123931    -0.161608   -0.0449706  -0.0224932    0.165778    0.098295     0.0710091   -0.0142062    0.0169091   -0.193213     0.00358972   0.338239    -0.199038
 -0.0417476   -0.0830158   -0.187744    -0.097902     -0.0333779   -0.0229813    0.225156    -0.0453021   -0.138571    -0.127654    -0.115786    -0.0552025   -0.0155567    0.150758    -0.0142138  -0.119429    0.0853575   -0.108589   -0.0550089   -0.142667    -0.088609     0.122062     0.0918198   -0.0397609    0.0983866    0.00908659
 -0.00714467   0.0205846    0.0560559    0.0144962     0.157828     0.093461     0.0340158   -0.192325     0.0212094    0.0111439   -0.0370394   -0.047492    -0.0812718   -0.153002     0.0834706   0.0320319   0.0693692   -0.0203762   0.0932314    0.0129042   -0.160864    -0.0182174    0.140455    -0.0210444    0.0952155    0.0125586
 -0.0928109    0.00017046  -0.0909188    0.000994279  -0.0867618    0.0332339   -0.0504249   -0.108681     0.140445    -0.0602455   -0.0220636   -0.00978019   0.0528072   -0.0487844    0.0613526  -0.227577   -0.0456991   -0.166992    0.124916    -0.0693145   -0.234079    -0.160473     0.0132529   -0.058302     0.00632632   0.0224584
 -0.037719    -0.0159904   -0.0766294    0.0465352     0.0379625    0.127836     0.0836367   -0.033837    -0.0565738   -0.0202528    0.0369771    0.0283372    0.100068     0.0474183    0.0205095   0.0559269   0.0481296   -0.0606508  -0.0338646   -0.207796     0.127938    -0.0112107   -0.056674     0.123062     0.0797283    0.0031831
 -0.0787881   -0.0185454   -0.159867    -0.0380968    -0.0616413   -0.0566393    0.0542733    0.0543801    0.209027     0.135103    -0.0786201    0.0346584   -0.0111091    0.253912    -0.169384    0.122207    0.205917    -0.0956876  -0.122109    -0.0649952    0.0268619   -0.109961     0.0436749   -0.0452694   -0.0988023    0.0918183
 -0.151192     0.136609    -0.0690912    0.158039     -0.00344474   0.153737     0.0533675    0.0688677   -0.0636107    0.113009    -0.0639      -0.163555     0.00603279   0.00682062   0.0338795   0.0305389   0.233093    -0.159992    0.040435     0.00162957   0.148142     0.128157    -0.0357093   -0.14162      0.0605991   -0.0850918
 -0.160785     0.0386843   -0.137741     0.086053     -0.0270206   -0.16541      0.040127     0.0618143    0.0381644   -0.0550945   -0.0695128    0.0923379    0.191921     0.117546     0.0089415   0.0991005   0.0727707    0.0536156  -0.0270119    0.183716    -0.106055     0.159821    -0.013427    -0.0746437   -0.0663378    0.134726
  0.0719629    0.0996559    0.141112     0.0624526    -0.0221651   -0.133028    -0.135164     0.0628041    0.0180122   -0.0419835    0.152018    -0.0416045   -0.0578787    0.0289795    0.0164075   0.0116134  -0.0314215    0.163583   -0.0552652    0.100898     0.119249     0.0829316    0.0981735   -0.0543894   -0.00894798  -0.0122672
  0.0258511    0.0662992   -0.251257     0.112874      0.0802677    0.0633231    0.00749013   0.0138865    0.0800368    0.0915884   -0.0967938   -0.00462349   0.0875717   -0.0290011   -0.0699997   0.0784074   0.188741    -0.144418   -0.0661833    0.0903102   -0.0784827   -0.046899    -0.0276111    0.0655475    0.16854     -0.0366614[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     10
│     14
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.037877
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      7
│     10
│     12
│      ⋮
│     23
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.998301
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      8
│     10
│      ⋮
│     19
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.995639
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      7
│     10
│     12
│      ⋮
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.016291
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     10
│     14
│     16
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.013292
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      5
│      7
│      8
│      ⋮
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.973835
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     10
│     14
│     16
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.034022
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      7
│     10
│     12
│      ⋮
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.998619
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      8
│     10
│      ⋮
│     19
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.992305
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      7
│     10
│     12
│      ⋮
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.016209
┌ Info: EM with 100000 data points 10 iterations avll -1.016209
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.135492    0.0646561   0.0428922    0.0507677   -0.00477787   0.202642    -0.0405464    0.0167101    0.0149715   -0.0709328    0.0994201    0.0881725  -0.0637578   -0.106585    -0.192444     0.104729     -0.0481292    0.0121462    0.14934      0.0681797   -0.126108    -0.215238     0.0151948    0.284892      0.0462691    0.0517524
  0.181489   -0.171704   -0.08521     -0.0496287    0.0896826   -0.0889728    0.0490635   -0.199958    -0.0403602   -0.204245    -0.0381636   -0.0129101  -0.068777    -0.00755246  -0.0546855    0.00212825    0.0500985    0.0624029    0.0499129    0.0763681   -0.239977     0.028671     0.101982     0.0399492    -0.125035     0.0893305
 -0.184093   -0.0554591   0.136498    -0.0795675   -0.0726933   -0.086602    -0.0208455   -0.0553051   -0.0145382   -0.107958     0.0237502   -0.0135693  -0.157166     0.125671     0.0089085    0.0356366    -0.0965942    0.0392603   -0.0388956    0.0897427   -0.0771253   -0.176521     0.198481     0.000804095  -0.0282319    0.176845
 -0.062105   -0.101471   -0.0677834   -0.0700262    0.091717     0.133717    -0.0728675   -0.0196312   -0.011393     0.0349233   -0.0171506   -0.0906984  -0.0817387   -0.0360168   -0.0237737   -0.0213098     0.107879    -0.0568986   -0.0389504   -0.111771     0.0460575    0.139888     0.00256237   0.0127038    -0.109154     0.0241793
  0.0239513  -0.0817566   0.0649566   -0.0969882    0.0351088   -0.0672266    0.0114013    0.0892325   -0.0471634   -0.0626509   -0.0328415   -0.0395283   0.0334328   -0.0319776   -0.0580137    0.000979711  -0.11148      0.117083     0.182048    -0.00112292  -0.222753    -0.0107909   -0.0805186    0.0292628     0.0405354    0.049496
 -0.0378014  -0.142834    0.106645     0.122767    -0.0767771   -0.175677    -0.291388     0.0561778    0.102827     0.0622602   -0.00265257  -0.0207836  -0.222163    -0.0465121    0.087956    -0.0523404    -0.0765998   -0.0889475   -0.188682    -0.0221241    0.0296042    0.0178281   -0.120121    -0.155619      0.00351558   0.0320282
  0.0269655   0.0516481  -0.0385654   -0.0178421   -8.47414e-5  -0.126787    -0.00597114   0.0349131   -0.128242    -0.233509     0.0230873   -0.0986972   0.00744894  -0.0906839    0.108804    -0.0286883    -0.0988468    0.0364053   -0.0864075   -0.211725    -0.137245     0.16258     -0.0636501    0.00534019    0.103142    -0.0342152
 -0.0941002   0.0427673   0.157453    -0.0111773   -0.174854    -0.0692575    0.153729     0.0857657   -0.0190449    0.122318     0.159383    -0.169098   -0.120122    -0.00509802   0.0832639   -0.100513      0.0984689   -0.132581     0.194421     0.197       -0.00718766  -0.148638     0.0159765   -0.103963     -0.0876755    0.080393
 -0.144714    0.0679117  -0.0868638   -0.106572     0.0872542   -0.00859989   0.107646     0.0846261   -0.00719356   0.0303633   -0.0456116    0.135471   -0.0837698   -0.0206317   -0.07829      0.035796      0.0122959   -0.0574611   -0.00934915  -0.0538985    0.0502701   -0.107231    -0.0393184   -0.0515022     0.0659053    0.0306074
 -0.126173   -0.025825    0.0102142   -0.0422052   -0.194076    -0.0464273    0.151113     0.137079     0.00789622   0.00151022   0.0357325   -0.0740609  -0.0890269   -0.0570957   -0.00565572  -0.015333      0.185502     0.0552821    0.111944    -0.0489706   -0.0824592    0.0633321   -0.122529     0.0467563     0.110952     0.00709112
  0.188478    0.0368649  -0.0767507    0.121089     0.0710454   -0.0143132   -0.0303476    0.106696    -0.037641    -0.124913    -0.237771     0.0594592  -0.114426     0.125425    -0.0638388   -0.0725919    -0.0317433   -0.0401188   -0.103574    -0.0251589    0.0954944    0.047275    -0.0435346    0.00320726    0.0393357    0.147031
  0.0700211   0.0463496   0.00905486   0.0337136    0.0175818   -0.0761365    0.0143414   -0.0538061    0.203636     0.152105     0.101162    -0.0613716   0.0149746   -0.0431544   -0.0965835   -0.0363415     0.06736     -0.033449     0.144942     0.0581111    0.0805211   -0.0967637    0.0209885    0.026768      0.175169    -0.037084
 -0.0146893   0.0529808  -0.0377043    0.203362    -0.112641    -0.0385654   -0.113617     0.192156     0.0235749    0.0428035    0.0500741    0.178397    0.106609     0.0512403   -0.0075396    0.0105899    -0.0361904    0.00448646  -0.0889645   -0.0689675   -0.00631521  -0.159105     0.120271     0.0872365     0.231866    -0.0181007
 -0.170149   -0.0868749  -0.0423579   -0.025453    -0.0940597    0.0623775    0.0599694    0.117104    -0.0986083    0.0552929   -0.0772088    0.0303763   0.00403516   0.14901      0.0841588    0.0411847    -0.20567      0.0818897   -0.0316043   -0.0126612   -0.0016258   -0.167097    -0.0195509    0.112999      0.180744    -0.11815
  0.0731845  -0.148966    0.101876     0.0121131   -0.0230023    0.163419    -0.12088     -0.0210711   -0.0254105   -0.0921751   -0.0531624   -0.21227     0.206106    -0.0575956   -0.150209     0.0197272    -0.00415674  -0.0990513   -0.0793412   -0.0835692   -0.123148    -0.0634942    0.113529     0.203623     -0.162371    -0.0903184
  0.126124   -0.0619507   0.15185      0.0245757    0.0254527    0.0728625   -0.0109063   -0.0413896    0.141007    -0.0409916    0.14733      0.0943636   0.0605022    0.0527631   -0.139338     0.070619      0.121922    -0.161242     0.131588    -0.0366166    0.0301788    0.129928     0.0991691    0.0566569     0.0566321   -0.0478682
 -0.02723    -0.0918682  -0.225451    -0.0351731   -0.0261665    0.00790323  -0.0300283    0.0002895   -0.00918467  -0.0993938   -0.181233     0.0301871   0.00584251   0.118119    -0.0892504   -0.341271      0.0309796    0.236966    -0.0240366   -0.0172504   -0.0433137   -0.0909675    0.0102895   -0.0187413     0.0259162   -0.0391474
 -0.0990603  -0.0427993  -0.0166204    0.0451036    0.0847664    0.0970561    0.151617    -0.307841     0.0148915   -0.0102909   -0.147171    -0.0267757   0.107045    -0.00132352   0.116895    -0.0393797    -0.11146      0.0545067    0.0131626    0.0348757    0.054824    -0.16349      0.114312    -0.0683501     0.0482848   -0.012404
 -0.145332    0.0482545  -0.0368922   -0.0203541   -0.0827853    0.102567     0.0688364    0.1096       0.055988     0.0162843    0.110905    -0.126782    0.092944     0.0887932   -0.128665     0.136839     -0.0322166   -0.0573625    0.0738084   -0.241111     0.108869    -0.0477087    0.0457222   -0.0371087     0.152676     0.000776163
 -0.0595707   0.0422946   0.120947     0.0864731    0.0597819    0.153008     0.114741    -0.102244     0.032063     0.0519837    0.043531     0.0166763  -0.118483    -0.0707789    0.00575947   0.0169592    -0.0444414    0.0984046    0.0174473    0.16203      0.0728242   -0.0488138    0.0839105   -0.0466526     0.12107      0.151479
 -0.0448586  -0.0568349   0.0370196   -0.170441     0.02638     -0.0447606    0.0779221   -0.1166       0.151225     0.155971    -0.176591     0.0729324   0.0553923   -0.130725    -0.0617675   -0.0769489    -0.00400906   0.026224     0.0181478    0.0783898   -0.0275619   -0.0381683   -0.120024     0.0220847     0.0538744    0.0970355
  0.0460592   0.108678    0.0460147    0.0560749    0.0146649    0.183215    -0.0508812    0.0178976   -0.0606188   -0.0559586   -0.0624898    0.0721815   0.0940423   -0.0204773    0.0678907    0.137256     -0.118754    -0.206119    -0.113967    -0.0806114   -0.247079     0.146541    -0.0207371   -0.103249     -0.189388     0.0145386
 -0.0938257  -0.0519153   0.125422    -0.0778157   -0.136478    -0.00312138   0.185282    -0.182474     0.010448     0.0880242   -0.121724     0.114154    0.0940733   -0.15683     -0.15673      0.068239      0.122933    -0.124913     0.0235111   -0.13365      0.0111425   -0.0442447   -0.13698      0.152392     -0.00339399  -0.0296165
  0.0896756   0.0705284   0.0416408   -0.0430713   -0.147196    -0.127772    -0.0603449   -0.0509349    0.0564018    0.0950808   -0.0884892    0.289465    0.0833984   -0.189514     0.067327     0.0171033     0.0759407    0.0296622    0.0921066    0.136799     0.00335492   0.0904748   -0.170332    -0.0567727    -0.0338352   -0.105544
  0.200456    0.0536574  -0.0758697    0.0361454   -0.0663829   -0.269791    -0.0965316   -0.0216492    0.0621077    0.0824185   -0.168266     0.0268221   0.0377539    0.161214     0.006723    -0.0232745    -0.0396446    0.115408     0.0330589   -0.0160821   -0.079947    -0.029717    -0.0682261    0.108563     -0.0123612   -0.0929679
  0.0482398  -0.3374     -0.00343287  -0.0392658   -0.029812     0.207762     0.0439585   -0.00589615  -0.047104     0.180533    -0.0416123   -0.116637   -0.083827    -0.125325    -0.0633591    0.134737      0.0476531    0.0671405    0.104076     0.0887924   -0.0364928    0.111344    -0.0114931    0.216818     -0.31804      0.12659
  0.198903    0.0256034  -0.150519     0.0392423    0.0593296    0.0672073    0.071132    -0.136113    -0.0245105   -0.0378016   -0.00692453  -0.0305563   0.124308     0.00541872  -0.0465108    0.181358      0.13644     -0.0408171   -0.0978037    0.0188128   -0.00149737   0.00240798  -0.122025     0.00923098    0.213635    -0.045879
  0.04603     0.110709    0.0123382   -0.00795001  -0.0821665   -0.0557469    0.160352    -0.177425     0.0817097    0.0618456    0.00875774  -0.0391268   0.09102      0.0523099    0.0588573    0.0248361    -0.00796509  -0.0560693   -0.100697    -0.0303017    0.0599185    0.222597    -0.00897064  -0.109463      0.141601    -0.00292068
 -0.0288386  -0.0706765   0.0126612   -0.0334696    0.059669    -0.155387     0.0747682   -0.154604     0.069138    -0.020865    -0.057159    -0.0517596   0.159359     0.107986     0.0173275    0.125501     -0.131705    -0.287718     0.0104457    0.0508792   -0.0542335   -0.148616    -0.0150566    0.119461     -0.110974    -0.0380626
  0.129171    0.137282   -0.0622744   -0.0491064   -0.058947     0.0154854    0.0490924    0.0285935    0.142738    -0.121831     0.0663371   -0.0788838  -0.0294175   -0.039737     0.00595034   0.120648      0.104251     0.230649    -0.045115     0.0177194    0.162057    -0.0854207   -0.259669    -0.0654086    -0.0158727   -0.0265776
 -0.106463    0.0413666   0.0401502   -0.020302    -0.111716     0.0912294    0.0585578   -0.0548836    0.111419    -0.0391149   -0.0425806    0.0811129  -0.0758137   -0.149051     0.12847      0.0559954    -0.02522     -0.0280941   -0.0575428   -0.0915194   -0.148333     0.136046     0.00676978  -0.041779      0.0343035   -0.00770854
 -0.0496674   0.0782501   0.135921    -0.100218     0.00205898  -0.100397    -0.264209    -0.140449     0.0329218   -0.021583    -0.104178     0.0360506  -0.00949771  -0.0560613   -0.0638837   -0.0246628     0.0976985    0.0327427   -0.0634879    0.0882627   -0.142466     0.0709013    0.102217     0.0864348     0.101383    -0.0873951kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4173674920721349
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417386
[ Info: iteration 2, average log likelihood -1.417331
[ Info: iteration 3, average log likelihood -1.417290
[ Info: iteration 4, average log likelihood -1.417235
[ Info: iteration 5, average log likelihood -1.417143
[ Info: iteration 6, average log likelihood -1.416948
[ Info: iteration 7, average log likelihood -1.416503
[ Info: iteration 8, average log likelihood -1.415590
[ Info: iteration 9, average log likelihood -1.414234
[ Info: iteration 10, average log likelihood -1.413013
[ Info: iteration 11, average log likelihood -1.412366
[ Info: iteration 12, average log likelihood -1.412125
[ Info: iteration 13, average log likelihood -1.412042
[ Info: iteration 14, average log likelihood -1.412013
[ Info: iteration 15, average log likelihood -1.412002
[ Info: iteration 16, average log likelihood -1.411998
[ Info: iteration 17, average log likelihood -1.411996
[ Info: iteration 18, average log likelihood -1.411995
[ Info: iteration 19, average log likelihood -1.411995
[ Info: iteration 20, average log likelihood -1.411994
[ Info: iteration 21, average log likelihood -1.411994
[ Info: iteration 22, average log likelihood -1.411994
[ Info: iteration 23, average log likelihood -1.411993
[ Info: iteration 24, average log likelihood -1.411993
[ Info: iteration 25, average log likelihood -1.411993
[ Info: iteration 26, average log likelihood -1.411993
[ Info: iteration 27, average log likelihood -1.411993
[ Info: iteration 28, average log likelihood -1.411992
[ Info: iteration 29, average log likelihood -1.411992
[ Info: iteration 30, average log likelihood -1.411992
[ Info: iteration 31, average log likelihood -1.411992
[ Info: iteration 32, average log likelihood -1.411992
[ Info: iteration 33, average log likelihood -1.411992
[ Info: iteration 34, average log likelihood -1.411992
[ Info: iteration 35, average log likelihood -1.411992
[ Info: iteration 36, average log likelihood -1.411992
[ Info: iteration 37, average log likelihood -1.411992
[ Info: iteration 38, average log likelihood -1.411992
[ Info: iteration 39, average log likelihood -1.411992
[ Info: iteration 40, average log likelihood -1.411992
[ Info: iteration 41, average log likelihood -1.411992
[ Info: iteration 42, average log likelihood -1.411992
[ Info: iteration 43, average log likelihood -1.411992
[ Info: iteration 44, average log likelihood -1.411992
[ Info: iteration 45, average log likelihood -1.411992
[ Info: iteration 46, average log likelihood -1.411992
[ Info: iteration 47, average log likelihood -1.411991
[ Info: iteration 48, average log likelihood -1.411991
[ Info: iteration 49, average log likelihood -1.411991
[ Info: iteration 50, average log likelihood -1.411991
┌ Info: EM with 100000 data points 50 iterations avll -1.411991
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.417385519829058
│     -1.4173307975714737
│      ⋮
└     -1.4119914469395711
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412006
[ Info: iteration 2, average log likelihood -1.411937
[ Info: iteration 3, average log likelihood -1.411877
[ Info: iteration 4, average log likelihood -1.411804
[ Info: iteration 5, average log likelihood -1.411713
[ Info: iteration 6, average log likelihood -1.411601
[ Info: iteration 7, average log likelihood -1.411473
[ Info: iteration 8, average log likelihood -1.411342
[ Info: iteration 9, average log likelihood -1.411221
[ Info: iteration 10, average log likelihood -1.411122
[ Info: iteration 11, average log likelihood -1.411049
[ Info: iteration 12, average log likelihood -1.410998
[ Info: iteration 13, average log likelihood -1.410964
[ Info: iteration 14, average log likelihood -1.410941
[ Info: iteration 15, average log likelihood -1.410924
[ Info: iteration 16, average log likelihood -1.410910
[ Info: iteration 17, average log likelihood -1.410898
[ Info: iteration 18, average log likelihood -1.410887
[ Info: iteration 19, average log likelihood -1.410877
[ Info: iteration 20, average log likelihood -1.410867
[ Info: iteration 21, average log likelihood -1.410858
[ Info: iteration 22, average log likelihood -1.410849
[ Info: iteration 23, average log likelihood -1.410841
[ Info: iteration 24, average log likelihood -1.410833
[ Info: iteration 25, average log likelihood -1.410826
[ Info: iteration 26, average log likelihood -1.410819
[ Info: iteration 27, average log likelihood -1.410812
[ Info: iteration 28, average log likelihood -1.410807
[ Info: iteration 29, average log likelihood -1.410801
[ Info: iteration 30, average log likelihood -1.410797
[ Info: iteration 31, average log likelihood -1.410793
[ Info: iteration 32, average log likelihood -1.410789
[ Info: iteration 33, average log likelihood -1.410785
[ Info: iteration 34, average log likelihood -1.410782
[ Info: iteration 35, average log likelihood -1.410780
[ Info: iteration 36, average log likelihood -1.410777
[ Info: iteration 37, average log likelihood -1.410775
[ Info: iteration 38, average log likelihood -1.410773
[ Info: iteration 39, average log likelihood -1.410771
[ Info: iteration 40, average log likelihood -1.410770
[ Info: iteration 41, average log likelihood -1.410768
[ Info: iteration 42, average log likelihood -1.410767
[ Info: iteration 43, average log likelihood -1.410766
[ Info: iteration 44, average log likelihood -1.410765
[ Info: iteration 45, average log likelihood -1.410764
[ Info: iteration 46, average log likelihood -1.410763
[ Info: iteration 47, average log likelihood -1.410762
[ Info: iteration 48, average log likelihood -1.410761
[ Info: iteration 49, average log likelihood -1.410761
[ Info: iteration 50, average log likelihood -1.410760
┌ Info: EM with 100000 data points 50 iterations avll -1.410760
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4120057976793225
│     -1.4119371602146051
│      ⋮
└     -1.4107599372905193
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410769
[ Info: iteration 2, average log likelihood -1.410711
[ Info: iteration 3, average log likelihood -1.410660
[ Info: iteration 4, average log likelihood -1.410601
[ Info: iteration 5, average log likelihood -1.410530
[ Info: iteration 6, average log likelihood -1.410444
[ Info: iteration 7, average log likelihood -1.410347
[ Info: iteration 8, average log likelihood -1.410247
[ Info: iteration 9, average log likelihood -1.410153
[ Info: iteration 10, average log likelihood -1.410070
[ Info: iteration 11, average log likelihood -1.410000
[ Info: iteration 12, average log likelihood -1.409942
[ Info: iteration 13, average log likelihood -1.409894
[ Info: iteration 14, average log likelihood -1.409855
[ Info: iteration 15, average log likelihood -1.409824
[ Info: iteration 16, average log likelihood -1.409799
[ Info: iteration 17, average log likelihood -1.409778
[ Info: iteration 18, average log likelihood -1.409762
[ Info: iteration 19, average log likelihood -1.409749
[ Info: iteration 20, average log likelihood -1.409739
[ Info: iteration 21, average log likelihood -1.409731
[ Info: iteration 22, average log likelihood -1.409724
[ Info: iteration 23, average log likelihood -1.409719
[ Info: iteration 24, average log likelihood -1.409714
[ Info: iteration 25, average log likelihood -1.409710
[ Info: iteration 26, average log likelihood -1.409706
[ Info: iteration 27, average log likelihood -1.409703
[ Info: iteration 28, average log likelihood -1.409699
[ Info: iteration 29, average log likelihood -1.409696
[ Info: iteration 30, average log likelihood -1.409693
[ Info: iteration 31, average log likelihood -1.409690
[ Info: iteration 32, average log likelihood -1.409688
[ Info: iteration 33, average log likelihood -1.409685
[ Info: iteration 34, average log likelihood -1.409682
[ Info: iteration 35, average log likelihood -1.409679
[ Info: iteration 36, average log likelihood -1.409676
[ Info: iteration 37, average log likelihood -1.409673
[ Info: iteration 38, average log likelihood -1.409670
[ Info: iteration 39, average log likelihood -1.409667
[ Info: iteration 40, average log likelihood -1.409664
[ Info: iteration 41, average log likelihood -1.409661
[ Info: iteration 42, average log likelihood -1.409658
[ Info: iteration 43, average log likelihood -1.409655
[ Info: iteration 44, average log likelihood -1.409652
[ Info: iteration 45, average log likelihood -1.409649
[ Info: iteration 46, average log likelihood -1.409646
[ Info: iteration 47, average log likelihood -1.409642
[ Info: iteration 48, average log likelihood -1.409639
[ Info: iteration 49, average log likelihood -1.409635
[ Info: iteration 50, average log likelihood -1.409632
┌ Info: EM with 100000 data points 50 iterations avll -1.409632
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4107693909129686
│     -1.4107114052929108
│      ⋮
└     -1.4096320333786798
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409637
[ Info: iteration 2, average log likelihood -1.409584
[ Info: iteration 3, average log likelihood -1.409535
[ Info: iteration 4, average log likelihood -1.409478
[ Info: iteration 5, average log likelihood -1.409408
[ Info: iteration 6, average log likelihood -1.409323
[ Info: iteration 7, average log likelihood -1.409223
[ Info: iteration 8, average log likelihood -1.409112
[ Info: iteration 9, average log likelihood -1.408996
[ Info: iteration 10, average log likelihood -1.408882
[ Info: iteration 11, average log likelihood -1.408774
[ Info: iteration 12, average log likelihood -1.408675
[ Info: iteration 13, average log likelihood -1.408585
[ Info: iteration 14, average log likelihood -1.408505
[ Info: iteration 15, average log likelihood -1.408434
[ Info: iteration 16, average log likelihood -1.408372
[ Info: iteration 17, average log likelihood -1.408317
[ Info: iteration 18, average log likelihood -1.408270
[ Info: iteration 19, average log likelihood -1.408229
[ Info: iteration 20, average log likelihood -1.408193
[ Info: iteration 21, average log likelihood -1.408161
[ Info: iteration 22, average log likelihood -1.408132
[ Info: iteration 23, average log likelihood -1.408107
[ Info: iteration 24, average log likelihood -1.408083
[ Info: iteration 25, average log likelihood -1.408061
[ Info: iteration 26, average log likelihood -1.408041
[ Info: iteration 27, average log likelihood -1.408021
[ Info: iteration 28, average log likelihood -1.408002
[ Info: iteration 29, average log likelihood -1.407984
[ Info: iteration 30, average log likelihood -1.407967
[ Info: iteration 31, average log likelihood -1.407950
[ Info: iteration 32, average log likelihood -1.407933
[ Info: iteration 33, average log likelihood -1.407917
[ Info: iteration 34, average log likelihood -1.407901
[ Info: iteration 35, average log likelihood -1.407885
[ Info: iteration 36, average log likelihood -1.407869
[ Info: iteration 37, average log likelihood -1.407854
[ Info: iteration 38, average log likelihood -1.407839
[ Info: iteration 39, average log likelihood -1.407824
[ Info: iteration 40, average log likelihood -1.407809
[ Info: iteration 41, average log likelihood -1.407794
[ Info: iteration 42, average log likelihood -1.407779
[ Info: iteration 43, average log likelihood -1.407765
[ Info: iteration 44, average log likelihood -1.407751
[ Info: iteration 45, average log likelihood -1.407736
[ Info: iteration 46, average log likelihood -1.407722
[ Info: iteration 47, average log likelihood -1.407708
[ Info: iteration 48, average log likelihood -1.407694
[ Info: iteration 49, average log likelihood -1.407681
[ Info: iteration 50, average log likelihood -1.407667
┌ Info: EM with 100000 data points 50 iterations avll -1.407667
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4096365263733261
│     -1.4095839053273416
│      ⋮
└     -1.4076673473667944
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407663
[ Info: iteration 2, average log likelihood -1.407590
[ Info: iteration 3, average log likelihood -1.407519
[ Info: iteration 4, average log likelihood -1.407437
[ Info: iteration 5, average log likelihood -1.407334
[ Info: iteration 6, average log likelihood -1.407205
[ Info: iteration 7, average log likelihood -1.407050
[ Info: iteration 8, average log likelihood -1.406875
[ Info: iteration 9, average log likelihood -1.406689
[ Info: iteration 10, average log likelihood -1.406505
[ Info: iteration 11, average log likelihood -1.406332
[ Info: iteration 12, average log likelihood -1.406177
[ Info: iteration 13, average log likelihood -1.406041
[ Info: iteration 14, average log likelihood -1.405923
[ Info: iteration 15, average log likelihood -1.405820
[ Info: iteration 16, average log likelihood -1.405730
[ Info: iteration 17, average log likelihood -1.405652
[ Info: iteration 18, average log likelihood -1.405582
[ Info: iteration 19, average log likelihood -1.405521
[ Info: iteration 20, average log likelihood -1.405466
[ Info: iteration 21, average log likelihood -1.405417
[ Info: iteration 22, average log likelihood -1.405372
[ Info: iteration 23, average log likelihood -1.405331
[ Info: iteration 24, average log likelihood -1.405293
[ Info: iteration 25, average log likelihood -1.405258
[ Info: iteration 26, average log likelihood -1.405224
[ Info: iteration 27, average log likelihood -1.405193
[ Info: iteration 28, average log likelihood -1.405164
[ Info: iteration 29, average log likelihood -1.405136
[ Info: iteration 30, average log likelihood -1.405110
[ Info: iteration 31, average log likelihood -1.405085
[ Info: iteration 32, average log likelihood -1.405062
[ Info: iteration 33, average log likelihood -1.405040
[ Info: iteration 34, average log likelihood -1.405019
[ Info: iteration 35, average log likelihood -1.404999
[ Info: iteration 36, average log likelihood -1.404980
[ Info: iteration 37, average log likelihood -1.404962
[ Info: iteration 38, average log likelihood -1.404945
[ Info: iteration 39, average log likelihood -1.404928
[ Info: iteration 40, average log likelihood -1.404913
[ Info: iteration 41, average log likelihood -1.404898
[ Info: iteration 42, average log likelihood -1.404884
[ Info: iteration 43, average log likelihood -1.404870
[ Info: iteration 44, average log likelihood -1.404856
[ Info: iteration 45, average log likelihood -1.404844
[ Info: iteration 46, average log likelihood -1.404831
[ Info: iteration 47, average log likelihood -1.404819
[ Info: iteration 48, average log likelihood -1.404807
[ Info: iteration 49, average log likelihood -1.404796
[ Info: iteration 50, average log likelihood -1.404785
┌ Info: EM with 100000 data points 50 iterations avll -1.404785
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4076626057283095
│     -1.4075901465164795
│      ⋮
└     -1.4047847892361438
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4173674920721349
│     -1.417385519829058
│     -1.4173307975714737
│     -1.4172900634573025
│      ⋮
│     -1.404807290593849
│     -1.4047958823166677
└     -1.4047847892361438
32×26 Array{Float64,2}:
  0.0131748   0.000340278  -0.741862    0.202169    0.10156     -0.289683     0.0254299   -0.24647      0.291126    0.0168832     0.134149     -0.280217     0.4716      0.12949     -0.66713      0.138652    -0.285852   -0.541948    -0.126644    0.115974   -0.21378     -0.185636    -0.262668     0.251926   -0.625763     0.501106
  0.609844    0.398569     -0.190889   -0.326324   -0.127894     0.178744     0.207644     0.215689     0.325198    0.1563        0.468832     -0.0189761    0.205184   -0.0866204   -0.626755    -0.0703336   -0.255646   -0.0872195   -0.664152    0.302013    0.158287     0.211276    -0.0019423   -0.252805   -0.269812     0.263132
  0.0484394  -0.104569     -0.23484     0.238751   -0.171647    -0.112349    -0.484913     0.0750924   -0.194337   -0.0751525     0.328221      0.09328     -0.0783767  -0.00132858   0.257276    -0.345467     0.270133   -0.302198     0.0214336  -0.258449    0.0691575   -0.386373    -0.29227     -0.467741    0.117095    -0.391307
 -0.0451099   0.478849     -0.458922    0.268312   -0.0915265   -0.185656     0.160474     0.190619    -0.179717    0.160076     -0.120594      0.509605    -0.199384    0.0672416    0.136696     0.233471     0.322122   -0.33163     -0.20738    -0.318106   -0.295101    -0.446167     0.0447953    0.657753    0.394647    -0.198487
 -0.137627   -0.892281     -0.130631    0.287858    0.138421     0.322301    -0.112825     0.135407     0.0211552  -0.164281      0.179659     -0.2607       0.349081    0.133227    -0.00938285  -0.474057    -0.0499855   0.221894     0.444162   -0.134702    0.0863016    0.198286     0.19006      0.0649901  -0.00168306   0.586173
 -0.216788    0.267356     -0.351204    0.258354   -0.0101351    0.0665097   -0.140968    -0.0652533   -0.0325334  -0.322525     -0.0874521     0.0388043    0.174482    0.0775046    0.15024      0.0453967   -0.107563    0.322785     0.132229    0.0873354   0.167223     0.194521    -0.146882     0.363723   -0.30027      0.0868437
  0.0629867  -0.0633479     0.0554012   0.117605   -0.011017     0.0738196    0.15161      0.109837    -0.0618993   0.12152      -0.118702     -0.00229802  -0.0402419  -0.162346     0.116811     0.0668504    0.0948179   0.047519     0.0856947  -0.0396961   0.135191     0.00495268  -0.00264932  -0.253713    0.159435    -0.136466
 -0.0232201  -0.133802      0.0565056  -0.243381   -0.173483    -0.22335     -0.0149988   -0.186059     0.0874496   0.0499777    -0.107731     -0.00699973   0.105609    0.0951062   -0.286548    -0.0647961   -0.034686   -0.145       -0.0682984   0.175722   -0.0717215   -0.263051     0.113006     0.251962    0.0366688    0.141128
 -0.154178   -0.111182      0.113995   -0.114981   -0.221685     0.940472    -0.0937585   -0.308597     0.0872926   0.180245      0.00281057   -0.0693788   -0.413447   -0.423539     0.664247    -0.117143    -0.0633151  -0.164813    -0.421195   -0.486679   -0.46519      0.495649     0.47304     -0.0894073  -0.139338    -0.462356
  0.0830264   0.30845       0.37858    -0.174417    0.420144    -0.0627503   -0.0596065   -0.133358     0.441255   -0.118449      0.0279634    -0.0555661   -0.34005    -0.137233    -0.118311     0.307873    -0.294941    0.206401    -0.204401   -0.39264    -0.469761     0.460907    -0.102402     0.171462    0.0222914   -0.0114849
  0.530092   -0.437978      0.366899   -0.184153    0.00759439  -0.213502    -0.0976175    0.13709      0.212381    0.745801     -0.135099     -0.328861    -0.289163   -0.791265    -0.297188    -0.0707342    0.100502   -0.424877     0.397579   -0.0601454  -0.414947     0.0155441   -0.207345    -0.51218     0.306459     0.317379
  0.39676    -0.590934      0.319944   -0.0514511   0.364816     0.171313     0.0889678    0.360543    -0.377305    0.449578     -0.164883      0.927551    -0.204634   -0.1627      -0.0359594    0.0397008    0.118094    0.146435     0.328037   -0.0843709  -0.248366     0.0759206   -0.0722791    0.35147     0.195357    -0.000580684
 -0.257936    0.499114      0.442547   -0.169548   -0.0229102    0.248871    -0.140894     0.0454252   -0.960136   -0.110049     -0.0698943     0.226367    -0.347819   -0.131879    -0.148344     0.406464     0.0301879  -0.133971    -0.201985    0.608909   -0.427617    -0.241708     0.0484967   -0.342604    0.0981785    0.0592809
  0.0800502   0.00264809    0.694943   -0.71792     0.278335     0.00248103   0.454968    -0.339884     0.0199636  -0.0582272     0.291298      0.344167    -0.0573433   0.0359892    0.0232856    0.0812645    0.0433737   0.413482    -0.340486    0.213798    0.143566    -0.0847364   -0.20376     -0.0216073   0.238205    -0.344302
 -0.947065    0.203558      1.0415     -0.513945   -0.0766419   -0.553563    -0.230098     0.207211     0.491855    0.121034     -0.375957     -0.0935852   -0.404691    0.128781     0.188552     0.0365289   -0.416178   -0.111808     0.169747    0.0523489  -0.292134    -0.232703     0.152225    -0.280916   -0.12046     -0.192986
  0.268264   -0.241207      0.537557   -0.439699   -0.538896    -0.342011    -0.121394    -0.359145     0.316297    0.230659     -0.129003     -0.373344    -0.098939    0.556917    -0.131848     0.0333995    0.247341   -0.229801    -0.218321    0.167516   -0.0280084    0.180425     0.312905    -0.134057    0.407059    -0.384536
 -0.100626   -0.0207222    -0.320182    0.137735   -0.603316     0.742425    -0.400458    -0.20855     -0.0813364  -0.544681      0.33295      -0.212352     0.345142   -0.0131272    0.571758    -0.541089    -0.0167687   0.178753     0.141804    0.365033    0.289298     0.184782    -0.505637    -0.323131   -0.229886    -0.0138455
 -0.194639    0.164718     -0.417498    1.08781    -0.3609      -0.262495    -0.780801    -0.0168593    0.0813074  -0.332084     -0.783762     -0.596113    -0.221885    0.130077     0.205848    -0.195574     0.0703617  -0.244981     0.348346   -0.089351   -0.235672     0.123221     0.358087     0.239841    0.116825     0.346549
 -0.0720551  -0.184285     -0.879479    0.226916   -0.137591     0.0904039    0.426914     0.0523754    0.243958    0.399277     -0.586015     -0.125852     0.656777   -0.20265      0.389349    -0.0818401    0.272293    0.205602     0.301516   -0.666512    0.435154     0.0988483    0.100617     0.108705    0.196944    -0.327603
  0.358311   -0.283681     -0.55621     0.359847    0.352628     0.326028    -0.00671225   0.0219766    0.0723421  -0.341436      1.01458       0.240767     0.0312425   0.0348512    0.118122    -0.00890927   0.284285    0.212972    -0.128415   -1.0483     -0.00918003   0.28101     -0.181776     0.199135    0.368626    -0.0159268
 -0.121189    0.269896     -0.176916    0.490247   -0.382089     0.303075     0.677134    -0.062141    -0.249255   -0.292994     -0.420849     -0.403335    -0.34253     0.312967     0.633699     0.360449    -0.754602   -0.690419    -0.0257247  -0.27422    -0.0863184    0.136567     0.585417    -0.387068    0.0726485   -0.0898797
  0.592374    0.0949291     0.28826     0.560901    0.628066     0.433116     0.00686793   0.135766    -0.206481   -0.195325      0.0572977    -0.693597    -0.246306    0.204234     0.467459     0.867828    -0.68348     0.0741444   -0.0230431  -0.228131   -0.246177     0.355686    -0.419048    -0.894654    0.188861    -0.704607
 -0.472938    0.528795      0.0500347  -0.0051297   0.248781     0.222137     0.203489     0.294218     0.524631   -0.0227311    -0.0772974    -0.131284     0.432269   -0.612076    -0.122271     0.460277    -0.0644414   0.554372     0.0912431   0.0298395  -0.0125547    0.779955     0.0848835    0.52359    -0.252744     0.241557
 -0.573925    0.103546      0.0754692   0.232078    0.193859     0.122345    -0.329291    -0.182069    -0.498345   -0.602872     -0.181546      0.19813      0.172229    0.262302     0.0612557    0.120619    -0.181541    0.61159      0.112267    0.154703   -0.201208    -0.270466    -0.141575     0.579835   -0.360457    -0.0345285
  0.296434   -0.0303516     0.28294    -0.222439    0.0216748   -0.0911697   -0.0246203    0.226374    -0.321156    0.299662      0.244411      0.323682    -0.340185    0.050766    -0.0580241   -0.0813475    0.152364   -0.418711    -0.330432   -0.0569235  -0.280819    -0.8349      -0.188878    -0.406402    0.102532    -0.428659
 -0.0213957   0.0872768     0.15685    -0.181981    0.0452725    0.00499084   0.193207    -0.185248     0.270288    0.0323021    -0.000704869  -0.0961563   -0.0801471  -0.0830572   -0.0583142    0.141243    -0.159244   -0.0354903   -0.0666918  -0.0107586  -0.0273305    0.346742     0.104727     0.0737884   0.137587     0.0665455
 -0.362053    0.401902     -0.0727114   0.252864    0.104229    -0.335126    -0.207635     0.331114     0.102997    0.206541      0.264297      0.345192    -0.435023   -0.241131     0.0270737   -0.622144     0.0685202   0.0795933   -0.575566    0.0609874   0.194952    -0.25049     -0.0183649   -0.881103    0.598378     0.931832
  0.338414   -0.426206     -0.0740257   0.103411   -0.139157    -0.499429     0.235611    -0.285806    -0.127251   -0.211767      0.139496      0.0573596    0.186127    0.397719    -0.536828    -0.219311     0.249771    0.00595655   0.405106    0.690476    0.579887    -0.592716     0.0141997   -0.340828    0.403082     0.42888
  0.294611   -0.902786      0.0195261  -0.443884    0.0267553    0.112025     0.311231    -0.09506     -0.329546    0.546242     -0.871678     -0.745185     0.317698    0.0763944   -0.127517     0.863713     0.373627    0.25694      0.264596    0.0814144  -0.217012    -0.0842015    0.134695     0.829363   -0.601539    -0.24727
  0.383674    0.012768      0.177582   -0.159422    0.210608    -0.521166     0.698902     0.00506038   0.0400271  -0.0925635    -0.422332     -0.102486     0.283083   -0.0333714   -0.439783     0.748451    -0.432249   -0.390664     0.471718    0.420826    0.170144    -0.389656    -0.360196     0.172188   -0.388442     0.00496244
 -0.40983     0.0166901    -0.211499   -0.64043    -0.910422    -0.449627     0.236078    -0.204233     0.2301      0.425474     -0.393995      0.935876     0.25618    -0.271194    -0.74897     -0.826901     0.769687   -0.330892    -0.153608   -0.0226748   0.117259    -0.479197     0.082623     0.718182   -0.289852     0.632732
 -0.229351   -0.432617     -0.0272316  -0.358982    0.115401    -0.406746     0.0538169   -0.326695     1.13722    -0.000148346   0.0328226     0.256141     0.0347563  -0.203092    -0.244019    -0.709111     0.224882    0.202735     0.409293   -0.193051    0.219667     0.295471     0.0663505    0.751215    0.0827244    0.112534[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.404774
[ Info: iteration 2, average log likelihood -1.404763
[ Info: iteration 3, average log likelihood -1.404753
[ Info: iteration 4, average log likelihood -1.404743
[ Info: iteration 5, average log likelihood -1.404734
[ Info: iteration 6, average log likelihood -1.404724
[ Info: iteration 7, average log likelihood -1.404715
[ Info: iteration 8, average log likelihood -1.404706
[ Info: iteration 9, average log likelihood -1.404697
[ Info: iteration 10, average log likelihood -1.404689
┌ Info: EM with 100000 data points 10 iterations avll -1.404689
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.283787e+05
      1       7.020168e+05      -2.263618e+05 |       32
      2       6.871081e+05      -1.490875e+04 |       32
      3       6.807511e+05      -6.356953e+03 |       32
      4       6.774217e+05      -3.329455e+03 |       32
      5       6.753414e+05      -2.080288e+03 |       32
      6       6.738581e+05      -1.483233e+03 |       32
      7       6.727514e+05      -1.106701e+03 |       32
      8       6.718456e+05      -9.058638e+02 |       32
      9       6.711249e+05      -7.207142e+02 |       32
     10       6.705214e+05      -6.034961e+02 |       32
     11       6.700160e+05      -5.054208e+02 |       32
     12       6.696048e+05      -4.111089e+02 |       32
     13       6.692451e+05      -3.597821e+02 |       32
     14       6.689282e+05      -3.169051e+02 |       32
     15       6.686281e+05      -3.000757e+02 |       32
     16       6.683555e+05      -2.725803e+02 |       32
     17       6.681057e+05      -2.498080e+02 |       32
     18       6.678680e+05      -2.376812e+02 |       32
     19       6.676529e+05      -2.150669e+02 |       32
     20       6.674583e+05      -1.946756e+02 |       32
     21       6.672735e+05      -1.847793e+02 |       32
     22       6.671110e+05      -1.625248e+02 |       32
     23       6.669483e+05      -1.626959e+02 |       32
     24       6.667923e+05      -1.560080e+02 |       32
     25       6.666490e+05      -1.432207e+02 |       32
     26       6.665352e+05      -1.138276e+02 |       32
     27       6.664293e+05      -1.059631e+02 |       32
     28       6.663392e+05      -9.001818e+01 |       32
     29       6.662664e+05      -7.281817e+01 |       32
     30       6.662042e+05      -6.225630e+01 |       32
     31       6.661457e+05      -5.841243e+01 |       32
     32       6.660960e+05      -4.977315e+01 |       32
     33       6.660493e+05      -4.666204e+01 |       32
     34       6.660067e+05      -4.258034e+01 |       32
     35       6.659667e+05      -4.004705e+01 |       32
     36       6.659223e+05      -4.433852e+01 |       32
     37       6.658847e+05      -3.763572e+01 |       32
     38       6.658449e+05      -3.976468e+01 |       32
     39       6.658017e+05      -4.326015e+01 |       32
     40       6.657552e+05      -4.650545e+01 |       32
     41       6.657057e+05      -4.952103e+01 |       32
     42       6.656587e+05      -4.690957e+01 |       32
     43       6.656160e+05      -4.274985e+01 |       32
     44       6.655697e+05      -4.626902e+01 |       32
     45       6.655270e+05      -4.271905e+01 |       32
     46       6.654904e+05      -3.659668e+01 |       32
     47       6.654546e+05      -3.577452e+01 |       32
     48       6.654145e+05      -4.018206e+01 |       32
     49       6.653768e+05      -3.768236e+01 |       32
     50       6.653399e+05      -3.690252e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 665339.8717397929)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416422
[ Info: iteration 2, average log likelihood -1.411436
[ Info: iteration 3, average log likelihood -1.410120
[ Info: iteration 4, average log likelihood -1.409145
[ Info: iteration 5, average log likelihood -1.408096
[ Info: iteration 6, average log likelihood -1.407109
[ Info: iteration 7, average log likelihood -1.406429
[ Info: iteration 8, average log likelihood -1.406053
[ Info: iteration 9, average log likelihood -1.405846
[ Info: iteration 10, average log likelihood -1.405715
[ Info: iteration 11, average log likelihood -1.405618
[ Info: iteration 12, average log likelihood -1.405539
[ Info: iteration 13, average log likelihood -1.405472
[ Info: iteration 14, average log likelihood -1.405413
[ Info: iteration 15, average log likelihood -1.405360
[ Info: iteration 16, average log likelihood -1.405311
[ Info: iteration 17, average log likelihood -1.405267
[ Info: iteration 18, average log likelihood -1.405226
[ Info: iteration 19, average log likelihood -1.405188
[ Info: iteration 20, average log likelihood -1.405152
[ Info: iteration 21, average log likelihood -1.405119
[ Info: iteration 22, average log likelihood -1.405088
[ Info: iteration 23, average log likelihood -1.405059
[ Info: iteration 24, average log likelihood -1.405032
[ Info: iteration 25, average log likelihood -1.405007
[ Info: iteration 26, average log likelihood -1.404983
[ Info: iteration 27, average log likelihood -1.404961
[ Info: iteration 28, average log likelihood -1.404940
[ Info: iteration 29, average log likelihood -1.404920
[ Info: iteration 30, average log likelihood -1.404901
[ Info: iteration 31, average log likelihood -1.404884
[ Info: iteration 32, average log likelihood -1.404867
[ Info: iteration 33, average log likelihood -1.404851
[ Info: iteration 34, average log likelihood -1.404836
[ Info: iteration 35, average log likelihood -1.404822
[ Info: iteration 36, average log likelihood -1.404808
[ Info: iteration 37, average log likelihood -1.404795
[ Info: iteration 38, average log likelihood -1.404783
[ Info: iteration 39, average log likelihood -1.404771
[ Info: iteration 40, average log likelihood -1.404760
[ Info: iteration 41, average log likelihood -1.404749
[ Info: iteration 42, average log likelihood -1.404738
[ Info: iteration 43, average log likelihood -1.404728
[ Info: iteration 44, average log likelihood -1.404719
[ Info: iteration 45, average log likelihood -1.404709
[ Info: iteration 46, average log likelihood -1.404700
[ Info: iteration 47, average log likelihood -1.404692
[ Info: iteration 48, average log likelihood -1.404683
[ Info: iteration 49, average log likelihood -1.404675
[ Info: iteration 50, average log likelihood -1.404667
┌ Info: EM with 100000 data points 50 iterations avll -1.404667
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.176635    -0.563865   -0.831352    0.230907    0.0553259    0.274158    0.745461   -0.472632    -0.267917    -0.00166909  -0.359421     0.082086    -0.0330573    0.153893     0.18654      0.156532     -0.145948    -0.336388      0.147336    -0.799727   -0.658075      0.118835    0.762866     0.822107    -0.394826    0.0584665
 -0.175684     0.469108    0.44555    -0.434111    0.0161769    0.291978    0.248664    0.201755    -0.0239109    0.321806    -0.757436    -0.150885     0.199927    -0.514813    -0.361898     0.63031      -0.12342      0.29185      -0.186104     0.511508   -0.435184      0.260831   -0.0195709    0.497599    -0.383125   -0.00766186
 -0.303879     0.127804   -0.265606    0.122243    0.153586     0.274204   -0.146962    0.241913     0.450303    -0.506382     0.378546    -0.17276      0.336717     0.205686     0.0352704    0.0659629    -0.601627     0.422298      0.300964    -0.171601   -0.00745487    0.48274     0.0658026    0.687127    -0.404781    0.285356
 -0.303862     0.56247    -0.240638    0.959513   -0.495204    -0.364577   -0.67749     0.0830844    0.0113256   -0.360522    -0.647997    -0.389815    -0.515647     0.466874     0.0343136   -0.273146      0.241423    -0.445717     -0.221214     0.011937   -0.374776     -0.117114    0.422733     0.211277     0.201292    0.152163
 -0.20516      0.457405    0.416785   -0.278419    0.00771062   0.212196    0.0533613   0.0428629   -0.987169    -0.223268     0.128826     0.429821    -0.419905     0.0191374   -0.194812     0.42246      -0.0188547   -0.241072     -0.295226     0.595707   -0.41346      -0.456289    0.11085     -0.268254     0.143704    0.0627686
  0.0152098    0.597892   -0.55007    -0.0563389   0.158253    -0.260258    0.374943    0.270287    -0.0145911    0.383047     0.00858885   0.515147    -0.156677    -0.163027     0.0462513    0.538997      0.342381    -0.310594     -0.369389    -0.658705   -0.421527     -0.355165    0.0173166    0.775325     0.436135   -0.408879
  0.409176    -0.0517738  -0.390908   -0.192919    0.0362162   -0.227129    0.442727   -0.120156     0.509534     0.15704      0.152795    -0.363204     0.455774     0.286067    -0.774767     0.24722      -0.320808    -0.537641     -0.218305     0.189314   -0.120005     -0.0803633  -0.370823     0.175827    -0.473561    0.390888
 -0.409513     0.103407    0.0364335   0.382991    0.318782    -0.454803    0.0140198  -0.0914131   -0.376738    -0.295098    -0.357402     0.216856     0.283593     0.106115    -0.102023     0.163606     -0.0765126    0.328076      0.516241     0.392285    0.229938     -0.667169   -0.350395     0.367833    -0.0743679   0.154736
  0.376367     0.229917    0.122494    0.621688    0.184857     0.446325    0.327808    0.224279    -0.339811    -0.178367    -0.1085      -0.549092    -0.25052      0.385191     0.394332     0.938532     -0.665454    -0.226227     -0.0634626   -0.247041   -0.212442      0.165302   -0.0789751   -0.707054     0.132035   -0.41042
 -0.417986    -0.414675    0.994398   -0.501826   -0.169281    -0.0479578  -0.609176    0.442714    -0.119782     0.260179     0.127745     0.173735    -0.5626       0.303475     0.417971    -0.277981      0.0724307   -0.278087     -0.0759257   -0.186225   -0.784508     -0.547128    0.00824812  -0.297554    -0.0861768  -0.50853
  0.0329694   -0.590208   -0.499107    0.600864   -0.310099    -0.0572947  -0.517688    0.105113     0.19876      0.183997    -0.50014     -0.529591     0.338255    -0.184717     0.0610343   -0.237845      0.148486     0.128558      0.886606    -0.401224   -0.142594      0.364623   -0.0293441    0.162554     0.209275    0.461108
  0.711696    -0.220229    0.652704   -0.307378    0.205595    -0.745167   -0.195982   -0.385388     0.178032     0.305928     0.136049     0.051703    -0.707465    -0.0736491   -0.386942    -0.000912604  -0.0201834   -0.436956     -0.147182     0.144655   -0.287255     -0.645018   -0.370051    -0.428953     0.424635    0.0971997
 -0.436953     0.23301    -0.661336    0.413799    0.192198     0.606375    0.539641    0.461637     0.271316    -0.0764501   -0.170317    -0.0599063    0.626486    -0.218545     0.400016    -0.158102      0.412932     0.915807      0.00688447  -0.6925      0.712653      0.501482   -0.0905108    0.195164     0.128753   -0.252085
  0.0594581    0.0950512  -0.0185966  -0.0493543   0.00126999   0.239551    0.133161    0.189393     0.115851     0.368449     0.606853     0.251888    -0.331051    -0.248752    -0.175       -0.789923     -0.00575005  -0.137579     -0.563153     0.466475    0.247652     -0.0282684   0.25089     -0.724119     0.398572    0.488233
 -0.232876     0.649748    0.33275    -0.315429   -0.560411     0.227088   -0.267278   -0.347753     0.265226    -0.76446      0.223969    -0.091299     0.066954    -0.00926648   0.473887    -0.131595     -0.028279     0.21556      -0.103004     0.324879    0.339138      0.137212   -1.08977     -0.109135    -0.12211    -0.174001
 -0.299028    -0.0749647  -0.245356   -0.0502382  -0.736774     1.30657    -0.120281   -0.0577423   -0.141388     0.180908    -0.253566     0.124812     0.145964    -0.111568     0.83054      0.0357747     0.215165     0.031509     -0.288012     0.0967051  -0.41448       0.71599     0.356101     0.0463047   -0.0297634  -0.319471
 -0.23529      0.0208221   0.299911    0.053475    0.265076     0.525492   -0.173364   -0.446959     0.169841     0.0482141    0.120922    -0.326388    -0.447657    -0.445439     0.778487     0.0900771    -0.409501     0.0366727    -0.119316    -0.722297   -0.361603      0.505886    0.183231    -0.0634338    0.181219   -0.310282
  0.218426    -0.0475908  -0.810004    0.444155   -0.317252     0.557293   -0.475889   -0.0115937   -0.640712    -0.397717     0.527778     0.0253178    0.308822     0.0368641    0.346978    -0.441778     -0.0510442   -0.0711174     0.0490507    0.0327435   0.000349717  -0.312235   -0.582055    -0.248552    -0.319251   -0.0419953
 -0.0515633    0.0659471   0.12863     0.0151383   0.0558542    0.108253    0.0480208  -0.0782497   -0.0373624   -0.0661589   -0.12111      0.00524019  -0.138467    -0.0421214    0.163559     0.119796     -0.0307961    0.0306314     0.0485781   -0.0858351  -0.135506      0.0522399  -0.0140826   -0.00823705   0.0583727  -0.213121
  0.215121    -0.309391   -0.39879     0.502024    0.102406    -0.143122   -0.329667    0.0141351    0.133709    -0.330479     0.780414     0.286775    -0.134349     0.320547     0.183888    -0.440648      0.334663    -0.000349338  -0.0975088   -0.865233    0.099317     -0.088189   -0.132684    -0.265096     0.688369   -0.101151
  0.291807    -0.828652    0.0796874  -0.383271   -0.00530846   0.0433156   0.10425    -0.226156    -0.221003     0.436211    -0.646483    -0.502562     0.375263     0.0668359   -0.12248      0.622276      0.365348     0.214425      0.470539     0.187093    0.0679187    -0.124892   -0.0164265    0.67421     -0.452941   -0.409766
  0.2427      -0.226443    0.209742   -0.422904   -0.747429    -0.285033    0.201751   -0.526812     0.122374    -0.00903367  -0.405016    -0.377969     0.113138     0.579963     0.153337    -0.182892     -0.140415    -0.689193     -0.0867722    0.251578    0.326598      0.0184173   0.522106    -0.58405      0.326355   -0.658943
 -0.595056     0.15624    -0.564692    0.375981    0.321173    -0.0947387  -0.186258   -0.972379    -0.0735614   -0.862976    -0.158969    -0.00951676   0.321176    -0.220142    -0.0436307    0.208483     -0.456295     0.126474      0.00061554   0.585821    0.168672      0.535362    0.549754     0.0120326   -0.551891    0.443842
 -0.475044     0.173364    0.713045   -0.451406   -0.04281     -0.572386    0.180543   -0.105512     0.749826     0.21776     -0.535233    -0.311537    -0.317739    -0.0614786   -0.123285     0.187783     -0.358826     0.00411732    0.0517237    0.1195     -0.215389     -0.0391864   0.438198     0.21866      0.143204    0.12925
  0.245137    -0.0179075  -0.179153    0.192294   -0.0191985   -0.159445    0.269713    0.403093     0.0142289    0.595835    -0.271763     0.0900608   -0.00288938  -0.677808     0.00997624   0.0277772     0.0542223   -0.384315      0.132315    -0.165397    0.255677     -0.0483503  -0.00520453  -0.580231     0.0385202   0.0982868
  0.193842    -0.0516706   0.616221   -0.542583   -0.170802    -0.180123    0.253915   -0.129112     0.00540856   0.108613     0.233498    -0.0130117    0.21422      0.473671    -0.256618     0.273109      0.322707     0.510296     -0.222639     0.192708    0.264453      0.373942    0.0526991   -0.0930022    0.520546   -0.0030888
 -0.346273    -0.109561   -0.189454   -0.629648   -0.675251    -0.462415    0.142895   -0.267095     0.378497     0.329385    -0.243491     0.788205     0.283716    -0.251195    -0.618382    -0.910638      0.696413    -0.200287     -0.0987573   -0.0223284   0.175172     -0.333197    0.101885     0.666292    -0.198714    0.429862
 -0.192556    -0.912763    0.225296    0.194421   -0.0827958    0.411482    0.20768    -0.153294     0.08121     -0.360555     0.259643    -0.436661     0.0133423    0.0911403   -0.0481622   -0.650644      0.221488     0.0753148     0.677498     0.443032    0.521004     -0.203672    0.187456    -0.450155     0.132444    0.209988
  0.00541096   0.396918    0.160964   -0.185252    0.232316     0.0761143  -0.49536     0.0885286    0.324931    -0.0366639    0.326269    -0.149421    -0.0736354   -0.416608    -0.276321    -0.183491     -0.214586     0.19524      -0.607097    -0.129956   -0.228986      0.287909   -0.0926437   -0.35647     -0.298262    0.00097332
  0.029474    -0.146258   -0.30146     0.0820662  -0.195824    -0.154196   -0.124054    0.00982306  -0.0554395    0.04573      0.0385458    0.161016     0.167032     0.0531717   -0.092826    -0.268045      0.120113    -0.0387882    -0.0423875    0.108095    0.192103     -0.201849   -0.0437057    0.127331     0.0778997   0.247914
  0.235542    -0.0189664   0.0394923  -0.13564     0.0855732   -0.265484    0.289956    0.0463153    0.0730615   -0.0475337    0.00881493   0.0802985    0.18185      0.117766    -0.301665     0.340465     -0.00143115  -0.0113073     0.134472     0.0953734   0.160358     -0.161534   -0.117189     0.0906458   -0.0251022  -0.037565
  0.440734    -0.449179    0.369136   -0.305477    0.67205      0.228172    0.16671    -0.0752628    0.265899     0.039957     0.352374     0.776177    -0.163361    -0.27279     -0.161932     0.0701013     0.234533     0.449296      0.0992029   -0.270136   -0.30563       0.472723   -0.265645     0.571914     0.0281324   0.0473658[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.404660
[ Info: iteration 2, average log likelihood -1.404652
[ Info: iteration 3, average log likelihood -1.404645
[ Info: iteration 4, average log likelihood -1.404638
[ Info: iteration 5, average log likelihood -1.404631
[ Info: iteration 6, average log likelihood -1.404624
[ Info: iteration 7, average log likelihood -1.404617
[ Info: iteration 8, average log likelihood -1.404611
[ Info: iteration 9, average log likelihood -1.404605
[ Info: iteration 10, average log likelihood -1.404598
┌ Info: EM with 100000 data points 10 iterations avll -1.404598
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
