Julia Version 1.5.0-DEV.256
Commit 4513dda9e3 (2020-02-10 18:52 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed GaussianMixtures ─── v0.3.0
  Installed CMake ────────────── v1.1.2
  Installed Arpack ───────────── v0.4.0
  Installed HDF5 ─────────────── v0.12.5
  Installed QuadGK ───────────── v2.3.1
  Installed DataStructures ───── v0.17.9
  Installed StatsBase ────────── v0.32.0
  Installed Missings ─────────── v0.4.3
  Installed Arpack_jll ───────── v3.5.0+2
  Installed JLD ──────────────── v0.9.2
  Installed ScikitLearnBase ──── v0.5.0
  Installed Compat ───────────── v2.2.0
  Installed OrderedCollections ─ v1.1.0
  Installed Parameters ───────── v0.12.0
  Installed BinDeps ──────────── v1.0.0
  Installed SortingAlgorithms ── v0.3.1
  Installed Distributions ────── v0.22.4
  Installed BinaryProvider ───── v0.5.8
  Installed Distances ────────── v0.8.2
  Installed SpecialFunctions ─── v0.9.0
  Installed StaticArrays ─────── v0.12.1
  Installed FileIO ───────────── v1.2.2
  Installed URIParser ────────── v0.4.0
  Installed Rmath ────────────── v0.6.0
  Installed NearestNeighbors ─── v0.4.4
  Installed Clustering ───────── v0.13.3
  Installed Blosc ────────────── v0.5.1
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed LegacyStrings ────── v0.4.1
  Installed DataAPI ──────────── v1.1.0
  Installed CMakeWrapper ─────── v0.2.3
  Installed StatsFuns ────────── v0.9.3
  Installed PDMats ───────────── v0.9.11
  Installed FillArrays ───────── v0.8.4
#=#=#                                                                         ##O#- #                                                                       ###############                                                           21.2%######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                         #                                                                          2.2%####                                                                       5.8%#####                                                                      7.5%#######                                                                   10.9%############                                                              16.8%############                                                              17.2%################                                                          23.5%#####################                                                     29.7%##########################                                                36.2%#################################                                         46.7%##############################################                            64.1%############################################################              83.7%######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.2
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_zjVaJa/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.2
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -1.6133423775112354e6, [14718.091279562037, 85281.90872043798], [2596.467185848235 -6523.92795614119 -3647.969758285756; -2714.887939852874 5864.984205880425 3306.5539343370074], [[9522.65591274216 3438.618428422939 1729.2732686226136; 3438.618428422939 7701.074622735852 -2823.0296582279357; 1729.2732686226136 -2823.0296582279357 16703.41942151792], [90310.38948905564 -3041.6839868643374 -1846.9447171383588; -3041.6839868643374 92601.50939746725 2975.9989746920173; -1846.9447171383586 2975.9989746920173 82536.76696729288]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.321921e+03
      1       1.097019e+03      -2.249025e+02 |        7
      2       1.047678e+03      -4.934065e+01 |        4
      3       9.907778e+02      -5.690031e+01 |        0
      4       9.907778e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 990.7778045636969)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.062576
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.726723
[ Info: iteration 2, lowerbound -3.592857
[ Info: iteration 3, lowerbound -3.467956
[ Info: iteration 4, lowerbound -3.344582
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.228682
[ Info: iteration 6, lowerbound -3.132510
[ Info: dropping number of Gaussions to 6
[ Info: iteration 7, lowerbound -3.059264
[ Info: iteration 8, lowerbound -3.002352
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.952338
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.891856
[ Info: iteration 11, lowerbound -2.834952
[ Info: iteration 12, lowerbound -2.791613
[ Info: iteration 13, lowerbound -2.763375
[ Info: iteration 14, lowerbound -2.748547
[ Info: dropping number of Gaussions to 3
[ Info: iteration 15, lowerbound -2.724339
[ Info: iteration 16, lowerbound -2.695871
[ Info: iteration 17, lowerbound -2.664776
[ Info: iteration 18, lowerbound -2.627772
[ Info: iteration 19, lowerbound -2.586154
[ Info: iteration 20, lowerbound -2.542113
[ Info: iteration 21, lowerbound -2.498320
[ Info: iteration 22, lowerbound -2.457083
[ Info: iteration 23, lowerbound -2.419507
[ Info: iteration 24, lowerbound -2.385387
[ Info: iteration 25, lowerbound -2.354357
[ Info: iteration 26, lowerbound -2.328055
[ Info: iteration 27, lowerbound -2.311182
[ Info: iteration 28, lowerbound -2.307870
[ Info: dropping number of Gaussions to 2
[ Info: iteration 29, lowerbound -2.302916
[ Info: iteration 30, lowerbound -2.299259
[ Info: iteration 31, lowerbound -2.299256
[ Info: iteration 32, lowerbound -2.299254
[ Info: iteration 33, lowerbound -2.299254
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Mon Feb 10 23:54:48 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Mon Feb 10 23:54:56 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Mon Feb 10 23:54:59 2020: EM with 272 data points 0 iterations avll -2.062576
5.8 data points per parameter
, Mon Feb 10 23:55:01 2020: GMM converted to Variational GMM
, Mon Feb 10 23:55:10 2020: iteration 1, lowerbound -3.726723
, Mon Feb 10 23:55:10 2020: iteration 2, lowerbound -3.592857
, Mon Feb 10 23:55:10 2020: iteration 3, lowerbound -3.467956
, Mon Feb 10 23:55:10 2020: iteration 4, lowerbound -3.344582
, Mon Feb 10 23:55:11 2020: dropping number of Gaussions to 7
, Mon Feb 10 23:55:11 2020: iteration 5, lowerbound -3.228682
, Mon Feb 10 23:55:11 2020: iteration 6, lowerbound -3.132510
, Mon Feb 10 23:55:11 2020: dropping number of Gaussions to 6
, Mon Feb 10 23:55:11 2020: iteration 7, lowerbound -3.059264
, Mon Feb 10 23:55:11 2020: iteration 8, lowerbound -3.002352
, Mon Feb 10 23:55:11 2020: dropping number of Gaussions to 5
, Mon Feb 10 23:55:11 2020: iteration 9, lowerbound -2.952338
, Mon Feb 10 23:55:11 2020: dropping number of Gaussions to 4
, Mon Feb 10 23:55:11 2020: iteration 10, lowerbound -2.891856
, Mon Feb 10 23:55:11 2020: iteration 11, lowerbound -2.834952
, Mon Feb 10 23:55:11 2020: iteration 12, lowerbound -2.791613
, Mon Feb 10 23:55:11 2020: iteration 13, lowerbound -2.763375
, Mon Feb 10 23:55:11 2020: iteration 14, lowerbound -2.748547
, Mon Feb 10 23:55:11 2020: dropping number of Gaussions to 3
, Mon Feb 10 23:55:11 2020: iteration 15, lowerbound -2.724339
, Mon Feb 10 23:55:11 2020: iteration 16, lowerbound -2.695871
, Mon Feb 10 23:55:11 2020: iteration 17, lowerbound -2.664776
, Mon Feb 10 23:55:11 2020: iteration 18, lowerbound -2.627772
, Mon Feb 10 23:55:11 2020: iteration 19, lowerbound -2.586154
, Mon Feb 10 23:55:11 2020: iteration 20, lowerbound -2.542113
, Mon Feb 10 23:55:11 2020: iteration 21, lowerbound -2.498320
, Mon Feb 10 23:55:11 2020: iteration 22, lowerbound -2.457083
, Mon Feb 10 23:55:11 2020: iteration 23, lowerbound -2.419507
, Mon Feb 10 23:55:11 2020: iteration 24, lowerbound -2.385387
, Mon Feb 10 23:55:11 2020: iteration 25, lowerbound -2.354357
, Mon Feb 10 23:55:11 2020: iteration 26, lowerbound -2.328055
, Mon Feb 10 23:55:11 2020: iteration 27, lowerbound -2.311182
, Mon Feb 10 23:55:11 2020: iteration 28, lowerbound -2.307870
, Mon Feb 10 23:55:11 2020: dropping number of Gaussions to 2
, Mon Feb 10 23:55:11 2020: iteration 29, lowerbound -2.302916
, Mon Feb 10 23:55:11 2020: iteration 30, lowerbound -2.299259
, Mon Feb 10 23:55:11 2020: iteration 31, lowerbound -2.299256
, Mon Feb 10 23:55:11 2020: iteration 32, lowerbound -2.299254
, Mon Feb 10 23:55:11 2020: iteration 33, lowerbound -2.299254
, Mon Feb 10 23:55:11 2020: iteration 34, lowerbound -2.299253
, Mon Feb 10 23:55:11 2020: iteration 35, lowerbound -2.299253
, Mon Feb 10 23:55:11 2020: iteration 36, lowerbound -2.299253
, Mon Feb 10 23:55:11 2020: iteration 37, lowerbound -2.299253
, Mon Feb 10 23:55:11 2020: iteration 38, lowerbound -2.299253
, Mon Feb 10 23:55:11 2020: iteration 39, lowerbound -2.299253
, Mon Feb 10 23:55:11 2020: iteration 40, lowerbound -2.299253
, Mon Feb 10 23:55:11 2020: iteration 41, lowerbound -2.299253
, Mon Feb 10 23:55:11 2020: iteration 42, lowerbound -2.299253
, Mon Feb 10 23:55:11 2020: iteration 43, lowerbound -2.299253
, Mon Feb 10 23:55:11 2020: iteration 44, lowerbound -2.299253
, Mon Feb 10 23:55:11 2020: iteration 45, lowerbound -2.299253
, Mon Feb 10 23:55:11 2020: iteration 46, lowerbound -2.299253
, Mon Feb 10 23:55:11 2020: iteration 47, lowerbound -2.299253
, Mon Feb 10 23:55:11 2020: iteration 48, lowerbound -2.299253
, Mon Feb 10 23:55:11 2020: iteration 49, lowerbound -2.299253
, Mon Feb 10 23:55:11 2020: iteration 50, lowerbound -2.299253
, Mon Feb 10 23:55:11 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777329749, 178.0450922267025]
β = [95.95490777329749, 178.0450922267025]
m = [2.0002292577695853 53.85198717243115; 4.250300733264325 79.28686694427968]
ν = [97.95490777329749, 180.0450922267025]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763612044585 -0.00895312382746023; 0.0 0.012748664777438499], [0.18404155547407836 -0.007644049042400767; 0.0 0.008581705166230063]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000003
avll from stats: -0.998561690763016
avll from llpg:  -0.9985616907630145
avll direct:     -0.9985616907630145
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9906698831673709
avll from llpg:  -0.9906698831673708
avll direct:     -0.9906698831673708
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
 -0.0406079   -0.0280407    0.207604      0.00721549    0.139309     0.0376605   -0.0084664    0.0324742   -0.183495    -0.0329113    -0.148204    0.209442     0.0104551    0.116305    -0.0322702  -0.00181952   0.121776     0.118347      0.0179368   -0.00126072   0.0987375  -0.144136    -0.0354826    0.00394744   0.126518    -0.0134243
 -0.0653474   -0.130007     0.0487496    -0.0145959     0.216108     0.0893072   -0.174241     0.0192877    0.110847     0.00779118   -0.161137   -0.0324547   -0.0359139   -0.147084     0.0036404  -0.220991    -0.183645    -0.041549     -0.0554294   -0.0976434    0.0821603  -0.02336      0.0225512    0.0803309    0.00746951  -0.128543
  0.151484     0.0813173    0.27596       0.00830686   -0.0968475   -0.090464    -0.143802     0.143948    -0.10413      0.000327438   0.050245   -0.1271      -0.0502388    0.159588    -0.0572654  -0.0290906   -0.269558    -0.125416      0.0132811    0.0916199    0.0527136  -0.0210234    0.0660634    0.145517    -0.10468      0.114619
 -0.0498367   -0.0349998    0.0206338     0.096666     -0.0170198    0.0363078   -0.135017     0.0580387   -0.0859769   -0.0998414    -0.105371    0.124001    -0.00225461   0.0897438   -0.0937496  -0.112652     0.0616191    0.0419954    -0.0294872    0.100238     0.023799   -0.0815245   -0.142639    -0.0573238    0.016882     0.223089
  0.0946267    0.0325824   -0.000765543   0.138643      0.00260621   0.143814     0.0374274   -0.00810761   0.0374568    0.073588      0.230385   -0.0592582    0.020689    -0.138453     0.0106463   0.104371    -0.0778025    0.1434        0.0847365   -0.0777668   -0.0665995  -0.0297036    0.0787415    0.0371886    0.201081    -0.112623
  0.0828227   -0.0323362    0.0214623     0.0490566    -0.0474901   -0.0595961   -0.0211398    0.105065     0.010485    -0.0802916    -0.167062    0.0284318   -0.149861    -0.107459    -0.110856    0.167948     0.0818764   -0.0626139    -0.158501     0.246766     0.150004    0.0984226   -0.0242844   -0.178116     0.0366803   -0.0572329
  0.141966    -0.0959963   -0.0735972     0.0357403     0.0861572    0.029581     0.0277543   -0.0220562   -0.101106    -0.0272471     0.019061    0.075526     0.0931884    0.064829    -0.100029    0.0216639    0.0457515    0.18282       0.0290854   -0.0115741   -0.0382594   0.323361    -0.0406575   -0.131129     0.0560184    0.130848
  0.062179    -0.0100329    0.00606793   -0.14779      -0.024421     0.0331985    0.111265    -0.0243288   -0.14257     -0.070484      0.0844574  -0.0540809    0.0709057   -0.234468     0.023089   -0.0115986    0.116896    -0.00478078    0.0818319    0.160906     0.210479    0.0460438    0.0835513   -0.0308028   -0.0853052   -0.0887813
 -0.0367202   -0.0448901    0.085196      0.103698     -0.127001     0.00716971  -0.0938922    0.175788     0.0813702    0.00444711    0.0578142   0.119485    -0.00788643  -0.23167     -0.0338239   0.0443195   -0.0768763   -0.00531598    0.0171653   -0.116742     0.0792261   0.0791049   -0.188569     0.134297    -0.0642019    0.123873
 -0.129322    -0.060015    -0.0333715    -0.000619479   0.0401339    0.0385368    0.173402    -0.184671    -0.0248502    0.230096      0.0316383  -0.0897893   -0.106872     0.101201     0.0757338  -0.0931972   -0.112418    -0.0273857    -0.167981    -0.2752      -0.195365   -0.0417681   -0.171784     0.197979     0.0230988    0.307192
  0.164315     0.136571    -0.0108891    -0.00705468   -0.0467666   -0.0102045    0.0660016   -0.00675746   0.171681    -0.0823221    -0.058923    0.139952     0.17933     -0.00733414   0.0122632  -0.1358      -0.10061     -0.164096      0.0103807   -0.0595977   -0.0788545  -0.0708422   -0.0116131   -0.018413     0.0844459    0.0164737
 -0.0741667    0.156315     0.0167712     0.0556921     0.0646939    0.00503808   0.0467068    0.0418277    0.0828259   -0.14898       0.0058325  -0.131641     0.0103469   -0.0760816   -0.0349598   0.0488504    0.00151551  -0.0993346     0.167691    -0.0131692    0.0536519   0.0652161   -0.011171     0.0777008    0.0244339    0.0573765
 -0.151886     0.20804     -0.0059072     0.0437332     0.0387912   -0.0629938   -0.00624136  -0.143758    -0.0932793   -0.00818656   -0.039459   -0.072557     0.0687499   -0.18737     -0.145508    0.0277332    0.0518459    0.0795229     0.0141755   -0.0162085    0.16167    -0.00469794  -0.0999633   -0.281974    -0.0492338   -0.0943705
 -0.106852    -0.0941944    0.013002      0.107424      0.0173463    0.0904342    0.02611     -0.0798294   -0.109042     0.12263       0.0327258   0.124761     0.0382721    0.0479408    0.0829807  -0.151349     0.0809764    0.0332783     0.0538771    0.0219621   -0.0696297  -0.0129266   -0.00140471   0.0711715    0.0782438    0.121392
 -0.01714     -0.0139971   -0.0416227     0.0404465    -0.086382     0.131609    -0.00414917   0.00350098   0.00365351  -0.00832228    0.0451029   0.01599     -0.0989059    0.0203983    0.068123    0.0489924   -0.144421     0.0117429    -0.0512697   -0.134216    -0.100038   -0.155773    -0.0980417    0.0075547   -0.0671368    0.0655003
 -0.16471     -0.0486101   -0.0777718    -0.0902672     0.0125475   -0.0114663   -0.0960872   -0.0653272    0.0477956    0.0735735    -0.0577284   0.0524972   -0.0767132   -0.193187    -0.135545    0.153612    -0.0767118    0.174269     -0.0340592    0.15944      0.248771    0.078488     0.0989924    0.161482     0.0378104   -0.0198564
  0.108386     0.095513    -0.174141     -0.0343346     0.0561985    0.213732     0.0548206   -0.0775206   -0.0397984   -0.0586176     0.0298294   0.0846342    0.0999985    0.00505619   0.0437979   0.0977638   -0.0771887   -1.40363e-5    0.00416731   0.0705587   -0.0686784   0.0408829    0.0522102    0.0285401    0.0643671    0.111426
 -0.125573    -0.192921    -0.0539461    -0.00113614    0.120072     0.0357847    0.00518844   0.0500652   -0.0799936   -0.174582     -0.056373    0.0246643   -0.233343     0.0415991   -0.138407    0.087909     0.0673821    0.01056      -0.151456     0.0489764   -0.0451925   0.192207    -0.0994505   -0.0684869   -0.143312    -0.0535894
  0.143028    -0.0156107   -0.00779188   -0.153956      0.0575732    0.0938252    0.0356786    0.03857      0.0245821   -0.110352     -0.123552   -0.0161481    0.00605605   0.283289     0.101318    0.0572525   -0.0456317    0.0736393     0.110081     0.117441    -0.189291    0.142209     0.116863     0.0745966    0.0192311    0.0336514
 -0.0754496    0.122865     0.00118165    0.0088321    -0.12005      0.167643    -0.0930542   -0.0549656    0.0118388   -0.0381851     0.103314   -0.0711949   -0.125178     0.00250259   0.105667   -0.145342     0.1192       0.0140438    -0.0373469   -0.0140207    0.0783297  -0.0283162    0.0333782   -0.153107     0.00682848  -0.137747
  0.142778    -0.00948885   0.140875     -0.0614453     0.0724582   -0.0627578   -0.0363644   -0.0206474    0.21193      0.0319744    -0.0199777  -0.24221      0.0226095    0.0618748   -0.0247348   0.127566     0.0654031   -0.0331925    -0.0402719    0.0796514    0.0155955  -0.0634524   -0.0770297   -0.152388     0.0943029    0.12123
  0.155357    -0.0647949   -0.0941055    -0.0612846    -0.0646966    0.125702     0.0110415    0.119845    -0.0910427    0.0493967    -0.139164   -0.0283586    0.125579     0.116182     0.0382318   0.246495    -7.45027e-6  -0.0533087    -0.0713885    0.0593549    0.0199966  -0.0909403    0.137779    -0.0144611    0.0311014    0.132877
  0.0996642   -0.116323    -0.0150501     0.140403      0.0739056   -0.11826     -0.242515     0.0499585   -0.110166    -0.167495      0.175477    0.27647     -0.0904325   -0.0485624    0.140185   -0.0643935   -0.0215026    0.040722      0.0424343    0.0654146   -0.0429439  -0.0327851    0.214428    -0.235894     0.120121    -0.0236526
  0.153678    -0.0744931    0.0173635    -0.111368     -0.139046     0.0648076   -0.0887667    0.0915835    0.0484032    0.186238     -0.0399074  -0.0853642   -0.0408657   -0.0743743    0.0769302   0.0265181    0.119779     0.0989578    -0.0479213    0.0152537    0.0236867  -0.0532329   -0.103063    -0.160727     0.134827     0.0540592
  0.167275    -0.0271471   -0.108726      0.0025413    -0.0699884    0.0910608   -0.107642    -0.0380414    0.109801     0.101127     -0.168271    0.194894    -0.184335     0.00151574  -0.0569979  -0.138264    -0.00317102   0.0228203    -0.0462252   -0.122626     0.349502    0.0928914    0.12413     -0.0495156    0.052514     0.0213706
  0.0249224    0.00424125   0.0488428    -0.069438      0.213719    -0.154565     0.136633    -0.0642485    0.00894407  -0.00341136   -0.058638    0.116234     0.0501144    0.022671     0.0623566   0.0202191    0.0402375   -0.000463637   0.0631743   -0.034657     0.0612471   0.0489312    0.114712     0.186342     0.094117    -0.122521
  0.187563     0.111052     0.00976956    0.0612843    -0.13671      0.052253     0.0787181    0.129525    -5.92387e-5   0.0106069    -0.106617   -0.0457776    0.0940572   -0.00219929  -0.0367347  -0.00256597  -0.0253791   -0.0381447     0.0801666   -0.139887    -0.033411   -0.0696758   -0.0399043   -0.0279611    0.0252541   -0.0180317
 -0.117659     0.0248433    0.148248      0.0829301     0.0581959    0.108622     0.0642386   -0.00257171  -0.0514449   -0.215671      0.0426047   0.0942103    0.0863893   -0.0685633   -0.0661236   0.0785899   -0.0368429    0.137426      0.0240114    0.0372461   -0.0558234   0.0784234   -0.247194    -0.0750998   -0.0629283    0.086438
  0.043725     0.0220404   -0.022269      0.0255512    -0.209909    -0.0801738   -0.0508841   -0.115984    -0.141809    -0.131494      0.132537    0.00303211   0.00982851  -0.214286    -0.174027    0.0947582    0.0142362    0.0183811     0.00592916   0.0109627    0.113403   -0.0170606    0.0862238    0.171024     0.0375223   -0.0571017
  0.0681812    0.116702    -0.104875      0.247128     -0.0900249   -0.137287     0.154328    -0.0386871    0.176064     0.0193313    -0.0602299  -0.0449316    0.0998622    0.193945     0.0906802  -0.125159    -0.184283    -0.0390431    -0.0751887    0.0589544   -0.187506   -0.0756328    0.140365     0.148442     0.103457     0.0262819
 -0.165612     0.213946    -0.0804363     0.0197983    -0.0394217    0.0756836   -0.113967     0.0766944   -0.127713    -0.0986273     0.0259156   0.0500311   -0.0288814    0.0243404   -0.112447   -0.00676086  -0.0310073    0.159062     -0.150759    -0.0394567    0.180633    0.098881    -0.111334     0.133679    -0.0587453   -0.0398465
 -0.00355559  -0.0187243    0.133199      0.0544195     0.0932902   -0.129676    -0.0855415   -0.125451     0.00392065   0.0935439    -0.225782   -0.137976    -0.180926    -0.0272217    0.028614    0.0941005    0.0759911    0.0267813    -0.0101848   -0.0222065   -0.0969383  -0.0812706    0.104516     0.0882797   -0.0165589    0.156201kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4490610851516008
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.449162
[ Info: iteration 2, average log likelihood -1.449023
[ Info: iteration 3, average log likelihood -1.447299
[ Info: iteration 4, average log likelihood -1.430718
[ Info: iteration 5, average log likelihood -1.409888
[ Info: iteration 6, average log likelihood -1.406057
[ Info: iteration 7, average log likelihood -1.405180
[ Info: iteration 8, average log likelihood -1.404831
[ Info: iteration 9, average log likelihood -1.404684
[ Info: iteration 10, average log likelihood -1.404622
[ Info: iteration 11, average log likelihood -1.404596
[ Info: iteration 12, average log likelihood -1.404584
[ Info: iteration 13, average log likelihood -1.404579
[ Info: iteration 14, average log likelihood -1.404576
[ Info: iteration 15, average log likelihood -1.404574
[ Info: iteration 16, average log likelihood -1.404573
[ Info: iteration 17, average log likelihood -1.404573
[ Info: iteration 18, average log likelihood -1.404572
[ Info: iteration 19, average log likelihood -1.404572
[ Info: iteration 20, average log likelihood -1.404572
[ Info: iteration 21, average log likelihood -1.404572
[ Info: iteration 22, average log likelihood -1.404572
[ Info: iteration 23, average log likelihood -1.404572
[ Info: iteration 24, average log likelihood -1.404572
[ Info: iteration 25, average log likelihood -1.404572
[ Info: iteration 26, average log likelihood -1.404572
[ Info: iteration 27, average log likelihood -1.404572
[ Info: iteration 28, average log likelihood -1.404572
[ Info: iteration 29, average log likelihood -1.404572
[ Info: iteration 30, average log likelihood -1.404572
[ Info: iteration 31, average log likelihood -1.404572
[ Info: iteration 32, average log likelihood -1.404572
[ Info: iteration 33, average log likelihood -1.404572
[ Info: iteration 34, average log likelihood -1.404572
[ Info: iteration 35, average log likelihood -1.404572
[ Info: iteration 36, average log likelihood -1.404572
[ Info: iteration 37, average log likelihood -1.404572
[ Info: iteration 38, average log likelihood -1.404572
[ Info: iteration 39, average log likelihood -1.404572
[ Info: iteration 40, average log likelihood -1.404572
[ Info: iteration 41, average log likelihood -1.404572
[ Info: iteration 42, average log likelihood -1.404572
[ Info: iteration 43, average log likelihood -1.404572
[ Info: iteration 44, average log likelihood -1.404572
[ Info: iteration 45, average log likelihood -1.404572
[ Info: iteration 46, average log likelihood -1.404572
[ Info: iteration 47, average log likelihood -1.404572
[ Info: iteration 48, average log likelihood -1.404572
[ Info: iteration 49, average log likelihood -1.404572
[ Info: iteration 50, average log likelihood -1.404572
┌ Info: EM with 100000 data points 50 iterations avll -1.404572
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4491623025015277
│     -1.4490231440062433
│      ⋮
└     -1.4045715847684792
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.404752
[ Info: iteration 2, average log likelihood -1.404575
[ Info: iteration 3, average log likelihood -1.403443
[ Info: iteration 4, average log likelihood -1.392985
[ Info: iteration 5, average log likelihood -1.373670
[ Info: iteration 6, average log likelihood -1.367447
[ Info: iteration 7, average log likelihood -1.366176
[ Info: iteration 8, average log likelihood -1.365654
[ Info: iteration 9, average log likelihood -1.365328
[ Info: iteration 10, average log likelihood -1.365076
[ Info: iteration 11, average log likelihood -1.364862
[ Info: iteration 12, average log likelihood -1.364668
[ Info: iteration 13, average log likelihood -1.364499
[ Info: iteration 14, average log likelihood -1.364355
[ Info: iteration 15, average log likelihood -1.364233
[ Info: iteration 16, average log likelihood -1.364129
[ Info: iteration 17, average log likelihood -1.364036
[ Info: iteration 18, average log likelihood -1.363951
[ Info: iteration 19, average log likelihood -1.363869
[ Info: iteration 20, average log likelihood -1.363786
[ Info: iteration 21, average log likelihood -1.363698
[ Info: iteration 22, average log likelihood -1.363599
[ Info: iteration 23, average log likelihood -1.363483
[ Info: iteration 24, average log likelihood -1.363353
[ Info: iteration 25, average log likelihood -1.363207
[ Info: iteration 26, average log likelihood -1.363040
[ Info: iteration 27, average log likelihood -1.362864
[ Info: iteration 28, average log likelihood -1.362688
[ Info: iteration 29, average log likelihood -1.362517
[ Info: iteration 30, average log likelihood -1.362362
[ Info: iteration 31, average log likelihood -1.362237
[ Info: iteration 32, average log likelihood -1.362142
[ Info: iteration 33, average log likelihood -1.362070
[ Info: iteration 34, average log likelihood -1.362015
[ Info: iteration 35, average log likelihood -1.361971
[ Info: iteration 36, average log likelihood -1.361936
[ Info: iteration 37, average log likelihood -1.361907
[ Info: iteration 38, average log likelihood -1.361884
[ Info: iteration 39, average log likelihood -1.361865
[ Info: iteration 40, average log likelihood -1.361850
[ Info: iteration 41, average log likelihood -1.361838
[ Info: iteration 42, average log likelihood -1.361828
[ Info: iteration 43, average log likelihood -1.361819
[ Info: iteration 44, average log likelihood -1.361812
[ Info: iteration 45, average log likelihood -1.361805
[ Info: iteration 46, average log likelihood -1.361798
[ Info: iteration 47, average log likelihood -1.361791
[ Info: iteration 48, average log likelihood -1.361784
[ Info: iteration 49, average log likelihood -1.361776
[ Info: iteration 50, average log likelihood -1.361767
┌ Info: EM with 100000 data points 50 iterations avll -1.361767
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4047520374159523
│     -1.4045753163497425
│      ⋮
└     -1.361766627114392
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.361977
[ Info: iteration 2, average log likelihood -1.361753
[ Info: iteration 3, average log likelihood -1.361043
[ Info: iteration 4, average log likelihood -1.354776
[ Info: iteration 5, average log likelihood -1.336590
[ Info: iteration 6, average log likelihood -1.321838
[ Info: iteration 7, average log likelihood -1.314686
[ Info: iteration 8, average log likelihood -1.310929
[ Info: iteration 9, average log likelihood -1.308708
[ Info: iteration 10, average log likelihood -1.307157
[ Info: iteration 11, average log likelihood -1.305826
[ Info: iteration 12, average log likelihood -1.304524
[ Info: iteration 13, average log likelihood -1.303078
[ Info: iteration 14, average log likelihood -1.301426
[ Info: iteration 15, average log likelihood -1.299874
[ Info: iteration 16, average log likelihood -1.298834
[ Info: iteration 17, average log likelihood -1.298281
[ Info: iteration 18, average log likelihood -1.297942
[ Info: iteration 19, average log likelihood -1.297652
[ Info: iteration 20, average log likelihood -1.297305
[ Info: iteration 21, average log likelihood -1.296797
[ Info: iteration 22, average log likelihood -1.296022
[ Info: iteration 23, average log likelihood -1.295089
[ Info: iteration 24, average log likelihood -1.294281
[ Info: iteration 25, average log likelihood -1.293770
[ Info: iteration 26, average log likelihood -1.293418
[ Info: iteration 27, average log likelihood -1.293059
[ Info: iteration 28, average log likelihood -1.292630
[ Info: iteration 29, average log likelihood -1.292120
[ Info: iteration 30, average log likelihood -1.291580
[ Info: iteration 31, average log likelihood -1.291179
[ Info: iteration 32, average log likelihood -1.290980
[ Info: iteration 33, average log likelihood -1.290899
[ Info: iteration 34, average log likelihood -1.290864
[ Info: iteration 35, average log likelihood -1.290849
[ Info: iteration 36, average log likelihood -1.290842
[ Info: iteration 37, average log likelihood -1.290838
[ Info: iteration 38, average log likelihood -1.290835
[ Info: iteration 39, average log likelihood -1.290832
[ Info: iteration 40, average log likelihood -1.290829
[ Info: iteration 41, average log likelihood -1.290826
[ Info: iteration 42, average log likelihood -1.290823
[ Info: iteration 43, average log likelihood -1.290820
[ Info: iteration 44, average log likelihood -1.290816
[ Info: iteration 45, average log likelihood -1.290812
[ Info: iteration 46, average log likelihood -1.290808
[ Info: iteration 47, average log likelihood -1.290804
[ Info: iteration 48, average log likelihood -1.290799
[ Info: iteration 49, average log likelihood -1.290793
[ Info: iteration 50, average log likelihood -1.290786
┌ Info: EM with 100000 data points 50 iterations avll -1.290786
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3619772439239708
│     -1.3617528740804972
│      ⋮
└     -1.2907861340451772
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.291056
[ Info: iteration 2, average log likelihood -1.290769
[ Info: iteration 3, average log likelihood -1.289801
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.277697
[ Info: iteration 5, average log likelihood -1.255193
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.226935
[ Info: iteration 7, average log likelihood -1.226906
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.213979
[ Info: iteration 9, average log likelihood -1.219628
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.208268
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.213652
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.214298
[ Info: iteration 13, average log likelihood -1.228253
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.211486
[ Info: iteration 15, average log likelihood -1.217313
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.207444
[ Info: iteration 17, average log likelihood -1.214997
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.204827
[ Info: iteration 19, average log likelihood -1.210403
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      5
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.198095
[ Info: iteration 21, average log likelihood -1.229765
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.211723
[ Info: iteration 23, average log likelihood -1.213913
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.203399
[ Info: iteration 25, average log likelihood -1.210220
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.198166
[ Info: iteration 27, average log likelihood -1.216032
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.201053
[ Info: iteration 29, average log likelihood -1.205909
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.195075
[ Info: iteration 31, average log likelihood -1.200832
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.188253
[ Info: iteration 33, average log likelihood -1.207540
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.195004
[ Info: iteration 35, average log likelihood -1.202182
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.192041
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.197775
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.198778
[ Info: iteration 39, average log likelihood -1.203515
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.193071
[ Info: iteration 41, average log likelihood -1.199514
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.187495
[ Info: iteration 43, average log likelihood -1.207344
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.194537
[ Info: iteration 45, average log likelihood -1.200950
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.189242
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.195229
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.198573
[ Info: iteration 49, average log likelihood -1.202968
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.191403
┌ Info: EM with 100000 data points 50 iterations avll -1.191403
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.291055841559558
│     -1.2907691761574762
│      ⋮
└     -1.191403216524268
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.197123
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.186626
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.194000
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.164278
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.136753
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      8
│     10
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.110809
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.123627
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      9
│     10
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.114738
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      8
│      9
│     10
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.109792
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     15
│     18
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.109866
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      9
│     10
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.113373
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      8
│      9
│     10
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.112957
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     15
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.105649
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      9
│     10
│     18
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.099551
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      9
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.110700
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     10
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.111017
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│      9
│     10
│     15
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.096601
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.134146
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│      9
│     10
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.104781
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│      9
│     10
│     15
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.095612
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.118986
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     10
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.110471
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│      9
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.103185
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     15
│     18
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.109755
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.114543
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│      8
│      9
│     10
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.097565
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     15
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.115279
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     18
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.105964
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│      9
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.105721
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     10
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.116888
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     15
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.091892
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      4
│      9
│     10
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.094383
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│      9
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.109178
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     15
│     18
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.092899
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│      9
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.094055
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     10
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.109865
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     15
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.093441
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│      9
│     10
│     18
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.080621
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.116705
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     10
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.089647
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│      9
│     10
│     15
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.077281
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.120016
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.094983
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│      8
│      9
│     10
│     15
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.074273
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     18
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.111372
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.102570
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│      9
│     10
│     15
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.081114
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     10
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.105403
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.107387
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      4
│      9
│     10
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.082895
┌ Info: EM with 100000 data points 50 iterations avll -1.082895
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.197122848185547
│     -1.1866264408752638
│      ⋮
└     -1.082895416451852
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4490610851516008
│     -1.4491623025015277
│     -1.4490231440062433
│     -1.4472993818274216
│      ⋮
│     -1.1054028308070556
│     -1.107386916612179
└     -1.082895416451852
32×26 Array{Float64,2}:
 -0.124989   -0.229074     -0.045463    -0.0086174    0.0908616    0.0241224    0.0033216     0.0569227   -0.0687683   -0.170155    -0.0560561    0.0379149   -0.227648      0.0520247    -0.1512       0.0883       0.0762237    0.01958     -0.152943     0.0364107   -0.0560863    0.206915    -0.101449    -0.0912282   -0.143642   -0.0537291
  0.065445    0.0105156     0.00974702  -0.152887    -0.0180925    0.0349937    0.126442     -0.00229958  -0.141642    -0.0719281    0.0667352   -0.0823609    0.0676443    -0.237762      0.0397183   -0.0116524    0.153025    -0.0252251    0.0832984    0.159746     0.210325     0.0555057    0.108693    -0.0290282   -0.0838509  -0.0980997
  0.139463    0.0732184    -0.147823    -0.0420983    0.0509997    0.212415     0.0618626    -0.0463221   -0.0434122   -0.0611422    0.0204862    0.0835103    0.0943435     0.0047003    -0.00216054   0.085042    -0.0800399   -0.00906744   0.00266372   0.0625895   -0.0705979    0.0479145    0.0569332    0.025091     0.0645606   0.108343
 -0.107038   -0.0939863     0.0140025    0.0915911    0.00424391   0.0835057    0.0183016    -0.0778638   -0.108674     0.114437     0.0484528    0.126597     0.0600493     0.0635474     0.127417    -0.153611     0.0782544    0.0605021    0.055991     0.023238    -0.0712112    0.0286693    0.0207234    0.0189571    0.0895049   0.131585
  0.0479248   0.000940234   0.0166911   -0.0170735    0.0527036    0.0178188   -0.0364587     0.00756725   0.120401    -0.0282968   -0.0939606    0.0428828    0.0720379    -0.075433      0.0103378   -0.172223    -0.162263    -0.0941247   -0.0595037   -0.0757655   -0.00634548  -0.0505387   -0.00581159   0.0282452    0.0361027  -0.0238395
  0.0939737   0.0163447     0.00363421   0.131289     0.00817782   0.16838      0.0363371    -0.00944812   0.0499545    0.068854     0.19019     -0.0549419    0.005655     -0.154856      0.0118711    0.111021    -0.0537048    0.155384     0.109836    -0.0688042   -0.115601    -0.0156568    0.0787539    0.0804351    0.190177   -0.111157
  0.123852   -0.0325435    -0.0301688   -0.0832535   -0.0425816    0.0397782    0.00130833   -0.011959    -0.0478252   -0.123429     0.0362762   -0.00912986   0.0202833     0.0856754     0.00802041   0.0887699   -0.013639     0.0430508    0.0883761    0.0740172   -0.0744646    0.0682277    0.109992     0.13129      0.0149091  -0.0128793
 -0.128679    0.218695     -0.00769866   0.0701819   -0.00420996  -0.0821879   -0.0126517    -0.11344     -0.0998579   -0.023579    -0.00358868  -0.0615536    0.0325545    -0.191904     -0.151782     0.0403936    0.0137756    0.0449262    0.00221544  -0.00846979   0.13412      0.0214108   -0.0737194   -0.241516    -0.0383132  -0.0817144
  0.135595   -0.731566     -0.0127282   -0.144339     0.0713218   -0.174783    -0.235625      0.0346489   -0.114492    -0.167218     0.366669     0.20304     -0.110401     -0.325489      0.140517    -0.0819326   -0.0202307    0.033195    -0.0158607   -0.134229    -0.042512     0.0279618    0.338776    -0.35173      0.125005   -0.0237234
  0.116441    0.416422     -0.0220906    0.347063     0.0743315   -0.0477582   -0.237394      0.082034    -0.110486    -0.162586     0.0466705    0.355027    -0.0695271     0.235812      0.139923    -0.0579045   -0.0196574    0.0344932    0.118092     0.239001    -0.0421904   -0.0734917    0.0930239   -0.210749     0.1232     -0.0246856
  0.260728   -0.0182175    -0.159192    -0.105107    -0.0265739    0.0471839   -0.0316042    -0.0490929    0.142481     0.0620212   -0.179051     0.239269    -0.185511     -0.361455     -0.0601044   -0.126008     0.00960272   0.0125861   -0.092635    -0.16282      0.337745     0.100093     0.147019    -0.0569952    0.0212266  -0.0339271
  0.0957476  -0.0448173    -0.0524719    0.0440602   -0.109918     0.137119    -0.152602     -0.0377894    0.0646608    0.115385    -0.132877     0.109443    -0.184402      0.523991     -0.0347181   -0.130029    -0.0179793    0.03261      0.013576    -0.0780636    0.36184      0.0667024    0.104711    -0.0347083    0.059477    0.0127006
 -0.0715004   0.00565953   -0.0297727    0.00109456  -0.941165     0.0268624    0.183761     -0.139278    -0.19124      0.227534    -0.0281202   -0.151989    -0.106832      0.107422      0.0860548   -0.143281    -0.0949099   -0.0422978   -0.175093    -0.246076    -0.196876    -0.225147    -0.112942     0.339045    -0.0238793   0.329197
 -0.279577   -0.135049     -0.024951    -0.0397253    0.895008     0.0461918    0.144445     -0.215188     0.0270173    0.236428     0.088803    -0.10028     -0.106811      0.0983046     0.071436    -0.0344684   -0.135047    -0.0305046   -0.151501    -0.338082    -0.195417    -0.00906869  -0.205672     0.0462372    0.0871687   0.258611
 -0.0133052   0.0130531    -0.0152539    0.0362652   -0.0685097    0.113531    -0.00569074    0.00428941  -0.0219792   -0.00501943   0.0344421    0.0323522   -0.121863      0.0164874     0.0658076    0.0498928   -0.143125     0.024989    -0.0699417   -0.118713    -0.100972    -0.165741    -0.0845853    0.00363883  -0.0726464   0.0596831
 -0.0464326  -0.0283386     0.204331    -0.00169935   0.195224     0.0398034    0.00547871    0.0339473   -0.256755    -0.0481895   -0.131132     0.216089     0.00277091    0.110564     -0.0366813   -0.00429328   0.107304     0.125488    -0.0157264    0.00226557   0.107762    -0.14364     -0.0287552   -0.00628556   0.231207   -0.0144306
  0.060587    0.0178461     0.156452     0.0644666   -0.0715442   -0.00637815  -0.142852      0.106727    -0.0927321   -0.0110054   -0.0308386   -0.00934498  -0.0349641     0.119007     -0.0730367   -0.0639127   -0.109209    -0.0312824    0.0109902    0.0978124    0.0342703   -0.0492203   -0.0305805    0.0402283   -0.0587229   0.161085
 -0.0415933  -0.0436149     0.115908     0.106345    -0.107133    -0.0224361   -0.0940854     0.157555     0.0992612    0.0130796    0.0538706    0.117502    -0.000513012  -0.225225     -0.0313402    0.0517693   -0.100391    -0.0039763    0.0135093   -0.0957597    0.0610726    0.0722684   -0.198177     0.117827    -0.0609558   0.132384
 -0.024802    0.0788497    -0.0762762   -0.0310235   -0.11131      0.0735039   -0.0970939     0.111711    -0.0459516    0.0291842    0.0163553   -0.0159969   -0.0274181    -0.0167758    -0.00543425   0.0140624    0.0334085    0.126917    -0.0952132   -0.00572716   0.114294     0.0285431   -0.104405     0.00453051   0.0329439  -0.00142686
  0.0745027   0.0358923    -0.0295951    0.124633    -0.0795283   -0.110581     0.0859745     0.0560314    0.0745116   -0.0252243   -0.119781    -0.00820025  -0.0258296     0.0199878    -0.00607618   0.0224889   -0.0313894   -0.039164    -0.123714     0.158147    -0.00917392  -0.0173479    0.0594008   -0.0280968    0.0664051  -0.00665511
  0.0386526   0.00704933    0.104014    -0.0676036    0.173351    -0.106997     0.102654     -0.0259623    0.0366162    0.0231438   -0.0705043    0.105193    -0.768971      0.0191195     0.0693862   -0.0349962    0.0363178    0.0177993    0.0203907   -0.13095     -0.00834378   0.013415     0.110705     0.168726     0.0625322  -0.107246
 -0.0211879  -0.00271263   -0.0199525   -0.0884354    0.19283     -0.206392     0.178461     -0.155748    -0.00471132  -0.0342539   -0.0175718    0.127406     0.947207      0.0237065     0.0625816    0.127213     0.044649    -0.0164213    0.0526433   -0.0239909    0.265168     0.077835     0.118526     0.178598     0.1333     -0.159301
 -0.323032   -0.0972965    -0.0871902    0.0858292   -0.0905582    0.0223404    0.0430251    -0.0466853   -0.212302    -0.0342543    0.0132939    0.0770247    0.0762814     0.0809194    -0.0870876   -0.00437637   0.0395983    0.17609     -0.0657382   -0.0203151   -0.0253224    0.310654    -0.0402112   -0.206247     0.0524143   0.160585
  0.624495   -0.0971242    -0.0391504    0.0167765    0.181762     0.0611452   -0.0188284     0.0195777    0.0553438   -0.0210551    0.0291766    0.0741284    0.119975      0.0389536    -0.1629       0.131066     0.0507709    0.196496     0.116533    -0.0162987   -0.0485353    0.334495    -0.0357391   -0.0476615    0.0594995   0.11975
 -0.112321    0.0534236    -0.0299475   -0.0165433    0.0410912    0.00703075  -0.0345884    -0.00519577   0.0572835   -0.0846181   -0.0256118   -0.0257541   -0.0197631    -0.137602     -0.073373     0.133684    -0.0270795    0.0338321    0.0687399    0.0645044    0.136804     0.0690794    0.0371263    0.10527      0.022539    0.0108681
  0.0326718   0.069615      0.071933     0.0706134   -0.0336439    0.081865     0.0292915     0.0739661    0.00635262  -0.103357    -0.0406657    0.015504     0.0864429    -0.0216192    -0.0547495    0.0373661   -0.0306919    0.0507252    0.0322912   -0.0532069   -0.0502114   -0.0003888   -0.135211    -0.0368723   -0.0274315   0.0215174
  0.137662   -0.015239      0.0041144   -0.00966666  -0.00115351  -0.110182    -0.0398676    -0.0983913    0.147293     0.0648222   -0.0689146   -0.184076    -0.168173      0.0235333    -0.0752881   -0.62567      0.0632229   -0.0526257   -0.0484679    0.0899439   -0.00477614  -0.105945    -0.0675981   -0.150652     0.130338    0.135895
  0.136599   -0.0261643     0.179559    -0.0670058    0.161726    -0.00567689  -0.0489211    -0.0469532    0.258403     0.0223053   -0.0807173   -0.288414     0.191383      0.0717016     0.0119258    0.817378     0.0688078   -0.0119145   -0.0357874    0.0942859    0.0544702   -0.0348129    0.00497763  -0.145443     0.0598897   0.120288
 -0.376212    0.0156467     0.139173     0.135307     0.0833738   -0.111937    -0.0847076    -0.0681233   -0.048622     0.0814143   -0.214335    -0.145856    -0.0646625    -0.0735964     0.0145902    0.0459327    0.0366805    0.0423685   -0.0780949    0.0218925   -0.0863132   -0.113662     0.0651626    0.0889771   -0.0130684   0.190497
  0.519396   -0.0513738     0.11033     -0.0601635    0.102352    -0.154617    -0.0958648    -0.147435     0.0880533    0.100996    -0.236909    -0.179919    -0.31557      -0.000171036   0.0139885    0.180854     0.186655     0.00833542   0.0828925   -0.0470311   -0.115927     0.00986542   0.129091     0.0870365    0.0206746   0.113222
  0.136236   -0.0682197    -0.106498    -0.0625327   -0.0681586    0.118456    -0.000455612   0.1181      -0.0885936    0.0776194   -0.138814    -0.0231848    0.126451      0.0903902     0.0871502    0.28827      0.0219201   -0.0525691   -0.0727353    0.0460647    0.0200576   -0.0958656    0.157588    -0.00727874   0.039542    0.027041
 -0.0784513   0.12045       0.00164035   0.0119505   -0.118615     0.166246    -0.103351     -0.0592145    0.0367189   -0.0372089    0.0983639   -0.0616988   -0.148102      0.00364478    0.107242    -0.141804     0.12089      0.0145257   -0.0577321   -0.00384083   0.0953349   -0.0253071    0.0249496   -0.153129     0.0230886  -0.113175[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│      9
│     10
│     15
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.095835
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     10
│     15
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.076447
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      4
│      8
│      9
│      ⋮
│     18
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.069712
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     10
│     15
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.095433
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      8
│      9
│     10
│     15
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.079719
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      8
│      9
│     10
│     15
│     18
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.081313
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      8
│      9
│     10
│     15
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.087470
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     10
│     15
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.087150
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      4
│      8
│      9
│      ⋮
│     18
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.073274
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     10
│     15
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.095413
┌ Info: EM with 100000 data points 10 iterations avll -1.095413
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.682374e+05
      1       7.343249e+05      -2.339124e+05 |       32
      2       7.094665e+05      -2.485845e+04 |       32
      3       6.927226e+05      -1.674391e+04 |       32
      4       6.785381e+05      -1.418450e+04 |       32
      5       6.668031e+05      -1.173494e+04 |       32
      6       6.601935e+05      -6.609628e+03 |       32
      7       6.560391e+05      -4.154448e+03 |       32
      8       6.534816e+05      -2.557444e+03 |       32
      9       6.523211e+05      -1.160485e+03 |       32
     10       6.518146e+05      -5.064976e+02 |       32
     11       6.515849e+05      -2.296979e+02 |       32
     12       6.514823e+05      -1.026132e+02 |       32
     13       6.514337e+05      -4.858488e+01 |       32
     14       6.514064e+05      -2.733620e+01 |       32
     15       6.513856e+05      -2.078807e+01 |       31
     16       6.513665e+05      -1.911867e+01 |       30
     17       6.513520e+05      -1.449787e+01 |       28
     18       6.513445e+05      -7.485130e+00 |       26
     19       6.513394e+05      -5.162589e+00 |       24
     20       6.513362e+05      -3.132822e+00 |       21
     21       6.513344e+05      -1.799238e+00 |       19
     22       6.513324e+05      -2.000262e+00 |       19
     23       6.513311e+05      -1.342694e+00 |       20
     24       6.513302e+05      -8.399326e-01 |       16
     25       6.513298e+05      -4.905085e-01 |       10
     26       6.513295e+05      -2.660184e-01 |       10
     27       6.513292e+05      -2.713356e-01 |       13
     28       6.513288e+05      -4.023057e-01 |        9
     29       6.513287e+05      -1.418124e-01 |        2
     30       6.513287e+05      -1.886489e-02 |        0
     31       6.513287e+05       0.000000e+00 |        0
K-means converged with 31 iterations (objv = 651328.6537753632)
┌ Info: K-means with 32000 data points using 31 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.352557
[ Info: iteration 2, average log likelihood -1.316103
[ Info: iteration 3, average log likelihood -1.281342
[ Info: iteration 4, average log likelihood -1.236806
[ Info: iteration 5, average log likelihood -1.190646
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.144657
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.124801
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      7
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.081909
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     21
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.094872
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.090743
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     10
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.074154
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     11
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.053560
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     21
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.077698
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     10
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.082619
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.074264
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     15
│     21
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.046676
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     10
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.082402
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.078340
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     15
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.067096
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.057167
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     11
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.058319
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│     15
│     21
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.080180
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.099499
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.069474
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     11
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.051991
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     10
│     15
│     21
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.046449
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.082869
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.083159
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      7
│     10
│     15
│     21
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.052456
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.090628
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.086752
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     10
│     11
│     13
│     15
│     21
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.034035
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      7
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.093260
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.078209
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     10
│     15
│     21
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.053634
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.088889
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      7
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.072758
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     10
│     15
│     21
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.025750
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.099972
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.091838
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     10
│     15
│     21
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.040660
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     11
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.081313
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.076005
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     13
│     15
│     21
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.029681
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     11
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.084547
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.089529
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     21
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.053763
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     11
│     13
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.052890
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.094881
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     15
│     21
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.050287
┌ Info: EM with 100000 data points 50 iterations avll -1.050287
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0490734   -0.0169822    0.125512     0.0407686     0.0917452   -0.131124    -0.0901842   -0.104553     0.0168602    0.0905912   -0.225022   -0.16073    -0.180897    -0.0396248    0.0146403    0.112692     0.108824    0.0251581   -0.0020883  -0.0110772    -0.0993638   -0.0540028   0.0967001   0.0880046    0.00480124   0.153252
  0.187741    -0.0798944    0.00470945  -0.103391     -0.136006     0.0602702   -0.112684     0.100437     0.0644703    0.184875    -0.0205176  -0.0767755  -0.0149416   -0.0762032    0.109999     0.0271002    0.114547    0.0993026   -0.036215    0.0376536     0.0393732   -0.0505952  -0.0834508  -0.158882     0.134569     0.0492579
  0.122355    -0.018218    -0.0349431   -0.146704      0.0608347    0.109316     0.0348926    0.0404435    0.0164889   -0.111404    -0.0815524  -0.0238724   0.0247498    0.282901     0.125578     0.0873965   -0.0453378   0.0521776    0.132394    0.115284     -0.18657      0.151915    0.116524    0.0762479    0.0212665    0.0194188
 -0.0543726   -0.0224263   -0.0320293    0.0936273    -0.121607     0.0586884   -0.0397692   -0.0752528   -0.0981194    0.0450211    0.0355894   0.099774    0.0248316   -0.0903631   -0.0490174   -0.0118971    0.0465577   0.0151865    0.0391143  -0.0111847     0.0346995    0.0247507   0.0584995   0.0857716    0.0457617    0.111769
  0.137667    -0.0204482    0.0900686   -0.0370957     0.0798462   -0.0576732   -0.0449707   -0.0757532    0.205082     0.0421092   -0.0725028  -0.237175    0.00937068   0.0484979   -0.0349699    0.0818702    0.0659229  -0.0321936   -0.041388    0.0917736     0.0240536   -0.0742225  -0.0332129  -0.14894      0.0960714    0.127732
  0.149371     0.0726974    0.28176     -0.000815959  -0.123897    -0.0935064   -0.153316     0.144637    -0.103611    -0.0112704    0.0496422  -0.1245     -0.0509498    0.135204    -0.0569542   -0.0278972   -0.26624    -0.0995325    0.0526621   0.0864777     0.0481497   -0.0167444   0.046       0.129192    -0.114117     0.113389
  0.132539     0.0310803   -0.0441785    0.00676668   -0.215926    -0.116965    -0.0536818   -0.196767    -0.138914    -0.15395      0.261821   -0.0124658   0.00767922  -0.209       -0.197523     0.0791024    0.0211274   0.044108    -0.0963829  -0.000499557   0.118372    -0.0786376   0.090362    0.169919    -0.0150454   -0.119907
 -0.0780048    0.15507      0.00974596   0.0579226     0.065934     0.0109876    0.0374685    0.0457297    0.0883738   -0.167089     0.0172981  -0.122585    0.0172596   -0.0703698   -0.035131     0.123697     0.0287276  -0.109855     0.185323   -0.0164985     0.0213849    0.0792361  -0.0055266   0.0721759   -0.0055956    0.0372144
  0.153498    -0.0973965   -0.0629092    0.0512053     0.0472122    0.0416431    0.0133173   -0.0144946   -0.0783233   -0.0280699    0.0213606   0.0755869   0.0989354    0.0603932   -0.126245     0.0628387    0.0455809   0.186444     0.0254249  -0.0179747    -0.0369087    0.322625   -0.0378432  -0.127133     0.0561313    0.140057
 -0.0426425   -0.0413587    0.130308     0.106966     -0.108303    -0.0267129   -0.0934873    0.160646     0.107784     0.0184043    0.0535381   0.117091   -0.00197071  -0.230711    -0.0279018    0.053255    -0.10725    -0.0098118    0.0174113  -0.107241      0.0638784    0.0758246  -0.195174    0.122885    -0.0628001    0.130203
  0.118242    -0.0845902   -0.0159365    0.0930565     0.036257    -0.0950705   -0.205811     0.0567603   -0.117311    -0.153535     0.168168    0.26669    -0.0571433   -0.0579647    0.0838258   -0.0430945   -0.015435    0.0426593    0.0649032   0.0876661     0.00895355  -0.0224792   0.183506   -0.205787     0.0987787   -0.0363463
 -0.0266591   -0.00583522   0.0909363    0.0197079     0.0608292    0.0823568   -0.00249022   0.0181788   -0.129158    -0.0250747   -0.0472031   0.118794   -0.0581984    0.0592672    0.0178139    0.0172955   -0.0225784   0.0644465   -0.0431331  -0.0618497     0.00262694  -0.153689   -0.0596678  -0.00282817   0.0798935    0.0245129
 -0.0635007   -0.157985     0.0648966   -0.0164472     0.252116     0.0272196   -0.178086     0.0248626    0.126014     0.0256957   -0.160837   -0.0824569  -0.0348081   -0.148818     0.007033    -0.212924    -0.232436   -0.0365967   -0.0715393  -0.0989471     0.0821455   -0.0102415   0.0385022   0.0942996   -0.00153216  -0.12478
  0.00917857   0.00257735   0.0488499   -0.07713       0.18336     -0.154123     0.139042    -0.0860504    0.0177118   -0.00525923  -0.0492379   0.11559     0.00052858   0.0209687    0.0655021    0.0381395    0.0404463   0.00196682   0.0368061  -0.0817852     0.114044     0.0428478   0.114978    0.175533     0.0924293   -0.132747
  0.177197     0.11025      0.00636514   0.0588031    -0.128278     0.0502259    0.0574451    0.120816     0.0599704    0.0113531   -0.118774   -0.0402782   0.0914629    0.0240825   -0.0396823   -0.00217676  -0.0257348  -0.034948     0.0320383  -0.137028     -0.0364921   -0.0623406  -0.0404906  -0.0357167    0.0162975   -0.0202152
  0.0613721   -0.0354818    0.025204     0.0196095    -0.0533885   -0.0873725    0.00833941   0.13215     -0.00560302  -0.0750963   -0.174849    0.0302234  -0.140614    -0.130516    -0.116037     0.163647     0.0876859  -0.0605332   -0.175752    0.242773      0.155383     0.0991129  -0.014188   -0.156901     0.034539    -0.0500239
 -0.124251    -0.22977     -0.0461545   -0.00839987    0.0903703    0.0237328    0.0029509    0.0546743   -0.069       -0.170692    -0.0566857   0.0395415  -0.227571     0.0530524   -0.150317     0.0880962    0.0755156   0.0210073   -0.152443    0.0371558    -0.055415     0.207706   -0.100505   -0.0903276   -0.143446    -0.0537384
  0.127414    -0.0661853   -0.111685    -0.0621532    -0.0735824    0.115708    -0.00765586   0.116052    -0.0855715    0.0822546   -0.140534   -0.0266362   0.121892     0.0827865    0.0868215    0.256549     0.0140812  -0.0532716   -0.0708306   0.0369091     0.0229273   -0.0978304   0.157038   -0.00892623   0.0331787    0.041566
  0.0956786    0.114596    -0.101468     0.257373     -0.11762     -0.141478     0.175641    -0.034828     0.167533     0.0247988   -0.0612824  -0.0721099   0.088935     0.180863     0.0980288   -0.123843    -0.177804   -0.0326142   -0.0867903   0.0709132    -0.179145    -0.126538    0.137735    0.123191     0.0947254    0.0245193
 -0.0476865   -0.038978     0.0180401    0.137109     -0.0355225    0.076704    -0.109296     0.0613837   -0.0790393   -0.0305755   -0.117641    0.133208   -0.00411178   0.102528    -0.0905435   -0.101296     0.0768082   0.0493844   -0.0238391   0.119531      0.0178059   -0.0811104  -0.122306   -0.0598583    0.0155641    0.222263
 -0.127801     0.0199988    0.138307     0.0807687     0.0437989    0.10924     -0.00915168   0.00311583  -0.056739    -0.229865     0.0541462   0.0732982   0.0749328   -0.0988576   -0.0705349    0.0797227   -0.0407672   0.143236     0.0282946   0.0255207    -0.0449874    0.0450393  -0.212719   -0.0242083   -0.061822     0.0604148
  0.162582     0.118256    -0.0265937   -0.0306924    -0.0711726   -0.00127922   0.053753    -0.0107829    0.126557    -0.0773491   -0.044128    0.140194    0.161589    -0.0379674    0.00709352  -0.135803    -0.110312   -0.159797    -0.0483171  -0.0549935    -0.0740617   -0.0824641  -0.0159494  -0.0126214    0.0687282    0.0148351
  0.183571    -0.0293915   -0.112937    -0.0224085    -0.0685667    0.0922271   -0.0870857   -0.0447342    0.105723     0.085639    -0.161075    0.184608   -0.185888     0.087657    -0.036667    -0.134044    -0.0024621   0.0197504   -0.0441381  -0.135228      0.346523     0.0870061   0.13281    -0.0449395    0.0404669   -0.00936512
  0.140542     0.0712573   -0.143733    -0.0445261     0.052278     0.21078      0.058454    -0.046716    -0.0470842   -0.0614355    0.022632    0.0830078   0.093672     0.00787823   0.00273515   0.0844567   -0.0807228  -0.0074875    0.0025621   0.0607059    -0.0692637    0.0462      0.0608211   0.0254179    0.0641511    0.107842
 -0.194676     0.212548    -0.144878     0.0184284    -0.0908089    0.0821582   -0.0888849    0.13263     -0.131631    -0.108023     0.0428201   0.0350344  -0.0382672    0.0311474   -0.105883     0.00564922  -0.0323089   0.159281    -0.144252   -0.0410703     0.176883     0.0992529  -0.111146    0.134943    -0.0555969   -0.0403072
 -0.15161      0.241715    -0.00443664   0.0722798     0.042726    -0.0654308   -0.00548339  -0.0928814   -0.0934545   -0.00208034  -0.0332189  -0.0698849   0.0372583   -0.184759    -0.142601     0.0285951    0.0118529   0.0355146    0.0196093  -0.0134405     0.130158     0.0369081  -0.095882   -0.282935    -0.0348036   -0.0802678
 -0.0784903    0.120406     0.00180408   0.0120288    -0.118731     0.166246    -0.103069    -0.0590538    0.0366236   -0.0371263    0.0988607  -0.0617191  -0.148168     0.00364801   0.107439    -0.141782     0.120858    0.0144883   -0.0580285  -0.00404841    0.0953525   -0.0255586   0.0248324  -0.153285     0.0234169   -0.113481
 -0.162433    -0.0454607   -0.0709889   -0.0980547     0.043542    -0.00181386  -0.0869497   -0.0638444    0.0136034    0.00509591  -0.0575602   0.0680644  -0.0672641   -0.208553    -0.133958     0.16277     -0.0781901   0.165032    -0.0289324   0.165966      0.284016     0.0742525   0.102526    0.164073     0.0329338   -0.042555
 -0.109499    -0.0944138    0.0136639    0.0826848     0.00545786   0.0830553    0.0161251   -0.0760103   -0.108404     0.114221     0.0452206   0.125265    0.0580717    0.0637894    0.131548    -0.154256     0.0865333   0.0646005    0.0551211   0.0233205    -0.0737207    0.0274641   0.0194175   0.0216236    0.0934781    0.135879
 -0.180984    -0.0686883   -0.0269658   -0.0214068     0.0446632    0.0371803    0.161806    -0.179264    -0.0748861    0.232461     0.0378836  -0.123706   -0.107977     0.101225     0.0784944   -0.0873755   -0.116319   -0.0364044   -0.159618   -0.297632     -0.195269    -0.109002   -0.164841    0.183587     0.0358366    0.292165
  0.0602271    0.0348243    0.0109084   -0.149929     -0.0306207    0.0312126    0.171264    -0.00443188  -0.139516    -0.068226     0.0520325  -0.160856    0.0667499   -0.240327     0.0272442   -0.0100101    0.170337   -0.0295285    0.0860858   0.14895       0.204988     0.0599097   0.0930686   0.00293915  -0.101171    -0.100809
  0.0930933    0.0141986    0.00289201   0.129839      0.00801803   0.163793     0.0356933   -0.00817562   0.0453144    0.0713583    0.194501   -0.0564496   0.00322809  -0.154222     0.0115628    0.112891    -0.0543855   0.161384     0.116198   -0.0679076    -0.113555    -0.0163673   0.0783478   0.0846004    0.191091    -0.114018[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     13
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.066728
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     10
│     11
│     13
│     18
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.028452
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│     10
│     13
│     15
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.028330
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│     10
│     11
│     13
│      ⋮
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.023053
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     13
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.049902
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      4
│      7
│     10
│      ⋮
│     18
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.009818
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     13
│     18
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.052278
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     10
│     11
│     13
│     18
│     21
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.023107
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     10
│     13
│     15
│     18
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.013042
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      7
│     10
│     11
│     13
│     18
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.028606
┌ Info: EM with 100000 data points 10 iterations avll -1.028606
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.188727     0.197979    -0.0610451   -0.203907    -0.0483132    0.117467      0.0423132  -0.0176545    0.0213992    0.0747119   -0.103373     0.101395     0.00476746  -0.0277956    0.0663672    0.13701     -0.103387      0.0445249    0.0364398   -0.202846     0.174178    0.0788262    0.159383     0.0777637   0.049296    -0.110854
  0.0334312   -0.0833361   -0.0261781    0.111447     0.0283926   -0.0886056     0.14204    -0.114113     0.0310183   -0.143642     0.0706206    0.166597    -0.102891     0.139976     0.143625    -0.0846453   -0.0365313     0.016922    -0.0147859    0.0152059   -0.168977    0.257119     0.119268    -0.0222681  -0.0954679   -0.170199
 -0.070453    -0.213551     0.0314779    0.00207502   0.0846554   -0.0537917    -0.101607    0.109587    -0.0647202   -0.0833864    0.0424123   -0.0382182   -0.0329935   -0.0167918   -0.162773    -0.129602    -0.0375854    -0.0314806    0.0528702   -0.202395    -0.216422    0.179124     0.0537531   -0.0883191  -0.0330887   -0.144096
 -0.175237    -0.0958155    0.08784     -0.0203431    0.0324537    0.159935     -0.140208   -0.125661    -0.135972     0.146929    -0.161345    -0.146024     0.0284022   -0.0344006    0.137065    -0.0961369    0.0473427    -0.0712463    0.0327254   -0.266896     0.12051    -0.00815875  -0.052072     0.0824238   0.149759    -0.0350865
 -0.0315158   -0.0315356    0.220351     0.126641     0.0682372    0.0668913    -0.0167811  -0.102504     0.0182289   -0.0415541   -0.22805      0.050306    -0.174353     0.0324806   -0.109796     0.00967955  -0.0666982     0.0648803   -0.21785      0.111179     0.0482369   0.110703    -0.106526    -0.132331    0.0583069    0.0537105
 -0.0348755   -0.0860216   -0.0602685    0.00918182   0.0229972    0.181483     -0.225157    0.147681     0.171128     0.065549     0.170151    -0.0865722    0.0996556   -0.075825     0.0868702    0.00429147  -0.119282     -0.0285503    0.043382     0.0906447   -0.0215996   0.0255601   -0.0125734    0.0190902  -0.0209485    0.0435575
 -0.133548     0.00108401   0.0427542   -0.0317812   -0.029565    -0.0424955     0.0484649   0.105784     0.0765657   -0.108716    -0.0439134   -0.0692831    0.109967     0.0945581    0.139364     0.00722165   0.159319     -0.0940134    0.112322    -0.0406715   -0.0195023  -0.126266    -0.0162541    0.0169644  -0.0910246    0.0924272
 -0.0311761    0.0342583    0.136157     0.0801899    0.0966261    0.0601611     0.179761    0.0421429    0.0184492   -0.104314     0.0159493   -0.0747395   -0.0692172   -0.0129316    0.0287007   -0.00887142   0.0894561     0.00588606  -0.157459     0.238764     0.093549    0.0459883   -0.0882344   -0.119646   -0.175037     0.114374
 -0.106686    -0.0743808   -0.0231924    0.0562557   -0.175047     0.0640248     0.087868   -0.157544    -0.043325     0.120295    -0.0719967   -0.0675845   -0.100744    -0.00397027  -0.194129     0.0164983    0.00390251   -0.0444034   -0.0877749   -0.0796801    0.0997191   0.137686    -0.0759126    0.0117493  -0.109105     0.147309
 -0.10839      0.0814384    8.55047e-5   0.00958375  -0.0832221   -0.0948687    -0.120349    0.0520941   -0.0998717   -0.174791    -0.331274    -0.07442     -0.0301672    0.198957    -0.0814472    0.0459386    0.0793177    -0.0709527   -0.0740109   -0.0258672    0.10289    -0.129721     0.165311    -0.0561592  -0.116594     0.0845358
 -0.0170882    0.00422401  -0.195258     0.0921688   -0.107467    -0.0133747    -0.168193   -0.00329968   0.0555589    0.0973798   -0.175241     0.112269     0.0673937    0.154688    -0.0964254    0.0740533   -0.0433638     0.00730825   0.224664     0.0093006   -0.0166003   0.178817    -0.0353045    0.0850338  -0.0499042    0.0298417
  0.173347     0.0907267    0.0225908    0.0333338   -0.0194469    0.16571      -0.0557595  -0.0866792    0.0492493    0.0350337   -0.088291     0.069722     0.00837334   0.0858366   -0.140952     0.0380642    0.0587173     0.0360356   -0.0539647   -0.0966917    0.0472536   0.0935146    0.251256     0.0106632  -0.131947    -0.266497
  0.020421     0.00337884  -0.0365265    0.0243406   -0.0945186    0.000692318  -0.13152     0.158685    -0.0502067    0.0169618   -0.126999     0.081094     0.199712    -0.147519     0.107855    -0.143999    -0.073654      0.193471     0.0467997    0.112019    -0.030474   -0.0143974    0.0113014    0.140227    0.191617     0.113661
  0.0352731   -0.0702235    0.00299778  -0.056174    -0.0215989    0.130158     -0.055198    0.0623048    0.0491      -0.0387318    0.0411915   -0.162198     0.0133319    0.146623     0.00211257   0.0228038    0.000241766  -0.0691475    0.0168722   -0.109251    -0.148709   -0.0495377    0.00127257  -0.0796952   0.0883404   -0.0294415
 -0.151538     0.154576     0.00180991   0.0144065   -0.00392918  -0.0758055     0.0193643   0.0533636   -0.00110293  -0.249138    -0.138628    -0.193151     0.114852     0.0986811    0.0275763   -0.00242073  -0.0222314    -0.0624928    0.0513333   -0.0976711    0.0916377   0.17683      0.0694266    0.0737453   0.0736382   -0.150022
  0.0981164    0.0329902   -0.197055    -0.189464    -0.00491136  -0.124788     -0.0581349   0.169235     0.113614    -0.0767401   -0.131663    -0.115692    -0.0416883   -0.183851     0.0215382   -0.103165    -0.0750231    -0.141474    -0.160872     0.0133681    0.0728996   0.120615    -0.166625     0.10129     0.138527    -0.0102431
  0.043543     0.0443949   -0.101061     0.0336425    0.00967223  -0.155251     -0.0620679   0.0870331    0.19197      0.0277789   -0.0297402    0.122018     0.103009     0.0356375   -0.0476937   -0.0561445   -0.011796     -0.133815    -0.0138986    0.0341779    0.042801    0.0809298    0.0190823    0.0890954   0.0361147   -0.136689
 -0.0135635   -0.0676451   -0.173166     0.116505     0.0308121   -0.00275444    0.0631744  -0.157657     0.0733418   -0.0958556    0.101942     0.115133    -0.0500996    0.062148     0.0940643   -0.0567353   -0.160409      0.103166     0.0662027    0.0211155   -0.101536   -0.0305943    0.0125948    0.101532   -0.0569621    0.043108
 -0.0374494   -0.190653    -0.131349     0.114003    -0.151436     0.0456721     0.0264759  -0.013199    -0.05461      0.0449293    0.0922882    0.105069     0.0842415    0.178046    -0.0868898   -0.076291     0.159702      0.0402366   -0.0943236    0.0996336    0.116299   -0.103674     0.0647718   -0.0860918  -0.0407994   -0.0448225
  0.0896237   -0.00921304  -0.073365    -0.167078    -0.123121    -0.0499427     0.103004   -0.0181095    0.0604733   -0.147723    -0.0469801   -0.172626     0.0158263   -0.0267498   -0.19681     -0.0546437   -0.124299      0.00601851  -0.013321    -0.166111    -0.0802717   0.205965     0.164835     0.130803   -0.0545125    0.0401852
  0.0349376    0.0154707    0.0481429    0.21117      0.0397569   -0.0951816     0.150482   -0.0800867   -0.0398776   -0.141316    -0.00300755  -0.0950822    0.125515     0.168151    -0.156808     0.03829      0.108188     -0.0386657   -0.0583238   -0.0484396    0.105417   -0.0929249   -0.054891    -0.0585461  -0.0725093    0.0938678
 -0.0856164   -0.151428    -0.0745687   -0.0384451   -0.00967506  -0.0198501     0.128028   -0.0758414   -0.0183367    0.044285    -0.0397945   -0.0490116    0.075736     0.0136179    0.0233733    0.0209462   -0.0424627    -0.00367812  -0.248033     0.153932    -0.0375195   0.055918    -0.0429878   -0.120696    0.0311924   -0.12492
 -0.028483    -0.0362185   -0.0835851    0.0469836    0.0843036   -0.0134733    -0.126713   -0.0671717   -0.125047    -0.113236    -0.0892315    0.070341    -0.0215455    0.0509896   -0.119053    -0.0584182   -0.0118006     0.0749004    0.162511     0.0478544    0.154985   -0.139529    -0.067749     0.0524248   0.00292339  -0.194447
  0.144992    -0.00568266   0.137458    -0.0176709    0.107668    -0.230893      0.0133256  -0.00168286  -0.00368938  -0.152787     0.088262    -0.103931    -0.191165    -0.0182242   -0.0254477   -0.1005       0.0296417    -0.0955612   -0.183996    -0.0574173    0.0400037  -0.0847982   -0.0194389   -0.105137    0.0170069    0.0564114
  0.00287445   0.0968138    0.0801054   -0.130604    -0.025679    -0.02947      -0.0913196  -0.0760064   -0.00633678  -0.0541508    0.0252072   -0.0685936   -0.142937     0.019964     0.0507983   -0.128613    -0.0585837    -0.010033    -0.00240736  -0.101101    -0.0276561  -0.0775465   -0.0160294   -0.0190681  -0.116092     0.172546
  0.0836927   -0.0928031   -0.128296    -0.119002    -0.220055     0.141537      0.145803    0.174669    -0.124163     0.0208169   -0.0511244   -0.133045     0.0372617   -0.00203534   0.0587879   -0.053821    -0.0338801     0.0854605    0.00183672  -0.124291     0.102352   -0.00129685   0.080538    -0.152463    0.0701198   -0.0383795
 -0.0573706    0.0258323   -0.0352828    0.0843166   -0.00189016  -0.0866734    -0.0701322   0.15496     -0.00256409   0.0132185    0.205247     0.00523536   0.0274603    0.0361362   -0.0960537   -0.0890545    0.0683291    -0.0738639    0.00678611  -0.0212036   -0.150932    0.140979     0.0654523    0.109065   -0.0239915    0.0160742
 -0.141432     0.0776735    0.0408292   -0.0985926   -0.0605352   -0.0886689    -0.0172382  -0.103259     0.17501      0.147694     0.134045     0.0131596   -0.0626842    0.121051    -0.0287194    0.130042     0.057853      0.0750406    0.102736    -0.107122    -0.147592    0.0778674   -0.0640351    0.0274645  -0.0449158    0.209625
 -0.1286      -0.00554371  -0.212653     0.0431317    0.027389    -0.0680134     0.0951766   0.042357    -0.0469937    0.00119479  -0.00733051   0.0142001    0.119284     0.0616371   -0.0788494    0.216567    -0.0724988    -0.0674651   -0.00474313  -0.0196238    0.0935755  -0.0129749    0.065916    -0.14649     0.0069736    0.122853
 -0.152183     0.122248    -0.20097      0.232575     0.0221408    0.00971573    0.0806759   0.00129098   0.0179861    0.0207373   -0.0847088   -0.0823671   -0.0416222    0.0606341    0.0877706    0.110129    -0.0524102    -0.0415343    0.00790467  -0.00169491   0.0683194   0.1206       0.128424    -0.0287229  -0.102949    -0.0673096
  0.0334694   -0.0138386   -0.0515114    0.0543007   -0.129576    -0.00149145    0.0890637   0.19214     -0.160983     0.0222388    0.0279165   -0.12722      0.214379    -0.0481523    0.166181     0.06248      0.113616     -0.103148    -0.0679665   -0.0214389   -0.0525575   0.114578     0.103902     0.0233582  -0.0250091   -0.260701
  0.0728767    0.0528827    0.0672734    0.0720201    0.0873428    0.0501425     0.109357   -0.0498602    0.0175154    0.0044805   -0.019866     0.0358361    0.085074    -0.128483    -0.0969859    0.0942765   -0.0445981     0.00111337   0.0662861   -0.00339754  -0.0299455   0.00510827  -0.0431709    0.018586   -0.108297     0.106645kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.431562244085532
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.431582
[ Info: iteration 2, average log likelihood -1.431514
[ Info: iteration 3, average log likelihood -1.431462
[ Info: iteration 4, average log likelihood -1.431399
[ Info: iteration 5, average log likelihood -1.431319
[ Info: iteration 6, average log likelihood -1.431206
[ Info: iteration 7, average log likelihood -1.431031
[ Info: iteration 8, average log likelihood -1.430724
[ Info: iteration 9, average log likelihood -1.430174
[ Info: iteration 10, average log likelihood -1.429298
[ Info: iteration 11, average log likelihood -1.428234
[ Info: iteration 12, average log likelihood -1.427332
[ Info: iteration 13, average log likelihood -1.426795
[ Info: iteration 14, average log likelihood -1.426545
[ Info: iteration 15, average log likelihood -1.426441
[ Info: iteration 16, average log likelihood -1.426398
[ Info: iteration 17, average log likelihood -1.426381
[ Info: iteration 18, average log likelihood -1.426373
[ Info: iteration 19, average log likelihood -1.426370
[ Info: iteration 20, average log likelihood -1.426368
[ Info: iteration 21, average log likelihood -1.426367
[ Info: iteration 22, average log likelihood -1.426366
[ Info: iteration 23, average log likelihood -1.426366
[ Info: iteration 24, average log likelihood -1.426366
[ Info: iteration 25, average log likelihood -1.426365
[ Info: iteration 26, average log likelihood -1.426365
[ Info: iteration 27, average log likelihood -1.426365
[ Info: iteration 28, average log likelihood -1.426365
[ Info: iteration 29, average log likelihood -1.426365
[ Info: iteration 30, average log likelihood -1.426364
[ Info: iteration 31, average log likelihood -1.426364
[ Info: iteration 32, average log likelihood -1.426364
[ Info: iteration 33, average log likelihood -1.426364
[ Info: iteration 34, average log likelihood -1.426364
[ Info: iteration 35, average log likelihood -1.426364
[ Info: iteration 36, average log likelihood -1.426364
[ Info: iteration 37, average log likelihood -1.426364
[ Info: iteration 38, average log likelihood -1.426364
[ Info: iteration 39, average log likelihood -1.426364
[ Info: iteration 40, average log likelihood -1.426364
[ Info: iteration 41, average log likelihood -1.426364
[ Info: iteration 42, average log likelihood -1.426364
[ Info: iteration 43, average log likelihood -1.426363
[ Info: iteration 44, average log likelihood -1.426363
[ Info: iteration 45, average log likelihood -1.426363
[ Info: iteration 46, average log likelihood -1.426363
[ Info: iteration 47, average log likelihood -1.426363
[ Info: iteration 48, average log likelihood -1.426363
[ Info: iteration 49, average log likelihood -1.426363
[ Info: iteration 50, average log likelihood -1.426363
┌ Info: EM with 100000 data points 50 iterations avll -1.426363
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.431581702375427
│     -1.4315140750228745
│      ⋮
└     -1.4263633201572303
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.426383
[ Info: iteration 2, average log likelihood -1.426313
[ Info: iteration 3, average log likelihood -1.426260
[ Info: iteration 4, average log likelihood -1.426198
[ Info: iteration 5, average log likelihood -1.426124
[ Info: iteration 6, average log likelihood -1.426041
[ Info: iteration 7, average log likelihood -1.425953
[ Info: iteration 8, average log likelihood -1.425869
[ Info: iteration 9, average log likelihood -1.425796
[ Info: iteration 10, average log likelihood -1.425737
[ Info: iteration 11, average log likelihood -1.425692
[ Info: iteration 12, average log likelihood -1.425657
[ Info: iteration 13, average log likelihood -1.425630
[ Info: iteration 14, average log likelihood -1.425608
[ Info: iteration 15, average log likelihood -1.425589
[ Info: iteration 16, average log likelihood -1.425572
[ Info: iteration 17, average log likelihood -1.425555
[ Info: iteration 18, average log likelihood -1.425539
[ Info: iteration 19, average log likelihood -1.425523
[ Info: iteration 20, average log likelihood -1.425506
[ Info: iteration 21, average log likelihood -1.425489
[ Info: iteration 22, average log likelihood -1.425471
[ Info: iteration 23, average log likelihood -1.425453
[ Info: iteration 24, average log likelihood -1.425435
[ Info: iteration 25, average log likelihood -1.425418
[ Info: iteration 26, average log likelihood -1.425400
[ Info: iteration 27, average log likelihood -1.425384
[ Info: iteration 28, average log likelihood -1.425368
[ Info: iteration 29, average log likelihood -1.425354
[ Info: iteration 30, average log likelihood -1.425342
[ Info: iteration 31, average log likelihood -1.425330
[ Info: iteration 32, average log likelihood -1.425321
[ Info: iteration 33, average log likelihood -1.425312
[ Info: iteration 34, average log likelihood -1.425305
[ Info: iteration 35, average log likelihood -1.425299
[ Info: iteration 36, average log likelihood -1.425293
[ Info: iteration 37, average log likelihood -1.425289
[ Info: iteration 38, average log likelihood -1.425285
[ Info: iteration 39, average log likelihood -1.425281
[ Info: iteration 40, average log likelihood -1.425278
[ Info: iteration 41, average log likelihood -1.425276
[ Info: iteration 42, average log likelihood -1.425274
[ Info: iteration 43, average log likelihood -1.425272
[ Info: iteration 44, average log likelihood -1.425270
[ Info: iteration 45, average log likelihood -1.425268
[ Info: iteration 46, average log likelihood -1.425267
[ Info: iteration 47, average log likelihood -1.425266
[ Info: iteration 48, average log likelihood -1.425265
[ Info: iteration 49, average log likelihood -1.425264
[ Info: iteration 50, average log likelihood -1.425263
┌ Info: EM with 100000 data points 50 iterations avll -1.425263
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4263825336353677
│     -1.4263128856433738
│      ⋮
└     -1.4252626665681454
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425273
[ Info: iteration 2, average log likelihood -1.425215
[ Info: iteration 3, average log likelihood -1.425163
[ Info: iteration 4, average log likelihood -1.425105
[ Info: iteration 5, average log likelihood -1.425033
[ Info: iteration 6, average log likelihood -1.424948
[ Info: iteration 7, average log likelihood -1.424851
[ Info: iteration 8, average log likelihood -1.424750
[ Info: iteration 9, average log likelihood -1.424651
[ Info: iteration 10, average log likelihood -1.424561
[ Info: iteration 11, average log likelihood -1.424483
[ Info: iteration 12, average log likelihood -1.424418
[ Info: iteration 13, average log likelihood -1.424364
[ Info: iteration 14, average log likelihood -1.424319
[ Info: iteration 15, average log likelihood -1.424283
[ Info: iteration 16, average log likelihood -1.424253
[ Info: iteration 17, average log likelihood -1.424229
[ Info: iteration 18, average log likelihood -1.424208
[ Info: iteration 19, average log likelihood -1.424190
[ Info: iteration 20, average log likelihood -1.424175
[ Info: iteration 21, average log likelihood -1.424162
[ Info: iteration 22, average log likelihood -1.424150
[ Info: iteration 23, average log likelihood -1.424138
[ Info: iteration 24, average log likelihood -1.424128
[ Info: iteration 25, average log likelihood -1.424118
[ Info: iteration 26, average log likelihood -1.424109
[ Info: iteration 27, average log likelihood -1.424100
[ Info: iteration 28, average log likelihood -1.424091
[ Info: iteration 29, average log likelihood -1.424083
[ Info: iteration 30, average log likelihood -1.424075
[ Info: iteration 31, average log likelihood -1.424067
[ Info: iteration 32, average log likelihood -1.424060
[ Info: iteration 33, average log likelihood -1.424053
[ Info: iteration 34, average log likelihood -1.424046
[ Info: iteration 35, average log likelihood -1.424039
[ Info: iteration 36, average log likelihood -1.424033
[ Info: iteration 37, average log likelihood -1.424027
[ Info: iteration 38, average log likelihood -1.424021
[ Info: iteration 39, average log likelihood -1.424015
[ Info: iteration 40, average log likelihood -1.424009
[ Info: iteration 41, average log likelihood -1.424004
[ Info: iteration 42, average log likelihood -1.423999
[ Info: iteration 43, average log likelihood -1.423994
[ Info: iteration 44, average log likelihood -1.423989
[ Info: iteration 45, average log likelihood -1.423984
[ Info: iteration 46, average log likelihood -1.423980
[ Info: iteration 47, average log likelihood -1.423975
[ Info: iteration 48, average log likelihood -1.423971
[ Info: iteration 49, average log likelihood -1.423967
[ Info: iteration 50, average log likelihood -1.423963
┌ Info: EM with 100000 data points 50 iterations avll -1.423963
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4252730626839367
│     -1.4252145436165125
│      ⋮
└     -1.4239627053341823
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423968
[ Info: iteration 2, average log likelihood -1.423921
[ Info: iteration 3, average log likelihood -1.423879
[ Info: iteration 4, average log likelihood -1.423832
[ Info: iteration 5, average log likelihood -1.423775
[ Info: iteration 6, average log likelihood -1.423706
[ Info: iteration 7, average log likelihood -1.423623
[ Info: iteration 8, average log likelihood -1.423529
[ Info: iteration 9, average log likelihood -1.423427
[ Info: iteration 10, average log likelihood -1.423323
[ Info: iteration 11, average log likelihood -1.423221
[ Info: iteration 12, average log likelihood -1.423124
[ Info: iteration 13, average log likelihood -1.423034
[ Info: iteration 14, average log likelihood -1.422950
[ Info: iteration 15, average log likelihood -1.422874
[ Info: iteration 16, average log likelihood -1.422805
[ Info: iteration 17, average log likelihood -1.422744
[ Info: iteration 18, average log likelihood -1.422691
[ Info: iteration 19, average log likelihood -1.422645
[ Info: iteration 20, average log likelihood -1.422605
[ Info: iteration 21, average log likelihood -1.422571
[ Info: iteration 22, average log likelihood -1.422541
[ Info: iteration 23, average log likelihood -1.422516
[ Info: iteration 24, average log likelihood -1.422493
[ Info: iteration 25, average log likelihood -1.422473
[ Info: iteration 26, average log likelihood -1.422456
[ Info: iteration 27, average log likelihood -1.422439
[ Info: iteration 28, average log likelihood -1.422425
[ Info: iteration 29, average log likelihood -1.422411
[ Info: iteration 30, average log likelihood -1.422398
[ Info: iteration 31, average log likelihood -1.422386
[ Info: iteration 32, average log likelihood -1.422375
[ Info: iteration 33, average log likelihood -1.422364
[ Info: iteration 34, average log likelihood -1.422353
[ Info: iteration 35, average log likelihood -1.422343
[ Info: iteration 36, average log likelihood -1.422333
[ Info: iteration 37, average log likelihood -1.422323
[ Info: iteration 38, average log likelihood -1.422314
[ Info: iteration 39, average log likelihood -1.422305
[ Info: iteration 40, average log likelihood -1.422296
[ Info: iteration 41, average log likelihood -1.422287
[ Info: iteration 42, average log likelihood -1.422278
[ Info: iteration 43, average log likelihood -1.422269
[ Info: iteration 44, average log likelihood -1.422261
[ Info: iteration 45, average log likelihood -1.422253
[ Info: iteration 46, average log likelihood -1.422245
[ Info: iteration 47, average log likelihood -1.422237
[ Info: iteration 48, average log likelihood -1.422229
[ Info: iteration 49, average log likelihood -1.422221
[ Info: iteration 50, average log likelihood -1.422213
┌ Info: EM with 100000 data points 50 iterations avll -1.422213
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4239678653106174
│     -1.423920891009193
│      ⋮
└     -1.422213059524694
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422213
[ Info: iteration 2, average log likelihood -1.422157
[ Info: iteration 3, average log likelihood -1.422105
[ Info: iteration 4, average log likelihood -1.422047
[ Info: iteration 5, average log likelihood -1.421976
[ Info: iteration 6, average log likelihood -1.421891
[ Info: iteration 7, average log likelihood -1.421789
[ Info: iteration 8, average log likelihood -1.421672
[ Info: iteration 9, average log likelihood -1.421544
[ Info: iteration 10, average log likelihood -1.421409
[ Info: iteration 11, average log likelihood -1.421274
[ Info: iteration 12, average log likelihood -1.421143
[ Info: iteration 13, average log likelihood -1.421019
[ Info: iteration 14, average log likelihood -1.420905
[ Info: iteration 15, average log likelihood -1.420801
[ Info: iteration 16, average log likelihood -1.420707
[ Info: iteration 17, average log likelihood -1.420624
[ Info: iteration 18, average log likelihood -1.420550
[ Info: iteration 19, average log likelihood -1.420485
[ Info: iteration 20, average log likelihood -1.420427
[ Info: iteration 21, average log likelihood -1.420374
[ Info: iteration 22, average log likelihood -1.420327
[ Info: iteration 23, average log likelihood -1.420284
[ Info: iteration 24, average log likelihood -1.420244
[ Info: iteration 25, average log likelihood -1.420207
[ Info: iteration 26, average log likelihood -1.420172
[ Info: iteration 27, average log likelihood -1.420139
[ Info: iteration 28, average log likelihood -1.420107
[ Info: iteration 29, average log likelihood -1.420077
[ Info: iteration 30, average log likelihood -1.420048
[ Info: iteration 31, average log likelihood -1.420020
[ Info: iteration 32, average log likelihood -1.419994
[ Info: iteration 33, average log likelihood -1.419968
[ Info: iteration 34, average log likelihood -1.419943
[ Info: iteration 35, average log likelihood -1.419918
[ Info: iteration 36, average log likelihood -1.419894
[ Info: iteration 37, average log likelihood -1.419871
[ Info: iteration 38, average log likelihood -1.419849
[ Info: iteration 39, average log likelihood -1.419827
[ Info: iteration 40, average log likelihood -1.419806
[ Info: iteration 41, average log likelihood -1.419785
[ Info: iteration 42, average log likelihood -1.419765
[ Info: iteration 43, average log likelihood -1.419746
[ Info: iteration 44, average log likelihood -1.419727
[ Info: iteration 45, average log likelihood -1.419709
[ Info: iteration 46, average log likelihood -1.419692
[ Info: iteration 47, average log likelihood -1.419675
[ Info: iteration 48, average log likelihood -1.419659
[ Info: iteration 49, average log likelihood -1.419643
[ Info: iteration 50, average log likelihood -1.419628
┌ Info: EM with 100000 data points 50 iterations avll -1.419628
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4222126048941932
│     -1.42215745157748
│      ⋮
└     -1.419627802451325
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.431562244085532
│     -1.431581702375427
│     -1.4315140750228745
│     -1.4314618961736525
│      ⋮
│     -1.4196588831557624
│     -1.4196430913342304
└     -1.419627802451325
32×26 Array{Float64,2}:
 -0.200729   -0.200176   -0.0228887   0.401819   -0.203875    -0.698343    -0.23978     0.284279    -0.12485      0.495829    -0.789466   -0.637195     0.23391     0.38408    -0.21056     0.160498    -0.209765    -0.393473    0.254045   -0.129628    -0.230189    0.1489     -0.351858    -0.419733    0.401309    0.0345538
 -0.333691   -0.36794     0.10947     0.206211   -0.59891      0.125973     0.373494    0.509996    -0.521859     0.0582965   -0.465764    0.811391     0.39786     0.445192    0.143317    0.119033    -0.153283    -0.359359    0.414877    0.192396     0.47535    -0.229852   -0.518569    -0.281722    0.293575    0.102221
  0.114369    0.527597    0.341141   -0.41273    -0.405925    -0.0680181    0.504123   -0.141439    -0.522986     0.305872    -0.579607   -0.225846    -0.163153   -0.529457    0.132589   -0.0154929    0.666964     0.331814    0.171733    0.340823     0.279158   -0.338353    0.360548    -0.668208    0.225194    0.232728
  0.426044   -0.0400904   0.51526    -0.0335884   0.0571065    0.938175     0.860354   -0.0546547   -0.252283     0.376968    -0.435669   -0.1949       0.349567   -0.0019891  -0.0719988   0.220843     0.215315     0.270243    0.789946   -0.287041    -0.218381    0.302094    0.199255     0.0555924   0.19302     0.264991
 -0.467768   -0.167024   -0.0500969   0.172549   -0.0977145    0.432709     0.486309   -0.329955     0.118306     0.230723     0.580786    0.512051    -0.060117   -0.322896   -0.105606   -0.389695     0.277109     0.437127    0.27937    -0.0866661   -0.0820391  -0.249645    0.441786     0.512291   -0.834361   -0.356
  0.066067   -0.0739828  -0.119422    0.304797   -0.200911     0.442691     0.0910826  -0.371371    -0.0669456    0.356298     0.725764    0.194895    -0.295539   -0.655624    0.186594    0.907817    -0.146785    -0.101993    0.420872   -0.00548413   0.295597    0.176485   -0.247825    -0.319062   -0.664493    0.0345828
  3.7572e-5  -0.406387   -0.235233    0.362791   -0.0265752    0.449832    -0.0252409   0.399969     0.462831    -0.0559076    0.157474    0.427381     0.111314    0.368568    0.25682     0.0381075   -0.118812    -0.42463     0.349561   -0.848165     0.019822   -0.241543    0.489337     1.06098     0.0459912  -0.39098
  0.412297    0.0577685  -0.618634   -0.621727    0.0236538    0.237893     0.182088    0.225034     0.0867033   -0.111484     0.188603    0.40361      0.479097   -0.697713    0.406119   -0.343306    -0.125018     0.310686    0.468291    0.0408832    0.300837    0.130152    0.22055      0.686995    0.421126   -0.260189
  0.304152   -0.0745509  -0.132896   -0.342275    0.387977    -0.0915241   -0.448049    0.0533148    0.0301552    0.069148     0.103813   -0.110135     0.431956   -0.342743   -0.472821   -0.792102    -0.0389863   -0.239178    0.32394    -0.210286    -0.882929   -0.295632    0.0974946    0.199734   -0.264267    0.205701
  0.05576     0.854065    0.388907   -0.167721    0.401049    -0.243171    -0.222318   -0.216743     0.518076    -0.158243    -0.0507421  -0.702729    -0.20148    -0.650487    0.267971   -0.420464    -0.0562484   -0.367825    0.15537     0.215467    -0.392651    0.225589    0.0322774   -0.125126   -0.191304   -0.80137
 -0.698321   -0.291883   -0.873723    0.436046   -0.239719    -0.430104    -0.518935   -0.0265328    0.194404    -0.231112     0.233731   -0.0250171    0.0359201   0.303465    0.0684475  -0.193745    -0.459392    -0.157245   -0.597259    0.369352     0.314095   -0.345228   -0.125637     0.0173606  -0.496625   -0.834874
 -0.192377    0.198533   -0.184545    0.220717    0.00805722  -0.0970859    0.2582     -0.0229951    0.0637542    0.468274    -0.231231   -0.443701    -0.228214    0.277268   -0.189925    0.0379542    0.0673039   -0.378205    0.0543375   0.0994621   -0.247338   -0.289667    0.111469     0.122766   -0.111923   -0.487368
  0.0521092  -0.240757    0.41578     0.0955145   0.414847    -0.403385     0.273928   -0.823908    -0.0747597   -0.496094     0.184754    0.258945     0.0425966   0.114876    0.201738    0.0245498    0.286089    -0.0475195   0.103249   -0.0141376    0.0589108  -0.093085   -0.49596     -1.03125    -0.29419    -0.0707254
 -0.0983984   0.260269    0.145601   -0.3877      0.487727     0.0595286   -0.213595    0.17365     -0.247775    -0.70272     -0.224579   -0.432365    -0.187345    0.213528    0.0244956   0.253983    -0.332308     0.0390255  -0.34755     0.211307     0.159713    0.327749   -0.405232    -0.214568    0.328475    0.522853
  0.172592   -0.0487621   0.0195791  -0.126103    0.0421992   -0.114142    -0.629975   -0.38038      0.373917     0.00930776   0.725452   -0.605984    -0.234204   -0.305352   -0.233222   -0.0819763   -0.0208132    0.778779   -0.569083   -0.465358    -0.254216    0.818735    0.247883     0.354139   -0.288817    0.506114
  0.0883811  -0.377837    0.134333    0.145584   -0.619341    -0.0566426    0.0443292   0.154548    -0.167101    -0.0651191   -0.0603731   0.784019     0.425541    0.0114946   0.0814596  -0.056583     0.0948276    0.427062   -0.161552   -0.173985     0.0508114   0.311154    0.417089    -0.0649183  -0.0196888   0.411439
 -0.209433   -0.0886466  -0.278956    0.561435   -0.0893059   -0.00284919  -0.631736    0.329057    -0.404722     0.0548964   -0.176676   -0.200098    -0.0827672   0.134407   -0.490017    0.617446     0.189844     0.230484    0.0188418  -0.741228     0.177784    0.151647    0.106548     0.392863    0.183969    0.32419
 -0.52206     0.0218546  -0.650528    0.53973     0.414002     0.136511     0.398736    0.0767695   -0.216789     0.208964    -0.366459    0.145777     0.506265   -0.153297    0.321909    0.197342     0.225098    -0.309384    0.266475   -0.763052     0.214503   -0.743581    0.178173    -0.105023    0.207859   -0.188835
 -0.167198   -0.207818   -0.235918    0.0998811   0.620178     0.238038    -0.299458    0.0235473    0.222462    -0.883248    -0.112518   -0.196304     0.096835    0.0486343   0.21644     0.206388    -0.0592189    0.24819    -0.366745   -0.393085     0.322627    0.346273    0.25292     -0.131331   -0.222057   -0.301702
  0.388747    0.03792    -0.219989   -0.220625    0.120591     0.0571308   -0.347241    0.457493     0.730165    -0.174491    -0.443613    0.180157     0.443526    0.173786   -0.183446   -0.121335     0.581958    -0.0163047  -0.439385   -0.394139     0.227621    0.174371   -0.220347     0.250036    1.08554    -0.220527
  0.106325   -0.008047   -0.152654    0.0551207  -0.183348     0.12544      0.17457    -0.00227188   0.278181     0.324569    -0.045102    0.099062     0.156071   -0.225705   -0.0779012  -0.00795424   0.129263     0.033106    0.274215   -0.0959595    0.114933   -0.0149182   0.14067      0.184751   -0.175064   -0.322006
 -0.0575791  -0.0466377  -0.0532148  -0.0137162   0.0113921   -0.0689023   -0.111266    0.166084    -0.0393444   -0.143999    -0.0245669  -0.092986     0.0342181   0.128926    0.043974   -0.0476401   -0.12992     -0.0544686  -0.132483   -0.0310363   -0.0307898   0.16033     0.00492106  -0.0389138   0.0673458   0.0014623
  0.130968    0.186529    0.0734933   0.103319   -0.0634867   -0.092134     0.0787104  -0.203087    -0.135746     0.0169564   -0.143752    0.18052     -0.322048    0.625317   -0.220493   -0.0670989   -0.00422746  -0.512879    0.407131    0.397803    -0.266088   -0.720105   -0.131784    -0.0719573  -0.116318   -0.11129
 -0.285824    0.0902213  -0.0528754   0.104662    0.256167    -0.0198631    0.618836    0.320365     0.546931    -0.0460271   -0.483758   -0.240811     0.206934    0.587241   -0.245234   -0.196169     0.14441     -0.0626814  -0.278051    0.46279     -0.214998   -0.296626    0.554614     0.0629413   0.0930116  -0.593226
 -0.0937545  -0.109794   -0.76822    -0.35199     0.45068     -0.095507     0.0985191  -0.0205424    0.00748209   0.0317748   -0.121895   -0.670676    -0.287658   -0.230987   -0.355317    0.0712152    0.199698    -0.0828384  -0.143828    0.153876     0.495104   -0.345721   -0.648661    -0.356886    0.308835   -0.116887
  0.259019    0.592112    0.133334   -0.340806    0.344871     0.198852    -0.155764   -0.123539    -0.316872    -0.265652     0.629311   -0.53592     -0.661579   -0.419575    0.0690848   0.171073     0.0168063   -0.28266    -0.132736   -0.248068     0.229499    0.192106   -0.346062     0.24361    -0.164601    0.211924
  0.115328    0.0658502   0.0992951  -0.0961987   0.0867716    0.00512983  -0.199485   -0.305608    -0.454286     0.0145887   -0.0989919  -0.00623227   0.578427   -0.540064   -0.0883749  -0.010453    -0.37112      0.179675    0.106832    0.221862    -0.0659909   0.222727   -0.298152    -0.467343   -0.175054    0.536592
 -0.108787   -0.261809    0.33734     0.0538505  -0.155265     0.119495     0.118985   -0.122116    -0.247142    -0.403782     0.157531    0.340264    -0.11275     0.324051   -0.0187521   0.184148     0.277501     0.359745    0.0612273  -0.424278     0.0898721   0.16891     0.00540152  -0.158946    0.0121942   0.613473
  0.0542795  -0.205082    0.450902   -0.304953    0.0444122   -0.660999    -0.208065   -0.0700208    0.330791    -0.429232    -0.0958963  -0.100918    -0.110164    0.344114    0.0726277  -0.431834    -0.338458    -0.0177548  -0.462496    0.168601    -0.241832    0.606358   -0.133362    -0.153218   -0.136962   -0.0526994
  0.162229    0.177161    0.168864   -0.150579   -0.35446      0.435473    -0.229474    0.167926     0.195614    -0.294261     0.158628   -0.0124703   -0.498815    0.43853    -0.0772652   0.218359    -0.340426     0.0552772  -0.48032     0.543176     0.215324    0.700323    0.290698     0.158019   -0.256048   -0.42213
  0.149739    0.162566    0.433385    0.194213   -0.997453    -0.556573    -0.0411971   0.186995     0.190678     0.766247    -0.0175832   0.107723    -0.287744    0.0429766   0.13316    -0.378994    -0.260918    -0.263052   -0.382145    0.427151    -0.267668    0.48619     0.0537932    0.0776983  -0.0167994   0.20168
 -0.570129    0.169904   -0.245381    0.0395052  -0.352841    -0.182158    -0.0231218  -0.0620528   -0.220257     0.0619034    0.376154   -0.235992    -0.268114    0.273887    0.237704    0.0351538   -0.0144023    0.0694184  -0.714633    0.33393     -0.191986    0.0233353   0.331659     0.0776145   0.129546    0.706386[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419613
[ Info: iteration 2, average log likelihood -1.419599
[ Info: iteration 3, average log likelihood -1.419585
[ Info: iteration 4, average log likelihood -1.419571
[ Info: iteration 5, average log likelihood -1.419558
[ Info: iteration 6, average log likelihood -1.419546
[ Info: iteration 7, average log likelihood -1.419533
[ Info: iteration 8, average log likelihood -1.419521
[ Info: iteration 9, average log likelihood -1.419510
[ Info: iteration 10, average log likelihood -1.419498
┌ Info: EM with 100000 data points 10 iterations avll -1.419498
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.810267e+05
      1       7.184878e+05      -2.625389e+05 |       32
      2       7.036769e+05      -1.481091e+04 |       32
      3       6.982131e+05      -5.463789e+03 |       32
      4       6.954274e+05      -2.785690e+03 |       32
      5       6.937343e+05      -1.693157e+03 |       32
      6       6.925490e+05      -1.185256e+03 |       32
      7       6.916977e+05      -8.512791e+02 |       32
      8       6.909891e+05      -7.086447e+02 |       32
      9       6.904414e+05      -5.476382e+02 |       32
     10       6.899559e+05      -4.855484e+02 |       32
     11       6.895468e+05      -4.091016e+02 |       32
     12       6.891855e+05      -3.612543e+02 |       32
     13       6.888441e+05      -3.414081e+02 |       32
     14       6.885539e+05      -2.902440e+02 |       32
     15       6.882775e+05      -2.763515e+02 |       32
     16       6.880287e+05      -2.487930e+02 |       32
     17       6.877925e+05      -2.362006e+02 |       32
     18       6.875814e+05      -2.111603e+02 |       32
     19       6.873804e+05      -2.009350e+02 |       32
     20       6.871611e+05      -2.192991e+02 |       32
     21       6.869630e+05      -1.981508e+02 |       32
     22       6.867887e+05      -1.742976e+02 |       32
     23       6.866323e+05      -1.563400e+02 |       32
     24       6.865128e+05      -1.195655e+02 |       32
     25       6.864125e+05      -1.002501e+02 |       32
     26       6.863195e+05      -9.302315e+01 |       32
     27       6.862366e+05      -8.288087e+01 |       32
     28       6.861555e+05      -8.116276e+01 |       32
     29       6.860742e+05      -8.130189e+01 |       32
     30       6.859981e+05      -7.611024e+01 |       32
     31       6.859252e+05      -7.282784e+01 |       32
     32       6.858557e+05      -6.957325e+01 |       32
     33       6.857857e+05      -6.996618e+01 |       32
     34       6.857176e+05      -6.812576e+01 |       32
     35       6.856492e+05      -6.834611e+01 |       32
     36       6.855932e+05      -5.603211e+01 |       32
     37       6.855377e+05      -5.547595e+01 |       32
     38       6.854844e+05      -5.334928e+01 |       32
     39       6.854340e+05      -5.034547e+01 |       32
     40       6.853855e+05      -4.855261e+01 |       32
     41       6.853428e+05      -4.269287e+01 |       32
     42       6.852959e+05      -4.686340e+01 |       32
     43       6.852552e+05      -4.071618e+01 |       32
     44       6.852138e+05      -4.135037e+01 |       32
     45       6.851750e+05      -3.886811e+01 |       32
     46       6.851382e+05      -3.673006e+01 |       32
     47       6.850995e+05      -3.873015e+01 |       32
     48       6.850657e+05      -3.376480e+01 |       32
     49       6.850359e+05      -2.981665e+01 |       32
     50       6.850094e+05      -2.648492e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 685009.4421599107)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.431779
[ Info: iteration 2, average log likelihood -1.426676
[ Info: iteration 3, average log likelihood -1.425504
[ Info: iteration 4, average log likelihood -1.424829
[ Info: iteration 5, average log likelihood -1.424122
[ Info: iteration 6, average log likelihood -1.423227
[ Info: iteration 7, average log likelihood -1.422253
[ Info: iteration 8, average log likelihood -1.421478
[ Info: iteration 9, average log likelihood -1.421018
[ Info: iteration 10, average log likelihood -1.420775
[ Info: iteration 11, average log likelihood -1.420637
[ Info: iteration 12, average log likelihood -1.420545
[ Info: iteration 13, average log likelihood -1.420475
[ Info: iteration 14, average log likelihood -1.420418
[ Info: iteration 15, average log likelihood -1.420369
[ Info: iteration 16, average log likelihood -1.420325
[ Info: iteration 17, average log likelihood -1.420285
[ Info: iteration 18, average log likelihood -1.420248
[ Info: iteration 19, average log likelihood -1.420214
[ Info: iteration 20, average log likelihood -1.420182
[ Info: iteration 21, average log likelihood -1.420151
[ Info: iteration 22, average log likelihood -1.420122
[ Info: iteration 23, average log likelihood -1.420094
[ Info: iteration 24, average log likelihood -1.420067
[ Info: iteration 25, average log likelihood -1.420041
[ Info: iteration 26, average log likelihood -1.420017
[ Info: iteration 27, average log likelihood -1.419993
[ Info: iteration 28, average log likelihood -1.419970
[ Info: iteration 29, average log likelihood -1.419949
[ Info: iteration 30, average log likelihood -1.419928
[ Info: iteration 31, average log likelihood -1.419908
[ Info: iteration 32, average log likelihood -1.419889
[ Info: iteration 33, average log likelihood -1.419871
[ Info: iteration 34, average log likelihood -1.419853
[ Info: iteration 35, average log likelihood -1.419837
[ Info: iteration 36, average log likelihood -1.419821
[ Info: iteration 37, average log likelihood -1.419805
[ Info: iteration 38, average log likelihood -1.419791
[ Info: iteration 39, average log likelihood -1.419777
[ Info: iteration 40, average log likelihood -1.419763
[ Info: iteration 41, average log likelihood -1.419750
[ Info: iteration 42, average log likelihood -1.419737
[ Info: iteration 43, average log likelihood -1.419725
[ Info: iteration 44, average log likelihood -1.419713
[ Info: iteration 45, average log likelihood -1.419701
[ Info: iteration 46, average log likelihood -1.419689
[ Info: iteration 47, average log likelihood -1.419678
[ Info: iteration 48, average log likelihood -1.419667
[ Info: iteration 49, average log likelihood -1.419657
[ Info: iteration 50, average log likelihood -1.419646
┌ Info: EM with 100000 data points 50 iterations avll -1.419646
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.129701    0.191568   -0.0228772   -0.338728   -0.25439     -0.14454    -0.299983    -0.217403   -0.174532     0.155786    0.433591    -0.184794   -0.314118   -0.497679    -0.135537    0.102147   -0.137166     0.0537987   -0.0881343    0.0332867    0.264349     0.410487    -0.305029    -0.00115773  -0.103742     0.387987
  0.206202   -0.151877    0.136579     0.311671    0.508702    -0.359969   -0.298163    -0.499266    0.117328    -0.470574    0.346801     0.548077    0.237708   -0.126908     0.694694    0.0282119   0.539976     0.208618    -0.0305438   -0.279965     0.579032     0.00956184  -0.680797    -0.907444     0.151098     0.817955
 -0.645534    0.0767032  -0.198321    -0.0479255  -0.304181    -0.165299    0.111905     0.0288246  -0.444512    -0.172392    0.25104     -0.075618   -0.0117617   0.267542     0.373942   -0.0758898   0.0663535    0.208249    -0.514016     0.12579     -0.117348     0.0486322    0.305278     0.0637664    0.042177     0.694251
  0.167042    0.432629    0.375101    -0.609947   -0.218164     0.105717    0.519759    -0.395614   -0.561039     0.30618    -0.592723    -0.357123   -0.147492   -0.409431    -0.0737134   0.0436879   0.767196     0.451767     0.341322     0.23509      0.136559    -0.23419      0.118464    -0.536342     0.375916     0.532054
 -0.0939537  -0.172036    0.230986    -0.100772    0.190794    -0.314795   -0.701194     0.270173    0.00227572  -0.459249   -0.0824795   -0.105624   -0.0377668   0.69635     -0.441818   -0.527572   -0.38472      0.12717     -0.35486     -0.13546     -0.408339     0.467239     0.119017     0.367005     0.124826     0.229145
 -0.0515077  -0.237147   -0.296723    -0.0986863   0.0624068   -0.275329   -0.613198    -0.100259    0.392483    -0.575676   -0.0649993   -0.479421   -0.0270878   0.203747     0.424207    0.236886    0.174468     0.00276531  -0.956917    -0.0246579    0.0370275    0.420749     0.135419    -0.333878     0.101227    -0.328475
  0.10576    -0.205251    0.189734    -0.0671778   0.200195    -0.0627322   0.137831    -0.158388   -0.174676    -0.299465   -0.343857    -0.0815715   0.193306    0.146921     0.0579891   0.0445141  -0.00747371  -0.0415838    0.116492     0.116204    -0.00037803  -0.0794507   -0.446067    -0.543513    -0.0761871    0.0662976
  0.197719   -0.0754774  -0.52114     -0.580385    0.671118    -0.080116   -0.314272    -0.286559    0.180912    -0.113241    0.450306    -0.545407   -0.210878   -0.0333583   -0.436251    0.177999    0.194109     0.00357575   0.556892    -0.79932     -0.107954    -0.262136    -0.412112     0.257895    -0.0546466   -0.0915085
  0.239327    0.21846     0.0450619   -0.139484    0.552806    -0.0447758  -0.386476    -0.0566311  -0.24244     -0.0291647   0.00997116  -0.118845    0.828275   -0.77483     -0.239178   -0.486866   -0.352944    -0.128009     0.245359    -0.141018    -0.511811     0.0727115    0.00360894  -0.0811253   -0.125779     0.502867
  0.123382   -0.0703438  -0.294796    -0.318464   -0.270781     0.194265    0.146513    -0.0443475   0.187305     0.447338    0.164218     0.294894    0.0145477  -0.183575    -0.0681946  -0.770883    0.247313    -0.146227     0.1789       0.327146    -0.626301    -0.711309     0.324367     0.524663    -0.428946    -0.274487
 -0.160159    0.185756    0.246622     0.409833   -0.0472797    0.0938095   0.342568    -0.453167   -0.686194     0.327208    0.531398    -0.215485   -0.575648   -0.382536     0.22021     0.254302   -0.431295    -0.35409      0.635769     0.493085    -0.404156    -0.253676     0.242109    -0.365736    -1.0701      -0.337111
  0.0373274  -0.167921    0.285763     0.908668   -0.349026     0.0384612  -0.24499     -0.489337    0.0184164    0.152158    0.468319     0.328182   -0.534333    0.505337    -0.532538    0.425208    0.111832     0.206811    -0.148642    -0.245609    -0.128841    -0.0405115    0.0745455   -0.176337    -0.432985     0.505461
 -0.615061   -0.442801   -0.657348     0.468801   -0.200948    -0.239026   -0.422786     0.0934105   0.362558    -0.353164    0.387799     0.341129   -0.03331     0.20775      0.0242881  -0.237398   -0.575794    -0.152619    -0.331564     0.00116777   0.502785    -0.152719     0.0188395    0.255998    -0.515321    -0.928363
 -0.438698    0.114509   -0.189732    -0.0885619   0.390176    -0.282215   -0.0636716   -0.132875   -0.209921    -0.171033   -0.279843    -0.787779   -0.322841    0.389377    -0.309772    0.072319   -0.246425    -0.131561    -0.492904     0.574893    -0.0444179   -0.0919071   -0.345806    -0.237206     0.0415325   -0.114941
  0.545047    0.0773167  -0.191838    -0.228821   -0.111274     0.47828     0.0827918    0.210374    0.393286    -0.502124   -0.217639     0.71912     0.319082    0.0812341    0.226528   -0.0476505   0.0818792    0.143074     0.319085    -0.256423     0.457847     0.141827     0.340667     0.600544     0.258771    -0.220634
 -0.328513   -0.111264   -0.0705536    0.248558    0.132131     0.484578    0.654466    -0.464669    0.193155    -0.012825    0.723563     0.529445   -0.110677   -0.42497      0.0855138   0.136573    0.387152     0.441881     0.279068    -0.0916775    0.340602    -0.178188     0.187582     0.0442447   -0.631847    -0.373393
 -0.295252   -0.140303   -0.42934      0.314204   -0.06558      0.450651   -0.224744     0.600588    0.433953     0.205128    0.0180813   -0.25581     0.011763    0.440619    -0.168281    0.214918    0.0463755   -0.283371    -0.420967    -0.293749    -0.0639814   -0.0389335    0.27748      1.10388      0.140706    -0.194184
  0.143754   -0.267698    0.355921     0.0983314  -0.206121     0.810493    0.35062     -0.188372   -0.149339     0.0462186  -0.195508    -0.126887    0.334228    0.00226219   0.017126    0.5596     -0.27391      0.44616      0.0424219    0.0346721   -0.00842783   0.962299     0.14632      0.00382607  -0.274713    -0.0293061
 -0.098007    0.0342229  -0.0719916    0.0972837  -0.00928108   0.0798066   0.00459341   0.0860044   0.0749864   -0.0655671   0.0395437    0.0192511  -0.0196991   0.0976262   -0.0380395   0.0271182  -0.0258131   -0.0306224    0.00446876  -0.0827325    0.0373054    0.0429775    0.143414     0.14062     -0.0601412   -0.111202
 -0.173582   -0.587794   -0.257322     0.640105   -0.602752    -0.527663    0.183263     0.0743142   0.0153351    0.74095    -0.828063    -0.0636608   0.66274     0.499133    -0.349856   -0.0788724   0.191551     0.00716242   0.330457    -0.148656    -0.0606085   -0.218158     0.117576    -0.367248     0.00113418  -0.367072
 -0.185048    0.0366368   0.295521     0.269823   -0.0710391   -0.210009   -0.357331     0.300524   -0.202021    -0.395021   -0.482045    -0.349773   -0.271172    0.381607    -0.0755893   0.788684   -0.25978      0.0692236    0.0296672   -0.286994     0.379903     0.404234    -0.365127    -0.536751     0.634237     0.528025
 -0.315153   -0.23804     0.156508     0.131946   -0.544673     0.20536     0.389588     0.418307   -0.655531     0.0136303  -0.328624     0.848616    0.260963    0.381388     0.199495    0.180741   -0.182381    -0.45787      0.348613     0.308409     0.550216    -0.376103    -0.506642    -0.35237      0.301605     0.152474
  0.101065   -0.186982    0.592402    -0.567017    0.0850473   -0.575596    0.11221     -0.483177    0.218383    -0.715727    0.0274865    0.154166    0.121214   -0.0327276    0.114621   -0.521714   -0.26149      0.181186    -0.209877     0.331065    -0.416924     0.572166     0.11902     -0.529848    -0.355526     0.0712202
 -0.156119   -0.242507   -0.060691     0.404734    0.0733086    0.327591    0.364838     0.201833   -0.259061     0.304025   -0.114569     0.275306    0.334982    0.103546     0.231827    0.121746    0.219148    -0.1752       0.699408    -0.974918    -0.238685    -0.382572     0.291294     0.386243     0.156705     0.0846205
 -0.370129    0.302258   -0.719662     0.282338    0.488977     0.21223     0.29286      0.319671    0.00957025   0.15483    -0.665153    -0.299746    0.199407   -0.44812     -0.109123    0.2756      0.170082    -0.1421       0.0461581   -0.346739     0.606098    -0.254863    -0.0106318   -0.121521     0.237996    -0.264989
  0.149063   -0.0449255  -0.0672645   -0.141185   -0.113999     0.199942    0.00348889   0.15468    -0.00629927  -0.0261809   0.20887      0.264871    0.146963   -0.281766     0.100984   -0.039706    0.0928982    0.177682     0.0333218   -0.316035     0.0322502    0.255823     0.218865     0.302826     0.0850136    0.160909
  0.158882    0.553477    0.321126    -0.153961    0.288678    -0.157582   -0.0822896   -0.0976541   0.8069       0.0270935  -0.196457    -0.582367   -0.328816   -0.219784     0.262855   -0.391287    0.0950568   -0.496272     0.0875929    0.186238    -0.113619     0.0815299   -0.156448     0.0723177   -0.0122668   -0.997874
 -0.292655    0.0403111   0.00633851   0.023791    0.242955    -0.205005    0.774576     0.0871066   0.355927    -0.266264   -0.435908    -0.0110295   0.0422286   0.731452    -0.232091   -0.228537    0.087515    -0.263288    -0.0655939    0.431982    -0.231784    -0.401419     0.40888     -0.101705     0.180818    -0.519629
  0.355914   -0.244974   -0.132247    -0.0203942  -0.471345    -0.164874   -0.0215359    0.255245    0.147389     0.579247   -0.163738    -0.0561585   0.380553   -0.349251    -0.0891639  -0.160197    0.0373366   -0.0153465    0.098526     0.0412401   -0.175356     0.21172      0.0903888   -0.0141457    0.217073    -0.128079
  0.305735    0.60428     0.200452    -0.468501    0.342601     0.393902   -0.0990924    0.13686    -0.106412    -0.579898    0.648856    -0.475411   -0.846443   -0.174669     0.0770449   0.121166   -0.131743     0.0525331   -0.566267     0.261006     0.150164     0.346782    -0.0311193    0.0217584   -0.19101      0.11081
  0.0360985   0.291432    0.698463     0.249276   -1.01674     -0.768479    0.0505912    0.236287    0.294344     0.667275   -0.151604     0.0771403  -0.432356    0.27728      0.290011   -0.324259   -0.440126    -0.32832     -0.577929     0.418899    -0.312991     0.618572    -0.0110962    0.10397     -0.025269     0.318538
  0.0140298   0.406449   -0.143221     0.199052    0.0804257   -0.616376   -0.541732     0.0693998  -0.2846       0.597042   -0.29445     -0.254428   -0.132965    0.695007    -0.342698   -0.271192   -0.176866    -0.505234     0.129691     0.613327    -0.25677     -0.426613    -0.470741    -0.559911    -0.0617887   -0.159901[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419636
[ Info: iteration 2, average log likelihood -1.419625
[ Info: iteration 3, average log likelihood -1.419615
[ Info: iteration 4, average log likelihood -1.419605
[ Info: iteration 5, average log likelihood -1.419595
[ Info: iteration 6, average log likelihood -1.419585
[ Info: iteration 7, average log likelihood -1.419576
[ Info: iteration 8, average log likelihood -1.419566
[ Info: iteration 9, average log likelihood -1.419557
[ Info: iteration 10, average log likelihood -1.419547
┌ Info: EM with 100000 data points 10 iterations avll -1.419547
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
