Julia Version 1.5.0-DEV.260
Commit a211abcdfa (2020-02-10 22:01 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed GaussianMixtures ─── v0.3.0
  Installed PDMats ───────────── v0.9.11
  Installed Blosc ────────────── v0.5.1
  Installed JLD ──────────────── v0.9.2
  Installed Arpack ───────────── v0.4.0
  Installed QuadGK ───────────── v2.3.1
  Installed CMake ────────────── v1.2.0
  Installed BinaryProvider ───── v0.5.8
  Installed LegacyStrings ────── v0.4.1
  Installed Rmath ────────────── v0.6.0
  Installed Arpack_jll ───────── v3.5.0+2
  Installed Missings ─────────── v0.4.3
  Installed HDF5 ─────────────── v0.12.5
  Installed OrderedCollections ─ v1.1.0
  Installed Parameters ───────── v0.12.0
  Installed StaticArrays ─────── v0.12.1
  Installed StatsBase ────────── v0.32.0
  Installed DataAPI ──────────── v1.1.0
  Installed SpecialFunctions ─── v0.9.0
  Installed DataStructures ───── v0.17.9
  Installed FileIO ───────────── v1.2.2
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed URIParser ────────── v0.4.0
  Installed Compat ───────────── v2.2.0
  Installed FillArrays ───────── v0.8.4
  Installed CMakeWrapper ─────── v0.2.3
  Installed StatsFuns ────────── v0.9.3
  Installed Distributions ────── v0.22.4
  Installed SortingAlgorithms ── v0.3.1
  Installed BinDeps ──────────── v1.0.0
  Installed ScikitLearnBase ──── v0.5.0
  Installed NearestNeighbors ─── v0.4.4
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed Distances ────────── v0.8.2
  Installed Clustering ───────── v0.13.3
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                         #                                                                          2.3%####                                                                       6.8%########                                                                  12.5%###############                                                           20.9%#####################                                                     30.5%##############################                                            42.7%#####################################                                     52.7%##################################################                        69.7%###################################################################       93.9%######################################################################## 100.0%
#=#=#                                                                         ##############################                                            42.5%######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.2.0
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.2
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building CMake → `~/.julia/packages/CMake/ULbyn/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_tAls9N/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.2.0
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.2
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -1.216216311637931e6, [99980.59888704424, 19.401112955752584], [-35.88781605269816 -157.94761349991785 22.66419657603302; 10.303559663001675 -20.17576721785152 65.28338312048501], [[100198.94974882583 43.8060782513096 -20.074998610565956; 43.8060782513096 99537.6987246647 410.2596386445862; -20.074998610565956 410.2596386445862 99059.51541867062], [29.028339165866562 8.344113679802545 41.771847395065485; 8.34411367980255 57.999861226242615 -59.38876530789661; 41.77184739506548 -59.38876530789661 222.83311915127837]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.594861e+03
      1       1.071005e+03      -5.238553e+02 |        7
      2       1.030151e+03      -4.085452e+01 |        5
      3       9.762975e+02      -5.385325e+01 |        0
      4       9.762975e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 976.29752478004)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.064615
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.686765
[ Info: iteration 2, lowerbound -3.548112
[ Info: iteration 3, lowerbound -3.417689
[ Info: iteration 4, lowerbound -3.288804
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.166821
[ Info: iteration 6, lowerbound -3.058780
[ Info: dropping number of Gaussions to 6
[ Info: iteration 7, lowerbound -2.968071
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.866826
[ Info: iteration 9, lowerbound -2.756377
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.633233
[ Info: iteration 11, lowerbound -2.517264
[ Info: iteration 12, lowerbound -2.431919
[ Info: iteration 13, lowerbound -2.378507
[ Info: dropping number of Gaussions to 3
[ Info: iteration 14, lowerbound -2.341802
[ Info: iteration 15, lowerbound -2.316185
[ Info: iteration 16, lowerbound -2.307487
[ Info: dropping number of Gaussions to 2
[ Info: iteration 17, lowerbound -2.302973
[ Info: iteration 18, lowerbound -2.299262
[ Info: iteration 19, lowerbound -2.299257
[ Info: iteration 20, lowerbound -2.299255
[ Info: iteration 21, lowerbound -2.299254
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Thu Feb 13 07:20:13 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Thu Feb 13 07:20:22 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Thu Feb 13 07:20:24 2020: EM with 272 data points 0 iterations avll -2.064615
5.8 data points per parameter
, Thu Feb 13 07:20:26 2020: GMM converted to Variational GMM
, Thu Feb 13 07:20:33 2020: iteration 1, lowerbound -3.686765
, Thu Feb 13 07:20:33 2020: iteration 2, lowerbound -3.548112
, Thu Feb 13 07:20:33 2020: iteration 3, lowerbound -3.417689
, Thu Feb 13 07:20:33 2020: iteration 4, lowerbound -3.288804
, Thu Feb 13 07:20:33 2020: dropping number of Gaussions to 7
, Thu Feb 13 07:20:33 2020: iteration 5, lowerbound -3.166821
, Thu Feb 13 07:20:33 2020: iteration 6, lowerbound -3.058780
, Thu Feb 13 07:20:33 2020: dropping number of Gaussions to 6
, Thu Feb 13 07:20:33 2020: iteration 7, lowerbound -2.968071
, Thu Feb 13 07:20:33 2020: dropping number of Gaussions to 5
, Thu Feb 13 07:20:33 2020: iteration 8, lowerbound -2.866826
, Thu Feb 13 07:20:33 2020: iteration 9, lowerbound -2.756377
, Thu Feb 13 07:20:33 2020: dropping number of Gaussions to 4
, Thu Feb 13 07:20:33 2020: iteration 10, lowerbound -2.633233
, Thu Feb 13 07:20:34 2020: iteration 11, lowerbound -2.517264
, Thu Feb 13 07:20:34 2020: iteration 12, lowerbound -2.431919
, Thu Feb 13 07:20:34 2020: iteration 13, lowerbound -2.378507
, Thu Feb 13 07:20:34 2020: dropping number of Gaussions to 3
, Thu Feb 13 07:20:34 2020: iteration 14, lowerbound -2.341802
, Thu Feb 13 07:20:34 2020: iteration 15, lowerbound -2.316185
, Thu Feb 13 07:20:34 2020: iteration 16, lowerbound -2.307487
, Thu Feb 13 07:20:34 2020: dropping number of Gaussions to 2
, Thu Feb 13 07:20:34 2020: iteration 17, lowerbound -2.302973
, Thu Feb 13 07:20:34 2020: iteration 18, lowerbound -2.299262
, Thu Feb 13 07:20:34 2020: iteration 19, lowerbound -2.299257
, Thu Feb 13 07:20:34 2020: iteration 20, lowerbound -2.299255
, Thu Feb 13 07:20:34 2020: iteration 21, lowerbound -2.299254
, Thu Feb 13 07:20:34 2020: iteration 22, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 23, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 24, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 25, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 26, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 27, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 28, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 29, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 30, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 31, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 32, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 33, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 34, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 35, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 36, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 37, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 38, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 39, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 40, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 41, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 42, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 43, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 44, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 45, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 46, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 47, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 48, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 49, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: iteration 50, lowerbound -2.299253
, Thu Feb 13 07:20:34 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601382, 95.95490777398616]
β = [178.04509222601382, 95.95490777398616]
m = [4.250300733269911 79.28686694436185; 2.0002292577753704 53.85198717246129]
ν = [180.04509222601382, 97.95490777398616]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484843 -0.007644049042327528; 0.0 0.008581705166333562], [0.3758763611948386 -0.008953123827346018; 0.0 0.012748664777409336]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999994
avll from stats: -0.9932326976309103
avll from llpg:  -0.9932326976309088
avll direct:     -0.9932326976309087
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9915136318563043
avll from llpg:  -0.9915136318563043
avll direct:     -0.9915136318563043
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
 -0.0447833  -0.0584311   -0.1071       0.036031    0.0920451  -0.180814   -0.0717393     0.0966717    0.0952385   -0.072268      0.100741     0.133223     0.0652773    0.0176885   -0.0116779   0.00173087   0.104315     0.220376    -0.0136348   -0.0631912   -0.11273      0.028237     -0.00223704  -0.0758767     0.149587     -0.0784307
  0.112774    0.0163222    0.0370054    0.0482933  -0.110694   -0.0547513  -0.085571     -0.0897849   -0.159091     0.00291932    0.0640285   -0.325427    -0.0275557   -0.0452624   -0.0260657   0.194657    -0.0725899    0.118404    -0.0432197   -0.0325151   -0.143378     0.162231     -0.0861832    0.0141059     0.0412941    -0.0420283
 -0.118959   -0.15928     -0.0921744   -0.120818    0.0417432  -0.130946    0.050134      0.0470521    0.0801915   -0.0456387    -0.13579      0.0319676   -0.0193591   -0.00572314  -0.131039   -0.0513279    0.166948    -0.0697275    0.0723473   -0.0577892   -0.00868902   0.0365876    -0.150325     0.0572208    -0.0825152     0.0469306
 -0.118324   -0.0712377    0.142533    -0.0579058  -0.103053   -0.0493842   0.0758453     0.00642257   0.0639148   -0.0417203    -0.0338992    0.048243     0.00650899   0.0922865    0.0584796   0.0489986    0.0258667    0.00883421  -0.0208438    0.0932839    0.0613994    0.0639218     0.0105051    0.0208554    -0.0783297    -0.0326905
  0.113593    0.10052     -0.0495171   -0.100326   -0.178562   -0.0539479   0.18655       0.0818452    0.0896013    0.0963746     0.245766    -0.00233646  -0.0479251   -0.0214288   -0.095456    0.0977128    0.189403    -0.0567937   -0.12843      0.107832    -0.063992     0.237058      0.0109966    0.0339577     0.0693947     0.0359749
  0.047753   -0.00861486  -0.128734     0.109748    0.122689    0.123447   -0.175946      0.099311    -0.122931     0.00992939    0.157538    -0.0663415    0.074031     0.0148646   -0.0647567  -0.117143     0.0535175    0.230828    -0.012642     0.063746    -0.251695     0.0911073    -0.145542    -0.0490129    -0.0726523    -0.112387
  0.0857495  -0.00134894   0.00448606  -0.214847   -0.160463    0.0509066   0.200572     -0.00435638  -0.0677442   -0.0827724     0.0657497   -0.00235111  -0.0787321   -0.175415    -0.0201015  -0.0353178    0.0263705   -0.0393594    0.0317678   -0.122611     0.127517     0.00254389    0.0794749    0.150729     -0.0614381    -0.0529103
  0.0150587  -0.0756196    0.056265    -0.147021   -0.0741384  -0.0127361   0.236013     -0.1225      -0.052877     0.288718      0.0155419   -0.0700131    0.0788419   -0.0944899    0.178786   -0.0382871    0.0761532    0.0737035    0.08499      0.0808877    0.106222    -0.000106032   0.119293    -0.173679     -0.0327382    -0.00682716
  0.0377662   0.060808    -0.0452026    0.0709095   0.028565    0.147387   -0.0747538     0.0633693    0.00145189  -0.029083      0.0588048   -0.0164965    0.0319777   -0.0147111    0.185747   -0.00738395  -0.00926247   0.00221729  -0.0127538    0.131278     0.0969605    0.058957      0.135185     0.150445      0.0766374     0.0227998
 -0.0288473   0.0572273   -0.0116941    0.0161215  -0.0660289   0.190997    0.157874     -0.0943613    0.0489395    0.0783072    -0.0835314   -0.0690795    0.0146505    0.132528    -0.0669623   0.0315341    0.0234251    0.0748936    0.0424398    0.183906    -0.0730208    0.0765076    -0.228706     0.175953      0.0433071     0.222358
 -0.0551984   0.0833231   -0.0881665    0.0131983  -0.0605572   0.110441    0.112771     -0.0894315    0.0268015   -0.125476      0.0411141    0.0674981   -0.00146541   0.024778     0.0320932   0.254105     0.120805     0.103565     0.149102     0.0647969    0.0209685   -0.0241727    -0.00766686  -0.0317015     0.0766941    -0.0757323
  0.0290568  -0.0747715    0.00292466  -0.0599174   0.128573   -0.08749     0.0429429     0.0367013    0.0674179    0.0271759    -0.00999144   0.0200858    0.184061     0.0147884   -0.0208383   0.0598543   -0.126797    -0.109008     0.108591    -0.11486      0.00988436  -0.0415047     0.127681     0.06215      -0.0300181     0.152001
 -0.0708476  -0.0536258    0.130572    -0.0493139   0.0773956   0.0611591  -0.0573225    -0.0643319    0.0592727    0.0551227    -0.158691    -0.0166101   -0.057864    -0.00571682  -0.0351094  -0.0147879   -0.0291162   -0.128115    -0.0404356    0.0169162   -0.0515084    0.0896971     0.0168731    0.126213     -0.158836     -0.102375
  0.217262    0.0796605   -0.1308      -0.0820937   0.109676    0.0501594   0.0986677     0.178438     0.0778864   -0.130378     -0.013616     0.103753     0.0436469   -0.0679531   -0.0172824  -0.128321     0.109447    -0.0895397    0.0286247    0.152366    -0.0373212   -0.00145446    0.00189557  -0.0630182     0.119329     -0.015701
  0.0988394   0.10543     -0.0104314   -0.0109269  -0.109846    0.0233095   0.000232902   0.0218151    0.0261656    0.109928      0.0665099    0.0853563   -0.0528471   -0.286714     0.0110716   0.0486047    0.143482    -0.0461464    0.00501096   0.0812559    0.0644342    0.141841     -0.032947    -0.02805       0.000633956  -0.0466899
 -0.116793    0.176842    -0.16633      0.0241178  -0.0765307  -0.229825    0.019425     -0.210029     0.146477    -0.0541988     0.0343182    0.0264314    0.0990125   -0.0272618    0.0565081   0.128471     0.0649164    0.0494332    0.0163463    0.0240117    0.153838    -0.211233      0.0956037   -0.0110572    -0.0769801    -0.0776012
  0.0433972  -0.233117     0.150252     0.0184528   0.109737    0.0852034  -0.135974     -0.0573286   -0.184784     0.0246497     0.174741     0.0647017   -0.00520553   0.0620198    0.0796952   0.0393992    0.0229591    0.0894932   -0.0285712   -0.0496826    0.00825939   0.119962     -0.0317614   -0.0746755    -0.0622277     0.113205
 -0.048957   -0.0411932    0.0746621   -0.0402554   0.118809   -0.0429893   0.0177286     0.0877346   -0.174796    -0.149377     -0.05166     -0.0113017   -0.0163349    0.119678     0.0536812   0.0255587    0.107801     0.0152475   -0.0383287    0.0927442    0.0286843   -0.122813     -0.0878318    0.0919119    -0.0476955    -0.099107
 -0.11042    -0.152694     0.0168811   -0.0911116  -0.0207351   0.0799575   0.0710853    -0.00267425   0.131453     0.000594782   0.112255    -0.0506897    0.0451623    0.0664282    0.0258375   0.0718464   -0.163766     0.030774     0.336751    -0.0145951   -0.0682992    0.0276715     0.101626    -0.0488923    -0.0596528     0.0126761
  0.0592976  -0.0243441   -0.0909237    0.0145841  -0.0281606  -0.0454026  -0.0077028     0.0486523    0.052502     0.168439     -0.00269576  -0.064945     0.0288377   -0.0587825    0.0491091  -0.0403549    0.101283     0.0158532    0.0186082   -0.139705    -0.0848887   -0.107013      0.218472    -0.06757       0.00901413    0.0855864
 -0.0706987   0.132357     0.0694714   -0.0624655   0.136353    0.0340511   0.132677     -0.0205838   -0.0698065    0.102127     -0.0750257    0.05476      0.104126    -0.142498     0.156081    0.0160445    0.147318     0.0762009   -0.135286     0.00841578  -0.0613437   -0.0232704     0.0246625   -0.0964587    -0.0988503    -0.12389
  0.0368272  -0.140766     0.0868034    0.0180166  -0.061836   -0.151618   -0.00671435   -0.0041026   -0.113716     0.125307      0.00601997   0.0940634   -0.192661    -0.0564649   -0.11619    -0.0971595   -0.209675     0.139324     0.00991527  -0.12013      0.0142386   -0.0114872     0.0920532   -0.0719916     0.0177056    -0.106918
 -0.144065    0.0163136   -0.122151    -0.0499087  -0.129487    0.127896    0.0435119     0.0605054    0.132892    -0.008823     -0.0543238    0.0808838   -0.149267     0.0497152    0.111455   -0.104497     0.11406      0.0862368   -0.0114589    0.159334     0.246778     0.0611892    -0.0391493   -0.0307963    -0.150914      0.237855
  0.0230627  -0.0469603   -0.00170197  -0.016766   -0.0849824  -0.17925     0.0367077     0.0572059   -0.147173     0.0623776    -0.0495512    0.0781846    0.0752306   -0.111913     0.136854   -0.0983414    0.0372989   -0.0841822    0.0837225    0.063633     0.0414332    0.0453615     0.0396436    0.000396854  -0.00231679    0.0854632
  0.146114    0.0911325   -0.0230929    0.113446   -0.0316233  -0.222227   -0.0551561     0.0453917    0.0611178   -0.22639       0.0793969   -0.130983    -0.109612    -0.00697524  -0.0806509  -0.249944    -0.196109     0.00277171   0.170166     0.222493     0.239125     0.0427951     0.121001     0.128076      0.0455142    -0.103644
 -0.193794    0.013118    -0.0798652    0.121949   -0.081237   -0.116472   -0.0807209    -0.0277353   -0.0714349   -0.0830954     0.164264    -0.0889287   -0.0527575   -0.187569    -0.023317   -0.0202864   -0.0963037   -0.142451    -0.09665     -0.0307061    0.00465877   0.0841281    -0.181128     0.021281      0.0101556    -0.0285213
 -0.0730246   0.109517    -0.136365     0.0251952  -0.0091947  -0.191044   -0.0286084     0.0935295   -0.0152367    0.244676     -0.161076     0.0314689   -0.0714829   -0.0584709    0.13626     0.277958    -0.126821    -0.103188    -0.0648159    0.0628587    0.106818    -0.0539129     0.100098    -0.202575      0.0445437     0.0560985
 -0.0591536   0.0494901   -0.0388439    0.0466715  -0.0794011  -0.0615262   0.124561     -0.170739     0.0124069    0.00728198   -0.147238    -0.00619353   0.166411     0.054738     0.0505164   0.0117055   -0.0920672    0.15239      0.00483295   0.170317     0.00669326  -0.0222094     0.149041    -0.0645203     0.0692757    -0.0644241
  0.012762    0.0650607    0.0234262    0.027981    0.0289778   0.137779   -0.0849326    -0.0273525   -0.0167219    0.0749776    -0.069914    -0.0189238   -0.0771604   -0.0257104   -0.131217   -0.138318    -0.0796512   -0.0865743   -0.0447401    0.14925     -0.0733122    0.138721      0.00787192  -0.133753      0.0352188     0.0787287
  0.048461    0.189932     0.0243313    0.0350849  -0.130321   -0.0354952  -0.0742514     0.0855005   -0.0819155   -0.016433     -0.00923333  -0.0756565    0.07933      0.118145     0.140465    0.032018     0.0907161    0.00221402   0.0556358   -0.140404     0.0409711    0.119214      0.130132     0.0646992     0.0358071    -0.0015023
  0.0607362   0.1288      -0.187848    -0.0753962   0.101551    0.0109628   0.345901     -0.0805873   -0.0338655    0.0580075    -0.104429     0.0119363   -0.247419     0.0359803   -0.0832967  -0.0973154   -0.130122     0.0144275   -0.0234431   -0.0358653    0.118809    -0.109974      0.0583538    0.0653279    -0.0453921    -0.020032
  0.0463501   0.0248159    0.0305109   -0.250504   -0.101698    0.0441186   0.0118526    -0.11051      0.030044     0.115098      0.0435948   -0.118358     0.0241013    0.0169463    0.0531579  -0.0889084    0.0290462   -0.101146     0.0433882   -0.00223621  -0.0705345   -0.172603      0.0457864   -0.111502     -0.10482      -0.0825047kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4247800670007877
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.424832
[ Info: iteration 2, average log likelihood -1.424775
[ Info: iteration 3, average log likelihood -1.424449
[ Info: iteration 4, average log likelihood -1.420124
[ Info: iteration 5, average log likelihood -1.403023
[ Info: iteration 6, average log likelihood -1.389546
[ Info: iteration 7, average log likelihood -1.385140
[ Info: iteration 8, average log likelihood -1.383715
[ Info: iteration 9, average log likelihood -1.383215
[ Info: iteration 10, average log likelihood -1.383014
[ Info: iteration 11, average log likelihood -1.382914
[ Info: iteration 12, average log likelihood -1.382852
[ Info: iteration 13, average log likelihood -1.382804
[ Info: iteration 14, average log likelihood -1.382765
[ Info: iteration 15, average log likelihood -1.382731
[ Info: iteration 16, average log likelihood -1.382703
[ Info: iteration 17, average log likelihood -1.382679
[ Info: iteration 18, average log likelihood -1.382660
[ Info: iteration 19, average log likelihood -1.382645
[ Info: iteration 20, average log likelihood -1.382633
[ Info: iteration 21, average log likelihood -1.382623
[ Info: iteration 22, average log likelihood -1.382616
[ Info: iteration 23, average log likelihood -1.382610
[ Info: iteration 24, average log likelihood -1.382605
[ Info: iteration 25, average log likelihood -1.382601
[ Info: iteration 26, average log likelihood -1.382598
[ Info: iteration 27, average log likelihood -1.382596
[ Info: iteration 28, average log likelihood -1.382594
[ Info: iteration 29, average log likelihood -1.382593
[ Info: iteration 30, average log likelihood -1.382592
[ Info: iteration 31, average log likelihood -1.382591
[ Info: iteration 32, average log likelihood -1.382591
[ Info: iteration 33, average log likelihood -1.382591
[ Info: iteration 34, average log likelihood -1.382590
[ Info: iteration 35, average log likelihood -1.382590
[ Info: iteration 36, average log likelihood -1.382590
[ Info: iteration 37, average log likelihood -1.382590
[ Info: iteration 38, average log likelihood -1.382590
[ Info: iteration 39, average log likelihood -1.382590
[ Info: iteration 40, average log likelihood -1.382590
[ Info: iteration 41, average log likelihood -1.382590
[ Info: iteration 42, average log likelihood -1.382590
[ Info: iteration 43, average log likelihood -1.382590
[ Info: iteration 44, average log likelihood -1.382590
[ Info: iteration 45, average log likelihood -1.382590
[ Info: iteration 46, average log likelihood -1.382589
[ Info: iteration 47, average log likelihood -1.382589
[ Info: iteration 48, average log likelihood -1.382589
[ Info: iteration 49, average log likelihood -1.382589
[ Info: iteration 50, average log likelihood -1.382589
┌ Info: EM with 100000 data points 50 iterations avll -1.382589
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.424831519532434
│     -1.4247752751757554
│      ⋮
└     -1.3825894851701104
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.382696
[ Info: iteration 2, average log likelihood -1.382605
[ Info: iteration 3, average log likelihood -1.382313
[ Info: iteration 4, average log likelihood -1.379005
[ Info: iteration 5, average log likelihood -1.366382
[ Info: iteration 6, average log likelihood -1.354670
[ Info: iteration 7, average log likelihood -1.349831
[ Info: iteration 8, average log likelihood -1.347146
[ Info: iteration 9, average log likelihood -1.344987
[ Info: iteration 10, average log likelihood -1.343444
[ Info: iteration 11, average log likelihood -1.342526
[ Info: iteration 12, average log likelihood -1.342014
[ Info: iteration 13, average log likelihood -1.341713
[ Info: iteration 14, average log likelihood -1.341525
[ Info: iteration 15, average log likelihood -1.341402
[ Info: iteration 16, average log likelihood -1.341318
[ Info: iteration 17, average log likelihood -1.341256
[ Info: iteration 18, average log likelihood -1.341211
[ Info: iteration 19, average log likelihood -1.341179
[ Info: iteration 20, average log likelihood -1.341154
[ Info: iteration 21, average log likelihood -1.341134
[ Info: iteration 22, average log likelihood -1.341117
[ Info: iteration 23, average log likelihood -1.341102
[ Info: iteration 24, average log likelihood -1.341089
[ Info: iteration 25, average log likelihood -1.341077
[ Info: iteration 26, average log likelihood -1.341067
[ Info: iteration 27, average log likelihood -1.341057
[ Info: iteration 28, average log likelihood -1.341047
[ Info: iteration 29, average log likelihood -1.341039
[ Info: iteration 30, average log likelihood -1.341030
[ Info: iteration 31, average log likelihood -1.341021
[ Info: iteration 32, average log likelihood -1.341013
[ Info: iteration 33, average log likelihood -1.341005
[ Info: iteration 34, average log likelihood -1.340996
[ Info: iteration 35, average log likelihood -1.340987
[ Info: iteration 36, average log likelihood -1.340977
[ Info: iteration 37, average log likelihood -1.340967
[ Info: iteration 38, average log likelihood -1.340957
[ Info: iteration 39, average log likelihood -1.340946
[ Info: iteration 40, average log likelihood -1.340936
[ Info: iteration 41, average log likelihood -1.340927
[ Info: iteration 42, average log likelihood -1.340918
[ Info: iteration 43, average log likelihood -1.340911
[ Info: iteration 44, average log likelihood -1.340905
[ Info: iteration 45, average log likelihood -1.340901
[ Info: iteration 46, average log likelihood -1.340896
[ Info: iteration 47, average log likelihood -1.340893
[ Info: iteration 48, average log likelihood -1.340890
[ Info: iteration 49, average log likelihood -1.340888
[ Info: iteration 50, average log likelihood -1.340886
┌ Info: EM with 100000 data points 50 iterations avll -1.340886
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3826955933045353
│     -1.3826048503000898
│      ⋮
└     -1.3408857863472325
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.341010
[ Info: iteration 2, average log likelihood -1.340871
[ Info: iteration 3, average log likelihood -1.340366
[ Info: iteration 4, average log likelihood -1.335400
[ Info: iteration 5, average log likelihood -1.319468
[ Info: iteration 6, average log likelihood -1.307597
[ Info: iteration 7, average log likelihood -1.302056
[ Info: iteration 8, average log likelihood -1.298609
[ Info: iteration 9, average log likelihood -1.296062
[ Info: iteration 10, average log likelihood -1.293902
[ Info: iteration 11, average log likelihood -1.292036
[ Info: iteration 12, average log likelihood -1.290554
[ Info: iteration 13, average log likelihood -1.289490
[ Info: iteration 14, average log likelihood -1.288679
[ Info: iteration 15, average log likelihood -1.287990
[ Info: iteration 16, average log likelihood -1.287418
[ Info: iteration 17, average log likelihood -1.286997
[ Info: iteration 18, average log likelihood -1.286691
[ Info: iteration 19, average log likelihood -1.286433
[ Info: iteration 20, average log likelihood -1.286188
[ Info: iteration 21, average log likelihood -1.285969
[ Info: iteration 22, average log likelihood -1.285796
[ Info: iteration 23, average log likelihood -1.285676
[ Info: iteration 24, average log likelihood -1.285597
[ Info: iteration 25, average log likelihood -1.285543
[ Info: iteration 26, average log likelihood -1.285506
[ Info: iteration 27, average log likelihood -1.285478
[ Info: iteration 28, average log likelihood -1.285457
[ Info: iteration 29, average log likelihood -1.285440
[ Info: iteration 30, average log likelihood -1.285427
[ Info: iteration 31, average log likelihood -1.285415
[ Info: iteration 32, average log likelihood -1.285406
[ Info: iteration 33, average log likelihood -1.285398
[ Info: iteration 34, average log likelihood -1.285392
[ Info: iteration 35, average log likelihood -1.285386
[ Info: iteration 36, average log likelihood -1.285381
[ Info: iteration 37, average log likelihood -1.285376
[ Info: iteration 38, average log likelihood -1.285372
[ Info: iteration 39, average log likelihood -1.285369
[ Info: iteration 40, average log likelihood -1.285365
[ Info: iteration 41, average log likelihood -1.285362
[ Info: iteration 42, average log likelihood -1.285359
[ Info: iteration 43, average log likelihood -1.285356
[ Info: iteration 44, average log likelihood -1.285353
[ Info: iteration 45, average log likelihood -1.285350
[ Info: iteration 46, average log likelihood -1.285347
[ Info: iteration 47, average log likelihood -1.285344
[ Info: iteration 48, average log likelihood -1.285341
[ Info: iteration 49, average log likelihood -1.285338
[ Info: iteration 50, average log likelihood -1.285335
┌ Info: EM with 100000 data points 50 iterations avll -1.285335
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3410095502284276
│     -1.340870840610222
│      ⋮
└     -1.2853350240807948
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.285514
[ Info: iteration 2, average log likelihood -1.285291
[ Info: iteration 3, average log likelihood -1.284039
[ Info: iteration 4, average log likelihood -1.272444
[ Info: iteration 5, average log likelihood -1.245255
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.216124
[ Info: iteration 7, average log likelihood -1.218090
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.195130
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.194766
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.205023
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.202242
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.198544
[ Info: iteration 13, average log likelihood -1.205205
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.187081
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.189516
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.184173
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.205180
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.200033
[ Info: iteration 19, average log likelihood -1.204950
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.185229
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.186976
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.180462
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.200818
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.195379
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.199578
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.189562
[ Info: iteration 27, average log likelihood -1.188193
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.173553
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.196547
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.199589
[ Info: iteration 31, average log likelihood -1.202233
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.182880
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.185055
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.179179
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.199335
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.193933
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.199829
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.188685
[ Info: iteration 39, average log likelihood -1.187908
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.173800
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.196863
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.199355
[ Info: iteration 43, average log likelihood -1.202387
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.183092
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.185256
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.179095
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.199405
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.194093
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.199989
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.188636
┌ Info: EM with 100000 data points 50 iterations avll -1.188636
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.285514035486199
│     -1.2852905541712256
│      ⋮
└     -1.1886355187826252
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.188215
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.173725
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.180316
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│     12
│     15
│     16
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.153478
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.123052
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.084516
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     17
│     18
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.116083
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.098149
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     14
│     17
│     21
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.096696
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│     13
│     15
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.087944
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.110036
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│      ⋮
│     16
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.081814
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     13
│     17
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.103805
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.095227
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     14
│     18
│     21
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.093535
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│     13
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.090646
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     18
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.107573
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.082522
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     13
│     18
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.098314
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.088815
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     18
│     21
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.093640
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.076261
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     18
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.103135
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.087662
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     14
│     18
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.092420
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│     13
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.077424
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     14
│     18
│     21
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.097612
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.087496
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     13
│     14
│     18
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.083250
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.090405
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     18
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.104588
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.076726
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     13
│     18
│     21
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.087576
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.091504
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     18
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.094781
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│      ⋮
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.070317
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     18
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.107565
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.088671
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     14
│     18
│     21
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.086986
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│     13
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.081240
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     14
│     18
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.098954
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.081592
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     13
│     14
│     18
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.087530
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.091533
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     18
│     21
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.099185
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.080604
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     13
│     18
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.088797
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│     14
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.085808
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     18
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.099052
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.071561
┌ Info: EM with 100000 data points 50 iterations avll -1.071561
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1882148278466447
│     -1.1737254150599163
│      ⋮
└     -1.0715605717657637
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4247800670007877
│     -1.424831519532434
│     -1.4247752751757554
│     -1.4244492944194616
│      ⋮
│     -1.085808401463848
│     -1.0990517241873978
└     -1.0715605717657637
32×26 Array{Float64,2}:
  0.148995     0.0769727   -0.017759      0.109176     -0.0314901  -0.234326   -0.0584404    0.044772     0.0746181   -0.129872     0.0495286   -0.127813    -0.107496      0.00281095  -0.0956581   -0.244561    -0.175126     0.00756538   0.162621     0.223393     0.257746    0.0610707    0.118293     0.147806     0.0213857   -0.103218
  0.0624395   -0.00197192  -0.0486534    -0.0584813    -0.0138855   0.0993631   0.00726055   0.0491339   -0.090618    -0.033296     0.129824    -0.0236868   -0.000418564  -0.0804243   -0.0449528   -0.0682482    0.035934     0.0999322    0.01414     -0.0335225   -0.0718799   0.0455227   -0.0447568    0.0376305   -0.0615936   -0.0840356
  0.120677    -0.0297566    0.127947      1.34512       0.121423    0.113786   -0.0629777   -2.29199     -0.00717932  -1.1723      -0.155188    -0.0198734    0.209239      0.00651937   0.136289     0.00808472  -0.396847    -0.213706    -0.00753933  -0.0348577    0.514054    0.147796    -0.172282    -0.123881     0.00435709  -0.0460429
 -0.0693912   -0.0589287    0.130879     -0.0626672     0.0752132   0.0254126  -0.0569704   -0.04052      0.0560003    0.0876814   -0.158062    -0.0217049   -0.046341     -0.0086724   -0.0497167   -0.0195861    0.00957585  -0.113775    -0.0348521    0.0222923   -0.0920524   0.0882319    0.00909181   0.1282      -0.186092    -0.106865
 -0.0770299   -0.069022    -0.126937     -0.0583357    -0.0840115  -0.178642    0.0262939    0.0725294   -0.151894     0.110886    -0.0469499    0.0746382    0.0968376    -0.0823203    0.137364    -0.0986481    0.344982    -0.0811105    0.168234     0.0490972    0.0377229   0.0432265    0.0419084   -0.00173787   0.0593189    0.0819021
  0.100196    -0.0512466    0.38532       0.019991     -0.0915461  -0.180337    0.0850201   -0.0209721   -0.117527     0.0555244   -0.0363169    0.0803145    0.0783826    -0.14926      0.13683     -0.0981008   -0.456777    -0.0881694   -0.0679471    0.0369193    0.049761    0.0476383    0.0564985    0.00131897  -0.0104155    0.12423
 -0.04292      0.0829448   -0.0555859    -0.474534     -0.0136093   0.187216    0.157116    -0.0799261    0.0654191   -0.0472276    0.0444964    0.021755     0.0765131    -0.0313661   -0.0963997    0.0660794    0.0289212    0.0752263    0.0148297    0.440434    -0.0591467   0.0735251   -0.22637      0.161176     0.062824     0.378055
 -0.00780998   0.00135668   0.0356082     0.359298     -0.15437     0.194668    0.159154    -0.130079     0.0452982    0.20833     -0.114934    -0.105766    -0.00982667    0.218905    -0.0677475    0.0240582    0.0231724    0.0686179    0.0812956   -0.102354    -0.0852576   0.0752415   -0.24648      0.182547     0.00262742   0.0910955
  0.0433679   -0.0200105    0.039971     -0.0160608     0.0378261  -0.0533861  -0.0106749   -0.00670772  -0.0752346   -0.0234979    0.00262876  -0.102572     0.0467508     0.00453099   0.00565117   0.0872527   -0.0275771   -0.00311141  -0.00704649  -0.0296806   -0.0304743  -0.00125685  -0.026824     0.0350544   -0.00622183  -0.0108695
  0.112137     0.106948    -0.0373122    -0.0619085    -0.137557   -0.0401932   0.104644     0.0706169    0.0677178    0.0878895    0.15801      0.0243379   -0.0187979    -0.118123    -0.0563599    0.0850673    0.185129    -0.0505943   -0.0871739    0.108734    -0.0216265   0.18284      0.00853658   0.012299     0.0501245   -0.00715133
 -0.0480799    0.135626     0.0634928    -0.0876447     0.108719    0.0423504   0.133311    -0.00295065  -0.0328285    0.0671145   -0.0752491    0.0561374    0.093781     -0.140476     0.162681    -0.00343286   0.144093     0.0730856   -0.148129     0.00473431  -0.0519195  -0.0301744    0.0504939   -0.0989282   -0.0857365   -0.123487
 -0.109485    -0.159513     0.0266386    -0.0942656    -0.0247736   0.101394    0.0711266   -0.0269335    0.133165     0.0120435    0.103988    -0.050442     0.0442589     0.0642778    0.0263578    0.0716771   -0.155151     0.0271683    0.317874    -0.00459245  -0.0677181   0.0501475    0.0680553   -0.0492055   -0.0462532    0.0270494
  0.0666843    0.135476    -0.189236     -0.0720592     0.0995506   0.050055    0.333511    -0.0806916   -0.0343082    0.060916    -0.0925246   -0.0131979   -0.25128       0.0358766   -0.0315469   -0.0882554   -0.129729     0.00636274   0.0103791    0.00674598   0.15217    -0.0554806    0.0570786    0.0589627   -0.0461939   -0.0160624
 -0.105425     0.141101    -0.169861      0.0168128    -0.0855891  -0.187366    0.0107961   -0.206256     0.162426    -0.0534632    0.0356883    0.00198679   0.0734782     0.0128036    0.0323866    0.0647749    0.112906     0.0491763    0.01291     -0.0184269    0.153475   -0.219774     0.113111    -0.0183543   -0.0732241   -0.0770735
  0.0303495   -0.57178     -0.108926      0.0460577     0.0297137   0.140925   -0.192742     0.00185896   0.00163591  -0.0872915    0.0740786   -0.0160043    0.4119       -0.0153968    0.172564    -0.0184826   -0.0103757   -0.0380465    0.140002     0.130115     0.114305    0.037309     0.163635     0.0527678   -0.00714486   0.0409967
  0.0112921    0.629693    -0.0489451     0.17662       0.0350078   0.131669   -0.0684705    0.0770029    0.00163604   0.0267176    0.0672377   -0.0165378   -0.305408     -0.0152239    0.20147     -0.0028493   -0.0100491    0.0354973   -0.12712      0.128439     0.0742985   0.0737124    0.123578     0.129122     0.118098     0.010707
  0.0428735   -0.127303     0.0872631     0.00415532   -0.0779691  -0.151498    0.00955346  -0.00587022  -0.11749      0.147476     0.00290389   0.079855    -0.226514     -0.0673523   -0.121843    -0.114663    -0.2107       0.135629     0.035708    -0.13153     -0.0019514  -0.00138747   0.0927466   -0.0471892    0.0204318   -0.0931098
  0.0510756    0.0361908    0.0264567    -0.240827     -0.0987537   0.0700134   0.0487439   -0.11066      0.043701     0.142067     0.0511712   -0.0424285    0.0245178     0.00716551   0.0538931   -0.075448     0.0186152   -0.0788105    0.0587194   -0.00245284  -0.0581424  -0.167453     0.0495511   -0.119601    -0.0860651   -0.013072
 -0.147772    -0.0384535    0.224272     -0.129098     -0.127483   -0.0505541   0.0795359    0.0161367   -0.0179663   -0.0388834   -0.0228806    0.0879886   -0.0116867     0.0298414    0.0571363   -0.0135515   -0.963544    -0.00649513   0.0210717    0.0924202    0.0566624   0.0430072    0.0234318    0.0176115   -0.077517    -0.0867448
 -0.113262    -0.110963    -0.017712     -0.00708969   -0.0945025  -0.0583069   0.0745515    0.00103385  -0.0259726   -0.0421697   -0.0301409    0.0568111    0.0205882     0.116253     0.0637041    0.147051     1.04784      0.0174221   -0.0297863    0.102619     0.0597664   0.0628604    0.0589413    0.0237773   -0.079726     0.00383008
 -0.548319     0.0258179   -0.103818      0.0148654    -0.0613957   0.0925079   0.0942776   -0.139538     0.0210169   -0.107319     0.0555699   -1.04159     -0.0353665     0.00408931   0.0811681    0.238356     0.107183     0.0183119    0.137747     0.0770305    0.0444539   0.0453503   -0.0241985   -0.147816     0.250069     0.0438509
  0.376692     0.119487    -0.0214198     0.0141963    -0.0199326   0.103201    0.10623     -0.0267626   -0.00750548  -0.107793     0.0370183    0.935104     0.00148124    0.0510822   -0.0597041    0.253308     0.110778     0.198024     0.113426     0.0362852    0.0223113   0.0450943   -0.0186516    0.0220166   -0.117418    -0.151052
 -0.0225321   -0.0462676    0.000468782   0.0196304     0.0261417  -0.0505522  -0.0762514    0.0396916   -0.0833749    0.143699    -0.013673     0.0423431   -0.0409418     0.00537752   0.105655     0.159194    -0.0503854    0.00616444  -0.0551867    0.0102292    0.0708112   0.0477006    0.0408652   -0.157257    -0.00600839   0.0815536
 -0.0380258   -0.0387744   -0.079716      0.0331655     0.108845   -0.198289   -0.0418552    0.114495     0.0904665   -0.0422224    0.0911535    0.155642     0.0665356     0.0351911   -0.00630831  -0.0276954    0.0977644    0.171853    -0.022185    -0.0673246   -0.0842162   0.0201467    0.038549    -0.0623808    0.134518    -0.0560925
 -0.0745331    0.0479432   -0.0303952     0.0471751    -0.0780421  -0.0558315   0.12523     -0.181999     0.0121812   -0.00204195  -0.177595    -0.00434277   0.16821       0.0566432    0.0652149    0.0222222   -0.0921104    0.162446     0.0050905    0.166458     0.0140001  -0.0247852    0.149368    -0.0649132    0.0691411   -0.0372853
 -0.122842    -0.15806     -0.135393     -0.106762      0.038674   -0.11765     0.0545605    0.0469426    0.0404364   -0.05791     -0.0950992    0.0297954   -0.0257157    -0.0325806   -0.116781    -0.026595     0.173951    -0.0751669    0.0626069   -0.0627348   -0.0284687   0.0453612   -0.0568783    0.0555037   -0.0617544    0.0588711
 -0.0997596   -0.0305517   -0.0199571    -0.0183366    -0.0844888  -0.0408681   0.07336     -0.0734908   -0.0753976    0.129057     0.0554057   -0.104684     0.0159367    -0.155395     0.0684965   -0.0281974    0.00572956  -0.0487562   -0.00406841   0.0128582    0.0563311   0.0524693   -0.00836565  -0.0684551    0.00722662  -0.0487994
 -0.0694139    0.0446145   -0.0227865    -0.000800955  -0.0643465   0.125517   -0.0288288    0.0214579    0.00448004   0.0471808   -0.0468484    0.0272288   -0.100867     -0.0160688   -0.00103539  -0.116719     0.0227597   -0.0152431   -0.0297257    0.153888     0.0947666   0.106508    -0.005507    -0.0888483   -0.0375671    0.176249
  0.200183     0.0764873   -0.117579     -0.0896783     0.109142    0.0557986   0.0940787    0.187639     0.0695321   -0.109792    -0.0323354    0.0931574    0.0438651    -0.0566925   -0.0161893   -0.149052     0.102306    -0.0865371    0.0370513    0.147968    -0.019821    0.00447427   0.00420464  -0.0667692    0.077841     0.00532275
  0.106322     0.188965     0.0218408     0.022657     -0.13798    -0.0282737  -0.0672686    0.0832557   -0.0818818    0.00111909  -0.0400334   -0.0625358    0.0746767     0.123169     0.137757     0.0242018    0.0943994   -0.00320748   0.0528094   -0.138464     0.0438754   0.0869669    0.161135     0.060672     0.044354     0.00244251
  0.1082      -0.0455687   -0.0773336     0.00975069   -0.034849   -0.11487    -0.0502362   -0.0718768    0.0590453    0.173485    -0.0639413   -0.569337     0.044259      0.244569     0.0673536   -0.0288749    0.0795589   -0.0214793    0.0706788   -0.133267    -0.0431164  -0.112108     0.257566     0.250681     0.0877462    0.168724
  0.022753    -0.0102403   -0.0931681    -0.0192197    -0.0192704  -0.0947157   0.00826883   0.121163     0.0337685    0.105834     0.0877886    0.489297     0.0146785    -0.228271     0.0457021   -0.0852415    0.0974875    0.0417537   -0.0464514   -0.14265     -0.117915   -0.0721093    0.176108    -0.275727    -0.220632    -0.0307176[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     18
│     21
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.102096
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│      ⋮
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.078159
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     14
│     18
│     21
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.086822
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│      ⋮
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.066559
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     14
│     18
│     21
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.097466
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│      ⋮
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.072523
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     13
│     14
│     18
│     21
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.081556
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│      ⋮
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.081265
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     18
│     21
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.098375
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│      ⋮
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.066316
┌ Info: EM with 100000 data points 10 iterations avll -1.066316
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.428966e+05
      1       7.066379e+05      -1.362587e+05 |       32
      2       6.754707e+05      -3.116717e+04 |       32
      3       6.601298e+05      -1.534096e+04 |       32
      4       6.473596e+05      -1.277019e+04 |       32
      5       6.383351e+05      -9.024428e+03 |       32
      6       6.330125e+05      -5.322632e+03 |       32
      7       6.300540e+05      -2.958474e+03 |       32
      8       6.285356e+05      -1.518413e+03 |       32
      9       6.277051e+05      -8.305016e+02 |       32
     10       6.273004e+05      -4.047621e+02 |       32
     11       6.270914e+05      -2.089587e+02 |       32
     12       6.269466e+05      -1.448429e+02 |       32
     13       6.267951e+05      -1.514716e+02 |       32
     14       6.266157e+05      -1.793561e+02 |       32
     15       6.264200e+05      -1.957428e+02 |       32
     16       6.262546e+05      -1.653783e+02 |       31
     17       6.261502e+05      -1.044066e+02 |       32
     18       6.260814e+05      -6.885284e+01 |       31
     19       6.260240e+05      -5.738111e+01 |       32
     20       6.259717e+05      -5.224343e+01 |       32
     21       6.259162e+05      -5.552215e+01 |       32
     22       6.258473e+05      -6.892763e+01 |       32
     23       6.257647e+05      -8.255722e+01 |       32
     24       6.256662e+05      -9.849655e+01 |       32
     25       6.255379e+05      -1.283486e+02 |       32
     26       6.254003e+05      -1.375332e+02 |       32
     27       6.252598e+05      -1.405079e+02 |       32
     28       6.251137e+05      -1.461177e+02 |       32
     29       6.249985e+05      -1.152625e+02 |       32
     30       6.249307e+05      -6.777726e+01 |       31
     31       6.248341e+05      -9.653031e+01 |       30
     32       6.246499e+05      -1.842669e+02 |       32
     33       6.243149e+05      -3.350160e+02 |       32
     34       6.236357e+05      -6.791517e+02 |       32
     35       6.227057e+05      -9.299691e+02 |       32
     36       6.218339e+05      -8.718163e+02 |       32
     37       6.214219e+05      -4.119789e+02 |       32
     38       6.212939e+05      -1.280763e+02 |       31
     39       6.212551e+05      -3.878446e+01 |       31
     40       6.212409e+05      -1.415957e+01 |       29
     41       6.212349e+05      -6.027780e+00 |       22
     42       6.212330e+05      -1.889627e+00 |       19
     43       6.212322e+05      -8.402307e-01 |       16
     44       6.212316e+05      -5.646757e-01 |       12
     45       6.212313e+05      -3.115175e-01 |        4
     46       6.212312e+05      -9.924530e-02 |        4
     47       6.212310e+05      -1.591757e-01 |        7
     48       6.212309e+05      -1.689209e-01 |        5
     49       6.212307e+05      -1.405876e-01 |        2
     50       6.212307e+05      -7.169496e-02 |        0
K-means terminated without convergence after 50 iterations (objv = 621230.6558185369)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.341448
[ Info: iteration 2, average log likelihood -1.308682
[ Info: iteration 3, average log likelihood -1.270853
[ Info: iteration 4, average log likelihood -1.226389
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.178785
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.138128
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     21
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.104772
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.106333
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     11
│     15
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.076335
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     17
│     19
│     21
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.091413
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     13
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.123681
[ Info: iteration 12, average log likelihood -1.110328
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     26
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.057578
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     11
│     17
│     19
│     21
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.074840
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.152754
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.095616
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     15
│     21
│     22
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.058977
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     19
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.109457
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.116151
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.092070
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     13
│     15
│     21
│     26
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.062760
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     19
│     22
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.109952
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.120562
[ Info: iteration 24, average log likelihood -1.108837
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     21
│     26
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.057368
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     13
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.101555
[ Info: iteration 27, average log likelihood -1.126928
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     11
│     21
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.062674
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     10
│     15
│     17
│      ⋮
│     28
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.061083
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.147725
[ Info: iteration 31, average log likelihood -1.120418
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     21
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.063584
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     10
│     15
│     17
│     19
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.070664
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     13
│     22
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.101702
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     21
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.110738
[ Info: iteration 36, average log likelihood -1.124223
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     15
│     19
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.066962
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     17
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.096530
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     13
│     21
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.087317
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.103797
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     15
│     19
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.053789
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.109679
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     13
│     17
│     18
│     21
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.100203
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     15
│     19
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.101638
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.118015
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     17
│     22
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.078914
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     21
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.088064
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      9
│     13
│     15
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.100476
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.110599
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     10
│     11
│     19
│     21
│     28
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.062782
┌ Info: EM with 100000 data points 50 iterations avll -1.062782
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.131151   -0.0728073     0.109716    -0.0714864   -0.111841    -0.0539881   0.0771318    0.00904185  -0.0230044   -0.0403375  -0.0269157     0.0724257     0.0039087    0.0702648    0.0603421    0.0618483   -0.0171386     0.00437641   -0.00144093   0.09727      0.0580291    0.0520549     0.0404735     0.0203875    -0.0785472   -0.0444696
 -0.128575   -0.116883     -0.1499      -0.0985801   -0.00356732  -0.0595132   0.0525351    0.0496453    0.0766177   -0.0447382  -0.0891575     0.0436291    -0.0529396    0.0102905   -0.0713439   -0.0559542    0.17244      -0.0344194     0.0430374   -0.00380996   0.0439121    0.0531146    -0.0604804     0.0295215    -0.0863716    0.108979
  0.0211546  -0.194502      0.125064     0.0142166    0.130354     0.0921173  -0.129815    -0.0322508   -0.188876     0.0326794   0.143488      0.061838     -0.00730654   0.047984     0.0688463    0.0510275    0.018106      0.100923     -0.040503    -0.0474683   -0.00675696   0.121224     -0.00196508   -0.111477     -0.065103     0.112229
 -0.0758601   0.0820975    -0.0783669    0.0363617   -0.0775698   -0.117543    0.053243    -0.0522881    0.010101     0.116036   -0.186488      0.0111367     0.0550099    0.0155971    0.100698     0.14143     -0.104783      0.0425993    -0.0267236    0.119663     0.0789363   -0.022564      0.121591     -0.127218      0.0632395    0.00612046
  0.0419685  -0.000581129  -0.00419002   0.110545    -0.0252027    0.0750168  -0.162746     0.0857074   -0.0297564    0.137842    0.120872      0.0243459     0.0519671    0.0806686   -0.0285027   -0.111094    -0.0246367     0.236124      0.034106     0.177941    -0.159861    -0.0196293    -0.263976     -0.105733     -0.0725188   -0.11828
  0.0384601  -0.126946      0.0871732    0.00971043  -0.0815117   -0.149607   -0.00266937  -0.00602499  -0.127992     0.151251    0.00417083    0.0844126    -0.221647    -0.0681658   -0.121527    -0.118714    -0.216085      0.137477      0.0311986   -0.131579    -0.0039021    0.000451089   0.0926913    -0.0518476     0.0266241   -0.0974623
 -0.023518    0.0385976    -0.00570669  -0.0189265   -0.0924543    0.191286    0.158246    -0.107922     0.0543156    0.0915861  -0.0434185    -0.0469952     0.0290422    0.104804    -0.0813817    0.0431275    0.0256367     0.0716321     0.0521705    0.143665    -0.0735002    0.0745189    -0.236468      0.173529      0.0294114    0.220443
  0.157027    0.131218     -0.0446151   -0.0392876   -0.0107995    0.0141881   0.0157871    0.140733    -0.00948831  -0.0570272  -0.0378323     0.0182847     0.0580279    0.030256     0.0637314   -0.0641369    0.0986589    -0.0470678     0.0448709    0.0117388    0.0120284    0.043248      0.0798369    -0.00605132    0.0613371    0.00337272
  0.0632103   0.134046     -0.187348    -0.0687881    0.0987772    0.0454026   0.324015    -0.0776575   -0.0345308    0.0624671  -0.0926116    -0.0155322    -0.25077      0.035989    -0.0357769   -0.0873806   -0.128472      0.00102052    0.00948638  -0.00176986   0.144353    -0.0485984     0.0548697     0.0569467    -0.0440114   -0.0118461
  0.102378    0.106056     -0.050625    -0.0985506   -0.168241    -0.076915    0.166281     0.07687      0.0798108    0.0917919   0.220592      0.00594183   -0.00140893  -0.0245476   -0.0950788    0.120844     0.176974     -0.0576079    -0.127724     0.104018    -0.0686052    0.205567      0.0172455     0.0348022     0.066902     0.0181849
 -0.0650908  -0.0581482     0.130921    -0.0285749    0.0763212    0.026979   -0.0570504   -0.0961606    0.0548145    0.0566019  -0.157978     -0.021389     -0.0406694   -0.00815111  -0.0456191   -0.0187628   -0.000128734  -0.115631     -0.0340822    0.0211558   -0.0773688    0.089992      0.00440124    0.122032     -0.180915    -0.105576
  0.0500714  -0.00649578   -0.170187     0.107681     0.200087     0.15338    -0.175065     0.100299    -0.148965    -0.0339859   0.232226     -0.0861338     0.0845327   -0.0294974   -0.0792608   -0.109851     0.0855713     0.227812     -0.0446914    0.0200699   -0.263317     0.157346     -0.134031     -0.0475768    -0.0753791   -0.106424
 -0.0633953   0.0453555    -0.0499368    0.00917486  -0.0849224    0.126023   -0.0369376    0.0321308    0.0255934    0.0256262  -0.0535041     0.0343076    -0.188199     0.0357446    0.178998    -0.149886     0.00388552   -0.00718736   -0.0665091    0.148209     0.0741755    0.0995952     0.0152997    -0.0521535    -0.282627     0.311376
 -0.0391621  -0.042453      0.0687967   -0.0383722    0.11763     -0.0482504   0.0312229    0.0744956   -0.143207    -0.132263   -0.0517208    -0.0124837    -0.0107773    0.123875     0.0529007    0.0376543    0.0970888     0.0121284    -0.0566584    0.0401311    0.0265917   -0.141733     -0.0710833     0.10053      -0.0328562   -0.100055
  0.0292236  -0.046917      0.0442301   -0.106135    -0.0670584    0.0190728   0.165742    -0.104014    -0.0870009    0.288571   -0.0221343    -0.0818461     0.0819655   -0.0895069    0.123605    -0.0594295    0.0641677     0.0481328     0.0768716    0.081675     0.0733991    0.0252909     0.110925     -0.167153      0.00686489  -0.0359247
  0.148964    0.076587     -0.0173779    0.108912    -0.0314099   -0.234403   -0.0581035    0.044832     0.075991    -0.128741    0.0495521    -0.127        -0.107749     0.00330041  -0.0952154   -0.244511    -0.175723      0.00771556    0.1633       0.222615     0.258112     0.0616043     0.117914      0.148139      0.0224886   -0.103273
  0.0439326   0.089661     -0.0100529   -0.00572815  -0.115997     0.0434637   0.0302161    0.0372221    0.0189926    0.0801089   0.0401337     0.0833215    -0.0618731   -0.263399     0.0281913   -0.0123548    0.140357     -0.0258375     0.00824182   0.128506     0.115256     0.110285      0.00694589   -0.0402158     0.00652858   0.00949853
  0.0409631  -0.0996431    -0.0097246   -0.0703481    0.100278    -0.0905995   0.0493714    0.0585258    0.129389     0.0212231  -0.000118444  -0.0155185     0.256885    -0.015952    -0.0360211    0.0490751   -0.133054     -0.108348      0.112666    -0.111413     0.0130699   -0.0277054     0.142108      0.063358     -0.039625     0.157117
  0.0215843   0.039106     -0.077281     0.111755     0.0325422    0.136864   -0.128572     0.0404284    0.00156277  -0.0302437   0.0711672    -0.0163408     0.046667    -0.0153191    0.188142    -0.0108074   -0.0112842    -0.000901912   0.00412412   0.129632     0.0950096    0.0566218     0.143222      0.0900531     0.0569031    0.0263625
 -0.227795    0.0146754    -0.086892     0.106814    -0.0875185   -0.0714596  -0.0909007   -0.0167777   -0.0500521   -0.0561635   0.112252     -0.132407     -0.0551616   -0.192207    -0.0226407   -0.0128983   -0.0905624    -0.154571     -0.0955081   -0.0583594    0.0131604    0.0890463    -0.147275      0.0227561     0.0229989   -0.0387771
 -0.0761623   0.0816254    -0.0584746    0.0125334   -0.0311915    0.104583    0.110141    -0.0830512    0.0197667   -0.113149    0.043383      0.0345577    -0.0146749    0.0345789    0.0105461    0.24626      0.119777      0.106609      0.137906     0.0510525    0.0564088    0.0185843    -0.022305     -0.0537483     0.0555184   -0.0662817
 -0.10721    -0.155822      0.0343851   -0.104971    -0.00363802   0.127571    0.0737259   -0.0846866    0.215568     0.0193979   0.117717     -0.058478      0.051433     0.0700382    0.026395     0.0791985   -0.273832      0.028638      0.326428    -0.0155634   -0.142403     0.0239837     0.169594     -0.04761      -0.0606762    0.00394628
 -0.0377907  -0.0296918    -0.077645     0.029783     0.109512    -0.192823   -0.0422511    0.12371      0.0849207   -0.0360073   0.0886938     0.142749      0.0642162    0.0319106   -0.00952739  -0.025685     0.0933929     0.163529     -0.0221711   -0.0688371   -0.0771825    0.0113527     0.0437288    -0.0570392     0.126931    -0.0536934
  0.0660342  -0.0319082    -0.0870125   -0.0069277   -0.0271971   -0.108066   -0.0155264    0.0341961    0.0493034    0.141096    0.004901     -0.0389801     0.0303738    0.0098159    0.055398    -0.0560338    0.0931754     0.0117339     0.0141254   -0.138562    -0.0824865   -0.091479      0.221016     -0.0189124    -0.0653964    0.0703897
  0.144335    0.0263618     0.0355767    0.0448853   -0.0647293   -0.0436994  -0.0867328   -0.128744    -0.145605     0.0078846   0.0591421    -0.294314     -0.0277031   -0.0463615   -0.0159114    0.19978     -0.0754005     0.0831792    -0.054292    -0.0489855   -0.147151     0.165631     -0.0979761    -0.0264023     0.0521607   -0.028438
 -0.112114   -0.141905      0.0165052   -0.0831988   -0.0814784    0.0746788   0.0650338    0.0328623    0.0997336    0.0123721   0.0843573    -0.0377177     0.0265083    0.0655556    0.0327213    0.0629734   -0.0438709     0.0255816     0.266048     0.0176286    0.0256588    0.065884     -0.000428314  -0.048693     -0.0546194    0.0789092
 -0.046779    0.134426      0.0629636   -0.0870658    0.109247     0.0451721   0.133223    -0.00482811  -0.0324032    0.0674886  -0.0751826     0.0535623     0.096437    -0.140547     0.16088     -0.00229541   0.14309       0.0723067    -0.146395     0.00385972  -0.0538709   -0.0300634     0.0521956    -0.0983869    -0.0851389   -0.12291
  0.0488761   0.0389934     0.0222545   -0.245118    -0.103247     0.0742784   0.0447789   -0.110158     0.0471907    0.14377     0.0466165    -0.0354234     0.0249963    0.00708149   0.0571126   -0.0772156    0.0248827    -0.0832964     0.0508965    0.0017925   -0.0577539   -0.170889      0.042279     -0.13084      -0.0859323   -0.0179759
  0.0808353  -0.000911455   0.0166316   -0.231889    -0.159642     0.0554475   0.195953    -0.00108318  -0.0722389   -0.082304    0.0732841     0.00144708   -0.0818576   -0.167902    -0.0232406   -0.0254528    0.0193248    -0.0289297     0.0516897   -0.140121     0.0891725   -0.00365638    0.0833516     0.143551     -0.0517868   -0.0527956
 -0.10729     0.140576     -0.172445     0.0176792   -0.0871881   -0.181899    0.0121915   -0.201799     0.150845    -0.0534269   0.0355694    -0.000221847   0.0725359    0.0152004    0.0346227    0.0625045    0.107327      0.0494549     0.0104917   -0.0206403    0.155231    -0.22184       0.112686     -0.0184603    -0.0726749   -0.0734239
 -0.0112612  -0.0606667     0.0652079   -0.0278268   -0.087129    -0.178294    0.0491074    0.0378728   -0.137585     0.0897139  -0.0417182     0.0761698     0.0892464   -0.105501     0.137306    -0.0982403    0.0406017    -0.0839059     0.0798945    0.0434972    0.0417707    0.0449666     0.0480071    -0.000134472   0.033283     0.0969196
  0.0224658   0.0706795     0.090449     0.0222534    0.078396     0.138848   -0.0850334   -0.0352671   -0.0230274    0.102115   -0.0702843    -0.00654802   -0.0498852   -0.0126844   -0.268111    -0.125125    -0.0842114    -0.144606     -0.0544405    0.220754    -0.0888078    0.147569      0.0330033    -0.175195      0.185686     0.100177[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.131711
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     15
│     17
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.066296
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      9
│     10
│     13
│      ⋮
│     28
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.020596
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     11
│     15
│     22
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.103596
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     17
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.079302
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      9
│     10
│     13
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.015498
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.113549
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     11
│     15
│     17
│     22
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.052292
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      9
│     10
│     13
│      ⋮
│     28
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.034779
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     15
│     19
│     22
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.092876
┌ Info: EM with 100000 data points 10 iterations avll -1.092876
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.100923    0.19643      0.0051565   -0.0702065    0.0813062   -0.074282   -0.0925718    0.129882    -0.081343    -0.0325759    0.160599     0.199757      0.145134    -0.154784    0.0707718    0.117639     0.134638     0.0617338    -0.0103275   0.0978686     0.0990094    -0.0412814    -0.0738428   -0.069984    -0.059817    -0.0330605
 -0.12353     0.174945     0.0551172   -0.182616    -0.0139926    0.0205937   0.0510021    0.0433242    0.0457734   -0.045857     0.0590897   -0.203737      0.0404913    0.228709    0.0271968    0.00251654  -0.0628975   -0.0192198    -0.0149907  -0.0731845     0.000412549   0.0166273    -0.199613    -0.0699151    0.0222649   -0.0105199
 -0.148265   -0.0582315    7.37154e-5  -0.0225743   -0.135261    -0.0271698   0.053118    -0.0764145    0.036461    -0.0274197   -0.0262307   -0.104302      0.117714    -0.0211933  -0.0149265    0.0818381    0.100197     0.0732945    -0.0673622   0.121008      0.132334     -0.074762      0.0514454   -0.015535     0.193019     0.132028
  0.0264689  -0.147254     0.0762382   -0.145984     0.0676294    0.100033   -0.0723344    0.022322    -0.0108654   -0.158888     0.181744     0.0222316     0.0478048    0.155123    0.0300506   -0.0361432   -0.0664103    0.0618595    -0.0940168  -0.0639929    -0.177613     -0.132608      0.0787724    0.0924583   -0.0671812   -0.086845
 -0.0142029  -0.128928    -0.0194183   -0.00721196  -0.0432838    0.0589001   0.0195412   -0.0760734   -0.00439349   0.0518261   -0.0249534    0.0904405    -0.172275    -0.0126563  -0.0169691    0.235924     0.00922996   0.225964     -0.16947     0.097581      0.0246433    -0.069353     -0.0615722   -0.0967477   -0.132341    -0.0312692
 -0.0463527   0.117225    -0.16987      0.0670813   -0.0356914    0.0741889  -0.144304     0.0818751   -0.0441511    0.0198261    0.0216926   -0.0753804     0.0128867    0.0501797   0.00287125  -0.0159481   -0.0963904   -0.153118      0.0949924   0.0911482     0.0235115     0.000220817   0.143259    -0.00218826  -0.0514194    0.0215974
 -0.0115436   0.0521392   -0.133148    -0.105736     0.0244071    0.0483177  -0.102427     0.0302917    0.0318669    0.122199    -0.00415321  -0.0522359     0.04169     -0.0088388  -0.047439    -0.0897107   -0.138126    -0.0724915    -0.0443031   0.0607259     0.148348     -0.0115318    -0.131706     0.183102    -0.183559     0.0868859
 -0.109342   -0.00565115   0.040342     0.21475     -0.101444     0.152482    0.0164803    0.278371    -0.100577     0.113453    -0.0359225   -0.0284836    -0.100605    -0.0946629   0.0219917   -0.044558    -0.00997996   0.000518549  -0.107251   -0.003382     -0.137894      0.0998464    -0.120673    -0.106886    -0.025544     0.0250811
  0.0890987  -0.0882192    0.0553018    0.00906669  -0.025882    -0.0431588  -0.0288236   -0.0391672   -0.0633757    0.0317932   -0.14085      0.0691073     0.00652536   0.117914   -0.0155846    0.0657443    0.0237374   -0.0100391     0.098071    0.0593016    -0.0372104     0.0209722     0.200715     0.031019    -0.127441    -0.0185807
 -0.184563    0.0827091   -0.0607627    0.00268762   0.175214     0.14657    -0.0884442    0.0410016    0.143801    -0.147855     0.0791302    0.111048      0.117004     0.0458277  -0.0213154   -0.0454582    0.0958626    0.155518      0.123965   -0.00642328   -0.0238417    -0.0208306     0.0405176   -0.078892     0.0502193   -0.0711186
 -0.0195849  -0.0695404   -0.148066     0.0118749   -0.00520976   0.217343    0.0433337    0.0297286   -0.185404    -0.0130299    0.118725     0.0566837     0.051201     0.0991661   0.0489403    0.0865995    0.087461     0.143086      0.110946   -0.0695034     0.0443183     0.0660363    -0.130685    -0.0612254   -0.0531752   -0.0664265
  0.0778786  -0.16427     -0.159971    -0.241227     0.0341916   -0.0592474   0.0261994    0.0471313    0.00593616  -0.0551303    0.252501     0.0341772    -0.00770903  -0.0342723   0.0561673   -0.142763    -0.204214     0.0945027    -0.120861    0.0374703     0.0443896     0.186193     -0.111972    -0.120558    -0.238269    -0.156099
  0.0548904   0.113831    -0.0193961   -0.0803834   -0.0399014    0.0083236   0.0631619    0.182807    -0.0909552    0.0687845    0.0960727   -0.18171       0.0888401   -0.0199383   0.0390134    0.0304952   -0.07895     -0.120404      0.0111996   0.000601822  -0.106046      0.0690234     0.112098    -0.155118    -0.00916821   0.0158051
 -0.128591   -0.00734986   0.0754882    0.0903318   -0.120242     0.0442335   0.0918123    0.0895466    0.0308988    0.00745631   0.102891     0.060153     -0.0504466   -0.0548554  -0.196767     0.0392061   -0.0257627    0.102139     -0.0288894  -0.0822979    -0.153534     -0.0609601     0.0554873    0.193033     0.123936    -0.121253
 -0.01788    -0.0113919    0.00927349   0.0530739   -0.0139494   -0.0692204   0.026878    -0.123333     0.0995412    0.106185     0.0148209   -0.0195462     0.0650745    0.225641    0.024034    -0.195511    -0.0451486   -0.0757378    -0.09297    -0.0121675    -0.0525159    -0.0692977    -0.17106     -0.00980391  -0.0387228   -0.0467913
  0.0784059   0.0320301    0.0750985    0.0771456    0.00383938  -0.0363399   0.149305     0.0239497   -0.0586908    0.0313573    0.0486251   -0.149283      0.124494     0.0596006  -0.105299    -0.0426017   -0.0274373    0.131909      0.069544   -0.0847509     0.104236      0.191353     -0.150588    -0.0391971    0.159914     0.0862285
 -0.139817    0.0187312    0.0314804   -0.0166216   -0.058734     0.0738833   0.0422949    0.120938    -0.0563405    0.0829494   -0.0608957    0.0870978     0.145439    -0.108658    0.174781     0.12452      0.13202     -0.181938     -0.170472   -0.0776529     0.187539      0.0286009    -0.0529197    0.0756036    0.0856461   -0.110476
  0.0051238   0.00272617  -0.0327051   -0.109058     0.0804526    0.0350388  -0.00712298  -0.0436788    0.00865877  -0.102498     0.0936568    0.0237989     0.0619879   -0.116279   -0.0324449    0.14888      0.0438592    0.0349094     0.033593    0.000202845   0.0349455     0.0149847     0.25139      0.137446     0.0450913    0.0902341
  0.0601904   0.0664393   -0.014534    -0.113229     0.040713     0.0529054   0.170627    -0.00526483   0.120222     0.0130925   -0.0699987    0.00836629   -0.0504239   -0.119109   -0.091336     0.0280185    0.0982784   -0.0517001     0.0752191   0.0505474    -0.00982707    0.0968378     0.00972419  -0.013218    -0.139327    -0.0304296
 -0.043015    0.00842765   0.0952439   -0.162541    -0.0059765   -0.120315   -0.126293     0.00450801   0.0769444    0.0211024    0.0544224   -0.0617835    -0.0529437   -0.0118861   0.199052    -0.0952604   -0.0359361   -0.0483485     0.0869016   0.0421655    -0.0218102     0.0100246    -0.0767762   -0.200965     0.188967    -0.170596
 -0.066332    0.0732679   -0.231393    -0.0617467   -0.111932     0.0532787   0.0822058    0.0689415    0.03688      0.146835    -0.0596447    0.0642693     0.0944964    0.0317885   0.040303    -0.0325395   -0.0834116   -0.0248057    -0.0404616  -0.0235412    -0.129158     -0.0592089    -0.243091    -0.139085    -0.0440462   -0.0394357
 -0.0330371  -0.0510493    0.1254       0.0017695    0.0783104   -0.257049   -0.0263166   -0.00714127  -0.0645176   -0.106115     0.145724    -0.102287      0.00621367   0.210962    0.0292456    0.004716     0.0405095   -0.0551482    -0.102972   -0.0781461    -0.0986211     0.11421       0.0432033   -0.168735     0.0475656   -0.0135302
  0.0796669  -0.00768942   0.0548557   -0.12204     -0.0244152    0.0917382   0.0987197   -0.0408939   -0.0414765   -0.063387     0.0156609    0.0655783    -0.0606077    0.0621816   0.0919362   -0.0724307   -0.0333432   -0.0418699    -0.0931099  -0.00718697    0.111816     -0.0506489     0.0942963    0.0305196    0.026642     0.114232
 -0.209017    0.126804    -0.0895229   -0.0510181    0.135778    -0.0704165   0.216566    -0.101548    -0.0740986    0.115459     0.0138274   -0.14949       0.0630317    0.0277624   0.00954008  -0.273222    -0.167301     0.152386      0.145524    0.0475103    -0.0122731     0.134089      0.026301    -0.158922    -0.120149     0.124792
 -0.0291416   0.0248331    0.066948     0.151518    -0.0555604    0.0309916  -0.0558017    0.0950893    0.0524153   -0.0652985    0.0951192    0.00568147    0.0236696   -0.242713    0.130337    -0.023286     0.183802    -0.0569581    -0.0510315   0.132365     -0.0889836     0.145848      0.0347244   -0.0263672    0.0776604    0.0427842
 -0.102909    0.106044    -0.0164333   -0.0748723   -0.0207532    0.115556   -0.150629     0.0397864    0.0418404    0.086108     0.0838769   -0.0843207    -0.122143    -0.104944   -0.142504    -0.0579681    0.012785    -0.00199499    0.0242061   0.0079949    -0.0550149    -0.0148102     0.0102864   -0.0416863   -0.0972559    0.0807893
 -0.0453721  -0.102436     0.0563682   -0.0296787   -0.0241126   -0.146795   -0.178668    -0.127291     0.102596    -0.122379     0.0839093   -0.00433758    0.0102046   -0.149389    0.111749    -0.0449641   -0.102265    -0.180884      0.181041   -0.236408     -0.0363505     0.0743965    -0.00943824  -0.0644821    0.09755      0.16062
  0.0214316   0.0530104   -0.110862    -0.164262    -0.161927    -0.0784416  -0.00698509  -0.135442     0.0554101    0.173343     0.108536    -0.0509043     0.180274     0.0103896   0.0392033   -0.0022107   -0.0496244    0.0573324     0.0239858  -0.136507     -0.0587157    -0.0180231    -0.101249    -0.0433833    0.0905815   -0.00731879
  0.125826    0.181555    -0.0514759    0.121935     0.127366     0.0444849  -0.0218422   -0.00767195   0.0887195   -0.018976    -0.213478     0.0564843    -0.00974319  -0.165563   -0.111573     0.0433484   -0.129966     0.163412      0.0666337  -0.0498171    -0.0559472    -0.134371     -0.0648159   -0.210451    -0.0291885    0.14948
  0.0703625  -0.106831    -0.245936    -0.00878286   0.0568362   -0.165765   -0.291531     0.144325     0.109368    -0.151188     0.0896726   -0.0301803    -0.192902     0.0944632   0.150144     0.0855712    0.0827654    0.0709449    -0.226544   -0.000393827   0.0753031    -0.105296      0.0913872   -0.0431434   -0.0145116    0.0711729
 -0.106521    0.0433992   -0.193109    -0.0516573   -0.0409305   -0.0540929   0.0439687   -0.148202     0.0514985   -0.0822594    0.12052      0.000370983  -0.0520247   -0.0167206   0.0167269   -0.0481288    0.0554165   -0.145658     -0.044373   -0.00958691    0.0826954     0.000729514   0.36871      0.00226731   0.0630326    0.103944
 -0.116433    0.0667722    0.0838117    0.13406      0.0148608    0.0209132   0.0638375    0.0114813   -0.10227      0.02963      0.126109     0.143726      0.0153883    0.045489   -0.135392     0.103799    -0.0789724    0.00315004   -0.0822457  -0.128702     -0.188995      0.0603095     0.106765    -0.0833385   -0.028934     0.0756381kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4267476616037063
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.426767
[ Info: iteration 2, average log likelihood -1.426711
[ Info: iteration 3, average log likelihood -1.426668
[ Info: iteration 4, average log likelihood -1.426613
[ Info: iteration 5, average log likelihood -1.426541
[ Info: iteration 6, average log likelihood -1.426451
[ Info: iteration 7, average log likelihood -1.426344
[ Info: iteration 8, average log likelihood -1.426229
[ Info: iteration 9, average log likelihood -1.426110
[ Info: iteration 10, average log likelihood -1.425981
[ Info: iteration 11, average log likelihood -1.425813
[ Info: iteration 12, average log likelihood -1.425545
[ Info: iteration 13, average log likelihood -1.425090
[ Info: iteration 14, average log likelihood -1.424378
[ Info: iteration 15, average log likelihood -1.423472
[ Info: iteration 16, average log likelihood -1.422612
[ Info: iteration 17, average log likelihood -1.422015
[ Info: iteration 18, average log likelihood -1.421692
[ Info: iteration 19, average log likelihood -1.421540
[ Info: iteration 20, average log likelihood -1.421473
[ Info: iteration 21, average log likelihood -1.421443
[ Info: iteration 22, average log likelihood -1.421430
[ Info: iteration 23, average log likelihood -1.421425
[ Info: iteration 24, average log likelihood -1.421422
[ Info: iteration 25, average log likelihood -1.421421
[ Info: iteration 26, average log likelihood -1.421420
[ Info: iteration 27, average log likelihood -1.421420
[ Info: iteration 28, average log likelihood -1.421420
[ Info: iteration 29, average log likelihood -1.421420
[ Info: iteration 30, average log likelihood -1.421419
[ Info: iteration 31, average log likelihood -1.421419
[ Info: iteration 32, average log likelihood -1.421419
[ Info: iteration 33, average log likelihood -1.421419
[ Info: iteration 34, average log likelihood -1.421419
[ Info: iteration 35, average log likelihood -1.421419
[ Info: iteration 36, average log likelihood -1.421419
[ Info: iteration 37, average log likelihood -1.421419
[ Info: iteration 38, average log likelihood -1.421419
[ Info: iteration 39, average log likelihood -1.421419
[ Info: iteration 40, average log likelihood -1.421419
[ Info: iteration 41, average log likelihood -1.421419
[ Info: iteration 42, average log likelihood -1.421419
[ Info: iteration 43, average log likelihood -1.421419
[ Info: iteration 44, average log likelihood -1.421419
[ Info: iteration 45, average log likelihood -1.421419
[ Info: iteration 46, average log likelihood -1.421419
[ Info: iteration 47, average log likelihood -1.421419
[ Info: iteration 48, average log likelihood -1.421419
[ Info: iteration 49, average log likelihood -1.421419
[ Info: iteration 50, average log likelihood -1.421419
┌ Info: EM with 100000 data points 50 iterations avll -1.421419
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4267669540141739
│     -1.426710967863408
│      ⋮
└     -1.4214186858809303
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421434
[ Info: iteration 2, average log likelihood -1.421377
[ Info: iteration 3, average log likelihood -1.421331
[ Info: iteration 4, average log likelihood -1.421277
[ Info: iteration 5, average log likelihood -1.421207
[ Info: iteration 6, average log likelihood -1.421119
[ Info: iteration 7, average log likelihood -1.421014
[ Info: iteration 8, average log likelihood -1.420898
[ Info: iteration 9, average log likelihood -1.420779
[ Info: iteration 10, average log likelihood -1.420669
[ Info: iteration 11, average log likelihood -1.420574
[ Info: iteration 12, average log likelihood -1.420499
[ Info: iteration 13, average log likelihood -1.420441
[ Info: iteration 14, average log likelihood -1.420397
[ Info: iteration 15, average log likelihood -1.420363
[ Info: iteration 16, average log likelihood -1.420336
[ Info: iteration 17, average log likelihood -1.420313
[ Info: iteration 18, average log likelihood -1.420293
[ Info: iteration 19, average log likelihood -1.420276
[ Info: iteration 20, average log likelihood -1.420260
[ Info: iteration 21, average log likelihood -1.420247
[ Info: iteration 22, average log likelihood -1.420235
[ Info: iteration 23, average log likelihood -1.420225
[ Info: iteration 24, average log likelihood -1.420217
[ Info: iteration 25, average log likelihood -1.420209
[ Info: iteration 26, average log likelihood -1.420203
[ Info: iteration 27, average log likelihood -1.420198
[ Info: iteration 28, average log likelihood -1.420193
[ Info: iteration 29, average log likelihood -1.420190
[ Info: iteration 30, average log likelihood -1.420186
[ Info: iteration 31, average log likelihood -1.420184
[ Info: iteration 32, average log likelihood -1.420182
[ Info: iteration 33, average log likelihood -1.420180
[ Info: iteration 34, average log likelihood -1.420178
[ Info: iteration 35, average log likelihood -1.420177
[ Info: iteration 36, average log likelihood -1.420175
[ Info: iteration 37, average log likelihood -1.420174
[ Info: iteration 38, average log likelihood -1.420173
[ Info: iteration 39, average log likelihood -1.420172
[ Info: iteration 40, average log likelihood -1.420172
[ Info: iteration 41, average log likelihood -1.420171
[ Info: iteration 42, average log likelihood -1.420170
[ Info: iteration 43, average log likelihood -1.420170
[ Info: iteration 44, average log likelihood -1.420169
[ Info: iteration 45, average log likelihood -1.420168
[ Info: iteration 46, average log likelihood -1.420168
[ Info: iteration 47, average log likelihood -1.420167
[ Info: iteration 48, average log likelihood -1.420167
[ Info: iteration 49, average log likelihood -1.420166
[ Info: iteration 50, average log likelihood -1.420166
┌ Info: EM with 100000 data points 50 iterations avll -1.420166
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.42143375044235
│     -1.4213770427695198
│      ⋮
└     -1.4201660211726022
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420177
[ Info: iteration 2, average log likelihood -1.420128
[ Info: iteration 3, average log likelihood -1.420088
[ Info: iteration 4, average log likelihood -1.420044
[ Info: iteration 5, average log likelihood -1.419990
[ Info: iteration 6, average log likelihood -1.419925
[ Info: iteration 7, average log likelihood -1.419850
[ Info: iteration 8, average log likelihood -1.419768
[ Info: iteration 9, average log likelihood -1.419682
[ Info: iteration 10, average log likelihood -1.419599
[ Info: iteration 11, average log likelihood -1.419523
[ Info: iteration 12, average log likelihood -1.419454
[ Info: iteration 13, average log likelihood -1.419395
[ Info: iteration 14, average log likelihood -1.419344
[ Info: iteration 15, average log likelihood -1.419302
[ Info: iteration 16, average log likelihood -1.419267
[ Info: iteration 17, average log likelihood -1.419237
[ Info: iteration 18, average log likelihood -1.419212
[ Info: iteration 19, average log likelihood -1.419191
[ Info: iteration 20, average log likelihood -1.419172
[ Info: iteration 21, average log likelihood -1.419155
[ Info: iteration 22, average log likelihood -1.419139
[ Info: iteration 23, average log likelihood -1.419125
[ Info: iteration 24, average log likelihood -1.419111
[ Info: iteration 25, average log likelihood -1.419097
[ Info: iteration 26, average log likelihood -1.419084
[ Info: iteration 27, average log likelihood -1.419072
[ Info: iteration 28, average log likelihood -1.419059
[ Info: iteration 29, average log likelihood -1.419047
[ Info: iteration 30, average log likelihood -1.419035
[ Info: iteration 31, average log likelihood -1.419024
[ Info: iteration 32, average log likelihood -1.419012
[ Info: iteration 33, average log likelihood -1.419001
[ Info: iteration 34, average log likelihood -1.418989
[ Info: iteration 35, average log likelihood -1.418978
[ Info: iteration 36, average log likelihood -1.418967
[ Info: iteration 37, average log likelihood -1.418956
[ Info: iteration 38, average log likelihood -1.418945
[ Info: iteration 39, average log likelihood -1.418935
[ Info: iteration 40, average log likelihood -1.418924
[ Info: iteration 41, average log likelihood -1.418913
[ Info: iteration 42, average log likelihood -1.418902
[ Info: iteration 43, average log likelihood -1.418892
[ Info: iteration 44, average log likelihood -1.418882
[ Info: iteration 45, average log likelihood -1.418871
[ Info: iteration 46, average log likelihood -1.418861
[ Info: iteration 47, average log likelihood -1.418851
[ Info: iteration 48, average log likelihood -1.418841
[ Info: iteration 49, average log likelihood -1.418831
[ Info: iteration 50, average log likelihood -1.418822
┌ Info: EM with 100000 data points 50 iterations avll -1.418822
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4201768495968854
│     -1.4201282043558374
│      ⋮
└     -1.418821822652559
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418821
[ Info: iteration 2, average log likelihood -1.418760
[ Info: iteration 3, average log likelihood -1.418703
[ Info: iteration 4, average log likelihood -1.418638
[ Info: iteration 5, average log likelihood -1.418561
[ Info: iteration 6, average log likelihood -1.418468
[ Info: iteration 7, average log likelihood -1.418360
[ Info: iteration 8, average log likelihood -1.418241
[ Info: iteration 9, average log likelihood -1.418119
[ Info: iteration 10, average log likelihood -1.418002
[ Info: iteration 11, average log likelihood -1.417893
[ Info: iteration 12, average log likelihood -1.417797
[ Info: iteration 13, average log likelihood -1.417713
[ Info: iteration 14, average log likelihood -1.417640
[ Info: iteration 15, average log likelihood -1.417577
[ Info: iteration 16, average log likelihood -1.417522
[ Info: iteration 17, average log likelihood -1.417475
[ Info: iteration 18, average log likelihood -1.417434
[ Info: iteration 19, average log likelihood -1.417398
[ Info: iteration 20, average log likelihood -1.417366
[ Info: iteration 21, average log likelihood -1.417338
[ Info: iteration 22, average log likelihood -1.417313
[ Info: iteration 23, average log likelihood -1.417290
[ Info: iteration 24, average log likelihood -1.417269
[ Info: iteration 25, average log likelihood -1.417250
[ Info: iteration 26, average log likelihood -1.417233
[ Info: iteration 27, average log likelihood -1.417216
[ Info: iteration 28, average log likelihood -1.417201
[ Info: iteration 29, average log likelihood -1.417186
[ Info: iteration 30, average log likelihood -1.417172
[ Info: iteration 31, average log likelihood -1.417158
[ Info: iteration 32, average log likelihood -1.417145
[ Info: iteration 33, average log likelihood -1.417132
[ Info: iteration 34, average log likelihood -1.417119
[ Info: iteration 35, average log likelihood -1.417107
[ Info: iteration 36, average log likelihood -1.417095
[ Info: iteration 37, average log likelihood -1.417083
[ Info: iteration 38, average log likelihood -1.417071
[ Info: iteration 39, average log likelihood -1.417060
[ Info: iteration 40, average log likelihood -1.417048
[ Info: iteration 41, average log likelihood -1.417037
[ Info: iteration 42, average log likelihood -1.417026
[ Info: iteration 43, average log likelihood -1.417015
[ Info: iteration 44, average log likelihood -1.417005
[ Info: iteration 45, average log likelihood -1.416995
[ Info: iteration 46, average log likelihood -1.416984
[ Info: iteration 47, average log likelihood -1.416974
[ Info: iteration 48, average log likelihood -1.416964
[ Info: iteration 49, average log likelihood -1.416955
[ Info: iteration 50, average log likelihood -1.416945
┌ Info: EM with 100000 data points 50 iterations avll -1.416945
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4188214246153616
│     -1.4187596025460187
│      ⋮
└     -1.4169451975858967
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416944
[ Info: iteration 2, average log likelihood -1.416877
[ Info: iteration 3, average log likelihood -1.416814
[ Info: iteration 4, average log likelihood -1.416742
[ Info: iteration 5, average log likelihood -1.416653
[ Info: iteration 6, average log likelihood -1.416542
[ Info: iteration 7, average log likelihood -1.416407
[ Info: iteration 8, average log likelihood -1.416248
[ Info: iteration 9, average log likelihood -1.416074
[ Info: iteration 10, average log likelihood -1.415893
[ Info: iteration 11, average log likelihood -1.415717
[ Info: iteration 12, average log likelihood -1.415554
[ Info: iteration 13, average log likelihood -1.415408
[ Info: iteration 14, average log likelihood -1.415280
[ Info: iteration 15, average log likelihood -1.415169
[ Info: iteration 16, average log likelihood -1.415072
[ Info: iteration 17, average log likelihood -1.414987
[ Info: iteration 18, average log likelihood -1.414911
[ Info: iteration 19, average log likelihood -1.414844
[ Info: iteration 20, average log likelihood -1.414783
[ Info: iteration 21, average log likelihood -1.414727
[ Info: iteration 22, average log likelihood -1.414677
[ Info: iteration 23, average log likelihood -1.414630
[ Info: iteration 24, average log likelihood -1.414587
[ Info: iteration 25, average log likelihood -1.414547
[ Info: iteration 26, average log likelihood -1.414510
[ Info: iteration 27, average log likelihood -1.414475
[ Info: iteration 28, average log likelihood -1.414442
[ Info: iteration 29, average log likelihood -1.414411
[ Info: iteration 30, average log likelihood -1.414381
[ Info: iteration 31, average log likelihood -1.414353
[ Info: iteration 32, average log likelihood -1.414327
[ Info: iteration 33, average log likelihood -1.414301
[ Info: iteration 34, average log likelihood -1.414277
[ Info: iteration 35, average log likelihood -1.414253
[ Info: iteration 36, average log likelihood -1.414231
[ Info: iteration 37, average log likelihood -1.414210
[ Info: iteration 38, average log likelihood -1.414189
[ Info: iteration 39, average log likelihood -1.414170
[ Info: iteration 40, average log likelihood -1.414151
[ Info: iteration 41, average log likelihood -1.414133
[ Info: iteration 42, average log likelihood -1.414115
[ Info: iteration 43, average log likelihood -1.414099
[ Info: iteration 44, average log likelihood -1.414082
[ Info: iteration 45, average log likelihood -1.414067
[ Info: iteration 46, average log likelihood -1.414052
[ Info: iteration 47, average log likelihood -1.414037
[ Info: iteration 48, average log likelihood -1.414023
[ Info: iteration 49, average log likelihood -1.414010
[ Info: iteration 50, average log likelihood -1.413997
┌ Info: EM with 100000 data points 50 iterations avll -1.413997
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4169443588091
│     -1.4168771356268732
│      ⋮
└     -1.4139967243732705
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4267476616037063
│     -1.4267669540141739
│     -1.426710967863408
│     -1.4266677825232452
│      ⋮
│     -1.4140233068201706
│     -1.4140097919768404
└     -1.4139967243732705
32×26 Array{Float64,2}:
 -0.187416     -0.346033   -0.221865     0.076116    -0.0242157   0.334964   -0.184156   -0.178886     0.488333     0.158655    -0.191579    0.206763   -0.00914281  -0.740001     -0.205891     0.0316969    -0.789534    0.214643   -0.00485574    0.0616882   -0.126316    -0.17511     -0.700855    0.0507799  -0.453989    0.193667
 -0.243999     -0.490375    0.159868     0.260421     0.27599     0.336306    0.218276    0.178888    -0.0570681   -0.290576     0.325615    0.179463   -0.122347     0.275609      0.26599      0.38388      -0.127487   -0.376822   -0.101091     -0.303558    -0.431346    -0.417442    -0.60464    -0.126252    0.729404   -0.0693464
 -0.190001     -0.0168924   0.15782      0.845766    -0.367999   -0.367775   -0.296724    0.22598      0.221033     0.248786     0.633321   -0.146972   -0.0879115    0.0345055    -0.0475626   -0.616046      0.128011   -0.32868     0.59874       0.0310727   -0.657422     0.171431    -0.29793     0.136742   -0.325699   -0.0467474
  0.0974813     0.395297   -0.577846     0.0850095   -0.223858    0.625895    0.372171    0.183239    -0.153885     0.0910949   -0.386156    0.167337   -0.271665     0.143757      0.0674641   -0.53075      -0.0337724  -0.326157    0.141912     -0.324333    -0.405386    -0.534957    -0.419215    0.0553601  -0.0538059   0.0707862
 -0.14156      -0.0905147   0.0554888    0.354154    -0.163554   -0.375769    0.34998    -0.0278285   -0.405381    -0.126788    -0.21583     0.262634    0.200744    -0.379731      0.291276     0.273669      0.240203    0.249516   -0.363588     -0.867323    -0.185796    -0.00195239  -0.385528   -0.0068709  -0.511622    0.218399
 -0.448234     -0.0341091  -0.236929     0.00346094   0.111701   -0.18237     0.128916    0.00652617  -0.0755983    0.305752     0.123401    0.584419    0.184274     0.47868      -0.222562     0.214497      0.0974439   0.206955    0.0869809    -0.417519    -0.0292552    0.536662    -0.10171    -0.0252168  -0.10791     0.278672
  0.000300779  -0.593506    0.123866    -0.335403     0.205681    0.0981377  -0.193385    0.270258    -0.0486407    0.186268    -0.0961312   0.382053   -0.360507     0.000734564   0.151125     0.237295      0.192447    0.745173   -0.164226      0.271994    -0.0812398   -0.0943297   -0.193126   -0.115064    0.0181313  -0.0331577
  0.00897756    0.200176    0.189937    -0.0320313    0.197556    0.327237    0.13267    -0.0135625   -0.330712     0.0799191   -0.0246002   0.0514767  -0.0544752   -0.141795      0.227375    -0.0608871     0.432514    0.412797   -0.0959552    -0.0672299    0.229574    -0.0846037    0.0201967   0.336089   -0.276675   -0.0380272
  0.174287      0.255406    0.440411    -0.239573     0.165659   -0.437078   -0.285713   -0.333436     0.00824561   0.475316    -0.127194   -0.515222    0.384523    -0.754723     -0.0370981   -0.430997     -0.0385682   0.39599     0.102976      0.474634     0.527705     0.381037     0.567517   -0.0231258  -0.213224   -0.0104258
 -0.0744957     0.0152164   0.510178    -0.594386     0.499863   -0.425863    0.202028   -0.628306    -0.260166     0.235028    -0.0893108   0.237094    0.383639    -0.0474637    -0.0778682    0.726865     -0.0544046  -0.0334721  -0.335437     -0.0114112    0.358049     0.847326     0.189382    0.0166449  -0.34792     0.475247
 -0.105469      0.0297347   0.221516     0.297623     0.275391   -0.642497   -0.47586    -0.107204    -0.337491    -0.655904     0.360173   -0.0141159   0.397772    -0.279863     -0.0144336    0.181295     -0.363381   -0.11023    -0.286611     -0.200686    -0.557783    -0.0892436    0.699288    0.0568679   0.0742417   0.532255
 -0.192197      0.709836    0.221205    -0.164332    -0.258676    0.229268   -0.477959   -0.452234    -0.652459    -0.234047     0.159038   -0.119312    0.291651     0.100601      0.0253589   -0.521697     -0.0283181  -0.407971   -0.0710354    -0.432594     0.514866     0.380329     0.382103    0.940583    0.0786613   0.841226
  0.00982811   -0.116058    0.0877793    0.012819    -0.0239105  -0.0263816   0.0206203   0.0208061    0.0139974   -0.00169995   0.115619   -0.112192   -0.0541995   -0.00176721   -0.00205721   0.0791025    -0.109697   -0.0880765   0.0277929     0.00745511  -0.13897     -0.131497    -0.115935   -0.124728    0.0639335  -0.00621605
 -0.147634      0.422943   -0.175524    -0.14723     -0.151573   -0.118922    0.102036   -0.0710319    0.230197    -0.0895954    0.124044   -0.175102    0.125999     0.117666     -0.00453898  -0.308867     -0.0372951  -0.307847    0.000647686   0.36333      0.153125     0.116211     0.3405     -0.298725    0.0556339  -0.0506728
  0.632566      0.0436129  -0.559395    -0.271047    -0.316042    0.0239748  -0.375665   -0.15964      0.313425     0.107945    -0.058579   -0.28884     0.442239     0.0795461    -0.164644     0.184923     -0.234057   -0.224242   -0.0935703    -0.477465     0.296282     0.245613     0.235714   -0.048502    0.131718    0.158069
  0.229237     -0.0270842  -0.126237    -0.678906     0.441283    0.757253   -0.182768    0.286141     0.55591      0.353507     0.0134028  -0.19771    -0.266638     0.251944     -0.139348    -0.0752909     0.0785733   0.130017    0.277614      0.847354     0.463107     0.366211     0.199431    0.0903293   0.294175   -0.169947
  0.126217     -0.584131    0.156229    -0.464268     0.10375    -0.4374      0.325563    0.432242     0.23667      0.461156     0.201824   -0.586871   -0.0983001    0.177941     -0.050016    -0.000102295  -0.681522   -0.410066   -0.0187792     0.211914    -0.613151     0.0257088   -0.34467    -0.870064   -0.0360929  -0.158395
  0.106848      0.12818    -0.299148    -0.130984    -0.1343      0.024685   -0.233545    0.0136591    0.218996     0.00967215   0.0812811  -0.220946    0.00344684   0.145581     -0.0188177   -0.334568      0.164687   -0.102731    0.158845      0.066226     0.0914694    0.227714     0.216218    0.150411    0.0417486  -0.0998808
 -0.408114      0.431475    0.291677     0.246401    -0.471823    0.247519    0.150058   -0.0925357    0.332918     0.216699    -0.229133   -0.670847    0.427761     0.362373     -0.199084     0.370032      0.0639305  -0.538085   -0.0184053     0.304286     0.535699    -0.201349    -0.0415268  -0.675976    0.367806    0.248283
  0.0788248    -0.0654395   0.00824444   0.13185     -0.503962    0.239149   -0.410167    0.148325    -0.147246    -0.0603098    0.327725    0.855137    0.227298    -0.0496963     0.344969     0.357947     -0.0955199  -0.363171    0.468568      0.147777     0.107792    -0.260287     0.0248854  -0.70938     0.105058    0.587187
 -0.172214     -0.196383    0.1296       0.0747979   -0.0477141  -0.44282     0.452965   -0.0760093   -0.150765    -0.574974     0.0692308  -0.0640353  -0.830333    -0.844422      0.102562    -0.336561      0.134216    0.288386   -0.435476      0.542435    -0.327186    -0.424043     0.357963    0.217507   -0.589883   -0.310712
  0.26467       0.120894   -0.252134    -0.0449374   -0.0814363  -0.0356223  -0.198855    0.135831     0.212833    -0.783966     0.399314   -0.704163   -0.0277049   -0.101335     -0.141104    -0.546679     -0.268094   -0.471547    0.127632      0.500119    -0.255902    -0.348929     0.532133    0.0280548   0.903315   -0.268488
 -0.102437      0.196275    0.0122509    0.0114615    0.142089   -0.184364    0.246623    0.201887     0.326828    -0.0311117   -0.103003   -0.631962   -0.0542411    0.213895     -0.407574    -0.0174773     0.0118089   0.344283   -0.230781     -0.260163    -0.170273    -0.0656018   -0.0182598   0.270132    0.02876    -0.938686
  0.4763        0.0257529   0.0336359   -0.647344    -0.305979   -0.263932   -0.0742051   0.0558889   -0.372695     0.240428     0.0897421  -0.592678   -0.105134     0.715595      0.530837    -0.218427      0.738236   -0.384234    0.233593     -0.144947     0.254165    -0.0472397    0.0748679  -0.154604   -0.0452227  -0.463733
  0.0790651     0.215009   -0.26416      0.595143    -0.305959   -0.250418    0.43363    -0.176125    -0.526725    -0.321169    -0.0748507   0.364265    0.347286    -0.346255     -0.241862     0.300787     -0.159724    0.0623163  -0.245036     -1.1998      -0.295994    -0.433302    -0.132044   -0.208413   -0.0990383   0.502844
  0.510169      0.0740558   0.426244    -0.553614     0.432301    0.118373    0.0526336  -0.637598    -0.492187    -0.0524975   -0.166249   -0.35449     0.254187    -0.441993     -0.444003    -0.127701     -0.793462    0.355369    0.301416     -0.243506    -0.139257    -0.809398    -0.0985953  -0.247462    0.0705926  -0.158422
  0.226213     -0.327014    0.850427     0.200832     0.0478929   0.330615   -0.176155   -0.0834378   -0.0266158   -0.115707     0.282791   -0.620283   -0.573331    -0.0897746    -0.197556     0.705824      0.48472     0.619111    0.0597934     0.208306    -0.0157438   -0.624679    -0.40862     0.311799    0.159404   -0.184013
 -0.680678     -0.151976    0.495757     0.335994     0.354392    0.435257    0.201828    0.244445    -0.201032     0.342675    -0.0164535   0.917106   -0.119916    -0.235102      0.345992     0.401479      0.270072    0.54979     0.0832382     0.00367073  -0.177273     0.183722    -0.638358    0.253002   -0.292773    0.0581784
 -0.00118408    0.130213   -1.11801      0.0154823    0.0264771   0.278497   -0.260509   -0.627941     0.148263    -0.148912    -0.0203636   0.309715   -0.217824    -0.311042     -0.104101    -0.03423       0.468113    0.631732    0.0212643    -0.342082     0.667485     0.329742    -0.0967198   0.579712   -0.170466    0.121598
 -0.291527      0.0383639  -0.855701     0.475112    -0.183153   -0.152261   -0.197251    0.68188      0.482904    -0.0681441   -0.210097    0.231258   -0.0144748    0.107771      0.413366    -0.223073      0.354556    0.193031   -0.72222       0.150759     0.409754     1.00324      0.128537    0.137031   -0.0931311  -0.00111733
 -0.738799     -0.29655    -0.33275     -0.686742     0.494483    0.404851    0.597329    0.226163    -0.308431    -0.424577    -0.549262    1.00121    -0.2057       0.54325       0.113443     0.114764      0.0567193   0.346607   -0.480337      0.309071     0.228972    -0.247212     0.353208   -0.274553    0.199426   -0.185747
 -0.170601      1.07156    -0.507884    -0.0827931    0.181917    0.0304261   0.485027    0.792396    -0.00644819  -0.0881179    0.208216    0.643224    0.554521     0.272073      0.205391     0.0776545    -0.469418   -0.115127   -0.499526      0.193941     0.00528923   0.621967     0.591016   -0.70631    -0.114223    0.110308[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413984
[ Info: iteration 2, average log likelihood -1.413972
[ Info: iteration 3, average log likelihood -1.413960
[ Info: iteration 4, average log likelihood -1.413948
[ Info: iteration 5, average log likelihood -1.413937
[ Info: iteration 6, average log likelihood -1.413927
[ Info: iteration 7, average log likelihood -1.413916
[ Info: iteration 8, average log likelihood -1.413906
[ Info: iteration 9, average log likelihood -1.413896
[ Info: iteration 10, average log likelihood -1.413886
┌ Info: EM with 100000 data points 10 iterations avll -1.413886
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.476549e+05
      1       7.161507e+05      -1.315042e+05 |       32
      2       6.993198e+05      -1.683089e+04 |       32
      3       6.936927e+05      -5.627093e+03 |       32
      4       6.908942e+05      -2.798551e+03 |       32
      5       6.891158e+05      -1.778326e+03 |       32
      6       6.877529e+05      -1.362885e+03 |       32
      7       6.866361e+05      -1.116849e+03 |       32
      8       6.857105e+05      -9.256272e+02 |       32
      9       6.849467e+05      -7.637305e+02 |       32
     10       6.843107e+05      -6.360529e+02 |       32
     11       6.837762e+05      -5.344927e+02 |       32
     12       6.833720e+05      -4.041582e+02 |       32
     13       6.830349e+05      -3.371220e+02 |       32
     14       6.827373e+05      -2.975657e+02 |       32
     15       6.824639e+05      -2.734670e+02 |       32
     16       6.821974e+05      -2.664752e+02 |       32
     17       6.819738e+05      -2.236449e+02 |       32
     18       6.817728e+05      -2.009765e+02 |       32
     19       6.815927e+05      -1.801282e+02 |       32
     20       6.814338e+05      -1.588476e+02 |       32
     21       6.812784e+05      -1.554302e+02 |       32
     22       6.811233e+05      -1.550880e+02 |       32
     23       6.809771e+05      -1.462099e+02 |       32
     24       6.808396e+05      -1.374473e+02 |       32
     25       6.807086e+05      -1.310506e+02 |       32
     26       6.805851e+05      -1.234846e+02 |       32
     27       6.804695e+05      -1.156149e+02 |       32
     28       6.803563e+05      -1.132221e+02 |       32
     29       6.802572e+05      -9.902000e+01 |       32
     30       6.801636e+05      -9.358871e+01 |       32
     31       6.800774e+05      -8.625933e+01 |       32
     32       6.800043e+05      -7.311903e+01 |       32
     33       6.799416e+05      -6.264448e+01 |       32
     34       6.798769e+05      -6.469417e+01 |       32
     35       6.798064e+05      -7.056749e+01 |       32
     36       6.797336e+05      -7.274360e+01 |       32
     37       6.796637e+05      -6.990559e+01 |       32
     38       6.796030e+05      -6.072881e+01 |       32
     39       6.795469e+05      -5.613384e+01 |       32
     40       6.794927e+05      -5.414115e+01 |       32
     41       6.794401e+05      -5.258383e+01 |       32
     42       6.793909e+05      -4.919730e+01 |       32
     43       6.793440e+05      -4.689476e+01 |       32
     44       6.792964e+05      -4.764770e+01 |       32
     45       6.792476e+05      -4.879434e+01 |       32
     46       6.792023e+05      -4.531865e+01 |       32
     47       6.791613e+05      -4.096448e+01 |       32
     48       6.791234e+05      -3.788902e+01 |       32
     49       6.790897e+05      -3.370452e+01 |       32
     50       6.790541e+05      -3.556860e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 679054.1476845986)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425439
[ Info: iteration 2, average log likelihood -1.420556
[ Info: iteration 3, average log likelihood -1.419330
[ Info: iteration 4, average log likelihood -1.418495
[ Info: iteration 5, average log likelihood -1.417596
[ Info: iteration 6, average log likelihood -1.416650
[ Info: iteration 7, average log likelihood -1.415868
[ Info: iteration 8, average log likelihood -1.415359
[ Info: iteration 9, average log likelihood -1.415058
[ Info: iteration 10, average log likelihood -1.414870
[ Info: iteration 11, average log likelihood -1.414737
[ Info: iteration 12, average log likelihood -1.414635
[ Info: iteration 13, average log likelihood -1.414552
[ Info: iteration 14, average log likelihood -1.414481
[ Info: iteration 15, average log likelihood -1.414420
[ Info: iteration 16, average log likelihood -1.414366
[ Info: iteration 17, average log likelihood -1.414317
[ Info: iteration 18, average log likelihood -1.414273
[ Info: iteration 19, average log likelihood -1.414232
[ Info: iteration 20, average log likelihood -1.414194
[ Info: iteration 21, average log likelihood -1.414159
[ Info: iteration 22, average log likelihood -1.414127
[ Info: iteration 23, average log likelihood -1.414096
[ Info: iteration 24, average log likelihood -1.414067
[ Info: iteration 25, average log likelihood -1.414039
[ Info: iteration 26, average log likelihood -1.414014
[ Info: iteration 27, average log likelihood -1.413990
[ Info: iteration 28, average log likelihood -1.413967
[ Info: iteration 29, average log likelihood -1.413945
[ Info: iteration 30, average log likelihood -1.413925
[ Info: iteration 31, average log likelihood -1.413906
[ Info: iteration 32, average log likelihood -1.413888
[ Info: iteration 33, average log likelihood -1.413870
[ Info: iteration 34, average log likelihood -1.413854
[ Info: iteration 35, average log likelihood -1.413839
[ Info: iteration 36, average log likelihood -1.413824
[ Info: iteration 37, average log likelihood -1.413810
[ Info: iteration 38, average log likelihood -1.413797
[ Info: iteration 39, average log likelihood -1.413784
[ Info: iteration 40, average log likelihood -1.413773
[ Info: iteration 41, average log likelihood -1.413761
[ Info: iteration 42, average log likelihood -1.413750
[ Info: iteration 43, average log likelihood -1.413740
[ Info: iteration 44, average log likelihood -1.413730
[ Info: iteration 45, average log likelihood -1.413721
[ Info: iteration 46, average log likelihood -1.413712
[ Info: iteration 47, average log likelihood -1.413703
[ Info: iteration 48, average log likelihood -1.413695
[ Info: iteration 49, average log likelihood -1.413687
[ Info: iteration 50, average log likelihood -1.413680
┌ Info: EM with 100000 data points 50 iterations avll -1.413680
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.271336     0.0771485    0.0883428  -0.592952      0.102388    -0.546091     0.0115753     0.135983   -0.184068   -0.262284     0.131401   -0.701704   -0.0103732    0.407009    0.053684    -0.5955     -0.0219234  -0.519967    0.0329512    0.436727   -0.277111     0.0967716    0.476042   -0.511287    0.372856    -0.226486
  0.312542     0.162739     0.0003632  -0.102374     -0.275648     0.545787     0.79561      -0.328091   -0.179092    0.906645     0.110949   -0.0214801  -0.369617    -0.0651518   0.56684     -0.103294   -0.232406   -0.471693    0.123154     0.173171    0.262277    -0.319484    -0.173604   -0.559351   -0.437165     0.0380882
  0.59845     -0.757989     0.390359    0.201129     -0.299548     0.0496663   -0.286155     -0.430662   -0.0804635   0.186854     0.227271   -0.692984   -0.27203     -0.333457    0.0873519    0.127931    0.852821    0.0844041   0.237744    -0.269518    0.0312465   -0.483172    -0.334676    0.486366    0.00540258  -0.00786733
  0.128046     0.296868     0.964916   -0.0444488     0.41726      0.0602931    0.180685     -1.13602    -0.479847    0.450493    -0.554715   -0.426295    0.340512    -0.230434    0.0166713   -0.570857   -0.522777    0.183937    0.909703     0.290531    0.00807066  -0.322897     0.15929     0.351185   -0.12309      0.15835
 -0.390623     0.692875     0.594409   -0.035606     -0.03785     -0.135838     0.0156342    -0.0332329   0.0596816   0.294519    -0.108536   -0.468802    0.570816    -0.0211305   0.159903     0.144265    0.321442   -0.323478   -0.195016     0.648393    0.985262     0.332949     0.303103   -0.330442    0.315673     0.0882429
 -0.359632     0.00226338   0.178442    0.629707     -0.285641    -0.527652    -0.117311      0.270481    0.380039    0.401553     0.617163   -0.0478771  -0.139158     0.106125   -0.0305579   -0.37977     0.205249   -0.404597    0.442639     0.149093   -0.597204     0.710062    -0.24052     0.129674   -0.519194     0.118787
 -0.325062    -0.173766    -0.662684    0.0315851     0.438924    -0.241292     0.129537     -0.073777    0.558789   -0.0150412    0.0639047  -0.141816   -0.253899    -0.488586    0.0894427   -0.555276   -0.170909    0.370902   -0.553425     0.322912    0.258653     0.528801     0.147407    0.117628   -0.234609    -0.296744
  0.0294255    0.234271    -0.473642    0.0861606    -0.664348    -0.0726264   -0.11238       0.230097    0.573       0.244757    -0.312561   -0.135073    0.240722     0.229132   -0.11353      0.131343   -0.207762   -0.0255883  -0.147127    -0.0470736   0.111053     0.281353     0.023799   -0.415197   -0.313482    -0.136791
  0.021222     0.185257     0.229312   -0.0752418     0.00939056  -0.00555709  -0.289947     -0.045317   -0.27136    -0.0916362    0.0395066   0.0670322  -0.0274692   -0.377732    0.153685     0.0676778   0.227606    0.400254   -0.109553    -0.0264284   0.169796    -0.0689214    0.153582    0.325529   -0.370337     0.224222
 -0.320374    -0.299453     0.0425613   0.165788     -0.403396     0.23954     -0.446467      0.0965337  -0.107329   -0.00340921   0.302342    0.860274    0.0547082   -0.199423    0.393358    -0.0346742   0.0409941  -0.184404    0.526142     0.235744   -0.119478     0.00522237  -0.327828   -0.414406   -0.0423322    0.556852
 -0.0687437   -0.380442     0.0879114   0.161635      0.252925     0.132523     0.244237      0.142396   -0.0268033  -0.0984691    0.111371    0.0690073  -0.102098     0.0297755   0.135952     0.20773    -0.124926   -0.0908041  -0.136165    -0.167753   -0.326116    -0.223258    -0.441226   -0.152309    0.174891    -0.0612364
 -0.291135     0.600892    -0.328684    0.321756     -0.252885     0.172856     0.0375588    -0.200751   -0.0333764  -0.674844     0.252621   -0.134319    0.199511     0.058014   -0.0948532   -0.435943   -0.265199   -0.895096   -0.0328353   -0.261608   -0.059858    -0.0720461    0.343128    0.270257    0.367225     0.481847
  0.389827     0.108673    -0.395121   -0.674081      0.312069     0.800066    -0.205356      0.306505    0.522962    0.11088     -0.0421551  -0.287412   -0.312047     0.321155   -0.249214    -0.356334    0.149426    0.0188828   0.262283     0.76793     0.292135     0.210464     0.240396    0.276524    0.445676    -0.264028
  0.103685     0.235966    -0.696631    0.566466     -0.422695     0.148547     0.000846666   0.606661   -0.0517598  -0.113875     0.290422   -0.026513   -0.140411     0.114991   -0.183708    -0.622958    0.169089    0.134886    0.290456    -0.337016   -0.406067    -0.57502     -0.194534   -0.17908     0.251183    -0.399165
 -0.414235     0.135244     0.509757    0.0857808     0.240602    -0.375831     0.738289     -0.189462   -0.250166    0.216454    -0.0291925   0.469783    0.441741    -0.332619    0.0178395    0.888876   -0.126005    0.112351   -0.373551    -0.454681    0.134165     0.357272    -0.19756    -0.353129   -0.599814     0.556078
 -0.733505    -0.255925     0.478284    0.343883      0.498645     0.934077    -0.171474      0.634593   -0.209807   -0.114681    -0.11893     0.474956   -0.55495      0.0310978   0.50867      0.269626    0.511786    0.55346     0.11083      0.353541   -0.0525937   -0.00930839  -0.389793    0.481251    0.425328    -0.412912
 -0.0794681   -0.183859    -0.499164    0.0997084     0.183497     0.587616     0.0244807    -0.220752   -0.031278    0.004535    -0.307191    0.561736   -0.0443051   -0.451743   -0.143575     0.020327   -0.593047    0.286021   -0.0364856   -0.58484    -0.35451     -0.423769    -0.750066    0.330534   -0.275758     0.524571
  0.350182     0.17174      0.684644   -0.157799     -0.452877    -0.0157766    0.142501      0.460926   -0.429423   -0.20467      0.03111    -0.019156    0.255886     0.39171     0.222224     0.619737    0.0277575  -0.410496    0.208104    -0.240205   -0.476177    -1.01282     -0.221066   -0.578882    0.121407    -0.152103
 -0.0157756    0.442143    -0.748716    0.127071     -0.309848     0.0307175    0.00854083    0.0667582  -0.11857    -0.155941    -0.358071    0.470455   -0.0519506    0.106704    0.269924    -0.0512918   0.790138    0.308619   -0.236665    -0.365562    0.501117     0.581361     0.0623016   0.512279   -0.29821      0.00414168
 -0.192945    -0.144257     0.303953    0.178814     -0.268058    -0.439121     0.523563     -0.080816   -0.390378   -0.586268    -0.0817183  -0.289541   -0.809954    -0.613049   -0.0972071   -0.235676    0.275183    0.441461   -0.483319     0.322427   -0.538131    -0.732176    -0.0420897   0.356356   -0.664198    -0.354313
 -0.00733532   0.173739    -0.0505448  -0.174493     -0.0555855   -0.0328413    0.0414925    -0.0438219   0.103338    0.0564838    0.0943007  -0.243127    0.0183239    0.145117   -0.0640593   -0.157309    0.0389097  -0.0453916   0.0590974    0.124568    0.115743    -0.00729343   0.147608   -0.0790568   0.116466    -0.181001
 -0.0777377   -0.27465     -0.137244   -0.265293     -0.127428     0.0894457   -0.348659     -0.116289    0.330856    0.451845     0.109031    0.0853844  -0.0973219    0.749108   -0.30291      0.970123    0.201901    0.133246    0.0865788   -0.393674    0.378641     0.0920859   -0.450543   -0.387837    0.573268     0.358549
 -0.24366     -0.0960998   -0.108691   -0.170196      0.279212    -0.0716788    0.344359     -0.0896244  -0.403434    0.188848    -0.138566    0.507364    0.0960146    0.204034    0.00175262   0.081021    0.213733    0.230942   -0.1529      -0.348708    0.00917922   0.509971    -0.0376964   0.213114   -0.209455     0.242084
  0.252853    -0.75016      0.517323   -0.426242      0.792648    -0.109553     0.0248348     0.151006    0.251675    0.617111     0.0702651  -0.0227859   0.00218233  -0.0713322  -0.0116514    0.414971    0.0776594   0.917287   -0.00152255   0.521778    0.100976     0.109527    -0.163749   -0.382613   -0.44496     -0.451849
  0.503214     0.147188    -0.155491    0.00223658    0.348598     0.0553458   -0.67548       0.0925652  -0.212783   -0.161055     0.190936    0.39968     0.73215     -0.116172    0.248302     0.36394    -0.27039    -0.16644    -0.178922    -0.0513542   0.0886608    0.319822     0.505993   -0.316529    0.351085     0.750461
  0.0966022   -0.133374    -0.13425    -0.106288     -0.121426     0.0349967   -0.0416153     0.0887577   0.109837    0.0223562    0.149215   -0.235478    0.00879659   0.0433759  -0.0502449   -0.144975   -0.175416   -0.166629    0.114452     0.0882653  -0.104539    -0.0425963   -0.0204817  -0.263588    0.0913385   -0.0684913
 -0.39753      0.289633     0.834754    0.377817     -0.267721     0.535255    -0.340941      0.203369    0.326991    0.455485     0.274891   -0.872214   -0.318391     0.409039   -0.422895    -0.356042   -0.77393    -0.0959446   0.0396691    0.497286   -0.570661    -1.11281     -0.235645   -0.284746    0.155236    -0.28444
 -0.589892    -0.331721     0.223289    0.424055      0.0493393   -0.926919    -0.453821     -0.110186   -0.401267   -0.397312     0.458144    0.230878    0.282044    -0.263903   -0.0810961    0.0525916  -0.424563    0.0660285  -0.135324    -0.404044   -0.633065    -0.153136     0.549936   -0.0703956  -0.0132885    0.425583
 -0.140101     0.280052     0.325771    0.000696698   0.738144    -0.208077     0.246045     -0.038696    0.0962872  -0.350744     0.163132   -0.667634    0.0963365    0.125868   -0.524826     0.162101   -0.116828    0.190354   -0.315653    -0.528493   -0.539926     0.159139    -0.194812    0.737375    0.319466    -0.589125
  0.126732    -0.283909     0.0390658  -0.0567838    -0.257102     0.0248622   -0.0637202    -0.140245    0.585648   -0.852746     0.0749528  -0.26221    -0.110723    -0.759898   -0.06198      0.337746   -0.392543   -0.0528587   0.00624451   0.370553    0.155536    -0.541533     0.315867   -0.29509     0.525443    -0.236976
  0.715359     0.438978    -0.302974   -0.662218     -0.289889    -0.255864    -0.447803     -0.55501    -0.134485    0.272415     0.0879481  -0.489587    0.467114    -0.127511   -0.270075    -0.33028    -0.141187   -0.124305    0.0855723   -0.478353    0.480161     0.441193     0.389502    0.351675   -0.179428     0.113504
 -0.680694     0.00713099  -0.431196   -0.693981      0.520485     0.284964     0.65582       0.278308   -0.304633   -0.417833    -0.324712    0.916029   -0.0722296    0.553415    0.0873422    0.083647   -0.133666    0.223447   -0.487336     0.353061    0.184785    -0.0679844    0.438099   -0.470693    0.11774     -0.179354[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413673
[ Info: iteration 2, average log likelihood -1.413666
[ Info: iteration 3, average log likelihood -1.413659
[ Info: iteration 4, average log likelihood -1.413653
[ Info: iteration 5, average log likelihood -1.413647
[ Info: iteration 6, average log likelihood -1.413641
[ Info: iteration 7, average log likelihood -1.413636
[ Info: iteration 8, average log likelihood -1.413631
[ Info: iteration 9, average log likelihood -1.413626
[ Info: iteration 10, average log likelihood -1.413621
┌ Info: EM with 100000 data points 10 iterations avll -1.413621
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
