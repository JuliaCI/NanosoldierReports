Julia Version 1.5.0-DEV.263
Commit d785bdc711 (2020-02-12 15:14 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed GaussianMixtures ─── v0.3.0
  Installed URIParser ────────── v0.4.0
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed Rmath ────────────── v0.6.0
  Installed Arpack ───────────── v0.4.0
  Installed FileIO ───────────── v1.2.2
  Installed Distributions ────── v0.22.4
  Installed SortingAlgorithms ── v0.3.1
  Installed DataAPI ──────────── v1.1.0
  Installed LegacyStrings ────── v0.4.1
  Installed NearestNeighbors ─── v0.4.4
  Installed StatsFuns ────────── v0.9.3
  Installed SpecialFunctions ─── v0.9.0
  Installed DataStructures ───── v0.17.9
  Installed StaticArrays ─────── v0.12.1
  Installed BinaryProvider ───── v0.5.8
  Installed Parameters ───────── v0.12.0
  Installed HDF5 ─────────────── v0.12.5
  Installed PDMats ───────────── v0.9.11
  Installed Missings ─────────── v0.4.3
  Installed QuadGK ───────────── v2.3.1
  Installed FillArrays ───────── v0.8.4
  Installed Distances ────────── v0.8.2
  Installed ScikitLearnBase ──── v0.5.0
  Installed BinDeps ──────────── v1.0.0
  Installed CMake ────────────── v1.2.0
  Installed StatsBase ────────── v0.32.0
  Installed Arpack_jll ───────── v3.5.0+2
  Installed Compat ───────────── v2.2.0
  Installed OrderedCollections ─ v1.1.0
  Installed Blosc ────────────── v0.5.1
  Installed JLD ──────────────── v0.9.2
  Installed CMakeWrapper ─────── v0.2.3
  Installed Clustering ───────── v0.13.3
#=#=#                                                                         ###############                                                           21.2%######################################################################## 100.0%
#=#=#                                                                         #                                                                          2.4%####                                                                       6.9%#########                                                                 13.5%################                                                          22.6%########################                                                  33.6%#################################                                         46.2%#############################################                             63.2%############################################################              84.0%######################################################################## 100.0%
#=#=#                                                                         ###############                                                           21.8%######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.2.0
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.2
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Building CMake → `~/.julia/packages/CMake/ULbyn/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_XJjV3S/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.2.0
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.2
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -3.2932737862823433e6, [9598.719974381524, 90401.28002561847], [-15897.562468971733 5867.005034219487 -490.67049732478415; 16210.733596295137 -6071.647316465658 367.9038003064287], [[28890.849757876495 -7129.713307470305 477.76005245341474; -7129.713307470305 12332.363756358867 -389.3966465549861; 477.76005245341474 -389.39664655498615 9614.471504429714], [70976.20869134035 7345.254701489704 -975.30881592812; 7345.254701489704 87587.46852327936 -71.59220273880229; -975.3088159281199 -71.5922027388024 90249.39774139696]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.857432e+03
      1       1.152979e+03      -7.044524e+02 |        8
      2       1.036042e+03      -1.169371e+02 |        4
      3       9.670064e+02      -6.903592e+01 |        0
      4       9.670064e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 967.0063588088005)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.066958
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.755933
[ Info: iteration 2, lowerbound -3.601812
[ Info: iteration 3, lowerbound -3.449198
[ Info: iteration 4, lowerbound -3.300021
[ Info: iteration 5, lowerbound -3.176052
[ Info: iteration 6, lowerbound -3.093881
[ Info: dropping number of Gaussions to 6
[ Info: iteration 7, lowerbound -3.039549
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.992736
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.934065
[ Info: iteration 10, lowerbound -2.867262
[ Info: iteration 11, lowerbound -2.797905
[ Info: iteration 12, lowerbound -2.729510
[ Info: iteration 13, lowerbound -2.665336
[ Info: iteration 14, lowerbound -2.604622
[ Info: dropping number of Gaussions to 3
[ Info: iteration 15, lowerbound -2.531011
[ Info: iteration 16, lowerbound -2.461129
[ Info: iteration 17, lowerbound -2.406031
[ Info: iteration 18, lowerbound -2.364101
[ Info: iteration 19, lowerbound -2.333301
[ Info: iteration 20, lowerbound -2.313576
[ Info: iteration 21, lowerbound -2.307422
[ Info: dropping number of Gaussions to 2
[ Info: iteration 22, lowerbound -2.302932
[ Info: iteration 23, lowerbound -2.299261
[ Info: iteration 24, lowerbound -2.299257
[ Info: iteration 25, lowerbound -2.299255
[ Info: iteration 26, lowerbound -2.299254
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Thu Feb 13 16:21:14 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Thu Feb 13 16:21:22 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Thu Feb 13 16:21:24 2020: EM with 272 data points 0 iterations avll -2.066958
5.8 data points per parameter
, Thu Feb 13 16:21:26 2020: GMM converted to Variational GMM
, Thu Feb 13 16:21:34 2020: iteration 1, lowerbound -3.755933
, Thu Feb 13 16:21:34 2020: iteration 2, lowerbound -3.601812
, Thu Feb 13 16:21:34 2020: iteration 3, lowerbound -3.449198
, Thu Feb 13 16:21:34 2020: iteration 4, lowerbound -3.300021
, Thu Feb 13 16:21:34 2020: iteration 5, lowerbound -3.176052
, Thu Feb 13 16:21:34 2020: iteration 6, lowerbound -3.093881
, Thu Feb 13 16:21:35 2020: dropping number of Gaussions to 6
, Thu Feb 13 16:21:35 2020: iteration 7, lowerbound -3.039549
, Thu Feb 13 16:21:35 2020: dropping number of Gaussions to 5
, Thu Feb 13 16:21:35 2020: iteration 8, lowerbound -2.992736
, Thu Feb 13 16:21:35 2020: dropping number of Gaussions to 4
, Thu Feb 13 16:21:35 2020: iteration 9, lowerbound -2.934065
, Thu Feb 13 16:21:35 2020: iteration 10, lowerbound -2.867262
, Thu Feb 13 16:21:35 2020: iteration 11, lowerbound -2.797905
, Thu Feb 13 16:21:35 2020: iteration 12, lowerbound -2.729510
, Thu Feb 13 16:21:35 2020: iteration 13, lowerbound -2.665336
, Thu Feb 13 16:21:35 2020: iteration 14, lowerbound -2.604622
, Thu Feb 13 16:21:35 2020: dropping number of Gaussions to 3
, Thu Feb 13 16:21:35 2020: iteration 15, lowerbound -2.531011
, Thu Feb 13 16:21:35 2020: iteration 16, lowerbound -2.461129
, Thu Feb 13 16:21:35 2020: iteration 17, lowerbound -2.406031
, Thu Feb 13 16:21:35 2020: iteration 18, lowerbound -2.364101
, Thu Feb 13 16:21:35 2020: iteration 19, lowerbound -2.333301
, Thu Feb 13 16:21:35 2020: iteration 20, lowerbound -2.313576
, Thu Feb 13 16:21:35 2020: iteration 21, lowerbound -2.307422
, Thu Feb 13 16:21:35 2020: dropping number of Gaussions to 2
, Thu Feb 13 16:21:35 2020: iteration 22, lowerbound -2.302932
, Thu Feb 13 16:21:35 2020: iteration 23, lowerbound -2.299261
, Thu Feb 13 16:21:35 2020: iteration 24, lowerbound -2.299257
, Thu Feb 13 16:21:35 2020: iteration 25, lowerbound -2.299255
, Thu Feb 13 16:21:35 2020: iteration 26, lowerbound -2.299254
, Thu Feb 13 16:21:35 2020: iteration 27, lowerbound -2.299253
, Thu Feb 13 16:21:35 2020: iteration 28, lowerbound -2.299253
, Thu Feb 13 16:21:35 2020: iteration 29, lowerbound -2.299253
, Thu Feb 13 16:21:35 2020: iteration 30, lowerbound -2.299253
, Thu Feb 13 16:21:35 2020: iteration 31, lowerbound -2.299253
, Thu Feb 13 16:21:35 2020: iteration 32, lowerbound -2.299253
, Thu Feb 13 16:21:35 2020: iteration 33, lowerbound -2.299253
, Thu Feb 13 16:21:35 2020: iteration 34, lowerbound -2.299253
, Thu Feb 13 16:21:35 2020: iteration 35, lowerbound -2.299253
, Thu Feb 13 16:21:35 2020: iteration 36, lowerbound -2.299253
, Thu Feb 13 16:21:35 2020: iteration 37, lowerbound -2.299253
, Thu Feb 13 16:21:35 2020: iteration 38, lowerbound -2.299253
, Thu Feb 13 16:21:35 2020: iteration 39, lowerbound -2.299253
, Thu Feb 13 16:21:35 2020: iteration 40, lowerbound -2.299253
, Thu Feb 13 16:21:35 2020: iteration 41, lowerbound -2.299253
, Thu Feb 13 16:21:35 2020: iteration 42, lowerbound -2.299253
, Thu Feb 13 16:21:35 2020: iteration 43, lowerbound -2.299253
, Thu Feb 13 16:21:35 2020: iteration 44, lowerbound -2.299253
, Thu Feb 13 16:21:35 2020: iteration 45, lowerbound -2.299253
, Thu Feb 13 16:21:35 2020: iteration 46, lowerbound -2.299253
, Thu Feb 13 16:21:35 2020: iteration 47, lowerbound -2.299253
, Thu Feb 13 16:21:35 2020: iteration 48, lowerbound -2.299253
, Thu Feb 13 16:21:35 2020: iteration 49, lowerbound -2.299253
, Thu Feb 13 16:21:35 2020: iteration 50, lowerbound -2.299253
, Thu Feb 13 16:21:35 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601672, 95.9549077739833]
β = [178.04509222601672, 95.9549077739833]
m = [4.250300733269887 79.28686694436149; 2.0002292577753464 53.85198717246116]
ν = [180.04509222601672, 97.9549077739833]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484297 -0.007644049042327728; 0.0 0.008581705166333033], [0.37587636119488244 -0.008953123827346643; 0.0 0.012748664777409454]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -0.987345906575517
avll from llpg:  -0.9873459065755162
avll direct:     -0.9873459065755164
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9833860993083767
avll from llpg:  -0.9833860993083768
avll direct:     -0.9833860993083768
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
 -0.0318874     0.0569872   -0.0315177   -0.0177605     0.0474515    -0.0854445    0.0712181   -0.0643076    0.0504075   -0.068038    -0.0746597    0.0269029   -0.10083     -0.063009    -0.0578494     0.170919     0.0128676    0.0949534   -0.0261812   -0.0034314    0.156126     0.0692928   -0.0722783   -0.129852    -0.00547819   -0.177427
 -0.147712     -0.0303323   -0.0167875    0.0144236    -0.0493144     0.17564     -0.130699     0.0530119    0.0910107    0.200508     0.0955637   -0.118133    -0.0230177   -0.170763     0.00740245   -0.310008     0.0306164    0.0577491    0.0323225    0.0488649    0.167378    -0.131658     0.134084    -0.095703    -0.0414662    -0.0491734
 -0.109687     -0.0839157   -0.0727859   -0.016354      0.0295709     0.0304549    0.0227624    0.128732     0.0828231   -0.140666     0.142247     0.00198359  -0.0863065   -0.00434817   0.08955       0.172922     0.0883884   -0.189436    -0.0231741    0.161312    -0.0527341    0.0182352    0.0994567    0.0710399   -0.094668     -0.0998368
  0.139949      0.0663365    0.0645089    0.145635      0.000422686   0.0250781   -0.0108402   -0.0827836    0.0358351    0.149758     0.124156    -0.0856759    0.158412    -0.0139696    0.155797      0.157106    -0.233491    -0.0762961    0.072298    -0.0396314    0.0119573   -0.00737835  -0.0199838    0.0111714   -0.137902     -0.104081
  0.032058      0.107485    -0.0187441   -0.0849776    -0.122914      0.100573    -0.0121475   -0.00346614   0.0181917    0.158062    -0.0969842    0.0504951    0.0377399    0.0514699    0.162321     -0.0733542    0.0458335   -0.00613384   0.0911477    0.036478     0.0934177   -0.124444     0.0773516    0.124431     0.21712      -0.0282521
 -0.0257649    -0.0328524    0.123252     0.0200912    -0.138226      0.133637    -0.0933116   -0.0397553    0.131552    -0.124475     0.0207428   -0.115917    -0.0304798    0.124067     0.0762582    -0.118982    -0.113405    -0.0940712    0.0393294   -0.257585    -0.113649    -0.111803    -0.135973    -0.0353643    0.00672288    0.137638
 -0.0749083    -0.0708154    0.00103787   0.234993     -0.0785094    -0.0889147   -0.0256963    0.0209717   -0.042204     0.0797309    0.00195467   0.148156    -0.12648      0.0216982    0.125258      0.10823      0.00253725   0.154501     0.0889442    0.088606    -0.0876746   -0.0945952    0.050659    -0.220433    -0.114195     -0.0228489
  0.148148     -0.0191171   -0.0972702   -0.20785      -0.0282541    -0.068582     0.0717655   -0.0103589    0.0526514   -0.00446469   0.169821    -0.173383    -0.143855     0.0530488   -0.0133027    -0.150854     0.138036    -0.0984422   -0.0376803    0.137542    -0.136903     0.0205125    0.10402      0.00704125   0.193991     -0.0507245
  0.0950865     0.00177081  -0.16304      0.0382744     0.0345492     0.0362512    0.196019     0.0709709   -0.043939    -0.102093    -0.0836171    0.136367    -0.0449131    0.0106818    0.152491      0.0667444   -0.0750188    0.0139807   -0.051956    -0.0165288    0.130396     0.15445      0.0380421    0.0296273   -0.0404516    -0.213665
 -0.052962      0.215038    -0.0565182    0.0144154    -0.00697514    0.0119473   -0.0685587    0.075076     0.0265746   -0.0257194    0.0708959   -0.00657417   0.0336604   -0.0230011   -0.182777     -0.038746     0.0105033   -0.117486    -0.0179904    0.15558     -0.219792    -0.0193709   -0.0360674   -0.139909     0.128771      0.0310816
 -0.0521154    -0.0392645    0.012673    -0.034781      0.141516     -0.102244    -0.00228865   0.00845842  -0.0453067   -0.0419828   -0.119575     0.0844371   -0.0854692    0.056364     0.0302669    -0.0450985    0.0718338   -0.0402425   -0.0731488    0.0920775   -0.0165327   -0.026543    -0.0680799   -0.02767      0.105408     -0.0442958
  0.121902      0.121162    -0.186783    -0.0229827    -0.0492539    -0.00701585  -0.102436    -0.0557003    0.0324583   -0.0615563   -0.100654     0.00620068  -0.20245     -0.160598     0.0975732     0.116662     0.0641643    0.0614041   -0.136757     0.0736804    0.0793298    0.00242404  -0.0407086    0.0488968    0.127225      0.0713475
  0.157189      0.0380141   -0.0738436    0.0793016    -0.15301      -0.00361971  -0.0676329   -0.0811108   -0.04333      0.107655    -0.213879     0.0333688   -0.0493129    0.147594     0.137299     -0.0553008    0.0505666   -0.141913     0.0544291    0.0502941    0.111038     0.187991    -0.00417335   0.089923    -0.0131741    -0.00996472
  0.0282468    -0.176659     0.0799976    0.169503     -0.0998125     0.056814    -0.13723      0.0371955    0.0317112   -0.18404     -0.0341786    0.00172585   0.0269371   -0.320476     0.0715442     0.0428775    0.138423     0.0245301   -0.0151795    0.0318837   -0.132007    -0.137428    -0.0281712   -0.0542788    0.123896     -0.0158462
  0.150387     -0.095063     0.0323308    0.000847207  -0.142498     -0.0601155   -0.197245    -0.063705    -0.0580739    0.0291377    0.036038    -0.0299956    0.0232596   -0.102826     0.0491172     0.0839985    0.027716     0.0952577   -0.0203343    0.121003     0.105156    -0.0635344    0.221757     0.0870833   -0.0744413     0.0558144
 -0.000480824   0.0553662    0.0127256    0.00277105   -0.175028      0.0800502    0.0180171   -0.0956546   -0.0204301   -0.0402635   -0.0673048   -0.00196865  -0.0381868    0.172241    -0.0733273    -0.171586    -0.0723903    0.0648437    0.0682038    0.0560378    0.0250588    0.173334    -0.211464    -0.0581077    0.137664     -0.066789
  0.0379092    -0.104457    -0.0820382   -0.0927419    -0.107928     -0.0749104    0.0136186    0.032298     0.00554684  -0.0238092    0.0613829   -0.106309     0.0715515    0.134815     0.172857     -0.00714819  -0.016432    -0.0494193   -0.006234    -0.11554     -0.0127402    0.0349203    0.00358572  -0.0996111   -0.00397209    0.268938
 -0.0877284     0.0570984    0.104704     0.0621845     0.0395676    -0.178214    -0.02477      0.0478947    0.0485442   -0.0135058    0.00679867   0.0603238   -0.0377378   -0.205225     0.0394172    -0.127619    -0.113075     0.0918474    0.0679329   -0.0711023    0.0146932   -0.020277     0.10448      0.0446941    0.0260157     0.0472657
  0.0306602     0.00655395   0.0483551    0.0292368     0.0931066     0.096626     0.0343708   -0.0312999    0.0156658   -0.173617    -0.087258     0.0686405    0.00136824  -0.00842639   0.0291129    -0.0655872    0.0454396   -0.0224318   -0.0682572   -0.0563073    0.0334349   -0.00173238  -0.0281905   -0.117931    -0.220957      0.0324986
 -0.0293805    -0.127929    -0.187327    -0.0489583    -0.0814772    -0.159307    -0.0454476    0.114044     0.133365     0.0115627   -0.0454337   -0.164308    -0.00642547   0.107089     0.0956835     0.131691    -0.00413507  -0.219036     0.106808    -0.172901    -0.0163287   -0.0338171    0.0403731   -0.0615864    0.0239721     0.0268708
  0.0307237    -0.0175736    0.0760028    0.0908867     0.177231      0.00680776   0.0594977    0.0984729    0.0822739   -0.0120293   -0.195479    -0.120606    -0.14675      0.080057     0.0333345    -0.100924    -0.0925732    0.00430679  -0.108205    -0.00419701  -0.141365    -0.0535316   -0.0766389    0.0193172   -0.0471757    -0.0147251
 -0.0965721     0.223612    -0.013616    -0.0550871     0.0620909    -0.0483931    0.0543796    0.0271136    0.00640592   0.0189005   -0.146862    -0.0423729    0.048047     0.0291264    0.203474     -0.12378     -0.126708    -0.12739     -0.0465628   -0.00402361   0.0695025   -0.0458512   -0.11715      0.0464321   -0.0384736     0.0705057
  0.13109       0.0498194   -0.168588    -0.243381     -0.0220139    -0.079866     0.0419737    0.14063     -0.0586305    0.216066    -0.00841335  -0.0580826   -0.0603102    0.0355196    0.000211284  -0.00907136   0.0151123    0.0195615   -0.0438064   -0.0351669   -0.0367492    0.16774     -0.0148832   -0.0835058    0.0297434     0.173031
 -0.122764     -0.0573918   -0.00488273   0.0041306     0.0739375     0.00284648   0.154087    -0.00531879   0.0694987    0.211685    -0.0777459    0.160359    -0.0227278    0.0488492   -0.18097      -0.111838     0.201218    -0.0423097    0.0680044   -0.142398    -0.0194949   -0.0883743    0.0214437    0.0632379   -0.141694      0.099981
 -0.100328      0.0562115   -0.172526     0.144204      0.0560386    -0.0625067   -0.119684     0.0917241   -0.207644    -0.133658    -0.0108811   -0.117962    -0.146215     0.0749279    0.0759132     0.030615     0.150578    -0.11247     -0.124303    -0.0521323    0.0182933    0.0401185   -0.131173     0.122827    -0.0762075    -0.035933
  0.00103926   -0.0423052   -0.0459325   -0.0983656    -0.0960682    -0.118481     0.100189     0.0675148    0.0905761    0.0264987    0.0116277   -0.262781     0.0706412   -0.0182448   -0.00897163    0.0949845   -0.176131    -0.0417186    0.203466     0.0652778   -0.0122519    0.0397362    0.0415526    0.0804681    0.0676596    -0.0518062
  0.122888      0.184628    -0.260448    -0.0375675    -0.176595      0.0629852   -0.0410098    0.0710388    0.213248    -0.0211734    0.0892062   -0.15999     -0.273253     1.12053e-5  -0.0317831    -0.131815    -0.0464605    0.0251353    0.110566     0.141932     0.0327202    0.12988      0.0837817   -0.0465839    0.072656     -0.0728456
 -0.0903113     0.0976693   -0.0955491    0.0457995    -0.128234     -0.118682     0.23999     -0.111099    -0.0437195    0.0290214    0.0797433    0.0403772   -0.185723    -0.039615    -0.108047      0.0497893   -0.0457774    0.0236343   -0.077109     0.0348848    0.105231    -0.074226    -0.0177328   -0.0310629    0.171015     -0.0943211
 -0.150446     -0.0861138    0.00501923  -0.183878      0.0537155    -0.0214705    0.169755     0.126286    -0.0309861   -0.024804    -0.00528555  -0.00505467   0.0331964    0.103417     0.1213       -0.0583005    0.139614     0.0235132   -0.00953182   0.130345    -0.158706     0.180581    -0.168008    -0.0278871   -0.0907488    -0.115117
  0.168238      0.0362609   -0.0935277   -0.130161     -0.171837      0.2237       0.0255101   -0.138061    -0.0991503   -0.0351165    0.0810274    0.0687392   -0.021867    -0.148628     0.0311327    -0.0806492   -0.0884308    0.0390761    0.119151    -0.0730789   -0.00527623   0.0815544   -0.0963097    0.110638    -0.0288376     0.0994157
  0.00917615    0.0315397    0.0618145   -0.122582      0.0764361     0.0389178   -0.00769683   0.114348     0.0942563    0.171718    -0.017761    -0.106006     0.0524053   -0.0586831    0.131964      0.148169    -0.0138375    0.0515551   -0.179308    -0.0543412   -0.0835628    0.160512    -0.0636771   -0.0999665   -0.000855695  -0.0856103
 -0.0195285    -0.0282522   -0.0894615    0.11753      -0.167026      0.0677601    0.128892     0.125284     0.00430672   0.102519    -0.129485    -0.195168    -0.0777275    0.0686166   -0.0889028    -0.0347711   -0.064955    -0.0453391    0.224058    -0.100456     0.0267121   -0.123735     0.13716     -0.033383    -0.0721536    -0.0970576kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4109044848014962
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410998
[ Info: iteration 2, average log likelihood -1.410902
[ Info: iteration 3, average log likelihood -1.410403
[ Info: iteration 4, average log likelihood -1.406124
[ Info: iteration 5, average log likelihood -1.395271
[ Info: iteration 6, average log likelihood -1.388417
[ Info: iteration 7, average log likelihood -1.386214
[ Info: iteration 8, average log likelihood -1.385178
[ Info: iteration 9, average log likelihood -1.384576
[ Info: iteration 10, average log likelihood -1.384198
[ Info: iteration 11, average log likelihood -1.383935
[ Info: iteration 12, average log likelihood -1.383729
[ Info: iteration 13, average log likelihood -1.383546
[ Info: iteration 14, average log likelihood -1.383357
[ Info: iteration 15, average log likelihood -1.383131
[ Info: iteration 16, average log likelihood -1.382850
[ Info: iteration 17, average log likelihood -1.382551
[ Info: iteration 18, average log likelihood -1.382296
[ Info: iteration 19, average log likelihood -1.382091
[ Info: iteration 20, average log likelihood -1.381927
[ Info: iteration 21, average log likelihood -1.381793
[ Info: iteration 22, average log likelihood -1.381681
[ Info: iteration 23, average log likelihood -1.381586
[ Info: iteration 24, average log likelihood -1.381500
[ Info: iteration 25, average log likelihood -1.381417
[ Info: iteration 26, average log likelihood -1.381327
[ Info: iteration 27, average log likelihood -1.381198
[ Info: iteration 28, average log likelihood -1.380944
[ Info: iteration 29, average log likelihood -1.380458
[ Info: iteration 30, average log likelihood -1.379759
[ Info: iteration 31, average log likelihood -1.379018
[ Info: iteration 32, average log likelihood -1.378340
[ Info: iteration 33, average log likelihood -1.377755
[ Info: iteration 34, average log likelihood -1.377322
[ Info: iteration 35, average log likelihood -1.377017
[ Info: iteration 36, average log likelihood -1.376805
[ Info: iteration 37, average log likelihood -1.376663
[ Info: iteration 38, average log likelihood -1.376570
[ Info: iteration 39, average log likelihood -1.376509
[ Info: iteration 40, average log likelihood -1.376469
[ Info: iteration 41, average log likelihood -1.376444
[ Info: iteration 42, average log likelihood -1.376427
[ Info: iteration 43, average log likelihood -1.376416
[ Info: iteration 44, average log likelihood -1.376409
[ Info: iteration 45, average log likelihood -1.376404
[ Info: iteration 46, average log likelihood -1.376401
[ Info: iteration 47, average log likelihood -1.376398
[ Info: iteration 48, average log likelihood -1.376396
[ Info: iteration 49, average log likelihood -1.376394
[ Info: iteration 50, average log likelihood -1.376393
┌ Info: EM with 100000 data points 50 iterations avll -1.376393
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4109977765499577
│     -1.4109023912887
│      ⋮
└     -1.3763930603491745
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.376530
[ Info: iteration 2, average log likelihood -1.376407
[ Info: iteration 3, average log likelihood -1.376036
[ Info: iteration 4, average log likelihood -1.373019
[ Info: iteration 5, average log likelihood -1.362201
[ Info: iteration 6, average log likelihood -1.352167
[ Info: iteration 7, average log likelihood -1.349035
[ Info: iteration 8, average log likelihood -1.347954
[ Info: iteration 9, average log likelihood -1.347328
[ Info: iteration 10, average log likelihood -1.346865
[ Info: iteration 11, average log likelihood -1.346468
[ Info: iteration 12, average log likelihood -1.346088
[ Info: iteration 13, average log likelihood -1.345698
[ Info: iteration 14, average log likelihood -1.345282
[ Info: iteration 15, average log likelihood -1.344840
[ Info: iteration 16, average log likelihood -1.344370
[ Info: iteration 17, average log likelihood -1.343873
[ Info: iteration 18, average log likelihood -1.343366
[ Info: iteration 19, average log likelihood -1.342860
[ Info: iteration 20, average log likelihood -1.342374
[ Info: iteration 21, average log likelihood -1.341930
[ Info: iteration 22, average log likelihood -1.341545
[ Info: iteration 23, average log likelihood -1.341222
[ Info: iteration 24, average log likelihood -1.340948
[ Info: iteration 25, average log likelihood -1.340708
[ Info: iteration 26, average log likelihood -1.340490
[ Info: iteration 27, average log likelihood -1.340287
[ Info: iteration 28, average log likelihood -1.340099
[ Info: iteration 29, average log likelihood -1.339926
[ Info: iteration 30, average log likelihood -1.339771
[ Info: iteration 31, average log likelihood -1.339633
[ Info: iteration 32, average log likelihood -1.339512
[ Info: iteration 33, average log likelihood -1.339405
[ Info: iteration 34, average log likelihood -1.339307
[ Info: iteration 35, average log likelihood -1.339221
[ Info: iteration 36, average log likelihood -1.339150
[ Info: iteration 37, average log likelihood -1.339091
[ Info: iteration 38, average log likelihood -1.339043
[ Info: iteration 39, average log likelihood -1.339002
[ Info: iteration 40, average log likelihood -1.338969
[ Info: iteration 41, average log likelihood -1.338940
[ Info: iteration 42, average log likelihood -1.338917
[ Info: iteration 43, average log likelihood -1.338898
[ Info: iteration 44, average log likelihood -1.338883
[ Info: iteration 45, average log likelihood -1.338870
[ Info: iteration 46, average log likelihood -1.338860
[ Info: iteration 47, average log likelihood -1.338852
[ Info: iteration 48, average log likelihood -1.338845
[ Info: iteration 49, average log likelihood -1.338839
[ Info: iteration 50, average log likelihood -1.338834
┌ Info: EM with 100000 data points 50 iterations avll -1.338834
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3765300103476552
│     -1.3764069952464284
│      ⋮
└     -1.3388338497924797
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.339011
[ Info: iteration 2, average log likelihood -1.338814
[ Info: iteration 3, average log likelihood -1.338168
[ Info: iteration 4, average log likelihood -1.332471
[ Info: iteration 5, average log likelihood -1.313671
[ Info: iteration 6, average log likelihood -1.297900
[ Info: iteration 7, average log likelihood -1.291593
[ Info: iteration 8, average log likelihood -1.288519
[ Info: iteration 9, average log likelihood -1.286584
[ Info: iteration 10, average log likelihood -1.285219
[ Info: iteration 11, average log likelihood -1.284262
[ Info: iteration 12, average log likelihood -1.283627
[ Info: iteration 13, average log likelihood -1.283211
[ Info: iteration 14, average log likelihood -1.282906
[ Info: iteration 15, average log likelihood -1.282622
[ Info: iteration 16, average log likelihood -1.282286
[ Info: iteration 17, average log likelihood -1.281869
[ Info: iteration 18, average log likelihood -1.281381
[ Info: iteration 19, average log likelihood -1.280908
[ Info: iteration 20, average log likelihood -1.280585
[ Info: iteration 21, average log likelihood -1.280433
[ Info: iteration 22, average log likelihood -1.280385
[ Info: iteration 23, average log likelihood -1.280369
[ Info: iteration 24, average log likelihood -1.280360
[ Info: iteration 25, average log likelihood -1.280353
[ Info: iteration 26, average log likelihood -1.280345
[ Info: iteration 27, average log likelihood -1.280336
[ Info: iteration 28, average log likelihood -1.280325
[ Info: iteration 29, average log likelihood -1.280312
[ Info: iteration 30, average log likelihood -1.280298
[ Info: iteration 31, average log likelihood -1.280281
[ Info: iteration 32, average log likelihood -1.280262
[ Info: iteration 33, average log likelihood -1.280241
[ Info: iteration 34, average log likelihood -1.280219
[ Info: iteration 35, average log likelihood -1.280198
[ Info: iteration 36, average log likelihood -1.280176
[ Info: iteration 37, average log likelihood -1.280155
[ Info: iteration 38, average log likelihood -1.280134
[ Info: iteration 39, average log likelihood -1.280113
[ Info: iteration 40, average log likelihood -1.280093
[ Info: iteration 41, average log likelihood -1.280073
[ Info: iteration 42, average log likelihood -1.280053
[ Info: iteration 43, average log likelihood -1.280033
[ Info: iteration 44, average log likelihood -1.280014
[ Info: iteration 45, average log likelihood -1.279995
[ Info: iteration 46, average log likelihood -1.279978
[ Info: iteration 47, average log likelihood -1.279962
[ Info: iteration 48, average log likelihood -1.279947
[ Info: iteration 49, average log likelihood -1.279934
[ Info: iteration 50, average log likelihood -1.279923
┌ Info: EM with 100000 data points 50 iterations avll -1.279923
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3390111602090418
│     -1.338813985423807
│      ⋮
└     -1.2799228272647112
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.280129
[ Info: iteration 2, average log likelihood -1.279892
[ Info: iteration 3, average log likelihood -1.279076
[ Info: iteration 4, average log likelihood -1.268637
[ Info: iteration 5, average log likelihood -1.233814
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.204550
[ Info: iteration 7, average log likelihood -1.207341
[ Info: iteration 8, average log likelihood -1.200558
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.188384
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.196324
[ Info: iteration 11, average log likelihood -1.201684
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.188586
[ Info: iteration 13, average log likelihood -1.196912
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.192412
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.190788
[ Info: iteration 16, average log likelihood -1.197917
[ Info: iteration 17, average log likelihood -1.193394
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.182370
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.198460
[ Info: iteration 20, average log likelihood -1.201373
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.188151
[ Info: iteration 22, average log likelihood -1.196139
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.191859
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.190439
[ Info: iteration 25, average log likelihood -1.197707
[ Info: iteration 26, average log likelihood -1.193301
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.182381
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.191593
[ Info: iteration 29, average log likelihood -1.198253
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.185674
[ Info: iteration 31, average log likelihood -1.194306
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.190031
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.188519
[ Info: iteration 34, average log likelihood -1.195869
[ Info: iteration 35, average log likelihood -1.191509
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.180744
[ Info: iteration 37, average log likelihood -1.199233
[ Info: iteration 38, average log likelihood -1.193540
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.182539
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.191661
[ Info: iteration 41, average log likelihood -1.197073
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.184677
[ Info: iteration 43, average log likelihood -1.193544
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.189532
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.188226
[ Info: iteration 46, average log likelihood -1.195670
[ Info: iteration 47, average log likelihood -1.191400
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.180686
[ Info: iteration 49, average log likelihood -1.199207
[ Info: iteration 50, average log likelihood -1.193515
┌ Info: EM with 100000 data points 50 iterations avll -1.193515
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2801292023757733
│     -1.279891996593667
│      ⋮
└     -1.1935150104527978
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.182782
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     13
│     14
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.180507
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.180118
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     13
│     14
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.156821
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│     20
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.109499
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     13
│     14
│     16
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.102328
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     10
│     18
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.075460
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     13
│     14
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.107404
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     16
│     20
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.077718
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     13
│     14
│     18
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.098617
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     10
│     20
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.075396
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     13
│     14
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.098894
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      8
│     16
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.065399
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     10
│     13
│     14
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.107638
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│     20
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.078281
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     13
│     14
│     16
│     18
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.090313
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      8
│     10
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.078327
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     13
│     14
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.104472
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     16
│     18
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.068045
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     10
│     13
│     14
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.101684
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      8
│     20
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.075563
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     13
│     14
│     16
│     18
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.093292
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     10
│     20
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.077659
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     13
│     14
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.096040
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     16
│     18
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.068230
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     13
│     14
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.100066
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     10
│     20
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.068651
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│     13
│     14
│     16
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.090528
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│     20
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.085049
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     13
│     14
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.092603
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│     10
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.058637
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      8
│     13
│     14
│     16
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.099966
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│     20
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.080130
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     13
│     14
│     18
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.088489
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│     10
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.066243
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     13
│     14
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.104722
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     18
│     20
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.068394
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     13
│     14
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.092168
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      5
│     10
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.063070
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     13
│     14
│     18
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.102949
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│     20
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.077636
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     13
│     14
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.087849
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│     10
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.055569
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     13
│     14
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.109023
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│     20
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.076404
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│     13
│     14
│     16
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.086267
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     10
│     20
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.079284
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     13
│     14
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.097705
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     18
│     20
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.064441
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      8
│     13
│     14
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.089432
┌ Info: EM with 100000 data points 50 iterations avll -1.089432
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1827818720347438
│     -1.1805065133034034
│      ⋮
└     -1.0894320912953046
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4109044848014962
│     -1.4109977765499577
│     -1.4109023912887
│     -1.4104031252274156
│      ⋮
│     -1.0977047114847156
│     -1.0644413287547576
└     -1.0894320912953046
32×26 Array{Float64,2}:
 -0.0544156    -0.122935    -0.186453    -0.0341148   -0.0815638   -0.165365   -0.0730664    0.112652     0.133853     0.019181    -0.0375278   -0.185         0.0211683   0.0919163    0.0939219    0.130278    -0.0218171  -0.225624    0.108598    -0.144706      0.00620037   -0.0346371    0.0329925   -0.0546734    0.0187757    0.0312558
  0.0413134    -0.0774335    0.0168633    0.10144     -0.109698    -0.0927322  -0.133522    -0.0154969   -0.0598437    0.0384411    0.0263328    0.0415549    -0.0385361  -0.0248327    0.0813457    0.112122     0.0222918   0.113326    0.0427659    0.118984      0.0270189    -0.0731039    0.15069     -0.112291    -0.0927128    0.0247945
 -0.0761436     0.0529698   -0.178776     0.133459     0.0599235   -0.0363895  -0.129539     0.11302     -0.20524     -0.126342    -0.0193558   -0.124153     -0.136769    0.0723217    0.0804763    0.0443024    0.165914   -0.110946   -0.124589    -0.0889804     0.0194516     0.0411839   -0.132428     0.131556    -0.0782578   -0.0308908
  0.15638       0.00497316  -0.100665     0.078336    -0.156752     0.0113576  -0.0696296   -0.0747177   -0.0525021    0.0997431   -0.205226     0.0020965    -0.10143     0.149576     0.14093     -0.0706527    0.0386514  -0.127405    0.0674935    0.0401624     0.102164      0.188369     0.00161463   0.0845301   -0.0156091   -0.00202909
 -0.0278748    -0.012378    -0.0885752    0.106913    -0.167867     0.0885811   0.111163     0.138135    -0.0137227    0.107676    -0.140284    -0.156062     -0.0703307   0.0680074   -0.0654869   -0.0290269   -0.0464178  -0.0110849   0.220037    -0.0999799     0.000996056  -0.163729     0.167817    -0.0247298   -0.114292    -0.090732
  0.0824614     0.0348462   -0.1532      -0.0722455   -0.135877    -0.0166235  -0.0270878    0.0268866    0.0961983   -0.0131707    0.0748176   -0.137696     -0.0925048   0.069963     0.0886763   -0.0702984   -0.0292853  -0.0446889   0.0525267    0.00561964    0.00349886    0.078805     0.0423036   -0.0682596    0.0293333    0.114065
 -0.0872999     0.0173902    0.0777656   -0.0815959   -0.0204899    0.0346412  -0.00590066   0.0471525    0.0467966   -0.0668646    0.0269335   -0.0555697     0.0282771   0.0891983    0.0232826   -0.0722555    0.0295985  -0.0801368   0.00840678   0.0024018    -0.160832      0.0261938   -0.118136    -0.0808965   -0.00185909   0.00728077
 -0.000180081   0.049207     0.028679     0.00872887  -0.171637     0.0937381   0.00513266  -0.0905855   -0.0279907   -0.0474569   -0.0587446    0.00175645   -0.0485711   0.18144     -0.028551    -0.168991    -0.0717982   0.0988086   0.0457784    0.0682622    -0.00205429    0.164008    -0.214291    -0.0678089    0.125613    -0.162063
 -0.0809263    -0.0129136    0.0210827    0.0384468    0.0980697    0.0487283   0.095186    -0.0229858    0.0180443    0.0119443   -0.0459993    0.105178     -0.0303315   0.0203272   -0.0782975   -0.0791176    0.129942    0.0165654   0.0120565   -0.118744     -0.0306662    -0.0520392    0.00764521  -0.0419827   -0.20148      0.0599537
  0.0101661    -0.172177     0.114672     0.168759    -0.113817     0.0580387  -0.0756705    0.0195709    0.0532143   -0.179364    -0.0353299    0.000879429   0.0311867  -0.3156       0.0748513    0.0454419    0.0743236   0.028603   -0.044487     0.0188826    -0.157758     -0.126944    -0.0278964   -0.0552137    0.137658    -0.0507746
 -0.00571792    0.0360753   -0.0719495   -0.0474733   -0.101876    -0.103386    0.087857     0.20661      0.0989815    0.0819397   -0.0334373   -0.274895      0.106727   -0.0172152   -0.0421485    0.0457483   -0.176251    0.0924444   0.260463     0.189667      0.0283863     0.0511282    0.219157     0.0847334    0.105664    -0.420604
 -0.0591935    -0.0545233   -0.0300964   -0.145516    -0.0777235   -0.0920325   0.0948734    0.00837859   0.0907222    0.00553985   0.106077    -0.264344      0.0360265  -0.0275667    0.00405398   0.141058    -0.197398   -0.142368    0.132641    -0.0995953    -0.0481817     0.0398646   -0.0490722    0.0806411    0.0111124    0.302724
 -0.105494      0.115182    -0.0943843    0.10071     -0.106133    -0.0434829   0.237306    -0.0978759   -0.0435362   -0.0416841    0.232735    -0.00461505   -0.152472    0.145906    -0.079858     0.184104    -0.0239994   0.0704993  -0.0772953    0.0375711     0.13127      -0.0769293    0.237771    -1.6479       0.117606    -0.0431299
 -0.0609188     0.0825088   -0.11099      0.0261782   -0.145451    -0.164864    0.239721    -0.1177      -0.0436839    0.0369625    0.0262451    0.0385036    -0.200229   -0.0635353   -0.120776     0.0401715   -0.0633801  -0.0027809  -0.0770025    0.0316807     0.0994934    -0.0756994   -0.225526     0.779098     0.165332    -0.106481
  0.0877687    -0.00648293  -0.147768     0.0442571    0.0414629    0.067682    0.176585     0.0755594   -0.0486527   -0.0803181   -0.128715     0.125901     -0.0452924   0.0258537    0.154922     0.0165118   -0.069213    0.0299379  -0.0487603    0.000289834   0.127171      0.149498     0.0512481    0.0313236   -0.0254659   -0.211769
 -0.0685735    -0.0789862   -0.0727747   -0.00338534   0.0367007    0.0242287   0.0208448    0.159025     0.069215    -0.140664     0.206152    -0.0103357    -0.0866086   0.00550148   0.0839575    0.167425     0.0964066  -0.176932   -0.0364555    0.158023     -0.0512274     0.0248562    0.0993724    0.0907348   -0.0895967   -0.09696
 -0.156863     -0.0403174   -0.0218421    0.0153795   -0.0561656    0.192257   -0.132649     0.0561737    0.0784148    0.209261     0.100112    -0.149741     -0.0240513  -0.169756     0.00882162  -0.311155     0.0256448   0.0227081   0.0218361    0.0594108     0.167454     -0.136665     0.135902    -0.0958374   -0.0438005   -0.0509209
  0.141666      0.0152057   -0.114839    -0.196028    -0.0299242   -0.0703801   0.0649781    0.00789036   0.0598067   -0.0172745    0.16339     -0.12264      -0.100184    0.0439401   -0.0291199   -0.143613     0.118081   -0.103965   -0.0267871    0.142628     -0.139593      0.0857403    0.100276    -0.00160451   0.183561    -0.0372388
  0.184245      0.0429163   -0.0834059   -0.063393    -0.168587     0.231433    0.0265654   -0.141135    -0.102965    -0.035902     0.0839965    0.083018     -0.0214998  -0.150855     0.0213131   -0.0798819   -0.105494    0.0309598   0.110348    -0.0736712    -0.00308298    0.0827252   -0.0971144    0.110031    -0.0416538    0.111929
  0.00586208    0.0518688    0.060882    -0.126164     0.0748178    0.0362335  -0.00859664   0.113893     0.100862     0.180736    -0.015451    -0.103377      0.0540724  -0.0544001    0.141557     0.0987675    0.0234557   0.0284816  -0.179233    -0.0535558    -0.0726875     0.156565    -0.0634418   -0.0999772   -0.0116865   -0.10878
  0.130949      0.056145    -0.107498    -0.117918    -0.0567345   -0.220503    0.0346233    0.143294    -0.0563679    0.208707     0.0541408   -0.0639719    -0.0444955   0.0195995   -0.00919186  -0.00641925   0.016764    0.0207073  -0.119589    -0.177186     -0.415011     -0.24063     -0.0590912   -0.0821715   -0.0181548    0.149288
  0.130976      0.0454012   -0.241324    -0.376573    -0.0527251   -0.0114131   0.0440323    0.113311    -0.057022     0.219119    -0.0654347   -0.0716534    -0.0567973   0.0261623   -0.0043561    0.00738609   0.0207363   0.0208984   0.0507288    0.0248895     0.283536      0.525027     0.0179796   -0.0798961    0.099281     0.19471
  0.0746669    -0.0695139   -0.189251    -0.015293    -0.0419457   -0.0020968  -0.171263    -0.0542257    0.00756774  -0.128572    -0.0877039   -0.0931196    -0.213898   -0.149581     0.0848686    0.103209     0.0616066   0.0832761  -0.150604     0.110733      0.0651545     0.00227002  -0.0798494    0.0491288    0.130419     0.101666
  0.167629      0.231919    -0.192168    -0.0216918   -0.0538893   -0.033556   -0.0481461   -0.0533208    0.0365497   -0.0366071   -0.0876953    0.128944     -0.174991   -0.149336     0.0772297    0.0952558    0.0615895  -0.0389156  -0.0995171    0.0391998     0.0666189    -0.00535083   0.0480961    0.0256386    0.130517     0.0336633
  0.0589912     0.0948815    0.00474261   0.0181598   -0.079771     0.0737495  -0.00309385  -0.010593     0.0365143    0.15404      0.0157441   -0.0590775     0.0921049   0.0127913    0.154258     0.0354886   -0.0891381  -0.0340256   0.0851517    0.00324635    0.0408789    -0.0983476    0.0418691    0.102323     0.025399    -0.0626602
 -0.0940015     0.266105    -0.0173232   -0.0518508    0.0365776   -0.0489893   0.0518105    0.0576581    0.0131268    0.0221182   -0.0864939   -0.0529663     0.0413887   0.0156402    0.177797    -0.135162    -0.119539   -0.127462   -0.0504725   -0.00369652    0.0351936    -0.0458684   -0.093064     0.0517812   -0.0486776    0.0805049
 -0.0886551     0.0580524    0.11106      0.0575124    0.0750627   -0.172333   -0.0248465    0.00283455   0.033082    -0.0130932    0.0570829    0.107313     -0.0424922  -0.21182      0.002136    -0.114879    -0.138172    0.104161    0.0705121   -0.0669757     0.037265     -0.0252517    0.105135     0.0428602    0.0244373    0.0537514
 -0.0329535     0.0803456   -0.0302886   -0.022814     0.0493201   -0.0972765   0.0719276   -0.0477484    0.0588138   -0.0588405   -0.0713175    0.0193548    -0.101002   -0.0573638   -0.0479336    0.169504     0.01565     0.0842395  -0.0430382   -0.00276114    0.161658      0.0604827   -0.0610243   -0.12759     -0.0174349   -0.170614
  0.0339926    -0.015072     0.0928446    0.0966958    0.150203     0.1161      0.0446697    0.0688857    0.0799851   -0.045958    -0.23281     -0.512363     -0.139416    0.0826148    0.0278654   -0.0696274   -0.120207   -0.0755537  -0.113941     0.0407977    -0.10017      -0.047955    -0.0640548    0.00678052   0.0368401    0.00132731
  0.102208     -0.031021     0.0538117    0.0819433    0.00336701  -0.0885085   0.0885199    0.215862     0.0841532    0.0118091   -0.166274     0.215464     -0.141328    0.071727     0.0549436   -0.0864609   -0.0628939   0.0636902  -0.102971    -0.033705     -0.174112     -0.0586927   -0.0912042    0.0354941   -0.119151    -0.0243854
 -0.0420136    -0.0368726    0.102412     0.0548268   -0.101624    -0.105683    0.0563215    0.00599055  -0.0311589   -0.176366    -0.211229     0.107826     -0.402731    0.228332     0.0281007   -0.01006     -0.0214423  -0.0465517  -0.0761099    0.0967529    -0.0300081    -0.0225627   -0.0654585    0.0366291    0.115456    -0.0724703
 -0.072289     -0.00299906  -0.0805248   -0.102468     0.470135    -0.0999556  -0.0390518    0.00847187  -0.0683526    0.0829551    0.00473968   0.0904929     0.277094   -0.106856     0.033387    -0.0800473    0.133475   -0.026948   -0.071206     0.0874487    -0.0131712    -0.0327606   -0.0906829   -0.0549603    0.101906    -0.0198577[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     10
│     20
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.077025
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│     10
│     13
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.060363
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     10
│     16
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.061241
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      5
│     10
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.061847
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     10
│     20
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.067128
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      8
│     10
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.055212
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     10
│     20
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.072672
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      5
│     10
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.058142
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     10
│     16
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.065589
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│     10
│     13
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.064008
┌ Info: EM with 100000 data points 10 iterations avll -1.064008
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.543303e+05
      1       6.862962e+05      -2.680341e+05 |       32
      2       6.598872e+05      -2.640893e+04 |       32
      3       6.419272e+05      -1.796001e+04 |       32
      4       6.301380e+05      -1.178923e+04 |       32
      5       6.244048e+05      -5.733162e+03 |       32
      6       6.215119e+05      -2.892916e+03 |       32
      7       6.195319e+05      -1.980030e+03 |       32
      8       6.180979e+05      -1.433931e+03 |       32
      9       6.170431e+05      -1.054840e+03 |       32
     10       6.162387e+05      -8.043970e+02 |       32
     11       6.154215e+05      -8.172002e+02 |       32
     12       6.143065e+05      -1.114970e+03 |       32
     13       6.126954e+05      -1.611148e+03 |       32
     14       6.107067e+05      -1.988683e+03 |       32
     15       6.088956e+05      -1.811082e+03 |       32
     16       6.079563e+05      -9.393077e+02 |       32
     17       6.075648e+05      -3.915173e+02 |       32
     18       6.073238e+05      -2.409651e+02 |       32
     19       6.071104e+05      -2.134815e+02 |       32
     20       6.068589e+05      -2.514468e+02 |       32
     21       6.066108e+05      -2.481399e+02 |       32
     22       6.064084e+05      -2.023920e+02 |       32
     23       6.062357e+05      -1.726300e+02 |       32
     24       6.060815e+05      -1.541976e+02 |       32
     25       6.059593e+05      -1.222027e+02 |       32
     26       6.058718e+05      -8.757412e+01 |       32
     27       6.057999e+05      -7.191481e+01 |       31
     28       6.057470e+05      -5.280715e+01 |       32
     29       6.056961e+05      -5.093495e+01 |       32
     30       6.056528e+05      -4.334080e+01 |       32
     31       6.056087e+05      -4.409687e+01 |       32
     32       6.055680e+05      -4.072208e+01 |       32
     33       6.055288e+05      -3.916759e+01 |       32
     34       6.054955e+05      -3.324052e+01 |       32
     35       6.054665e+05      -2.907507e+01 |       32
     36       6.054444e+05      -2.211314e+01 |       31
     37       6.054265e+05      -1.782738e+01 |       31
     38       6.054121e+05      -1.444607e+01 |       32
     39       6.054012e+05      -1.083341e+01 |       31
     40       6.053912e+05      -1.004651e+01 |       28
     41       6.053773e+05      -1.390075e+01 |       30
     42       6.053612e+05      -1.613103e+01 |       30
     43       6.053488e+05      -1.240608e+01 |       27
     44       6.053390e+05      -9.802421e+00 |       29
     45       6.053267e+05      -1.224365e+01 |       28
     46       6.053177e+05      -9.065454e+00 |       30
     47       6.053102e+05      -7.481938e+00 |       25
     48       6.053047e+05      -5.424521e+00 |       27
     49       6.052981e+05      -6.628974e+00 |       28
     50       6.052888e+05      -9.347564e+00 |       27
K-means terminated without convergence after 50 iterations (objv = 605288.7709613361)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.332520
[ Info: iteration 2, average log likelihood -1.308397
[ Info: iteration 3, average log likelihood -1.285466
[ Info: iteration 4, average log likelihood -1.260285
[ Info: iteration 5, average log likelihood -1.231998
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.185533
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.143724
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.115254
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      4
│      5
│     20
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.064677
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     15
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.157031
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     14
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.145212
[ Info: iteration 12, average log likelihood -1.138196
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     17
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.078690
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      4
│      5
│      6
│      ⋮
│     22
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.049899
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.187887
[ Info: iteration 16, average log likelihood -1.144817
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     18
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.091037
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.100366
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      5
│     11
│     17
│     20
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.083189
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.132846
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     14
│     15
│     18
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.108781
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.146947
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.108311
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     14
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.081336
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     15
│     20
│     21
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.073367
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.146304
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.126466
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      6
│     14
│     15
│     18
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.067414
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      9
│     11
│     17
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.095153
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.138265
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.117075
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│     11
│     14
│     15
│     18
│     21
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.070670
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.145126
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.111936
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.092416
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     14
│     15
│     18
│     21
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.081492
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      6
│      9
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.129104
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.134809
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     18
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.089527
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     14
│     20
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.091970
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      9
│     17
│     21
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.095724
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      6
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.119185
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     15
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.108713
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.104770
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      9
│     11
│     17
│      ⋮
│     21
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.068452
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.139542
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     15
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.112894
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.109323
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     11
│     17
│     18
│     21
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.065254
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      4
│      6
│     15
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.101586
┌ Info: EM with 100000 data points 50 iterations avll -1.101586
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0918007     0.266534    -0.0194824    -0.0579841   0.0388334  -0.0510086    0.0502459     0.0539283    0.0128665    0.0245265   -0.0902778   -0.0548374     0.0412364   0.0181057    0.178361     -0.135203    -0.115636    -0.125009     -0.0475559   -0.00354567   0.0315139   -0.0503563   -0.0952121    0.0489346   -0.046358     0.0807318
  0.146183      0.179584    -0.256303     -0.0362777  -0.173846    0.0885141   -0.0541384     0.0659749    0.182001     0.00297347   0.0753262   -0.164018     -0.273616    0.00173814  -0.0223447    -0.12617     -0.0580122    0.000371535   0.110154     0.140514     0.0372328    0.14804      0.0824251   -0.0535431    0.0682268   -0.0582506
 -0.0479485    -0.00110611   0.056426      0.0496105   0.0781261   0.0982829    0.0422571    -0.0310263   -0.0248708   -0.128886    -0.0442367    0.0386352    -0.03102    -0.0462376    0.0113892    -0.0964496    0.0576885    0.00973802   -0.0208797   -0.0971094    0.0153095   -0.0416431    0.013456    -0.116375    -0.164844     0.016616
  0.154904      0.0042602   -0.114867     -0.207997   -0.0283402  -0.0720524    0.0718517    -0.00204919   0.0359024   -0.0140606    0.174593    -0.137935     -0.102451    0.0500288   -0.0216405    -0.147731     0.12276     -0.107299     -0.0343591    0.149936    -0.148812     0.0825614    0.10287      0.013686     0.182636    -0.0269254
  0.0217225     0.107401    -0.0428581    -0.108715   -0.108375    0.10082     -0.00971545    0.0244991    0.00298883   0.150516    -0.0962404   -0.0572075     0.0286732   0.0439288    0.151808     -0.0732208    0.0488976   -0.00953274    0.0869442    0.0331299    0.0536297   -0.155483     0.0720042    0.136414     0.147398    -0.00610884
  0.00626386    0.0542892    0.0614291    -0.125634    0.0767979   0.0393666   -0.00826995    0.112784     0.100799     0.179941    -0.0167977   -0.104968      0.0560208  -0.0569121    0.142111      0.105055     0.0269698    0.0299467    -0.175228    -0.0529315   -0.0715993    0.15791     -0.0636308   -0.0932144   -0.00866061  -0.107546
 -0.0567053    -0.0206363    0.0129453    -0.0220032   0.176749   -0.102904     0.0101332     0.00716874  -0.0491837   -0.0503057   -0.106529     0.100232     -0.0722906   0.0651598    0.0304506    -0.0441254    0.0539553   -0.0370135    -0.073801     0.0921342   -0.0218742   -0.027619    -0.0774608   -0.00812133   0.108766    -0.0470985
 -0.0882168     0.0571178    0.112007      0.0586851   0.0790259  -0.172802    -0.0256808     0.00192932   0.0319197   -0.0111894    0.0540331    0.109698     -0.0434836  -0.212438     0.000602778  -0.111253    -0.136891     0.106116      0.0702419   -0.0684963    0.0398612   -0.0306493    0.10504      0.0442034    0.0237296    0.0570646
 -0.0310234     0.198514    -0.0835886    -0.0452124  -0.0457207   0.0148722   -0.0803101     0.0939928    0.0145786   -0.0250286    0.0406194   -0.00993144    0.0410895   0.00418881  -0.21792      -0.0379984    0.00110802  -0.235243      0.011085     0.158037    -0.204362    -0.0354917   -0.0177856   -0.134553     0.0988567    0.0689599
 -0.0271928    -0.0214212    0.0385477     0.0644374   0.0189662   0.0894031   -0.0171809     0.10694      0.0769151    0.0660777   -0.0732559   -0.155204     -0.0920015  -0.0236135    0.009037     -0.171357    -0.0407903   -0.00114905   -0.0481205    0.0379084   -0.0231316   -0.0803191    0.0026522   -0.0237766   -0.029231    -0.025811
  0.000258327  -0.176998     0.122621      0.159239   -0.0916448   0.0674986   -0.0944721     0.0560382    0.0775753   -0.125759    -0.0165303   -0.0128171     0.0413493  -0.232642     0.129121      0.0875687    0.0804037    0.0308633    -0.0792208    0.0369956   -0.184775    -0.104384    -0.0078596   -0.0851556    0.118777    -0.0650909
 -0.0311395    -0.00801712  -0.0534812    -0.0851844  -0.0855288  -0.0961026    0.0835746     0.105106     0.0910023    0.0408252    0.0306976   -0.264403      0.0684053  -0.0198172   -0.0257197     0.092294    -0.180888    -0.04635       0.202311     0.0416917   -0.0139986    0.0426911    0.085401     0.0826133    0.0631399   -0.0690655
  0.0836401    -0.0116905   -0.153503      0.0417079   0.045269    0.0742297    0.192328      0.0823293   -0.0474294   -0.0859095   -0.134641     0.130992     -0.0483786   0.0251206    0.155152      0.00949038  -0.0619391    0.042617     -0.0503768    0.0024399    0.130444     0.15202      0.0522797    0.0306584   -0.0201102   -0.21274
 -0.0742938     0.096095    -0.106507      0.0508149  -0.135204   -0.127276     0.238555     -0.114484    -0.0440251    0.011761     0.0894482    0.0247412    -0.186776    0.0031444   -0.109203      0.0898802   -0.0502497    0.0218206    -0.0787385    0.0336117    0.112896    -0.0755018   -0.077546     0.0119885    0.154727    -0.0895883
  0.120681      0.0865275   -0.192097     -0.0202195  -0.0488202  -0.0132368   -0.108192     -0.0528074    0.0210657   -0.0822703   -0.0886728    0.0178968    -0.1916     -0.149597     0.0779265     0.0985184    0.0613828    0.0288812    -0.122715     0.0754247    0.0666442   -0.00113681  -0.0178676    0.035918     0.130638     0.0666673
  0.122542     -0.0806923    0.0137636     0.0139487  -0.117441   -0.0982315   -0.19444      -0.0497621   -0.0772814   -0.0477107    0.0253281   -0.0562643     0.0149333  -0.0571233    0.0445231     0.101504     0.0438455    0.0766533    -0.013127     0.0952892    0.107755    -0.0570052    0.172416     0.0269583   -0.0545838    0.0506197
  0.0271799    -0.0961925   -0.0428359    -0.166534   -0.120937   -0.166762    -0.0151605    -0.0440805    0.00686801  -0.0481515    0.0521287   -0.105796      0.163311    0.0741586    0.250341     -0.0313294   -0.0196235   -0.0971609     0.011104    -0.159942    -0.0184075    0.0429084   -0.001327    -0.0969011    0.00591345   0.229297
  0.10288       0.047154    -0.195756     -0.305257   -0.0256221  -0.181012     0.0401773     0.136811    -0.0504028    0.211842     0.0202478   -0.0698448    -0.0609138   0.0276971   -0.011515     -0.00508733   0.0077143    0.0166244    -0.0664093   -0.0970854   -0.0743232    0.286059    -0.0370792   -0.0767902    0.0432304    0.179764
 -0.0399346     0.0667744   -0.0305139    -0.0262734   0.0400788  -0.0979519    0.0751094    -0.050967     0.0626799   -0.0651573   -0.0800179    0.0214801    -0.106259   -0.0582099   -0.0463848     0.170102     0.0222428    0.0947186    -0.0419042   -0.00330275   0.165748     0.0603786   -0.0658825   -0.127466    -0.0227986   -0.177704
  0.156681      0.0159633   -0.104477      0.0776962  -0.152626    0.0178028   -0.0693332    -0.0714767   -0.0565955    0.106012    -0.213577    -0.000122569  -0.0995555   0.148459     0.139439     -0.0674341    0.0397629   -0.122064      0.0610997    0.0369912    0.0968991    0.187651    -0.00156262   0.0902883   -0.0166203   -0.00908713
 -0.0815835     0.0167861   -0.1823        0.151237    0.0267689  -0.0488308   -0.138497      0.206501    -0.186541    -0.12463     -0.0165278   -0.126609     -0.154545    0.0447904    0.125995      0.0264799    0.209031    -0.111033     -0.149348    -0.110064     0.0497904    0.0253884   -0.0761156    0.137683    -0.0624282    0.00232981
 -0.113434     -0.0394644   -0.000881845   0.0172811   0.0848881  -0.00322125   0.135671     -0.00556754   0.069477     0.192352    -0.0312695    0.149089     -0.0209454   0.0477897   -0.177765     -0.0976798    0.196607     0.0149871     0.0594654   -0.145016    -0.0555261   -0.0917979    0.0200827    0.041122    -0.181739     0.098699
 -0.0417647    -0.00925318   0.160993      0.0379514  -0.110431    0.0774149   -0.114578     -0.0545481    0.106332    -0.119848     0.0244638   -0.115056     -0.0630831   0.110437     0.0743471    -0.105224    -0.0857346   -0.120475      0.0340947   -0.225368    -0.114542    -0.0870445   -0.133529    -0.0598278   -0.00604317   0.107596
 -0.0647959    -0.0706891   -0.00399136    0.23276    -0.0785568  -0.0855248   -0.0401842     0.027011    -0.0572926    0.122656     0.0102134    0.14827      -0.130918    0.00705362   0.12762       0.121003     0.010164     0.148585      0.0773228    0.0928512   -0.0842484   -0.0889079    0.0562771   -0.286744    -0.12165     -0.021195
  0.183667      0.0426172   -0.0833204    -0.0624086  -0.168569    0.23163      0.0264207    -0.140782    -0.103069    -0.0353159    0.0840168    0.0828411    -0.0216584  -0.150676     0.0221226    -0.0799404   -0.103174     0.0310513     0.110154    -0.0738107   -0.00323502   0.083223    -0.0970333    0.109024    -0.0412568    0.110769
 -0.159086     -0.0746643    0.00476524   -0.193571    0.0811148  -0.0204896    0.169311      0.128734    -0.0330357   -0.0326293   -0.00594541  -0.0294221     0.0844274   0.14738      0.133277     -0.0606575    0.169707     0.0119068    -0.00993073   0.12988     -0.158946     0.177156    -0.154516    -0.0243922   -0.108953    -0.120917
 -0.00484604    0.0325695    0.0454323     0.0141303  -0.18077     0.157738     0.0283725    -0.143855    -0.0268264   -0.058793    -0.0530591   -0.00296978   -0.0429316   0.142772    -0.0284159    -0.174414    -0.0638903    0.180369      0.102281     0.0745247    0.0340512    0.167007    -0.14677     -0.0677513    0.120352    -0.23099
  0.0634799     0.168795    -0.267742     -0.0325446  -0.164991    0.0442129   -0.0578157     0.052969     0.445875    -0.0823042    0.154469    -0.209236     -0.0957488  -0.0249127   -0.153807     -0.113925    -0.0183497    0.0712557     0.100482     0.136747    -0.00469943   0.188362     0.0842775   -0.0647923    0.0845262   -0.0827031
  0.00501498   -0.0959344   -0.0935868     0.0876041  -0.167009    0.0761152    0.105577      0.185262    -0.0196411    0.115748    -0.0788113   -0.182224     -0.0739895   0.0672565   -0.0258722    -0.0194401   -0.0581919   -0.0148219     0.158735    -0.171361     0.0287832   -0.276665     0.100477    -0.028891    -0.0985466    0.0555222
 -0.0762873    -0.0677659   -0.0754831     0.0129168   0.0403173   0.0346563   -0.00562481    0.149013     0.0431462   -0.125498     0.176103    -0.0260104    -0.0880164   0.00533245   0.080941      0.135388     0.098246    -0.168059     -0.0408208    0.156568    -0.034561     0.0281444    0.083852     0.100246    -0.0858236   -0.0845382
 -0.0539595    -0.121522    -0.187492     -0.0306813  -0.0796044  -0.177484    -0.0727794     0.110623     0.131626     0.0122985   -0.039456    -0.184508      0.0206567   0.0937846    0.0928314     0.128698    -0.0203413   -0.22399       0.107248    -0.145941     0.0098223   -0.0352184    0.0331821   -0.0517366    0.0164368    0.0327523
  0.122271      0.0985686    0.0478859     0.146107   -0.0588199   0.0381962   -0.000939906  -0.0532199    0.0566998    0.151039     0.120554    -0.0882156     0.15469    -0.0353568    0.154712      0.156196    -0.238069    -0.0711603     0.0719642   -0.0328621    0.0126546   -0.0100348    0.00284518   0.0335893   -0.132178    -0.104741[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.138242
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     14
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.089096
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      4
│      5
│      9
│     11
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.043687
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      5
│     14
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.098807
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.081136
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      4
│      5
│      6
│      9
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.026289
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     14
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.107120
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     20
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.070269
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      4
│      5
│      9
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.034457
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     14
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.107347
┌ Info: EM with 100000 data points 10 iterations avll -1.107347
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.178859    -0.279393     0.120618    -0.0286083    0.240507    -0.103752    -0.0380035    0.169232    -0.00445548   0.0254904    0.0508174   -0.0130604   -0.200301      0.128396    -0.0225723   -0.0558977    0.11568      0.00491041  -0.0461884    0.10847    -0.061978    -0.0223161    0.0512746   -0.0296964   0.097699    -0.131359
  0.0342118    0.125321    -0.00566576  -0.0828948    0.066413    -0.203743     0.099287     0.177254    -0.132308     0.0419238   -0.239376     0.133641     0.0556042     0.138787     0.0384946   -0.0221524    0.00361782  -0.113781     0.141302     0.0534299  -0.0518785    0.0755415    0.00521495  -0.161321   -0.0293064    0.0901876
 -0.188685     0.134398     0.0278578    0.143787     0.0216354   -0.19927     -0.0897318   -0.0346408   -0.0171394   -0.0875347   -0.144039    -0.175988     0.162591      0.0592761   -0.0835735    0.269801    -0.214389    -0.0262338    0.0598923   -0.008663   -0.0619617    0.0581007   -0.0649977    0.160831    0.0653382   -0.0876547
 -0.0197614   -0.179628     0.208875    -0.0785744    0.0166299    0.0580847    0.101823     0.0972689   -0.0500164   -0.0257955   -0.0411326    0.00102713   0.0556128     0.122812     0.196522    -0.0185421   -0.0952568    0.137598     0.200719     0.0286851  -0.172212     0.104486     0.186007    -0.0827715   0.100809    -0.0757215
 -0.183482    -0.0461048   -0.102543     0.0117651   -0.052729    -0.0914831    0.175242     0.0237684   -0.0485815   -0.0606933   -0.0284676   -0.0197295    0.230136     -0.0311735    0.0197624   -0.0698544   -0.00217454   0.162564     0.0621828    0.123211    0.0672282   -0.094218     0.0402647    0.0245498  -0.00555843   0.108578
  0.113374     0.0608392    0.178186     0.0733306    0.080195     0.024205    -0.0936137    0.0544521   -0.107486    -0.0959178    0.116781     0.0394822   -0.0537035    -0.211457     0.0741623   -0.0659583   -0.169122     0.0354102    0.05071     -0.0865185   0.220184     0.00778681   0.0371069    0.0370227   0.0750472    0.200538
  0.0229104    0.0811182   -0.0604118    0.0459281   -0.0240526   -0.0530694    0.0653245    0.0108738   -0.0557501   -0.00514466  -0.0228696   -0.166684    -0.0684841     0.142911    -0.0100573   -0.0306286   -0.0311387    0.116657     0.0004945   -0.0925946  -0.0111706   -0.0129004   -0.0756669   -0.0383064   0.0687122   -0.018804
  0.0221791    0.164165    -0.134055    -0.0270535   -0.0400993   -0.0389555   -0.0225284   -0.05157      0.0186811   -0.0155846   -0.124007     0.171953     0.202178     -0.0523811    0.165608     0.0627866    0.139419    -0.0271125    0.0788341   -0.0124352  -0.0254477   -0.0287167   -0.00707356   0.0880034   0.182213    -0.0262189
 -0.0395381    0.0666349    0.0773742    0.00397762   0.0496883    0.0332999   -0.0699882    0.0557952    0.0164548   -0.0860345   -0.140587     0.0899437    0.0674697    -0.0862725    0.0212824   -0.169045    -0.167862    -0.103963    -0.129366    -0.0414554  -0.122199     0.18987      0.0613679    0.0538602   0.115535     0.143599
  0.121649     0.0206983   -0.00211386   0.0776771    0.100686     0.048727     0.146734     0.212832    -0.0212191   -0.0839399   -0.0340086   -0.0189315   -0.129855     -0.142822     0.136752     0.0898044   -0.0837036    0.00805955  -0.0275508    0.0586167  -0.0281503   -0.0127996    0.00272346   0.0918745  -0.0645826    0.128202
  0.115163    -0.130519    -0.065979    -0.0420692   -0.0966809   -0.15838     -0.0943831    0.0622854    0.00159898   0.125455     0.130747    -0.103583     0.0937177    -0.0999799    0.0856677    0.0977676    0.108424    -0.0112388    0.0385612   -0.0047459   0.156664    -0.0960874    0.11209     -0.068687    0.00765246   0.00143861
 -0.0349291    0.0212749    0.142337    -0.111611    -0.102946    -0.0424155    0.0717924   -0.104076     0.0619334    0.12837     -0.00365699  -0.16277      0.21653      -0.00362782  -0.106032     0.0658911   -0.00582002  -0.126919    -0.043369    -0.111561    0.144795     0.0116427   -0.056693     0.16255     0.016841    -0.0402958
 -0.0698689    0.0991149    0.0558375    0.0264652   -0.0991777   -0.0504256    0.196358     0.0316425   -0.0115707   -0.0949991    0.0274163   -0.175167     0.0227092    -0.00555023   0.0914517   -0.0768002    0.00597286   0.103236     0.00471104  -0.153059    0.047743     0.191966    -0.0632819   -0.0979688   0.180093     0.183532
 -0.00788289  -0.0259293    0.00585194  -0.113916    -0.0321521    0.00708403   0.0270694   -0.00615658   0.0656828    0.168576    -0.0666082    0.0377463   -0.0904483     0.0715722    0.00463725  -0.13861      0.107643     0.0532529    0.150179     0.0648412   0.024516    -0.0122562   -0.0358729    0.0333295   0.298936     0.116524
 -0.169468     0.00404828   0.176772     0.102585    -0.0697513    0.0467913   -0.00881005  -0.0512737   -0.041795    -0.0162473   -0.0398826    0.027315     0.100344      0.0663909    0.135984    -0.0111992   -0.0320152    0.126369    -0.200146     0.0566532   0.0743419    0.1331       0.0101851    0.041583   -0.0844403   -0.183378
 -0.0504957    0.0881795   -0.131968    -0.0800381   -0.00425253   0.0805081   -0.117919     0.0851879   -0.0397276    0.172178     0.0281395    0.0523965   -0.011599     -0.0308856   -0.144318    -0.0323348    0.146624     0.0357694   -0.0319479   -0.221655    0.00161773  -0.0281198    0.149379     0.0917353   0.0159653   -0.144913
 -0.1433      -0.0833947   -0.083262     0.0148395    0.108893     0.157876    -0.0197806    0.117799    -0.0460543    0.0370441   -0.00930549   0.00544313   0.110253      0.100848     0.0494124   -0.154909    -0.145011    -0.00641856  -0.0181592   -0.01981     0.230933     0.08003     -0.0322948   -0.107973    0.144542    -0.037136
  0.0609039   -0.0646907    0.0500378    0.0798003    0.0555628   -0.0525976    0.0972675   -0.153584    -0.307658     0.241432    -0.00410905  -0.132988    -0.00446725    0.0485947    0.0396498   -0.0841203    0.120931     0.0900654   -0.135117    -0.0162191   0.142876     0.0720276   -0.0491312   -0.0346035  -0.0418381   -0.00422608
 -0.0358549   -0.12967      0.102335    -0.0380261   -0.0739391    0.183546     0.0764737   -0.123827     0.028601     0.0197676    0.150582     0.0779401   -0.00659314    0.12554      0.0182239    0.0113249   -0.0617809   -0.0277309    0.0527711    0.0255389  -0.00942236   0.0115489   -0.045211     0.12452    -0.137964     0.0584542
  0.00740887   0.0926083    0.0142815    0.0198503    0.0124876   -0.065071    -0.049078     0.0248695    0.23363      0.194486     0.036983     0.0254835   -0.121208      0.0358584    0.108121     0.00926071  -0.162399     0.0719633    0.0679193    0.101926   -0.157014     0.00845166  -0.00527882   0.0453079   0.00813132  -0.18096
 -0.00517079   0.0954205   -0.0075573    0.123847     0.129273    -0.00290512   0.010999    -0.0343445   -0.0765017    0.0073024    0.152226     0.00666589   0.0379722    -0.0117034   -0.0806869    0.0663431    0.0669413    0.0169492    0.0102187   -0.0721847   0.115445    -0.150074     0.201696    -0.0659216   0.0905332    0.0866241
  0.0311455   -0.0470631   -0.0969767    0.022026    -0.178955     0.277773    -0.0129391   -0.124926    -0.0863224   -0.0728778    0.0105508    0.0224717    0.00756865    0.0299332   -0.182971     0.0505175    0.00736206  -0.115973    -0.113692     0.0695831   0.214416     0.0825189    0.154932     0.0741105  -0.0832647   -0.155318
 -0.0431902   -0.00329415  -0.0706824   -0.0694984   -0.0225123    0.050828     0.00391     -0.092916    -0.0282444    0.0792675   -0.00356366   0.109175     0.105019     -0.0393642   -0.0423924   -0.0398942   -0.0345536    0.105232    -0.0187716    0.147439    0.0711504   -0.00764064   0.0303358    0.156666    0.0555273   -0.0886543
 -0.203281    -0.0569615    0.170735     0.207903    -0.0131902    0.0750294   -0.0466692   -0.195365    -0.0218049   -0.0128828    0.128859     0.023966     0.189373      0.0720335    0.043905    -0.041241    -0.0662971    0.0317233   -0.121479    -0.179781   -0.0752756    0.0588326   -0.0209793    0.100755    0.0529742   -0.116402
 -0.0170233    0.00367793  -0.0905376    0.0491433    0.0479972    0.0960023    0.0827061   -0.191973     0.0234001   -0.189978     0.0801861    0.106175     0.0931702    -0.14899      0.154819     0.120279    -0.010438     0.0423479    0.13478      0.117604    0.0425043    0.0871006   -0.088637     0.0555331  -0.0845253    0.0706233
  0.102975    -0.114992     0.0194844    0.0651359    0.166601    -0.121734     0.00904713   0.0764807   -0.104358    -0.0143168   -0.0400338   -0.0438953    0.000313567  -0.0371424   -0.0418184   -0.200907    -0.0385933   -0.241882    -0.0278507    0.0415157  -0.0376711   -0.0555867    0.0605535    0.0637655   0.0664936    0.210917
  0.0817581   -0.0473793   -0.0318582    0.204381    -0.0807368    0.0568818   -0.0528078    0.10115      0.105488    -0.122109     0.0434863   -0.114845     0.00442218   -0.0742107   -0.181837    -0.0539506    0.133969     0.0801931   -0.0792783   -0.0486101  -0.03754      0.0192883    0.125335     0.0593727  -0.065028    -0.0225027
 -0.0104406   -0.105124     0.0247694    0.155209     0.296182     0.184572    -0.0951504    0.0914474    0.00827562   0.0653861   -0.0181784    0.00190369   0.170872     -0.0563301    0.0319902   -0.0573059    0.181263    -0.134587    -0.0200127    0.0255415   0.0414848    0.145582     0.267276    -0.166143    0.0113771    0.0954188
 -0.0380125   -0.12214      0.0745453   -0.0965576    0.188719     0.0331019   -0.235988    -0.0766207    0.0877631   -0.143852     0.0173982   -0.280115     0.17465       0.0376366   -0.0182409   -0.162811     0.0235709    0.0687433   -0.0141637   -0.091719   -0.101319    -0.144323    -0.211747    -0.130942    0.0261842    0.0607644
  0.0778615   -0.0457175    0.0300577    0.195832     0.0671302    0.0921703   -0.168855    -0.113827    -0.0731619    0.15523      0.20573     -0.0670651    0.0688653    -0.16754      0.119221     0.0349461    0.0737144    0.0596124   -0.0517683   -0.0618016  -0.159714     0.164804    -0.10244     -0.144028   -0.0812838   -0.0363592
  0.0114416   -0.131235    -0.307794    -0.032579    -0.0926344   -0.0140007   -0.0540318    0.302088     0.0208112   -0.0978124   -0.0906533   -0.01091      0.0110639    -0.0470705    0.169776     0.0405877   -0.173634    -0.038283    -0.0822114   -0.0230909  -0.147109     0.119802    -0.0163943   -0.234171   -0.150795     0.0757159
 -0.0230871   -0.0961407   -0.122201     0.0736712    0.0154618   -0.0396534   -0.0526175    0.00872606   0.0853882   -0.223879     0.0949061    0.0654022    0.0364965     0.137853     0.0627498    0.156941     0.190669    -0.00106199  -0.119931     0.107895    0.0278175    0.048552    -0.0836487    0.0617356   0.03132     -0.142985kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.425527910935081
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425546
[ Info: iteration 2, average log likelihood -1.425474
[ Info: iteration 3, average log likelihood -1.425417
[ Info: iteration 4, average log likelihood -1.425350
[ Info: iteration 5, average log likelihood -1.425270
[ Info: iteration 6, average log likelihood -1.425174
[ Info: iteration 7, average log likelihood -1.425057
[ Info: iteration 8, average log likelihood -1.424900
[ Info: iteration 9, average log likelihood -1.424647
[ Info: iteration 10, average log likelihood -1.424193
[ Info: iteration 11, average log likelihood -1.423419
[ Info: iteration 12, average log likelihood -1.422353
[ Info: iteration 13, average log likelihood -1.421301
[ Info: iteration 14, average log likelihood -1.420594
[ Info: iteration 15, average log likelihood -1.420247
[ Info: iteration 16, average log likelihood -1.420104
[ Info: iteration 17, average log likelihood -1.420048
[ Info: iteration 18, average log likelihood -1.420026
[ Info: iteration 19, average log likelihood -1.420017
[ Info: iteration 20, average log likelihood -1.420014
[ Info: iteration 21, average log likelihood -1.420012
[ Info: iteration 22, average log likelihood -1.420011
[ Info: iteration 23, average log likelihood -1.420011
[ Info: iteration 24, average log likelihood -1.420010
[ Info: iteration 25, average log likelihood -1.420010
[ Info: iteration 26, average log likelihood -1.420010
[ Info: iteration 27, average log likelihood -1.420009
[ Info: iteration 28, average log likelihood -1.420009
[ Info: iteration 29, average log likelihood -1.420009
[ Info: iteration 30, average log likelihood -1.420009
[ Info: iteration 31, average log likelihood -1.420009
[ Info: iteration 32, average log likelihood -1.420009
[ Info: iteration 33, average log likelihood -1.420009
[ Info: iteration 34, average log likelihood -1.420009
[ Info: iteration 35, average log likelihood -1.420008
[ Info: iteration 36, average log likelihood -1.420008
[ Info: iteration 37, average log likelihood -1.420008
[ Info: iteration 38, average log likelihood -1.420008
[ Info: iteration 39, average log likelihood -1.420008
[ Info: iteration 40, average log likelihood -1.420008
[ Info: iteration 41, average log likelihood -1.420008
[ Info: iteration 42, average log likelihood -1.420008
[ Info: iteration 43, average log likelihood -1.420008
[ Info: iteration 44, average log likelihood -1.420008
[ Info: iteration 45, average log likelihood -1.420008
[ Info: iteration 46, average log likelihood -1.420008
[ Info: iteration 47, average log likelihood -1.420008
[ Info: iteration 48, average log likelihood -1.420008
[ Info: iteration 49, average log likelihood -1.420008
[ Info: iteration 50, average log likelihood -1.420008
┌ Info: EM with 100000 data points 50 iterations avll -1.420008
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4255462394723577
│     -1.4254744373335855
│      ⋮
└     -1.4200079147510452
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420023
[ Info: iteration 2, average log likelihood -1.419952
[ Info: iteration 3, average log likelihood -1.419892
[ Info: iteration 4, average log likelihood -1.419822
[ Info: iteration 5, average log likelihood -1.419740
[ Info: iteration 6, average log likelihood -1.419650
[ Info: iteration 7, average log likelihood -1.419560
[ Info: iteration 8, average log likelihood -1.419479
[ Info: iteration 9, average log likelihood -1.419412
[ Info: iteration 10, average log likelihood -1.419360
[ Info: iteration 11, average log likelihood -1.419321
[ Info: iteration 12, average log likelihood -1.419290
[ Info: iteration 13, average log likelihood -1.419264
[ Info: iteration 14, average log likelihood -1.419243
[ Info: iteration 15, average log likelihood -1.419224
[ Info: iteration 16, average log likelihood -1.419208
[ Info: iteration 17, average log likelihood -1.419194
[ Info: iteration 18, average log likelihood -1.419182
[ Info: iteration 19, average log likelihood -1.419170
[ Info: iteration 20, average log likelihood -1.419160
[ Info: iteration 21, average log likelihood -1.419150
[ Info: iteration 22, average log likelihood -1.419140
[ Info: iteration 23, average log likelihood -1.419131
[ Info: iteration 24, average log likelihood -1.419121
[ Info: iteration 25, average log likelihood -1.419112
[ Info: iteration 26, average log likelihood -1.419102
[ Info: iteration 27, average log likelihood -1.419092
[ Info: iteration 28, average log likelihood -1.419082
[ Info: iteration 29, average log likelihood -1.419071
[ Info: iteration 30, average log likelihood -1.419061
[ Info: iteration 31, average log likelihood -1.419050
[ Info: iteration 32, average log likelihood -1.419040
[ Info: iteration 33, average log likelihood -1.419029
[ Info: iteration 34, average log likelihood -1.419019
[ Info: iteration 35, average log likelihood -1.419009
[ Info: iteration 36, average log likelihood -1.418999
[ Info: iteration 37, average log likelihood -1.418990
[ Info: iteration 38, average log likelihood -1.418981
[ Info: iteration 39, average log likelihood -1.418973
[ Info: iteration 40, average log likelihood -1.418965
[ Info: iteration 41, average log likelihood -1.418958
[ Info: iteration 42, average log likelihood -1.418952
[ Info: iteration 43, average log likelihood -1.418946
[ Info: iteration 44, average log likelihood -1.418941
[ Info: iteration 45, average log likelihood -1.418937
[ Info: iteration 46, average log likelihood -1.418933
[ Info: iteration 47, average log likelihood -1.418929
[ Info: iteration 48, average log likelihood -1.418925
[ Info: iteration 49, average log likelihood -1.418922
[ Info: iteration 50, average log likelihood -1.418920
┌ Info: EM with 100000 data points 50 iterations avll -1.418920
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4200225723042386
│     -1.4199517004258548
│      ⋮
└     -1.4189195290895533
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418928
[ Info: iteration 2, average log likelihood -1.418867
[ Info: iteration 3, average log likelihood -1.418811
[ Info: iteration 4, average log likelihood -1.418743
[ Info: iteration 5, average log likelihood -1.418656
[ Info: iteration 6, average log likelihood -1.418550
[ Info: iteration 7, average log likelihood -1.418427
[ Info: iteration 8, average log likelihood -1.418295
[ Info: iteration 9, average log likelihood -1.418164
[ Info: iteration 10, average log likelihood -1.418045
[ Info: iteration 11, average log likelihood -1.417943
[ Info: iteration 12, average log likelihood -1.417858
[ Info: iteration 13, average log likelihood -1.417789
[ Info: iteration 14, average log likelihood -1.417735
[ Info: iteration 15, average log likelihood -1.417692
[ Info: iteration 16, average log likelihood -1.417658
[ Info: iteration 17, average log likelihood -1.417631
[ Info: iteration 18, average log likelihood -1.417608
[ Info: iteration 19, average log likelihood -1.417590
[ Info: iteration 20, average log likelihood -1.417573
[ Info: iteration 21, average log likelihood -1.417559
[ Info: iteration 22, average log likelihood -1.417547
[ Info: iteration 23, average log likelihood -1.417535
[ Info: iteration 24, average log likelihood -1.417524
[ Info: iteration 25, average log likelihood -1.417515
[ Info: iteration 26, average log likelihood -1.417505
[ Info: iteration 27, average log likelihood -1.417497
[ Info: iteration 28, average log likelihood -1.417489
[ Info: iteration 29, average log likelihood -1.417481
[ Info: iteration 30, average log likelihood -1.417474
[ Info: iteration 31, average log likelihood -1.417467
[ Info: iteration 32, average log likelihood -1.417460
[ Info: iteration 33, average log likelihood -1.417453
[ Info: iteration 34, average log likelihood -1.417447
[ Info: iteration 35, average log likelihood -1.417441
[ Info: iteration 36, average log likelihood -1.417436
[ Info: iteration 37, average log likelihood -1.417430
[ Info: iteration 38, average log likelihood -1.417425
[ Info: iteration 39, average log likelihood -1.417419
[ Info: iteration 40, average log likelihood -1.417414
[ Info: iteration 41, average log likelihood -1.417410
[ Info: iteration 42, average log likelihood -1.417405
[ Info: iteration 43, average log likelihood -1.417400
[ Info: iteration 44, average log likelihood -1.417396
[ Info: iteration 45, average log likelihood -1.417391
[ Info: iteration 46, average log likelihood -1.417387
[ Info: iteration 47, average log likelihood -1.417383
[ Info: iteration 48, average log likelihood -1.417379
[ Info: iteration 49, average log likelihood -1.417375
[ Info: iteration 50, average log likelihood -1.417371
┌ Info: EM with 100000 data points 50 iterations avll -1.417371
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4189280260450998
│     -1.4188673434966064
│      ⋮
└     -1.4173714290129222
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417378
[ Info: iteration 2, average log likelihood -1.417321
[ Info: iteration 3, average log likelihood -1.417271
[ Info: iteration 4, average log likelihood -1.417214
[ Info: iteration 5, average log likelihood -1.417144
[ Info: iteration 6, average log likelihood -1.417060
[ Info: iteration 7, average log likelihood -1.416960
[ Info: iteration 8, average log likelihood -1.416849
[ Info: iteration 9, average log likelihood -1.416730
[ Info: iteration 10, average log likelihood -1.416610
[ Info: iteration 11, average log likelihood -1.416494
[ Info: iteration 12, average log likelihood -1.416387
[ Info: iteration 13, average log likelihood -1.416290
[ Info: iteration 14, average log likelihood -1.416205
[ Info: iteration 15, average log likelihood -1.416132
[ Info: iteration 16, average log likelihood -1.416070
[ Info: iteration 17, average log likelihood -1.416018
[ Info: iteration 18, average log likelihood -1.415975
[ Info: iteration 19, average log likelihood -1.415939
[ Info: iteration 20, average log likelihood -1.415908
[ Info: iteration 21, average log likelihood -1.415882
[ Info: iteration 22, average log likelihood -1.415860
[ Info: iteration 23, average log likelihood -1.415840
[ Info: iteration 24, average log likelihood -1.415822
[ Info: iteration 25, average log likelihood -1.415806
[ Info: iteration 26, average log likelihood -1.415790
[ Info: iteration 27, average log likelihood -1.415776
[ Info: iteration 28, average log likelihood -1.415762
[ Info: iteration 29, average log likelihood -1.415749
[ Info: iteration 30, average log likelihood -1.415736
[ Info: iteration 31, average log likelihood -1.415723
[ Info: iteration 32, average log likelihood -1.415710
[ Info: iteration 33, average log likelihood -1.415697
[ Info: iteration 34, average log likelihood -1.415684
[ Info: iteration 35, average log likelihood -1.415671
[ Info: iteration 36, average log likelihood -1.415657
[ Info: iteration 37, average log likelihood -1.415644
[ Info: iteration 38, average log likelihood -1.415630
[ Info: iteration 39, average log likelihood -1.415616
[ Info: iteration 40, average log likelihood -1.415601
[ Info: iteration 41, average log likelihood -1.415587
[ Info: iteration 42, average log likelihood -1.415572
[ Info: iteration 43, average log likelihood -1.415557
[ Info: iteration 44, average log likelihood -1.415542
[ Info: iteration 45, average log likelihood -1.415527
[ Info: iteration 46, average log likelihood -1.415512
[ Info: iteration 47, average log likelihood -1.415497
[ Info: iteration 48, average log likelihood -1.415482
[ Info: iteration 49, average log likelihood -1.415468
[ Info: iteration 50, average log likelihood -1.415455
┌ Info: EM with 100000 data points 50 iterations avll -1.415455
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.41737763957553
│     -1.4173212282213714
│      ⋮
└     -1.4154545434836876
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415449
[ Info: iteration 2, average log likelihood -1.415374
[ Info: iteration 3, average log likelihood -1.415301
[ Info: iteration 4, average log likelihood -1.415215
[ Info: iteration 5, average log likelihood -1.415108
[ Info: iteration 6, average log likelihood -1.414978
[ Info: iteration 7, average log likelihood -1.414826
[ Info: iteration 8, average log likelihood -1.414660
[ Info: iteration 9, average log likelihood -1.414488
[ Info: iteration 10, average log likelihood -1.414319
[ Info: iteration 11, average log likelihood -1.414160
[ Info: iteration 12, average log likelihood -1.414013
[ Info: iteration 13, average log likelihood -1.413880
[ Info: iteration 14, average log likelihood -1.413762
[ Info: iteration 15, average log likelihood -1.413659
[ Info: iteration 16, average log likelihood -1.413569
[ Info: iteration 17, average log likelihood -1.413490
[ Info: iteration 18, average log likelihood -1.413422
[ Info: iteration 19, average log likelihood -1.413362
[ Info: iteration 20, average log likelihood -1.413310
[ Info: iteration 21, average log likelihood -1.413263
[ Info: iteration 22, average log likelihood -1.413221
[ Info: iteration 23, average log likelihood -1.413184
[ Info: iteration 24, average log likelihood -1.413150
[ Info: iteration 25, average log likelihood -1.413118
[ Info: iteration 26, average log likelihood -1.413090
[ Info: iteration 27, average log likelihood -1.413063
[ Info: iteration 28, average log likelihood -1.413038
[ Info: iteration 29, average log likelihood -1.413015
[ Info: iteration 30, average log likelihood -1.412994
[ Info: iteration 31, average log likelihood -1.412974
[ Info: iteration 32, average log likelihood -1.412955
[ Info: iteration 33, average log likelihood -1.412936
[ Info: iteration 34, average log likelihood -1.412919
[ Info: iteration 35, average log likelihood -1.412903
[ Info: iteration 36, average log likelihood -1.412887
[ Info: iteration 37, average log likelihood -1.412871
[ Info: iteration 38, average log likelihood -1.412856
[ Info: iteration 39, average log likelihood -1.412842
[ Info: iteration 40, average log likelihood -1.412827
[ Info: iteration 41, average log likelihood -1.412813
[ Info: iteration 42, average log likelihood -1.412799
[ Info: iteration 43, average log likelihood -1.412785
[ Info: iteration 44, average log likelihood -1.412771
[ Info: iteration 45, average log likelihood -1.412757
[ Info: iteration 46, average log likelihood -1.412743
[ Info: iteration 47, average log likelihood -1.412729
[ Info: iteration 48, average log likelihood -1.412715
[ Info: iteration 49, average log likelihood -1.412701
[ Info: iteration 50, average log likelihood -1.412686
┌ Info: EM with 100000 data points 50 iterations avll -1.412686
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4154491808020484
│     -1.4153742282558872
│      ⋮
└     -1.4126861488697557
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.425527910935081
│     -1.4255462394723577
│     -1.4254744373335855
│     -1.4254171780795464
│      ⋮
│     -1.4127150720341877
│     -1.4127007021919293
└     -1.4126861488697557
32×26 Array{Float64,2}:
 -0.510167    -0.157955   -0.227212     0.0814423  -0.039605   -0.0111113   -0.16018      0.894975    0.204857    0.163687   -0.834197     0.0895569  -0.0446399   -0.592076   -0.48552     -0.439654    -0.431082   -0.211808     -0.569879    -0.243629    -1.21658      0.183983    -0.410497     0.366363   -0.189838     0.095285
 -0.521584    -0.144317    0.270249     0.133513    0.340191    0.028248    -0.439963     0.568468    0.660023   -0.616521   -0.383654     0.184532    0.0677451    0.133366    0.155768    -0.0188155   -0.265123   -0.0921452    -0.0411909    0.390568    -0.390476     0.330514     0.0495009   -0.325696   -0.633444     0.228803
  0.0633628    0.205755    0.199216    -0.195156    0.377922   -0.122826    -0.368784     0.243505   -0.481402   -0.22002    -0.261473     0.0430826  -0.329837    -0.686629    0.0190017   -0.434011     0.25635     0.128664     -0.553739     0.429752    -0.279063     0.483149    -0.0915113    0.550808    0.578017     0.225027
  0.186596     0.12811    -0.259638    -0.0925916  -0.119747   -0.212049    -0.948973     0.032391   -0.357883   -0.500921   -0.174782    -0.0644905  -0.305575    -0.387239   -0.267912    -0.231333     0.216226    0.0610539     0.630788     0.253296    -0.575565    -0.0510192    0.123596    -0.140047   -0.119922     0.0360648
 -0.362766     0.154866   -0.176715     0.431264   -0.337646   -0.107655    -0.345194     0.118483   -0.331444    0.443391   -0.196994    -0.227619    0.00601574  -0.143927   -0.712583     0.359152    -0.515848    0.0354415     0.50199     -0.0738468    0.430516    -0.364126    -0.431471     0.618386    0.142494     0.641806
 -0.17996      0.0789361   0.0524389   -0.232058   -0.351602    0.207477    -0.401785     0.160529   -0.59548    -0.894193    0.0526208    0.709866   -0.167204     0.220407   -0.110797     0.374624     0.373743   -0.473699      0.265515    -0.0368513   -0.020847     0.00892053   0.10937     -0.32417     0.234175     0.131585
 -0.0812238    0.0349217   0.00445267  -0.0171069   0.0957152  -0.0159364    0.439683     0.138901    0.0530729   0.931542    0.00721634  -0.51857    -0.0750909    0.129018   -0.234416    -0.149766    -0.609116    0.570789      0.518094     0.106698     0.172994     0.384322     0.626888    -0.301859   -0.121555    -0.00794541
  0.0390898    0.344148    0.00399135  -0.296429    0.176558    0.395635     0.25746      0.260172   -0.490355    0.644223    0.175753    -0.196718   -0.152949     0.225601   -0.691521     0.128208     0.31161     0.301266      0.104763     0.00162582  -0.271276     0.346561    -0.125495    -0.245746    0.00520656  -0.438141
  0.0859197    0.0641044  -0.0187229    0.231514   -0.381443   -0.198151     0.284615    -0.620258    0.184825    0.384785    0.213172    -0.298855    0.142562    -0.549507    0.808196    -0.289381    -0.06245    -0.12671      -0.26337      0.354203     0.0415837   -0.169977     0.317519     0.0824671  -0.112486    -0.243079
  0.127661    -0.555058    0.157109     0.263867   -0.30245    -0.339603    -0.00387436  -0.41002     0.779588   -0.260282   -0.196561     0.169796    0.346903     0.739124    1.04536     -0.029712    -0.186665   -0.25303       0.226485     0.0130791    0.0756176   -0.341212     0.203226     0.607154   -0.0690926    0.158369
  0.24835     -0.366155    0.619082     0.370029   -0.381739   -0.20905     -0.333557    -0.49322     0.0985447  -0.631847    0.31062     -0.143402   -0.255447     0.0203646   0.0805218   -0.679005     0.350904    0.25491      -0.447431    -0.0703565   -0.30379     -0.928126     0.242564    -0.365547   -0.201297    -0.153092
  0.0372833   -0.448569    0.477464    -0.103531    0.313509    0.377839    -0.0491132   -0.774991   -0.206036   -0.371338    0.111796    -0.300815    0.287965     0.518166    0.363123    -0.758473     0.536407   -0.110716     -0.0583607    0.107488    -0.623306     0.625053     0.526488    -0.352663    0.0482276   -0.166387
 -0.868221    -1.04745    -0.207044     0.0722178   0.282083    0.0749262    0.0657153    0.411026    0.169687    0.410191    0.61406     -0.183484    0.879844    -0.974186   -0.344278    -0.546275    -0.380536    0.242765     -0.464801    -0.900325     1.07198      0.254692    -0.0526811    0.126166   -0.525698    -0.317252
 -0.317004     0.223053    0.139112     0.106555   -0.0207719   0.266725    -0.0228755   -0.242024   -0.482477    0.0400242   0.92298     -0.392832    0.89006     -0.411164   -0.322983     0.0361766   -0.0175673  -0.114471     -0.0117839   -0.822356     0.11582      0.167089    -0.549174     0.172527    0.362192    -0.225602
  1.04448     -0.04757    -0.305184    -0.209858   -0.271696   -0.335923     0.330197     0.111909    0.251582    0.600742    0.280844    -0.0548868   0.120046    -0.656245    0.0121474    0.220481    -0.28163     0.162043     -0.707557    -0.203789    -0.0578526   -0.329054    -0.446956     0.0891862   0.812403    -0.326292
  0.336815    -0.0149998   0.014989    -0.531235    1.48813    -0.00761634   0.297914     0.103104    0.340099   -0.432624   -0.128199    -0.0460103   0.202374     0.121818    0.107409    -0.178825    -0.0474213   0.192542     -0.298404    -0.34472      0.232234     0.601685    -0.36394     -0.0332461   0.183589    -0.134478
 -0.0170628   -0.118632   -0.0932354    0.0162048   0.112814   -0.141107     0.00244825  -0.0491765   0.111365   -0.0455581   0.172811    -0.15145     0.189328    -0.0777274   0.184075    -0.416278     0.110917   -0.0558723    -0.219676    -0.0304931    0.0985073    0.0188516   -0.0937587    0.0353646   0.144601    -0.0510856
 -0.054644    -0.0260818   0.110058     0.0703315  -0.0448868   0.130247    -0.0659222    0.0745628  -0.0469115  -0.101893   -0.0778637    0.162583   -0.0565204    0.137664    0.0671182    0.301519    -0.0735061   0.0425173     0.122446     0.0907166   -0.0204291   -0.0432748    0.113291    -0.0406041  -0.0394708    0.0757699
 -0.0625814    0.115648   -0.323806     0.272609   -0.409278    0.195772     0.293022    -0.554187   -0.485164   -0.054648   -0.114326    -0.0271971   0.205047    -0.512166   -0.254182     0.0340861   -0.243375   -0.63862      -0.0944671   -0.0603393    0.394685    -0.303257     0.0948706    0.292748    0.357249     0.202696
  0.0376537   -0.206616    0.293612    -0.163319   -0.310329    0.420098     0.0509304   -0.497345   -0.441101    0.397377    0.0902463   -0.0318587   0.0580905    0.234672    0.201312    -0.0389766    0.612483    0.169523      0.346496    -0.0785282    0.254631    -0.13509      0.507898     0.463133    0.34459      0.160904
 -0.492641    -0.510926    0.0856079    0.338229    0.0871285   0.367455    -0.692975     0.206828   -0.547669   -0.441322    0.00888542  -0.264107   -0.197606     0.531202   -0.735731     0.263294     0.180651   -0.000459178   0.313103    -0.48968      0.05029      0.149692    -0.22072      0.025196   -0.419009     0.267478
  0.303284    -0.361266    0.0756291   -0.215919    0.170754    0.480827    -0.46979      0.515271    0.411606   -0.115083   -0.272476     0.0182354  -0.0556264    0.654299   -0.385641     0.165848     0.312503    0.172493      0.182026    -0.41228     -0.185424     0.0952206   -0.151487     0.360469   -0.07864      0.195144
 -0.00878209  -0.320451    0.261255    -0.235936    0.186823    0.233752     0.576595     0.378455    0.203128    0.16432     0.334137     0.342918    0.146845     0.504687   -0.132424     0.231822     0.0276866  -0.114068     -0.753768    -0.270957     0.730812     0.108153    -0.268356     0.106566    0.00359977   0.00276274
 -0.0214114   -0.228321   -0.064595    -0.205583    0.139935    0.0380529    0.739354    -0.329139    0.200342    0.063856    0.31448      0.0584786   0.411897     0.643362    0.00424778   0.367066     0.0341627  -0.266651      0.601021    -0.484226     0.734707    -0.290455     0.337892    -0.388988   -0.0946917    0.397102
 -0.61456      0.365355   -0.29873      0.112018   -0.0483487  -0.54862      0.139674     0.017837   -0.0911009  -0.362197    0.264862    -0.0802129   0.0369287   -0.493668    0.489226     0.233545    -0.251944   -0.079929      0.130469     0.334994     0.00779295   0.0389463    0.00780336  -0.691061   -0.33231     -0.248042
  0.57252      0.456673    0.412877    -0.19697    -0.282827    0.329726     0.193035    -0.26606     0.186723   -0.304439    0.201309     0.269686    0.309452    -0.246295    0.647855     0.0761801   -0.278085   -0.482793     -0.0413722    0.322998     0.00227373   0.213282     0.708953    -0.481401    0.0138022   -0.405082
  0.0331622    0.211947   -0.00410097   0.370956    0.0931887  -0.251309     0.199806     0.437386    0.188845    0.129849   -0.166932    -0.460756    0.0695259   -0.129743   -0.0967791   -0.0357484   -0.126007    0.267515     -0.252645     0.084563    -0.154731    -0.338472    -0.383275    -0.447571   -0.441093    -0.455517
  0.0786875    0.419156   -0.121062    -0.343856    0.184772    0.0496326    0.174892     0.15985    -0.420133    0.295237   -0.0106273   -0.135967    0.0467357    0.152408   -0.371252     0.065301     0.134077    0.190243      0.11982     -0.105915    -0.273089     0.706166    -0.168822    -0.267634    0.145895    -0.441501
 -0.0293311   -0.411399   -0.8946      -0.234413   -0.0300685  -0.540708     0.020806     0.314825   -0.0682959  -0.0531427  -0.394644     0.125208    0.130975     0.206849    0.352031    -0.286884     0.0240373   0.429016      0.200359     0.0464878    0.640318    -0.0654982    0.0413426    0.134224    0.626213     0.330001
 -0.173963     0.177101   -0.73538      0.834798    0.0645657  -0.0283474   -0.293612     0.0458565   0.269545    0.0841965  -0.337737     0.455523    0.145176     0.401277    0.512749     0.257548     0.145919   -0.30606      -0.00394012   0.0906271   -0.27068     -0.0567353   -0.152221     0.199116    0.848886     0.0862144
  0.0859306    0.257338    0.275826    -0.0517111   0.020917   -0.302167     0.295026     0.317016    0.475486    0.278037   -0.321652     0.312198   -0.661518    -0.0390369   0.0728417    0.304122    -0.182152    0.0274737     0.00324468   0.5027       0.0662093   -0.238533     0.493333     0.275921   -0.329537     0.320877
  0.0498229   -0.18922     0.205645     0.645808    0.204135   -0.0356245   -0.197538    -0.35563     0.484893    0.520113    0.322581     0.0162698   0.0606992   -0.505353    0.403622    -0.00679908  -0.501212    0.396236     -0.415608     0.230358     0.0248212    0.0520897   -0.339816     0.586347   -0.0817341    0.253914[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412671
[ Info: iteration 2, average log likelihood -1.412656
[ Info: iteration 3, average log likelihood -1.412641
[ Info: iteration 4, average log likelihood -1.412626
[ Info: iteration 5, average log likelihood -1.412610
[ Info: iteration 6, average log likelihood -1.412595
[ Info: iteration 7, average log likelihood -1.412579
[ Info: iteration 8, average log likelihood -1.412563
[ Info: iteration 9, average log likelihood -1.412547
[ Info: iteration 10, average log likelihood -1.412532
┌ Info: EM with 100000 data points 10 iterations avll -1.412532
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.189732e+05
      1       7.117951e+05      -2.071781e+05 |       32
      2       6.966814e+05      -1.511365e+04 |       32
      3       6.913163e+05      -5.365090e+03 |       32
      4       6.885311e+05      -2.785226e+03 |       32
      5       6.865979e+05      -1.933264e+03 |       32
      6       6.852138e+05      -1.384050e+03 |       32
      7       6.841401e+05      -1.073712e+03 |       32
      8       6.832532e+05      -8.868817e+02 |       32
      9       6.824990e+05      -7.542641e+02 |       32
     10       6.818621e+05      -6.368610e+02 |       32
     11       6.813085e+05      -5.536272e+02 |       32
     12       6.808114e+05      -4.970607e+02 |       32
     13       6.803781e+05      -4.333156e+02 |       32
     14       6.799846e+05      -3.935121e+02 |       32
     15       6.796396e+05      -3.449812e+02 |       32
     16       6.793017e+05      -3.379225e+02 |       32
     17       6.790095e+05      -2.921893e+02 |       32
     18       6.787600e+05      -2.494843e+02 |       32
     19       6.785205e+05      -2.394814e+02 |       32
     20       6.783244e+05      -1.960704e+02 |       32
     21       6.781446e+05      -1.798886e+02 |       32
     22       6.779705e+05      -1.740755e+02 |       32
     23       6.778055e+05      -1.649708e+02 |       32
     24       6.776509e+05      -1.546475e+02 |       32
     25       6.775088e+05      -1.420247e+02 |       32
     26       6.773754e+05      -1.334243e+02 |       32
     27       6.772337e+05      -1.417517e+02 |       32
     28       6.770948e+05      -1.388263e+02 |       32
     29       6.769811e+05      -1.136923e+02 |       32
     30       6.768855e+05      -9.559923e+01 |       32
     31       6.767943e+05      -9.122300e+01 |       32
     32       6.767144e+05      -7.988048e+01 |       32
     33       6.766417e+05      -7.277020e+01 |       32
     34       6.765704e+05      -7.128127e+01 |       32
     35       6.765014e+05      -6.897747e+01 |       32
     36       6.764300e+05      -7.139832e+01 |       32
     37       6.763493e+05      -8.075910e+01 |       32
     38       6.762757e+05      -7.356774e+01 |       32
     39       6.762026e+05      -7.306919e+01 |       32
     40       6.761263e+05      -7.631327e+01 |       32
     41       6.760443e+05      -8.200165e+01 |       32
     42       6.759608e+05      -8.347383e+01 |       32
     43       6.758892e+05      -7.165902e+01 |       32
     44       6.758265e+05      -6.268270e+01 |       32
     45       6.757666e+05      -5.987020e+01 |       32
     46       6.757067e+05      -5.995461e+01 |       32
     47       6.756495e+05      -5.719856e+01 |       32
     48       6.755943e+05      -5.517435e+01 |       32
     49       6.755382e+05      -5.604904e+01 |       32
     50       6.754851e+05      -5.314314e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 675485.0977758411)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423947
[ Info: iteration 2, average log likelihood -1.419065
[ Info: iteration 3, average log likelihood -1.417812
[ Info: iteration 4, average log likelihood -1.416938
[ Info: iteration 5, average log likelihood -1.416029
[ Info: iteration 6, average log likelihood -1.415118
[ Info: iteration 7, average log likelihood -1.414388
[ Info: iteration 8, average log likelihood -1.413920
[ Info: iteration 9, average log likelihood -1.413645
[ Info: iteration 10, average log likelihood -1.413472
[ Info: iteration 11, average log likelihood -1.413348
[ Info: iteration 12, average log likelihood -1.413251
[ Info: iteration 13, average log likelihood -1.413169
[ Info: iteration 14, average log likelihood -1.413098
[ Info: iteration 15, average log likelihood -1.413035
[ Info: iteration 16, average log likelihood -1.412978
[ Info: iteration 17, average log likelihood -1.412926
[ Info: iteration 18, average log likelihood -1.412878
[ Info: iteration 19, average log likelihood -1.412834
[ Info: iteration 20, average log likelihood -1.412793
[ Info: iteration 21, average log likelihood -1.412755
[ Info: iteration 22, average log likelihood -1.412719
[ Info: iteration 23, average log likelihood -1.412685
[ Info: iteration 24, average log likelihood -1.412653
[ Info: iteration 25, average log likelihood -1.412623
[ Info: iteration 26, average log likelihood -1.412594
[ Info: iteration 27, average log likelihood -1.412567
[ Info: iteration 28, average log likelihood -1.412542
[ Info: iteration 29, average log likelihood -1.412518
[ Info: iteration 30, average log likelihood -1.412495
[ Info: iteration 31, average log likelihood -1.412474
[ Info: iteration 32, average log likelihood -1.412453
[ Info: iteration 33, average log likelihood -1.412434
[ Info: iteration 34, average log likelihood -1.412417
[ Info: iteration 35, average log likelihood -1.412400
[ Info: iteration 36, average log likelihood -1.412384
[ Info: iteration 37, average log likelihood -1.412369
[ Info: iteration 38, average log likelihood -1.412355
[ Info: iteration 39, average log likelihood -1.412341
[ Info: iteration 40, average log likelihood -1.412329
[ Info: iteration 41, average log likelihood -1.412317
[ Info: iteration 42, average log likelihood -1.412306
[ Info: iteration 43, average log likelihood -1.412295
[ Info: iteration 44, average log likelihood -1.412285
[ Info: iteration 45, average log likelihood -1.412275
[ Info: iteration 46, average log likelihood -1.412266
[ Info: iteration 47, average log likelihood -1.412257
[ Info: iteration 48, average log likelihood -1.412249
[ Info: iteration 49, average log likelihood -1.412241
[ Info: iteration 50, average log likelihood -1.412234
┌ Info: EM with 100000 data points 50 iterations avll -1.412234
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.561303   -0.109434   -0.00391442   0.0608201   -0.245331     0.124505    -0.530237   -0.207526   -0.276587    -0.303194      0.744968    -0.375067    1.03323     -0.426106   -0.247466    -0.285489     0.136206    0.126045   -0.00469649  -1.12953      0.194802    -0.0650713  -0.271923    0.104129     0.337585    -0.100202
  0.125452    0.0158476   0.367637     0.168552     0.365458    -0.167035     0.370777    0.191401    0.31985     -0.233518     -0.0576132   -0.543915   -0.135446     0.0675537   0.1282      -0.153976     0.065955    0.178499   -0.404508     0.179541    -0.418429    -0.0323413  -0.146579   -0.759298    -0.790017    -0.574566
 -0.0527244  -0.559026    0.0538405    0.242192    -0.135104    -0.430663    -0.169687   -0.445845    0.831793    -0.400154     -0.100413     0.373105    0.277315     0.575117    1.36068     -0.181305     0.15331    -0.475975    0.0459122    0.0586304   -0.0379769   -0.104518    0.13354     0.417906    -0.354233     0.162489
 -0.443138    0.038908    0.4453       0.0995617    0.0725694    0.0959932    0.157591    0.425677    0.408112     0.223565     -0.335577     0.179421    0.165661     0.55208     0.00542613   0.22147     -0.0820577   0.303574   -0.0869261   -0.00738588  -0.353659     0.204408   -0.203517    0.355103    -0.378337     0.135305
  0.402379    0.499926    0.555814    -0.0664729   -0.340073     0.239117    -0.549312   -0.111316   -0.722451    -1.07675       0.411374     0.693953   -0.149294     0.110541    0.191816     0.468436     0.464763   -0.621929   -0.178318     0.228737    -0.155554    -0.0768526  -0.0907167  -0.270153     0.333157    -0.102118
  0.207973   -0.200587    0.0248131   -0.0796293    0.318481     0.553543     0.19928    -0.565368   -0.51345      0.107194      0.1178      -0.394881    0.533299     0.581216    0.0184945   -0.528312     0.56636    -0.0500923  -0.0152047   -0.168937    -0.470932     0.668939    0.081403   -0.311072     0.146593    -0.380065
  0.0303022   0.0739733  -0.313381    -0.0495838    0.0959299   -0.380607     0.366813    0.556551    0.0905658   -0.33462       0.115903     0.129531    0.434217    -0.263185   -0.102213    -0.158168    -0.197647   -0.474427   -0.505106    -0.0483207    0.440413    -0.137608   -0.689056   -0.404744     0.275449     0.152548
 -0.214966   -0.131362    0.743322     0.527315    -0.102656    -0.168675    -0.229406   -0.377692    0.142997     0.405144      0.398466    -0.0389619  -0.288838    -0.444973    0.605493     0.140156    -0.0498881   0.805173    0.1469       0.632083     0.151884    -0.519822    0.422531    0.55639     -0.330676     0.51465
  0.246341   -0.202764    0.317713    -0.630342     0.469206     0.0727276   -0.0936849  -0.357866   -0.310285    -0.192977     -0.247821    -0.0704663  -0.160081    -0.48152     0.145777    -0.410781     0.35897     0.0291973  -0.406299     0.146283     0.0463083    0.451734    0.149259    0.777559     0.846864     0.116986
  0.663609   -0.381412   -1.31108     -0.560867    -0.713792    -0.690607     0.134208    0.527896   -0.0341785    0.221612     -0.874927    -0.0069554   0.276655    -0.375768    0.809941     0.50553     -0.04137     1.5867     -0.635139    -0.927825     0.191742    -0.388449   -0.388304    0.305874     0.654124     0.443564
 -0.849532   -0.508629    0.291856     0.134806     0.606017     0.537696     0.258248    0.70724    -0.197824     0.420779      0.504468    -0.102841    0.631791    -0.533941   -0.638975    -0.249714    -0.0905443  -0.0559869  -0.473533    -0.237264     0.98915      0.275573    0.0607331  -0.315263    -0.592568    -0.239298
 -0.0695832  -0.719802   -0.364038    -0.273529    -0.128867    -0.0466437   -0.0599489   0.395996   -0.121658    -0.123601      0.467647     0.133466   -0.10171      0.659505    0.215246    -0.208473    -0.0628934   0.32113     0.0994902    0.344633     0.588435     0.194169   -0.0064715  -0.499413     0.0887454   -0.220022
 -0.145568    0.0700103  -0.73309      0.449478     0.124291    -0.0943966   -0.261333    0.0165296   0.102033     0.201673     -0.338869     0.269211    0.244626     0.453675    0.441345     0.094507     0.22602    -0.143077    0.104524    -0.0901023   -0.075886     0.0534908  -0.105041    0.392568     0.95601      0.0448495
  0.0231714  -0.0207688   0.00115083  -0.00470095   0.0935158    0.0205403    0.0316486   0.0971829   0.0256102    0.0768152     0.0539974   -0.0591883   0.0452278    0.0753954   0.00865234  -0.0267823    0.054202    0.0390678  -0.0737091   -0.0414953    0.0233438    0.107673   -0.0568088  -0.0210296    0.0189705   -0.0978998
  0.154224   -0.0200338  -0.0133887    0.0948858   -0.23838     -0.0158754    0.171255   -0.558813   -0.163776     0.312365      0.176752    -0.107853    0.101779    -0.193632    0.0304927   -0.143361     0.0867032  -0.0584114   0.128704    -0.105076     0.352157    -0.305086    0.361613    0.291676     0.323175     0.0888923
 -0.0480958  -0.0889964   0.280083     0.0920197   -0.0842638    0.133264    -0.198584   -0.104125    0.105236    -0.567651     -0.00606823   0.267082    0.124389    -0.0222671   0.600383     0.0641196   -0.15121    -0.23059    -0.16614      0.188222     0.135306    -0.11323     0.3505      0.0717926   -0.019154     0.319305
  0.113238   -0.253055    0.0815846   -0.291631     0.479378     0.0225857    0.90791    -0.168332    0.290774     0.0979665     0.290396     0.118791    0.327093     0.642966    0.186002     0.266121    -0.0175989  -0.0177012  -0.0591355   -0.501361     0.964411    -0.0688787   0.198073    0.00344615   0.0985997    0.268162
  0.0618547   0.127245   -0.20471      0.0768913    0.0726913   -0.083652    -0.705757    0.201429   -0.25655     -0.4322       -0.255069    -0.125895   -0.201623    -0.346328   -0.32261     -0.204672     0.112445    0.15927     0.268741     0.153257    -0.450762     0.0194049  -0.216256   -0.0788626   -0.0488925    0.013141
  0.125445    0.683556   -0.0453294   -0.380476     0.0629619    0.124073     0.290715    0.263777   -0.597733     0.644825      0.260318    -0.297537   -0.0694853   -0.0569769  -0.707736     0.30452     -0.0148752   0.314059    0.197502    -0.11326     -0.126676     0.334718   -0.234654   -0.0933247    0.19726     -0.404892
  0.79855     0.457971    0.437684    -0.212871    -0.58334      0.485005     0.808013   -0.486126    0.576227     0.139082     -0.043381     0.152313    0.463758    -0.555157    0.746868    -0.399392    -0.320704   -0.395105   -0.083294     0.266786     0.0183019    0.321537    1.10049    -0.294974     0.0712472   -0.565235
 -0.31495     0.0481493  -0.372072     0.350251    -0.818443     0.0229932   -0.0871515  -0.130091   -0.235072     0.182283     -0.14577     -0.0299242   0.0851117   -0.1112     -0.127726     0.372158    -0.216946   -0.402331    0.416238     0.156034     0.33842     -0.463407    0.0607009   0.260585     0.08069      0.363981
 -0.186247   -0.283916    0.135999    -0.0707224   -0.359651     0.625404     0.250904   -0.105339   -0.406488     0.000881186   0.0424381    0.0886081   0.0842785    0.470523   -0.461329     0.517604     0.0819663  -0.266841    0.425313    -0.346795     0.211397    -0.177072    0.0167313  -0.0973758   -0.052739     0.301309
 -0.44824     0.0555803  -0.0103511    0.205152    -0.177526    -0.0175139   -0.341834    0.842346    0.014689     0.0585354    -0.617945     0.203771   -0.242528    -0.582266   -0.232289    -0.472777    -0.231496   -0.152306   -0.67992      0.173568    -1.13692      0.185645   -0.346237    0.310084    -0.126054     0.0383549
 -0.36069    -0.140737   -0.267063     0.264484     0.413711    -0.238308     0.133548    0.0240081   0.411585     0.791039     -0.432921    -0.771431    0.141512    -0.0152815  -0.0976887   -0.714133    -0.602171    0.766286    0.497892    -0.266621     0.0564747    0.345032    0.506879    0.112607    -0.152918     0.260021
 -0.1989     -0.621331   -0.0105201    0.128026     0.320896     0.299499    -0.937761    0.375731   -0.170514    -0.513022     -0.127825    -0.220812   -0.312851     0.610653   -0.834193     0.191357     0.296597    0.147599    0.228765    -0.702945     0.00716723   0.178914   -0.302685    0.321863    -0.28649      0.346566
  0.242669   -0.112616   -0.106507     0.574443     0.247228     0.00616351   0.044535   -0.233155    0.317875     0.614799      0.502026    -0.0951973   0.170443    -0.637319    0.170186    -0.0471453   -0.608886    0.13966    -0.778559     0.0675137    0.218347     0.0675983  -0.738913    0.569847     0.129004    -0.00532035
 -0.359193    0.489129   -0.258012     0.116603    -0.00952765  -0.487775     0.256139   -0.0944871  -0.0163133   -0.0531846     0.224793    -0.109034    0.0303679   -0.663571    0.450545     0.210023    -0.338362    0.0145674   0.0346267    0.341652    -0.0824522    0.082919    0.028643   -0.524417    -0.132971    -0.392734
  0.477325    0.0854233  -0.31832     -0.245707     0.302821    -0.391639     0.375805    0.414298    0.573136     0.514517     -0.657869     0.340494   -0.873863     0.223121   -0.0236759    0.211357    -0.0592245  -0.152977    0.178627     0.664321     0.00747746  -0.065141    0.499763    0.0023734    0.0573557    0.351787
  1.12834    -0.2512      0.524381     0.104099     0.0778825    0.326625    -0.206634    0.436512    0.799523     0.186641     -0.028423     0.360386   -0.158864     0.181654   -0.281959     0.565431    -0.170363    0.313145    0.0289922    0.0513723    0.0857016   -0.607325    0.251625   -0.0227383    0.00223417  -0.228942
 -0.391913    0.123742    0.197188    -0.256861    -0.18267      0.00461479  -0.341487   -0.213117   -0.374238    -0.470782     -0.126268     0.218039   -0.269162     0.274444    0.145138    -0.0199893    0.363755   -0.197077    0.688077     0.232851    -0.254593     0.22859     1.12436    -0.430411    -0.348161     0.1129
  0.432197   -0.374264    0.365734     0.400432    -0.651568    -0.501109    -0.10738    -0.642774   -0.00880632  -0.104739      0.196021    -0.460621   -0.00970485  -0.0669671   0.291594    -0.86049      0.199597    0.0454324  -0.459754     0.0420885   -0.327935    -0.797963    0.176493   -0.13861     -0.0962492   -0.444591
 -0.115048    0.0986934  -0.00688094  -0.248453     0.651616     0.0319468   -0.150136    0.260818    0.076598    -0.341554     -0.0677336    0.112814    0.0125532    0.0522365  -0.0813352    0.00115972  -0.0039383   0.129089    0.0558609   -0.0486693   -0.191002     0.545596   -0.203984   -0.204753     0.0677967    0.00311869[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412227
[ Info: iteration 2, average log likelihood -1.412220
[ Info: iteration 3, average log likelihood -1.412213
[ Info: iteration 4, average log likelihood -1.412207
[ Info: iteration 5, average log likelihood -1.412201
[ Info: iteration 6, average log likelihood -1.412195
[ Info: iteration 7, average log likelihood -1.412189
[ Info: iteration 8, average log likelihood -1.412184
[ Info: iteration 9, average log likelihood -1.412179
[ Info: iteration 10, average log likelihood -1.412173
┌ Info: EM with 100000 data points 10 iterations avll -1.412173
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
