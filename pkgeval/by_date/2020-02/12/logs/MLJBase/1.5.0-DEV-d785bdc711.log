Julia Version 1.5.0-DEV.263
Commit d785bdc711 (2020-02-12 15:14 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed OpenSpecFun_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.3+1
  Installed ScientificTypes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.1
  Installed Tables â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.11
  Installed Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
  Installed FixedPointNumbers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.1
  Installed Arpack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
  Installed MLJBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.11.3
  Installed Distributions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.22.4
  Installed ProgressMeter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.2.0
  Installed OpenBLAS_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.7+5
  Installed SortingAlgorithms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.1
  Installed DataAPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
  Installed IteratorInterfaceExtensions â”€ v1.0.0
  Installed ColorTypes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.1
  Installed SpecialFunctions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.0
  Installed LossFunctions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.1
  Installed DataStructures â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.17.9
  Installed PDMats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.11
  Installed InvertedIndices â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
  Installed Parsers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.11
  Installed MLJModelInterface â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.1.5
  Installed Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.0
  Installed StatsFuns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.3
  Installed BinaryProvider â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.8
  Installed QuadGK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.3.1
  Installed ComputationalResources â”€â”€â”€â”€â”€â”€ v0.3.1
  Installed StatsBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.32.0
  Installed DataValueInterfaces â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
  Installed Missings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.3
  Installed JSON â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.21.0
  Installed Crayons â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v4.0.1
  Installed FillArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.4
  Installed PrettyTables â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
  Installed LearnBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.2
  Installed CategoricalArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.7
  Installed Arpack_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v3.5.0+2
  Installed RecipesBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.0
  Installed Compat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v3.5.0
  Installed TableTraits â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
  Installed Reexport â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.0
  Installed OrderedCollections â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
  Installed MLJScientificTypes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.1.1
  Installed Formatting â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.1
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                         ##                                                                         3.1%######                                                                     9.5%##############                                                            20.5%########################                                                  34.1%######################################                                    53.9%########################################################                  78.6%####################################################################      94.7%######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [a7f614a8] + MLJBase v0.11.3
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [b99e7846] + BinaryProvider v0.5.8
  [324d7699] + CategoricalArrays v0.7.7
  [3da002f7] + ColorTypes v0.9.1
  [34da2185] + Compat v3.5.0
  [ed09eef8] + ComputationalResources v0.3.1
  [a8cc5b0e] + Crayons v4.0.1
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [e2d170a0] + DataValueInterfaces v1.0.0
  [31c24e10] + Distributions v0.22.4
  [1a297f60] + FillArrays v0.8.4
  [53c48c17] + FixedPointNumbers v0.7.1
  [59287772] + Formatting v0.4.1
  [41ab1584] + InvertedIndices v1.0.0
  [82899510] + IteratorInterfaceExtensions v1.0.0
  [682c06a0] + JSON v0.21.0
  [7f8f8fb0] + LearnBase v0.2.2
  [30fc2ffe] + LossFunctions v0.5.1
  [a7f614a8] + MLJBase v0.11.3
  [e80e1ace] + MLJModelInterface v0.1.5
  [2e2323e0] + MLJScientificTypes v0.1.1
  [e1d29d7a] + Missings v0.4.3
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [69de0a69] + Parsers v0.3.11
  [08abe8d2] + PrettyTables v0.8.2
  [92933f4c] + ProgressMeter v1.2.0
  [1fd47b50] + QuadGK v2.3.1
  [3cdcf5f2] + RecipesBase v0.8.0
  [189a3867] + Reexport v0.2.0
  [79098fc4] + Rmath v0.6.0
  [321657f4] + ScientificTypes v0.7.1
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [3783bdb8] + TableTraits v1.0.0
  [bd369af6] + Tables v0.2.11
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [9fa8497b] + Future 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building Rmath â†’ `~/.julia/packages/Rmath/BoBag/deps/build.log`
    Testing MLJBase
Status `/tmp/jl_xOH5Ah/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [b99e7846] BinaryProvider v0.5.8
  [336ed68f] CSV v0.5.23
  [324d7699] CategoricalArrays v0.7.7
  [3da002f7] ColorTypes v0.9.1
  [34da2185] Compat v3.5.0
  [ed09eef8] ComputationalResources v0.3.1
  [a8cc5b0e] Crayons v4.0.1
  [9a962f9c] DataAPI v1.1.0
  [a93c6f00] DataFrames v0.20.0
  [864edb3b] DataStructures v0.17.9
  [e2d170a0] DataValueInterfaces v1.0.0
  [7806a523] DecisionTree v0.10.1
  [85a47980] Dictionaries v0.2.1
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [48062228] FilePathsBase v0.7.0
  [1a297f60] FillArrays v0.8.4
  [53c48c17] FixedPointNumbers v0.7.1
  [59287772] Formatting v0.4.1
  [313cdc1a] Indexing v1.1.0
  [41ab1584] InvertedIndices v1.0.0
  [82899510] IteratorInterfaceExtensions v1.0.0
  [682c06a0] JSON v0.21.0
  [7f8f8fb0] LearnBase v0.2.2
  [30fc2ffe] LossFunctions v0.5.1
  [a7f614a8] MLJBase v0.11.3
  [e80e1ace] MLJModelInterface v0.1.5
  [2e2323e0] MLJScientificTypes v0.1.1
  [e1d29d7a] Missings v0.4.3
  [6f286f6a] MultivariateStats v0.7.0
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [69de0a69] Parsers v0.3.11
  [2dfb63ee] PooledArrays v0.5.3
  [08abe8d2] PrettyTables v0.8.2
  [92933f4c] ProgressMeter v1.2.0
  [1fd47b50] QuadGK v2.3.1
  [3cdcf5f2] RecipesBase v0.8.0
  [189a3867] Reexport v0.2.0
  [79098fc4] Rmath v0.6.0
  [321657f4] ScientificTypes v0.7.1
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [03a91e81] SplitApplyCombine v1.0.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [3783bdb8] TableTraits v1.0.0
  [bd369af6] Tables v0.2.11
  [9d95f2ec] TypedTables v1.2.0
  [ea10d353] WeakRefStrings v0.6.2
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [9fa8497b] Future 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
Loading some models for testing...                                           Test Summary: | Pass  Total
misc          |  104    104
Test Summary: | Pass  Total
interface     |   72     72
Test Summary: | Pass  Total
measures      |  208    208
Evaluating over 5 folds:  17%[====>                    ]  ETA: 0:00:00[KEvaluating over 5 folds:  33%[========>                ]  ETA: 0:00:03[KEvaluating over 5 folds:  50%[============>            ]  ETA: 0:00:02[KEvaluating over 5 folds:  67%[================>        ]  ETA: 0:00:01[KEvaluating over 5 folds:  83%[====================>    ]  ETA: 0:00:00[KEvaluating over 5 folds: 100%[=========================] Time: 0:00:02[K
Evaluating over 6 folds:  14%[===>                     ]  ETA: 0:00:00[KEvaluating over 6 folds:  29%[=======>                 ]  ETA: 0:00:01[KEvaluating over 6 folds:  43%[==========>              ]  ETA: 0:00:00[KEvaluating over 6 folds:  57%[==============>          ]  ETA: 0:00:00[KEvaluating over 6 folds:  71%[=================>       ]  ETA: 0:00:00[KEvaluating over 6 folds:  86%[=====================>   ]  ETA: 0:00:00[KEvaluating over 6 folds: 100%[=========================] Time: 0:00:00[K
Evaluating over 18 folds:   5%[=>                       ]  ETA: 0:00:00[KEvaluating over 18 folds:  11%[==>                      ]  ETA: 0:00:00[KEvaluating over 18 folds:  16%[===>                     ]  ETA: 0:00:00[KEvaluating over 18 folds:  21%[=====>                   ]  ETA: 0:00:00[KEvaluating over 18 folds:  26%[======>                  ]  ETA: 0:00:00[KEvaluating over 18 folds:  32%[=======>                 ]  ETA: 0:00:00[KEvaluating over 18 folds:  37%[=========>               ]  ETA: 0:00:00[KEvaluating over 18 folds:  42%[==========>              ]  ETA: 0:00:00[KEvaluating over 18 folds:  47%[===========>             ]  ETA: 0:00:00[KEvaluating over 18 folds:  53%[=============>           ]  ETA: 0:00:00[KEvaluating over 18 folds:  58%[==============>          ]  ETA: 0:00:00[KEvaluating over 18 folds:  63%[===============>         ]  ETA: 0:00:00[KEvaluating over 18 folds:  68%[=================>       ]  ETA: 0:00:00[KEvaluating over 18 folds:  74%[==================>      ]  ETA: 0:00:00[KEvaluating over 18 folds:  79%[===================>     ]  ETA: 0:00:00[KEvaluating over 18 folds:  84%[=====================>   ]  ETA: 0:00:00[KEvaluating over 18 folds:  89%[======================>  ]  ETA: 0:00:00[KEvaluating over 18 folds:  95%[=======================> ]  ETA: 0:00:00[KEvaluating over 18 folds: 100%[=========================] Time: 0:00:00[K
Evaluating over 1 folds:  50%[============>            ]  ETA: 0:00:00[KEvaluating over 1 folds: 100%[=========================] Time: 0:00:00[K
[ Info: Distributing cross-validation computation among 2 workers.
Evaluating over 5 folds:  17%[====>                    ]  ETA: 0:00:00[KEvaluating over 5 folds:  33%[========>                ]  ETA: 0:00:00[KEvaluating over 5 folds:  67%[================>        ]  ETA: 0:00:00[KEvaluating over 5 folds:  83%[====================>    ]  ETA: 0:00:00[KEvaluating over 5 folds: 100%[=========================] Time: 0:00:00[K
Evaluating over 6 folds:  14%[===>                     ]  ETA: 0:00:00[KEvaluating over 6 folds:  29%[=======>                 ]  ETA: 0:00:00[KEvaluating over 6 folds:  43%[==========>              ]  ETA: 0:00:00[KEvaluating over 6 folds:  57%[==============>          ]  ETA: 0:00:00[KEvaluating over 6 folds:  71%[=================>       ]  ETA: 0:00:00[KEvaluating over 6 folds:  86%[=====================>   ]  ETA: 0:00:00[KEvaluating over 6 folds: 100%[=========================] Time: 0:00:00[K
[ Info: Distributing cross-validation computation among 2 workers.
[ Info: Distributing cross-validation computation among 2 workers.
[ Info: Updating [34mMachine{Resampler} @ 5â€¦50[39m.
Evaluating over 1 folds:  50%[============>            ]  ETA: 0:00:00[KEvaluating over 1 folds: 100%[=========================] Time: 0:00:00[K
[ Info: Updating [34mMachine{Resampler} @ 5â€¦28[39m.
Evaluating over 1 folds:  50%[============>            ]  ETA: 0:00:00[KEvaluating over 1 folds: 100%[=========================] Time: 0:00:00[K
Evaluating over 1 folds:  50%[============>            ]  ETA: 0:00:00[KEvaluating over 1 folds: 100%[=========================] Time: 0:00:04[K
[ Info: Distributing cross-validation computation among 2 workers.
Evaluating over 1 folds:  50%[============>            ]  ETA: 0:00:00[KEvaluating over 1 folds: 100%[=========================] Time: 0:00:02[K
[ Info: Passing machine sample weights to any supported measures. 
Evaluating over 1 folds:  50%[============>            ]  ETA: 0:00:00[KEvaluating over 1 folds: 100%[=========================] Time: 0:00:01[K
Evaluating over 1 folds:  50%[============>            ]  ETA: 0:00:00[KEvaluating over 1 folds: 100%[=========================] Time: 0:00:00[K
[ Info: Passing machine sample weights to any supported measures. 
Evaluating over 6 folds:  14%[===>                     ]  ETA: 0:00:00[KEvaluating over 6 folds:  29%[=======>                 ]  ETA: 0:00:20[KEvaluating over 6 folds:  43%[==========>              ]  ETA: 0:00:11[KEvaluating over 6 folds:  57%[==============>          ]  ETA: 0:00:06[KEvaluating over 6 folds:  71%[=================>       ]  ETA: 0:00:03[KEvaluating over 6 folds:  86%[=====================>   ]  ETA: 0:00:01[KEvaluating over 6 folds: 100%[=========================] Time: 0:00:08[K
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Creating subsamples from a subset of all rows. 
Evaluating over 6 folds:  14%[===>                     ]  ETA: 0:00:00[KEvaluating over 6 folds:  29%[=======>                 ]  ETA: 0:00:00[KEvaluating over 6 folds:  43%[==========>              ]  ETA: 0:00:00[KEvaluating over 6 folds:  57%[==============>          ]  ETA: 0:00:00[KEvaluating over 6 folds:  71%[=================>       ]  ETA: 0:00:00[KEvaluating over 6 folds:  86%[=====================>   ]  ETA: 0:00:00[KEvaluating over 6 folds: 100%[=========================] Time: 0:00:00[K
[ Info: Training [34mMachine{Resampler} @ 3â€¦98[39m.
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Passing machine sample weights to any supported measures. 
Evaluating over 6 folds:  14%[===>                     ]  ETA: 0:00:00[KEvaluating over 6 folds:  29%[=======>                 ]  ETA: 0:00:00[KEvaluating over 6 folds:  43%[==========>              ]  ETA: 0:00:00[KEvaluating over 6 folds:  57%[==============>          ]  ETA: 0:00:00[KEvaluating over 6 folds:  71%[=================>       ]  ETA: 0:00:00[KEvaluating over 6 folds:  86%[=====================>   ]  ETA: 0:00:00[KEvaluating over 6 folds: 100%[=========================] Time: 0:00:00[K
[ Info: Training [34mMachine{Resampler} @ 1â€¦62[39m.
Evaluating over 6 folds:  14%[===>                     ]  ETA: 0:00:00[KEvaluating over 6 folds:  29%[=======>                 ]  ETA: 0:00:00[KEvaluating over 6 folds:  43%[==========>              ]  ETA: 0:00:00[KEvaluating over 6 folds:  57%[==============>          ]  ETA: 0:00:00[KEvaluating over 6 folds:  71%[=================>       ]  ETA: 0:00:00[KEvaluating over 6 folds:  86%[=====================>   ]  ETA: 0:00:00[KEvaluating over 6 folds: 100%[=========================] Time: 0:00:00[K
[ Info: Distributing cross-validation computation among 2 workers.
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Distributing cross-validation computation among 2 workers.
[ Info: Distributing cross-validation computation among 2 workers.
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Distributing cross-validation computation among 2 workers.
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Creating subsamples from a subset of all rows. 
[ Info: Distributing cross-validation computation among 2 workers.
[ Info: Training [34mMachine{Resampler} @ 7â€¦76[39m.
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Distributing cross-validation computation among 2 workers.
[ Info: Training [34mMachine{Resampler} @ 6â€¦10[39m.
[ Info: Distributing cross-validation computation among 2 workers.
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Creating subsamples from a subset of all rows. 
[ Info: Training [34mMachine{Resampler} @ 5â€¦07[39m.
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Training [34mMachine{Resampler} @ 8â€¦04[39m.
Test Summary: | Pass  Broken  Total
resampling    |   75       2     77
Test Summary: | Pass  Total
data          |  114    114
[ Info: Training [34mMachine{ConstantClassifier} @ 2â€¦99[39m.
[ Info: Training [34mMachine{ConstantClassifier} @ 2â€¦90[39m.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 9â€¦92[39m.
[ Info: Training [34mNodalMachine{FooBarRegressor} @ 3â€¦38[39m.
[ Info: Training [34mNodalMachine{SimpleDeterministicCompositeModel} @ 1â€¦72[39m.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 1â€¦19[39m.
[ Info: Training [34mNodalMachine{FooBarRegressor} @ 8â€¦95[39m.
[ Info: Updating [34mNodalMachine{SimpleDeterministicCompositeModel} @ 1â€¦72[39m.
[ Info: Updating [34mNodalMachine{FeatureSelector} @ 1â€¦19[39m.
[ Info: Training [34mNodalMachine{FooBarRegressor} @ 8â€¦95[39m.
[ Info: Training [34mNodalMachine{SimpleDeterministicCompositeModel} @ 1â€¦72[39m.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 4â€¦72[39m.
[ Info: Training [34mNodalMachine{FooBarRegressor} @ 5â€¦20[39m.
[ Info: Training [34mMachine{WrappedRidge} @ 6â€¦94[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 1â€¦45[39m.
[ Info: Training [34mNodalMachine{UnivariateBoxCoxTransformer} @ 1â€¦88[39m.
[ Info: Training [34mNodalMachine{FooBarRegressor} @ 2â€¦36[39m.
[ Info: Updating [34mMachine{WrappedRidge} @ 6â€¦94[39m.
â”Œ Info: Not retraining [34mNodalMachine{Standardizer} @ 1â€¦45[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
â”Œ Info: Not retraining [34mNodalMachine{UnivariateBoxCoxTransformer} @ 1â€¦88[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
[ Info: Updating [34mNodalMachine{FooBarRegressor} @ 2â€¦36[39m.
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 1â€¦75[39m.
[ Info: Spawning 3 sub-features to one-hot encode feature :x1.
[ Info: Training [34mNodalMachine{UnivariateStandardizer} @ 4â€¦82[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 6â€¦84[39m.
[ Info: Training [34mNodalMachine{DecisionTreeRegressor} @ 1â€¦48[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 3â€¦35[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 8â€¦84[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 3â€¦35[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 8â€¦84[39m.
[ Info: Training [34mMachine{Composite3} @ 1â€¦43[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 6â€¦44[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 1â€¦04[39m.
[ Info: Training [34mMachine{Composite3} @ 1â€¦96[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 1â€¦80[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 1â€¦11[39m.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 1â€¦80[39m.
[ Info: Training [34mNodalMachine{UnivariateStandardizer} @ 1â€¦06[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 5â€¦72[39m.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 8â€¦78[39m.
[ Info: Training [34mNodalMachine{UnivariateStandardizer} @ 1â€¦64[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 8â€¦65[39m.
[ Info: Updating [34mNodalMachine{FeatureSelector} @ 1â€¦80[39m.
â”Œ Info: Not retraining [34mNodalMachine{UnivariateStandardizer} @ 1â€¦06[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 5â€¦72[39m.
[ Info: Updating [34mNodalMachine{FeatureSelector} @ 8â€¦78[39m.
â”Œ Info: Not retraining [34mNodalMachine{UnivariateStandardizer} @ 1â€¦64[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 8â€¦65[39m.
[ Info: Training [34mMachine{Pipe} @ 8â€¦48[39m.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 1â€¦02[39m.
[ Info: Training [34mNodalMachine{UnivariateStandardizer} @ 8â€¦88[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 1â€¦67[39m.
[ Info: Training [34mMachine{Pipe21} @ 1â€¦73[39m.
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 1â€¦23[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 2â€¦60[39m.
[ Info: Training [34mMachine{Piper3} @ 1â€¦42[39m.
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 1â€¦95[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 3â€¦63[39m.
[ Info: Training [34mMachine{Piper3} @ 1â€¦86[39m.
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 1â€¦89[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 1â€¦53[39m.
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 1â€¦81[39m.
[ Info: Spawning 3 sub-features to one-hot encode feature :x3.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 1â€¦30[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 8â€¦81[39m.
[ Info: Training [34mMachine{Pipe4} @ 1â€¦77[39m.
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 3â€¦78[39m.
[ Info: Spawning 3 sub-features to one-hot encode feature :x3.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 1â€¦28[39m.
[ Info: Training [34mNodalMachine{StaticTransformer} @ 1â€¦55[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 7â€¦20[39m.
[ Info: Training [34mNodalMachine{StaticTransformer} @ 2â€¦79[39m.
[ Info: Training [34mMachine{Pipe9} @ 1â€¦25[39m.
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 5â€¦78[39m.
[ Info: Spawning 2 sub-features to one-hot encode feature :gender.
[ Info: Training [34mNodalMachine{UnivariateStandardizer} @ 1â€¦96[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 6â€¦91[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 1â€¦29[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 3â€¦59[39m.
[ Info: Training [34mNodalMachine{UnivariateBoxCoxTransformer} @ 1â€¦55[39m.
[ Info: Training [34mNodalMachine{RidgeRegressor} @ 1â€¦88[39m.
â”Œ Info: Not retraining [34mNodalMachine{Standardizer} @ 3â€¦59[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
â”Œ Info: Not retraining [34mNodalMachine{UnivariateBoxCoxTransformer} @ 1â€¦55[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
[ Info: Updating [34mNodalMachine{RidgeRegressor} @ 1â€¦88[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 5â€¦57[39m.
[ Info: Training [34mNodalMachine{PCA} @ 6â€¦31[39m.
â”Œ Info: Not retraining [34mNodalMachine{Standardizer} @ 5â€¦57[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
â”Œ Info: Not retraining [34mNodalMachine{PCA} @ 6â€¦31[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
[ Info: Training [34mNodalMachine{RidgeRegressor} @ 1â€¦13[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 1â€¦73[39m.
[ Info: Training [34mNodalMachine{PCA} @ 4â€¦14[39m.
[ Info: Training [34mNodalMachine{RidgeRegressor} @ 5â€¦46[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 1â€¦81[39m.
[ Info: Training [34mNodalMachine{PCA} @ 1â€¦55[39m.
[ Info: Training [34mNodalMachine{UnivariateBoxCoxTransformer} @ 1â€¦28[39m.
[ Info: Training [34mNodalMachine{RidgeRegressor} @ 1â€¦97[39m.
[ Info: Training [34mNodalMachine{DecisionTreeRegressor} @ 9â€¦05[39m.
[ Info: Training [34mNodalMachine{DecisionTreeRegressor} @ 3â€¦81[39m.
Test Summary:        | Pass  Total
machines+composition |  276    276
Test Summary: | Pass  Total
hyperparam    |   58     58
    Testing MLJBase tests passed 
