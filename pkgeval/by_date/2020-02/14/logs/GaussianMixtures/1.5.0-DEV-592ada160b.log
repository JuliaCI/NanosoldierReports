Julia Version 1.5.0-DEV.267
Commit 592ada160b (2020-02-13 16:56 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed CMakeWrapper ─────── v0.2.3
  Installed GaussianMixtures ─── v0.3.0
  Installed Arpack_jll ───────── v3.5.0+2
  Installed Blosc ────────────── v0.5.1
  Installed OrderedCollections ─ v1.1.0
  Installed NearestNeighbors ─── v0.4.4
  Installed StatsFuns ────────── v0.9.4
  Installed FileIO ───────────── v1.2.2
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed Arpack ───────────── v0.4.0
  Installed DataAPI ──────────── v1.1.0
  Installed Distances ────────── v0.8.2
  Installed Missings ─────────── v0.4.3
  Installed FillArrays ───────── v0.8.4
  Installed URIParser ────────── v0.4.0
  Installed QuadGK ───────────── v2.3.1
  Installed Compat ───────────── v2.2.0
  Installed BinDeps ──────────── v1.0.0
  Installed Parameters ───────── v0.12.0
  Installed SpecialFunctions ─── v0.10.0
  Installed DataStructures ───── v0.17.9
  Installed StatsBase ────────── v0.32.0
  Installed BinaryProvider ───── v0.5.8
  Installed Distributions ────── v0.22.4
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed LegacyStrings ────── v0.4.1
  Installed PDMats ───────────── v0.9.11
  Installed HDF5 ─────────────── v0.12.5
  Installed CMake ────────────── v1.2.0
  Installed SortingAlgorithms ── v0.3.1
  Installed StaticArrays ─────── v0.12.1
  Installed ScikitLearnBase ──── v0.5.0
  Installed Rmath ────────────── v0.6.0
  Installed JLD ──────────────── v0.9.2
  Installed Clustering ───────── v0.13.3
#=#=#                                                                         #######                                                                   10.8%######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                         #                                                                          2.1%####                                                                       5.8%#######                                                                   10.1%###########                                                               15.7%################                                                          23.5%##################                                                        26.0%########################                                                  34.6%###################################                                       49.8%#################################################                         68.1%#################################################################         91.4%######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.2.0
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.2
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.10.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.4
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building CMake → `~/.julia/packages/CMake/ULbyn/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_5zZGdA/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.2.0
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.2
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.10.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.4
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -1.4612233122271616e7, [45514.48977092656, 54485.51022907344], [19988.12425710536 32208.229761412746 12082.53826940679; -20410.641298437637 -31933.423137494887 -12281.422773119331], [[46326.33014354608 2193.1466856632487 621.5592156377443; 2193.1466856632487 48736.80870038869 1121.6926478693035; 621.5592156377443 1121.6926478693035 45703.60688088024], [53506.66269806273 -1568.2238818376268 -827.326042732428; -1568.2238818376268 51812.88243333386 -1184.4519317657569; -827.326042732428 -1184.4519317657569 54274.273985664986]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.403822e+03
      1       9.624412e+02      -4.413804e+02 |        7
      2       9.058130e+02      -5.662822e+01 |        2
      3       9.006114e+02      -5.201614e+00 |        0
      4       9.006114e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 900.6114096528026)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.074570
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.814500
[ Info: iteration 2, lowerbound -3.677797
[ Info: iteration 3, lowerbound -3.528176
[ Info: iteration 4, lowerbound -3.353794
[ Info: iteration 5, lowerbound -3.166937
[ Info: dropping number of Gaussions to 7
[ Info: iteration 6, lowerbound -2.983778
[ Info: iteration 7, lowerbound -2.822675
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.692767
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.593459
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.524736
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.469637
[ Info: iteration 12, lowerbound -2.423853
[ Info: iteration 13, lowerbound -2.387353
[ Info: iteration 14, lowerbound -2.355443
[ Info: iteration 15, lowerbound -2.328813
[ Info: iteration 16, lowerbound -2.311542
[ Info: iteration 17, lowerbound -2.307764
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.302917
[ Info: iteration 19, lowerbound -2.299259
[ Info: iteration 20, lowerbound -2.299256
[ Info: iteration 21, lowerbound -2.299254
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Fri Feb 14 23:13:51 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Fri Feb 14 23:13:59 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Fri Feb 14 23:14:01 2020: EM with 272 data points 0 iterations avll -2.074570
5.8 data points per parameter
, Fri Feb 14 23:14:03 2020: GMM converted to Variational GMM
, Fri Feb 14 23:14:11 2020: iteration 1, lowerbound -3.814500
, Fri Feb 14 23:14:11 2020: iteration 2, lowerbound -3.677797
, Fri Feb 14 23:14:11 2020: iteration 3, lowerbound -3.528176
, Fri Feb 14 23:14:11 2020: iteration 4, lowerbound -3.353794
, Fri Feb 14 23:14:11 2020: iteration 5, lowerbound -3.166937
, Fri Feb 14 23:14:12 2020: dropping number of Gaussions to 7
, Fri Feb 14 23:14:12 2020: iteration 6, lowerbound -2.983778
, Fri Feb 14 23:14:12 2020: iteration 7, lowerbound -2.822675
, Fri Feb 14 23:14:12 2020: dropping number of Gaussions to 6
, Fri Feb 14 23:14:12 2020: iteration 8, lowerbound -2.692767
, Fri Feb 14 23:14:12 2020: dropping number of Gaussions to 5
, Fri Feb 14 23:14:12 2020: iteration 9, lowerbound -2.593459
, Fri Feb 14 23:14:12 2020: dropping number of Gaussions to 4
, Fri Feb 14 23:14:12 2020: iteration 10, lowerbound -2.524736
, Fri Feb 14 23:14:12 2020: dropping number of Gaussions to 3
, Fri Feb 14 23:14:12 2020: iteration 11, lowerbound -2.469637
, Fri Feb 14 23:14:12 2020: iteration 12, lowerbound -2.423853
, Fri Feb 14 23:14:12 2020: iteration 13, lowerbound -2.387353
, Fri Feb 14 23:14:12 2020: iteration 14, lowerbound -2.355443
, Fri Feb 14 23:14:12 2020: iteration 15, lowerbound -2.328813
, Fri Feb 14 23:14:12 2020: iteration 16, lowerbound -2.311542
, Fri Feb 14 23:14:12 2020: iteration 17, lowerbound -2.307764
, Fri Feb 14 23:14:12 2020: dropping number of Gaussions to 2
, Fri Feb 14 23:14:12 2020: iteration 18, lowerbound -2.302917
, Fri Feb 14 23:14:12 2020: iteration 19, lowerbound -2.299259
, Fri Feb 14 23:14:12 2020: iteration 20, lowerbound -2.299256
, Fri Feb 14 23:14:12 2020: iteration 21, lowerbound -2.299254
, Fri Feb 14 23:14:12 2020: iteration 22, lowerbound -2.299254
, Fri Feb 14 23:14:12 2020: iteration 23, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 24, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 25, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 26, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 27, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 28, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 29, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 30, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 31, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 32, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 33, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 34, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 35, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 36, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 37, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 38, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 39, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 40, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 41, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 42, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 43, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 44, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 45, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 46, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 47, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 48, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 49, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: iteration 50, lowerbound -2.299253
, Fri Feb 14 23:14:12 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601396, 95.95490777398605]
β = [178.04509222601396, 95.95490777398605]
m = [4.250300733269909 79.28686694436183; 2.000229257775369 53.8519871724613]
ν = [180.04509222601396, 97.95490777398605]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484816 -0.007644049042327562; 0.0 0.00858170516633351], [0.3758763611948385 -0.008953123827346053; 0.0 0.012748664777409432]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000004
avll from stats: -1.0084616449857464
avll from llpg:  -1.0084616449857464
avll direct:     -1.0084616449857464
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9899933993337613
avll from llpg:  -0.9899933993337612
avll direct:     -0.9899933993337611
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
  0.00173203  -7.86991e-5   0.153768    -0.0210989    0.250929    -0.0476889    0.0357836   -0.0102505    0.0358974     0.0685783     0.22048      0.121611     0.161978      0.0375529    -0.182111      0.0268881    0.0396753   -0.114199    -0.0393238    0.0824835    0.0116466   -0.19819      -0.0159275    -0.0972583  -0.038179     -0.0743809
 -0.156548     0.0571593   -0.0127142    0.0284253   -0.0514473    0.00330074  -0.144081     0.0101986    0.0863344    -0.00195049   -0.114878     0.0418598    0.12692      -0.131911      0.0469321    -0.107288     0.0658642    0.101725     0.0386292   -0.131657     0.0427689    0.0845028    -0.164507     -0.055129   -0.195604     -0.142388
  0.100032     0.088119     0.0183671   -0.124818    -0.038382     0.0488363    0.0195881    0.0575499   -0.0435284     0.0746929    -0.145617     0.0707675   -0.0663        0.0274679     0.0610703    -0.0295628   -0.137528    -0.171467    -0.223635    -0.108987     0.0772395   -0.0596545    -0.0409825    -0.0982343  -0.0518405    -0.126173
  0.0126242    0.0517123    0.0775864    0.0578824    0.00872342   0.0136935    0.0419736    0.0120797    0.0390209     0.070629     -0.0118228    0.104029    -0.0403215    -0.0760358     0.000694784   0.0630641   -0.243947    -0.0791236    0.14023      0.0272173    0.0353122   -0.0345743     0.0290967    -0.0713967  -0.0794496     0.141629
 -0.00585227  -0.0671701   -0.138031    -0.166536    -0.0136604    0.00211181   0.00867033  -0.163882    -0.0335746     0.000406991   0.0249798    0.105364     0.0816117     0.019269     -0.0646956    -0.0648321    0.0571756    0.10644      0.0514113   -0.121772    -0.0342944    0.0764139     0.0475772    -0.084924    0.0532112     0.0066364
  0.0689291   -0.0759824    0.0257371   -0.047518    -0.0819136   -0.0772477    0.0280376   -0.0588863   -0.023315     -0.0858907     0.0741306    0.162029     0.000876038  -0.0721875     0.0588767    -0.0538191    0.0786714    0.0212759   -0.0895207    0.118472    -0.098345     0.0074159     0.00176444    0.0640597   0.170709      0.0541676
  0.00406763  -0.137448     0.175322     0.0410702   -0.027789    -0.0065269   -0.186324    -0.123177    -0.018778      0.184338     -0.158801    -0.130546    -0.216482     -0.0486929     0.169887     -0.0581595    0.0463536   -0.130581    -0.0859373    0.00164489   0.0910686   -0.0519112     0.0146429    -0.0840876  -0.00098821   -0.0141546
 -0.0508853    0.158641    -0.107149     0.0671364    0.0568423   -0.0411904    0.0817288    0.0332555   -0.101574     -0.156402     -0.0805723    0.0703082    3.72056e-5   -0.0079179    -0.114338      0.136887    -0.107399    -0.0068064    0.0931574   -0.0760923   -0.0706642    0.0468051     0.0133168    -0.0929998  -0.234442     -0.123029
  0.168674     0.177055    -0.0812219   -0.0812283   -0.166641     0.114784    -0.108345     0.0317546   -0.0573618     0.157748     -0.00861186  -0.112045    -0.158628     -0.16167       0.1943        0.0717361   -0.00149257   0.0222083   -0.172162    -0.113637    -0.020121    -0.0326308     0.0612416    -0.0520107  -0.0820971    -0.0461201
 -0.130243     0.109123     0.00769756  -0.0730784   -0.0122648   -0.121737     0.0638015    0.125377    -0.106813      0.0145341     0.156772     0.0280464    0.00130512    0.131888      0.0747532    -0.0225525   -0.0127114   -0.171426    -0.128234     0.053488    -0.138858    -0.130086      0.0394001    -0.0177807  -0.0418938     0.0570349
 -0.00433661  -0.103205    -0.107904     0.1022       0.208919     0.122155     0.186356    -0.0888709    0.0225645     0.0302218    -0.0758227    0.235603    -0.0147624     0.17994       0.0688788     0.0161713    0.069543     0.036155    -0.102938    -0.157488    -0.0981357   -0.0326941    -0.0764864     0.144067    0.035951     -0.0176169
  0.144666     0.178167    -0.1626      -0.0891513    0.0122805    0.0335673    0.0977359    0.204561     0.02547      -0.114401     -0.0379027    0.0185492   -0.178398      0.0895682     0.0431355    -0.0714065    0.0318811    0.0174793    0.220306     0.00655273  -0.147429    -0.000198559   0.0109088     0.162514   -0.0413045     0.0402942
 -0.00667228  -0.0346361   -0.0496716   -0.00614732   0.0693309   -0.227584     0.0527362    0.1183       0.0264608    -0.0533551    -0.00883836  -0.110081     0.0923838    -0.103481     -0.248868     -0.121414     0.268554     0.0896236    0.129064     0.0249347    0.0374303    0.141586      0.0591749     0.148171   -0.102268      0.009647
 -0.0435551    0.110081    -0.0506271    0.158713    -0.0476843   -0.0393905    0.057723    -0.139362    -0.0144755    -0.0390811     0.0700661    0.102672    -0.143023     -0.209206     -0.168916      0.143782    -0.0220769   -0.0563788   -0.232773    -0.0883388   -0.0246406   -0.115867     -0.137598     -0.107844   -0.00257755   -0.0677938
 -0.0450133    0.083645     0.0254913    0.146276     0.0907634   -0.0101651   -0.108044     0.0170215    0.127123      0.0944979    -0.0218116   -0.222054    -0.0538674    -0.131141      0.00117959    0.126929    -0.200976     0.0178553   -0.0450636   -0.0219116   -0.0430311   -0.0880357     0.126491     -0.0972359   0.0552723     0.168088
 -0.0146978    0.0466283    0.027911     0.0281826    0.212661     0.113091     0.140739     0.117554     0.000271836   0.066072      0.0681113   -0.10048     -0.181411     -0.0609795     0.0772274     0.0704522    0.0838624    0.150107     0.0380663   -0.0311179    0.174062    -0.225275     -0.150657     -0.12125     0.168453     -0.130718
  0.0863258    0.0484954   -0.124249    -0.0100399   -0.0088252    0.00451047   0.0141092    0.19634      0.0214382     0.117537     -0.108546     0.216521     0.0863931     0.0257814    -0.158588     -0.0546548   -0.0328275    0.0706585   -0.0472553    0.172219    -0.296633    -0.0263947     0.22384      -0.167489   -0.0351872    -0.146884
  0.08637     -0.125352     0.0348754   -0.177957    -0.0435901   -0.0767393    0.124974     0.0913531    0.0866568    -0.0951617    -0.198159     0.0325421    0.0593596    -0.00815118    0.199968      0.100903     0.0287057    0.0538333   -0.117002    -0.0593937   -0.111378    -0.107602     -0.0214229    -0.209881    0.070023      0.0980213
 -0.0577264   -0.226472    -0.0539313   -0.0536741    0.012889     0.111641    -0.0173722    0.0679809    0.205543      0.09211       0.0341004    0.0392687   -0.0403592    -0.00531668    0.0531918    -0.0326194   -0.0962871    0.0304835    0.0916847   -0.0477504   -0.119031     0.0277201    -0.0382848    -0.0019741   0.0559257     0.0176277
 -0.0695244   -0.0926142   -0.16486      0.179764    -0.0374978    0.0245081   -0.0281853    0.0162128    0.0308419    -0.0053476     0.0441778    0.00783378   0.0215999    -0.173538     -0.164805     -0.022733     0.108866     0.0677437    0.0472189    0.205772    -0.0252181    0.0353656    -0.290948      0.0858583  -0.116812      0.137201
  0.152422     0.121036    -0.0404631   -0.0244678   -0.0423419    0.0607856    0.0583464   -0.199888     0.0629541    -0.239416     -0.00903502  -0.259728    -0.0931328     0.0060893    -0.0634176    -0.201837     0.05318      0.0131507    0.0790061   -0.0323001    0.0357926    0.0449214    -0.117429     -0.0824605   0.10635       0.0897589
  0.142796     0.151989    -0.0192594    0.0364212    0.140965     0.0317868    0.0637665    0.00885461   0.00793032   -0.0547647    -0.0270424    0.0338372   -0.0830317    -0.0766741     0.0239817    -0.119031    -0.0232748    0.156096    -0.0932364   -0.0528185   -0.119048    -0.108571      0.0924851    -0.156405    0.0314096     0.0147269
  0.0495803    0.0570571    0.117313    -0.192971     0.139412    -0.0443044   -0.258431     0.0264074   -0.11927       0.0682951     0.0310373   -0.15238     -0.0616598    -0.0837691    -0.264491     -0.0769338    0.0185898    0.014041    -0.00584494   0.0122118   -0.133974    -0.0300424    -0.0959441     0.0280946   0.0266703    -0.152289
  0.208046    -0.0212169   -0.0279022   -0.113786     0.0365298    0.0325431   -0.202303     0.00914973  -0.0719735    -0.144968      0.0398269    0.134089    -0.0644861     0.000321185   0.0832125    -0.0253732    0.0572977    0.0413094   -0.253701    -0.0825071   -0.0652433   -0.047112     -0.190749     -0.139382   -0.0461025     0.135797
 -0.0685354    0.0671726    0.119252     0.133814     0.144739     0.13422     -0.0579827   -0.0972857    0.298793      0.159454     -0.0766048    0.182444     0.129523      0.124963     -0.043691      0.0784026   -0.0605808    0.0917554   -0.0173476    0.138149     0.0744064    0.0252033    -0.0089054    -0.119222   -0.113878     -0.00237415
  0.0410043   -0.00230739   0.0904882    0.0380157    0.010227    -0.0190776   -0.0392648   -0.0911814   -0.0504789    -0.0780824    -0.0842284   -0.112589    -0.0363157     0.0362195     0.0240524     0.00580608  -0.107284     0.0286719    0.0441611   -0.127883    -0.111399    -0.0777486     0.0227471    -0.0163514   0.0885022     0.027294
  0.051799    -0.216036     0.0859485    0.026866    -0.146387    -0.0860983    0.0499727   -0.0693875    0.058926      0.0253885    -0.0724349    0.0329603    0.107954      0.0178104    -0.0704589    -0.00527715  -0.0376019    0.0700795   -0.0355091   -0.138873    -0.0305027   -0.0857892     0.0542997    -0.0618805   0.00234003    0.0920946
  0.00225389  -0.0627579   -0.18329     -0.00483566   0.013483    -0.00608351   0.057413     0.00733183  -0.0166635    -0.0524912    -0.110428    -0.189707     0.0620832     0.0209229     0.0775763     0.156902     0.132609    -0.0327385   -0.270054     0.139054    -0.0222158    0.148171      0.0551915    -0.0365702   0.0755615    -0.143845
 -0.0499229   -0.0158317    0.0974798    0.0421658   -0.0724872   -0.107956     0.108081    -0.209515     0.101312     -0.148315      0.0327346   -0.0255841    0.022005     -0.160258      0.0191103     0.222785     0.0594676    0.0713282    0.156118     0.0147532    0.00262418   0.132276      0.0538953    -0.0168679   0.210331     -0.0424541
 -0.279649     0.0050273   -0.0515021    0.141212    -0.0444097    0.0698891    0.152433     0.0697916    0.0515938    -0.0570493    -0.0224877   -0.0189218   -0.0379586    -0.0721946    -0.142483     -0.0798103    0.0682112   -0.192761     0.0635028   -0.124425     0.0231285    0.00737774    0.0489389     0.0144773  -0.219303     -0.0018402
 -0.147306    -0.185294    -0.120259    -0.10616      0.0877858    0.0653772   -0.238781    -0.0179957   -0.0658334    -0.0208651    -0.0580481   -0.0518008   -0.0335647    -0.165049      0.105657     -0.0934223   -0.00401934  -0.0404496   -0.038885     0.0678258    0.195423     0.106559      0.0544822    -0.0577407  -0.000364302  -0.136832
  0.0604054   -0.0677603   -0.0428554   -0.118114     0.0133523    0.0379103   -0.0353603   -0.0619013    0.0256674     0.0342669    -0.0408197    0.185273    -0.18859       0.00646984    0.0617524    -0.200749    -0.0933273   -0.00523377   0.0412698    0.00525119  -0.003894    -0.0599375     0.000930589   0.0938614   0.140511      0.0473565kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4104084265271586
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410522
[ Info: iteration 2, average log likelihood -1.410425
[ Info: iteration 3, average log likelihood -1.409885
[ Info: iteration 4, average log likelihood -1.403357
[ Info: iteration 5, average log likelihood -1.385169
[ Info: iteration 6, average log likelihood -1.377231
[ Info: iteration 7, average log likelihood -1.375810
[ Info: iteration 8, average log likelihood -1.375313
[ Info: iteration 9, average log likelihood -1.375084
[ Info: iteration 10, average log likelihood -1.374960
[ Info: iteration 11, average log likelihood -1.374881
[ Info: iteration 12, average log likelihood -1.374822
[ Info: iteration 13, average log likelihood -1.374773
[ Info: iteration 14, average log likelihood -1.374724
[ Info: iteration 15, average log likelihood -1.374668
[ Info: iteration 16, average log likelihood -1.374592
[ Info: iteration 17, average log likelihood -1.374485
[ Info: iteration 18, average log likelihood -1.374353
[ Info: iteration 19, average log likelihood -1.374230
[ Info: iteration 20, average log likelihood -1.374138
[ Info: iteration 21, average log likelihood -1.374076
[ Info: iteration 22, average log likelihood -1.374038
[ Info: iteration 23, average log likelihood -1.374014
[ Info: iteration 24, average log likelihood -1.374000
[ Info: iteration 25, average log likelihood -1.373990
[ Info: iteration 26, average log likelihood -1.373984
[ Info: iteration 27, average log likelihood -1.373979
[ Info: iteration 28, average log likelihood -1.373975
[ Info: iteration 29, average log likelihood -1.373971
[ Info: iteration 30, average log likelihood -1.373969
[ Info: iteration 31, average log likelihood -1.373966
[ Info: iteration 32, average log likelihood -1.373964
[ Info: iteration 33, average log likelihood -1.373963
[ Info: iteration 34, average log likelihood -1.373961
[ Info: iteration 35, average log likelihood -1.373960
[ Info: iteration 36, average log likelihood -1.373959
[ Info: iteration 37, average log likelihood -1.373959
[ Info: iteration 38, average log likelihood -1.373958
[ Info: iteration 39, average log likelihood -1.373957
[ Info: iteration 40, average log likelihood -1.373957
[ Info: iteration 41, average log likelihood -1.373957
[ Info: iteration 42, average log likelihood -1.373956
[ Info: iteration 43, average log likelihood -1.373956
[ Info: iteration 44, average log likelihood -1.373956
[ Info: iteration 45, average log likelihood -1.373955
[ Info: iteration 46, average log likelihood -1.373955
[ Info: iteration 47, average log likelihood -1.373955
[ Info: iteration 48, average log likelihood -1.373955
[ Info: iteration 49, average log likelihood -1.373955
[ Info: iteration 50, average log likelihood -1.373955
┌ Info: EM with 100000 data points 50 iterations avll -1.373955
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4105221812776552
│     -1.4104246472691648
│      ⋮
└     -1.3739548513845798
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.374099
[ Info: iteration 2, average log likelihood -1.373990
[ Info: iteration 3, average log likelihood -1.373742
[ Info: iteration 4, average log likelihood -1.371032
[ Info: iteration 5, average log likelihood -1.357606
[ Info: iteration 6, average log likelihood -1.342446
[ Info: iteration 7, average log likelihood -1.338124
[ Info: iteration 8, average log likelihood -1.336913
[ Info: iteration 9, average log likelihood -1.336258
[ Info: iteration 10, average log likelihood -1.335775
[ Info: iteration 11, average log likelihood -1.335373
[ Info: iteration 12, average log likelihood -1.335036
[ Info: iteration 13, average log likelihood -1.334756
[ Info: iteration 14, average log likelihood -1.334518
[ Info: iteration 15, average log likelihood -1.334313
[ Info: iteration 16, average log likelihood -1.334149
[ Info: iteration 17, average log likelihood -1.334021
[ Info: iteration 18, average log likelihood -1.333917
[ Info: iteration 19, average log likelihood -1.333832
[ Info: iteration 20, average log likelihood -1.333758
[ Info: iteration 21, average log likelihood -1.333694
[ Info: iteration 22, average log likelihood -1.333636
[ Info: iteration 23, average log likelihood -1.333585
[ Info: iteration 24, average log likelihood -1.333542
[ Info: iteration 25, average log likelihood -1.333506
[ Info: iteration 26, average log likelihood -1.333477
[ Info: iteration 27, average log likelihood -1.333454
[ Info: iteration 28, average log likelihood -1.333436
[ Info: iteration 29, average log likelihood -1.333421
[ Info: iteration 30, average log likelihood -1.333409
[ Info: iteration 31, average log likelihood -1.333398
[ Info: iteration 32, average log likelihood -1.333390
[ Info: iteration 33, average log likelihood -1.333382
[ Info: iteration 34, average log likelihood -1.333374
[ Info: iteration 35, average log likelihood -1.333368
[ Info: iteration 36, average log likelihood -1.333362
[ Info: iteration 37, average log likelihood -1.333356
[ Info: iteration 38, average log likelihood -1.333351
[ Info: iteration 39, average log likelihood -1.333345
[ Info: iteration 40, average log likelihood -1.333340
[ Info: iteration 41, average log likelihood -1.333335
[ Info: iteration 42, average log likelihood -1.333330
[ Info: iteration 43, average log likelihood -1.333325
[ Info: iteration 44, average log likelihood -1.333320
[ Info: iteration 45, average log likelihood -1.333314
[ Info: iteration 46, average log likelihood -1.333308
[ Info: iteration 47, average log likelihood -1.333302
[ Info: iteration 48, average log likelihood -1.333296
[ Info: iteration 49, average log likelihood -1.333290
[ Info: iteration 50, average log likelihood -1.333283
┌ Info: EM with 100000 data points 50 iterations avll -1.333283
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.374098716602237
│     -1.3739897013257185
│      ⋮
└     -1.3332832078760328
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.333440
[ Info: iteration 2, average log likelihood -1.333273
[ Info: iteration 3, average log likelihood -1.332770
[ Info: iteration 4, average log likelihood -1.328613
[ Info: iteration 5, average log likelihood -1.314838
[ Info: iteration 6, average log likelihood -1.299526
[ Info: iteration 7, average log likelihood -1.290267
[ Info: iteration 8, average log likelihood -1.285196
[ Info: iteration 9, average log likelihood -1.281683
[ Info: iteration 10, average log likelihood -1.279262
[ Info: iteration 11, average log likelihood -1.277479
[ Info: iteration 12, average log likelihood -1.275779
[ Info: iteration 13, average log likelihood -1.274275
[ Info: iteration 14, average log likelihood -1.273202
[ Info: iteration 15, average log likelihood -1.272076
[ Info: iteration 16, average log likelihood -1.270857
[ Info: iteration 17, average log likelihood -1.269983
[ Info: iteration 18, average log likelihood -1.269551
[ Info: iteration 19, average log likelihood -1.269247
[ Info: iteration 20, average log likelihood -1.268934
[ Info: iteration 21, average log likelihood -1.268602
[ Info: iteration 22, average log likelihood -1.268271
[ Info: iteration 23, average log likelihood -1.267957
[ Info: iteration 24, average log likelihood -1.267684
[ Info: iteration 25, average log likelihood -1.267461
[ Info: iteration 26, average log likelihood -1.267299
[ Info: iteration 27, average log likelihood -1.267193
[ Info: iteration 28, average log likelihood -1.267135
[ Info: iteration 29, average log likelihood -1.267106
[ Info: iteration 30, average log likelihood -1.267092
[ Info: iteration 31, average log likelihood -1.267084
[ Info: iteration 32, average log likelihood -1.267080
[ Info: iteration 33, average log likelihood -1.267078
[ Info: iteration 34, average log likelihood -1.267076
[ Info: iteration 35, average log likelihood -1.267075
[ Info: iteration 36, average log likelihood -1.267075
[ Info: iteration 37, average log likelihood -1.267074
[ Info: iteration 38, average log likelihood -1.267073
[ Info: iteration 39, average log likelihood -1.267073
[ Info: iteration 40, average log likelihood -1.267072
[ Info: iteration 41, average log likelihood -1.267072
[ Info: iteration 42, average log likelihood -1.267072
[ Info: iteration 43, average log likelihood -1.267071
[ Info: iteration 44, average log likelihood -1.267071
[ Info: iteration 45, average log likelihood -1.267071
[ Info: iteration 46, average log likelihood -1.267070
[ Info: iteration 47, average log likelihood -1.267070
[ Info: iteration 48, average log likelihood -1.267070
[ Info: iteration 49, average log likelihood -1.267069
[ Info: iteration 50, average log likelihood -1.267069
┌ Info: EM with 100000 data points 50 iterations avll -1.267069
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3334399751492465
│     -1.3332732225294541
│      ⋮
└     -1.2670690641522544
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.267278
[ Info: iteration 2, average log likelihood -1.266997
[ Info: iteration 3, average log likelihood -1.264156
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.236530
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      3
│      4
│      8
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.203125
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.219507
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      8
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.191500
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│      7
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.191959
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      8
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.201792
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.198801
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      3
│      4
│      8
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.176261
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.205817
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.186991
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.177026
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.197783
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      7
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.187848
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     3
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.191224
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.194099
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      8
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.182982
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│      7
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.187131
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.196239
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.185597
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     1
│     3
│     4
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.177930
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.198247
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      4
│      8
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.182510
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.194111
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     4
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.186577
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.188733
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     3
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.184766
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.189575
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      8
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.182189
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      7
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.185918
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     4
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.184184
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.185932
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     1
│     3
│     6
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.175699
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      7
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.196309
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.189390
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      8
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.179394
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     4
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.184430
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.184919
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.182185
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      6
│      7
│      8
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.179276
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.198417
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.186669
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     4
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.178773
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.185559
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     3
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.180535
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.184500
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      7
│      8
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.175414
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      6
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.183018
┌ Info: EM with 100000 data points 50 iterations avll -1.183018
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2672784515179976
│     -1.2669969474051606
│      ⋮
└     -1.1830182903168334
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     1
│     2
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.189642
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.162787
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     14
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.167054
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.163016
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│     15
│     16
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.146264
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.119805
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.142919
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      5
│      7
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.116148
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     16
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.119652
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.118453
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     16
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.123407
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.114328
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.107476
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.122665
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.101479
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.105466
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.104509
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      5
│      7
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.111678
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.112635
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.110940
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.105392
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│     13
│     14
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.119122
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.090658
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     16
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.111619
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.093208
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.110353
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     16
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.104725
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.099384
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     16
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.106629
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.113002
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     16
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.100372
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.098409
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.093518
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.111823
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      8
│     14
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.114785
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.100730
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     16
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.098819
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.094480
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     14
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.114692
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.108885
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     16
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.101179
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.098838
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.107059
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.106376
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     16
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.102745
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.097729
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.102599
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.118361
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     16
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.098584
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.091827
┌ Info: EM with 100000 data points 50 iterations avll -1.091827
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.189641886001318
│     -1.162787295148233
│      ⋮
└     -1.0918274875978449
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4104084265271586
│     -1.4105221812776552
│     -1.4104246472691648
│     -1.4098845551218506
│      ⋮
│     -1.118360896817589
│     -1.0985838743128173
└     -1.0918274875978449
32×26 Array{Float64,2}:
 -0.118584     0.0833535     0.0266753   0.149694      0.0855243   -0.00996678   0.0285735   -0.260928     0.122598     0.159439    -0.00826544  -0.222997    0.0345058   -0.199668      0.0269176    0.119549    -0.200863     0.0310277   -0.438641    -0.0203898   -0.0354198   -0.713312      0.162933    -0.088638      0.0542757    0.17154
  0.0286575    0.082974      0.0224537   0.141629      0.0866065   -0.0100466   -0.287987     0.387007     0.135913     0.0686046   -0.0577669   -0.222439   -0.113084    -0.076083     -0.0475438    0.120458    -0.200761    -0.0338855    0.420281    -0.0219941   -0.100833     0.6658        0.0999412   -0.0907628     0.0473667    0.168263
  0.155721     0.163437     -0.0235598  -0.000286003  -0.0852162    0.0555228    0.109098    -0.203978     0.0526532   -0.135078    -0.0195856   -0.255466   -0.0748327    0.0102061    -0.123094    -0.16113      0.0508932   -0.0323865   -0.558388    -0.036854     0.121432     0.0517397    -0.0794696   -0.000659614   0.095355     0.0865195
  0.145643     0.108929     -0.0536537  -0.0439106    -0.0908635    0.0726533    0.0490522   -0.188954     0.0535635   -0.342156    -0.00649212  -0.243344   -0.0596735    0.00057866   -0.120827    -0.21574      0.0522764    0.023983     0.759955    -0.0259928   -0.0858123    0.0474571    -0.0939997   -0.148375      0.124561     0.0889148
  0.0809952   -0.0998068     0.0524481  -0.184223     -0.0592045   -0.0597647    0.12807      0.0738604    0.0832312   -0.102008    -0.181115     0.0316042   0.0496731    0.0245553     0.194674     0.0898393    0.074495     0.0583064   -0.106991    -0.0558687   -0.101425    -0.104922     -0.0131371   -0.202754      0.0298958    0.0607405
 -0.278366     0.00658942   -0.0459032   0.103573     -0.0493054    0.0665497    0.137615     0.0645207    0.0346888   -0.0614974   -0.00911502  -0.0262471  -0.00746717  -0.0737353    -0.149841    -0.0757362    0.054153    -0.185338     0.0788206   -0.117923     0.0426522   -0.0125608     0.0495853    0.0050144    -0.213356    -0.00718225
 -0.0500543    0.00253057    0.123478   -0.0835117    -0.0849876   -0.107724     0.106011    -0.208891     0.120264    -0.234421    -0.0885925    0.109577    0.318496    -0.513508      0.0994559    0.225025     0.00528981   0.0698946    0.147303    -0.00443409   0.046983    -0.320814      0.0514941    0.0176689     0.21594     -0.0253992
 -0.0503067   -0.038061      0.0547777   0.150528     -0.0660804   -0.107976     0.10504     -0.209434     0.109696    -0.0501526    0.127544    -0.109565   -0.226741     0.193222     -0.066032     0.229175     0.106143     0.0687071    0.163128     0.0139412   -0.0110692    0.446538      0.0588029   -0.054215      0.20909     -0.0928271
  0.0167401    0.0650538     0.127331    0.135563      0.185319     0.152756    -0.0595709   -0.0813339    0.275494     0.141053    -0.0660616    0.127683    0.103537     0.139207     -0.0629037    0.0811235   -0.0454988    0.0876927   -0.023013     0.139124     0.0384106    0.00507827   -0.0255351   -0.112079     -0.0822222   -0.0112576
  0.0522539   -0.148829      0.0764518   0.0285711    -0.112036    -0.0625488    0.0116612   -0.0250081    0.0371686    0.0316559   -0.0625909   -0.0380193   0.0727634   -0.00843427   -0.114181    -0.00753197  -0.0525561    0.07503     -0.0432633   -0.121883     0.00162733  -0.0892469     0.0475373   -0.0731832     0.0103379    0.0590941
  0.019297    -0.0173224    -0.0325404  -0.171521      0.0576949    0.0200021   -0.0878349   -0.101522    -0.0643253    0.0446613    0.0269836   -0.0230321   0.0384876    0.0160663    -0.138318    -0.103547     0.053539     0.0786583    0.0267689   -0.0678359   -0.0593073    0.0398713     0.0287241   -0.0479239     0.0459711   -0.0684596
  0.0509278   -0.001489      0.130387   -0.0698843     0.0285763   -0.0208519   -0.0918287   -0.092226    -0.0595689   -0.0426468   -0.116789    -0.0991932  -0.0463787    0.0552553     0.0126426   -0.041257    -0.114174     0.0537467    0.0490028   -0.0895591   -0.0734389   -0.084401      0.0273209   -0.0207424     0.0861382    0.0131994
 -0.0289338    0.109831     -0.0972707   0.187153     -0.0559598   -0.04091      0.0432956   -0.189449    -0.0153879   -0.0305574    0.0895706    0.0940723  -0.135505    -0.164725     -0.16859      0.16696     -0.0135728   -0.0671981   -0.223412    -0.0718075   -0.0148236   -0.118825     -0.135033    -0.114449      0.00286107  -0.0877218
  0.0602076   -0.0702809    -0.033904   -0.11193       0.0147559    0.023916    -0.0400468   -0.14926      0.00506046   0.0330294   -0.0711907    0.16769    -0.199103     0.01863       0.0618442   -0.21554     -0.0696351   -0.0332801    0.05818      0.0199206   -0.00194426  -0.0678172     0.011983     0.086502      0.040483     0.0573681
 -0.0266797    0.17854      -0.155206   -0.0962957     0.0153979    0.0359675    0.135876     0.256222     0.0858846   -0.11446     -0.0542066   -0.0224392  -0.165157    -0.0791048     0.0422071   -1.10524      0.0244215    0.0255621    0.23878     -0.0144592   -0.200351    -0.000864709   0.0109092    0.157914     -0.0306466   -0.304158
  0.179145     0.178515     -0.145793   -0.100049      0.0120241    0.0398968    0.0353136    0.21457     -0.0378908   -0.113288    -0.0544193    0.0481273  -0.167023     0.161579      0.0424639    0.689171     0.0346958    0.0177138    0.160448     0.0307611   -0.120704    -0.0239082     0.00979878   0.162543     -0.0267552    0.312096
 -0.0676689   -0.088881     -0.156656    0.192906     -0.02729      0.0208268   -0.0304024   -0.00438607   0.0303101   -0.00503101   0.00454051  -0.0570347   0.0237722   -0.179203     -0.151841    -0.0169871    0.108292     0.0704887    0.0525305    0.191724    -0.0237921    0.0228311    -0.29148      0.0871908    -0.0844413    0.142808
 -0.124206     0.123918      0.0249438  -0.108895     -0.0347216   -0.11533      0.0593483    0.116867    -0.102475     0.0187618    0.143763     0.0484973  -0.00425971   0.127737      0.0687042   -0.0229436    0.00966706  -0.183245    -0.15679      0.0747209   -0.128192    -0.114662      0.0574594   -0.0146922    -0.0589441    0.0751125
  0.0254354    0.0540431    -0.0409022   0.00742152   -0.00173177  -0.0447435    0.048777    -0.0035575   -0.0727064   -0.124418    -0.00523214   0.113124   -0.0286801   -0.0359554    -0.0108541    0.0380995   -0.0309592   -0.00893027   0.00411336   0.0399714   -0.0852092    0.0172673     0.039855    -0.044933     -0.0635196   -0.0301765
  0.0110018   -0.0122607     0.0382628   0.0517566     0.158508     0.0484777    0.0993097   -0.0352869    0.0197707    0.0697072    0.048986     0.116423   -0.0421213    0.0405694    -0.0100387    0.0276673   -0.0199006   -0.00340966   0.00279688  -0.0138568    0.0242476   -0.109593     -0.0553566   -0.0305525     0.0153215   -0.00432437
  0.136141    -0.000341526   0.029432   -0.0413143     0.0542378    0.00508038  -0.0986382   -0.0188038   -0.0515858   -0.0832185   -0.0383187    0.0337117  -0.11412     -0.0483915     0.0954855   -0.0644658    0.0327687    0.0116031   -0.173423    -0.0461502   -0.0507395   -0.0610545    -0.0460939   -0.143844     -0.00258172   0.0484
 -0.0958052    0.018459     -0.0407403   0.016601      0.0132276   -0.121896    -0.026215     0.0376923    0.0566057   -0.00132714  -0.0497981   -0.054634    0.108249    -0.110476     -0.109048    -0.0974255    0.175987     0.0934978    0.0870408   -0.0975834    0.0474498    0.107428     -0.0515339    0.0150753    -0.148461    -0.0597703
  0.177892     0.170599     -0.0562688  -0.0849304    -0.183286     0.111333    -0.10635      0.036574    -0.0436009    0.143387    -0.0169148   -0.114714   -0.156441    -0.160858      0.211624     0.0749898   -0.00894674   0.0115425   -0.165153    -0.0982013   -0.00661673  -0.0268745     0.0624307   -0.0308782    -0.0735114   -0.0542766
 -0.144538    -0.181083     -0.101283   -0.0975282     0.061941     0.0584419   -0.206961    -0.0157567   -0.0677707   -0.00257634  -0.0557297   -0.0591669  -0.106188    -0.176435      0.140122    -0.100726    -0.00378902  -0.0454737   -0.0572599    0.0785924    0.189717     0.101973      0.075384    -0.0578296     0.00770756  -0.142232
  0.100012     0.0305289     0.0174101  -0.14613      -0.0379463    0.956223     0.0191135    0.0670466   -0.0426123   -0.0706802   -0.116866     0.0753981  -0.031014     0.0709112     0.0696361    0.0538218   -0.131454    -0.202318     0.100996    -0.149438    -0.148034    -0.0500253    -0.0416868   -0.0783398    -0.0409033   -0.133265
  0.111221     0.106574      0.0176389  -0.106743     -0.0383925   -0.443541     0.0203611    0.0511118   -0.0470408    0.142652    -0.155033     0.0673929  -0.091758    -0.0303755     0.064235    -0.0893211   -0.148523    -0.169012    -0.417022    -0.0883203    0.306662    -0.0421968    -0.0431002   -0.0966962    -0.0388437   -0.14862
  0.0394705    0.0441484    -0.138526   -0.120638     -0.00313593   0.0655454    0.00234839   0.19275      0.0568647    0.0718848   -0.116899     0.247824    0.0498299    0.0563472    -0.121755    -0.0253989   -0.04629     -0.408136    -0.0482176    0.151767    -0.295804    -0.0309507     0.198704    -0.172196     -0.22942     -0.307638
  0.148371     0.0563938    -0.112924    0.0329864    -0.0136971   -0.0405071    0.02273      0.198348    -0.015299     0.152681    -0.0988818    0.189551    0.105906    -0.0170979    -0.191431    -0.0561505   -0.00233963   0.436419    -0.0459592    0.201327    -0.296034     0.0119121     0.251156    -0.162996      0.169573    -0.02898
  0.0256912   -0.225646     -0.145276   -0.0668012     0.00999557   0.0884228   -0.0183602    0.0683147    0.185014     0.100044    -0.111886    -0.037201   -0.0383096   -0.00374778    0.00903225  -0.96046     -0.149697    -0.00920799   0.130335    -0.0252458   -0.104915     0.0278049     0.334083    -0.0113575     0.0523789    0.0725379
 -0.0976813   -0.220568      0.056928   -0.0490093     0.0164616    0.0840051   -0.0171659    0.0696679    0.226502     0.0736465    0.235576     0.0938223  -0.0422418   -0.000627027   0.0773491    0.712344    -0.0170467    0.111357     0.0334242   -0.062098    -0.168941     0.0271801    -0.392155     0.00956373    0.0492025   -0.015868
 -0.00219415  -0.0568415    -0.25255    -0.00834962    0.00249649  -0.0258715   -0.024618    -0.0010646    0.0482742   -0.0615182   -0.0825044   -0.210565    0.0730253   -0.0300849     0.0995188    0.139446     0.166462    -0.215885    -0.255528     0.128881    -0.0328974    0.157125      0.0785679   -0.0361692     0.07514     -0.0992467
  0.0209999   -0.0583872    -0.116881   -0.0159607     0.0223681    0.0143805    0.172302     0.0293315   -0.0927009   -0.020913    -0.128721    -0.152577    0.0489713    0.102681      0.062213     0.118451     0.075438     0.0924993   -0.224384     0.13806     -0.00365033   0.142121      0.0140758   -0.0259015     0.137311    -0.206778[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     16
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.086191
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.073732
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.083603
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.077518
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.084358
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.077500
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.084374
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.077499
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.084375
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.077497
┌ Info: EM with 100000 data points 10 iterations avll -1.077497
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.001173e+05
      1       6.852014e+05      -2.149158e+05 |       32
      2       6.554730e+05      -2.972844e+04 |       32
      3       6.441017e+05      -1.137128e+04 |       32
      4       6.380105e+05      -6.091248e+03 |       32
      5       6.331730e+05      -4.837440e+03 |       32
      6       6.294724e+05      -3.700585e+03 |       32
      7       6.267839e+05      -2.688529e+03 |       32
      8       6.239962e+05      -2.787707e+03 |       32
      9       6.212540e+05      -2.742217e+03 |       32
     10       6.186299e+05      -2.624059e+03 |       32
     11       6.162879e+05      -2.342048e+03 |       32
     12       6.148358e+05      -1.452127e+03 |       32
     13       6.141436e+05      -6.921608e+02 |       32
     14       6.136348e+05      -5.088362e+02 |       32
     15       6.130923e+05      -5.424579e+02 |       32
     16       6.125032e+05      -5.891342e+02 |       32
     17       6.119654e+05      -5.377937e+02 |       32
     18       6.115084e+05      -4.569781e+02 |       32
     19       6.110882e+05      -4.201634e+02 |       32
     20       6.106581e+05      -4.301733e+02 |       32
     21       6.102248e+05      -4.332358e+02 |       32
     22       6.098446e+05      -3.801760e+02 |       32
     23       6.094828e+05      -3.618007e+02 |       32
     24       6.092043e+05      -2.785690e+02 |       32
     25       6.090291e+05      -1.751423e+02 |       32
     26       6.088796e+05      -1.495319e+02 |       32
     27       6.087736e+05      -1.060338e+02 |       32
     28       6.086942e+05      -7.939670e+01 |       32
     29       6.086271e+05      -6.709276e+01 |       31
     30       6.085699e+05      -5.718964e+01 |       31
     31       6.085113e+05      -5.856055e+01 |       32
     32       6.084452e+05      -6.609565e+01 |       30
     33       6.083761e+05      -6.912164e+01 |       31
     34       6.082957e+05      -8.039823e+01 |       32
     35       6.081924e+05      -1.032786e+02 |       31
     36       6.080768e+05      -1.156507e+02 |       31
     37       6.079388e+05      -1.379631e+02 |       31
     38       6.078234e+05      -1.154122e+02 |       31
     39       6.077184e+05      -1.050302e+02 |       32
     40       6.076155e+05      -1.028341e+02 |       32
     41       6.075588e+05      -5.678581e+01 |       31
     42       6.075315e+05      -2.726452e+01 |       31
     43       6.075150e+05      -1.648907e+01 |       30
     44       6.075023e+05      -1.266497e+01 |       28
     45       6.074893e+05      -1.303593e+01 |       27
     46       6.074745e+05      -1.477577e+01 |       28
     47       6.074562e+05      -1.834525e+01 |       27
     48       6.074323e+05      -2.392974e+01 |       27
     49       6.074081e+05      -2.417271e+01 |       31
     50       6.073847e+05      -2.340662e+01 |       31
K-means terminated without convergence after 50 iterations (objv = 607384.6741603927)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.324704
[ Info: iteration 2, average log likelihood -1.298432
[ Info: iteration 3, average log likelihood -1.276959
[ Info: iteration 4, average log likelihood -1.254145
[ Info: iteration 5, average log likelihood -1.222063
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.167696
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.140423
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      3
│      8
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.124176
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     16
│     21
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.123854
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     17
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.095100
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.099716
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      6
│     11
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.107308
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      8
│     14
│     15
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.107535
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.129159
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.098173
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      6
│      7
│     15
│     21
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.074434
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     11
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.125196
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.118766
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.091046
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     17
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.082662
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      7
│     14
│     21
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.096868
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.120994
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.102538
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      2
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.097817
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     11
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.095970
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      7
│     17
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.088262
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     14
│     15
│     16
│     19
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.084709
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│      8
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.115695
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.119685
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     11
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.087363
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     15
│     16
│     20
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.068994
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      2
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.121626
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     19
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.118703
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     17
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.091492
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     15
│     16
│     20
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.066428
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│      6
│     21
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.111066
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.124199
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     14
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.082487
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     15
│     16
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.072347
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      6
│      8
│     17
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.099631
[ Info: iteration 41, average log likelihood -1.144030
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.088038
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     15
│     16
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.070230
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      6
│      8
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.110577
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.140267
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.087305
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     15
│     16
│     20
│     21
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.066048
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│      8
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.119309
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.124688
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     14
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.076274
┌ Info: EM with 100000 data points 50 iterations avll -1.076274
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.187796     -0.0399146   -0.0427834  -0.117562    0.0391481    0.0338484   -0.174287    -0.00323109   -0.0702431   -0.175221     0.0674131    0.150021   -0.0643863    0.0131795    0.0948641   -0.0164798    0.06415      0.0361729   -0.26603     -0.0980938    -0.0612358   -0.0365159    -0.188988    -0.139853     -0.0530018     0.141169
  0.104832      0.0802413    0.0216613  -0.143942   -0.0282618    0.0736349    0.0276084    0.0600323    -0.0443051    0.0874647   -0.129909     0.0755756  -0.0883009    0.00212467   0.0704602   -0.0310652   -0.12424     -0.1738      -0.214064    -0.101418      0.162562    -0.058969     -0.053874    -0.0926487    -0.0298749    -0.151574
  0.0956021     0.0504863   -0.125033   -0.0409727  -0.00861256   0.0107165    0.0127955    0.19561       0.0193346    0.114422    -0.107517     0.217275    0.0782732    0.0193332   -0.157698    -0.0412007   -0.0235314    0.026652    -0.0471146    0.177061     -0.296229    -0.00937595    0.225661    -0.167423     -0.0242593    -0.164604
  0.11788      -0.0607242    0.0326317  -0.0419811  -0.0608957   -0.0735393    0.024147    -0.0762341    -0.0380323   -0.0788494    0.0646305    0.160372   -0.0122105   -0.0736093    0.0802084   -0.066538     0.0723752   -0.0181156   -0.0799574    0.140458     -0.092061    -0.0169725     0.040942     0.0116499     0.163769      0.0722591
 -0.000466573  -0.129596    -0.107585    0.0970757   0.209975     0.126575     0.205892    -0.11852       0.0220542    0.0392459   -0.0742223    0.223711   -0.00898387   0.17608      0.046697     0.0193255    0.0590884    0.0429065   -0.0958307   -0.134908     -0.0888624   -0.0299964    -0.0680265    0.123911      0.0333054     0.0069066
  0.0371049     0.0414144    0.0432709   0.0397603   0.248379     0.0814773    0.167204     0.10511      -0.00967673   0.093664     0.0971429   -0.132523   -0.300669    -0.0309903    0.0892906    0.0530451    0.0781963    0.142877     0.0381212   -0.0047159     0.136271    -0.220935     -0.214089    -0.123379      0.160084     -0.183323
 -0.187894      0.0495839   -0.0388076   0.0385928  -0.0530014   -0.0120092   -0.141664    -0.070459      0.100075     0.0117983   -0.109863     0.027278    0.168599    -0.125815     0.0439137   -0.108071     0.138215     0.101245     0.0333005   -0.147563      0.0594066    0.082106     -0.165366    -0.0892901    -0.19621      -0.131261
  0.0495711    -0.0339602    0.166683   -0.0166868   0.0309646   -0.0363896   -0.126906    -0.0805695    -0.0528106   -0.063412    -0.15963     -0.115101   -0.0177098    0.116443     0.00900019  -0.040209    -0.120223     0.0533738    0.0561798   -0.13331      -0.0404817   -0.110706      0.0607038   -0.0258499     0.0933597     0.0129062
  0.154894      0.147496    -0.0199399   0.0259617   0.145355    -0.0114913    0.0899539    0.00358644   -0.019252    -0.164179    -0.0254898    0.0383559  -0.0837657   -0.0687803    0.00960107  -0.121901    -0.014736     0.158507    -0.134322    -0.0671648    -0.112911    -0.0966111     0.0906061   -0.186244      0.0518494     0.014601
  0.00772967   -0.0591473   -0.19928    -0.0114056   0.0113936   -0.00113027   0.0640425    0.0141629    -0.015627    -0.047303    -0.107494    -0.186899    0.0652555    0.0282567    0.0856582    0.135179     0.127139    -0.077981    -0.247827     0.134311     -0.0186731    0.14999       0.047657    -0.0315425     0.105541     -0.147748
 -0.145593     -0.179903    -0.112738   -0.0978498   0.0650126    0.0607606   -0.204146    -0.0094965    -0.0753877   -0.0201295   -0.0435639   -0.0579784  -0.0244395   -0.0363122    0.156574    -0.096494    -0.00991635  -0.0362467    0.0259686    0.0334981     0.189989     0.111138      0.0932759   -0.0419774     0.0198008    -0.1321
  0.178604      0.173741    -0.0564681  -0.0851638  -0.178166     0.111688    -0.105875     0.0367851    -0.0445741    0.143615    -0.0153623   -0.114914   -0.156476    -0.160556     0.212239     0.0745807   -0.00884943   0.00921052  -0.166116    -0.0984164    -0.00683389  -0.0267877     0.0630904   -0.0295027    -0.0706595    -0.0540613
  0.0395034    -0.0484049    0.106396   -0.109071    0.0735338   -0.059629     0.0901979    0.0299356     0.0589848   -0.0213197    0.0192784    0.084842    0.0990653    0.0345022    0.0187786    0.0520625    0.0644436   -0.0201489   -0.0799031    0.00682494   -0.0462266   -0.15741      -0.017424    -0.156926     -0.00511978    0.00820247
 -0.0131018    -0.125103     0.166868    0.0175177  -0.0315452   -0.0216441   -0.177942    -0.112906     -0.0394291    0.184774    -0.18437     -0.131499   -0.22443     -0.06868      0.184984    -0.0575072    0.0173299   -0.135095    -0.103311     0.057109      0.0773439   -0.034288      0.0282372   -0.0844934     0.00293017   -0.0371707
 -0.0452057     0.08185      0.0245938   0.145077    0.085612    -0.00975403  -0.124865     0.0552268     0.128523     0.115094    -0.032875    -0.221426   -0.0378943   -0.138826    -0.00809289   0.119604    -0.200042    -0.00161214  -0.0199608   -0.0214085    -0.0684592   -0.0338032     0.130623    -0.0908519     0.0504319     0.169806
 -0.143256     -0.188369    -0.125286   -0.137126    0.0797617    0.0758601   -0.220992     0.00723774   -0.0759179   -0.0185609   -0.0260585   -0.0536986  -0.172831    -0.349333     0.112739    -0.108618    -0.0044519   -0.0407082   -0.137112     0.115225      0.201782     0.0998281     0.0437333   -0.0714976    -0.0233626    -0.164769
  0.044538      0.0300336    0.0939956  -0.0874365   0.00636217  -0.00140601  -0.03064     -0.0908768    -0.044887    -0.0847546   -0.102139    -0.0890177  -0.041171     0.0548515    0.0301145   -0.0370701   -0.097526     0.0453897    0.0477326   -0.0960136    -0.114012    -0.0809465     0.0223002   -0.00921147    0.0917484     0.0161737
 -0.00631339   -0.0305617   -0.03902    -0.0127867   0.0681855   -0.226515     0.0535452    0.1042        0.0218159   -0.00918458   0.00469624  -0.130828    0.0625293   -0.0917046   -0.244412    -0.0985665    0.239458     0.0744746    0.139581    -0.0366058     0.0427624    0.15039       0.0436067    0.128757     -0.103214      0.00269956
  0.0512262    -0.167637     0.0662437   0.0404155  -0.126135    -0.0677571    0.0396281   -0.0343108     0.0507362    0.0294906   -0.0658807   -0.0118115   0.0890656    0.00419331  -0.0891546   -0.00098971  -0.0549434    0.0807689   -0.0423184   -0.131737      0.00439493  -0.0846552     0.0499842   -0.0837758     0.00095968    0.0911246
  0.0424696     0.0883777    0.0644069   0.13964     0.0162832    0.0328377    0.0526144   -0.00205893    0.0237212    0.0379532   -0.00965765   0.128618   -0.0418668   -0.0694513    0.0164593    0.0557599   -0.230311    -0.0518894    0.123847     0.0188564     0.0424471   -0.000934716   0.0242448   -0.07297      -0.0596862     0.132003
 -0.0568959     0.172459    -0.108926    0.059935    0.05372     -0.0101049    0.0780251    0.065361     -0.10599     -0.173766    -0.074322     0.0687849  -0.0658971   -0.00678579  -0.101376     0.141925    -0.122577    -0.00137947   0.0905147   -0.0662243    -0.0741091    0.0480542     0.023804    -0.103059     -0.260947     -0.1201
 -0.0659547    -0.0882919   -0.157872    0.193135   -0.0276315    0.0214579   -0.0302399   -0.000346081   0.0295269   -0.00544063   0.00378253  -0.0564294   0.0227794   -0.179774    -0.148895    -0.0168083    0.108401     0.0724166    0.0491997    0.195237     -0.0238814    0.0238052    -0.291198     0.0908343    -0.0864431     0.143636
 -0.0197499    -0.0796895   -0.128995   -0.139356    0.00300253   0.0260579    0.0335213   -0.138452     -0.0298277    0.002601     0.0241731    0.0737809   0.0726266    0.0543782   -0.0558965   -0.0485587    0.0473794    0.114292     0.0343166   -0.115741      0.00667756   0.0470957     0.0665133   -0.0932148     0.0635254    -0.00367303
  0.0596674    -0.0684376   -0.0464538  -0.112376    0.0114998    0.0297079   -0.0378182   -0.150102      0.00785946   0.0277698   -0.0668238    0.169661   -0.198554     0.0212454    0.0617189   -0.213279    -0.0667265   -0.0327035    0.0626376    0.017962     -0.00356693  -0.0615713     0.0109816    0.0936221     0.0403787     0.0571306
 -0.0277776     0.0343823    0.096777   -0.0661516   0.00376644   0.00414266  -0.00930396  -0.0414336     0.0139342    0.12182     -0.0403895    0.0371386  -0.0526209   -0.0738024    0.00999334   0.0448373   -0.238408    -0.0704391    0.121053     0.0184375     0.032659    -0.128102      0.0237898   -0.07479      -0.0583163     0.100246
 -0.0767422     0.116769    -0.0393492   0.047077   -0.0447535   -0.0816092    0.05065     -0.0398724    -0.0594927   -0.00627669   0.120045     0.0872076  -0.0630854   -0.012783    -0.0584539    0.070687    -0.00373608  -0.135751    -0.189756    -0.000547646  -0.0715272   -0.12335      -0.0448611   -0.0615503    -0.0306516    -0.00606798
  0.0545019     0.0556401    0.10332    -0.208927    0.0830159    0.00193335  -0.239866     0.0113453    -0.113989     0.0812158    0.017105    -0.150365   -0.0420298   -0.0501513   -0.266985    -0.136019     0.0186415    0.020209    -0.00773809   0.00310431   -0.139761    -0.011774     -0.0252087    0.0143032     0.0294835    -0.143062
 -0.163806     -0.00506939   0.0174465   0.0726427  -0.0639646   -0.0209473    0.121996    -0.0747511     0.0760954   -0.10433      0.00973059  -0.0162519   0.0177994   -0.111685    -0.0735509    0.07501      0.0600283   -0.0605056    0.120602    -0.0564753     0.0329959    0.0351338     0.0534541   -0.00679427   -0.000644409  -0.03146
  0.0167467     0.0613073    0.125603    0.161145    0.201456     0.163416    -0.0540402   -0.0883991     0.301335     0.144707    -0.0744298    0.148187    0.120715     0.152574    -0.029656     0.0871287   -0.0514112    0.0903738   -0.0217814    0.139487      0.0530292    0.014715     -0.022376    -0.119563     -0.0929984    -0.00666359
 -0.0404421    -0.223119    -0.0430453  -0.058564    0.0133387    0.0874335   -0.0168903    0.0687839     0.20811      0.0855687    0.0673343    0.0339549  -0.040221    -0.00206017   0.0436487   -0.0992682   -0.0834097    0.051106     0.0821627   -0.0449985    -0.141588     0.0272022    -0.0351399   -0.000701555   0.0513853     0.027896
  0.0818366     0.177608    -0.141418   -0.0870061   0.0124155    0.0390868    0.0803533    0.240427      0.0218435   -0.116679    -0.0531178    0.0159858  -0.170876     0.0393114    0.0354201   -0.118618     0.0310054    0.0229049    0.194528     0.00980802   -0.152271    -0.0192932     0.00794625   0.150376     -0.0288524     0.0180686
  0.151021      0.136893    -0.039289   -0.0218953  -0.0926722    0.0650487    0.0823612   -0.197034      0.0520033   -0.242587    -0.015377    -0.250507   -0.0668364    0.00567457  -0.120631    -0.189624     0.0517149   -0.00406005   0.105519    -0.0311341     0.0169995    0.050015     -0.089318    -0.0775705     0.111128      0.0883926[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     15
│     16
│     17
│     21
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.065066
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      7
│     15
│      ⋮
│     23
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.032059
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      6
│      7
│      8
│      ⋮
│     21
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.026076
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      7
│     11
│      ⋮
│     24
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.034064
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      7
│     15
│     16
│     17
│     21
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.040945
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     25
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.010202
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     15
│     17
│     21
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.054493
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     24
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.020429
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│      7
│     15
│      ⋮
│     21
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.030747
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      7
│     14
│      ⋮
│     23
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.036332
┌ Info: EM with 100000 data points 10 iterations avll -1.036332
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0523037    0.000444068   0.0132202    0.141063     0.170557   -0.0580769    0.0731413    0.0289038   -0.0680439   -0.038931      0.00820724   0.0850405   -0.255503    0.0481116   0.139438      0.167232     0.0907632   -0.0169788    0.0187526  -0.162773    0.103593    -0.016078     0.100028    -0.0455063     0.100861     0.0424897
  0.114455     0.224127      0.0301339   -0.134549     0.0537673   0.0327657   -0.102973    -0.266017     0.0600755    0.00861926   -0.107624     0.00370177  -0.0489809   0.0651839  -0.0200121    -0.099286    -0.166681     0.0554252    0.0676058  -0.189802    0.15008      0.0713948   -0.0819005   -0.0304903    -0.155217     0.0128686
 -0.00777943  -0.159214     -0.0551764   -0.0485786   -0.203815   -0.0361271   -0.00142748   0.013127     0.0779156   -0.0389864    -0.0649999    0.0732242   -0.070701    0.0406238   0.0220587     0.0177205   -0.133143     0.111378    -0.0449628   0.0474738   0.0468076   -0.0121226   -0.12651     -0.000270478   0.0340886   -0.00162077
 -0.182276    -0.0375347     0.0592436   -0.00769907  -0.221445    3.61471e-5   0.0171762   -0.0668863   -0.0403788   -0.00604629   -0.0414445   -0.0851713   -0.0847202  -0.0666091   0.0202813     0.0625334   -0.0236845   -0.00636928  -0.235197   -0.0401386  -0.164083     0.165294     0.0761824    0.0774888    -0.0743883    0.0559731
  0.0350638   -0.101577      0.038632     0.0660143    0.0866495   0.0193589   -0.233566    -0.0267734    0.019971    -0.0397301     0.0737844   -0.0422076   -0.0320103   0.0680147   0.14831       0.104462    -0.0604236    0.0356609    0.158779   -0.111593   -0.0962214   -0.0115943   -0.0267644    0.0336289     0.0295      -0.102761
 -0.0541915   -0.234825      0.218851     0.0220757    0.0695185   0.0848972   -0.0749658   -0.270973     0.0472759    0.0838399    -0.0255724   -0.0597653    0.112384   -0.0343461   0.0782846     0.029054    -0.0291348    0.268999    -0.0454759   0.0962412   0.153969    -0.0264685    0.0259852   -0.0584052    -0.00392501  -0.0415666
  0.117415    -0.0305698     0.16404      0.0841709   -0.0323698  -0.103521     0.136326     0.0832665    0.167157     0.0124084     0.08632      0.0532235    0.0610622  -0.057179    0.146533     -0.0656015    0.00752187   0.095694    -0.168303    0.289141    0.165532    -0.0641735    0.0526146   -0.107846      0.00898955   0.0653837
  0.107238     0.062898     -0.131984    -0.0171298    0.0213402   0.095953     0.0213416   -0.0726322    0.0668837    0.167494     -0.173039    -0.0773835    0.0621894   0.0801524  -0.0676977    -0.0458412   -0.10332     -0.0878028   -0.13515     0.157893   -0.0078535   -0.130784     0.0248287   -0.00212922    0.137583    -0.0368074
 -0.0799203   -0.0224548    -0.0885636    0.091312     0.151388    0.0715661    0.146014    -0.0459814   -0.059758     0.150224      0.11124     -0.0492431   -0.0336547  -0.0576646   0.131137      0.113812    -0.135346     0.00237257  -0.24123     0.233239   -0.00531015  -0.0729503   -0.0727106   -0.120934      0.0542951   -0.0207444
 -0.119235    -0.0428074     0.0630155   -0.0601824   -0.102022    0.164182     0.0711282    0.0205507    0.0367499   -0.0418989    -0.18385      0.135573    -0.0962335  -0.0844768  -0.0699901    -0.179843    -0.161589     0.0993047    0.0589022   0.0512664  -0.12263     -0.00637451  -0.0066953   -0.151999     -0.340242     0.241961
  0.177108    -0.127769     -0.064414     0.0658181   -0.0203478  -0.0684304    0.0503681   -0.222743     0.0672505    0.0551085     0.0330379    0.012321     0.105251   -0.151288    0.117307     -0.0364898   -0.0764943   -0.0699766   -0.153431    0.0301369  -0.0452698    0.0821341    0.0184006    0.110698      0.0203204   -0.0113724
  0.0309105   -0.179915     -0.0926919    0.164327     0.105848    0.11344     -0.135588    -0.0569983   -0.177033    -0.116426      0.116232     0.0417975    0.128865   -0.042299    0.0445638    -0.00814541   0.0926191    0.111428     0.11384    -0.051503   -0.066075    -0.23632      0.149212    -0.0803094    -0.0789673    0.0925166
 -0.0288094    0.051823      0.0734024    0.139282     0.0172343   0.083317     0.11556      0.00477676  -0.148403     0.0126488    -0.00357961   0.20315      0.101057    0.0198137   0.162515      0.153729    -0.0895353    0.137398    -0.0249135  -0.149417   -0.0868522    0.0415642   -0.0435076   -0.165909     -0.0860451   -0.0286888
  0.00601254   0.200376      0.0065936   -0.125232    -0.0680578  -0.0656016    0.206627     0.0634708   -0.116928     0.000317335   0.0814252   -0.100067    -0.01357    -0.0863627  -0.0683634     0.0218003   -0.0338494   -0.0441354    0.24506    -0.0471525  -0.206139    -0.0297707   -0.08119      0.238749     -0.0694604   -0.106795
  0.277489     0.0563332    -0.0686274   -0.187009    -0.198634   -0.031988     0.033372    -0.00626929  -0.0585486   -0.117389      0.0948838    0.106518     0.0822214  -0.0742944   0.00071569    0.0341574    0.0479787   -0.219074     0.058586    0.0400003   0.00225366  -0.137943     0.169359    -0.107228      0.064658     0.0884974
  0.0624609    0.083363     -0.173223     0.132279    -0.0282035  -0.00256411   0.0534581    0.0164059    0.118884     0.00191443    0.0724993    0.0537871    0.14939     0.0855259  -0.0218274    -0.0700448   -0.0673157   -0.0866063    0.0314603   0.151523   -0.0595395   -0.034176    -0.105999     0.0428458     0.0382445   -0.105504
 -0.0922717   -0.0502898     0.0544058    0.0286406   -0.0187302   0.0968459   -0.108567     0.0120375    0.0130426    0.00138311   -0.0398473    0.1944      -0.016227    0.0770734  -0.122664     -0.168437    -0.00968075   0.0658099   -0.0840578   0.0575553  -0.022366     0.26585     -0.0753029    0.0352447     0.0595889    0.0156777
  0.0444564   -0.102451      0.164622    -0.0066165    0.093593    0.0492577    0.136415     0.192263    -0.0847783    0.0293819     0.0108369    0.0536496   -0.0928854   0.0219181  -0.0385461     0.075797     0.0574073    0.0645436    0.135614    0.127435   -0.0891256    0.0474101    0.0489713   -0.107739     -0.147563     0.0254823
 -0.0837494    0.00539987    0.0495933   -0.0238871   -0.0682273  -0.0808711    0.0253332    0.116981    -0.0644869   -0.0620362     0.138343     0.00596743   0.117553    0.0507218   0.0652167    -0.0409274    0.148867    -0.0387005    0.0361431   0.0497365  -0.0775605   -0.0235233    0.324698     0.108832      0.0162053    0.125565
  0.0126915    0.00835087   -0.0541351    0.0413605   -0.134332   -0.0718424    0.164159     0.101541    -0.195558     0.167542     -0.0948439   -0.0682229    0.0210987   0.0352127  -0.0170542    -0.0915538    0.102072     0.0129517    0.0962197  -0.14797     0.0283091   -0.0225537    0.0213928   -0.226211      0.138706    -0.142814
  0.0420284   -0.0360066    -0.0494924   -0.0106795   -0.0466961  -0.221526     0.0876784    0.0861662    0.0497873   -0.0533569    -0.0527885    0.00901756  -0.0479434  -0.0260533   0.13341       0.0454339   -0.0101282    0.113689     0.0376867   0.0788867   0.0104021    0.0133918    0.0968959    0.10296      -0.0419193   -0.0268482
 -0.0100583   -0.173165     -0.273151     0.0615072   -0.190679   -0.16119     -0.155769    -0.102688     0.0844484   -0.0919847     0.144271     0.0272901    0.151357   -0.0265457   0.233907     -0.0955731   -0.19429      0.0476647   -0.0164632   0.0727723   0.00251007  -0.13666     -0.032544     0.000220208  -0.0417155   -0.109492
  0.0130882   -0.025171      0.0697339   -0.0454381    0.123194    0.226986     0.0204248   -0.0886753   -0.00167181   0.00331632   -0.0591497   -0.0929817   -0.0445706   0.0905524  -0.0216012    -0.0917325   -0.176655     0.00380819  -0.193818    0.140009    0.0238644   -0.148422    -0.132165     0.0716201     0.108745     0.0812302
 -0.213825    -0.106635      0.126077    -0.100964    -0.297268    0.0552952    0.106166     0.020972    -0.0371971   -0.0685607     0.13296      0.0235347    0.180081   -0.0678219  -0.0568198    -0.00409189   0.0736789   -0.0290358    0.0888453   0.0549871  -0.130534    -0.0384455    0.00669186  -0.0772168     0.056683     0.0672397
 -0.00342756  -0.0107849    -0.0906355   -0.182713     0.0686007   0.0688963   -0.0763094    0.0519869   -0.0102288   -0.00280758    0.149886    -0.0800851   -0.0326504   0.0288039   0.12944       0.0659768   -0.149022     0.0582128    0.0538672   0.0550045  -0.0258075    0.0808918    0.23841     -0.0469081     0.0827965    0.0541089
  0.00533485   0.127481     -0.0951403   -0.0382426    0.219818    0.0332465    0.114002     0.0459539    0.0288236   -0.107055     -0.0107369   -0.0964141   -0.275777    0.0622369   0.0834034     0.0159736   -0.144105     0.136988    -0.0555559   0.156662    0.0795076    0.0255943    0.0590012   -0.0822443     0.128384    -0.134209
 -0.132985    -0.103943      0.0942357   -0.0961578   -0.0568546   0.0305297    0.0209006    0.0698369    0.180296    -0.115089     -0.165202     0.0937654    0.1108     -0.0915018   0.000435802  -0.0780993   -0.0907996   -0.0808737    0.241686    0.227263    0.17529      0.0262699   -0.085282     0.100016      0.0432027   -0.0294393
 -0.0640005   -0.0923385     0.00940022   0.0229947   -0.0232928  -0.115678    -0.00751873  -0.153203     0.0585445    0.14132       0.192503    -0.0269778    0.204832    0.100705   -0.182104     -0.065608    -0.0180018    0.0935703    0.103063   -0.0472973   0.057597    -0.0561118    0.126036    -0.24357      -0.0483931   -0.08428
  0.0735733   -0.0432674    -0.0800396   -0.24524      0.123322    0.126967     0.0486404    0.151338    -0.161638    -0.0992682    -0.0259102   -0.0270975    0.0256259   0.0416131  -0.143389      0.0389505   -0.0326175   -0.0471258   -0.129599    0.0123826   0.111402     0.0170417    0.0553781   -0.138684     -0.0494933    0.116409
  0.0692948    0.0210857     0.183379    -0.0334067    0.102314    0.0195039    0.056763    -0.074727     0.0754837    0.09244       0.0686295   -0.0503032    0.0315622  -0.0592464  -0.0449605    -0.0406994   -0.0747087   -0.141984    -0.0726843  -0.17246     0.116256    -0.188886    -0.0677609    0.16243      -0.0189428   -0.11896
  0.0409848   -0.0316771    -0.1205      -0.0531792   -0.0472515  -0.0115675    0.11108     -0.0531282    0.0403971   -0.104289     -0.0416912    0.0847613    0.137789    0.0984835  -0.0818643     0.021267     0.0818282    0.0321106    0.180611    0.180496   -0.0160542    0.141558    -0.354077    -0.249744      0.108316     0.0921082
  0.0623714    0.105998     -0.0358635   -0.247779    -0.0898575  -0.116371    -0.128449     0.151808     0.0220464    0.14752       0.0465599   -0.0840779   -0.077414    0.0432669   0.140051     -0.00932828   0.0471343   -0.0989199   -0.0629299   0.10403    -0.136933     0.0151063   -0.275978    -0.0689867    -0.108505    -0.133284kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4216504811616089
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421669
[ Info: iteration 2, average log likelihood -1.421614
[ Info: iteration 3, average log likelihood -1.421568
[ Info: iteration 4, average log likelihood -1.421506
[ Info: iteration 5, average log likelihood -1.421417
[ Info: iteration 6, average log likelihood -1.421294
[ Info: iteration 7, average log likelihood -1.421137
[ Info: iteration 8, average log likelihood -1.420950
[ Info: iteration 9, average log likelihood -1.420730
[ Info: iteration 10, average log likelihood -1.420446
[ Info: iteration 11, average log likelihood -1.420034
[ Info: iteration 12, average log likelihood -1.419425
[ Info: iteration 13, average log likelihood -1.418624
[ Info: iteration 14, average log likelihood -1.417782
[ Info: iteration 15, average log likelihood -1.417094
[ Info: iteration 16, average log likelihood -1.416650
[ Info: iteration 17, average log likelihood -1.416405
[ Info: iteration 18, average log likelihood -1.416283
[ Info: iteration 19, average log likelihood -1.416225
[ Info: iteration 20, average log likelihood -1.416197
[ Info: iteration 21, average log likelihood -1.416185
[ Info: iteration 22, average log likelihood -1.416178
[ Info: iteration 23, average log likelihood -1.416175
[ Info: iteration 24, average log likelihood -1.416174
[ Info: iteration 25, average log likelihood -1.416173
[ Info: iteration 26, average log likelihood -1.416173
[ Info: iteration 27, average log likelihood -1.416172
[ Info: iteration 28, average log likelihood -1.416172
[ Info: iteration 29, average log likelihood -1.416172
[ Info: iteration 30, average log likelihood -1.416172
[ Info: iteration 31, average log likelihood -1.416172
[ Info: iteration 32, average log likelihood -1.416171
[ Info: iteration 33, average log likelihood -1.416171
[ Info: iteration 34, average log likelihood -1.416171
[ Info: iteration 35, average log likelihood -1.416171
[ Info: iteration 36, average log likelihood -1.416171
[ Info: iteration 37, average log likelihood -1.416171
[ Info: iteration 38, average log likelihood -1.416171
[ Info: iteration 39, average log likelihood -1.416171
[ Info: iteration 40, average log likelihood -1.416171
[ Info: iteration 41, average log likelihood -1.416171
[ Info: iteration 42, average log likelihood -1.416171
[ Info: iteration 43, average log likelihood -1.416171
[ Info: iteration 44, average log likelihood -1.416171
[ Info: iteration 45, average log likelihood -1.416171
[ Info: iteration 46, average log likelihood -1.416171
[ Info: iteration 47, average log likelihood -1.416171
[ Info: iteration 48, average log likelihood -1.416171
[ Info: iteration 49, average log likelihood -1.416171
[ Info: iteration 50, average log likelihood -1.416171
┌ Info: EM with 100000 data points 50 iterations avll -1.416171
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4216686104045013
│     -1.4216137524741133
│      ⋮
└     -1.4161705775082938
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416185
[ Info: iteration 2, average log likelihood -1.416125
[ Info: iteration 3, average log likelihood -1.416071
[ Info: iteration 4, average log likelihood -1.415997
[ Info: iteration 5, average log likelihood -1.415893
[ Info: iteration 6, average log likelihood -1.415756
[ Info: iteration 7, average log likelihood -1.415594
[ Info: iteration 8, average log likelihood -1.415429
[ Info: iteration 9, average log likelihood -1.415283
[ Info: iteration 10, average log likelihood -1.415170
[ Info: iteration 11, average log likelihood -1.415090
[ Info: iteration 12, average log likelihood -1.415037
[ Info: iteration 13, average log likelihood -1.415002
[ Info: iteration 14, average log likelihood -1.414978
[ Info: iteration 15, average log likelihood -1.414963
[ Info: iteration 16, average log likelihood -1.414951
[ Info: iteration 17, average log likelihood -1.414943
[ Info: iteration 18, average log likelihood -1.414936
[ Info: iteration 19, average log likelihood -1.414930
[ Info: iteration 20, average log likelihood -1.414926
[ Info: iteration 21, average log likelihood -1.414922
[ Info: iteration 22, average log likelihood -1.414918
[ Info: iteration 23, average log likelihood -1.414915
[ Info: iteration 24, average log likelihood -1.414913
[ Info: iteration 25, average log likelihood -1.414910
[ Info: iteration 26, average log likelihood -1.414908
[ Info: iteration 27, average log likelihood -1.414907
[ Info: iteration 28, average log likelihood -1.414905
[ Info: iteration 29, average log likelihood -1.414903
[ Info: iteration 30, average log likelihood -1.414902
[ Info: iteration 31, average log likelihood -1.414901
[ Info: iteration 32, average log likelihood -1.414900
[ Info: iteration 33, average log likelihood -1.414899
[ Info: iteration 34, average log likelihood -1.414898
[ Info: iteration 35, average log likelihood -1.414897
[ Info: iteration 36, average log likelihood -1.414896
[ Info: iteration 37, average log likelihood -1.414895
[ Info: iteration 38, average log likelihood -1.414895
[ Info: iteration 39, average log likelihood -1.414894
[ Info: iteration 40, average log likelihood -1.414894
[ Info: iteration 41, average log likelihood -1.414893
[ Info: iteration 42, average log likelihood -1.414892
[ Info: iteration 43, average log likelihood -1.414892
[ Info: iteration 44, average log likelihood -1.414892
[ Info: iteration 45, average log likelihood -1.414891
[ Info: iteration 46, average log likelihood -1.414891
[ Info: iteration 47, average log likelihood -1.414890
[ Info: iteration 48, average log likelihood -1.414890
[ Info: iteration 49, average log likelihood -1.414890
[ Info: iteration 50, average log likelihood -1.414889
┌ Info: EM with 100000 data points 50 iterations avll -1.414889
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4161853653781524
│     -1.4161253807495053
│      ⋮
└     -1.4148891522149627
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414900
[ Info: iteration 2, average log likelihood -1.414851
[ Info: iteration 3, average log likelihood -1.414809
[ Info: iteration 4, average log likelihood -1.414760
[ Info: iteration 5, average log likelihood -1.414700
[ Info: iteration 6, average log likelihood -1.414626
[ Info: iteration 7, average log likelihood -1.414539
[ Info: iteration 8, average log likelihood -1.414442
[ Info: iteration 9, average log likelihood -1.414342
[ Info: iteration 10, average log likelihood -1.414243
[ Info: iteration 11, average log likelihood -1.414148
[ Info: iteration 12, average log likelihood -1.414060
[ Info: iteration 13, average log likelihood -1.413981
[ Info: iteration 14, average log likelihood -1.413912
[ Info: iteration 15, average log likelihood -1.413852
[ Info: iteration 16, average log likelihood -1.413802
[ Info: iteration 17, average log likelihood -1.413761
[ Info: iteration 18, average log likelihood -1.413727
[ Info: iteration 19, average log likelihood -1.413699
[ Info: iteration 20, average log likelihood -1.413676
[ Info: iteration 21, average log likelihood -1.413657
[ Info: iteration 22, average log likelihood -1.413641
[ Info: iteration 23, average log likelihood -1.413627
[ Info: iteration 24, average log likelihood -1.413615
[ Info: iteration 25, average log likelihood -1.413605
[ Info: iteration 26, average log likelihood -1.413596
[ Info: iteration 27, average log likelihood -1.413587
[ Info: iteration 28, average log likelihood -1.413580
[ Info: iteration 29, average log likelihood -1.413573
[ Info: iteration 30, average log likelihood -1.413567
[ Info: iteration 31, average log likelihood -1.413562
[ Info: iteration 32, average log likelihood -1.413556
[ Info: iteration 33, average log likelihood -1.413551
[ Info: iteration 34, average log likelihood -1.413547
[ Info: iteration 35, average log likelihood -1.413542
[ Info: iteration 36, average log likelihood -1.413538
[ Info: iteration 37, average log likelihood -1.413534
[ Info: iteration 38, average log likelihood -1.413530
[ Info: iteration 39, average log likelihood -1.413527
[ Info: iteration 40, average log likelihood -1.413523
[ Info: iteration 41, average log likelihood -1.413520
[ Info: iteration 42, average log likelihood -1.413516
[ Info: iteration 43, average log likelihood -1.413513
[ Info: iteration 44, average log likelihood -1.413509
[ Info: iteration 45, average log likelihood -1.413506
[ Info: iteration 46, average log likelihood -1.413503
[ Info: iteration 47, average log likelihood -1.413500
[ Info: iteration 48, average log likelihood -1.413497
[ Info: iteration 49, average log likelihood -1.413493
[ Info: iteration 50, average log likelihood -1.413490
┌ Info: EM with 100000 data points 50 iterations avll -1.413490
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.414899817924836
│     -1.414850941019066
│      ⋮
└     -1.4134901753731508
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413497
[ Info: iteration 2, average log likelihood -1.413445
[ Info: iteration 3, average log likelihood -1.413399
[ Info: iteration 4, average log likelihood -1.413346
[ Info: iteration 5, average log likelihood -1.413281
[ Info: iteration 6, average log likelihood -1.413200
[ Info: iteration 7, average log likelihood -1.413103
[ Info: iteration 8, average log likelihood -1.412993
[ Info: iteration 9, average log likelihood -1.412874
[ Info: iteration 10, average log likelihood -1.412753
[ Info: iteration 11, average log likelihood -1.412636
[ Info: iteration 12, average log likelihood -1.412527
[ Info: iteration 13, average log likelihood -1.412429
[ Info: iteration 14, average log likelihood -1.412342
[ Info: iteration 15, average log likelihood -1.412266
[ Info: iteration 16, average log likelihood -1.412199
[ Info: iteration 17, average log likelihood -1.412141
[ Info: iteration 18, average log likelihood -1.412090
[ Info: iteration 19, average log likelihood -1.412045
[ Info: iteration 20, average log likelihood -1.412004
[ Info: iteration 21, average log likelihood -1.411966
[ Info: iteration 22, average log likelihood -1.411932
[ Info: iteration 23, average log likelihood -1.411899
[ Info: iteration 24, average log likelihood -1.411869
[ Info: iteration 25, average log likelihood -1.411841
[ Info: iteration 26, average log likelihood -1.411814
[ Info: iteration 27, average log likelihood -1.411788
[ Info: iteration 28, average log likelihood -1.411764
[ Info: iteration 29, average log likelihood -1.411741
[ Info: iteration 30, average log likelihood -1.411719
[ Info: iteration 31, average log likelihood -1.411698
[ Info: iteration 32, average log likelihood -1.411678
[ Info: iteration 33, average log likelihood -1.411659
[ Info: iteration 34, average log likelihood -1.411640
[ Info: iteration 35, average log likelihood -1.411623
[ Info: iteration 36, average log likelihood -1.411606
[ Info: iteration 37, average log likelihood -1.411590
[ Info: iteration 38, average log likelihood -1.411575
[ Info: iteration 39, average log likelihood -1.411560
[ Info: iteration 40, average log likelihood -1.411545
[ Info: iteration 41, average log likelihood -1.411531
[ Info: iteration 42, average log likelihood -1.411518
[ Info: iteration 43, average log likelihood -1.411505
[ Info: iteration 44, average log likelihood -1.411492
[ Info: iteration 45, average log likelihood -1.411480
[ Info: iteration 46, average log likelihood -1.411468
[ Info: iteration 47, average log likelihood -1.411457
[ Info: iteration 48, average log likelihood -1.411446
[ Info: iteration 49, average log likelihood -1.411435
[ Info: iteration 50, average log likelihood -1.411425
┌ Info: EM with 100000 data points 50 iterations avll -1.411425
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4134966107308091
│     -1.4134452145300607
│      ⋮
└     -1.411424540280238
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411422
[ Info: iteration 2, average log likelihood -1.411358
[ Info: iteration 3, average log likelihood -1.411297
[ Info: iteration 4, average log likelihood -1.411227
[ Info: iteration 5, average log likelihood -1.411140
[ Info: iteration 6, average log likelihood -1.411033
[ Info: iteration 7, average log likelihood -1.410904
[ Info: iteration 8, average log likelihood -1.410757
[ Info: iteration 9, average log likelihood -1.410599
[ Info: iteration 10, average log likelihood -1.410438
[ Info: iteration 11, average log likelihood -1.410280
[ Info: iteration 12, average log likelihood -1.410131
[ Info: iteration 13, average log likelihood -1.409994
[ Info: iteration 14, average log likelihood -1.409869
[ Info: iteration 15, average log likelihood -1.409758
[ Info: iteration 16, average log likelihood -1.409659
[ Info: iteration 17, average log likelihood -1.409572
[ Info: iteration 18, average log likelihood -1.409494
[ Info: iteration 19, average log likelihood -1.409424
[ Info: iteration 20, average log likelihood -1.409362
[ Info: iteration 21, average log likelihood -1.409305
[ Info: iteration 22, average log likelihood -1.409254
[ Info: iteration 23, average log likelihood -1.409207
[ Info: iteration 24, average log likelihood -1.409164
[ Info: iteration 25, average log likelihood -1.409124
[ Info: iteration 26, average log likelihood -1.409088
[ Info: iteration 27, average log likelihood -1.409054
[ Info: iteration 28, average log likelihood -1.409023
[ Info: iteration 29, average log likelihood -1.408994
[ Info: iteration 30, average log likelihood -1.408967
[ Info: iteration 31, average log likelihood -1.408942
[ Info: iteration 32, average log likelihood -1.408919
[ Info: iteration 33, average log likelihood -1.408897
[ Info: iteration 34, average log likelihood -1.408877
[ Info: iteration 35, average log likelihood -1.408857
[ Info: iteration 36, average log likelihood -1.408839
[ Info: iteration 37, average log likelihood -1.408821
[ Info: iteration 38, average log likelihood -1.408805
[ Info: iteration 39, average log likelihood -1.408789
[ Info: iteration 40, average log likelihood -1.408774
[ Info: iteration 41, average log likelihood -1.408759
[ Info: iteration 42, average log likelihood -1.408745
[ Info: iteration 43, average log likelihood -1.408732
[ Info: iteration 44, average log likelihood -1.408718
[ Info: iteration 45, average log likelihood -1.408706
[ Info: iteration 46, average log likelihood -1.408694
[ Info: iteration 47, average log likelihood -1.408682
[ Info: iteration 48, average log likelihood -1.408671
[ Info: iteration 49, average log likelihood -1.408660
[ Info: iteration 50, average log likelihood -1.408649
┌ Info: EM with 100000 data points 50 iterations avll -1.408649
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4114221022646503
│     -1.4113580732320796
│      ⋮
└     -1.408649075790875
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4216504811616089
│     -1.4216686104045013
│     -1.4216137524741133
│     -1.4215683776131975
│      ⋮
│     -1.4086706103218647
│     -1.408659652788836
└     -1.408649075790875
32×26 Array{Float64,2}:
  0.372549    0.212257      0.634157     0.102575     0.545966     0.209068    -0.777902   -1.03798     0.117032    0.0481039    0.196683   -0.38677    -0.285967   -0.718876     0.0893883   -0.288036    0.13701      0.478364    0.46777    -0.302843   -0.171141     0.121859   -0.140219    -0.0592113    0.00563707   -0.0958163
  0.363039    0.291039     -0.287188    -0.382139    -0.101778     0.0226977   -0.167383    0.463384   -0.217359    0.0165573    0.411494   -0.305663   -0.177085   -0.539819    -0.00147349  -0.191425    0.180153     0.193254    0.779471   -0.50427     0.0543184   -0.945248   -0.139547    -0.403117    -0.63824       0.23845
  0.202778   -0.434803      1.25955      0.448009    -0.347846    -0.284116    -0.216263    0.135597    0.469045   -0.0809573    0.219967   -0.664858    0.318343   -0.0490718   -0.00155987  -0.298615    0.568326    -0.0505658  -0.0789528   0.0122284   0.208363     0.0178498   0.523256     0.0772151    0.0497433     0.00154202
  0.18469     0.200793      0.342329     0.985108     0.198173     0.795612    -0.208425    0.0728739  -0.579636    0.503236    -0.252392   -0.667584    0.936408   -0.0969081   -0.0215788   -0.581656    0.329753    -0.333039   -0.0357526  -0.534166    0.191703    -0.0550128   0.735203    -0.247983    -0.0299664     0.156871
 -0.1471     -0.506564      0.0928431    0.919227    -0.0875586    0.328231     0.260555   -0.198309    0.350797   -0.451704    -0.483002   -0.0843339   0.131057    0.41551      0.481951     0.297559   -0.0186545    0.207529    0.134707    0.171169    0.182291    -0.247461    0.175612    -0.343171     0.465956     -0.0971745
  0.255728    0.0658671    -0.236211     0.427888     0.169137     0.205933     0.23939     0.677924    0.395262    0.00507735  -0.506696   -0.548181    0.2388      0.233266    -0.0436498   -0.459018    0.0337869   -1.17304    -0.161276   -1.22377     1.09791     -0.63024    -0.274094     0.371029     0.294082      0.148336
 -0.0667392   0.270628     -0.144181     0.320795    -0.744572    -0.157559     0.472893    0.186166    0.63797     0.529789    -0.163311    0.305094   -0.642139   -0.1674       0.0186432    0.294845    0.26994     -0.21102     0.0852428  -0.495819    0.296083     0.351783    0.261988    -0.121076     0.451461     -0.0322262
  0.326081    0.095069      0.14976      0.0251996   -0.760726     0.115259     0.474581   -0.449858    0.418418   -0.152161     0.343496   -0.127921    0.138557    0.755823     0.157208    -0.103689   -0.040583     0.88152    -0.172602   -0.0364884   0.360943     0.292618   -0.0798086   -0.197801     0.282927     -0.221979
 -0.71727     0.148855      0.177385     0.146148    -0.0166984   -0.55865     -0.0195021  -0.34021    -0.0545563   0.125762     0.0629722   0.714601    0.718444   -0.103663     0.114505    -0.855728   -0.177787     0.136663    0.396997    0.0117476   0.0878891    0.149542   -0.00711649   0.292697     0.326759     -0.237066
 -0.134675   -0.0571651    -0.198864    -0.114199    -0.0711546    0.0166613    0.0207189  -0.0230703  -0.0801893   0.0291391   -0.185297    0.273684    0.061688    0.103539    -0.0189369    0.255285   -0.217453    -0.0136601  -0.0302924   0.0595186  -0.101853    -0.0377196  -0.0477805    0.0360374   -0.012525      0.0697718
  0.131765   -0.307222     -0.200515    -0.25139     -0.759879    -0.29932     -0.304855    0.249779    0.043143   -0.334953    -0.380012    0.469141   -0.242582    0.526927    -1.01009      1.01715    -0.0382379   -0.114832   -0.18906     0.303204    0.193502     0.326245   -0.626274     0.0686285   -0.568736      0.825762
  0.0192306   0.217974     -0.153908    -0.987381     0.21726     -0.337901     0.233924    0.0993078   0.78005    -0.407307     0.16724     0.468315   -0.672983    0.181317     0.175205     0.180137   -0.11852      0.049879   -0.0105107   0.387335   -0.0463644    0.438975   -0.912386     0.226396    -0.180115      0.0795299
  0.637711    0.391459     -0.170718    -0.337508     0.175639     0.100974     0.600398   -0.108317   -0.579901    0.62569      0.599851   -0.0977335   0.0385521   0.0726299   -0.137657    -0.495489    0.0149057    0.257807   -0.705011   -0.104056    0.177248     0.136041    0.294561    -0.213035     0.100972      0.000899131
  0.263089    0.167274     -0.771397    -0.386671     0.0148004   -0.128154     0.696133    0.384938   -0.14959    -0.0818815    0.0896124   0.192097    0.54093     0.390492    -0.260652    -0.3092      0.114431    -0.085426    0.321007    0.269354   -0.137425     0.164663    0.699663    -0.182775    -0.722732      0.228335
  0.480011   -0.105663     -0.127372    -0.64222      0.360101     1.27317      0.357674    0.549172   -0.124738   -0.0221774   -0.144517   -0.686252   -0.525555   -0.233958    -0.386093     0.609878   -0.295155    -0.0297293  -0.169812   -0.055357   -0.714543    -0.181008    0.0774599   -0.151252     0.216106      0.0718232
  0.145695    0.0442145     0.0175418    0.104343     0.35765      0.814894     0.0762045   0.146164    0.431141   -0.182248     0.27959    -0.445513   -1.31473    -0.136836     0.255238     0.485083    0.240682    -0.107598   -0.472706   -0.12358     0.544028    -0.289177    0.341702    -0.619622     0.365832     -0.349431
 -0.226676    0.126315      0.461324     0.207998     0.243846    -0.115398    -0.0595015  -0.448176    0.100795   -0.105906     0.234957   -0.0391792   0.433477   -0.354318    -0.435395     0.312171    0.255774     0.268653    0.0637845  -0.447733    0.365105    -0.183593    0.362996     0.678061    -0.0518956    -0.248995
  0.0834792   0.0141771     0.15149      0.206358     0.00554574  -0.348726    -0.289896   -0.139021    0.0847488   0.247984    -0.381142    0.560404    0.0165669  -0.0104614    0.311625    -0.161969    0.0314971    0.288694    0.269303   -0.574977    0.0852191   -0.0659969   0.187279     0.335646    -0.61407       0.252055
 -0.604225    0.047793     -0.0570897   -0.0489838   -0.0992625   -0.194537    -0.0893041   0.384193    0.196365   -0.241689     0.103599   -0.230084    0.0382568  -0.151793     0.707066    -0.275555   -0.0521777    0.358874    0.614083   -0.315012    0.140255    -0.186966    0.400641    -0.413284     0.266822     -0.435477
 -0.394248    0.166264     -0.348514    -0.281817     0.38847     -0.424476    -0.120712    0.417059   -0.31003    -0.292045     0.0109597  -0.0318814  -0.254141   -0.514473    -0.00867921   0.38104     0.0157415   -0.355688    0.361363    0.0992693  -0.215118    -0.15261    -0.147726     0.194917     0.432858     -0.217783
 -0.0861545  -0.898741      0.118535     0.00795583  -0.133811     0.213685    -0.0816264   0.0990566   0.296562   -0.175739    -0.109666    0.0521031   0.137723   -0.192024    -0.143479    -0.59401     0.341745    -0.0638448  -0.0393817  -0.0640609  -0.620038    -0.225196    0.112122    -0.504939     0.224988      0.773961
  0.461633   -0.073467      0.316016     0.134632    -0.0495882    0.488108     0.93367     0.105142    0.191618    0.0102279   -0.0278896  -0.207511    0.292385    0.0466325   -0.715395    -0.231951    0.478576    -0.218384    0.451531    0.480669   -0.0357353   -0.143353   -0.515881    -0.175845     0.355948      0.576402
  0.306711   -0.0266758    -0.016881    -0.00824157   0.0249125    0.309844     0.138614    0.101586   -0.373016    0.252532     0.262243   -0.20586    -0.0581727   0.0454821    0.0659015   -0.123535   -0.207639     0.0511208  -0.563167    0.0374513   0.119851    -0.0785176   0.206689    -0.245141     0.0300102     0.11625
  0.525785    0.0643569     0.10069     -0.0226528   -0.161602    -0.0948186   -0.134573   -0.0134534  -0.0579197   0.135918     0.253246   -0.243141   -0.10512    -0.326592    -0.358449    -0.188167    0.130684     0.0648626   0.382593   -0.291118    0.0102917   -0.39904     0.178236    -0.380128     0.0511364    -0.00739561
 -0.69786    -0.324057     -0.530267     0.17887     -0.0706447    0.188905     0.567916    0.16351     0.13146     0.285966    -0.159118    0.61949     0.256981    0.292034     0.20464      0.199828   -0.624454    -0.377893   -0.466018    0.714971    0.179621     0.276616   -0.155652     0.262751     0.0166974    -0.216912
  0.0097066   0.450729     -0.616332    -0.233728    -0.230661    -0.118293    -0.092807    0.0366409  -0.411182    0.254325    -0.177107    0.480519   -0.669825    0.329755     0.527886     0.230105   -0.954311     0.02264    -0.200923    0.186532    0.114849     0.132633   -0.20098     -0.357315    -0.0618279    -0.131811
 -0.141044   -0.000214959   0.0956503   -0.0855384   -0.00748991  -0.269943     0.0265885  -0.071692    0.0582599  -0.00761381   0.094187    0.112251    0.268435    0.007084     0.0433797   -0.117524   -0.0436217    0.0672592   0.100415    0.160967    0.00825179   0.0937254  -0.127502     0.159932     0.0086069    -0.16935
 -0.0498138  -0.0344326    -0.13443      0.0852101    0.108326     0.286661     0.0501544   0.0446996   0.0871515  -0.156621    -0.245787    0.0356375  -0.313495    0.174561     0.127163     0.267752   -0.082891    -0.0213647  -0.10739     0.0997587  -0.0520928    0.0885644  -0.0771887   -0.0125048   -0.0556915     0.156921
 -0.7109     -0.332169     -0.0972836   -0.140073    -0.470236    -0.0249229   -0.21237    -0.154982   -0.184809    0.163858     0.406172   -0.702012    0.566463    0.226634     0.130254     0.0124605   0.15073     -0.437562   -0.472512    0.78592    -0.215569     0.332616   -0.0136187   -0.13417     -0.000671021   0.0917009
  0.198725   -0.100361      0.406959    -0.130689     0.182244    -0.262217    -0.782917    0.191388   -0.0617665  -0.55232      0.0179113  -0.418773   -0.255736    0.205613     0.464494    -0.14584    -0.00668411  -0.443917   -0.377222    0.489149   -0.322868     0.217254   -0.533233     0.401598     0.00754894   -0.472949
  0.319059   -0.14542      -0.00437193  -0.204903     0.478376    -0.00250275  -0.302033   -0.370176   -0.56173    -0.284169    -0.123772    0.0708484   0.5715     -0.00523654  -0.0494484    0.0532339  -0.278011    -0.0888926  -0.0526543   0.237844   -0.481707    -0.377435   -0.455986     0.158606    -0.534098      0.0844965
 -0.20517    -0.297985      0.208242    -0.177076     0.0792612   -0.0830057   -0.0427074  -0.536017   -0.111151   -0.0481317    0.0182064   0.496626    0.0641844   0.00555741  -0.0910921    0.156418   -0.36324      0.388579   -0.108048    0.828415   -0.268433     0.481129   -0.179136     0.00518525   0.0385217    -0.298271[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408639
[ Info: iteration 2, average log likelihood -1.408629
[ Info: iteration 3, average log likelihood -1.408620
[ Info: iteration 4, average log likelihood -1.408610
[ Info: iteration 5, average log likelihood -1.408602
[ Info: iteration 6, average log likelihood -1.408593
[ Info: iteration 7, average log likelihood -1.408585
[ Info: iteration 8, average log likelihood -1.408577
[ Info: iteration 9, average log likelihood -1.408569
[ Info: iteration 10, average log likelihood -1.408562
┌ Info: EM with 100000 data points 10 iterations avll -1.408562
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.210036e+05
      1       7.069814e+05      -2.140222e+05 |       32
      2       6.922652e+05      -1.471618e+04 |       32
      3       6.864717e+05      -5.793553e+03 |       32
      4       6.836972e+05      -2.774464e+03 |       32
      5       6.820573e+05      -1.639893e+03 |       32
      6       6.808725e+05      -1.184866e+03 |       32
      7       6.799446e+05      -9.278860e+02 |       32
      8       6.791505e+05      -7.940705e+02 |       32
      9       6.784619e+05      -6.885640e+02 |       32
     10       6.778372e+05      -6.247040e+02 |       32
     11       6.773049e+05      -5.323072e+02 |       32
     12       6.768186e+05      -4.863003e+02 |       32
     13       6.763523e+05      -4.662978e+02 |       32
     14       6.759721e+05      -3.802750e+02 |       32
     15       6.756612e+05      -3.108482e+02 |       32
     16       6.753764e+05      -2.848238e+02 |       32
     17       6.751223e+05      -2.540353e+02 |       32
     18       6.749194e+05      -2.029541e+02 |       32
     19       6.747525e+05      -1.669333e+02 |       32
     20       6.745911e+05      -1.613131e+02 |       32
     21       6.744365e+05      -1.546003e+02 |       32
     22       6.742968e+05      -1.397925e+02 |       32
     23       6.741648e+05      -1.319958e+02 |       32
     24       6.740456e+05      -1.191276e+02 |       32
     25       6.739351e+05      -1.105433e+02 |       32
     26       6.738332e+05      -1.018597e+02 |       32
     27       6.737421e+05      -9.112108e+01 |       32
     28       6.736504e+05      -9.172251e+01 |       32
     29       6.735642e+05      -8.616105e+01 |       32
     30       6.734822e+05      -8.205954e+01 |       32
     31       6.734009e+05      -8.127619e+01 |       32
     32       6.733320e+05      -6.886332e+01 |       32
     33       6.732648e+05      -6.720238e+01 |       32
     34       6.732057e+05      -5.911416e+01 |       32
     35       6.731521e+05      -5.358421e+01 |       32
     36       6.731059e+05      -4.617794e+01 |       32
     37       6.730615e+05      -4.445838e+01 |       32
     38       6.730179e+05      -4.360168e+01 |       32
     39       6.729800e+05      -3.791744e+01 |       32
     40       6.729465e+05      -3.348678e+01 |       32
     41       6.729106e+05      -3.583029e+01 |       32
     42       6.728771e+05      -3.354839e+01 |       32
     43       6.728446e+05      -3.253514e+01 |       32
     44       6.728111e+05      -3.349512e+01 |       32
     45       6.727819e+05      -2.917617e+01 |       32
     46       6.727535e+05      -2.838499e+01 |       32
     47       6.727215e+05      -3.197677e+01 |       32
     48       6.726881e+05      -3.343239e+01 |       32
     49       6.726529e+05      -3.522702e+01 |       32
     50       6.726226e+05      -3.031243e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 672622.5593808923)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420645
[ Info: iteration 2, average log likelihood -1.415666
[ Info: iteration 3, average log likelihood -1.414276
[ Info: iteration 4, average log likelihood -1.413233
[ Info: iteration 5, average log likelihood -1.412149
[ Info: iteration 6, average log likelihood -1.411160
[ Info: iteration 7, average log likelihood -1.410478
[ Info: iteration 8, average log likelihood -1.410095
[ Info: iteration 9, average log likelihood -1.409883
[ Info: iteration 10, average log likelihood -1.409748
[ Info: iteration 11, average log likelihood -1.409649
[ Info: iteration 12, average log likelihood -1.409568
[ Info: iteration 13, average log likelihood -1.409499
[ Info: iteration 14, average log likelihood -1.409438
[ Info: iteration 15, average log likelihood -1.409382
[ Info: iteration 16, average log likelihood -1.409331
[ Info: iteration 17, average log likelihood -1.409284
[ Info: iteration 18, average log likelihood -1.409239
[ Info: iteration 19, average log likelihood -1.409196
[ Info: iteration 20, average log likelihood -1.409156
[ Info: iteration 21, average log likelihood -1.409117
[ Info: iteration 22, average log likelihood -1.409080
[ Info: iteration 23, average log likelihood -1.409044
[ Info: iteration 24, average log likelihood -1.409010
[ Info: iteration 25, average log likelihood -1.408978
[ Info: iteration 26, average log likelihood -1.408947
[ Info: iteration 27, average log likelihood -1.408918
[ Info: iteration 28, average log likelihood -1.408890
[ Info: iteration 29, average log likelihood -1.408865
[ Info: iteration 30, average log likelihood -1.408840
[ Info: iteration 31, average log likelihood -1.408817
[ Info: iteration 32, average log likelihood -1.408795
[ Info: iteration 33, average log likelihood -1.408775
[ Info: iteration 34, average log likelihood -1.408756
[ Info: iteration 35, average log likelihood -1.408737
[ Info: iteration 36, average log likelihood -1.408720
[ Info: iteration 37, average log likelihood -1.408703
[ Info: iteration 38, average log likelihood -1.408687
[ Info: iteration 39, average log likelihood -1.408672
[ Info: iteration 40, average log likelihood -1.408657
[ Info: iteration 41, average log likelihood -1.408643
[ Info: iteration 42, average log likelihood -1.408629
[ Info: iteration 43, average log likelihood -1.408616
[ Info: iteration 44, average log likelihood -1.408604
[ Info: iteration 45, average log likelihood -1.408592
[ Info: iteration 46, average log likelihood -1.408580
[ Info: iteration 47, average log likelihood -1.408569
[ Info: iteration 48, average log likelihood -1.408558
[ Info: iteration 49, average log likelihood -1.408547
[ Info: iteration 50, average log likelihood -1.408537
┌ Info: EM with 100000 data points 50 iterations avll -1.408537
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.122918   -0.405335   -0.0299081    -0.445702   -1.12543     -0.701073    -0.382607     0.24633     0.0904526   -0.063652   -0.468007     0.489597   -0.607939     0.577428     -0.515874    0.914735    -0.274489     -0.00136342  -0.384592    0.270053     0.171613    0.163158   -0.482515    -0.104324     -0.567673     0.395533
 -0.0888332  -0.512149    0.292818     -0.0511865   0.170525     0.0601854   -0.103123    -0.518162   -0.174547    -0.0521904  -0.0753423    0.480662    0.207367    -0.0857035    -0.0111631  -0.155525    -0.458191      0.384094    -0.13102     0.719518    -0.262059    0.281008   -0.209248    -0.102368     -0.00405072  -0.108079
 -0.0995909  -0.202073   -0.00192759    0.166286    0.339822     0.00822413  -0.332394    -0.0612246   0.162266    -0.16741    -0.289265    -0.0853368  -0.163699     0.210789      0.351901    0.221735     0.0689656    -0.212854     0.0466209   0.114347    -0.078567    0.257612   -0.0113851    0.478879     -0.294755     0.131861
 -0.899324   -0.273588   -0.567433      0.143476   -0.00997259   0.261916     0.348897     0.0571735   0.200626     0.0311823  -0.0950791    0.407381    0.257069     0.114602      0.252025    0.388259    -0.593306     -0.523454    -0.404085    0.819099     0.196094    0.300333   -0.308923     0.342537      0.0296289   -0.303681
  0.0227892   0.20826    -0.515645     -0.0729569  -0.07418      0.323329     0.598626     0.305085    0.114147    -0.0280159   0.263408    -0.0402313  -0.0501226   -0.0756122     0.028041   -0.192796     0.000904028   0.336865     0.591071   -0.30517      0.193558   -0.424843    0.103318    -0.62062       0.153656    -0.0177659
 -0.0526631  -0.263666    0.728659      0.582223   -0.0169902   -0.0482145   -0.432255    -0.350517    0.341555    -0.414943    0.0439561   -0.561103    0.143079    -0.41282       0.414834   -0.190403     0.560974      0.221415     0.523953   -0.0370983    0.0806272  -0.274066    0.229177    -0.333182      0.196456    -0.432825
  0.0230212   0.0175041  -0.00488055   -0.0782099   0.00210497   0.0605721    0.0786179   -0.0414425  -0.0139681   -0.0407304   0.030127     0.0257672   0.0189338    0.0798114     0.0288379  -2.60629e-5  -0.104666      0.0955592   -0.0878842   0.101933    -0.0457949   0.0341345  -0.0905      -0.0458765     0.022774    -0.026863
 -0.118105   -0.269715    0.592789      0.773075   -0.00263878   0.569971    -0.287653     0.268783   -0.160966     0.303386   -0.115404    -0.322015    0.834728    -0.0576994    -0.294999   -0.542826     0.339407     -0.561497    -0.143807   -0.0274172   -0.0549174   0.202944    0.673426     0.000496603   0.20404      0.247041
 -0.0507647  -0.249663   -0.169161      0.385137   -0.878856    -0.298917     0.493482     0.050727    0.755587     0.320427    0.356882     0.379439   -0.257725     0.0332564    -0.208354   -0.304441     0.0284212     0.0597159   -0.243568   -0.194238     0.0808875   0.928124    0.231091    -0.016679      1.18925     -0.367463
 -0.328332    0.0188992  -0.521614     -0.536086    0.0465569   -0.380303     0.412928     0.646954   -0.391253    -0.0636381  -0.661543     0.728456    0.133939     0.289929     -0.0939852  -0.1194      -0.345516     -0.0396648    0.273532    0.731715    -0.450251    0.553396    0.2989      -0.234784     -0.317323     0.303995
  0.276481   -0.177877   -0.264391      0.486851    0.1075       0.296848     0.194209     0.695808    0.364409    -0.0150814  -0.647355    -0.792837    0.425654     0.232108      0.192956   -0.83928     -0.143508     -1.44302     -0.18808    -1.2089       1.07408    -0.893847   -0.269401     0.321387      0.164196    -0.0161233
  0.379717   -0.073678   -0.0559159    -0.0603145  -0.115917     0.39548      0.512632     0.129923    0.198948    -0.331689   -0.135992     0.0459251   0.151254     0.259858     -0.980538    0.284919     0.27511      -0.446896     0.102264    0.504865     0.0936585   0.252177   -0.846275     0.0726959     0.0365068    0.81263
 -0.57624     0.067943    0.230559      0.352264   -0.216128    -1.20192     -0.24621     -0.292879    0.0486548    0.174622    0.317082     0.594595    0.429357     0.0703377     0.481169   -0.695359    -0.231847      0.126619     0.275217   -0.158034     0.277844    0.260927   -0.149241     0.692002      0.0434734   -0.0995288
  0.316051   -0.237183   -0.000957478   0.283224   -0.128451     0.13263      0.269417    -0.0498249  -0.00256189   0.310533    0.11936     -0.158       0.109326    -0.157529     -0.408331   -0.355501     0.305671      0.0374017    0.184721    0.00731307   0.0221759  -0.405391    0.242723    -0.470249      0.209435     0.250513
  0.185894    0.286755   -0.0240519    -0.611572    0.295596    -0.312667    -0.290462     0.199191    0.354317    -0.645972    0.126399     0.0821672  -0.885335     0.12177       0.535576   -0.0498467   -0.0400407    -0.198934    -0.265576    0.483119    -0.10231     0.324425   -0.915293     0.0617142     0.0158614   -0.296543
  0.0878355   0.398441   -0.466177     -0.21335    -0.236386    -0.00187925   0.209091    -0.126248   -0.19801      0.42633    -0.0686206    0.549398   -0.476638     0.21761       0.0994608   0.219721    -0.715914      0.245925    -0.21573    -0.00380736   0.200317    0.152651   -0.148885    -0.123145      0.036172    -0.095709
  0.525046   -0.224375    0.545837     -0.504581   -0.131204     0.0429531   -0.245614     0.113803    0.178862    -0.0243618   0.183149    -0.279991   -0.102449    -0.403672     -0.232322   -0.576965     0.283531      0.182762     0.398936   -0.508642    -0.640963   -0.211138   -0.0370706   -0.243687      0.271181     0.467127
  0.179296    0.0132715   0.00724349    0.387323   -0.265585     0.160364     0.694046    -0.252195    0.0341537    0.176398    0.14586     -0.219661    0.233684     1.08414       0.333973   -0.107597    -0.133956      0.383927    -0.628872    0.454307     0.415514    0.152423    0.138817    -0.242938     -0.00551897   0.0798163
 -0.128476   -0.0123835   0.0296571     0.0418375   0.0396883   -0.147666    -0.367188    -0.226357   -0.138642    -0.0063546  -0.178772     0.283384    0.0348048   -0.101859     -0.0222609   0.227575    -0.173967     -0.0905725   -0.123964    0.0428866   -0.096123    0.0724676  -0.121008     0.356306     -0.00551467  -0.0667426
  0.0599649   0.111986   -0.265115      0.0764341  -0.201895    -0.152216    -0.104988     0.670466   -0.144551     0.0220426   0.218285    -0.193421   -0.37207     -0.172226      0.441564   -0.0609948   -0.0949177    -0.0670442    0.312317   -0.278403     0.377282   -0.351745    0.363826    -0.494052     -0.157518     0.0510478
  0.415752   -0.128492   -0.20622      -0.453714    0.365535     1.14169      0.280144     0.40458    -0.347662    -0.0183088   0.0746404   -0.595595   -0.602982    -0.269643     -0.255369    0.606272    -0.304492     -0.0937364   -0.473551    0.178122    -0.398145   -0.189785    0.123473    -0.387927      0.286231     0.0106111
 -0.521561   -0.142435    0.0371369     0.55151    -0.188513    -0.081469     0.270152     0.203156    0.154562    -0.481383   -0.693547     0.49528    -0.0636928   -0.004059      0.289686    0.40098      0.126648      0.179392     0.295435   -0.442627    -0.120699   -0.210512   -0.00540752  -0.262664      0.584938     0.148594
 -0.444585    0.151414   -0.266539     -0.414074    0.285868     0.481562    -0.329628     0.0700884  -0.051716     0.444845    0.00534079  -0.364017    0.149175    -0.0361455     1.05106    -0.627212    -0.528139      0.164598    -0.171032   -0.130343    -0.310755    0.366206    0.605267    -0.293812      0.495984    -0.639097
  0.708198    0.327475   -0.356429     -0.697744    0.119498    -0.197896     0.368894     0.0991998  -0.393113     0.251992    0.955817     0.0601351   0.408059    -0.000828702  -0.451489   -0.431112     0.0384949    -0.246874    -0.243601    0.0672292   -0.161201   -0.0819379   0.299213     0.122589     -0.522353    -0.0676836
 -0.656045   -0.0285265   0.0270209    -1.32075    -0.0348723   -0.283749     0.0515967   -0.708524    0.282372     0.139375    0.352148     0.315245    0.257789     0.248058      0.208757    0.313736    -0.215593      0.787487     0.411335    0.0514334   -0.529229   -0.642164   -0.17556      0.152159     -0.184597     0.101271
 -0.317723    0.231573   -0.109057     -0.429885    0.212556    -0.615686    -0.154136     0.195179   -0.114952    -0.0536591   0.145838    -0.109876    0.00383952  -0.511775     -0.238917    0.240474     0.0814982    -0.241281     0.351336    0.0766265   -0.187318   -0.100684   -0.0174462    0.320794      0.277485    -0.412879
 -0.0700006   0.238166    0.658558      0.114119    0.0279241   -0.114813    -0.0582402   -0.301515    0.173386    -0.099389    0.481377    -0.163733    0.384105    -0.221921     -0.247577    0.201425     0.190834      0.258733    -0.0610705  -0.300361     0.491695   -0.0787278   0.243082     0.527828     -0.105079    -0.280804
  0.3007     -0.0469276  -0.0973049     0.119712   -0.0454427    0.0843211    0.0644013   -0.190282    0.210203     0.192991   -0.537418     0.505807    0.412811    -0.0677516    -0.0922583  -0.139603     0.18133       0.216474     0.401362   -0.620477    -0.0913743  -0.24323     0.245104     0.188311     -0.99801      0.284836
 -0.533138   -0.492116    0.0816431    -0.205944   -0.664452    -0.119082    -0.238634    -0.107912   -0.0706085   -0.0134522   0.363137    -0.674782    0.538266     0.273855      0.135189   -0.110057     0.449134     -0.372039    -0.289165    0.664735    -0.474551    0.171973   -0.0627018   -0.285373     -0.0862976    0.17778
  0.186691   -0.11306    -0.0962315    -0.163938    0.587007    -0.0109303   -0.548271    -0.0995489  -0.722191    -0.537092   -0.0516538   -0.219114    0.23687     -0.16894       0.13983     0.156959    -0.203856     -0.164058     0.0907129   0.29415     -0.369247   -0.584393   -0.599905     0.0215983    -0.45108      0.0769776
  0.878069    0.407912    0.32817       0.257893    0.611249     0.141157    -0.00420595  -0.503841   -0.537956     0.403802   -0.0155413   -0.331793   -0.0632246   -0.355862     -0.15791    -0.413487     0.0828698     0.416409    -0.133324   -0.684692     0.315448    0.0718356   0.267671    -0.0687472     0.0222634    0.0761567
 -0.011435    0.209408    0.137463      0.27585    -0.232184     0.491458     0.222313     0.0643377   0.95199      0.11381    -0.116241    -0.318967   -1.09403     -0.0226358     0.166453    0.628456     0.454309     -0.206501    -0.0609419  -0.537416     0.634031    0.0213822   0.369326    -0.129652      0.255464    -0.126025[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408527
[ Info: iteration 2, average log likelihood -1.408518
[ Info: iteration 3, average log likelihood -1.408509
[ Info: iteration 4, average log likelihood -1.408500
[ Info: iteration 5, average log likelihood -1.408491
[ Info: iteration 6, average log likelihood -1.408483
[ Info: iteration 7, average log likelihood -1.408474
[ Info: iteration 8, average log likelihood -1.408467
[ Info: iteration 9, average log likelihood -1.408459
[ Info: iteration 10, average log likelihood -1.408452
┌ Info: EM with 100000 data points 10 iterations avll -1.408452
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
