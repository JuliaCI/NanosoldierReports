Julia Version 1.5.0-DEV.271
Commit 438485e5a9 (2020-02-14 18:24 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed GaussianMixtures ─── v0.3.0
  Installed FillArrays ───────── v0.8.4
  Installed Distances ────────── v0.8.2
  Installed JLD ──────────────── v0.9.2
  Installed Rmath ────────────── v0.6.0
  Installed QuadGK ───────────── v2.3.1
  Installed HDF5 ─────────────── v0.12.5
  Installed BinDeps ──────────── v1.0.0
  Installed ScikitLearnBase ──── v0.5.0
  Installed PDMats ───────────── v0.9.11
  Installed CMakeWrapper ─────── v0.2.3
  Installed Missings ─────────── v0.4.3
  Installed Arpack ───────────── v0.4.0
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed Arpack_jll ───────── v3.5.0+2
  Installed FileIO ───────────── v1.2.2
  Installed StaticArrays ─────── v0.12.1
  Installed LegacyStrings ────── v0.4.1
  Installed Parameters ───────── v0.12.0
  Installed StatsFuns ────────── v0.9.4
  Installed SortingAlgorithms ── v0.3.1
  Installed URIParser ────────── v0.4.0
  Installed DataAPI ──────────── v1.1.0
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed Blosc ────────────── v0.5.1
  Installed NearestNeighbors ─── v0.4.4
  Installed DataStructures ───── v0.17.9
  Installed StatsBase ────────── v0.32.0
  Installed Distributions ────── v0.22.4
  Installed CMake ────────────── v1.2.0
  Installed OrderedCollections ─ v1.1.0
  Installed Compat ───────────── v2.2.0
  Installed BinaryProvider ───── v0.5.8
  Installed SpecialFunctions ─── v0.10.0
  Installed Clustering ───────── v0.13.3
#=#=#                                                                                                                                                    0.5%##                                                                         4.1%#####                                                                      8.2%##########                                                                14.3%###############                                                           21.2%#####################                                                     30.4%###############################                                           43.6%##########################################                                59.0%###########################################################               82.1%######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.2.0
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.2
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.10.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.4
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building CMake → `~/.julia/packages/CMake/ULbyn/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_WL5NEy/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.2.0
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.2
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.10.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.4
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -4.145018977725402e6, [99085.09173052915, 914.9082694708566], [-1292.1895897139088 1012.1439844654781 -931.1776972258697; 1574.8188612155784 -1116.1325000549027 722.5202237009454], [[96234.23049212692 297.6410239551419 -590.5507997623463; 297.6410239551419 96727.84032742347 711.669972251945; -590.5507997623462 711.669972251945 99121.72943089924], [3772.5518899094745 -806.2167476003098 1065.9615047432264; -806.2167476003098 2881.6711429269453 -662.9299434455498; 1065.9615047432264 -662.9299434455498 1405.4366280669562]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.427953e+03
      1       1.107430e+03      -3.205234e+02 |        7
      2       1.023096e+03      -8.433354e+01 |        4
      3       9.926775e+02      -3.041861e+01 |        2
      4       9.907886e+02      -1.888901e+00 |        0
      5       9.907886e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 990.7886223489095)
┌ Info: K-means with 272 data points using 5 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.083101
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.826839
[ Info: iteration 2, lowerbound -3.714336
[ Info: iteration 3, lowerbound -3.590922
[ Info: iteration 4, lowerbound -3.445465
[ Info: iteration 5, lowerbound -3.287639
[ Info: dropping number of Gaussions to 7
[ Info: iteration 6, lowerbound -3.119698
[ Info: iteration 7, lowerbound -2.942310
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.773637
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.610098
[ Info: iteration 10, lowerbound -2.485800
[ Info: iteration 11, lowerbound -2.408169
[ Info: dropping number of Gaussions to 4
[ Info: iteration 12, lowerbound -2.358364
[ Info: dropping number of Gaussions to 3
[ Info: iteration 13, lowerbound -2.325512
[ Info: iteration 14, lowerbound -2.308689
[ Info: dropping number of Gaussions to 2
[ Info: iteration 15, lowerbound -2.303157
[ Info: iteration 16, lowerbound -2.299265
[ Info: iteration 17, lowerbound -2.299259
[ Info: iteration 18, lowerbound -2.299256
[ Info: iteration 19, lowerbound -2.299254
[ Info: iteration 20, lowerbound -2.299254
[ Info: iteration 21, lowerbound -2.299253
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: 47 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sat Feb 15 00:58:55 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sat Feb 15 00:59:04 2020: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Sat Feb 15 00:59:06 2020: EM with 272 data points 0 iterations avll -2.083101
5.8 data points per parameter
, Sat Feb 15 00:59:08 2020: GMM converted to Variational GMM
, Sat Feb 15 00:59:17 2020: iteration 1, lowerbound -3.826839
, Sat Feb 15 00:59:17 2020: iteration 2, lowerbound -3.714336
, Sat Feb 15 00:59:17 2020: iteration 3, lowerbound -3.590922
, Sat Feb 15 00:59:17 2020: iteration 4, lowerbound -3.445465
, Sat Feb 15 00:59:17 2020: iteration 5, lowerbound -3.287639
, Sat Feb 15 00:59:17 2020: dropping number of Gaussions to 7
, Sat Feb 15 00:59:17 2020: iteration 6, lowerbound -3.119698
, Sat Feb 15 00:59:17 2020: iteration 7, lowerbound -2.942310
, Sat Feb 15 00:59:17 2020: dropping number of Gaussions to 6
, Sat Feb 15 00:59:17 2020: iteration 8, lowerbound -2.773637
, Sat Feb 15 00:59:17 2020: dropping number of Gaussions to 5
, Sat Feb 15 00:59:17 2020: iteration 9, lowerbound -2.610098
, Sat Feb 15 00:59:17 2020: iteration 10, lowerbound -2.485800
, Sat Feb 15 00:59:17 2020: iteration 11, lowerbound -2.408169
, Sat Feb 15 00:59:17 2020: dropping number of Gaussions to 4
, Sat Feb 15 00:59:17 2020: iteration 12, lowerbound -2.358364
, Sat Feb 15 00:59:17 2020: dropping number of Gaussions to 3
, Sat Feb 15 00:59:17 2020: iteration 13, lowerbound -2.325512
, Sat Feb 15 00:59:17 2020: iteration 14, lowerbound -2.308689
, Sat Feb 15 00:59:17 2020: dropping number of Gaussions to 2
, Sat Feb 15 00:59:17 2020: iteration 15, lowerbound -2.303157
, Sat Feb 15 00:59:17 2020: iteration 16, lowerbound -2.299265
, Sat Feb 15 00:59:17 2020: iteration 17, lowerbound -2.299259
, Sat Feb 15 00:59:17 2020: iteration 18, lowerbound -2.299256
, Sat Feb 15 00:59:17 2020: iteration 19, lowerbound -2.299254
, Sat Feb 15 00:59:17 2020: iteration 20, lowerbound -2.299254
, Sat Feb 15 00:59:17 2020: iteration 21, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 22, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 23, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 24, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 25, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 26, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 27, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 28, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 29, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 30, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 31, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 32, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 33, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 34, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 35, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 36, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 37, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 38, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 39, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 40, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 41, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 42, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 43, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 44, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 45, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: iteration 46, lowerbound -2.299253
, Sat Feb 15 00:59:17 2020: 47 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398592, 178.04509222601408]
β = [95.95490777398592, 178.04509222601408]
m = [2.0002292577753686 53.85198717246129; 4.250300733269907 79.2868669443618]
ν = [97.95490777398592, 180.04509222601408]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.37587636119484363 -0.008953123827346095; 0.0 0.012748664777409435], [0.1840415554748455 -0.0076440490423277255; 0.0 0.008581705166333508]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -1.0035972403475057
avll from llpg:  -1.0035972403475055
avll direct:     -1.0035972403475055
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9953998041639094
avll from llpg:  -0.9953998041639096
avll direct:     -0.9953998041639096
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
  0.0265288    -0.0229116   -0.107577     0.108442     0.0954408   -0.0754924    0.00145889   0.040192      0.11147      0.0544428   -0.018038    -0.0888583   -0.0326923   -0.143629     0.146527     0.0993012    -0.00758762  -0.0806832    0.0356439   -0.234486     0.0303171   -0.160255      0.170533     0.0496481   -0.0230586    0.00992867
 -0.110395     -0.122466     0.014077    -0.0684593   -0.246346     0.0183211   -0.161956    -0.10243      -0.162931    -0.168604    -0.127548    -0.241623     0.0119971   -0.18051     -0.00532778  -0.0653834     0.0958002   -0.121767     0.0609911    0.0500374   -0.122555    -0.0435022     0.0446685   -0.196076     0.0329382   -0.0935858
  0.0408519    -0.0588491   -0.0622549    0.22276      0.0148368    0.0217408    0.0113681   -0.133765      0.00918805   0.0710399    0.0279937    0.0342786    0.0899978    0.126097     0.0872524    0.0614348    -0.0461793   -0.0563059    0.130613    -0.00350482   0.13679      0.126329     -0.0399502    0.0027958   -0.0167903   -0.324262
  0.135048     -0.0322452    0.00256212  -0.0159649    0.175559    -0.00777524   0.00811742  -0.0655698     0.0799292   -0.0236287   -0.00300889  -0.00219765  -0.102953     0.043679    -0.00484583  -0.138877      0.0354324    0.0444054    0.00360494   0.222119     0.0184944    0.0543569     0.0804275   -0.0157721   -0.0952551    0.0572958
  0.205518      0.0789724    0.17791     -0.105273    -0.124088     0.16556     -0.186622     0.0438616     0.0415001    0.0587421   -0.0529036   -0.111904     0.157039    -0.0649924   -0.00222274  -0.240546      0.00271016  -0.15535     -0.23338      0.00750662  -0.123573     0.0785033     0.0363982    0.148897     0.069854     0.105954
 -0.0127593    -0.0871143   -0.00955327  -0.0597156   -0.201969     0.162573     0.193064     0.0068923    -0.11486     -0.00191033   0.0556405    0.0652522   -0.019094    -0.0435752    0.108703    -0.123414     -0.0323444    0.0740708    0.0562365   -0.0945394   -0.0500631    0.13545       0.104656     0.135279    -0.177167     0.140208
  0.0356418     0.00765596   0.143011    -0.00956789   0.10901     -0.177899     0.0378276    0.147051     -0.084623    -0.024244     0.106215     0.123212     0.141326     0.102425    -0.0919901    0.135403     -0.139382    -0.0617898    0.00312255  -0.150756    -0.154506    -0.0535274    -0.15325     -0.138041     0.0143795    0.0759074
 -0.118794     -0.0851735   -0.174773    -0.0598918    0.0844911   -0.100264     0.0153745   -0.0714275    -0.0638393   -0.0836528   -0.0363961    0.036108     0.188455    -0.0949813   -0.0797354    0.0114865    -0.0558758   -0.0607997   -0.100897    -0.00218244   0.152899    -0.0576576    -0.194712    -0.0207951   -0.103591     0.0711227
  0.0217314    -0.188067     0.0507258    0.109677     0.162961     0.0685004   -0.0348699    0.027954     -0.204166     0.128691     0.097735    -0.0418147    0.105949    -0.00251898  -0.0943663    0.0429948    -0.0384834   -0.0735537   -0.102163     0.0445055    0.190684     0.155635     -0.162421    -0.00159931   0.132329    -0.0392792
 -0.108367     -0.0383359   -0.0742252    0.0229872    0.0844618    0.0814758   -0.126686    -0.0387918     0.0449151    0.192212     0.0559521   -0.0208489   -0.170094     0.00351228  -0.0380168   -0.0542572    -0.216507     0.00391358   0.154477     0.0752522    0.0881591    0.0270632    -0.171547    -0.0399339    0.0525292    0.215828
 -0.0140985     0.216224    -0.186287    -0.0428485   -0.109163     0.198473     0.262502    -0.0959344    -0.057819     0.0913943    0.0559476    0.0295319   -0.0152057    0.102596     0.0531558   -0.144236      0.0325081    0.0095137   -0.0748534   -0.0966485   -0.159164     0.042759      0.0718978    0.0630423    0.201283    -0.0648032
  0.0879723    -0.0946487   -0.108259    -0.0218118    0.0147765   -0.0111862    0.1049       0.0763108     0.0263209   -0.116925    -0.0210902    0.0258613   -0.00318043   0.102137    -0.0818947   -0.178968      0.0473121   -0.0120741   -0.0368084   -0.092717    -0.031591     0.0142218     0.0287433   -0.0921846    0.0166514   -0.0297742
  0.108234      0.143071     0.0284539   -0.0372974    0.107414    -0.0699436   -0.126706    -0.2077        0.0937752   -0.0435268    0.213844    -0.0842323    0.0585557   -0.0681836   -0.135015     0.107818     -0.0419361   -0.100915     0.00335137   0.0745527    0.0127284   -0.0440528     0.0395309    0.0522679    0.104453    -0.114734
  0.0623957    -0.12523     -0.067308    -0.0200528   -0.0174859    0.118834     0.0343912    0.0206697    -0.0280621   -0.204932     0.0285043   -0.0498964    0.0617917   -0.0514103   -0.0728111   -0.0197272     0.08        -0.0788648    0.0818619    0.14126     -0.0838702   -0.00868095   -0.0613837    0.203815    -0.0178715   -0.0700829
  0.0364946     0.0507169    0.0950058    0.0768435    0.0486709   -0.107903     0.0488334   -0.000703437  -0.0301036   -0.00356015  -0.011867    -0.00177312   0.0502591   -0.036507     0.0120874    0.0929282     0.0383927    0.0281839    0.0181473   -0.0890652    0.218831     0.0389946    -0.100285    -0.0152683   -0.0542733    0.131426
  0.000960723  -0.0136108   -0.231035     0.0389787   -0.0277631    0.151635    -0.0963229    0.0569663     0.104316     0.0913912   -0.0198313   -0.0421693   -0.0732963    0.0599693    0.0183034    0.0642829    -0.0487548   -0.0809354    0.0489717   -0.162632    -0.0130946   -0.0661558     0.0154595    0.0834763    0.0922742   -0.0154385
  0.0141482    -0.199792    -0.0413756    0.205717     0.052371    -0.0530085    0.139615    -0.113711     -0.0860346   -0.0452616    0.202839     0.103769     0.0246514   -0.0801078   -0.0201035   -0.000712162   0.0381805   -0.0158629    0.092906     0.0676678   -0.115715    -0.0688025    -0.144778     0.0689748    0.0546475   -0.0320941
  0.113966     -0.243144     0.123692     0.0108393   -0.144629     0.176155    -0.0649517   -0.126165      0.0565648    0.0131357   -0.243114    -0.0538792    0.213564    -0.0438498   -0.112973     0.0891239    -0.0328674    0.179437    -0.151996    -0.178385     0.173357     0.008028     -0.0599139    0.061336    -0.00122701   0.000859841
 -0.0751568     0.124915     0.113393     0.124418    -0.0671132   -0.0423684   -0.105218     0.0466145    -0.0624188    0.0691453   -0.19674     -0.0117655    0.191898     0.0440192   -0.0691339    0.180771     -0.109435    -0.00644602   0.14846      0.0038607   -0.0522785    0.128277      0.130804     0.0687062   -0.00675978  -0.184839
  0.116536     -0.0538721    0.211042     0.0919253   -0.0219831    0.172345    -0.0695546   -0.114622      0.0191631   -0.148647    -0.0935285   -0.224035    -0.0189003   -0.0964368    0.055582    -0.120302     -0.0850266   -0.0216544   -0.0865743    0.0685643    0.0616709   -0.00842635   -0.0619473   -0.0854013   -0.0350313   -0.0434027
 -0.129186     -0.170296    -0.0890719   -0.0150967    0.133449    -0.05119      0.0333352    0.0467492     0.0405091   -0.0430569    0.0555111    0.166544    -0.03192      0.055937    -0.0210086    0.231823      0.0582358    0.175434    -0.0512998    0.0125036    0.0484499    0.0139478     0.131001    -0.107913     0.0187131   -0.00405696
 -0.0452746    -0.0411192   -0.00800295   0.0536906    0.00797395  -0.179439    -0.0842347   -0.0911521    -0.0109842    0.0556864    0.0165385   -0.155788     0.0931087    0.0526202   -0.0213292   -0.108559      0.00743241   0.0512818    0.0806032   -0.0333903    0.0137276    0.228055      0.239651     0.013548    -0.257901     0.0760398
  0.0840805    -0.187992    -0.0830721   -0.0732111    0.0573976   -0.16328      0.133398    -0.0340309    -0.0434039    0.00595085  -0.054658     0.0860081   -0.172054     0.0309728    0.0524383    0.0130869     0.073337     0.117052    -0.0812842   -0.0676192    0.0210794   -0.0720734    -0.0616785    0.0660691    0.024532    -0.0268573
  0.06079      -0.0748341   -0.0545784   -0.00327219  -0.0270259    0.0940685   -0.146408     0.0646153    -0.0646094   -0.00948499   0.0288114    0.101653     0.0391641    0.0618165   -0.057673    -0.102906      0.0877298    0.0360687   -0.126924    -0.0295229   -0.194149     0.0465646    -0.0811893   -0.0873287   -0.0429717   -0.0262915
  0.0325107     0.20305      0.0885807   -0.14458      0.0407356   -0.0872288    0.10274     -0.0675125    -0.022704    -0.0325079   -0.161818    -0.0371354   -0.277822     0.00682646   0.0396133   -0.0318585     0.116211     0.232588    -0.143261    -0.0927197   -0.0677172    0.000104676   0.00975985   0.0151519    0.221211     0.0321528
 -0.100999      0.0764645    0.0775271   -0.207789     0.128971    -0.0752595    0.113202    -0.0409803    -0.0800938   -0.051394    -0.0163941   -0.109324     0.0110734   -0.141821    -0.233926    -0.0575737     0.107643     0.0594575    0.0710788    0.0254848   -0.0193773    0.0202595    -0.029007    -0.0648161    0.00559324   0.0395745
 -0.10633      -0.0802068   -0.160029    -0.0719733    0.261955     0.0773929    0.0367222    0.115085     -0.0351854   -0.0946384   -0.0537351   -0.259653     0.0720157    0.111362    -0.0294546    0.1008        0.057276     0.0839812    0.010173    -0.0543692    0.00195059  -0.0610806     0.0611158    0.039758     0.0356157    0.0507285
  0.0659821     0.110884     0.012231    -0.0296537    0.0424125   -0.180651     0.111867    -0.00730396    0.0337718    0.0938706    0.0440242   -0.100489    -0.151654     0.0365695    0.0575918   -0.108549      0.0537138    0.150601     0.0152807   -0.128675     0.264477     0.119617      0.181909    -0.0341468   -0.0809982    0.0696059
 -0.191824      0.00721171  -0.083663     0.111369    -0.131125     0.118579    -0.0236676   -0.130693     -0.137356    -0.0989586   -0.0231926   -0.0726619    0.0080687   -0.143744     0.0163849    0.0623716     0.0195182   -0.0509842   -0.0997527   -0.156126     0.0776904    0.0431979    -0.0822156    0.073581    -0.115141     0.113834
 -0.0484582    -0.0940259   -0.0134943    0.0392936   -0.0373774    0.0996459    0.102401     0.0183699    -0.0208316   -0.0189072   -0.272197     0.00715198  -0.0463039   -0.161333    -0.0679224   -0.0179788    -0.0350624    0.015094    -0.0344801    0.079115     0.0385679   -0.0654762     0.0579541   -0.0488987   -0.042782    -0.149267
  0.118384     -0.118318     0.226898    -0.175556     0.0742694   -0.12695     -0.0604376   -0.0274026    -0.0324094    0.00389734  -0.0173411    0.0245435    0.0930464   -0.0994459   -0.00584948  -0.0516274     0.0136296   -0.0686764    0.0276525    0.0158559    0.0814028    0.0205732    -0.161876     0.0760215    0.0121471   -0.0341847
  0.0238995     0.015131    -0.0689568    0.0389142   -0.0766171    0.165706    -0.00914657  -0.0251273     0.0587486    0.109058     0.118945    -0.0653247    0.0793841    0.0144285    0.0509193   -0.0486061    -0.0620482   -0.0126652    0.168729     0.0865448   -0.0132235   -0.141583      0.090151     0.183974     0.00674895   0.0504387kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.406969327990741
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407042
[ Info: iteration 2, average log likelihood -1.406966
[ Info: iteration 3, average log likelihood -1.406635
[ Info: iteration 4, average log likelihood -1.402816
[ Info: iteration 5, average log likelihood -1.387373
[ Info: iteration 6, average log likelihood -1.376705
[ Info: iteration 7, average log likelihood -1.373660
[ Info: iteration 8, average log likelihood -1.371729
[ Info: iteration 9, average log likelihood -1.370482
[ Info: iteration 10, average log likelihood -1.369561
[ Info: iteration 11, average log likelihood -1.368714
[ Info: iteration 12, average log likelihood -1.367890
[ Info: iteration 13, average log likelihood -1.367093
[ Info: iteration 14, average log likelihood -1.366355
[ Info: iteration 15, average log likelihood -1.365714
[ Info: iteration 16, average log likelihood -1.365242
[ Info: iteration 17, average log likelihood -1.364898
[ Info: iteration 18, average log likelihood -1.364635
[ Info: iteration 19, average log likelihood -1.364427
[ Info: iteration 20, average log likelihood -1.364256
[ Info: iteration 21, average log likelihood -1.364083
[ Info: iteration 22, average log likelihood -1.363893
[ Info: iteration 23, average log likelihood -1.363737
[ Info: iteration 24, average log likelihood -1.363629
[ Info: iteration 25, average log likelihood -1.363560
[ Info: iteration 26, average log likelihood -1.363520
[ Info: iteration 27, average log likelihood -1.363496
[ Info: iteration 28, average log likelihood -1.363481
[ Info: iteration 29, average log likelihood -1.363471
[ Info: iteration 30, average log likelihood -1.363464
[ Info: iteration 31, average log likelihood -1.363459
[ Info: iteration 32, average log likelihood -1.363456
[ Info: iteration 33, average log likelihood -1.363454
[ Info: iteration 34, average log likelihood -1.363452
[ Info: iteration 35, average log likelihood -1.363451
[ Info: iteration 36, average log likelihood -1.363450
[ Info: iteration 37, average log likelihood -1.363450
[ Info: iteration 38, average log likelihood -1.363449
[ Info: iteration 39, average log likelihood -1.363449
[ Info: iteration 40, average log likelihood -1.363449
[ Info: iteration 41, average log likelihood -1.363449
[ Info: iteration 42, average log likelihood -1.363449
[ Info: iteration 43, average log likelihood -1.363449
[ Info: iteration 44, average log likelihood -1.363449
[ Info: iteration 45, average log likelihood -1.363449
[ Info: iteration 46, average log likelihood -1.363449
[ Info: iteration 47, average log likelihood -1.363449
[ Info: iteration 48, average log likelihood -1.363449
[ Info: iteration 49, average log likelihood -1.363449
[ Info: iteration 50, average log likelihood -1.363449
┌ Info: EM with 100000 data points 50 iterations avll -1.363449
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4070419098566083
│     -1.4069661031810474
│      ⋮
└     -1.363448611306263
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.363575
[ Info: iteration 2, average log likelihood -1.363465
[ Info: iteration 3, average log likelihood -1.363102
[ Info: iteration 4, average log likelihood -1.359255
[ Info: iteration 5, average log likelihood -1.344363
[ Info: iteration 6, average log likelihood -1.331635
[ Info: iteration 7, average log likelihood -1.327756
[ Info: iteration 8, average log likelihood -1.326264
[ Info: iteration 9, average log likelihood -1.325433
[ Info: iteration 10, average log likelihood -1.324916
[ Info: iteration 11, average log likelihood -1.324567
[ Info: iteration 12, average log likelihood -1.324306
[ Info: iteration 13, average log likelihood -1.324098
[ Info: iteration 14, average log likelihood -1.323938
[ Info: iteration 15, average log likelihood -1.323819
[ Info: iteration 16, average log likelihood -1.323732
[ Info: iteration 17, average log likelihood -1.323664
[ Info: iteration 18, average log likelihood -1.323608
[ Info: iteration 19, average log likelihood -1.323558
[ Info: iteration 20, average log likelihood -1.323512
[ Info: iteration 21, average log likelihood -1.323470
[ Info: iteration 22, average log likelihood -1.323430
[ Info: iteration 23, average log likelihood -1.323391
[ Info: iteration 24, average log likelihood -1.323354
[ Info: iteration 25, average log likelihood -1.323318
[ Info: iteration 26, average log likelihood -1.323283
[ Info: iteration 27, average log likelihood -1.323248
[ Info: iteration 28, average log likelihood -1.323214
[ Info: iteration 29, average log likelihood -1.323180
[ Info: iteration 30, average log likelihood -1.323146
[ Info: iteration 31, average log likelihood -1.323111
[ Info: iteration 32, average log likelihood -1.323077
[ Info: iteration 33, average log likelihood -1.323041
[ Info: iteration 34, average log likelihood -1.323005
[ Info: iteration 35, average log likelihood -1.322967
[ Info: iteration 36, average log likelihood -1.322926
[ Info: iteration 37, average log likelihood -1.322883
[ Info: iteration 38, average log likelihood -1.322838
[ Info: iteration 39, average log likelihood -1.322791
[ Info: iteration 40, average log likelihood -1.322741
[ Info: iteration 41, average log likelihood -1.322690
[ Info: iteration 42, average log likelihood -1.322637
[ Info: iteration 43, average log likelihood -1.322582
[ Info: iteration 44, average log likelihood -1.322527
[ Info: iteration 45, average log likelihood -1.322468
[ Info: iteration 46, average log likelihood -1.322408
[ Info: iteration 47, average log likelihood -1.322345
[ Info: iteration 48, average log likelihood -1.322280
[ Info: iteration 49, average log likelihood -1.322213
[ Info: iteration 50, average log likelihood -1.322143
┌ Info: EM with 100000 data points 50 iterations avll -1.322143
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3635751136837935
│     -1.3634646007089366
│      ⋮
└     -1.3221425450635114
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.322244
[ Info: iteration 2, average log likelihood -1.321995
[ Info: iteration 3, average log likelihood -1.321429
[ Info: iteration 4, average log likelihood -1.316774
[ Info: iteration 5, average log likelihood -1.299579
[ Info: iteration 6, average log likelihood -1.283301
[ Info: iteration 7, average log likelihood -1.276377
[ Info: iteration 8, average log likelihood -1.273423
[ Info: iteration 9, average log likelihood -1.271686
[ Info: iteration 10, average log likelihood -1.270458
[ Info: iteration 11, average log likelihood -1.269601
[ Info: iteration 12, average log likelihood -1.269046
[ Info: iteration 13, average log likelihood -1.268687
[ Info: iteration 14, average log likelihood -1.268450
[ Info: iteration 15, average log likelihood -1.268283
[ Info: iteration 16, average log likelihood -1.268153
[ Info: iteration 17, average log likelihood -1.268038
[ Info: iteration 18, average log likelihood -1.267925
[ Info: iteration 19, average log likelihood -1.267805
[ Info: iteration 20, average log likelihood -1.267670
[ Info: iteration 21, average log likelihood -1.267515
[ Info: iteration 22, average log likelihood -1.267337
[ Info: iteration 23, average log likelihood -1.267142
[ Info: iteration 24, average log likelihood -1.266933
[ Info: iteration 25, average log likelihood -1.266693
[ Info: iteration 26, average log likelihood -1.266393
[ Info: iteration 27, average log likelihood -1.266000
[ Info: iteration 28, average log likelihood -1.265482
[ Info: iteration 29, average log likelihood -1.264903
[ Info: iteration 30, average log likelihood -1.264499
[ Info: iteration 31, average log likelihood -1.264324
[ Info: iteration 32, average log likelihood -1.264267
[ Info: iteration 33, average log likelihood -1.264242
[ Info: iteration 34, average log likelihood -1.264226
[ Info: iteration 35, average log likelihood -1.264214
[ Info: iteration 36, average log likelihood -1.264203
[ Info: iteration 37, average log likelihood -1.264193
[ Info: iteration 38, average log likelihood -1.264183
[ Info: iteration 39, average log likelihood -1.264173
[ Info: iteration 40, average log likelihood -1.264162
[ Info: iteration 41, average log likelihood -1.264150
[ Info: iteration 42, average log likelihood -1.264137
[ Info: iteration 43, average log likelihood -1.264121
[ Info: iteration 44, average log likelihood -1.264103
[ Info: iteration 45, average log likelihood -1.264082
[ Info: iteration 46, average log likelihood -1.264056
[ Info: iteration 47, average log likelihood -1.264025
[ Info: iteration 48, average log likelihood -1.263989
[ Info: iteration 49, average log likelihood -1.263948
[ Info: iteration 50, average log likelihood -1.263901
┌ Info: EM with 100000 data points 50 iterations avll -1.263901
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3222435664032877
│     -1.3219954719551603
│      ⋮
└     -1.2639010309725462
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.264065
[ Info: iteration 2, average log likelihood -1.263702
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.261056
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.243816
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.212905
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.192018
[ Info: iteration 7, average log likelihood -1.189465
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.181544
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.172953
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.166839
[ Info: iteration 11, average log likelihood -1.172844
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.170414
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.165638
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.161145
[ Info: iteration 15, average log likelihood -1.167548
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.165689
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.161805
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.159029
[ Info: iteration 19, average log likelihood -1.167133
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.165555
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.161716
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.158952
[ Info: iteration 23, average log likelihood -1.167066
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.165496
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.161661
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.158899
[ Info: iteration 27, average log likelihood -1.167010
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.165436
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.161590
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.158817
[ Info: iteration 31, average log likelihood -1.166908
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.165301
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.161395
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.158538
[ Info: iteration 35, average log likelihood -1.166510
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.164794
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.160807
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.157969
[ Info: iteration 39, average log likelihood -1.166028
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.164448
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.160603
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.157880
[ Info: iteration 43, average log likelihood -1.165988
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.164436
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.160602
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.157880
[ Info: iteration 47, average log likelihood -1.165987
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.164436
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.160603
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.157880
┌ Info: EM with 100000 data points 50 iterations avll -1.157880
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2640649662355299
│     -1.2637018108057438
│      ⋮
└     -1.157880075057239
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.166262
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.164347
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.158901
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     13
│     14
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.133564
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│     21
│     22
│     25
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.084687
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      7
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.085788
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      6
│     21
│     22
│     25
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.065400
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     13
│     14
│     25
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.057451
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      6
│      7
│     21
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.043402
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     13
│     14
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.067937
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      6
│     21
│     22
│     25
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.050564
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      7
│     13
│     14
│     25
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.052518
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│     21
│     22
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.049239
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     13
│     14
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.060803
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│      7
│     21
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.045047
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     13
│     14
│     25
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.056731
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│     21
│     22
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.043815
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     13
│     14
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.059016
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│      7
│     21
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.044763
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     13
│     14
│     25
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.056702
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│     21
│     22
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.043870
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     13
│     14
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.059105
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│      7
│     21
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.044837
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     13
│     14
│     25
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.056692
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│     21
│     22
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.043870
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     13
│     14
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.059110
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│      7
│     21
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.044810
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     13
│     14
│     25
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.056687
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│     21
│     22
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.043868
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     13
│     14
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.059110
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│      7
│     21
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.044808
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     13
│     14
│     25
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.056683
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│     21
│     22
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.043865
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     13
│     14
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.059110
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│      7
│     21
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.044795
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     13
│     14
│     25
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.056682
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│     21
│     22
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.043863
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     13
│     14
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.059110
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│      7
│     21
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.044795
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     13
│     14
│     25
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.056681
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│     21
│     22
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.043860
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     13
│     14
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.059110
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│      7
│     21
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.044791
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     13
│     14
│     25
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.056681
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│     21
│     22
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.043858
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     13
│     14
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.059109
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│      7
│     21
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.044792
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     13
│     14
│     25
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.056681
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│     21
│     22
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.043856
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     13
│     14
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.059108
┌ Info: EM with 100000 data points 50 iterations avll -1.059108
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1662621385266145
│     -1.1643471267883914
│      ⋮
└     -1.0591082739076085
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.406969327990741
│     -1.4070419098566083
│     -1.4069661031810474
│     -1.406635241696261
│      ⋮
│     -1.056680921783484
│     -1.0438563840211803
└     -1.0591082739076085
32×26 Array{Float64,2}:
 -0.132137     -0.0821278   -0.17359     -0.0837386    0.0707746   -0.0916854    0.0199816   -0.0718859   -0.0688435   -0.0815289   -0.0324165    0.0395077     0.184061    -0.0948825  -0.116911     0.0108862   -0.0550718    -0.0582233  -0.0995711   -0.0160034    0.153483    -0.0543428   -0.228514    -0.0138021   -0.0795457    0.0823103
  0.00558582    0.0616929    0.0907938    0.0731796   -0.0189065   -0.10903      0.0595757   -0.00561311  -0.0378242    0.00352045  -0.0514728   -0.00452763    0.037232    -0.0354065   0.0193696    0.0930102    0.0396142     0.0275338   0.0197961   -0.0881293    0.224893     0.0393812   -0.0991024   -0.00996268  -0.0381557    0.117813
  0.0899466    -0.188306    -0.0992651   -0.0674667    0.0841689   -0.16546      0.141745    -0.0278179   -0.0407508    0.0375384   -0.0363843    0.0889183    -0.154614     0.0410868   0.0660114   -0.00375668   0.0717774     0.137167   -0.084799    -0.0696414    0.0142782   -0.0708577   -0.0609078    0.0820439    0.0214791    0.0214657
  0.10324      -0.0786236    0.202246     0.0678959    0.0355681    0.161365    -0.0598946   -0.112302     0.0176869   -0.13511     -0.0849921   -0.226415     -0.00591981  -0.0993106   0.0497329   -0.111318    -0.0886944    -0.0315921  -0.0806426    0.0716494    0.0800917    0.00184319  -0.0645932   -0.070518    -0.0251585   -0.0564185
  0.0571821    -0.0517176   -0.029821     0.00965393  -0.0383499    0.0860597   -0.144305     0.0694235   -0.0556829    0.0140013    0.0778897    0.10147       0.051528     0.0620697  -0.0550825   -0.088115     0.126362      0.0417165  -0.12851      0.0296694   -0.195547     0.0557098   -0.0979229   -0.0864753   -0.0400858   -0.0342559
 -0.0973461     0.0439281    0.0469316   -0.166027     0.104914    -0.0812273    0.144087    -0.0577784   -0.0756915   -0.0447923   -0.0168489   -0.105355      0.0149126   -0.137561   -0.22929     -0.0534493    0.0882131     0.0876616   0.0690888    0.0200188   -0.0207971   -0.0157844   -0.0456969   -0.0680595    0.00370466   0.0529957
  0.131678     -0.235977     0.123345     0.0146758   -0.140121     0.161284    -0.0630157   -0.129283     0.0583224   -0.00266985  -0.225081    -0.0518285     0.209812    -0.0303973  -0.112276     0.110396    -0.0501887     0.162009   -0.138103    -0.164519     0.155969     0.0184953   -0.0629686    0.0633666   -0.00417344   0.0282043
  0.029609     -0.0770547    0.0931324    0.0483908    0.138386    -0.0542857    0.00944007   0.0804901   -0.144287     0.0415503    0.0858007    0.0393081     0.131848     0.0488693  -0.0874618    0.0821698   -0.0873441    -0.0673946  -0.0505703   -0.0346519   -0.0036656    0.0304424   -0.176015    -0.0810221    0.0769993    0.0273589
 -0.11336      -0.0404041    0.042636    -0.00123763   0.0950098    0.00536639  -0.179898    -0.0460018    0.049376     0.190348    -0.0345516   -0.0536506     0.0256535   -0.0857808  -0.0343548    0.0222539   -0.223796      0.0201709   0.177866     0.0870928    0.0908541    0.0279284    0.0981862   -0.0145107   -0.779485     0.209688
 -0.119734      7.73292e-5  -0.297898    -0.00460396   0.0675515    0.131298    -0.0807114   -0.0182833    0.029517     0.181235     0.209365     0.0429592    -0.279473     0.142688   -0.0399022   -0.0589874   -0.239466     -0.0388379   0.113625     0.0593148    0.0836186    0.02735     -0.314239    -0.0838171    1.00193      0.213403
  0.117672      0.144262     0.0643715   -0.0425196    0.109593     0.0189048   -0.163633    -0.207777     0.0775984   -0.0668577    0.195329    -0.0827945     0.0578035   -0.0640068  -0.142143     0.105467    -0.0414776    -0.0972605   0.010764     0.109026     0.00296939  -0.0460672    0.060995     0.0132361    0.103351    -0.112289
 -0.106423     -0.0999731    0.0078627   -0.0823995   -0.247835     0.0175627   -0.140389    -0.0968357   -0.173888    -0.178714    -0.114635    -0.26595       0.0282877   -0.178015   -0.00598708  -0.0604089    0.0914967    -0.1298      0.0195893    0.0522547   -0.120939    -0.0352284    0.0519219   -0.224068     0.0292212   -0.0894042
  0.11078      -0.105504     0.226127    -0.175719     0.0743054   -0.119259    -0.0172862   -0.015751    -0.0564121    0.0393057   -0.0207984    0.0508931     0.100138    -0.100009   -0.00567759  -0.0558417    0.0217079    -0.0678305   0.0268981    0.0148244    0.0987184   -0.00856897  -0.185989     0.0264257   -0.00610283  -0.0246987
 -0.0136453     0.00707693  -0.249893     0.0297844   -0.0293096    0.201267    -0.0900838    0.0815031    0.104501     0.0879995   -0.0167702   -0.00771665   -0.105035     0.0670121   0.0153462    0.08476     -0.0392002    -0.0813487   0.0485519   -0.206863     0.0463886   -0.058851     0.022199     0.0829226    0.139186    -0.02488
 -0.019373     -0.622987    -0.179054    -0.04491     -0.108407     0.239533     0.258911    -0.0944465   -0.00757727   0.0754699    0.0223006    0.0176753    -0.0867077    0.102729    0.0369086   -0.10878      0.000102764   0.0369304  -0.0808264   -0.102146    -0.166395     0.0287859    0.1622       0.0388309    0.0740872   -0.292025
 -0.0102133     1.12311     -0.160409    -0.0583312   -0.111158     0.241223     0.260706    -0.128524    -0.0527122    0.106844     0.0996974    0.00432101    0.0720801    0.191283    0.0599035   -0.188406    -0.0326488    -0.0160512  -0.05594     -0.0935928   -0.149182     0.0662333    0.0127256    0.0828539    0.242531     0.186535
  0.204765      0.0584276    0.177904    -0.110081    -0.112368     0.180371    -0.190261     0.0347296    0.062813     0.0547023   -0.0527629   -0.138561      0.136256    -0.0739028   0.0033769   -0.240206     0.018224     -0.12103    -0.241812     0.0480989   -0.123699     0.0801404    0.0270651    0.145665     0.0562102    0.120516
 -0.0896961     0.033269    -0.0114638    0.0356065    0.0790355    0.00444068  -0.0321489    0.0806863   -0.0462563   -0.00403856  -0.13043     -0.131795      0.125484     0.0860805  -0.080677     0.113624    -0.0203651     0.0282423   0.0807091   -0.0129595   -0.0289048    0.0340584    0.101006     0.0863499    0.00453003  -0.0751757
 -0.0463636    -0.102612    -0.0124449    0.0332401   -0.0117899    0.1021       0.103968     0.0603294   -0.0345625   -0.0172806   -0.271433     0.0166159    -0.0468236   -0.161713   -0.073997    -0.0229665   -0.0954453     0.0120899  -0.03609      0.0835415    0.0308579   -0.0651144    0.0456349   -0.0199056   -0.0445783   -0.145466
  0.096348     -0.0711448   -0.108005    -0.0186414    0.0192564   -0.0107528    0.104118     0.118502     0.0230359   -0.117726    -0.00704899   0.0212568    -0.00240093   0.107853   -0.0813571   -0.207138    -0.0124861    -0.0560801  -0.0188167   -0.0953268   -0.00688672   0.00307695   0.0492679   -0.0813107    0.0173666   -0.0164291
 -0.195238      0.0132213   -0.101218     0.122306    -0.13515      0.125806    -0.0218717   -0.118699    -0.127065    -0.113445     0.0168199   -0.0788617    -0.0154106   -0.189199    0.0199152    0.0751281    0.00681438   -0.0520402  -0.109383    -0.165342     0.0819277    0.0468211   -0.0918437    0.0800578   -0.117337     0.123108
  0.0324151    -0.0656588   -0.0816598    0.198029     0.00678343   0.0181418    0.0100908   -0.132005    -0.00327693   0.0790742    0.0403948    0.00224317    0.0876473    0.0955277   0.115525     0.0642919   -0.0497918    -0.0519776   0.126485     0.0208925    0.149284     0.124659     0.00358791   0.0385917   -0.0171772   -0.310282
 -0.0120451    -0.0725548   -0.0595324   -0.0015682   -0.0983459   -0.00271589   0.0597293   -0.0332207   -0.067631     0.0274181    0.0398043   -0.0488603     0.0382479   -0.0021988   0.0319297   -0.116675    -0.0156868     0.0641268   0.0682797   -0.0417972   -0.0422653    0.176929     0.163757     0.0730198   -0.218998     0.109171
  0.000796456   0.0149505   -0.0788969    0.0394929   -0.0875938    0.171791    -0.00284218  -0.0424208    0.0589385    0.0932843    0.113536    -0.0641302     0.0896414    0.0113635   0.0507768   -0.0408457   -0.0668898    -0.010762    0.169416     0.085541    -0.0126246   -0.140822     0.102705     0.206659     0.00960416   0.0516389
  0.0584427     0.113621     0.0863339    0.0417856    0.0287298   -0.177959     0.121513    -0.283416     0.0968804    0.133844     0.0391888   -0.130547     -0.155001     0.0828173   0.0342816   -0.120518    -0.114409      0.180027    0.115004    -0.133933     0.176289     0.0896202    0.177311    -0.0307063   -0.0808901    0.0478875
  0.120928     -0.024983    -0.00207074  -0.0371301    0.17332     -0.0200319    0.0266602   -0.0646986    0.0831159   -0.0947189   -0.0226443    0.000353003  -0.0890355    0.0429438  -0.00944055  -0.130958     0.0356518     0.0503912  -0.00161776   0.206366     0.00904969   0.0729295    0.0931047   -0.0506812   -0.0954047    0.0410603
  0.056492      0.107105     0.118485    -0.133218     0.0353593   -0.193082     0.145245     0.612467    -0.0682565    0.0668424    0.0438045   -0.115359     -0.168675     0.0381956   0.0782237   -0.18415     -0.509581      0.135777   -0.368272    -0.131743     0.881381     0.131661     0.181137    -0.0908551   -0.0810816    0.0924567
  0.0705019     0.109129    -0.0571049    0.0762627    0.039103    -0.174583     0.104483     0.101356     0.0927795    0.094903     0.0220982   -0.11271      -0.0879778    0.0193562   0.0466405   -0.0478405    0.258897      0.162037   -0.0298804   -0.129727     0.190478     0.140547     0.220185    -0.0549577   -0.0809108    0.0820574
  0.0181777    -0.0110284   -0.09475      0.120181     0.0930375   -0.0871501   -0.00389719   0.036906     0.106083     0.0541823   -0.0181179   -0.0862082    -0.0207269   -0.159248    0.144529     0.100365    -0.00277326   -0.0459673  -0.0201419   -0.229964    -0.0257341   -0.153032     0.154223     0.0522192   -0.017292     0.00761193
  0.142849     -0.132665    -0.0646325   -0.0181467   -0.017033     0.122241     0.0302922    0.0418251   -0.0307692   -0.203504     0.0272523   -0.0488391     0.0613455   -0.0508589  -0.0766087   -0.0210369    0.0854989    -0.0646941   0.0186381    0.132142    -0.0919796   -0.0305665   -0.0542371    0.207089    -0.0260103   -0.0679031
 -0.12667      -0.169186    -0.0754804   -0.055337     0.112804    -0.0698383    0.0645443    0.0398229    0.0354524   -0.0144363    0.0434218    0.167807     -0.0474838    0.0810699  -0.0211048    0.226943     0.0584064     0.17257    -0.0499986    0.00882373  -0.00326158   0.0569423    0.152858    -0.0780734    0.0112108   -0.0066718
  0.0245505     0.028028     0.015142     0.0998467    0.053963    -0.0435389    0.123185    -0.0811222   -0.0541063   -0.0340954    0.027326     0.0444182    -0.138215    -0.034398    0.00793189  -0.00467022   0.0822873     0.115881   -0.0271197   -0.0146457   -0.0736269   -0.0290339   -0.065037     0.038897     0.11355      0.0105164[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│      7
│     21
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.044790
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.017975
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      6
│      7
│     21
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.037317
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.024318
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│      7
│     21
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.038029
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.016985
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      6
│      7
│     21
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.044603
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.017810
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      6
│      7
│     21
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.037291
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.024302
┌ Info: EM with 100000 data points 10 iterations avll -1.024302
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.970914e+05
      1       6.719110e+05      -2.251803e+05 |       32
      2       6.374935e+05      -3.441750e+04 |       32
      3       6.198803e+05      -1.761319e+04 |       32
      4       6.112545e+05      -8.625820e+03 |       32
      5       6.069863e+05      -4.268184e+03 |       32
      6       6.049535e+05      -2.032780e+03 |       32
      7       6.039577e+05      -9.957998e+02 |       32
      8       6.032815e+05      -6.762810e+02 |       32
      9       6.025309e+05      -7.505708e+02 |       32
     10       6.014309e+05      -1.099947e+03 |       32
     11       6.004085e+05      -1.022429e+03 |       32
     12       5.997975e+05      -6.109756e+02 |       32
     13       5.993832e+05      -4.143770e+02 |       32
     14       5.989753e+05      -4.078411e+02 |       32
     15       5.986299e+05      -3.454474e+02 |       32
     16       5.983809e+05      -2.489517e+02 |       32
     17       5.981714e+05      -2.095149e+02 |       32
     18       5.979878e+05      -1.836381e+02 |       32
     19       5.978202e+05      -1.675889e+02 |       32
     20       5.976352e+05      -1.849813e+02 |       32
     21       5.974326e+05      -2.025627e+02 |       32
     22       5.972527e+05      -1.799213e+02 |       32
     23       5.971190e+05      -1.337160e+02 |       32
     24       5.970442e+05      -7.477297e+01 |       32
     25       5.970077e+05      -3.652007e+01 |       31
     26       5.969843e+05      -2.342100e+01 |       31
     27       5.969687e+05      -1.557851e+01 |       29
     28       5.969577e+05      -1.102956e+01 |       31
     29       5.969474e+05      -1.025186e+01 |       31
     30       5.969392e+05      -8.181087e+00 |       30
     31       5.969322e+05      -7.018333e+00 |       28
     32       5.969260e+05      -6.232001e+00 |       30
     33       5.969212e+05      -4.755523e+00 |       27
     34       5.969175e+05      -3.692344e+00 |       21
     35       5.969150e+05      -2.532327e+00 |       20
     36       5.969129e+05      -2.157172e+00 |       21
     37       5.969104e+05      -2.486848e+00 |       20
     38       5.969085e+05      -1.830904e+00 |       21
     39       5.969072e+05      -1.350933e+00 |       18
     40       5.969060e+05      -1.169271e+00 |       14
     41       5.969039e+05      -2.118169e+00 |       23
     42       5.969016e+05      -2.302844e+00 |       25
     43       5.968985e+05      -3.113250e+00 |       26
     44       5.968955e+05      -3.015101e+00 |       24
     45       5.968929e+05      -2.557002e+00 |       24
     46       5.968913e+05      -1.630121e+00 |       17
     47       5.968892e+05      -2.059026e+00 |       24
     48       5.968854e+05      -3.788340e+00 |       26
     49       5.968822e+05      -3.245390e+00 |       23
     50       5.968797e+05      -2.458960e+00 |       19
K-means terminated without convergence after 50 iterations (objv = 596879.727587362)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.311558
[ Info: iteration 2, average log likelihood -1.277245
[ Info: iteration 3, average log likelihood -1.242574
[ Info: iteration 4, average log likelihood -1.197096
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.144126
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     16
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.107170
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.129240
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.106154
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.076124
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.059303
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     17
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.048631
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     16
│     18
│     19
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.047201
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.081865
[ Info: iteration 14, average log likelihood -1.061849
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      4
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.020706
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     17
│     19
│     23
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.037699
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.095578
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.064047
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.039720
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     18
│     19
│     23
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.040334
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      6
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.076040
[ Info: iteration 22, average log likelihood -1.079652
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.033621
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     15
│     16
│     19
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.038279
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.087987
[ Info: iteration 26, average log likelihood -1.083038
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     23
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.032168
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      4
│     16
│     17
│     19
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.039702
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.095493
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.062389
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.033880
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     15
│     18
│     19
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.048593
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     16
│     17
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.066230
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.069798
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.058467
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     17
│     19
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.039999
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     16
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.075422
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.081760
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.042126
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     16
│     19
│     23
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.028704
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      4
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.086221
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.082687
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     20
│     23
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.042643
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      6
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.060098
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.073908
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     19
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.033335
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     20
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.046454
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     16
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.064792
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.072575
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     19
│     23
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.027983
┌ Info: EM with 100000 data points 50 iterations avll -1.027983
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0334839   -0.0785266    0.0941634    0.0477487    0.132926   -0.0537564    0.00751738    0.0800517   -0.144377     0.0397212    0.080403     0.0400625    0.132143     0.0491338   -0.0889026    0.0859056   -0.0881353   -0.0665825   -0.0505651    -0.0390544   -0.00122552   0.0298172   -0.178603    -0.0831154     0.0775412     0.0287663
  0.00123393   0.0544887    0.081695     0.0717905   -0.0208819  -0.108802     0.0576937    -0.00868139  -0.0361842   -0.0018994   -0.0562701   -0.00118613   0.0385379   -0.0371124    0.0173076    0.0886278    0.0332659    0.0240337    0.0131661    -0.0823258    0.224393     0.0313822   -0.102191    -0.012084     -0.0391131     0.117329
  0.0178165   -0.0907817   -0.0388402   -0.0527025   -0.202604    0.160111     0.199769      0.0225489   -0.123056     0.00295648   0.0638504    0.0675556   -0.0133418   -0.0516427    0.0983005   -0.135279    -0.0348813    0.0657601    0.0574065    -0.0663052   -0.0566842    0.142602     0.102503     0.136104     -0.174187      0.13591
  0.0192909   -0.00962067  -0.0956821    0.122434     0.0923951  -0.0923426   -0.00573967    0.0376669    0.105416     0.0527976   -0.016657    -0.0868526   -0.0205337   -0.157541     0.146549     0.0990212   -0.00467824  -0.0487338   -0.0224459    -0.22809     -0.0177079   -0.149185     0.151658     0.0529373    -0.0176075     0.00734822
 -0.106638    -0.101505     0.00892477  -0.0799739   -0.255378    0.0173369   -0.144347     -0.0931687   -0.175432    -0.17977     -0.121014    -0.269685     0.0316882   -0.182852    -0.00651683  -0.059971     0.0833556   -0.135357     0.0105791     0.053068    -0.121846    -0.0333837    0.0521635   -0.23266       0.0308578    -0.0908819
 -0.138701    -0.084734    -0.188309    -0.079557     0.0786412  -0.0996291    0.0195936    -0.0734739   -0.0699315   -0.0774555   -0.042167     0.0451019    0.202468    -0.0980765   -0.13545      0.00847501  -0.0546727   -0.0599486   -0.0994719    -0.00933589   0.152687    -0.0539324   -0.241891    -0.0188319    -0.0832561     0.0802183
 -0.0124111    0.259949    -0.170393    -0.0501201   -0.109858    0.239666     0.259318     -0.112516    -0.0282038    0.0933095    0.0625748    0.0112224   -0.00450016   0.146292     0.0478128   -0.149541    -0.0160131    0.0101376   -0.0686471    -0.0978226   -0.15826      0.0479303    0.087543     0.060935      0.158317     -0.0523406
 -0.117514    -0.0215766   -0.12557     -0.00240311   0.0808103   0.0667723   -0.132693     -0.032324     0.040219     0.187419     0.0839846   -0.00453787  -0.125112     0.0275447   -0.0373294   -0.0176769   -0.232153    -0.0111104    0.147384      0.0738285    0.0871747    0.0276258   -0.104307    -0.0510501     0.0933649     0.211432
  0.0381166    0.265692     0.0841801   -0.144568     0.0417136  -0.0361429    0.105583     -0.0652878   -0.0241627   -0.0209152   -0.161736    -0.0238795   -0.286667     0.00698972   0.0387748   -0.0277713    0.114374     0.225099    -0.162906     -0.105792    -0.0650643    0.00663349   0.00417119   0.0142972     0.221959      0.0400709
 -0.10654     -0.0809613   -0.162       -0.0671071    0.258001    0.0774852    0.0366059     0.0985734   -0.0338482   -0.0958913   -0.0364706   -0.274918     0.0619302    0.11538     -0.0179809    0.0986379    0.0774865    0.0712902    0.00947565   -0.0680024    0.0011381   -0.0746552    0.0618933    0.0354064     4.45521e-5    0.0450055
  0.0590267   -0.0473855   -0.0267445    0.00684462  -0.0364382   0.0841419   -0.135272      0.0701805   -0.0546788    0.0148452    0.0793432    0.0994332    0.0508325    0.0571256   -0.058165    -0.0898289    0.124987     0.042918    -0.126392      0.0330817   -0.193599     0.0567696   -0.0975482   -0.0867279    -0.0378884    -0.0330171
  0.205072     0.0591881    0.181664    -0.112038    -0.1165      0.178283    -0.190918      0.0360436    0.0648667    0.0543598   -0.0525283   -0.138137     0.136921    -0.0774516    0.00255873  -0.239893     0.0179613   -0.12764     -0.248982      0.0484562   -0.124828     0.0803326    0.0260672    0.147117      0.0593955     0.122703
  0.0913369   -0.188524    -0.0957391   -0.0696329    0.0854832  -0.165485     0.141992     -0.0270155   -0.0392351    0.0383762   -0.0378946    0.0891563   -0.15187      0.0435917    0.0649917   -0.00541337   0.0704899    0.136728    -0.0859217    -0.0693026    0.0168826   -0.0727741   -0.0609797    0.0832485     0.0216169     0.0182165
  0.117373     0.144195     0.06286     -0.0421027    0.109788    0.0212872   -0.162049     -0.207893     0.0786222   -0.0715215    0.194669    -0.0821959    0.0578118   -0.0684503   -0.144565     0.105097    -0.0410652   -0.0955373    0.0102978     0.105705     0.00318711  -0.0464495    0.0599456    0.01436       0.103728     -0.11634
  0.0469609    0.0273527    0.118464     0.0687414   -0.0761229   0.0048798   -0.00618454   -0.0567089   -0.0620589    0.00440146  -0.208101    -0.0683042    0.137077    -0.0395663   -0.0554299    0.073906    -0.0341834    0.0858666   -0.0466245    -0.0845493    0.153554     0.0230886   -0.0252196    0.00609268   -0.0429898     0.0743317
  0.122993    -0.0376678    0.00382636  -0.0316507    0.174473   -0.011584     0.0209691    -0.0667904    0.0858051   -0.0966648   -0.0411595   -7.81281e-5  -0.0805706    0.0428407   -0.00822999  -0.129067     0.0344131    0.0537821   -0.00497043    0.225333     0.0140132    0.0762177    0.084631    -0.0415635    -0.0961835     0.032553
 -0.0129336    0.0225183   -0.231309     0.0286561   -0.0380806   0.287871    -0.0856126     0.12434      0.10566      0.0934609   -0.0293481    0.00407124  -0.103939     0.0795489    0.010787     0.0926175   -0.0417739   -0.0776646    0.0473351    -0.224775     0.068643    -0.0662139    0.0133139    0.0788609     0.178822     -0.0307315
  0.103771    -0.150848    -0.0320604   -0.0669143   -0.071333    0.156401     0.000890811  -0.0825406   -0.0568388   -0.145841    -0.0279551   -0.0718918    0.089585    -0.0892726   -0.0717827   -0.044014     0.0613239    0.0181826   -0.0398193     0.0847707   -0.0289385    0.0105379   -0.0103642    0.163934      0.00770807   -0.0968904
 -0.0381447   -0.0496836   -0.0721297    0.0562268    0.0147217  -0.181535    -0.0986128    -0.0913774   -0.00786969   0.0564099    0.0141411   -0.173876     0.0893907    0.0471881   -0.0317595   -0.0892176    0.00170134   0.0554994    0.0792886    -0.0147273   -0.0138996    0.211726     0.236075     0.000862733  -0.238704      0.0799825
 -0.001962     0.00153765  -0.176206     0.0188335   -0.0188207  -0.22554     -0.0674701    -0.0675803    0.072902     0.0993628   -0.0217652   -0.169212     0.102711     0.0413174    0.0149062    0.0246031   -0.0242622   -0.0535663    0.0575278    -0.135069    -0.0502433    0.0388778    0.103753     0.0816544    -0.165713      0.0394323
 -0.127148    -0.168335    -0.0788415   -0.0561746    0.108614   -0.0713307    0.064009      0.0399301    0.0364839   -0.0145028    0.04407      0.167933    -0.0466785    0.079791    -0.0213177    0.228244     0.0576226    0.172245    -0.0501298     0.00919763  -0.00395536   0.0564468    0.152117    -0.0803356     0.0113866    -0.00672639
 -0.0025424    0.0147167   -0.0799287    0.042218    -0.0874686   0.175161    -0.00222238   -0.0429464    0.0588418    0.0929457    0.114092    -0.0641921    0.0905875    0.00988427   0.0512749   -0.0411626   -0.0665096   -0.0123593    0.17067       0.0862168   -0.0133282   -0.141408     0.10159      0.205473      0.0114445     0.0516087
  0.143549    -0.136446    -0.06296     -0.0169966   -0.0175063   0.12953      0.0298201     0.0416166   -0.031677    -0.204354     0.0288428   -0.0478979    0.0617076   -0.0510238   -0.083287    -0.0207037    0.0849873   -0.0693319    0.0199447     0.132887    -0.090515    -0.0332005   -0.0566338    0.206772     -0.0255203    -0.0690974
  0.01717     -0.191409    -0.059732     0.294315     0.0627912  -0.0486412    0.127716     -0.0916459   -0.0681963   -0.039697     0.186157     0.112572    -0.00475828  -0.071163    -0.0163355    0.0204926    0.0403216    0.00959534   0.0998997     0.062292    -0.0749832   -0.0671776   -0.126198     0.0671048     0.0176286    -0.0230717
  0.0982288   -0.0739623   -0.106361    -0.0178816    0.0171052  -0.0119121    0.10425       0.121683     0.0255537   -0.117204    -0.00470308   0.0225266   -0.00246073   0.108688    -0.0816049   -0.207907    -0.0143876   -0.0555758   -0.020343     -0.093219    -0.00867715   0.00421436   0.0503428   -0.0820342     0.0164835    -0.0181436
  0.0720547    0.11197      0.00565373   0.0391318    0.0408318  -0.176092     0.109641     -0.00515617   0.0740725    0.0973583    0.0418905   -0.108883    -0.124783     0.0428024    0.0436833   -0.0945346    0.0524064    0.158371     0.000427461  -0.125698     0.213258     0.10653      0.195367    -0.0491599    -0.0803878     0.0710928
 -0.191664     0.00689412  -0.0953262    0.106024    -0.131536    0.114288    -0.0242443    -0.1219      -0.136775    -0.106543     0.0112508   -0.065519    -0.00386138  -0.167327     0.0183394    0.0791496    0.00561274  -0.0512541   -0.101672     -0.158604     0.0826822    0.0406259   -0.0859398    0.0684698    -0.113218      0.112931
 -0.0171653    0.0354497    0.0203179    0.165918    -0.0391906  -0.00982447  -0.0405249    -0.0492126   -0.0212242    0.0800194   -0.0754303    0.00628467   0.131759     0.0816771   -0.00871629   0.0949963   -0.085391    -0.0339177    0.13844       0.0245354    0.0457706    0.131096     0.0622012    0.09637      -0.0101344    -0.260281
 -0.0457455   -0.102976    -0.0125072    0.0339902   -0.0112151   0.102552     0.104279      0.0614345   -0.0342964   -0.0170928   -0.271831     0.0164113   -0.0462722   -0.161458    -0.0743726   -0.0232701   -0.095866     0.0122625   -0.0357488     0.0840147    0.030995    -0.0652532    0.0459621   -0.0191372    -0.0442953    -0.145327
 -0.0010904   -0.0986063    0.0870625   -0.0891927   -0.0120234   0.0275772    0.0472658    -0.0969535   -0.0122462   -0.0241529   -0.111646    -0.0851871    0.104058    -0.0967783   -0.178177     0.0189434    0.0285051    0.125874    -0.023184     -0.0651058    0.0598221    0.00587531  -0.053917    -0.0097297    -0.000834458   0.0478268
  0.111901    -0.0775609    0.205656     0.0792964    0.0246568   0.165573    -0.0615449    -0.120158     0.0180222   -0.134666    -0.0905191   -0.229383    -0.00643175  -0.103513     0.0509586   -0.113939    -0.0874426   -0.0342487   -0.0895625     0.073368     0.0829276    0.00983747  -0.0671035   -0.0702476    -0.0249934    -0.0635162
  0.110617    -0.0974179    0.222354    -0.174179     0.073768   -0.114296    -0.0253895    -0.0165313   -0.053812     0.04179     -0.0213896    0.0521201    0.0995318   -0.10086     -0.00527006  -0.053199     0.0199      -0.0687112    0.026515      0.0129621    0.0973006   -0.0123245   -0.185605     0.0264395    -0.00602951   -0.0259599[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│     16
│     17
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.049697
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      4
│      6
│     16
│     17
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.023461
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      4
│      6
│     16
│      ⋮
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.991088
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│     16
│     17
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.043170
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      4
│      6
│     15
│     16
│     17
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.009666
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      4
│      6
│     16
│      ⋮
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.993782
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│     16
│     17
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.045359
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│      6
│     16
│     17
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.010338
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      4
│      6
│     15
│      ⋮
│     27
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.983912
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      4
│     16
│     17
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.049178
┌ Info: EM with 100000 data points 10 iterations avll -1.049178
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0553222    0.144947   -0.230161     0.122686     0.0132151   -0.0951492    0.00287866   0.0988261    0.129428    0.0751846    0.108924     0.023446    -0.14074     -0.118946   -0.0877032     0.175201    -0.181299    -0.0872199  -0.0661721   -0.0464332    0.00323256   0.0485624    0.0328961    0.00881411  -0.121674     0.22502
 -0.0781731   -0.140106   -0.170421    -0.0822439   -0.204913     0.120175     0.174284     0.179432     0.0928525   0.178235    -0.0157282    0.0491328   -0.0313316    0.0747918  -0.118649      0.00611289  -0.0612186    0.0132639  -0.102715    -0.126518     0.10431     -0.00942767   0.0412533    0.0111662    0.128451    -0.116053
 -0.0128945   -0.058188   -0.0917725   -0.0438724    0.115501    -0.109362     0.0661145    0.0578279   -0.124654    0.0291402   -0.0146434   -0.0771834   -0.0391721   -0.136095   -0.207258     -0.099375    -0.109825    -0.0751941   0.161704     0.0689719   -0.079944     0.00160989  -0.0592827   -0.14286     -0.160142    -0.125871
 -0.113667     0.0152816  -0.166711    -0.169441    -0.148201     0.0198461    0.00952155  -0.0279833    0.0440226  -0.0546144   -0.00859147   0.169375     0.0444358    0.140129   -0.0712349     0.0755357    0.0635218   -0.0376292   0.128829    -0.0617122   -0.115142    -0.142649     0.0338471   -0.19346      0.101025     0.172054
 -0.0394719   -0.0200466  -0.00195552  -0.0170958   -0.032915     0.140612     0.0162429   -0.101314    -0.0659183   0.0284399   -0.0411997   -0.0775736    0.0989144   -0.0231916   0.104071      0.0345226    0.00530958  -0.0152434   0.0244998   -0.00322338  -0.0301605    0.0271271   -0.161714     0.0386179   -0.0544495   -0.154983
 -0.0553075   -0.0212358   0.0660505   -0.0565796   -0.14081      0.0875265    0.0479824   -0.10092      0.13192     0.0435961    0.126377     0.0722667   -0.0771897   -0.0401269  -0.0424425    -0.00184176  -0.0358242   -0.0150233   0.0116857    0.145521    -0.203668     0.0686865    0.0623196   -0.168387    -0.00139001  -0.169863
 -0.164398     0.074138    0.0300902    0.1055       0.0608582   -0.0388301   -0.0988038   -0.0442027   -0.131133    0.0587295   -0.14157      0.203437    -0.0322182    0.128951    0.122449     -0.085702     0.0817358    0.146008    0.0604697    0.044598    -0.0626579   -0.0374264   -0.0184043    0.044456    -0.081206     0.151171
  0.0638801    0.0707344   0.0939414    0.0506241   -0.160353     0.0333703   -0.0156087    0.202995     0.129274    0.09006     -0.0719648    0.00920358   0.0445024   -0.0791813  -0.0917509    -0.0667083   -0.0754866   -0.0537744   0.128054    -0.0462539    0.0733011   -0.0390826    0.0290437    0.0277828   -0.0955208   -0.113296
  0.0829474    0.119693    0.0761951   -0.00529995  -0.0588092    0.1529      -0.0295281   -0.029444    -0.263356    0.0118601   -0.0513278   -0.128016    -0.0821935    0.141164   -0.00584959    0.0748116   -0.0179485   -0.145347    0.0776602   -0.010009    -0.0730886   -0.0237826   -0.0418958    0.143137    -0.0864256    0.0374841
  0.0958152    0.0604016  -0.0540608    0.0986516   -0.0568685   -0.0855179    0.0116692    0.092815     0.148543   -0.107546    -0.0701035    0.138662    -0.00858375  -0.142571    0.0102394    -0.00698718   0.202778    -0.0231529   0.0263119    0.0653251    0.0217543   -0.0260051   -0.033713     0.036168     0.114191    -0.137372
 -0.0541684   -0.155859   -0.0715716   -0.0762342    0.00547962  -0.0548393   -0.0385413   -0.0839716    0.111856   -0.0339693   -0.0712404    0.0142693    0.165633    -0.15472    -0.0169768    -0.0676759    0.0227789   -0.0753044   0.0866767   -0.261635    -0.00989486   0.0354592   -0.0662477   -0.0312616   -0.160006    -0.128612
 -0.0148145    0.0195719  -0.101184     0.021813     0.144484    -0.119909     0.175934    -0.0598633   -0.0727966   0.0579186    0.0080585   -0.15291      0.00789759   0.176511   -0.158931      0.120238    -0.245817    -0.158127    0.0411167   -0.0420697   -0.0828976   -0.0161321    0.0573981    0.0267567    0.00620268  -0.0593655
 -0.0956547   -0.019999    0.1029       0.0698052    0.0180761    0.0908519   -0.0154676   -0.0121515    0.0349321  -0.0486858    0.0703607   -0.104779     0.00380038   0.140067   -0.117319     -0.0486766   -0.036446     0.0781456  -0.0884324   -0.142496    -0.0290655    0.0515596   -0.00504659   0.141445    -0.120597    -0.139963
  0.00933151   0.0219833   0.0237813    0.0896965   -0.0062682   -0.0212367   -0.0225399    0.0740863    0.0288224  -0.0322355    0.0454246   -0.147804     0.0522166    0.124131   -0.000787006  -0.0390345   -0.0441635    0.229053    0.0879736    0.00065644   0.0698809   -0.0178453   -0.0783239    0.0463155    0.0891994    0.0894051
  0.240826    -0.0359137   0.0068405   -0.205219    -0.0242632    0.0502583    0.0492733   -0.129747     0.0369787  -0.180097    -0.0284478    0.0790158    0.0802335    0.126785   -0.134781      0.0398058    0.013277     0.117424    0.0617653    0.0937808   -0.0695784    0.0481513   -0.0608888    0.0422613   -0.0137955    0.028118
  0.0484764   -0.206492    0.123889     0.0215166   -0.0557888   -0.213205    -0.0280094   -0.0367693    0.13517    -0.187254     0.168555     0.0883019   -0.0910894    0.152908    0.0828845    -0.0583683    0.00643599  -0.0388779   0.0203893   -0.075761     0.0637757   -0.0686732   -0.00738585   0.0257909    0.124587     0.226336
  0.0397245   -0.0241259   0.0483631    0.0210479    0.121764    -0.0103544   -0.0903659    0.00637317   0.0194713  -0.00540507   0.0146259   -0.0566541    0.0984814   -0.0977844   0.0615319    -0.017565    -0.117854     0.109755    0.0633737    0.0524632   -0.0172763    0.0231076    0.0486168    0.0369746    0.126362    -0.127393
 -0.159199     0.0247829  -0.0169438    0.150075    -0.0314736    0.0899633   -0.0773789   -0.187814    -0.0180459  -0.0494598   -0.14645     -0.0480044   -0.109003     0.191678    0.0368526    -0.0340545    0.0632848    0.0174987   0.00423288  -0.00254644  -0.154845     0.033469    -0.171146    -0.118475    -0.143027     0.107274
 -0.0138156    0.145359   -0.0642778   -0.031082     0.00216314   0.0128326   -0.0872971    0.205068     0.0189665   0.0809866   -0.0375965    0.15536     -0.0541435   -0.113554   -0.0937923    -0.0488565   -0.0952808   -0.0754604  -0.0519857    0.168976    -0.00151652  -0.0560842   -0.179574    -0.00530875  -0.0223067    0.0805144
  0.0502535    0.0319683   0.0183121    0.0787277   -0.041005     0.0234428    0.0794016    0.121955    -0.0622745  -0.0845836   -0.120691    -0.0154155    0.106846     0.066248    0.0507252    -0.0261781    0.0801606    0.0134377  -0.148522     0.136733     0.192203    -0.0453013   -0.00589454  -0.0768427    0.0988038    0.068529
 -0.151283    -0.062948    0.0174578   -0.162383     0.0892739    0.105938     0.0252517    0.264764     0.0138199  -0.1226      -0.0183878    0.0748153    0.00216953   0.0976866  -0.0440313     0.0102675    0.00127096  -0.0565741  -0.0723532    0.0362117    0.0295516   -0.0692128    0.101284     0.0323075   -0.121092    -0.0581414
 -0.208064    -0.0234874  -0.0977819    0.0575385    0.12518     -0.132947     0.0261027    0.157543    -0.0849722   0.136174    -0.148307    -0.0670976    0.0993147    0.067034    0.085962     -0.0761975   -0.054908    -0.0493788  -0.00176856  -0.0838085    0.132458     0.0298717    0.0452247    0.0147966    0.16507      0.099808
 -0.119894     0.132616   -0.132458    -0.0648083   -0.00492132  -0.00334259  -0.00498427  -0.175192    -0.0746889   0.189168    -0.0218424    0.0615548   -0.0318926   -0.0101895  -0.0459533    -0.0831353    0.0235748   -0.0490452  -0.0359248   -0.0482601    0.0700081   -0.125454     0.0921499    0.105531     0.112194     0.0169467
  0.111882     0.0425413  -0.135555     0.0447033    0.131392     0.0466222    0.023531    -0.156788    -0.103215   -0.207135     0.23966     -0.158943    -0.003401     0.0973256  -0.0424639    -0.182888     0.0102198    0.0407292  -0.263669     0.0170938    0.100325     0.117844     0.0347719    0.0642492    0.0281527   -0.0669488
 -0.00301891  -0.120856   -0.0599695   -0.073307    -0.164527     0.0136584   -0.0441603    0.11471     -0.0718702   0.179371    -0.0230174   -0.0468247    0.0116583    0.168917    0.0562471     0.0610684    0.193432    -0.0711065  -0.00821542   0.05995     -0.0713896   -0.123414    -0.198649    -0.0115384    0.0683035   -0.0475914
  0.006105     0.0257083   0.177912     0.0265716    0.0306704    0.0247611    0.0228988    0.0789037   -0.0430198   0.0691359   -0.0670762   -0.0635338    0.116152     0.0844303  -0.034454      0.031965     0.00678277  -0.0654536  -0.125387    -0.143138    -0.0852088    0.231219     0.00680568   0.164758    -0.163062    -0.0111224
  0.142035    -0.028165   -0.106629     0.0347027   -0.370094    -0.0305564    0.036203     0.015933    -0.0332151   0.136455     0.0169064    0.142085    -0.0837811    0.0127216  -0.127021     -0.00125253   0.163671    -0.106199    0.114873    -0.0391842   -0.0690408   -0.00894006  -0.0647122   -0.0227591   -0.0524074   -0.191607
 -0.0407681   -0.0769284  -0.158724    -0.0965481   -0.0418587    0.0197783    0.0174068    0.0590629   -0.101775    0.139602     0.0405482    0.137674    -0.170161     0.109176    0.0551005     0.0984061    0.0691414    0.0459681   0.0740109   -0.00545845   0.108374    -0.0297997   -0.0650378   -0.103603     0.0278409   -0.119544
  0.238086     0.0848426  -0.0244895    0.0167836   -0.0261693   -0.0870474   -0.0425163   -0.266798     0.111214    0.0478961   -0.153992     0.04276      0.112455     0.150602    0.153635      0.0361919   -0.0340243    0.02069     0.123048     0.064202     0.0233998    0.115162    -0.00543131   0.0268034   -0.0174893   -0.087447
 -0.141203    -0.0805516  -0.194942    -0.0454367   -0.0269745    0.12279      0.178849    -0.0787608   -0.0294437   0.203626    -0.0952912    0.00155663   0.148308     0.101573    0.170896     -0.0471142   -0.123832    -0.0582356  -0.234476     0.0260743    0.176935     0.116723    -0.0822951    0.179092    -0.00598306   0.0375474
 -0.22878     -0.0295258   0.171855     0.0231962   -0.110588     0.0807342   -0.0430441   -0.120551    -0.0609042  -0.274232     0.00639967   0.0524656   -0.0234075   -0.103945   -0.118991     -0.0483513   -0.0845373    0.0313499  -0.106947     0.0349731   -0.177673    -0.189378     0.0830795    0.00596756  -0.00458444  -0.00654509
 -0.121491    -0.161504   -0.053396     0.0271879   -0.177036     0.185337    -0.0854643   -0.120814    -0.0864526   0.135918    -0.191082    -0.022951     0.0498538    0.0473725  -0.0605602    -0.353646    -0.0932811   -0.0217352   0.00981562   0.0301938    0.161058     0.111771    -0.0346786   -0.131643     0.0134144    0.0109487kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4194917267705593
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419511
[ Info: iteration 2, average log likelihood -1.419449
[ Info: iteration 3, average log likelihood -1.419402
[ Info: iteration 4, average log likelihood -1.419345
[ Info: iteration 5, average log likelihood -1.419269
[ Info: iteration 6, average log likelihood -1.419162
[ Info: iteration 7, average log likelihood -1.418993
[ Info: iteration 8, average log likelihood -1.418689
[ Info: iteration 9, average log likelihood -1.418133
[ Info: iteration 10, average log likelihood -1.417236
[ Info: iteration 11, average log likelihood -1.416143
[ Info: iteration 12, average log likelihood -1.415230
[ Info: iteration 13, average log likelihood -1.414703
[ Info: iteration 14, average log likelihood -1.414463
[ Info: iteration 15, average log likelihood -1.414364
[ Info: iteration 16, average log likelihood -1.414324
[ Info: iteration 17, average log likelihood -1.414307
[ Info: iteration 18, average log likelihood -1.414300
[ Info: iteration 19, average log likelihood -1.414297
[ Info: iteration 20, average log likelihood -1.414295
[ Info: iteration 21, average log likelihood -1.414294
[ Info: iteration 22, average log likelihood -1.414293
[ Info: iteration 23, average log likelihood -1.414293
[ Info: iteration 24, average log likelihood -1.414293
[ Info: iteration 25, average log likelihood -1.414292
[ Info: iteration 26, average log likelihood -1.414292
[ Info: iteration 27, average log likelihood -1.414292
[ Info: iteration 28, average log likelihood -1.414291
[ Info: iteration 29, average log likelihood -1.414291
[ Info: iteration 30, average log likelihood -1.414291
[ Info: iteration 31, average log likelihood -1.414291
[ Info: iteration 32, average log likelihood -1.414291
[ Info: iteration 33, average log likelihood -1.414290
[ Info: iteration 34, average log likelihood -1.414290
[ Info: iteration 35, average log likelihood -1.414290
[ Info: iteration 36, average log likelihood -1.414290
[ Info: iteration 37, average log likelihood -1.414290
[ Info: iteration 38, average log likelihood -1.414290
[ Info: iteration 39, average log likelihood -1.414290
[ Info: iteration 40, average log likelihood -1.414290
[ Info: iteration 41, average log likelihood -1.414290
[ Info: iteration 42, average log likelihood -1.414290
[ Info: iteration 43, average log likelihood -1.414289
[ Info: iteration 44, average log likelihood -1.414289
[ Info: iteration 45, average log likelihood -1.414289
[ Info: iteration 46, average log likelihood -1.414289
[ Info: iteration 47, average log likelihood -1.414289
[ Info: iteration 48, average log likelihood -1.414289
[ Info: iteration 49, average log likelihood -1.414289
[ Info: iteration 50, average log likelihood -1.414289
┌ Info: EM with 100000 data points 50 iterations avll -1.414289
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4195113092671747
│     -1.419448580109041
│      ⋮
└     -1.4142891975309317
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414305
[ Info: iteration 2, average log likelihood -1.414246
[ Info: iteration 3, average log likelihood -1.414197
[ Info: iteration 4, average log likelihood -1.414138
[ Info: iteration 5, average log likelihood -1.414064
[ Info: iteration 6, average log likelihood -1.413976
[ Info: iteration 7, average log likelihood -1.413878
[ Info: iteration 8, average log likelihood -1.413779
[ Info: iteration 9, average log likelihood -1.413688
[ Info: iteration 10, average log likelihood -1.413609
[ Info: iteration 11, average log likelihood -1.413543
[ Info: iteration 12, average log likelihood -1.413489
[ Info: iteration 13, average log likelihood -1.413445
[ Info: iteration 14, average log likelihood -1.413409
[ Info: iteration 15, average log likelihood -1.413380
[ Info: iteration 16, average log likelihood -1.413357
[ Info: iteration 17, average log likelihood -1.413337
[ Info: iteration 18, average log likelihood -1.413321
[ Info: iteration 19, average log likelihood -1.413306
[ Info: iteration 20, average log likelihood -1.413292
[ Info: iteration 21, average log likelihood -1.413280
[ Info: iteration 22, average log likelihood -1.413268
[ Info: iteration 23, average log likelihood -1.413257
[ Info: iteration 24, average log likelihood -1.413246
[ Info: iteration 25, average log likelihood -1.413236
[ Info: iteration 26, average log likelihood -1.413227
[ Info: iteration 27, average log likelihood -1.413218
[ Info: iteration 28, average log likelihood -1.413210
[ Info: iteration 29, average log likelihood -1.413202
[ Info: iteration 30, average log likelihood -1.413195
[ Info: iteration 31, average log likelihood -1.413189
[ Info: iteration 32, average log likelihood -1.413183
[ Info: iteration 33, average log likelihood -1.413178
[ Info: iteration 34, average log likelihood -1.413173
[ Info: iteration 35, average log likelihood -1.413169
[ Info: iteration 36, average log likelihood -1.413165
[ Info: iteration 37, average log likelihood -1.413162
[ Info: iteration 38, average log likelihood -1.413159
[ Info: iteration 39, average log likelihood -1.413156
[ Info: iteration 40, average log likelihood -1.413154
[ Info: iteration 41, average log likelihood -1.413151
[ Info: iteration 42, average log likelihood -1.413149
[ Info: iteration 43, average log likelihood -1.413147
[ Info: iteration 44, average log likelihood -1.413146
[ Info: iteration 45, average log likelihood -1.413144
[ Info: iteration 46, average log likelihood -1.413142
[ Info: iteration 47, average log likelihood -1.413141
[ Info: iteration 48, average log likelihood -1.413140
[ Info: iteration 49, average log likelihood -1.413138
[ Info: iteration 50, average log likelihood -1.413137
┌ Info: EM with 100000 data points 50 iterations avll -1.413137
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4143049467052489
│     -1.4142455928699496
│      ⋮
└     -1.4131369411775656
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413148
[ Info: iteration 2, average log likelihood -1.413099
[ Info: iteration 3, average log likelihood -1.413058
[ Info: iteration 4, average log likelihood -1.413009
[ Info: iteration 5, average log likelihood -1.412948
[ Info: iteration 6, average log likelihood -1.412871
[ Info: iteration 7, average log likelihood -1.412779
[ Info: iteration 8, average log likelihood -1.412677
[ Info: iteration 9, average log likelihood -1.412574
[ Info: iteration 10, average log likelihood -1.412477
[ Info: iteration 11, average log likelihood -1.412392
[ Info: iteration 12, average log likelihood -1.412319
[ Info: iteration 13, average log likelihood -1.412257
[ Info: iteration 14, average log likelihood -1.412204
[ Info: iteration 15, average log likelihood -1.412157
[ Info: iteration 16, average log likelihood -1.412115
[ Info: iteration 17, average log likelihood -1.412076
[ Info: iteration 18, average log likelihood -1.412039
[ Info: iteration 19, average log likelihood -1.412004
[ Info: iteration 20, average log likelihood -1.411971
[ Info: iteration 21, average log likelihood -1.411940
[ Info: iteration 22, average log likelihood -1.411909
[ Info: iteration 23, average log likelihood -1.411880
[ Info: iteration 24, average log likelihood -1.411852
[ Info: iteration 25, average log likelihood -1.411824
[ Info: iteration 26, average log likelihood -1.411798
[ Info: iteration 27, average log likelihood -1.411772
[ Info: iteration 28, average log likelihood -1.411747
[ Info: iteration 29, average log likelihood -1.411722
[ Info: iteration 30, average log likelihood -1.411699
[ Info: iteration 31, average log likelihood -1.411676
[ Info: iteration 32, average log likelihood -1.411654
[ Info: iteration 33, average log likelihood -1.411632
[ Info: iteration 34, average log likelihood -1.411612
[ Info: iteration 35, average log likelihood -1.411592
[ Info: iteration 36, average log likelihood -1.411573
[ Info: iteration 37, average log likelihood -1.411555
[ Info: iteration 38, average log likelihood -1.411538
[ Info: iteration 39, average log likelihood -1.411522
[ Info: iteration 40, average log likelihood -1.411507
[ Info: iteration 41, average log likelihood -1.411492
[ Info: iteration 42, average log likelihood -1.411478
[ Info: iteration 43, average log likelihood -1.411465
[ Info: iteration 44, average log likelihood -1.411453
[ Info: iteration 45, average log likelihood -1.411441
[ Info: iteration 46, average log likelihood -1.411430
[ Info: iteration 47, average log likelihood -1.411419
[ Info: iteration 48, average log likelihood -1.411409
[ Info: iteration 49, average log likelihood -1.411400
[ Info: iteration 50, average log likelihood -1.411391
┌ Info: EM with 100000 data points 50 iterations avll -1.411391
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4131483473243809
│     -1.4130986213532395
│      ⋮
└     -1.4113908733716751
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411392
[ Info: iteration 2, average log likelihood -1.411338
[ Info: iteration 3, average log likelihood -1.411292
[ Info: iteration 4, average log likelihood -1.411243
[ Info: iteration 5, average log likelihood -1.411187
[ Info: iteration 6, average log likelihood -1.411121
[ Info: iteration 7, average log likelihood -1.411045
[ Info: iteration 8, average log likelihood -1.410958
[ Info: iteration 9, average log likelihood -1.410865
[ Info: iteration 10, average log likelihood -1.410768
[ Info: iteration 11, average log likelihood -1.410672
[ Info: iteration 12, average log likelihood -1.410580
[ Info: iteration 13, average log likelihood -1.410494
[ Info: iteration 14, average log likelihood -1.410416
[ Info: iteration 15, average log likelihood -1.410346
[ Info: iteration 16, average log likelihood -1.410282
[ Info: iteration 17, average log likelihood -1.410225
[ Info: iteration 18, average log likelihood -1.410172
[ Info: iteration 19, average log likelihood -1.410125
[ Info: iteration 20, average log likelihood -1.410080
[ Info: iteration 21, average log likelihood -1.410039
[ Info: iteration 22, average log likelihood -1.410001
[ Info: iteration 23, average log likelihood -1.409965
[ Info: iteration 24, average log likelihood -1.409930
[ Info: iteration 25, average log likelihood -1.409897
[ Info: iteration 26, average log likelihood -1.409866
[ Info: iteration 27, average log likelihood -1.409836
[ Info: iteration 28, average log likelihood -1.409808
[ Info: iteration 29, average log likelihood -1.409781
[ Info: iteration 30, average log likelihood -1.409756
[ Info: iteration 31, average log likelihood -1.409732
[ Info: iteration 32, average log likelihood -1.409710
[ Info: iteration 33, average log likelihood -1.409689
[ Info: iteration 34, average log likelihood -1.409669
[ Info: iteration 35, average log likelihood -1.409651
[ Info: iteration 36, average log likelihood -1.409634
[ Info: iteration 37, average log likelihood -1.409618
[ Info: iteration 38, average log likelihood -1.409603
[ Info: iteration 39, average log likelihood -1.409590
[ Info: iteration 40, average log likelihood -1.409577
[ Info: iteration 41, average log likelihood -1.409564
[ Info: iteration 42, average log likelihood -1.409553
[ Info: iteration 43, average log likelihood -1.409542
[ Info: iteration 44, average log likelihood -1.409531
[ Info: iteration 45, average log likelihood -1.409521
[ Info: iteration 46, average log likelihood -1.409512
[ Info: iteration 47, average log likelihood -1.409503
[ Info: iteration 48, average log likelihood -1.409494
[ Info: iteration 49, average log likelihood -1.409485
[ Info: iteration 50, average log likelihood -1.409477
┌ Info: EM with 100000 data points 50 iterations avll -1.409477
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.411391939256856
│     -1.4113377595341987
│      ⋮
└     -1.4094770946909223
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409478
[ Info: iteration 2, average log likelihood -1.409401
[ Info: iteration 3, average log likelihood -1.409326
[ Info: iteration 4, average log likelihood -1.409235
[ Info: iteration 5, average log likelihood -1.409120
[ Info: iteration 6, average log likelihood -1.408976
[ Info: iteration 7, average log likelihood -1.408804
[ Info: iteration 8, average log likelihood -1.408612
[ Info: iteration 9, average log likelihood -1.408410
[ Info: iteration 10, average log likelihood -1.408208
[ Info: iteration 11, average log likelihood -1.408019
[ Info: iteration 12, average log likelihood -1.407848
[ Info: iteration 13, average log likelihood -1.407698
[ Info: iteration 14, average log likelihood -1.407569
[ Info: iteration 15, average log likelihood -1.407459
[ Info: iteration 16, average log likelihood -1.407365
[ Info: iteration 17, average log likelihood -1.407284
[ Info: iteration 18, average log likelihood -1.407213
[ Info: iteration 19, average log likelihood -1.407150
[ Info: iteration 20, average log likelihood -1.407093
[ Info: iteration 21, average log likelihood -1.407041
[ Info: iteration 22, average log likelihood -1.406993
[ Info: iteration 23, average log likelihood -1.406948
[ Info: iteration 24, average log likelihood -1.406907
[ Info: iteration 25, average log likelihood -1.406869
[ Info: iteration 26, average log likelihood -1.406834
[ Info: iteration 27, average log likelihood -1.406801
[ Info: iteration 28, average log likelihood -1.406772
[ Info: iteration 29, average log likelihood -1.406745
[ Info: iteration 30, average log likelihood -1.406720
[ Info: iteration 31, average log likelihood -1.406697
[ Info: iteration 32, average log likelihood -1.406676
[ Info: iteration 33, average log likelihood -1.406657
[ Info: iteration 34, average log likelihood -1.406639
[ Info: iteration 35, average log likelihood -1.406622
[ Info: iteration 36, average log likelihood -1.406607
[ Info: iteration 37, average log likelihood -1.406592
[ Info: iteration 38, average log likelihood -1.406579
[ Info: iteration 39, average log likelihood -1.406566
[ Info: iteration 40, average log likelihood -1.406554
[ Info: iteration 41, average log likelihood -1.406543
[ Info: iteration 42, average log likelihood -1.406532
[ Info: iteration 43, average log likelihood -1.406522
[ Info: iteration 44, average log likelihood -1.406512
[ Info: iteration 45, average log likelihood -1.406503
[ Info: iteration 46, average log likelihood -1.406494
[ Info: iteration 47, average log likelihood -1.406486
[ Info: iteration 48, average log likelihood -1.406478
[ Info: iteration 49, average log likelihood -1.406470
[ Info: iteration 50, average log likelihood -1.406462
┌ Info: EM with 100000 data points 50 iterations avll -1.406462
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4094777788051067
│     -1.4094011114019023
│      ⋮
└     -1.4064623570519066
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4194917267705593
│     -1.4195113092671747
│     -1.419448580109041
│     -1.419401661449928
│      ⋮
│     -1.406477558493361
│     -1.4064698019413837
└     -1.4064623570519066
32×26 Array{Float64,2}:
 -0.47655     0.0503486   0.66147     0.15352     -0.292576      0.229209    -0.109285    -0.332581     0.10605     -0.589873    1.12509    -0.464594     0.26092     -0.66685     -0.562281   -0.173051    -0.548966    -0.109082    -0.453256     0.245617   -0.455923    -0.0496888   0.0838016  -0.199648   -0.00298194  -0.397745
  0.0808639  -0.22527     0.0996411   1.01202      0.479596      0.00055892   0.0926027   -0.482246    -0.460332     0.106277    0.59146    -0.534795     0.273419     0.539705    -0.394235    0.304607     0.184281    -0.406796    -0.264419     0.405206    0.215151    -0.483732    0.263789    0.071877    0.470967    -0.392041
  0.0683445  -0.240365    0.104771    0.0875672   -0.124102     -0.0730104   -0.132745     0.0595739   -0.408341     0.065163   -0.454992   -0.242714    -0.472022     0.0349733   -0.900852    0.00988977  -0.640864     0.244385    -0.149513     0.778132    0.0713777   -0.0359681  -0.27967    -0.271282    0.325354     0.664386
 -0.518668    0.145662    0.62895     0.341287     0.0912381     0.308834    -0.541465    -0.165118     0.431915    -0.559861   -0.16554    -0.587135     0.00799173   0.590197    -0.44992    -0.206184     0.439164     0.0171918   -0.251867     0.442001   -0.326899    -0.404602   -0.279072   -0.143088   -0.218361     0.671959
 -0.0807671  -0.303579   -0.295361   -0.451335     0.237151      0.202446     0.0852009   -0.0769361    0.403362     0.0639824  -0.495309   -0.245098     0.257       -0.88183     -0.496278   -0.204438     0.13452     -0.314901     0.565623     0.496895    0.102297     0.856727   -0.144929   -0.67435    -0.184298    -0.0830022
 -0.606075   -0.212904    0.193238   -0.0667815    0.164532     -0.0674383    0.385883     0.0649479    0.0459639   -0.0268957  -0.360332   -0.104148    -0.115689     0.202454     0.167382    0.145933    -0.00170921   0.0395272    0.824506     0.425004   -0.436646     0.523071   -0.443301   -0.108214   -0.278219     0.252437
  0.437934    0.765239    0.0899973  -0.726329    -0.665445      0.208929     0.295293     0.209616     0.272018    -0.0711864  -0.580877    0.468392    -0.553031     0.0919895   -0.213735    0.186541     0.0401082   -0.254721     0.913155     0.0760162   0.36322     -0.038067   -0.0648073  -0.130876   -0.0698771    0.316065
 -0.332235    0.702146   -0.010554   -0.381541     0.307621      0.171188     0.168387     0.0897878   -0.578488     0.820682   -0.0527329   0.388078    -0.300681     0.022034    -0.0571665   0.0140264   -0.00833501  -0.632594     0.595297    -0.214595   -0.031073     0.0277096   0.527782    0.0957563   0.00761982   0.289543
 -0.862929   -0.530046   -0.0962155  -0.143947     0.537519      0.0935331    0.439188     0.362182     0.205449    -0.168822   -0.24311     0.105686     0.339023    -0.91565      0.149894   -0.48464      0.0502638    0.0210574   -0.398749    -0.589183   -0.0398588   -0.263361    0.254612   -0.492831   -0.413013     0.0313037
  0.171421   -0.255      -0.38088    -0.0658309   -0.0366578     0.387434     0.0173246   -0.0436015   -0.023979    -0.271577   -0.68339     0.701948     0.00255682   0.251853     0.731802    0.282589     0.40598      0.381603    -0.306725    -0.940247   -0.301689    -0.0375335   0.211606    0.335547   -0.300274     0.427822
 -0.148559    0.0756549  -0.0343409   0.472839     0.0770603     0.262844     0.0309051   -0.829012     0.116434     0.129541    0.264102    0.0329491   -0.125496     0.00351548   0.201544   -0.0876005    0.121274    -0.0461246    0.308246     0.0173154   0.079175    -0.205487    0.0957657  -0.0798888  -0.00619619  -0.156221
  0.146564   -0.0901357   0.0404651  -0.333683    -0.231905     -0.385302    -0.0433266    0.862692    -0.195122    -0.15676    -0.0175406  -0.0384209    0.0773609    0.120141    -0.116674    0.0123965   -0.157415    -0.00804471  -0.396418    -0.119383    0.0573331    0.15147    -0.103066    0.227288    0.0613225   -0.0234485
 -0.172635   -0.0288613  -0.0511771  -0.0222435    0.0668711    -0.00780383   0.533313    -0.525343     0.346019    -0.287111    0.0751862   0.465397     0.0812689   -0.771425     0.187392    0.625513    -0.920663     0.0348727    0.0390912   -0.135028   -0.730959    -0.463365    0.167458    0.494253    0.39169     -0.272308
  0.0911627  -0.0487084   0.370537    0.295053    -0.26668      -0.0295715    0.170256     0.233508    -0.210879    -0.259326    0.0557581   0.108732    -0.351528     0.923594     0.391886    0.468688    -0.45193      0.144925    -0.0585175   -0.0683172  -0.23473     -0.573028   -0.114473    0.945898   -0.00112495  -0.0869182
  0.83728     0.472959   -0.497252    0.312809    -0.490522     -0.193809    -0.32289      0.00341218  -0.553718    -0.175916    0.323308    0.147741    -0.0280857    0.260776     0.0623829  -0.113691    -0.22637      0.379977    -0.0171694   -0.286686    0.170154    -0.242808   -0.430102    0.0459466   0.0321731   -0.622968
  0.390652   -0.269579   -0.400946   -0.274101    -0.0932565    -0.225479     0.170205     0.497264    -0.7241       0.500612   -0.225422    0.304536     0.269117     0.237619    -0.0124641   0.498593     0.042989    -0.185167     0.368409    -0.249487   -0.00977118   0.54926    -0.653217    0.399483    0.180594    -0.791258
 -0.176777   -0.741449    0.148576   -0.288641    -0.27302      -0.323063    -0.162174     0.183008     0.479488     0.409565   -0.266246   -0.0694936    0.919686     0.0769562    0.0919963   0.00695627   0.39331      0.168502    -0.642782    -0.245609    0.086902     0.211688    0.0751467   0.36444    -0.137526    -0.339821
 -0.215684    0.332226    0.015175   -0.217917    -0.158089     -0.0137449   -0.356799     0.441031    -0.0441928    0.349838    0.269646   -0.021892     0.514981     0.00345407  -0.493613   -0.486723     0.200639    -0.100547    -0.414107    -0.61401     0.137292     0.646569    0.184184   -0.300833    0.0945943    0.277664
  0.302518   -0.353254    0.537259    0.373188    -0.104935     -0.622086     0.0911385    0.1658       0.412856    -0.463801   -0.582365    0.120274     0.529347     0.211453    -0.209937    0.357394    -0.299923    -0.279854    -0.21119     -0.0844056  -0.289156    -0.139915   -0.630497   -0.355301    0.577371     0.272358
 -0.0929497   0.345418    0.49551     0.73852     -0.449385     -0.304624    -0.201647    -0.243739     0.288047     1.20028    -0.37871    -0.458821     0.164951     0.277683     0.321722    0.0431227   -0.257708    -0.144799    -0.162095    -0.411833    0.0515488   -0.0684333   0.0869852  -0.010568    0.493378    -0.651497
  0.350019   -0.262378   -0.326808   -0.449541     0.431975      0.384773     0.00689716  -0.243894    -0.431871    -1.07768     0.200961    0.457206     0.187914     0.0995637   -0.369716   -0.286125     0.287956     0.117834    -0.0765866    0.432983    0.130303    -0.0310692  -0.316328   -0.0634104  -0.803802     0.337898
  0.252253   -0.241592   -0.618907   -0.76423      0.159334      0.544198    -0.235554     0.496177    -0.00493258  -0.538724    0.418671   -0.496049     0.265677     0.149012    -0.0571737  -0.101138    -0.258729     0.0689031   -0.816692     0.161793   -0.778083    -0.189911   -0.0592721   0.15777     0.520485     0.172785
 -0.232403    0.255196    0.310504    0.588529    -0.0967207    -0.262103     0.0442207   -0.406687    -0.0910893    0.204102   -0.286028    0.457019     0.0508319   -0.0793935   -0.0915841  -0.276248     0.223785     0.11969      0.514713    -0.0857222   0.802112     0.025757   -0.260161   -0.0686615  -0.805753    -0.37144
  0.227545    0.0914426   0.349705   -0.201007    -0.162059     -0.366474     0.0338752    1.13513     -0.250329    -0.548887   -0.445365    0.397654     0.346934    -0.136476    -0.0867441   0.112668    -0.0536886    0.121544    -0.453868    -0.288576    0.415021    -0.0851259  -0.135578    0.233919   -0.565348     0.0610441
 -0.269914   -0.0481288  -0.330437    0.0744545   -0.205473     -0.0889639    0.201912     0.234676    -0.187733     0.298661    0.471114   -0.604913    -0.573982     0.147527     0.269158   -0.413682     0.389022     0.0669376    0.15089      0.0312757   0.604957     0.158824    0.259781    0.416329   -0.14915     -0.410502
 -0.363276    0.0714049  -0.787751    0.0644685   -0.0988254     0.886704    -0.0929277   -0.839344    -0.322202     0.396268    0.364185   -0.255179    -0.662404     0.0946334    0.250956   -0.391922     0.228417     0.107758     0.162404     0.337709   -0.0675365    0.09765     0.0150433   0.0683756   0.0623626   -0.00458905
  0.145244   -0.56878    -0.622522    0.195816     0.337988     -0.118705    -0.540098    -0.558258     0.411559     0.127533    0.602694   -0.0320343    0.149845     0.00205465   0.443436   -0.123892     0.219203     0.278546    -0.176961     0.114695   -0.239892     0.0769959   0.0040774  -0.552134    0.388016    -0.429528
 -0.12032     0.270269    0.136632    0.00374896  -0.000512835   0.14026     -0.0398828   -0.665077     0.885579    -0.353537    0.254113    0.186901    -0.314365    -0.0369125    0.310013   -0.228069    -0.0574934    0.0744148    0.00538027   0.122334   -0.0337457   -0.382971    0.654058   -0.352132   -0.100353     0.544645
 -0.148938    0.132269    0.147633   -0.159757     0.173161     -0.0168761    0.0569487    0.0186853   -0.244914     0.0743048  -0.246008    0.212479    -0.0348589   -0.309514    -0.377376   -0.0149663   -0.38309     -0.103451     0.0379681    0.0413336   0.0642274    0.0965938  -0.0387248  -0.110157   -0.170658     0.225752
  0.0954061  -0.122083   -0.119035   -0.243801    -0.114885     -0.0148904    0.2537      -0.0165789    0.517535     0.27443    -0.118893    0.00444628  -0.156145    -0.0815613    0.158915    0.110225     0.204316    -0.399758     0.334194     0.065603   -0.05947     -0.043752    0.287683   -0.0780505   0.297487     0.031696
 -0.192174   -0.306013   -0.032857    0.166005     0.073622     -0.0206951   -0.0484933    0.0221383    0.0326848   -0.131471    0.0626313  -0.114181     0.157161     0.0952233    0.194301   -0.10174      0.0737505    0.251557    -0.163371    -0.0760681  -0.0813167    0.151944   -0.0381355   0.0709586  -0.190929    -0.167481
  0.287372    0.345288   -0.169543    0.0794751   -0.167399      0.0738938   -0.149529    -0.041199    -0.163196     0.0639673   0.118224    0.0159662   -0.172896     0.2709      -0.0730161   0.0137293    0.0753956   -0.0367517   -0.0450062    0.0234744   0.0689893   -0.253226   -0.0670238   0.0324946   0.214969     0.00605526[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406455
[ Info: iteration 2, average log likelihood -1.406448
[ Info: iteration 3, average log likelihood -1.406442
[ Info: iteration 4, average log likelihood -1.406435
[ Info: iteration 5, average log likelihood -1.406429
[ Info: iteration 6, average log likelihood -1.406423
[ Info: iteration 7, average log likelihood -1.406418
[ Info: iteration 8, average log likelihood -1.406412
[ Info: iteration 9, average log likelihood -1.406407
[ Info: iteration 10, average log likelihood -1.406402
┌ Info: EM with 100000 data points 10 iterations avll -1.406402
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.116719e+05
      1       7.016963e+05      -2.099757e+05 |       32
      2       6.870115e+05      -1.468478e+04 |       32
      3       6.812910e+05      -5.720545e+03 |       32
      4       6.783791e+05      -2.911868e+03 |       32
      5       6.765852e+05      -1.793953e+03 |       32
      6       6.754246e+05      -1.160547e+03 |       32
      7       6.745960e+05      -8.286154e+02 |       32
      8       6.739009e+05      -6.951099e+02 |       32
      9       6.733250e+05      -5.758909e+02 |       32
     10       6.728391e+05      -4.859037e+02 |       32
     11       6.724271e+05      -4.120322e+02 |       32
     12       6.720530e+05      -3.741069e+02 |       32
     13       6.717136e+05      -3.393449e+02 |       32
     14       6.714166e+05      -2.970472e+02 |       32
     15       6.711347e+05      -2.818885e+02 |       32
     16       6.708453e+05      -2.894180e+02 |       32
     17       6.705710e+05      -2.742759e+02 |       32
     18       6.703075e+05      -2.634639e+02 |       32
     19       6.700729e+05      -2.346277e+02 |       32
     20       6.698595e+05      -2.134012e+02 |       32
     21       6.696506e+05      -2.088545e+02 |       32
     22       6.694657e+05      -1.849085e+02 |       32
     23       6.692874e+05      -1.783206e+02 |       32
     24       6.691274e+05      -1.600378e+02 |       32
     25       6.689808e+05      -1.465697e+02 |       32
     26       6.688408e+05      -1.400164e+02 |       32
     27       6.686945e+05      -1.462320e+02 |       32
     28       6.685525e+05      -1.420153e+02 |       32
     29       6.684094e+05      -1.431527e+02 |       32
     30       6.682595e+05      -1.499181e+02 |       32
     31       6.681235e+05      -1.359280e+02 |       32
     32       6.679929e+05      -1.306155e+02 |       32
     33       6.678651e+05      -1.278466e+02 |       32
     34       6.677442e+05      -1.208625e+02 |       32
     35       6.676325e+05      -1.117423e+02 |       32
     36       6.675355e+05      -9.694697e+01 |       32
     37       6.674499e+05      -8.562165e+01 |       32
     38       6.673782e+05      -7.171719e+01 |       32
     39       6.673064e+05      -7.174290e+01 |       32
     40       6.672363e+05      -7.009467e+01 |       32
     41       6.671722e+05      -6.409385e+01 |       32
     42       6.671177e+05      -5.459577e+01 |       32
     43       6.670710e+05      -4.666210e+01 |       32
     44       6.670278e+05      -4.318928e+01 |       32
     45       6.669917e+05      -3.610154e+01 |       32
     46       6.669630e+05      -2.865635e+01 |       32
     47       6.669393e+05      -2.374579e+01 |       32
     48       6.669188e+05      -2.052550e+01 |       32
     49       6.668992e+05      -1.960960e+01 |       32
     50       6.668787e+05      -2.041678e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 666878.7430970182)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417586
[ Info: iteration 2, average log likelihood -1.412744
[ Info: iteration 3, average log likelihood -1.411466
[ Info: iteration 4, average log likelihood -1.410536
[ Info: iteration 5, average log likelihood -1.409571
[ Info: iteration 6, average log likelihood -1.408663
[ Info: iteration 7, average log likelihood -1.408008
[ Info: iteration 8, average log likelihood -1.407623
[ Info: iteration 9, average log likelihood -1.407404
[ Info: iteration 10, average log likelihood -1.407265
[ Info: iteration 11, average log likelihood -1.407164
[ Info: iteration 12, average log likelihood -1.407083
[ Info: iteration 13, average log likelihood -1.407015
[ Info: iteration 14, average log likelihood -1.406955
[ Info: iteration 15, average log likelihood -1.406903
[ Info: iteration 16, average log likelihood -1.406856
[ Info: iteration 17, average log likelihood -1.406813
[ Info: iteration 18, average log likelihood -1.406775
[ Info: iteration 19, average log likelihood -1.406740
[ Info: iteration 20, average log likelihood -1.406708
[ Info: iteration 21, average log likelihood -1.406678
[ Info: iteration 22, average log likelihood -1.406651
[ Info: iteration 23, average log likelihood -1.406626
[ Info: iteration 24, average log likelihood -1.406603
[ Info: iteration 25, average log likelihood -1.406582
[ Info: iteration 26, average log likelihood -1.406562
[ Info: iteration 27, average log likelihood -1.406543
[ Info: iteration 28, average log likelihood -1.406525
[ Info: iteration 29, average log likelihood -1.406509
[ Info: iteration 30, average log likelihood -1.406494
[ Info: iteration 31, average log likelihood -1.406479
[ Info: iteration 32, average log likelihood -1.406466
[ Info: iteration 33, average log likelihood -1.406453
[ Info: iteration 34, average log likelihood -1.406441
[ Info: iteration 35, average log likelihood -1.406429
[ Info: iteration 36, average log likelihood -1.406418
[ Info: iteration 37, average log likelihood -1.406408
[ Info: iteration 38, average log likelihood -1.406398
[ Info: iteration 39, average log likelihood -1.406389
[ Info: iteration 40, average log likelihood -1.406380
[ Info: iteration 41, average log likelihood -1.406372
[ Info: iteration 42, average log likelihood -1.406364
[ Info: iteration 43, average log likelihood -1.406356
[ Info: iteration 44, average log likelihood -1.406348
[ Info: iteration 45, average log likelihood -1.406341
[ Info: iteration 46, average log likelihood -1.406334
[ Info: iteration 47, average log likelihood -1.406327
[ Info: iteration 48, average log likelihood -1.406321
[ Info: iteration 49, average log likelihood -1.406314
[ Info: iteration 50, average log likelihood -1.406308
┌ Info: EM with 100000 data points 50 iterations avll -1.406308
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.234059   -0.248989    0.163115     0.0490127     0.0152089    0.0178041   -0.0175552   0.0191696  -0.38512     0.0869058  -0.514079   -0.26936     -0.49352    -0.0316595   -0.785828    0.0689475   -0.656288     0.279728   -0.00370543   0.791449    -0.022903      0.00726884  -0.344061   -0.283236     0.128693     0.67058
  0.14915    -0.242548   -0.42143     -0.322869     -0.0132718    0.0988865   -0.527175    0.138284    0.222789   -0.130575    0.254378    0.112624     0.615542   -0.145877     0.056829   -0.110149     0.120239     0.191379   -1.12537     -0.226269     0.0199858    -0.0169126    0.18348     0.159303    -0.100568    -0.27463
 -0.364986   -0.323495    0.0139013   -0.236404      0.541894     0.0625894    0.709673    0.232506    0.267046    0.234273   -0.433351    0.0761072   -0.0120959  -0.650631    -0.207605   -0.174612     0.15544     -0.954295    0.515081     0.24797      0.252897      0.280667     0.394768   -0.370371    -0.147373     0.436763
  0.0384362   0.400906   -0.0242054   -0.927858     -0.439831     0.0251254    0.12545     0.380275    0.178543   -0.0742353  -0.939597    0.697793    -0.0768004  -0.287122    -0.0259202  -0.287552    -0.112853     0.323141    0.364064    -0.442717    -0.0678289     0.534861    -0.0148687  -0.120662    -0.44076      0.48232
 -0.0885605  -0.192504    0.443813    -0.0853592    -0.597032    -0.193387     0.0964079   0.761459   -0.214372   -0.0846152   0.0915577  -0.440473     0.48749     0.034359    -0.577263   -0.303505    -0.136607    -0.281645   -1.13059     -0.245262    -0.296772      0.322523    -0.0519655   0.31147      0.285158     0.0369263
  0.0389667  -0.359054   -0.298429    -0.676306      0.454472     0.470442     0.203994   -0.131318   -0.35663    -1.21533     0.138014    0.37743      0.0740424   0.0359474   -0.419623   -0.23637      0.227923     0.0675318  -0.0494245    0.437151    -0.113179     -0.136282    -0.314181    0.0571672   -0.669198     0.730515
 -0.58394     0.530211    0.323435    -0.0740745     0.0389987    0.262445     0.274804    0.420218   -0.502863    0.592941    0.164195    0.446482    -0.110985    0.193993     0.100927    0.372561     0.137404    -0.364399    0.449928    -0.581895    -0.174117      0.213226     0.520249    0.255436    -0.160036     0.211351
 -0.207172   -0.446593    0.0740655    0.0462746     0.206069    -0.133801     0.235484    0.249704    0.171348   -0.500349   -0.365505    0.436634     0.264372   -0.08117      0.544759    0.16441      0.164269     0.461048   -0.539711    -0.598453    -0.187576     -0.419485     0.244586    0.210445    -0.356053     0.141543
 -0.169702   -0.0900483   0.406029     0.146749      0.124929    -0.213407    -0.0690026   0.160792   -0.0940843  -0.152537   -0.295847    0.216062     0.28955    -0.00799418  -0.221291    0.034398    -0.185682     0.198037   -0.184363    -0.0488198    0.118315      0.0696929   -0.251878    0.021653    -0.312943     0.123871
  0.0691226   0.0882913  -0.187231    -0.0789858    -0.0578085    0.0975188    0.0238907  -0.0628159   0.0368734   0.109038    0.049555   -0.041236    -0.136443    0.0473479    0.0422265  -0.0295427    0.0614558   -0.111668    0.0573238    0.00161889  -0.0666363    -0.0556824    0.0847009  -0.0134747    0.152911     0.000474594
 -0.464488    0.400608    0.488311    -0.195324      0.00715935   0.046784     0.0574308  -0.0623176   0.236606   -0.454567    0.848354   -0.212692     0.02425    -1.13947     -0.866287   -0.258716    -0.491838    -0.241985   -0.00226852   0.14706     -0.0103733    -0.0761378    0.298046   -0.158718    -0.258988    -0.457141
 -0.284895   -0.290491   -0.165477    -0.240575      0.515998     0.22955     -0.172248   -0.158427    0.326949    0.0873754   0.513486   -0.310452     0.337419   -0.182155     0.0823163   0.0365354    0.1167      -0.142658   -0.358625    -0.088426    -0.802114      0.727918    -0.0787276  -0.914718     0.438995     0.241187
  0.115837   -0.485395   -0.359645    -0.0924916    -0.0439248   -0.0497547   -0.304834   -0.376708    0.381157    0.296397   -0.7829     -0.431141     0.512833   -0.714322    -0.507325   -0.305538     0.126511     0.0625517   0.491255     0.502533     0.000819086   0.609598    -0.328509   -0.485473     0.00814789  -0.574107
 -0.0348699   0.166243   -0.00262586   0.0540018    -0.0114323   -0.0789781   -0.516201    0.158195   -0.151813    0.123996    0.308707   -0.12309     -0.0288116   0.354998    -0.31324    -0.679635     0.408529     0.134497   -0.0567387   -0.100769     0.826656      0.334994     0.0608807  -0.382676    -0.287136     0.165102
  0.495322   -0.0625509   0.404771     0.00468148   -0.0790223   -0.364131     0.136279    0.473186    0.106432   -0.369098   -0.459611    0.257072     0.374376    0.193939    -0.257115    0.526439    -0.348588    -0.407637   -0.239269    -0.173016    -0.317815     -0.373773    -0.345322   -0.141413     0.530419     0.360871
 -0.550642    0.460602    0.680091     0.445636      0.0756973    0.34131     -0.888435   -0.260431    0.417055   -0.720213    0.0268256  -0.646439    -0.0585035   0.536157    -0.465621   -0.29733      0.634262     0.102944   -0.271907     0.48724     -0.444418     -0.551362    -0.282582   -0.228479    -0.204466     0.628532
 -0.511083    0.37336     0.409998     0.721313     -0.211028    -0.0124607    0.201572   -0.219686    0.128248    0.563637   -0.44064     0.0534028    0.466641   -0.209988     0.245348   -0.52623      0.34116     -0.482179    0.182391    -0.622576     0.733518     -0.268804    -0.213711   -0.265979    -0.544621    -0.488562
  0.0294646  -0.26018     0.0328168    1.00117       0.345818     0.0135258   -0.0014431  -0.534649   -0.392191    0.166186    0.644545   -0.477423     0.273071    0.458016    -0.195672    0.205683     0.142538    -0.266487   -0.304065     0.27739      0.0856313    -0.481454     0.2063      0.0879709    0.485128    -0.535972
 -0.515278   -0.797715    0.209845    -0.12321      -0.0647001   -0.301735     0.249464    0.0335768   0.570219    0.128412   -0.0946362  -0.298014     0.363627    0.274967     0.345298    0.138412     0.237287     0.0567399   0.12157      0.0528148   -0.250028      0.209531    -0.0974264   0.0828623   -0.101183    -0.154074
 -0.016592    0.100133    0.177812     0.337683     -0.119344     0.210803     0.0204179  -0.838095    0.821201   -0.334849    0.332841    0.115779    -0.0820784  -0.134175     0.170251   -0.382202    -0.192574     0.163039    0.0781338    0.330023    -0.256117     -0.398246     0.574236   -0.420669     0.0801573    0.439413
 -0.219774   -0.0350046  -0.0229426   -0.0255239     0.0471877    0.0169906    0.557973   -0.559287    0.38169    -0.183502    0.131023    0.430111    -0.0154558  -0.64187      0.250576    0.616583    -1.03495     -0.0103754   0.109033    -0.160018    -0.818005     -0.438626     0.141023    0.586073     0.542124    -0.271394
  0.073793    0.321073    0.42735      0.74845      -0.455053    -0.561385    -0.323041   -0.249294    0.338383    0.90737    -0.302719   -0.310677    -0.0310455   0.450582     0.501334    0.191737    -0.26696      0.0920868  -0.045611    -0.336125    -0.0910899     0.149466     0.0311992   0.00103935   0.694229    -0.539667
  0.592953   -0.137833   -0.483242    -0.214098     -0.135392     0.270566    -0.242813    0.358546   -0.192506   -0.47012     0.487848   -0.325907    -0.307663    0.646459     0.256666   -0.0272705   -0.185608     0.268852   -0.309681     0.0317541   -0.567468     -0.19577     -0.079999    0.291904     0.625258     0.0144894
 -0.450924    0.072343   -0.818896    -0.0947152    -0.0643698    0.542241     0.0202372  -0.660868   -0.176373    0.557632    0.457882   -0.408234    -0.686133    0.0144731    0.362083   -0.48481      0.292613     0.0946186   0.176369     0.260335     0.0366304     0.188787     0.161544    0.0971566    0.0672226   -0.0493694
  0.0239133  -0.203227   -0.105768     0.53315       0.0695925    0.432198     0.138703   -0.423349   -0.147084   -0.369222   -0.305253    0.276395    -0.487709    0.780406     0.725369    0.304459     0.0121617    0.127048    0.285881     0.0926811   -0.131201     -0.366165    -0.375606    0.61873     -0.615952    -0.162015
  0.0131713   0.135553   -0.177211    -0.000830294   0.0931285    0.083701    -0.148336   -0.139738   -0.075628    0.141682    0.182455    0.0803746   -0.256128   -0.0182551    0.0526175  -0.0599107    0.00546183  -0.0794928   0.222183     0.0692265    0.0987358     0.123565     0.12483    -0.0697976    0.0725044   -0.0450331
 -0.11856     0.0790705   0.015378     0.221438     -0.469851    -0.0279572    0.187752    0.182333   -0.203665    0.256868   -0.141516   -0.00785471  -0.410394    0.0563691    0.0682138  -0.00297999   0.0232093    0.0524313   0.148892     0.168423     0.753345     -0.266702     0.461087    0.914363    -0.268452    -0.251664
  0.339931   -0.199814   -0.36722     -0.255646     -0.0682592   -0.373361     0.11971     0.684132   -0.670832    0.312627   -0.256418    0.172357     0.29882     0.163022     0.0426892   0.234851     0.135229    -0.0344965   0.0751161   -0.364334     0.187928      0.50355     -0.597192    0.522766    -0.0352976   -0.778016
  0.5874      0.478271    0.0536281    0.252253     -1.06593     -0.616725    -0.214387    0.157666   -0.588704   -0.0630723   0.187181    0.104636    -0.0456037   0.878431    -0.24733    -0.180574    -0.71253      0.952651    0.0836986   -0.31337      0.456514     -0.910891    -0.535082    0.480451    -0.075577    -0.226267
  0.582995    0.0122779  -0.350187    -0.353651     -0.150167    -0.0813526   -0.0389342  -0.142865    0.703109   -0.0616852   0.203308    0.300165    -0.554351   -0.0554995    0.543805    0.594334     0.536688    -0.0330773   0.902275    -0.0540176    0.471501     -0.395587    -0.0852299  -0.594831    -0.0629462   -0.210082
  0.201381    0.249917   -0.470635     0.264227      0.113399     0.00395171  -0.0401889  -0.1578     -0.621973   -0.257723    0.225312    0.254874    -0.0455652  -0.292484    -0.0195999  -0.0881783   -0.114537     0.149961    0.427809     0.0572649    0.0138976     0.244509    -0.497186   -0.363629    -0.387274    -0.527652
  0.31258     0.757921    0.236966    -0.460791     -0.411315     0.0694037    0.371516    0.112025   -0.0648266   0.302435   -0.429332    0.137635    -0.359782    0.50104     -0.595301    0.360903    -0.153825    -0.631318    0.835957     0.450534     0.311397     -0.176484    -0.187545    0.0981394    0.156089     0.301006[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406302
[ Info: iteration 2, average log likelihood -1.406296
[ Info: iteration 3, average log likelihood -1.406290
[ Info: iteration 4, average log likelihood -1.406284
[ Info: iteration 5, average log likelihood -1.406278
[ Info: iteration 6, average log likelihood -1.406273
[ Info: iteration 7, average log likelihood -1.406267
[ Info: iteration 8, average log likelihood -1.406262
[ Info: iteration 9, average log likelihood -1.406257
[ Info: iteration 10, average log likelihood -1.406252
┌ Info: EM with 100000 data points 10 iterations avll -1.406252
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
