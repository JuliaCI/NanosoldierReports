Julia Version 1.5.0-DEV.247
Commit 1297b518e3 (2020-02-07 18:46 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed CMakeWrapper ─────── v0.2.3
  Installed GaussianMixtures ─── v0.3.0
  Installed Arpack_jll ───────── v3.5.0+2
  Installed Distances ────────── v0.8.2
  Installed NearestNeighbors ─── v0.4.4
  Installed QuadGK ───────────── v2.3.1
  Installed BinaryProvider ───── v0.5.8
  Installed Distributions ────── v0.22.4
  Installed SortingAlgorithms ── v0.3.1
  Installed LegacyStrings ────── v0.4.1
  Installed Compat ───────────── v2.2.0
  Installed Parameters ───────── v0.12.0
  Installed FileIO ───────────── v1.2.1
  Installed HDF5 ─────────────── v0.12.5
  Installed DataStructures ───── v0.17.9
  Installed StatsBase ────────── v0.32.0
  Installed OrderedCollections ─ v1.1.0
  Installed StaticArrays ─────── v0.12.1
  Installed DataAPI ──────────── v1.1.0
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed ScikitLearnBase ──── v0.5.0
  Installed FillArrays ───────── v0.8.4
  Installed Arpack ───────────── v0.4.0
  Installed StatsFuns ────────── v0.9.3
  Installed JLD ──────────────── v0.9.2
  Installed BinDeps ──────────── v1.0.0
  Installed CMake ────────────── v1.1.2
  Installed Rmath ────────────── v0.6.0
  Installed Missings ─────────── v0.4.3
  Installed URIParser ────────── v0.4.0
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed Blosc ────────────── v0.5.1
  Installed SpecialFunctions ─── v0.9.0
  Installed PDMats ───────────── v0.9.11
  Installed Clustering ───────── v0.13.3
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                         #                                                                          2.4%####                                                                       6.8%########                                                                  12.2%##############                                                            20.7%######################                                                    31.9%##################################                                        48.1%################################################                          67.1%#######################################################                   77.5%######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_06y10r/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -2.551653139025914e6, [97282.95558216753, 2717.044417832486], [-3608.3740909460976 -2348.1144439205627 -3964.581561984802; 3526.252395804585 2150.7672352793093 3633.073063283909], [[93776.52993873887 -2035.6421220656935 -3698.2160694662825; -2035.6421220656935 96905.42633047598 -2377.403117865427; -3698.2160694662825 -2377.403117865427 95103.49057191114], [6176.692187601465 2114.0790746446437 4152.2406034657915; 2114.0790746446437 2864.213575817126 2646.843885295424; 4152.240603465791 2646.843885295424 5523.247503409762]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.890956e+03
      1       1.525052e+03      -3.659039e+02 |        8
      2       1.410364e+03      -1.146886e+02 |        2
      3       1.389201e+03      -2.116298e+01 |        3
      4       1.369001e+03      -2.019925e+01 |        2
      5       1.341407e+03      -2.759440e+01 |        2
      6       1.287120e+03      -5.428723e+01 |        0
      7       1.287120e+03       0.000000e+00 |        0
K-means converged with 7 iterations (objv = 1287.1196402889955)
┌ Info: K-means with 272 data points using 7 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.064833
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.684386
[ Info: iteration 2, lowerbound -3.572160
[ Info: iteration 3, lowerbound -3.448444
[ Info: iteration 4, lowerbound -3.309413
[ Info: iteration 5, lowerbound -3.174101
[ Info: iteration 6, lowerbound -3.054410
[ Info: dropping number of Gaussions to 6
[ Info: iteration 7, lowerbound -2.925301
[ Info: iteration 8, lowerbound -2.784282
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.646610
[ Info: iteration 10, lowerbound -2.525850
[ Info: iteration 11, lowerbound -2.443999
[ Info: dropping number of Gaussions to 4
[ Info: iteration 12, lowerbound -2.388905
[ Info: iteration 13, lowerbound -2.353126
[ Info: dropping number of Gaussions to 3
[ Info: iteration 14, lowerbound -2.324776
[ Info: iteration 15, lowerbound -2.308519
[ Info: dropping number of Gaussions to 2
[ Info: iteration 16, lowerbound -2.303127
[ Info: iteration 17, lowerbound -2.299264
[ Info: iteration 18, lowerbound -2.299258
[ Info: iteration 19, lowerbound -2.299255
[ Info: iteration 20, lowerbound -2.299254
[ Info: iteration 21, lowerbound -2.299253
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sun Feb  9 00:13:42 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sun Feb  9 00:13:50 2020: K-means with 272 data points using 7 iterations
11.3 data points per parameter
, Sun Feb  9 00:13:52 2020: EM with 272 data points 0 iterations avll -2.064833
5.8 data points per parameter
, Sun Feb  9 00:13:54 2020: GMM converted to Variational GMM
, Sun Feb  9 00:14:03 2020: iteration 1, lowerbound -3.684386
, Sun Feb  9 00:14:03 2020: iteration 2, lowerbound -3.572160
, Sun Feb  9 00:14:03 2020: iteration 3, lowerbound -3.448444
, Sun Feb  9 00:14:03 2020: iteration 4, lowerbound -3.309413
, Sun Feb  9 00:14:03 2020: iteration 5, lowerbound -3.174101
, Sun Feb  9 00:14:03 2020: iteration 6, lowerbound -3.054410
, Sun Feb  9 00:14:04 2020: dropping number of Gaussions to 6
, Sun Feb  9 00:14:04 2020: iteration 7, lowerbound -2.925301
, Sun Feb  9 00:14:04 2020: iteration 8, lowerbound -2.784282
, Sun Feb  9 00:14:04 2020: dropping number of Gaussions to 5
, Sun Feb  9 00:14:04 2020: iteration 9, lowerbound -2.646610
, Sun Feb  9 00:14:04 2020: iteration 10, lowerbound -2.525850
, Sun Feb  9 00:14:04 2020: iteration 11, lowerbound -2.443999
, Sun Feb  9 00:14:04 2020: dropping number of Gaussions to 4
, Sun Feb  9 00:14:04 2020: iteration 12, lowerbound -2.388905
, Sun Feb  9 00:14:04 2020: iteration 13, lowerbound -2.353126
, Sun Feb  9 00:14:04 2020: dropping number of Gaussions to 3
, Sun Feb  9 00:14:04 2020: iteration 14, lowerbound -2.324776
, Sun Feb  9 00:14:04 2020: iteration 15, lowerbound -2.308519
, Sun Feb  9 00:14:04 2020: dropping number of Gaussions to 2
, Sun Feb  9 00:14:04 2020: iteration 16, lowerbound -2.303127
, Sun Feb  9 00:14:04 2020: iteration 17, lowerbound -2.299264
, Sun Feb  9 00:14:04 2020: iteration 18, lowerbound -2.299258
, Sun Feb  9 00:14:04 2020: iteration 19, lowerbound -2.299255
, Sun Feb  9 00:14:04 2020: iteration 20, lowerbound -2.299254
, Sun Feb  9 00:14:04 2020: iteration 21, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 22, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 23, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 24, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 25, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 26, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 27, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 28, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 29, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 30, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 31, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 32, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 33, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 34, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 35, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 36, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 37, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 38, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 39, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 40, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 41, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 42, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 43, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 44, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 45, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 46, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 47, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 48, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 49, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: iteration 50, lowerbound -2.299253
, Sun Feb  9 00:14:04 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601382, 95.95490777398619]
β = [178.04509222601382, 95.95490777398619]
m = [4.25030073326991 79.28686694436183; 2.000229257775371 53.8519871724613]
ν = [180.04509222601382, 97.95490777398619]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.1840415554748482 -0.007644049042327429; 0.0 0.008581705166333359], [0.3758763611948371 -0.008953123827346005; 0.0 0.01274866477740947]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -1.0010625673578724
avll from llpg:  -1.001062567357873
avll direct:     -1.001062567357873
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9794624557191199
avll from llpg:  -0.9794624557191202
avll direct:     -0.9794624557191202
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
 -0.0157427   0.0753273    0.138441     0.0204707   0.0174883    0.0625067    0.0816156    0.0696833    0.110526    -0.0739544    0.0290468    0.0645321    -0.0473731    0.0264711   -0.0968307     0.0828002   -0.145042    -0.097027   -0.214726    -0.0138971   -0.171559     -0.0987104     0.0970321   -0.0807569   0.010258    -0.0320453
 -0.160666    0.21259      0.0366103   -0.0925903   0.0213229   -0.116231     0.0243719   -0.181273    -0.0682558   -0.0460121   -0.0482506    0.100322     -0.0901282    0.0395773    0.0490976     0.154253     0.118299    -0.0888137  -0.0259046   -0.00558571   0.0117469     0.0711324    -0.0766641   -0.108005   -0.0397586   -0.0310138
  0.0575034  -0.0404312   -0.0507368    0.086627    0.0757678    0.0542891    0.0167993   -0.183932     0.0391606    0.052163     0.00687221  -0.0322771     0.0361946    0.0727981   -7.60725e-5    0.0375296    0.00138142   0.175642    0.0776307   -0.171737     0.0424946    -0.00892275   -0.0212341   -0.10131    -0.063369    -0.0327418
 -0.164872    0.0270361    0.0857651   -0.0243506   0.0907353    0.0353821   -0.0997619    0.00437729  -0.118128    -0.0553656   -0.221537     0.000363698   0.0572676    0.107658     0.0520612     0.121773    -0.0575774    0.0124316  -0.0638446   -0.0748652   -0.0572662     0.139362     -0.10484      0.10596    -0.0871562    0.0818281
 -0.0332697  -0.0288629    0.00158352   0.0647637  -0.134691    -0.217766    -0.0181667    0.253637     0.00293549   0.0617003   -0.00408369  -0.0586912     0.051284     0.00932007   0.0258036    -0.0617849    0.1265      -0.027635   -0.0202372    0.0120652   -0.00541051    0.124212      0.00622248  -0.0679841   0.0985456    0.00337288
  0.0330835   0.1147       0.250189     0.012019    0.136435    -0.161568     0.0692732   -0.0544668   -0.0816366    0.0430854    0.0113335   -0.19526       0.0654259   -0.0841329    0.178474     -0.0773944    0.109548    -0.123228    0.0737113   -0.00243035   0.0675678    -0.0084837     0.0231464    0.0320187   0.00225618  -0.205975
 -0.0513425   0.117632     0.113274    -0.0588206  -0.118492     0.0266666   -0.00284049  -0.130162     0.0674574   -0.0566978    0.10706     -0.0417404     0.133006    -0.0595146    0.0891376    -0.0886804    0.203905    -0.0961997  -0.107683    -0.376979     0.0473033    -0.0505538     0.12276     -0.196408   -0.0927917    0.0288894
  0.0534686  -0.0331272   -0.117326     0.267948   -0.0572139    0.0961242    0.169505     0.122593     0.054744     0.170267     0.0569516   -0.120748     -0.00698292  -0.122183    -0.0613798     0.0246403   -0.0642446   -0.145209    0.01063     -0.13285     -0.0789379    -0.0670393     0.101133     0.0751741   0.0234409    0.0240388
 -0.0971244  -0.0422616    0.078355    -0.143865   -0.148774    -0.148342     0.0966882    0.0254735   -0.0433217    0.0272511   -0.112345     0.0763277    -0.108357    -0.0841249   -0.0864858    -0.177534    -0.0526442   -0.235514    0.0629242   -0.0550419    0.164685      0.016127      0.018604    -0.0490415  -0.00848724  -0.165831
  0.0379995  -0.0372579   -0.152244     0.0175618  -0.00132464  -0.065155     0.0256366    0.0327842   -0.00214395  -0.03052     -0.119471    -0.0178166     0.0868273   -0.0495976    0.140133      0.0150922    0.0830677   -0.129404    0.0856611    0.0817659    0.0480326    -0.0576577    -0.202054     0.14932    -0.0743268    0.0174522
 -0.152399    0.195733    -0.0241874    0.240594    0.181822    -0.167869    -0.0649105   -0.00837866   0.0322538   -0.0784464   -0.0162304    0.0357917    -0.100855     0.0391066   -0.13933       0.13345      0.148653    -0.0363992   0.0287678   -0.00694554   0.000784191  -0.171084     -0.0560676   -0.0585965  -0.127979    -0.160059
  0.0132992   0.00808676   0.0848661    0.0859084  -0.0552468   -0.00969309  -0.097069     0.00291522   0.00337833   0.00230756  -0.0324819   -0.0196454     0.128223     0.00952196   0.0571789    -0.0466857   -0.00291085  -0.146734   -0.0297486   -0.0905916   -0.102667     -0.105882      0.0218676   -0.0968655   0.0703316    0.0056596
  0.0246345  -0.0837826    0.0676317    0.0542183  -0.0862945    0.0294327    0.0579357   -0.0898348    0.0202298   -0.0624316   -0.0670319    0.385667      0.103181     0.289198     0.157027      0.0739114    0.00323662   0.0687859  -0.0452438    0.087153     0.0374179    -0.198345     -0.130039     0.131643   -0.0677927    0.0400975
  0.031162    0.0974001   -0.146643    -0.0500581   0.0168398   -0.176423     0.0388274   -0.0443215    0.12554      0.0299125   -0.157724     0.02345       0.00539139  -0.13154      0.11479      -0.0601089    0.179247    -0.012567    0.116761    -0.0443076   -0.105823      0.0960949    -0.00264497  -0.0114119   0.0426353    0.206903
 -0.0674745  -0.0700742    0.010564     0.0349835   0.0699218    0.0794426   -0.0531168    0.0770841    0.0211979    0.0874153   -0.0210849    0.132665      0.172481     0.0117256    0.14546       0.0511427   -0.00372534   0.140757   -0.147017     0.15815     -0.102404     -0.238881     -0.0169753   -0.0178709  -0.0505825    0.00749514
 -0.0344085   0.0698239    0.0964164    0.0690957   0.0407774   -0.11889     -0.0459442    0.0886456   -0.257524     0.0278481    0.0420851   -0.0643781    -0.164148     0.146798     0.0167104    -0.0421219   -0.212245    -0.25903     0.0215728    0.0344613    0.144261     -0.186115      0.0955076    0.0278414   0.0232961    0.069762
 -0.131559   -0.0597418   -0.0691914    0.0897331  -0.194706    -0.0946856   -0.0368523    0.186201    -0.0588953   -0.0685779    0.0194715   -0.0749113    -0.016006     0.0335891   -0.000813508  -0.0516835    0.075452    -0.181025   -0.0182415    0.124873    -0.0123707    -0.005247      0.0335021    0.153877    0.0145827   -0.150808
 -0.0630757  -0.158114     0.0960364   -0.0188783   0.0325611    0.0602554   -0.0492937    0.149801    -0.0743267    0.161713     0.106856     0.123845     -0.0727562    0.0485521    0.0550063     0.142689    -0.0900993   -0.0268996  -0.0556695    0.0251306    0.0088336    -0.0937861     0.0237844    0.0188362   0.0136863    0.0815998
  0.0194765  -0.045827     0.0467744   -0.095816    0.166021    -0.0101545    0.0272315    0.0413002    0.0173856    0.0113557   -0.0975431    0.014204      0.0498289    0.0427814   -0.0547184     0.1114      -0.0872106   -0.0882481  -0.00968887   0.0119461   -0.183526     -0.0657815     0.0300908    0.205001    0.0653902    0.00933779
 -0.103761    0.057283    -0.103361    -0.0815043  -0.0830115   -0.00529637   0.0404287   -0.0406301   -0.0623895    0.00362742   0.0568927    0.118655     -0.176819     0.126411    -0.0537673    -0.0740755    0.108434     0.0750376   0.0994943    0.177094    -0.0461855     0.0997759    -0.141442     0.011799   -0.0808115    0.0325274
  0.0900678  -0.174634    -0.01725      0.14268     0.0537361    0.18529     -0.0421274   -0.00129685   0.068982    -0.0747803    0.106531     0.0739403    -0.0429721   -0.0356063    0.0483739    -0.00599258  -0.146737     0.0347396  -0.0345562    0.0253495    0.0337862    -0.0428057     0.00644794   0.0132502   0.069931    -0.00295855
  0.0384226  -0.0720633   -0.0772264    0.0522859   0.00398731  -0.00100634   0.0609745    0.201197    -0.0618258    0.0685572   -0.0695797    0.012242      0.0893358   -0.177758    -0.109108     -0.118075     0.0795138    0.109814   -0.0304757    0.0608916    0.0272491    -0.089448      0.0868923   -0.110337   -0.106681    -0.0093035
 -0.105622   -0.117746    -0.10805      0.0952869   0.156197     0.179834     0.080427     0.0667349   -0.00701411  -0.0216002   -0.0170476   -0.235008     -0.1429       0.134151     0.15182       0.0218407    0.0712602   -0.0484076   0.00207533  -0.0462579    0.209627      0.0619306     0.0896971   -0.0169945  -0.205009    -0.31255
  0.0949755   0.0696293   -0.152171    -0.250646   -0.0502177   -0.106494    -0.102645     0.292709     0.0943071    0.0405748    0.00320861  -0.0536304    -0.0719418   -0.0511197   -0.0317313    -0.0408391   -0.045017    -0.0169486  -0.0684347    0.00437807   0.0884673    -0.000382999  -0.0271341   -0.0971595  -0.0712138    0.013337
 -0.110444    0.142964     0.00316239   0.0755252  -0.17828      0.112731    -0.125824    -0.12679     -0.0636847   -0.0476705   -0.0149696   -0.139172     -0.0131752   -0.0756542    0.106089     -0.0304598   -0.0450322   -0.244866   -0.0312151   -0.0608172   -0.0753412    -0.0668133    -0.136407    -0.0403737   0.00530609   0.0759318
  0.0380371   0.0711128   -0.0325831    0.0822027  -0.0567194   -0.0449657    0.0549806    0.106457     0.1695      -0.0567984   -0.0631734    0.0110567     0.0123981    0.139888     0.0136034    -0.103564    -0.102084     0.0345586   0.027014    -0.057549     0.0630276    -0.225259      1.88622e-5   0.1205     -0.0325746    0.172947
 -0.0199851   0.206398    -0.0850159   -0.127225   -0.00832957  -0.111254     0.130053    -0.161551     0.12335     -0.129504     0.164235     0.0928137     0.141038    -0.0808661   -0.0279523     0.0271192   -0.0357767    0.0548013   0.057619     0.116491    -0.0316831     0.0684729     0.0164927   -0.0629316  -0.195377     0.0940601
 -0.0354075   0.0411374   -0.089637    -0.0430583  -0.157842     0.034429     0.220139    -0.140136    -0.0428444    0.188715    -0.0519069    0.167681     -0.0602553    0.158338    -0.0524536    -0.010829     0.0810755   -0.0457518   0.00794997  -0.299621     0.104793     -0.0216308    -0.0455738    0.0296909  -0.0722474   -0.131001
 -0.105425    0.0651746   -0.0106288   -0.0664081  -0.152236     0.0195667   -0.0326273    0.217084    -0.0770505    0.138874     0.129891    -0.120219      0.0166247   -0.0758038   -0.132383      0.0346603   -0.00770097  -0.0305911   0.156623     0.0851255    0.0852018     0.0228671    -0.0173366    0.167443   -0.130585     0.0492825
  0.0219668  -0.154453    -0.2188       0.125833   -0.0469139   -0.207854     0.0986462    0.0922129   -0.0438315   -0.0285224    0.120063    -0.248811      0.0100564   -0.00589471  -0.0677603    -0.0567707    0.00690521  -0.088819    0.0653353   -0.088561     0.0681297     0.0117        0.00394585  -0.0369519  -0.143289    -0.0142958
  0.0863183   0.0434585    0.0208366    0.171087    0.0994788    0.0433474   -0.00848251  -0.0796441    0.129466    -0.121664    -0.0312223   -0.0118356     0.029983     0.0181934    0.113608      0.0512237   -0.0170013    0.0596793   0.180605    -0.0611195    0.163532      0.121677     -0.0345186    0.13604     0.0551201    0.148887
 -0.0340011  -0.110654     0.0314101   -0.15809     0.0140207    0.0215014   -0.0290516    0.0107319    0.10875     -0.202718     0.19764      0.062474      0.153817     0.00183789  -0.0809338     0.0546263   -0.0940438    0.0148461   0.0574252   -0.239083     0.0708357    -0.015414     -0.101349    -0.0993001  -0.0611437   -0.122345kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4414988765974737
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.441600
[ Info: iteration 2, average log likelihood -1.441503
[ Info: iteration 3, average log likelihood -1.440407
[ Info: iteration 4, average log likelihood -1.429832
[ Info: iteration 5, average log likelihood -1.406497
[ Info: iteration 6, average log likelihood -1.398752
[ Info: iteration 7, average log likelihood -1.397538
[ Info: iteration 8, average log likelihood -1.396996
[ Info: iteration 9, average log likelihood -1.396714
[ Info: iteration 10, average log likelihood -1.396579
[ Info: iteration 11, average log likelihood -1.396513
[ Info: iteration 12, average log likelihood -1.396479
[ Info: iteration 13, average log likelihood -1.396460
[ Info: iteration 14, average log likelihood -1.396450
[ Info: iteration 15, average log likelihood -1.396445
[ Info: iteration 16, average log likelihood -1.396441
[ Info: iteration 17, average log likelihood -1.396439
[ Info: iteration 18, average log likelihood -1.396438
[ Info: iteration 19, average log likelihood -1.396437
[ Info: iteration 20, average log likelihood -1.396436
[ Info: iteration 21, average log likelihood -1.396436
[ Info: iteration 22, average log likelihood -1.396435
[ Info: iteration 23, average log likelihood -1.396435
[ Info: iteration 24, average log likelihood -1.396435
[ Info: iteration 25, average log likelihood -1.396435
[ Info: iteration 26, average log likelihood -1.396435
[ Info: iteration 27, average log likelihood -1.396435
[ Info: iteration 28, average log likelihood -1.396435
[ Info: iteration 29, average log likelihood -1.396435
[ Info: iteration 30, average log likelihood -1.396435
[ Info: iteration 31, average log likelihood -1.396435
[ Info: iteration 32, average log likelihood -1.396435
[ Info: iteration 33, average log likelihood -1.396435
[ Info: iteration 34, average log likelihood -1.396435
[ Info: iteration 35, average log likelihood -1.396435
[ Info: iteration 36, average log likelihood -1.396435
[ Info: iteration 37, average log likelihood -1.396435
[ Info: iteration 38, average log likelihood -1.396435
[ Info: iteration 39, average log likelihood -1.396435
[ Info: iteration 40, average log likelihood -1.396435
[ Info: iteration 41, average log likelihood -1.396435
[ Info: iteration 42, average log likelihood -1.396435
[ Info: iteration 43, average log likelihood -1.396435
[ Info: iteration 44, average log likelihood -1.396435
[ Info: iteration 45, average log likelihood -1.396435
[ Info: iteration 46, average log likelihood -1.396435
[ Info: iteration 47, average log likelihood -1.396435
[ Info: iteration 48, average log likelihood -1.396435
[ Info: iteration 49, average log likelihood -1.396435
[ Info: iteration 50, average log likelihood -1.396435
┌ Info: EM with 100000 data points 50 iterations avll -1.396435
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4416002452954426
│     -1.4415025483658757
│      ⋮
└     -1.3964345456616996
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.396608
[ Info: iteration 2, average log likelihood -1.396461
[ Info: iteration 3, average log likelihood -1.395954
[ Info: iteration 4, average log likelihood -1.391343
[ Info: iteration 5, average log likelihood -1.377052
[ Info: iteration 6, average log likelihood -1.367114
[ Info: iteration 7, average log likelihood -1.363478
[ Info: iteration 8, average log likelihood -1.361288
[ Info: iteration 9, average log likelihood -1.359801
[ Info: iteration 10, average log likelihood -1.358720
[ Info: iteration 11, average log likelihood -1.357734
[ Info: iteration 12, average log likelihood -1.356648
[ Info: iteration 13, average log likelihood -1.355638
[ Info: iteration 14, average log likelihood -1.355017
[ Info: iteration 15, average log likelihood -1.354649
[ Info: iteration 16, average log likelihood -1.354435
[ Info: iteration 17, average log likelihood -1.354310
[ Info: iteration 18, average log likelihood -1.354238
[ Info: iteration 19, average log likelihood -1.354197
[ Info: iteration 20, average log likelihood -1.354174
[ Info: iteration 21, average log likelihood -1.354161
[ Info: iteration 22, average log likelihood -1.354154
[ Info: iteration 23, average log likelihood -1.354150
[ Info: iteration 24, average log likelihood -1.354148
[ Info: iteration 25, average log likelihood -1.354146
[ Info: iteration 26, average log likelihood -1.354145
[ Info: iteration 27, average log likelihood -1.354145
[ Info: iteration 28, average log likelihood -1.354144
[ Info: iteration 29, average log likelihood -1.354144
[ Info: iteration 30, average log likelihood -1.354144
[ Info: iteration 31, average log likelihood -1.354144
[ Info: iteration 32, average log likelihood -1.354143
[ Info: iteration 33, average log likelihood -1.354143
[ Info: iteration 34, average log likelihood -1.354143
[ Info: iteration 35, average log likelihood -1.354143
[ Info: iteration 36, average log likelihood -1.354143
[ Info: iteration 37, average log likelihood -1.354143
[ Info: iteration 38, average log likelihood -1.354143
[ Info: iteration 39, average log likelihood -1.354143
[ Info: iteration 40, average log likelihood -1.354143
[ Info: iteration 41, average log likelihood -1.354143
[ Info: iteration 42, average log likelihood -1.354143
[ Info: iteration 43, average log likelihood -1.354143
[ Info: iteration 44, average log likelihood -1.354143
[ Info: iteration 45, average log likelihood -1.354143
[ Info: iteration 46, average log likelihood -1.354143
[ Info: iteration 47, average log likelihood -1.354143
[ Info: iteration 48, average log likelihood -1.354143
[ Info: iteration 49, average log likelihood -1.354143
[ Info: iteration 50, average log likelihood -1.354143
┌ Info: EM with 100000 data points 50 iterations avll -1.354143
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.396608120585391
│     -1.3964614427469144
│      ⋮
└     -1.3541429982444426
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.354365
[ Info: iteration 2, average log likelihood -1.354165
[ Info: iteration 3, average log likelihood -1.353594
[ Info: iteration 4, average log likelihood -1.348114
[ Info: iteration 5, average log likelihood -1.329432
[ Info: iteration 6, average log likelihood -1.313245
[ Info: iteration 7, average log likelihood -1.306668
[ Info: iteration 8, average log likelihood -1.303366
[ Info: iteration 9, average log likelihood -1.301045
[ Info: iteration 10, average log likelihood -1.299090
[ Info: iteration 11, average log likelihood -1.297390
[ Info: iteration 12, average log likelihood -1.296074
[ Info: iteration 13, average log likelihood -1.295098
[ Info: iteration 14, average log likelihood -1.294081
[ Info: iteration 15, average log likelihood -1.293159
[ Info: iteration 16, average log likelihood -1.292674
[ Info: iteration 17, average log likelihood -1.292343
[ Info: iteration 18, average log likelihood -1.291969
[ Info: iteration 19, average log likelihood -1.291579
[ Info: iteration 20, average log likelihood -1.291221
[ Info: iteration 21, average log likelihood -1.290949
[ Info: iteration 22, average log likelihood -1.290786
[ Info: iteration 23, average log likelihood -1.290702
[ Info: iteration 24, average log likelihood -1.290656
[ Info: iteration 25, average log likelihood -1.290627
[ Info: iteration 26, average log likelihood -1.290607
[ Info: iteration 27, average log likelihood -1.290591
[ Info: iteration 28, average log likelihood -1.290578
[ Info: iteration 29, average log likelihood -1.290567
[ Info: iteration 30, average log likelihood -1.290558
[ Info: iteration 31, average log likelihood -1.290550
[ Info: iteration 32, average log likelihood -1.290542
[ Info: iteration 33, average log likelihood -1.290534
[ Info: iteration 34, average log likelihood -1.290526
[ Info: iteration 35, average log likelihood -1.290518
[ Info: iteration 36, average log likelihood -1.290510
[ Info: iteration 37, average log likelihood -1.290500
[ Info: iteration 38, average log likelihood -1.290488
[ Info: iteration 39, average log likelihood -1.290474
[ Info: iteration 40, average log likelihood -1.290456
[ Info: iteration 41, average log likelihood -1.290433
[ Info: iteration 42, average log likelihood -1.290405
[ Info: iteration 43, average log likelihood -1.290368
[ Info: iteration 44, average log likelihood -1.290321
[ Info: iteration 45, average log likelihood -1.290268
[ Info: iteration 46, average log likelihood -1.290204
[ Info: iteration 47, average log likelihood -1.290129
[ Info: iteration 48, average log likelihood -1.290051
[ Info: iteration 49, average log likelihood -1.289979
[ Info: iteration 50, average log likelihood -1.289915
┌ Info: EM with 100000 data points 50 iterations avll -1.289915
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3543646642720868
│     -1.3541654300956287
│      ⋮
└     -1.2899152676996162
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.290151
[ Info: iteration 2, average log likelihood -1.289793
[ Info: iteration 3, average log likelihood -1.288434
[ Info: iteration 4, average log likelihood -1.274905
[ Info: iteration 5, average log likelihood -1.245438
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.223228
[ Info: iteration 7, average log likelihood -1.219774
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.212336
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.218642
[ Info: iteration 10, average log likelihood -1.215156
[ Info: iteration 11, average log likelihood -1.208151
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.205032
[ Info: iteration 13, average log likelihood -1.209222
[ Info: iteration 14, average log likelihood -1.205493
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.203504
[ Info: iteration 16, average log likelihood -1.207565
[ Info: iteration 17, average log likelihood -1.203318
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.200909
[ Info: iteration 19, average log likelihood -1.205341
[ Info: iteration 20, average log likelihood -1.202052
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.200542
[ Info: iteration 22, average log likelihood -1.205176
[ Info: iteration 23, average log likelihood -1.201928
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.200429
[ Info: iteration 25, average log likelihood -1.205059
[ Info: iteration 26, average log likelihood -1.201820
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.200329
[ Info: iteration 28, average log likelihood -1.204971
[ Info: iteration 29, average log likelihood -1.201747
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.200270
[ Info: iteration 31, average log likelihood -1.204929
[ Info: iteration 32, average log likelihood -1.201714
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.200241
[ Info: iteration 34, average log likelihood -1.204912
[ Info: iteration 35, average log likelihood -1.201697
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.200223
[ Info: iteration 37, average log likelihood -1.204900
[ Info: iteration 38, average log likelihood -1.201682
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.200205
[ Info: iteration 40, average log likelihood -1.204888
[ Info: iteration 41, average log likelihood -1.201666
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.200186
[ Info: iteration 43, average log likelihood -1.204871
[ Info: iteration 44, average log likelihood -1.201646
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.200162
[ Info: iteration 46, average log likelihood -1.204851
[ Info: iteration 47, average log likelihood -1.201621
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.200134
[ Info: iteration 49, average log likelihood -1.204824
[ Info: iteration 50, average log likelihood -1.201587
┌ Info: EM with 100000 data points 50 iterations avll -1.201587
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2901511425758057
│     -1.2897934051452473
│      ⋮
└     -1.2015867360709611
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.200447
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.199948
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.196539
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.166022
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      8
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.123223
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.117601
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      8
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.101442
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.102894
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│      8
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.084864
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.106935
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.093626
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.091638
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.096061
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.096475
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│      8
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.073964
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.093843
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.079169
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.076720
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      5
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.080044
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.093559
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      8
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.070717
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.082932
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      8
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.076861
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.083141
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│      8
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.066662
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.090087
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.076542
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.074534
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      5
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.078297
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.091801
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      8
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.069320
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.081842
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      8
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.076325
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.083025
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│      8
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.066614
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.089968
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.076233
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      7
│      8
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.073585
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.088224
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.086900
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│      8
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.067626
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.090365
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.076963
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      8
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.075738
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.081738
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.085221
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│      8
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.066995
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.089277
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      5
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.074251
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.082202
┌ Info: EM with 100000 data points 50 iterations avll -1.082202
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2004470017715072
│     -1.1999484852112847
│      ⋮
└     -1.0822019196504467
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4414988765974737
│     -1.4416002452954426
│     -1.4415025483658757
│     -1.4404066219520406
│      ⋮
│     -1.0892774717584284
│     -1.0742513779011513
└     -1.0822019196504467
32×26 Array{Float64,2}:
 -0.0241909   -0.0258455  -0.115267     0.0384353   -0.12957    -0.0379254    0.158679    -0.0926699   -0.0319189    0.119363    -0.019579     0.0231704   -0.0340892    0.108515    -0.0366498    -0.0280785    0.0529328   -0.082523    0.0303031  -0.271691      0.0884358   -0.000161217  -0.0263926    0.0176231  -0.0790637    -0.106211
  0.029486     0.169421    0.254612     0.00959333   0.148571   -0.138946     0.0996777   -0.044468    -0.0493061    0.0313089    0.0131653   -0.216933     0.0748333   -0.0849741    0.175668     -0.0929631    0.12282     -0.134934    0.0731786   0.0157655     0.0775078   -0.0149365     0.0215315    0.0300208   0.000170531  -0.197844
 -0.021063    -0.0227301   0.00907249   0.0102851   -0.073514    0.0138595    0.0141819   -0.00996508  -0.0102672   -0.0491551    0.0343244    0.0351059    0.074191    -0.00985014   0.0328215    -0.0283235    0.0450335   -0.0326481  -0.0323951  -0.0972776     0.0194819   -0.0798913    -0.00175966  -0.0690975  -0.0734164     0.00981198
  0.0630319    0.0742703  -0.0488952    0.0605352   -0.0613506  -0.0411894    0.0583925    0.0934888    0.158707    -0.0562357   -0.043864     0.0438831    0.0132126    0.128308     0.00916027   -0.0839465   -0.120026     0.02631     0.0106109  -0.073312      0.0214925   -0.218296     -0.0183827    0.106173   -0.00543177    0.201996
 -0.115847     0.0614841  -0.107241    -0.0684646   -0.084233   -0.00324773   0.0383833   -0.0413778   -0.0546109    0.00595864   0.0559276    0.117044    -0.186253     0.124718    -0.0510329    -0.0713396    0.0970864    0.0514238   0.0955628   0.15401      -0.0326752    0.096978     -0.108245     0.0085826  -0.0777524     0.03217
  0.014237     0.0910588  -0.147659    -0.0490327    0.0154939  -0.206291     0.0501157   -0.0499179    0.126574     0.0387444   -0.16542      0.0209963   -0.0211261   -0.115359     0.0989104    -0.143238     0.186923     0.0206269   0.105889   -0.0417599    -0.100226     0.101323     -0.0162945   -0.0116484   0.040228      0.187345
 -0.16397      0.195585   -0.0233297    0.246155     0.180572   -0.169455    -0.0608899   -0.00213376   0.0368885   -0.0629315    0.00352577   0.0355738   -0.0898864    0.0430483   -0.143899      0.131347     0.147613    -0.0288669   0.0427583  -0.00738329    0.00665672  -0.151757     -0.0528939   -0.0574402  -0.0950335    -0.164146
  0.0451216   -0.03529    -0.0499624    0.0697932    0.0761489   0.057286     0.00802089  -0.199183     0.0477864    0.0474116    0.00736551  -0.033014     0.0312679    0.0480056   -0.000563474   0.055394     0.00121927   0.195676    0.0692132  -0.163868      0.047749    -0.0019052     0.00887544  -0.101381   -0.0695997    -0.0311916
 -0.072643     0.0935865   0.0619445   -0.00361534  -0.0145957  -0.0690661   -0.0249715   -0.0664695   -0.0625829   -0.0370195   -0.0301832    0.0604495    0.0324402    0.0509826    0.0500574     0.049708     0.027362    -0.107984   -0.0374415  -0.0649592    -0.027559    -0.0167415    -0.0277775   -0.0984637   0.0446503    -0.035321
  0.0961166    0.0584298  -0.147747    -0.242032    -0.04762    -0.141581    -0.111511     0.291216     0.113089     0.0454996    0.00719849  -0.0474582   -0.0955108   -0.0522703   -0.0314074    -0.0122657   -0.0445301   -0.0309164  -0.0643842   0.00687154    0.0911423   -0.0203323    -0.0295784   -0.0828426  -0.0535767     0.00593688
  0.00613942  -0.0789311  -0.001872     0.0589356   -0.140469   -0.207313    -0.00532848   0.185323     0.00222636   0.0473786   -0.0134322   -0.0466197    0.0501474    0.0203054    0.0196704    -0.0633611    0.124323    -0.0460121  -0.0232382  -0.0027953    -0.0205486    0.113695     -0.0435853   -0.0762852   0.0957165    -0.0323054
  0.0174445   -0.0470941   0.0437097   -0.0942648    0.149085   -0.00827159   0.0281131    0.0367778    0.0776705    0.0117296   -0.0622722   -0.00687365   0.0390545    0.0415035   -0.0616239     0.110667    -0.087277    -0.0948581  -0.0291752   0.0307478    -0.187327    -0.0742643     0.0294502    0.194771    0.0655317     0.00967101
 -0.137032     0.0533037  -0.0172698   -0.0747638   -0.114387    0.0127146   -0.041376     0.300302    -0.0498994    0.140491     0.155614    -0.13932     -0.0139946   -0.0847576   -0.166006      0.0173763   -0.0485947   -0.0620694   0.0397731   0.0511649     0.0892532    0.0737803    -0.019567    -0.247506   -0.100111      0.0727534
 -0.0781808    0.0715555  -0.0032069   -0.0585914   -0.163004    0.0163117   -0.0268219    0.130881    -0.0793835    0.136723     0.0711838   -0.0924753   -0.00305508  -0.0721526   -0.111919      0.0499521    0.0213047    0.0117547   0.271705    0.133735      0.0807648    0.0209085    -0.0144566    0.454189   -0.135255      0.074425
 -0.148891    -0.0920462   0.0856025   -0.0242142    0.0908967   0.0752999   -0.0242664   -0.0262857   -0.117007    -0.215091    -0.162654     0.00337238   0.0773132   -0.483369    -0.345188      0.124771    -0.0588154    0.0134818  -0.0305656   0.137744     -0.100039     0.101491     -0.212335     0.0949849  -0.0525295     0.294935
 -0.165887     0.155818    0.133425    -0.0230181    0.0895572   0.0223036   -0.128725    -0.00480272  -0.11737      0.0955233   -0.263576    -0.00868145   0.0283991    0.783598     0.294727      0.115978    -0.052906     0.0206895  -0.136573   -0.279271     -0.0310678    0.176426      0.0445714    0.112022   -0.106861     -0.15137
 -2.48735     -0.0353145   0.0638849    0.0755139   -0.169858   -0.177991     0.119674     0.153914     0.0537065    0.114209    -0.179906     0.109858    -0.107939    -0.105737     0.00445434   -0.202383    -0.0448835   -0.240045    0.136165   -0.000393448   0.210005     0.328771      0.0241098   -0.0290282  -0.00581364   -0.308511
  0.743515    -0.0662017   0.119049     0.0540021   -0.147168   -0.208641     0.111842    -0.128491    -0.0128215    0.157313    -0.143727     0.103888    -0.162962    -0.0344015   -0.166509     -0.150614    -0.0633186   -0.232395    0.0902587  -0.181215      0.0885126    0.336575     -0.0206985   -0.0889558  -0.00557366   -0.410769
 -0.771548    -0.0428464   0.0991827   -0.343596    -0.142114   -0.283649     0.0992732   -0.111735    -0.219123    -0.0108606   -0.0772574    0.018177    -0.131872    -0.0738896   -0.0968853    -0.155155    -0.0549678   -0.238535   -0.0291051  -0.0991561     0.282269    -0.689074      0.0782082    0.0381695   0.0662688     0.321736
  1.6115      -0.0343427   0.0315674   -0.275096    -0.150503   -0.0337028    0.0828341    0.166724    -0.0728268   -0.136616    -0.0978764    0.144801    -0.0307627   -0.119767    -0.183774     -0.255556    -0.035153    -0.232729    0.12643     0.0548611     0.118415     0.131296      0.00653939  -0.0416198  -0.0638511    -0.254905
  0.0350388   -0.0326362  -0.0928474    0.2325      -0.0908584   0.0788515    0.144198     0.0898618    0.054617     0.176762     0.0623839   -0.0971401   -0.0166919   -0.113029    -0.0237601     0.0364159   -0.0575819   -0.145688   -0.0215025  -0.135655     -0.0764885   -0.0819051     0.101674     0.0662042   0.0202795     0.0378071
 -0.106033    -0.0602278  -0.136316     0.0905098   -0.192895   -0.106549    -0.0363382    0.180812    -0.0649673   -0.0698517    0.027808    -0.0902407   -0.017348     0.0402105   -0.00493931   -0.0522264    0.0731834   -0.19211    -0.0591788   0.12345      -0.00469941   0.00573859    0.0281556    0.162445    0.0154562    -0.161296
 -0.0465056    0.075717    0.113836     0.040504     0.029761   -0.0294146    0.0237982    0.0652042   -0.0413054   -0.0204131    0.0365018   -0.00304618  -0.0795526    0.0787178   -0.0585093     0.00996443  -0.16861     -0.174907   -0.103846   -0.000683557  -0.0233152   -0.154119      0.0934339   -0.0430357   0.0111617     0.0156635
  0.0630669   -0.183821   -0.0154535    0.126672     0.0575655   0.199478    -0.0397822   -0.00721101   0.0541785   -0.0734031    0.120826     0.117851    -0.0368319   -0.0371368    0.0679844     0.00594542  -0.148733     0.0315331  -0.0384611  -0.0284998     0.0388084   -0.0493405     0.0239564    0.029279    0.0680292    -0.0104492
 -0.027391     0.216652   -0.0861978   -0.147181     0.0394329  -0.11539      0.165607    -0.194944     0.125814    -0.66392      0.0685704    0.0975153    0.142397    -0.0663854   -0.0894979     0.0283448    0.159603     0.0660094   0.101565    0.334589     -0.00751837   0.0757915     0.0897876   -0.0115739  -0.197401      0.0927544
 -0.0274607    0.199419   -0.103735    -0.156275    -0.106032   -0.107851     0.175361    -0.130908     0.12132      0.332868     0.312366     0.0873366    0.126396    -0.0950574   -0.134828      0.0199573   -0.229367     0.0463759   0.0313497  -0.155787     -0.0395847    0.0558193    -0.110394    -0.113158   -0.207091      0.0943234
 -0.0656776   -0.126444    0.0953338   -0.0166001    0.0407375   0.0693729   -0.0501669    0.15079     -0.0888035    0.124843     0.114833     0.141382    -0.0282264    0.0387703    0.0616402     0.146299    -0.0781337   -0.0313533  -0.0784759   0.0206827     0.00951139  -0.0877922     0.0556335    0.0119139   0.0267602     0.0833763
  0.0869144    0.0416128   0.0211203    0.153614     0.148861    0.0416595   -0.0077523   -0.0795137    0.109606    -0.112741    -0.049501     0.0030443    0.0112693    0.0188399    0.129336      0.0488554   -0.0732551    0.0750183   0.1403     -0.0668632     0.161341     0.1048       -0.034916     0.132809    0.0513341     0.145473
  0.0254769   -0.0275628  -0.156282     0.00300328  -0.0361919  -0.0647956    0.0283526    0.0314452   -0.00459116  -0.0133628   -0.110118    -0.010002     0.0727757   -0.0407268    0.132206      0.0366548    0.0829779   -0.0927768   0.0819984   0.0505383     0.0449629   -0.0622383    -0.197067     0.15413    -0.0516399     0.0175612
 -0.0488834   -0.0751103  -0.00729463   0.0329152    0.0681292   0.106625    -0.0798243    0.0887819    0.0202635    0.0935134   -0.0217632    0.133022     0.176842     0.0151285    0.137153      0.0540434   -0.00511002   0.194023   -0.178758    0.161102     -0.104419    -0.245824     -0.0166101   -0.0183639  -0.0608159     0.0165774
 -0.191516    -0.101231   -0.0229479    0.129386     0.157134    0.136627     0.126192     0.153536    -1.21866     -0.00924475  -0.0164549   -0.220428    -0.00589809   0.139115     0.150105      0.00511208   0.0753185   -0.0528904   0.020491   -0.0247533     0.199039     0.0650063     0.0959651   -0.0777585  -0.199071     -0.36589
 -0.0197827   -0.142898   -0.153173     0.0773812    0.20247     0.140753     0.0990456   -0.0132694    1.55813     -0.023118    -0.0212639   -0.239952    -0.203648     0.129201     0.204574      0.0262851    0.0862551   -0.043985   -0.0409441  -0.089519      0.229877     0.0602914     0.0949632    0.0114382  -0.274269     -0.28019[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      7
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.074759
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│      8
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.067212
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      7
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.073346
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│      8
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.066910
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      7
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.073212
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│      8
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.066782
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      7
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.072941
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│      8
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.066102
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│      7
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.070829
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      7
│      8
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.069229
┌ Info: EM with 100000 data points 10 iterations avll -1.069229
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.845649e+05
      1       7.280202e+05      -2.565447e+05 |       32
      2       6.996631e+05      -2.835711e+04 |       32
      3       6.859006e+05      -1.376245e+04 |       32
      4       6.778771e+05      -8.023532e+03 |       32
      5       6.723340e+05      -5.543102e+03 |       32
      6       6.684504e+05      -3.883580e+03 |       32
      7       6.658507e+05      -2.599717e+03 |       32
      8       6.637666e+05      -2.084053e+03 |       32
      9       6.622704e+05      -1.496261e+03 |       32
     10       6.613470e+05      -9.233708e+02 |       32
     11       6.605261e+05      -8.209499e+02 |       32
     12       6.596919e+05      -8.341488e+02 |       32
     13       6.589701e+05      -7.218206e+02 |       32
     14       6.581796e+05      -7.905154e+02 |       32
     15       6.574482e+05      -7.313258e+02 |       32
     16       6.569593e+05      -4.889188e+02 |       32
     17       6.566297e+05      -3.296217e+02 |       32
     18       6.563447e+05      -2.849791e+02 |       32
     19       6.559808e+05      -3.639487e+02 |       32
     20       6.554991e+05      -4.816386e+02 |       32
     21       6.549299e+05      -5.692005e+02 |       32
     22       6.543653e+05      -5.646293e+02 |       32
     23       6.538975e+05      -4.677932e+02 |       32
     24       6.535070e+05      -3.905477e+02 |       32
     25       6.532381e+05      -2.688379e+02 |       32
     26       6.530109e+05      -2.271979e+02 |       32
     27       6.527237e+05      -2.872059e+02 |       32
     28       6.523357e+05      -3.880488e+02 |       32
     29       6.518680e+05      -4.677099e+02 |       32
     30       6.512563e+05      -6.116279e+02 |       32
     31       6.503977e+05      -8.586222e+02 |       32
     32       6.495895e+05      -8.082154e+02 |       32
     33       6.491587e+05      -4.308532e+02 |       32
     34       6.489863e+05      -1.723207e+02 |       32
     35       6.489128e+05      -7.353297e+01 |       31
     36       6.488811e+05      -3.173486e+01 |       31
     37       6.488600e+05      -2.107806e+01 |       31
     38       6.488429e+05      -1.712147e+01 |       29
     39       6.488299e+05      -1.292461e+01 |       28
     40       6.488171e+05      -1.282726e+01 |       28
     41       6.487988e+05      -1.830062e+01 |       29
     42       6.487813e+05      -1.754099e+01 |       29
     43       6.487583e+05      -2.297887e+01 |       30
     44       6.487292e+05      -2.906533e+01 |       26
     45       6.486870e+05      -4.223640e+01 |       31
     46       6.486197e+05      -6.727022e+01 |       30
     47       6.485129e+05      -1.068483e+02 |       32
     48       6.483834e+05      -1.295052e+02 |       32
     49       6.482252e+05      -1.581634e+02 |       32
     50       6.480766e+05      -1.486095e+02 |       32
K-means terminated without convergence after 50 iterations (objv = 648076.5921712765)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.345461
[ Info: iteration 2, average log likelihood -1.308834
[ Info: iteration 3, average log likelihood -1.273477
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.236495
[ Info: iteration 5, average log likelihood -1.198774
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.138768
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     12
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.103536
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      6
│     13
│     17
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.092556
[ Info: iteration 9, average log likelihood -1.132748
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.082064
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     13
│     18
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.061680
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     17
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.098489
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.090739
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.070005
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.073350
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     12
│     13
│     17
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.056357
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.098919
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     10
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.060341
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      7
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.068665
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     13
│     17
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.063189
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.081736
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      6
│     10
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.056495
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.071453
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     12
│     13
│     17
│     18
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.055719
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.104602
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.078554
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.068548
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     13
│     17
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.043047
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│      6
│     10
│     18
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.057748
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     22
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.104850
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.095772
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     17
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.068527
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     13
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.059432
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     22
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.067739
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.085410
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     12
│     13
│     17
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.060105
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.084656
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.062268
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     17
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.065018
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     13
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.072374
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.066680
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     10
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.049260
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     17
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.064671
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     13
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.074501
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      6
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.069593
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.054531
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      7
│     17
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.064499
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     18
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.078865
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     12
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.077924
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.070127
┌ Info: EM with 100000 data points 50 iterations avll -1.070127
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0868138     0.0449252   0.0191555    0.174124     0.163606    0.0430294   -0.00440968  -0.0829587    0.115089    -0.103504    -0.0659599   -0.00778035  -0.000263071   0.0189401     0.136547     0.0488212   -0.0569152    0.0788046   0.143518   -0.0605482    0.161743     0.10806      -0.0313165    0.148992    0.0538087    0.15236
  0.0209808    -0.14391    -0.218825     0.102558    -0.0621363  -0.181293     0.0944719    0.0481017   -0.0195728   -0.0201247    0.137818    -0.236032     0.0034975    -0.00374806   -0.0540281   -0.0770419    0.026485    -0.118798    0.0497527  -0.165136     0.0708358    0.0117905     0.0179405   -0.0638721  -0.13988     -0.00429882
 -0.188122     -0.0460252   0.0818348   -0.132122    -0.150887   -0.184181     0.103262    -0.00303932  -0.0721957    0.0379638   -0.121726     0.0898098   -0.116746     -0.077947     -0.111128    -0.183312    -0.0507101   -0.235898    0.0733326  -0.0689258    0.174309    -0.000848629   0.020227    -0.0279613   0.00458302  -0.142748
 -0.000258364  -0.0546959  -0.037967     0.0642499    0.0642292   0.0843648   -0.042544    -0.0526191    0.0326217    0.0786259   -0.00297362   0.0710643    0.102521      0.0242751     0.0657502    0.0452326    0.00129852   0.258075   -0.0613863   0.00881657  -0.0451759   -0.123749     -0.00188313  -0.056797   -0.0712355   -0.00719314
  0.0105787    -0.0807657  -0.00050923   0.0623049   -0.138385   -0.216493    -0.0124194    0.202174     0.00308661   0.0465162   -0.0138438   -0.0517391    0.0497629     0.014837      0.0212428   -0.0667941    0.127726    -0.0361776  -0.0272382   0.0115754   -0.0265069    0.110852     -0.042339    -0.0786971   0.0971677   -0.0226959
  0.0735631     0.0747542  -0.0500315    0.0762088   -0.0605537  -0.0424486    0.064356     0.0981546    0.165864    -0.0578811   -0.0531457    0.0486525    0.012386      0.134469      0.0164498   -0.0880411   -0.118775     0.0329429   0.0115484  -0.0716051    0.0159682   -0.223436     -0.0148941    0.120771    0.00133853   0.212578
 -0.160244      0.027127    0.106213    -0.0224321    0.0883945   0.045189    -0.0823827   -0.0176166   -0.115035    -0.056463    -0.208791    -0.00122742   0.050309      0.155186     -0.0314245    0.117744    -0.0523182    0.0147804  -0.0860433  -0.0652518   -0.0683689    0.137659     -0.083232     0.0990064  -0.0759607    0.0861482
 -0.10429      -0.122938   -0.0897964    0.102436     0.180778    0.142752     0.113292     0.0687688    0.200985    -0.014072    -0.0189166   -0.230601    -0.104896      0.133778      0.177595     0.0157116    0.0817307   -0.0472923  -0.0112254  -0.0546696    0.210982     0.062196      0.0944309   -0.0328319  -0.235796    -0.321174
  0.0205953    -0.036878    0.0453428   -0.095518     0.136589   -0.00814916   0.0542418    0.0479653    0.0393304    0.0319057   -0.373816     0.0169286    0.0193743     0.0381935    -0.0841947    0.110451    -0.0941303   -0.100273   -0.0382719   0.0389808   -0.16909     -0.0689941     0.0293578    0.183317    0.0763038    0.0359143
 -0.115967      0.132759    0.0214563    0.0650274   -0.177939    0.11624     -0.127653    -0.145557    -0.0629613   -0.0507594    0.00166197  -0.135215     0.00916212   -0.0843373     0.069223    -0.0356076   -0.0623217   -0.242363   -0.031182   -0.0854728   -0.0686276   -0.0667099    -0.128343    -0.043918    0.0184051    0.0730392
 -0.0651191    -0.132595    0.0982694   -0.0186413    0.0379401   0.0691619   -0.0500664    0.150443    -0.0872888    0.126814     0.112028     0.149322    -0.0327092     0.0389668     0.0656973    0.145971    -0.0761756   -0.0299875  -0.0811963   0.0228078    0.0092973   -0.0887637     0.0566704    0.0148506   0.0282492    0.0848957
 -0.109623      0.0714155   0.138137     0.0796826    0.0511442   0.0586169    0.102596     0.0889516    0.10221     -0.076828     0.0108488    0.102241    -0.036191      0.0227758    -0.201174     0.0595696   -0.124717    -0.105267   -0.230807    0.0675609   -0.152141    -0.143315      0.0828741   -0.0569358   0.0127488   -0.0281621
 -0.000229378   0.0365651   0.103822     0.0715134   -0.0597568  -0.0132092   -0.0590401    0.00279642  -0.0732344   -0.0187523   -0.0294577   -0.0195569    0.123029      0.0156766     0.0728957   -0.031391    -0.00578928  -0.1427     -0.0674543  -0.160467    -0.0693089   -0.101996      0.0491919   -0.11376     0.0705987    0.00474343
  0.0636621    -0.188365   -0.0164144    0.129779     0.0583174   0.200267    -0.038663    -0.00874689   0.0536239   -0.0728597    0.124942     0.127809    -0.0415906    -0.0364724     0.0617304    0.00455987  -0.144595     0.033847   -0.0362288  -0.0222805    0.0381559   -0.0489293     0.0262813    0.0295185   0.0676242   -0.0131336
 -0.105483     -0.0597813  -0.139102     0.0920915   -0.193275   -0.106338    -0.0365653    0.182304    -0.0619537   -0.0699986    0.0255398   -0.0929802   -0.0173732     0.0398429    -0.0055782   -0.051533     0.0725341   -0.191039   -0.0593549   0.123102    -0.00534507   0.00507781    0.0291049    0.159482    0.015575    -0.161835
  0.0126097     0.0910705  -0.147265    -0.0497099    0.014828   -0.201566     0.0458236   -0.0487799    0.126805     0.0376367   -0.162714     0.0212393   -0.0192389    -0.113593      0.0994706   -0.137196     0.185008     0.0227286   0.106948   -0.0415894   -0.099672     0.100526     -0.0170013   -0.012663    0.0396346    0.191172
 -0.149223      0.220911    0.0391344   -0.090838     0.0209482  -0.120337     0.0409412   -0.185863    -0.0892186   -0.0353096   -0.0210959    0.104331    -0.0855571     0.0563823     0.0471963    0.142005     0.112333    -0.0904323  -0.0506617  -0.0224967    0.00824147   0.0752978    -0.0521378   -0.112684   -0.0419967   -0.059706
 -0.0382813     0.100649    0.2179      -0.189667    -0.124672    0.0415118   -0.00301691  -0.175036     0.169592    -0.00618547   0.15973     -0.0163936    0.119478     -0.0502817     0.199662    -0.0727382    0.286364    -0.063118   -0.156491   -0.347765     0.00896388  -0.0990322     0.13601     -0.215516   -0.0872666    0.0189563
  0.0309935     0.154281    0.228286    -0.00147953   0.137243   -0.11921      0.107332    -0.0650621   -0.0391358    0.0305694    0.0115869   -0.191862     0.0693595    -0.0467748     0.160502    -0.0799586    0.116521    -0.129877    0.0718717  -0.00567126   0.0743499    0.00267646    0.0206607    0.0145117  -0.00482205  -0.186951
  0.0975899     0.0587952  -0.155778    -0.239477    -0.0481978  -0.137445    -0.108241     0.289537     0.114097     0.0438068    0.00636257  -0.0468577   -0.094087     -0.0527228    -0.0316221   -0.00914139  -0.0399297   -0.0282207  -0.0653528   0.00660549   0.0917113   -0.01454      -0.0307592   -0.0792693  -0.0502774    0.00282881
 -0.108508      0.0633863  -0.00878202  -0.0660233   -0.144188    0.0130674   -0.0365843    0.213572    -0.0651622    0.138971     0.112954    -0.114204    -0.0138481    -0.0839862    -0.139511     0.0360754   -0.011649    -0.0188079   0.169614    0.102258     0.0833565    0.0431859    -0.0166599    0.134221   -0.121121     0.0842056
 -0.149254      0.17696    -0.0306444    0.236898     0.167128   -0.162175    -0.041096    -0.00535883   0.0336085   -0.0549607    0.00512637   0.0206355   -0.0871769     0.0322213    -0.131172     0.125638     0.13326     -0.0297146   0.046003   -0.0198544    0.00755019  -0.124142     -0.0495012   -0.060077   -0.0972842   -0.152406
  0.0119043    -0.105353    0.0424575   -0.0908723    0.236606   -0.014187    -0.115825    -0.00422946   0.284562    -0.105212     1.47712     -0.144424     0.144958      0.0474181     0.0590519    0.115067    -0.0650433   -0.0682218   0.0221225   0.0364171   -0.328182    -0.103941      0.0387029    0.269077    0.0189335   -0.152991
  0.0250681    -0.0726184  -0.0795296    0.0627838   -0.0295914  -0.0148265    0.103026     0.202699    -0.0717821    0.0878657   -0.0874166    0.0115567    0.0618656    -0.168726     -0.113762    -0.106799     0.128702     0.0952693  -0.0395902   0.0490229    0.0228835   -0.0614847     0.143484    -0.102781   -0.0868625   -0.00516323
  0.0448644    -0.0331878  -0.0950437    0.232715    -0.0794206   0.083027     0.141629     0.123593     0.0503939    0.185906     0.068537    -0.0874145   -0.0139587    -0.110403     -0.023826     0.0334749   -0.0736294   -0.144565   -0.0233352  -0.132692    -0.0839833   -0.0891204     0.108928     0.069806    0.0238131    0.0484963
 -0.0385684    -0.111559    0.035878    -0.152333     0.0190067   0.0285407   -0.019417     0.00352184   0.0881878   -0.206777     0.159022     0.0631656    0.152582     -0.000288818  -0.0532333    0.0569591   -0.148809     0.0192178   0.0618756  -0.246475     0.0832029   -0.0102175    -0.102944    -0.0890926  -0.0760511   -0.124628
 -0.0337591     0.0406795  -0.0903391   -0.0222484   -0.161059    0.0360058    0.218826    -0.144292    -0.0429217    0.182968    -0.0521507    0.168121    -0.04823       0.16174      -0.0393377   -0.00678969   0.0904546   -0.0460829   0.0103136  -0.304485     0.10448      0.00403017   -0.0451078    0.034348   -0.0619284   -0.142835
  0.0312896    -0.0236304  -0.162797     0.00918769  -0.0440854  -0.0688281    0.0293661    0.0303947   -0.0085106   -0.00933321  -0.109296    -0.0152873    0.0587383    -0.0415324     0.138778     0.0391748    0.0925597   -0.086345    0.0763932   0.0701434    0.0413517   -0.0624135    -0.201896     0.171028   -0.0509948    0.0223854
 -0.12777       0.0641299  -0.103051    -0.10967     -0.0957289  -0.010092     0.0430223   -0.0337139   -0.0557596    0.00424534   0.0525218    0.116482    -0.222106      0.113729     -0.0515614   -0.0773171    0.093461     0.0377785   0.131954    0.233721    -0.0404279    0.0900883    -0.123165     0.0235357  -0.0905796    0.0630326
  0.0168303    -0.0802594   0.0608558    0.0544746   -0.0764869   0.0373191    0.0500359   -0.0751696    0.0355594   -0.0640953   -0.0768792    0.385737     0.0689957     0.289566      0.163511     0.0589536    0.0285268    0.0660338  -0.044426    0.081135     0.0291638   -0.188074     -0.0961856    0.10842    -0.0417856    0.0213611
 -0.0272906     0.208077   -0.0949073   -0.150173    -0.033161   -0.111701     0.17021     -0.16319      0.123675    -0.170928     0.189442     0.0924296    0.134139     -0.080641     -0.11227      0.0240848   -0.033219     0.0561841   0.0666752   0.0916746   -0.023251     0.0660412    -0.00948433  -0.0620559  -0.202114     0.0935139
 -0.0314408     0.0555779   0.0751887    0.0444835    0.0348799  -0.107849    -0.0379654    0.0933286   -0.207071     0.0294212    0.0381922   -0.0611099   -0.134359      0.135677      0.00998952  -0.0608616   -0.197459    -0.259791    0.0211853   0.00852409   0.139011    -0.174943      0.0940917   -0.0140808   0.00522621   0.06553[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      7
│     17
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.047566
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      4
│      6
│      7
│      ⋮
│     25
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.005194
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      7
│     10
│     17
│     25
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.015533
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      4
│      6
│      7
│      ⋮
│     25
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.014203
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      7
│     17
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.029443
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      4
│      6
│      7
│      ⋮
│     27
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.981696
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      7
│     17
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.046749
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      4
│      6
│      7
│      ⋮
│     25
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.005223
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      7
│     10
│     17
│     25
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.015466
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      4
│      6
│      7
│      ⋮
│     25
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.014205
┌ Info: EM with 100000 data points 10 iterations avll -1.014205
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.130249     0.171827    0.0969529    0.115263    -0.106311     0.141888    0.0656396    0.0986147   -0.117504    -0.0541139    0.0057342    -0.0948175    -0.084356    0.0939262    0.0979377    -0.0120243    0.0556596   -0.0768264    0.11905     -0.122416     0.0947321   -0.272936    -0.0953303   -0.0144093   -0.0800562   -0.0567959
  0.0203866   -0.0223215  -0.160355    -0.0766856   -0.155992     0.0662724  -0.136273    -0.24202      0.122573     0.021823    -0.256942     -0.177048     -0.0414903  -0.0672716   -0.00614126   -0.0305718   -0.0783214    0.0717399    0.117546    -0.0774639   -0.0527642    0.046729    -0.0883831    0.0535226   -0.203017     0.0974343
 -0.0600676    0.0184579  -0.0583323    0.228998     0.185234     0.0719416  -0.0559302    0.0551023   -0.0140602   -0.0522254   -0.0583762     0.0526182     0.142369    0.0583432   -0.0532824    -0.0987036    0.0268404    0.0300687    0.0972761   -0.0778568    0.0523676    0.0396583    0.21946     -0.0551374    0.0600341    0.0843449
  0.103756     0.0959518  -0.0165546   -0.0150189    0.05853      0.0503322  -0.0040137    0.0922181   -0.00650308   0.146263    -0.0685718     0.0715372    -0.0403856  -0.0376307   -0.0124051     0.300297     0.0609932   -0.0158529   -0.0471432    0.084055    -0.0743213   -0.00365702   0.128049    -0.113639    -0.199966    -0.0625902
  0.0331073   -0.0176164   0.200102     0.195053     0.0245832    0.210051    0.137213    -0.00143808   0.143623    -0.0385738    0.0369462    -0.0659343    -0.0433516   0.1077       0.058398     -0.064292    -0.0538114    0.119808     0.0360575   -0.0980969   -0.0449652   -0.147962    -0.114845    -0.0581577   -0.0309548    0.0295917
  0.178012     0.250342   -0.210363     0.00942268  -0.101618     0.0486427  -0.0148403    0.0686186    0.0841077    0.0195974    0.0752935     0.0846771    -0.0117121   0.00389686   0.00233628   -0.00766866   0.0190554    0.123885    -0.14848      0.0411985    0.00263724   0.126454     0.0358909   -0.0178439    0.135452    -0.0586018
  0.146516     0.0473333   0.0251676   -0.0922189    0.111298     0.213593    0.0105469   -0.11293      0.0433247    0.00745914  -0.0862379    -0.0025565    -0.0128191   0.0114365   -0.0119542    -0.0260306    0.0916212   -0.0184578   -0.091189     0.0161103    0.0234017    0.010374     0.0568548    0.079528    -0.0972088   -0.00562885
  0.113398    -0.0169076   0.0554815   -0.0553627    0.0251995    0.051241   -0.129293     0.0671725    0.093187     0.0411629    0.116325     -0.0998959     0.126798    0.0204214   -0.224918     -0.163809     0.0500062   -0.0164181    0.0621565    0.0989944   -0.134262     0.0728356    0.18529     -0.0918816    0.108505    -0.15266
 -0.0556404    0.0619112  -0.233606    -0.00273171   0.0768042    0.150573   -0.106562    -0.112433    -0.0427604   -0.0694541    0.0760911     0.0595084    -0.0183987  -0.0689626    0.147968     -0.0126602    0.00948427  -0.218081    -0.07018      0.0162867   -0.055339    -0.006356    -0.0365185   -0.0534671    0.0444257    0.109641
  0.0855633    0.0114875   0.0635081    0.0633049    0.0467497   -0.0575625   0.0872372   -0.167482    -0.0236085    0.104451     0.0574232     0.0236411     0.0145595   0.0401944    0.263964     -0.194974    -0.052853     0.039779     0.0180997    0.0882411    0.121329    -0.0583259    0.0339441   -0.107843    -0.0658155   -0.0477418
 -0.0592761    0.0507681  -0.109773     0.0467491    0.0155586    0.084162   -0.0756566   -0.0405982   -0.13046      0.166224     0.00639474   -0.0660395     0.038073    0.0886669    0.0755699     0.149989    -0.0586959    0.113255     0.072093    -0.25942     -0.0285794   -0.093936    -0.107515     0.096064    -0.117817    -0.042702
  0.00792982   0.108302   -0.10304      0.0646054   -0.0577706    0.0584624   0.104498    -0.0396561   -0.0347152   -0.0361963   -0.0452584     0.0349064    -0.0616611  -0.084337     0.0400031    -0.123013     0.0540847   -0.00290855  -0.0274303   -0.00290703   0.331195     0.0117774   -0.140574     4.71272e-5  -0.0711002   -0.170652
 -0.0177332    0.146067   -0.00600523   0.0284016   -0.0227512    0.0516299  -0.00586835   0.00365053   0.0514086   -0.054113     0.0104028     0.0127392    -0.12587     0.073465     0.0329693    -0.083273     0.00294161  -0.0527261   -0.00499794   0.0869787   -0.0675994   -0.140155    -0.0585342   -0.0332981   -0.219014    -0.0426743
  0.0435248   -0.0659066   0.0881233   -0.183785     0.127324     0.25646     0.119999    -0.0516454   -0.114062    -0.0623553   -0.0696466     0.00882263   -0.100765   -0.142202     0.156379     -0.0512141    0.0514701    0.119189     0.125305     0.182585    -0.200836    -0.0377587    0.0747717   -0.0343289    0.0174816    0.0213703
  0.080998     0.131986    0.00339473  -0.105293    -0.0553976    0.056604    0.00763652  -0.0330566    0.151866    -0.00387373  -0.023508     -0.0460397    -0.0942341  -0.106199     0.00713945    0.0148488    0.0989097   -0.115697    -0.0689188   -0.00891836   0.186643     0.0665024    0.00205428  -0.089469     0.0885299    0.0163267
  0.0503595   -0.100619    0.121393     0.0920394   -0.154256    -0.051264    0.0724989   -0.0875996    0.158096     0.103643     0.00461106    0.0721969    -0.149543    0.0268319   -0.0724583     0.0203459    0.073689    -0.0479957    0.0299726    0.00335825   0.138047    -0.081478     0.150556     0.015029    -0.00255287   0.193143
  0.088486     0.0168673   0.0440837    0.140113     0.0713909    0.012487   -0.126945     0.0458858   -0.0808558   -0.11892      0.0621761    -0.0945873    -0.0100002   0.0017683    0.0552992     0.110223    -0.109615    -0.0676766    0.184682    -0.00308263   0.117431     0.194844    -0.0866671    0.0724263    0.0541948   -0.0277825
  0.0929452   -0.226289    0.0241683   -0.0235527   -0.110764     0.0421701  -0.126876    -0.145915    -0.00582515  -0.0810031   -0.0427856     0.179735      0.0826609  -0.0760786   -0.0518261    -0.0954143   -0.0633023    0.138073     0.14571      0.00767947  -0.0924807    0.147513     0.0593102    0.161473    -0.0605099   -0.104674
 -0.032042     0.0874545   0.12432     -0.00153323   0.16535     -0.186644   -0.0866166   -0.115795     0.0109744   -0.0495619    0.106281     -0.0136522     0.0773875  -0.0656932    0.000117273  -0.0127479   -0.0109017   -0.0426486   -0.133068    -0.098836     0.027996    -0.043167     0.0477394   -0.101989    -0.168763     0.0887934
 -0.0689896    0.0457293   0.217693    -0.270401     0.0083233   -0.0197038  -0.0349145    0.0780848   -0.0945537   -0.222947     0.0195806     0.0381923     0.0152197  -0.120585    -0.0216772     0.206382     0.214305     0.158184     0.0378971   -0.117534     0.101821    -0.0811958    0.183021    -0.106202     0.0833585   -0.0682487
 -0.0582874    0.127749    0.0137317    0.112031     0.0504768    0.0393903   0.110332    -0.19868      0.0228582    0.0563466    0.0368562     0.158199     -0.020277    0.0879247   -0.0485531     0.0440663    0.0112354    0.0153976    0.0269253   -0.083392     0.045953    -0.0635178   -0.0457977   -0.0627203   -0.130301    -0.0887648
  0.111311    -0.0560776  -0.0835637   -0.0518494    0.0498887    0.0659642   0.12206      0.0150621    0.137886     0.00914334  -0.0595056     0.0399911    -0.143794   -0.0162001    0.016938      0.103848    -0.208883    -0.0400182    0.061074     0.266005    -0.0508001   -0.0443915    0.0366854   -0.133204    -0.120294     0.00919858
 -0.180284    -0.0335874  -0.052986     0.0875979   -0.00370448   0.0326905  -0.0792724    0.0434818    0.185294    -0.147952    -0.0252081    -0.0223366    -0.106295   -0.0657979   -0.0185856    -0.227118    -0.0928691   -0.025484    -0.0341952   -0.122018     0.0798232    0.00836142  -0.0562628   -0.119185    -0.0315595   -0.0950845
 -0.104526    -0.0371287  -0.00816631   0.0824592    0.104498    -0.149947   -0.114312    -0.0212781    0.0209672    0.0706327   -0.00648233   -0.0466168     0.0338346   0.105938     0.0988657    -0.204444    -0.106835    -0.088479     0.151796    -0.107543    -0.156658    -0.0394364   -0.0022478    0.0224143   -0.033631     0.0705748
  0.0177108    0.0242913   0.151735     0.0975929   -0.136828     0.0940449   0.0221295    0.0778776   -0.031845     0.0954564   -0.0243359     0.187753     -0.0707892  -0.194048    -0.0460327    -0.021518    -0.0569396   -0.00983008   0.011343    -0.00902026  -0.0451938    0.166747    -0.0434835    0.0582373    0.104309    -0.0676181
  0.00776481  -0.276044    0.185579     0.10921      0.12057     -0.0899176  -0.202501     0.123677    -0.0106119   -0.128097     0.125236     -0.156205      0.0338047  -0.0381414    0.067191     -0.00358559   0.0877842    0.100047    -0.0245909    0.0734171    0.0341351    0.207219    -0.0353979   -0.216353     0.0584425    0.0836822
 -0.165773     0.0376448   0.00145916   0.0247557    0.111129     0.181729    0.228068     0.00284719   0.081289     0.159395    -0.0960142    -0.0508555     0.0926402   0.144364     0.0172614    -0.0421604    0.225566    -0.0752874   -0.0493191   -0.194378    -0.0600022   -0.0468527    0.0797604   -0.211015    -0.06667      0.00508333
 -0.103155     0.0489195  -0.0133167   -0.0261732    0.0326405    0.118621    0.172555     0.179017    -0.0379641   -0.20437     -0.000743781   0.0352914     0.244449   -0.0715095    0.119343     -0.0155929   -0.054744     0.246979    -0.125237    -0.0565665    0.167375     0.0750578   -0.132677     0.00326302   0.0420433   -0.160944
 -0.0427522    0.0511107  -0.0228725    0.0999883    0.00894309  -0.0130295  -0.19999     -0.00481831  -0.150833     0.075387     0.0203515     0.000583165   0.151783   -0.124784    -0.138286     -0.154251     0.140817     0.00939541   0.166733     0.0948837   -0.180248     0.06699     -0.230681    -0.00263918  -0.127796    -0.00785073
  0.0324075   -0.0222622  -0.093803    -0.094893    -0.105131    -0.0412646  -0.0267108   -0.0134673   -0.0232446    0.123478     0.185396     -0.152206      0.124119    0.0414188    0.24367       0.159257     0.0797028    0.00749245  -0.0511221   -0.107398    -0.0219111    0.0305301    0.067277    -0.115563     0.0956297   -0.0713073
  0.105507     0.120416    0.0612186   -0.204691     0.0846631    0.0525778  -0.18834      0.126981     0.00804854   0.00221867   0.0346772     0.0577202     0.0657111   0.0373528   -0.122968      0.0854337    0.0279831    0.163208    -0.13263      0.118919    -0.173782    -0.0218911   -0.114001    -0.0109518   -0.0914825   -0.10487
 -0.120449    -0.0553082   0.00652925  -0.0636843    0.0195452   -0.009286   -0.00936179   0.169068    -0.0618077   -0.13864     -0.160762     -0.0406519    -0.231951    0.153745    -0.0535175    -0.0952311    0.0279603   -0.113494    -0.0402077   -0.135008     0.00383118  -0.0199223   -0.084031    -0.098142     0.0195369   -0.152691kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4199112037677897
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419930
[ Info: iteration 2, average log likelihood -1.419876
[ Info: iteration 3, average log likelihood -1.419838
[ Info: iteration 4, average log likelihood -1.419795
[ Info: iteration 5, average log likelihood -1.419744
[ Info: iteration 6, average log likelihood -1.419683
[ Info: iteration 7, average log likelihood -1.419608
[ Info: iteration 8, average log likelihood -1.419506
[ Info: iteration 9, average log likelihood -1.419329
[ Info: iteration 10, average log likelihood -1.418974
[ Info: iteration 11, average log likelihood -1.418266
[ Info: iteration 12, average log likelihood -1.417116
[ Info: iteration 13, average log likelihood -1.415835
[ Info: iteration 14, average log likelihood -1.414949
[ Info: iteration 15, average log likelihood -1.414541
[ Info: iteration 16, average log likelihood -1.414389
[ Info: iteration 17, average log likelihood -1.414335
[ Info: iteration 18, average log likelihood -1.414315
[ Info: iteration 19, average log likelihood -1.414307
[ Info: iteration 20, average log likelihood -1.414304
[ Info: iteration 21, average log likelihood -1.414303
[ Info: iteration 22, average log likelihood -1.414302
[ Info: iteration 23, average log likelihood -1.414302
[ Info: iteration 24, average log likelihood -1.414301
[ Info: iteration 25, average log likelihood -1.414301
[ Info: iteration 26, average log likelihood -1.414301
[ Info: iteration 27, average log likelihood -1.414301
[ Info: iteration 28, average log likelihood -1.414301
[ Info: iteration 29, average log likelihood -1.414301
[ Info: iteration 30, average log likelihood -1.414300
[ Info: iteration 31, average log likelihood -1.414300
[ Info: iteration 32, average log likelihood -1.414300
[ Info: iteration 33, average log likelihood -1.414300
[ Info: iteration 34, average log likelihood -1.414300
[ Info: iteration 35, average log likelihood -1.414300
[ Info: iteration 36, average log likelihood -1.414300
[ Info: iteration 37, average log likelihood -1.414300
[ Info: iteration 38, average log likelihood -1.414300
[ Info: iteration 39, average log likelihood -1.414300
[ Info: iteration 40, average log likelihood -1.414300
[ Info: iteration 41, average log likelihood -1.414300
[ Info: iteration 42, average log likelihood -1.414300
[ Info: iteration 43, average log likelihood -1.414299
[ Info: iteration 44, average log likelihood -1.414299
[ Info: iteration 45, average log likelihood -1.414299
[ Info: iteration 46, average log likelihood -1.414299
[ Info: iteration 47, average log likelihood -1.414299
[ Info: iteration 48, average log likelihood -1.414299
[ Info: iteration 49, average log likelihood -1.414299
[ Info: iteration 50, average log likelihood -1.414299
┌ Info: EM with 100000 data points 50 iterations avll -1.414299
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4199298118281134
│     -1.4198761138235598
│      ⋮
└     -1.4142993475424495
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414314
[ Info: iteration 2, average log likelihood -1.414254
[ Info: iteration 3, average log likelihood -1.414203
[ Info: iteration 4, average log likelihood -1.414141
[ Info: iteration 5, average log likelihood -1.414061
[ Info: iteration 6, average log likelihood -1.413962
[ Info: iteration 7, average log likelihood -1.413843
[ Info: iteration 8, average log likelihood -1.413712
[ Info: iteration 9, average log likelihood -1.413580
[ Info: iteration 10, average log likelihood -1.413461
[ Info: iteration 11, average log likelihood -1.413367
[ Info: iteration 12, average log likelihood -1.413299
[ Info: iteration 13, average log likelihood -1.413253
[ Info: iteration 14, average log likelihood -1.413224
[ Info: iteration 15, average log likelihood -1.413204
[ Info: iteration 16, average log likelihood -1.413190
[ Info: iteration 17, average log likelihood -1.413179
[ Info: iteration 18, average log likelihood -1.413169
[ Info: iteration 19, average log likelihood -1.413161
[ Info: iteration 20, average log likelihood -1.413153
[ Info: iteration 21, average log likelihood -1.413146
[ Info: iteration 22, average log likelihood -1.413139
[ Info: iteration 23, average log likelihood -1.413132
[ Info: iteration 24, average log likelihood -1.413126
[ Info: iteration 25, average log likelihood -1.413119
[ Info: iteration 26, average log likelihood -1.413113
[ Info: iteration 27, average log likelihood -1.413106
[ Info: iteration 28, average log likelihood -1.413099
[ Info: iteration 29, average log likelihood -1.413092
[ Info: iteration 30, average log likelihood -1.413085
[ Info: iteration 31, average log likelihood -1.413078
[ Info: iteration 32, average log likelihood -1.413070
[ Info: iteration 33, average log likelihood -1.413063
[ Info: iteration 34, average log likelihood -1.413055
[ Info: iteration 35, average log likelihood -1.413047
[ Info: iteration 36, average log likelihood -1.413039
[ Info: iteration 37, average log likelihood -1.413031
[ Info: iteration 38, average log likelihood -1.413023
[ Info: iteration 39, average log likelihood -1.413015
[ Info: iteration 40, average log likelihood -1.413007
[ Info: iteration 41, average log likelihood -1.412998
[ Info: iteration 42, average log likelihood -1.412991
[ Info: iteration 43, average log likelihood -1.412983
[ Info: iteration 44, average log likelihood -1.412975
[ Info: iteration 45, average log likelihood -1.412968
[ Info: iteration 46, average log likelihood -1.412961
[ Info: iteration 47, average log likelihood -1.412954
[ Info: iteration 48, average log likelihood -1.412948
[ Info: iteration 49, average log likelihood -1.412942
[ Info: iteration 50, average log likelihood -1.412936
┌ Info: EM with 100000 data points 50 iterations avll -1.412936
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4143142027273996
│     -1.4142538006929652
│      ⋮
└     -1.4129357491677776
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412943
[ Info: iteration 2, average log likelihood -1.412886
[ Info: iteration 3, average log likelihood -1.412839
[ Info: iteration 4, average log likelihood -1.412784
[ Info: iteration 5, average log likelihood -1.412718
[ Info: iteration 6, average log likelihood -1.412638
[ Info: iteration 7, average log likelihood -1.412546
[ Info: iteration 8, average log likelihood -1.412447
[ Info: iteration 9, average log likelihood -1.412349
[ Info: iteration 10, average log likelihood -1.412258
[ Info: iteration 11, average log likelihood -1.412181
[ Info: iteration 12, average log likelihood -1.412116
[ Info: iteration 13, average log likelihood -1.412064
[ Info: iteration 14, average log likelihood -1.412020
[ Info: iteration 15, average log likelihood -1.411983
[ Info: iteration 16, average log likelihood -1.411951
[ Info: iteration 17, average log likelihood -1.411923
[ Info: iteration 18, average log likelihood -1.411896
[ Info: iteration 19, average log likelihood -1.411872
[ Info: iteration 20, average log likelihood -1.411848
[ Info: iteration 21, average log likelihood -1.411826
[ Info: iteration 22, average log likelihood -1.411805
[ Info: iteration 23, average log likelihood -1.411785
[ Info: iteration 24, average log likelihood -1.411765
[ Info: iteration 25, average log likelihood -1.411747
[ Info: iteration 26, average log likelihood -1.411730
[ Info: iteration 27, average log likelihood -1.411713
[ Info: iteration 28, average log likelihood -1.411698
[ Info: iteration 29, average log likelihood -1.411684
[ Info: iteration 30, average log likelihood -1.411670
[ Info: iteration 31, average log likelihood -1.411658
[ Info: iteration 32, average log likelihood -1.411646
[ Info: iteration 33, average log likelihood -1.411636
[ Info: iteration 34, average log likelihood -1.411626
[ Info: iteration 35, average log likelihood -1.411616
[ Info: iteration 36, average log likelihood -1.411608
[ Info: iteration 37, average log likelihood -1.411600
[ Info: iteration 38, average log likelihood -1.411593
[ Info: iteration 39, average log likelihood -1.411586
[ Info: iteration 40, average log likelihood -1.411579
[ Info: iteration 41, average log likelihood -1.411573
[ Info: iteration 42, average log likelihood -1.411568
[ Info: iteration 43, average log likelihood -1.411563
[ Info: iteration 44, average log likelihood -1.411558
[ Info: iteration 45, average log likelihood -1.411554
[ Info: iteration 46, average log likelihood -1.411549
[ Info: iteration 47, average log likelihood -1.411545
[ Info: iteration 48, average log likelihood -1.411542
[ Info: iteration 49, average log likelihood -1.411538
[ Info: iteration 50, average log likelihood -1.411535
┌ Info: EM with 100000 data points 50 iterations avll -1.411535
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.412942953333608
│     -1.4128860377852677
│      ⋮
└     -1.4115349545274898
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411542
[ Info: iteration 2, average log likelihood -1.411488
[ Info: iteration 3, average log likelihood -1.411441
[ Info: iteration 4, average log likelihood -1.411387
[ Info: iteration 5, average log likelihood -1.411320
[ Info: iteration 6, average log likelihood -1.411238
[ Info: iteration 7, average log likelihood -1.411139
[ Info: iteration 8, average log likelihood -1.411025
[ Info: iteration 9, average log likelihood -1.410899
[ Info: iteration 10, average log likelihood -1.410767
[ Info: iteration 11, average log likelihood -1.410636
[ Info: iteration 12, average log likelihood -1.410511
[ Info: iteration 13, average log likelihood -1.410395
[ Info: iteration 14, average log likelihood -1.410293
[ Info: iteration 15, average log likelihood -1.410205
[ Info: iteration 16, average log likelihood -1.410130
[ Info: iteration 17, average log likelihood -1.410067
[ Info: iteration 18, average log likelihood -1.410014
[ Info: iteration 19, average log likelihood -1.409969
[ Info: iteration 20, average log likelihood -1.409930
[ Info: iteration 21, average log likelihood -1.409895
[ Info: iteration 22, average log likelihood -1.409864
[ Info: iteration 23, average log likelihood -1.409836
[ Info: iteration 24, average log likelihood -1.409809
[ Info: iteration 25, average log likelihood -1.409785
[ Info: iteration 26, average log likelihood -1.409762
[ Info: iteration 27, average log likelihood -1.409740
[ Info: iteration 28, average log likelihood -1.409719
[ Info: iteration 29, average log likelihood -1.409699
[ Info: iteration 30, average log likelihood -1.409681
[ Info: iteration 31, average log likelihood -1.409662
[ Info: iteration 32, average log likelihood -1.409645
[ Info: iteration 33, average log likelihood -1.409628
[ Info: iteration 34, average log likelihood -1.409612
[ Info: iteration 35, average log likelihood -1.409596
[ Info: iteration 36, average log likelihood -1.409581
[ Info: iteration 37, average log likelihood -1.409566
[ Info: iteration 38, average log likelihood -1.409551
[ Info: iteration 39, average log likelihood -1.409537
[ Info: iteration 40, average log likelihood -1.409523
[ Info: iteration 41, average log likelihood -1.409509
[ Info: iteration 42, average log likelihood -1.409496
[ Info: iteration 43, average log likelihood -1.409483
[ Info: iteration 44, average log likelihood -1.409470
[ Info: iteration 45, average log likelihood -1.409458
[ Info: iteration 46, average log likelihood -1.409446
[ Info: iteration 47, average log likelihood -1.409434
[ Info: iteration 48, average log likelihood -1.409423
[ Info: iteration 49, average log likelihood -1.409412
[ Info: iteration 50, average log likelihood -1.409401
┌ Info: EM with 100000 data points 50 iterations avll -1.409401
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.411541896997514
│     -1.4114883504656257
│      ⋮
└     -1.4094007715989274
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409399
[ Info: iteration 2, average log likelihood -1.409328
[ Info: iteration 3, average log likelihood -1.409261
[ Info: iteration 4, average log likelihood -1.409183
[ Info: iteration 5, average log likelihood -1.409087
[ Info: iteration 6, average log likelihood -1.408969
[ Info: iteration 7, average log likelihood -1.408826
[ Info: iteration 8, average log likelihood -1.408663
[ Info: iteration 9, average log likelihood -1.408487
[ Info: iteration 10, average log likelihood -1.408307
[ Info: iteration 11, average log likelihood -1.408131
[ Info: iteration 12, average log likelihood -1.407966
[ Info: iteration 13, average log likelihood -1.407816
[ Info: iteration 14, average log likelihood -1.407684
[ Info: iteration 15, average log likelihood -1.407569
[ Info: iteration 16, average log likelihood -1.407469
[ Info: iteration 17, average log likelihood -1.407384
[ Info: iteration 18, average log likelihood -1.407310
[ Info: iteration 19, average log likelihood -1.407246
[ Info: iteration 20, average log likelihood -1.407189
[ Info: iteration 21, average log likelihood -1.407138
[ Info: iteration 22, average log likelihood -1.407092
[ Info: iteration 23, average log likelihood -1.407051
[ Info: iteration 24, average log likelihood -1.407012
[ Info: iteration 25, average log likelihood -1.406977
[ Info: iteration 26, average log likelihood -1.406944
[ Info: iteration 27, average log likelihood -1.406912
[ Info: iteration 28, average log likelihood -1.406883
[ Info: iteration 29, average log likelihood -1.406855
[ Info: iteration 30, average log likelihood -1.406829
[ Info: iteration 31, average log likelihood -1.406804
[ Info: iteration 32, average log likelihood -1.406780
[ Info: iteration 33, average log likelihood -1.406758
[ Info: iteration 34, average log likelihood -1.406736
[ Info: iteration 35, average log likelihood -1.406715
[ Info: iteration 36, average log likelihood -1.406695
[ Info: iteration 37, average log likelihood -1.406676
[ Info: iteration 38, average log likelihood -1.406658
[ Info: iteration 39, average log likelihood -1.406641
[ Info: iteration 40, average log likelihood -1.406624
[ Info: iteration 41, average log likelihood -1.406607
[ Info: iteration 42, average log likelihood -1.406591
[ Info: iteration 43, average log likelihood -1.406576
[ Info: iteration 44, average log likelihood -1.406561
[ Info: iteration 45, average log likelihood -1.406546
[ Info: iteration 46, average log likelihood -1.406532
[ Info: iteration 47, average log likelihood -1.406518
[ Info: iteration 48, average log likelihood -1.406504
[ Info: iteration 49, average log likelihood -1.406491
[ Info: iteration 50, average log likelihood -1.406478
┌ Info: EM with 100000 data points 50 iterations avll -1.406478
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4093990544557606
│     -1.4093282815485426
│      ⋮
└     -1.4064783164993817
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4199112037677897
│     -1.4199298118281134
│     -1.4198761138235598
│     -1.4198381693532052
│      ⋮
│     -1.406504308652568
│     -1.4064911323264488
└     -1.4064783164993817
32×26 Array{Float64,2}:
 -0.140399     0.0735138  -0.153163   -0.0816428    0.37871      0.194256     0.153233    -0.166382   -0.123492    -0.274335     0.167886     0.403643     0.138752   -0.886485    -0.273193    -0.124175   -0.233589    -0.296022    -0.336655     -0.343838    0.3532      0.0184563   -0.498144    -0.27012    -0.453405   -0.965227
 -0.350896     0.283771   -0.433624    0.186803    -0.100502     0.249055     0.211124     0.113352   -0.437579    -0.566024    -0.500581    -0.220484     0.17134    -0.654227     0.00434475  -0.049881   -0.0666716   -0.0864976    0.368665      0.247773    0.116095    0.499349     0.260064     0.214764   -0.552155   -0.450835
 -0.0771164    0.0383288   0.0970178   0.0563973    0.115246    -0.0164429   -0.0908748    0.174661    0.0571134   -0.00170041  -0.0128067    0.0464787   -0.0861911  -0.0930232    0.0444284   -0.156428   -0.0320658   -0.0927676    0.0897642    -0.0852552   0.0325047  -0.0044512   -0.00581426  -0.05594    -0.213662   -0.0936161
  0.11006      0.100604   -0.150737   -0.11205     -0.0974742    0.164121     0.15238     -0.277794   -0.0215131   -0.0489163    0.0442742   -0.133854     0.197938    0.152981     0.00196338   0.126695    0.00805352   0.2221      -0.0388489     0.156636    0.0869201   0.0873298   -0.00436583   0.108934    0.341333   -0.0103271
 -0.203927    -0.153397   -0.139554    0.19017     -0.134119     0.203455    -0.141457     0.256327    0.563087     0.0344003   -0.551198    -0.564715    -0.326112    0.522793     0.689412    -0.159954   -0.159116     0.228806     0.375621      0.0845548   0.053941    0.159668     0.343789     0.458262    0.324765    0.280399
  0.366776     0.315705   -0.3837      0.868867    -0.410977     0.334838    -0.647919     0.145442    0.322761    -0.291399    -0.169413     0.430762    -0.0463065  -0.0385443    0.118467     0.15436    -0.242684     0.109923    -0.0706094    -0.0178462  -0.315942    0.378125     0.494552     0.127406    0.572225    0.391647
  0.0560236    0.586666   -0.106032   -0.17941     -0.14149     -0.525143     0.408094     0.490709   -0.348668    -0.0942653   -0.248908    -0.0904431    0.418952    0.324477    -0.496443    -0.513535    0.180948     0.334891     0.000173544   0.206009   -0.113206   -0.0714947    0.647083    -0.117273   -0.134558    0.220547
 -0.109534     0.958059   -0.217076    0.114707    -0.0360397    0.30694      0.560115     0.300017    0.356877     0.575683    -0.393935    -0.204889    -0.440488   -0.3053      -0.0876253   -0.158539   -0.125031    -0.163023     0.117529      0.321633   -0.401284    0.18735     -0.0919561    0.0150218   0.227261    0.416667
 -0.0146478    0.0995838  -0.0601432   0.226843     0.00187706  -0.19667     -0.199715     0.220301   -0.0243358    0.579678     0.34047      0.0601066    0.085464    0.0598564   -0.132757    -0.152217    0.491434     0.294865    -0.606108     -0.194      -0.0132256  -0.708991     0.166634    -0.612057   -0.105285    0.08575
 -0.295698     0.408321    0.213697    0.568148    -0.129435    -0.240826     0.0194988    0.420975   -0.0549776    0.274745     0.0913015    0.306578    -0.429716   -0.571941     0.078379    -0.495373    0.638929     0.0120898    0.313692     -0.331141    0.444678   -0.532667    -0.184006     0.123339    0.0124442  -0.170038
 -0.470285     0.380167    0.367605    0.101131     0.0801848    0.0922304   -0.00129085  -0.482949   -0.2394       0.629935    -0.186468     0.634947     0.10052     0.451336     0.55154     -0.0787019  -0.403346     0.0883779    0.199137      0.10092     0.158505   -0.472091    -0.159526     0.0772064  -0.463437    0.141223
 -0.949199     0.278662    0.71389     0.581884     0.495821     0.287601     0.158976     0.87719     0.111639     0.272902     0.458415    -0.254578    -0.40634     0.0332865    0.614442    -0.163789   -0.0622492    0.360506     0.245218      0.058551   -0.109043    0.0413634    0.0806659   -0.684877   -0.23637    -0.0415557
  0.2771      -0.250649   -0.244922   -0.167879    -0.00315203   0.197631    -0.282122    -0.3592      0.214082    -0.213582    -0.364225     0.330269    -0.315806   -0.07014      0.197931     0.222295   -0.523338    -0.339192    -0.0868119    -0.224061   -0.168108    0.217994    -0.231927    -0.355987   -0.304343   -0.0636091
  0.0626911   -0.15302     0.70997    -0.106388     0.236214    -0.236565     0.224237    -0.0820412   0.101294    -0.161269    -0.520315     0.273049    -0.41565     0.0070118    0.0612028    0.418776    0.939424    -0.588851    -0.468309     -0.160298   -0.188101   -0.219918    -0.22718     -0.523029   -0.623651    0.338943
 -0.0542845   -0.224855    0.0269965   0.148029     0.40577      0.00625374  -0.493899     0.292124   -0.261069     0.00211999   0.689577    -0.0978833    0.105977   -0.00945074  -0.110571     0.0849512   0.0789014    0.0491924    0.62786      -0.589157   -0.0462372   0.0127708   -0.441378    -0.0696034   0.027636    0.604673
 -0.0936437   -0.393298    0.774639    0.155215     0.0971962   -0.205349     0.136331     0.0129954   0.0469637   -0.136016     0.42876     -0.28158     -0.177868    0.243889    -0.0743393    0.290215    0.324939    -0.358951     0.568501      0.529898   -0.262422    0.148006    -0.160389     0.129762   -0.113486    0.00731989
 -0.314663     0.270954   -0.840297    0.0485093    0.120591     0.475136    -0.387006     0.412344   -0.0623044    0.0974719    0.612424    -0.392483     0.162647   -0.355496    -0.0983807   -0.429166   -1.03726      0.482492     0.267135      0.190757    0.0352326   0.201915     0.187547     0.158586    0.0520094  -0.593379
  0.325854     0.256485   -0.303853   -0.298443    -0.158968     0.547434     0.128088    -0.193516   -0.428402     0.253277    -0.0215889    0.188648     0.336572   -0.0402853    0.125213    -0.79358    -0.561784     0.519747     0.263012     -0.379672   -0.111348    0.00128545  -0.0729317    0.147551    0.964994    0.0436402
  0.271776     0.563303    0.309855   -0.894063     0.3756       0.099089     0.326185    -0.198117   -0.307645    -0.563665     0.152411    -0.187525     0.28282     0.25128      0.137622     0.247201   -0.58247      0.00205424   0.112873      0.249375    0.470307    0.591398    -0.323582    -0.105196    0.38402    -0.0970031
  0.143665     0.022118   -0.458909   -0.591632    -0.322964     0.310739     0.304809    -0.479012    0.502882    -0.32543     -0.0322325   -0.340924     0.309632    0.342416    -0.434089     0.320036   -0.29207      0.0219132    0.194573      0.581414    0.0820643   0.588411    -0.0255918    0.879387    0.214378   -0.175687
  0.211643    -0.6676      0.206172   -0.297224    -0.240846     0.576378    -0.0215958   -0.178781   -0.125418    -0.259162     0.412936    -0.251533     0.113776    0.103986     0.247912     0.14938     0.307317     0.443849    -0.3654        0.180254   -0.53993    -0.229081     0.314644    -0.474918    0.0814984  -0.191575
 -0.295136    -0.517033    0.386822   -0.0694046    0.247867    -0.164506    -0.358966    -0.382509    0.0143495    0.0857397    0.482528    -0.363454     0.181607    0.151354     0.111086     0.364259    0.306759     0.17702     -0.495116     -0.192887    0.737705    0.118974     0.157975     0.157355    0.0375208  -0.363036
  0.882021    -0.305245    0.200723   -0.258698    -0.271864    -0.157772     0.0409257   -0.146175    0.502984    -0.0500968   -0.0164081    0.378663    -0.633755    0.177377    -0.195064    -0.541583    0.317686    -0.120454    -0.161753     -0.110959   -0.0526952  -0.128785    -0.532379     0.142118    0.313804    0.0893323
  0.726735    -0.7239     -0.0233957  -0.33008     -0.119624    -0.136866    -0.33471     -0.462227   -0.464716    -0.189422     0.0555863    0.0542714    0.785659    0.091129    -0.698317    -0.198289    0.0405705   -0.0782743    0.0427063    -0.115844   -0.23628     0.167785    -0.191736     0.1377     -0.164327   -0.0456136
  0.00596206  -0.113681    0.467556    0.3553       0.0658635   -0.370101    -0.0678278    0.35709    -0.0847879    0.30711      0.241504     0.123128    -0.0108416  -0.25696     -0.112837    -0.335555    0.752467     0.0436899   -0.389541     -0.449505   -0.0869152  -0.351425     0.270463    -0.550678   -0.316192    0.0159986
 -0.011893    -0.0568959   0.0246982  -0.109004    -0.212239     0.391001    -0.106939    -0.0759515  -0.279693    -0.310493    -0.120727     0.0260569    0.158332    0.0867245   -0.131745    -0.186017    0.0267514    0.201763     0.445183     -0.151656   -0.160842    0.247273    -0.195455     0.23398    -0.195351   -0.0166289
 -0.0268004   -0.101836   -0.105344    0.269793     0.458255    -0.695493    -0.623933     0.507877   -0.0976849    0.0993847   -0.0998633    0.436205    -0.263692    0.0646394    0.0644957    0.173895   -0.0237373   -0.693701     0.293464     -0.232372    0.128616   -0.204002     0.0135717   -0.10978    -0.918116    0.323863
 -0.792466    -0.164699   -0.499096    0.28634     -0.349697    -0.0158762   -0.199472     0.323284    0.814243     0.72629     -0.318106    -0.229225    -0.223681   -0.240213    -0.282678     0.540849    0.41552     -0.146514    -0.071103      0.430758   -0.452113   -0.366737     0.61586     -0.102837   -0.713235   -0.227939
  0.330548     0.234771   -0.581238    0.00633471  -0.0615523   -0.983188     0.113418    -0.162885    0.625679     0.360516     0.00270957  -0.172688     0.111753    0.244198    -0.115005     0.440135   -0.0128981   -0.317966    -0.34702      -0.177726    0.371425   -0.577439    -0.326515     0.354384    0.897465    0.474177
 -0.0283365    0.0672771  -0.251246    0.172894     0.516638     0.783131    -0.26252     -0.336363    0.28804      0.438912     0.17304     -0.385378    -0.462943   -0.204696     0.587903     0.554699   -0.249897    -0.0429914   -0.0344239    -0.129132    0.162863   -0.343727    -0.566715    -0.191692    0.519511    0.248279
 -0.101412     0.268887   -0.120919   -0.0399438    0.0570676    0.505713     0.791382    -0.167486    0.353671    -0.220306    -0.495345     0.00398023  -0.472438    0.11561      0.360981     0.117078   -0.791221    -0.185778    -0.599266      0.294195   -0.270932    0.15665      0.571372    -1.10676    -0.265637   -0.0811012
  0.02915      0.369541    0.603138    0.219259    -0.263097    -0.417773     0.512895    -0.349609   -0.00186356  -0.285218    -0.529907     0.0911452    0.0499922   0.181612     0.443339     0.509595    0.321175     0.0528078   -0.802669      0.526911   -0.0376834   0.113007     0.683662    -0.167813    0.193372   -0.751712[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406466
[ Info: iteration 2, average log likelihood -1.406454
[ Info: iteration 3, average log likelihood -1.406442
[ Info: iteration 4, average log likelihood -1.406431
[ Info: iteration 5, average log likelihood -1.406419
[ Info: iteration 6, average log likelihood -1.406409
[ Info: iteration 7, average log likelihood -1.406398
[ Info: iteration 8, average log likelihood -1.406388
[ Info: iteration 9, average log likelihood -1.406378
[ Info: iteration 10, average log likelihood -1.406369
┌ Info: EM with 100000 data points 10 iterations avll -1.406369
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.881710e+05
      1       7.000970e+05      -1.880740e+05 |       32
      2       6.859939e+05      -1.410316e+04 |       32
      3       6.807415e+05      -5.252314e+03 |       32
      4       6.781744e+05      -2.567105e+03 |       32
      5       6.766427e+05      -1.531725e+03 |       32
      6       6.755919e+05      -1.050797e+03 |       32
      7       6.747432e+05      -8.487369e+02 |       32
      8       6.740596e+05      -6.835801e+02 |       32
      9       6.735180e+05      -5.416140e+02 |       32
     10       6.730845e+05      -4.334725e+02 |       32
     11       6.727387e+05      -3.458444e+02 |       32
     12       6.724221e+05      -3.165442e+02 |       32
     13       6.721295e+05      -2.926422e+02 |       32
     14       6.718848e+05      -2.446813e+02 |       32
     15       6.716454e+05      -2.393892e+02 |       32
     16       6.714229e+05      -2.224780e+02 |       32
     17       6.712199e+05      -2.030037e+02 |       32
     18       6.710338e+05      -1.860820e+02 |       32
     19       6.708491e+05      -1.847345e+02 |       32
     20       6.706642e+05      -1.849297e+02 |       32
     21       6.704883e+05      -1.759013e+02 |       32
     22       6.703178e+05      -1.704454e+02 |       32
     23       6.701472e+05      -1.706297e+02 |       32
     24       6.699794e+05      -1.677655e+02 |       32
     25       6.698231e+05      -1.563011e+02 |       32
     26       6.696785e+05      -1.446812e+02 |       32
     27       6.695581e+05      -1.203484e+02 |       32
     28       6.694409e+05      -1.172044e+02 |       32
     29       6.693535e+05      -8.735487e+01 |       32
     30       6.692709e+05      -8.267781e+01 |       32
     31       6.691892e+05      -8.170530e+01 |       32
     32       6.691107e+05      -7.849992e+01 |       32
     33       6.690375e+05      -7.317303e+01 |       32
     34       6.689651e+05      -7.242738e+01 |       32
     35       6.688927e+05      -7.239978e+01 |       32
     36       6.688232e+05      -6.947225e+01 |       32
     37       6.687582e+05      -6.497019e+01 |       32
     38       6.686950e+05      -6.323775e+01 |       32
     39       6.686324e+05      -6.256404e+01 |       32
     40       6.685709e+05      -6.151597e+01 |       32
     41       6.685172e+05      -5.371395e+01 |       32
     42       6.684696e+05      -4.754829e+01 |       32
     43       6.684259e+05      -4.376022e+01 |       32
     44       6.683815e+05      -4.439425e+01 |       32
     45       6.683399e+05      -4.160431e+01 |       32
     46       6.683040e+05      -3.587813e+01 |       32
     47       6.682696e+05      -3.440230e+01 |       32
     48       6.682316e+05      -3.801425e+01 |       32
     49       6.681966e+05      -3.501867e+01 |       32
     50       6.681669e+05      -2.968609e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 668166.8820373308)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418704
[ Info: iteration 2, average log likelihood -1.413602
[ Info: iteration 3, average log likelihood -1.412106
[ Info: iteration 4, average log likelihood -1.410877
[ Info: iteration 5, average log likelihood -1.409605
[ Info: iteration 6, average log likelihood -1.408585
[ Info: iteration 7, average log likelihood -1.407998
[ Info: iteration 8, average log likelihood -1.407700
[ Info: iteration 9, average log likelihood -1.407531
[ Info: iteration 10, average log likelihood -1.407417
[ Info: iteration 11, average log likelihood -1.407331
[ Info: iteration 12, average log likelihood -1.407261
[ Info: iteration 13, average log likelihood -1.407203
[ Info: iteration 14, average log likelihood -1.407153
[ Info: iteration 15, average log likelihood -1.407109
[ Info: iteration 16, average log likelihood -1.407070
[ Info: iteration 17, average log likelihood -1.407034
[ Info: iteration 18, average log likelihood -1.407002
[ Info: iteration 19, average log likelihood -1.406971
[ Info: iteration 20, average log likelihood -1.406942
[ Info: iteration 21, average log likelihood -1.406915
[ Info: iteration 22, average log likelihood -1.406888
[ Info: iteration 23, average log likelihood -1.406861
[ Info: iteration 24, average log likelihood -1.406835
[ Info: iteration 25, average log likelihood -1.406809
[ Info: iteration 26, average log likelihood -1.406783
[ Info: iteration 27, average log likelihood -1.406757
[ Info: iteration 28, average log likelihood -1.406732
[ Info: iteration 29, average log likelihood -1.406706
[ Info: iteration 30, average log likelihood -1.406681
[ Info: iteration 31, average log likelihood -1.406657
[ Info: iteration 32, average log likelihood -1.406633
[ Info: iteration 33, average log likelihood -1.406609
[ Info: iteration 34, average log likelihood -1.406587
[ Info: iteration 35, average log likelihood -1.406565
[ Info: iteration 36, average log likelihood -1.406545
[ Info: iteration 37, average log likelihood -1.406525
[ Info: iteration 38, average log likelihood -1.406506
[ Info: iteration 39, average log likelihood -1.406488
[ Info: iteration 40, average log likelihood -1.406472
[ Info: iteration 41, average log likelihood -1.406456
[ Info: iteration 42, average log likelihood -1.406440
[ Info: iteration 43, average log likelihood -1.406426
[ Info: iteration 44, average log likelihood -1.406412
[ Info: iteration 45, average log likelihood -1.406399
[ Info: iteration 46, average log likelihood -1.406387
[ Info: iteration 47, average log likelihood -1.406375
[ Info: iteration 48, average log likelihood -1.406364
[ Info: iteration 49, average log likelihood -1.406354
[ Info: iteration 50, average log likelihood -1.406343
┌ Info: EM with 100000 data points 50 iterations avll -1.406343
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.365878     -0.373378    -0.14323      0.471245    0.195991   -0.193873   -0.503416    0.807929     0.321848     0.312119    -0.145262    0.0229937  -0.341508    -0.125815    -0.283216    0.239557     0.425729   -0.28715     0.193898   -0.14171    -0.214953    -0.191448    0.335567   -0.133632   -0.902547     0.120125
 -0.442828      0.327049    -0.133673     0.368965    0.262476   -0.731097   -0.184169   -0.0878189   -0.0436469    0.12734     -0.555943    0.504829   -0.0701006    0.338331     0.0994706  -0.307497    -0.326203   -0.597552    0.369952   -0.169118    0.931961    -0.0741567  -0.137281    0.703664   -0.312211     0.0927698
 -0.352792      0.561348    -0.142673     0.442484    0.141343    0.304458    0.198343    0.46729      0.232313    -0.280458    -0.365586   -0.316557   -0.418794    -0.492977     0.427282    0.0156087   -0.267935   -0.168347    0.105904    0.144976    0.100148     0.480791    0.28334    -0.275413   -0.0444527   -0.362126
  0.140181      0.040877     0.0385477    0.244248    0.0129899  -0.100503   -0.392954    0.07805     -0.0297441    0.328242    -0.0383401   0.566701   -0.254125    -0.0896903    0.181686   -0.24694      0.232649   -0.0778357  -0.0582646  -0.675437    0.140078    -0.435836   -0.0543214  -0.258414   -0.174524     0.136434
  0.866993     -0.811092    -0.0359492   -0.31614    -0.119985   -0.107425   -0.464111   -0.572617    -0.247446    -0.118138     0.170433    0.143514    0.624054     0.156083    -0.842388   -0.148982     0.158123   -0.0536807   0.096076   -0.0612984  -0.207499    -0.0925842  -0.323302    0.20028    -0.121737     0.15094
  0.156032      0.817188    -0.257111    -0.136245   -0.193998   -0.473775    0.504604    0.589707    -0.126799     0.14685     -0.298622   -0.0254247   0.271518     0.296709    -0.581888   -0.574953     0.102713    0.262298   -0.0814056   0.265857   -0.243021    -0.164797    0.570866   -0.246219   -0.068294     0.429445
  0.000933225   0.00741973   1.22327      0.141135    0.0768687  -0.661123    0.208354   -0.215798     0.0506339   -0.297232    -0.310783    0.21617    -0.467015     0.437994     0.16574     0.64973      0.942394   -0.690497   -0.43073    -0.163608   -0.253522    -0.0904957   0.108263   -0.407816   -0.349853     0.252291
  0.224335     -0.150016    -0.407298    -0.371825   -0.372933    0.138044    0.392399   -0.48694      0.311664    -0.438969    -0.252395   -0.485604    0.332718     0.226878    -0.633434    0.276696    -0.0417498  -0.152679    0.233785    0.371635   -0.131289     0.828395    0.235817    0.78601     0.168059    -0.144406
 -0.226293      0.347371    -0.764325     0.178191   -0.170422    0.159426   -0.58503    -9.37366e-5  -0.00441217   0.434991     0.601151   -0.280815    0.261511    -0.424595    -0.10298    -0.34009     -0.980303    0.589272   -0.134282    0.113315    0.00540516   0.0470354   0.795064   -0.0891995   0.00883296  -0.73663
 -0.193409      0.390757    -0.523823     0.0495955   0.237281    0.646576   -0.160534    0.478374     0.125887     0.323417     0.342454   -0.143142    0.0498277   -0.0502703   -0.238191   -0.492579    -0.65888     0.321998    0.758218    0.0811565   0.0934399    0.151389   -0.548824    0.653903    0.582573     0.184857
 -0.346539      0.390656     0.248248     0.676817   -0.390146   -0.199332    0.194183    0.520196     0.0393443    0.38371      0.30012    -0.0152635  -0.46919     -0.533798     0.135497   -0.339341     1.0555      0.235463    0.13289    -0.0176848   0.0888109   -0.732999   -0.0203644  -0.0214329   0.179655    -0.0732696
 -0.389492      0.223094    -0.459124    -0.0329121  -0.223462    0.467922    0.0734495  -0.115979    -0.863925    -0.615571    -0.343611   -0.135516    0.601241    -0.598687    -0.183053   -0.197826    -0.0550933   0.170795    0.533036    0.142352    0.057699     0.404806    0.0267234   0.355864   -0.689356    -0.309975
 -0.197228     -0.421395     0.648079     0.0101205   0.159709   -0.298816   -0.125436   -0.187564    -0.16836      0.372141     0.603722   -0.247089    0.446141     0.689735     0.0618303  -0.0398695    0.726426    0.494717    0.172375   -0.249759    0.13018     -0.239671   -0.0781713   0.340074    0.177623     0.435446
 -0.475438     -0.148404     0.751792     0.164059    0.0799078   0.495416    0.26843     0.064428    -0.0834578    0.133382    -0.0395247   0.23794    -0.121285     0.64461      0.453829   -0.287063    -0.287822    0.308087    0.468957    0.182177   -0.711645    -0.17072    -0.184097   -0.34171    -0.622307     0.128649
  0.141649      0.207837     0.206341    -0.0948557  -0.369267    0.035314    0.589905   -0.39148     -0.0674544   -0.0114406   -0.284906    0.203724    0.303824     0.0561125    0.0681045   0.00171448   0.236795    0.327357   -0.813688    0.473909   -0.0835261   -0.111722    0.425012   -0.0631669  -0.0820307   -1.06919
  0.285738      0.169303    -0.0352327   -0.321684    0.296479    0.211681    0.496701   -0.344759     0.28504     -0.0570303   -0.896155    0.439743   -0.30863     -0.395779    -0.0201983   0.258538    -0.0737961  -0.428912   -0.194572    0.197773   -0.186898     0.208449   -0.196548   -0.635175   -0.582509     0.264816
  0.1119        0.0277401    0.00310963  -0.0567805   0.0281779   0.167916   -0.0864156  -0.0904327    0.0479418   -0.126669     0.0305061   0.092148   -0.00648252  -0.0619107    0.0157764  -0.0168587   -0.0117285   0.0135446  -0.0146968  -0.0712773   0.0851194    0.0452521  -0.106568   -0.0748888  -0.0980836   -0.116736
 -0.577303     -0.453546     0.423308     0.0715721   0.446624    0.895703    0.198926   -0.0106201    0.139193     0.210047     0.533201   -0.897828   -0.389279     0.276551     0.905631    0.202392     0.0253771   0.182234   -0.453488   -0.0803561   0.00789231  -0.373909    0.242488   -0.401598    0.542607    -0.244818
 -0.133444     -0.463032     0.340968    -0.062987    0.202437   -0.0843825  -0.595387   -0.444907    -0.0501688   -0.173662     0.523729   -0.025797    0.0547307   -0.100978     0.137626    0.640553    -0.0605758  -0.157406   -0.144331   -0.01472     0.346396     0.439235   -0.156747    0.0654338  -0.155372    -0.326762
 -0.036505     -0.0677928   -0.0458541    0.0371858   0.157565   -0.0800939  -0.08027     0.0975709    0.026904     0.00026648   0.209966   -0.329523    0.177632     0.100266    -0.19397     0.185614     0.253763    0.111147   -0.140747    0.0917954   0.121646    -0.177985    0.170538   -0.151008   -0.00142838   0.0761163
 -0.0734988     0.338432     0.113803     0.0823822   0.817902   -0.0718492  -0.698517    0.358494    -0.347668     0.499387     0.609657    0.124118   -0.0830468   -0.14404      0.501016    0.249761    -0.0238448  -0.097573    0.011493   -0.196046   -0.033896    -0.572771   -0.457271   -0.892345   -0.178581     0.622673
  0.635649      0.448926    -0.057002     0.0895605  -0.208906    0.272906   -0.0847467  -0.414442    -0.287859     0.00640926  -0.202509    0.643809    0.197695     0.284203     0.0897098  -0.0680507   -0.443119    0.292075    0.0636567  -0.156321   -0.141243     0.324404    0.0496169   0.0631852   0.914862     0.534215
  0.525062     -0.881784     0.28649     -0.302815   -0.472791    0.139738   -0.0140001  -0.126516    -0.218273    -0.345989     0.126006   -0.231099   -0.187666    -0.260435     0.131998    0.254626     0.277851    0.113359   -0.655151    0.108482   -0.84925     -0.0852039   0.589905   -1.16346    -0.226432     0.512543
 -0.108489      0.214242     0.058993     0.0382362  -0.0389146   0.128675    0.112909   -0.00974193   0.0420499    0.0850333   -0.0893805  -0.0488762  -0.0727599    0.0343508    0.149832   -0.104215    -0.130064    0.0371447   0.202042    0.108904   -0.0539404    0.18501    -0.0280193   0.142125    0.0736443    0.0694359
 -0.139251      0.322569    -0.670969     0.167624   -0.266774   -0.0331837   0.0836273  -0.417577     0.549078     0.759638    -0.191853   -0.211357   -0.106297     0.00548882   0.136797    0.490251    -0.215775   -0.183724   -0.336438    0.149429   -0.0109514   -0.731272   -0.242996    0.142345    0.453296     0.352489
 -0.173125     -0.173791    -0.0812287    0.165058   -0.591109   -0.0469258  -0.240278    0.458679     0.171512    -0.157838    -0.462637   -0.543539   -0.0750157    0.749641     0.787066   -0.137473    -0.161391    0.423226    0.184204    0.390052   -0.170149     0.366356    0.770931    0.585486    0.436827     0.301276
  0.271397     -0.291844    -0.148656    -0.216961   -0.153271    0.149382   -0.0812594  -0.17845     -0.0696965   -0.39153      0.0182312   0.32932     0.0209047   -0.246308    -0.0668064  -0.19295     -0.145794   -0.101461   -0.10464    -0.0487701  -0.0821079    0.022657   -0.186428   -0.0994084  -0.191973    -0.572774
  0.18138       0.320537    -0.0230149   -1.02741     0.348916    0.12847     0.468443   -0.0367175   -0.185348    -0.423815     0.416366   -0.452866    0.479871     0.07655      0.0161174   0.120983    -0.525342    0.0567903   0.0497261   0.380232    0.501425     0.287835   -0.273812   -0.0142122   0.381988    -0.376371
  0.659443     -0.329474     0.272757    -0.0892626  -0.0888592  -0.523654    0.0163076   0.340999     0.765915    -0.180686     0.120308    0.0858132  -0.752212     0.261542    -0.152664   -0.18233      0.34449    -0.335423   -0.314043    0.0282855  -0.104411     0.0271345  -0.66996     0.286411    0.350435     0.199739
 -0.255739      0.0180485    0.328492     0.0366913   0.357768   -0.114253    0.270417    0.0406268   -0.341753     0.136564     0.252406    0.443017    0.105072    -0.907053    -0.318862   -0.418373     0.163419   -0.350602   -0.103193   -0.564309    0.344442    -0.202151   -0.327643   -0.486926   -0.592435    -0.672706
  0.0634855    -0.2875      -0.206154     0.0173077   0.173413    0.30425    -0.242429    0.497292    -0.860676    -0.446577     0.330795   -0.23059     0.225356    -0.107313    -0.204834   -0.47545      0.0484716   0.221863    0.260892   -1.35875    -0.493412     0.419319   -0.238376   -0.138079    0.477721     0.162698
  0.37513      -0.201001    -0.298503    -0.247471   -0.0604652   0.775499   -0.0538619  -0.713962     0.75735     -0.144572    -0.286688   -0.314905   -0.348301     0.244443     0.492283    0.154906    -0.250565    0.339012    0.270466   -0.163664    0.130746     0.0923869  -0.0963299   0.0904753   0.436472     0.0950688[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406334
[ Info: iteration 2, average log likelihood -1.406324
[ Info: iteration 3, average log likelihood -1.406315
[ Info: iteration 4, average log likelihood -1.406306
[ Info: iteration 5, average log likelihood -1.406298
[ Info: iteration 6, average log likelihood -1.406290
[ Info: iteration 7, average log likelihood -1.406282
[ Info: iteration 8, average log likelihood -1.406274
[ Info: iteration 9, average log likelihood -1.406267
[ Info: iteration 10, average log likelihood -1.406260
┌ Info: EM with 100000 data points 10 iterations avll -1.406260
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
