Julia Version 1.5.0-DEV.234
Commit f2d68ad6eb (2020-02-05 16:31 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed GaussianMixtures ─── v0.3.0
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed LegacyStrings ────── v0.4.1
  Installed Rmath ────────────── v0.6.0
  Installed Compat ───────────── v2.2.0
  Installed Blosc ────────────── v0.5.1
  Installed NearestNeighbors ─── v0.4.4
  Installed QuadGK ───────────── v2.3.1
  Installed PDMats ───────────── v0.9.11
  Installed CMake ────────────── v1.1.2
  Installed SpecialFunctions ─── v0.9.0
  Installed CMakeWrapper ─────── v0.2.3
  Installed BinaryProvider ───── v0.5.8
  Installed SortingAlgorithms ── v0.3.1
  Installed Arpack ───────────── v0.4.0
  Installed URIParser ────────── v0.4.0
  Installed StaticArrays ─────── v0.12.1
  Installed Missings ─────────── v0.4.3
  Installed OrderedCollections ─ v1.1.0
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed HDF5 ─────────────── v0.12.5
  Installed ScikitLearnBase ──── v0.5.0
  Installed Clustering ───────── v0.13.3
  Installed Distributions ────── v0.22.4
  Installed BinDeps ──────────── v1.0.0
  Installed Distances ────────── v0.8.2
  Installed FileIO ───────────── v1.2.1
  Installed DataAPI ──────────── v1.1.0
  Installed Parameters ───────── v0.12.0
  Installed StatsFuns ────────── v0.9.3
  Installed JLD ──────────────── v0.9.2
  Installed Arpack_jll ───────── v3.5.0+2
  Installed StatsBase ────────── v0.32.0
  Installed FillArrays ───────── v0.8.4
  Installed DataStructures ───── v0.17.9
#=#=#                                                                         ##O#- #                                                                       ##O=#  #                                                                      #                                                                          2.7%#####                                                                      7.0%#########                                                                 12.9%###############                                                           22.1%########################                                                  33.9%##################################                                        48.2%###############################################                           66.5%###############################################################           87.6%######################################################################## 100.0%
#=#=#                                                                         ##O#- #                                                                       ##O=#  #                                                                      ######################################################################## 100.0%
#=#=#                                                                         ##O#- #                                                                       ##O=#  #                                                                      ######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_a5pF2r/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -1.0406946158727674e7, [17365.227050625683, 82634.77294937431], [5087.155294348531 -6016.1692338730945 23460.7035089236; -5231.005801680914 6352.352153972926 -23605.9354592919], [[18353.14097996816 -1351.5287305563888 3783.5535838707624; -1351.5287305563886 17929.599007399785 -5801.9098795841655; 3783.5535838707615 -5801.9098795841655 35698.84784391201], [81324.15953465742 1638.088041058376 -4064.2893494068376; 1638.088041058376 82003.03478552564 5482.051710635077; -4064.2893494068376 5482.051710635076 64167.81974857692]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.723259e+03
      1       9.202152e+02      -8.030436e+02 |        6
      2       8.775655e+02      -4.264964e+01 |        2
      3       8.631137e+02      -1.445185e+01 |        0
      4       8.631137e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 863.1136677499226)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.081312
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.823624
[ Info: iteration 2, lowerbound -3.694808
[ Info: iteration 3, lowerbound -3.543038
[ Info: iteration 4, lowerbound -3.348965
[ Info: iteration 5, lowerbound -3.133140
[ Info: iteration 6, lowerbound -2.932054
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.768849
[ Info: iteration 8, lowerbound -2.660317
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.590924
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.524216
[ Info: iteration 11, lowerbound -2.468953
[ Info: iteration 12, lowerbound -2.426613
[ Info: iteration 13, lowerbound -2.389847
[ Info: iteration 14, lowerbound -2.357654
[ Info: iteration 15, lowerbound -2.330536
[ Info: iteration 16, lowerbound -2.312389
[ Info: iteration 17, lowerbound -2.307580
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.302921
[ Info: iteration 19, lowerbound -2.299260
[ Info: iteration 20, lowerbound -2.299256
[ Info: iteration 21, lowerbound -2.299254
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Fri Feb  7 19:18:54 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Fri Feb  7 19:19:02 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Fri Feb  7 19:19:05 2020: EM with 272 data points 0 iterations avll -2.081312
5.8 data points per parameter
, Fri Feb  7 19:19:07 2020: GMM converted to Variational GMM
, Fri Feb  7 19:19:16 2020: iteration 1, lowerbound -3.823624
, Fri Feb  7 19:19:16 2020: iteration 2, lowerbound -3.694808
, Fri Feb  7 19:19:16 2020: iteration 3, lowerbound -3.543038
, Fri Feb  7 19:19:16 2020: iteration 4, lowerbound -3.348965
, Fri Feb  7 19:19:16 2020: iteration 5, lowerbound -3.133140
, Fri Feb  7 19:19:16 2020: iteration 6, lowerbound -2.932054
, Fri Feb  7 19:19:16 2020: dropping number of Gaussions to 7
, Fri Feb  7 19:19:16 2020: iteration 7, lowerbound -2.768849
, Fri Feb  7 19:19:16 2020: iteration 8, lowerbound -2.660317
, Fri Feb  7 19:19:16 2020: dropping number of Gaussions to 5
, Fri Feb  7 19:19:16 2020: iteration 9, lowerbound -2.590924
, Fri Feb  7 19:19:16 2020: dropping number of Gaussions to 3
, Fri Feb  7 19:19:16 2020: iteration 10, lowerbound -2.524216
, Fri Feb  7 19:19:16 2020: iteration 11, lowerbound -2.468953
, Fri Feb  7 19:19:16 2020: iteration 12, lowerbound -2.426613
, Fri Feb  7 19:19:16 2020: iteration 13, lowerbound -2.389847
, Fri Feb  7 19:19:16 2020: iteration 14, lowerbound -2.357654
, Fri Feb  7 19:19:16 2020: iteration 15, lowerbound -2.330536
, Fri Feb  7 19:19:16 2020: iteration 16, lowerbound -2.312389
, Fri Feb  7 19:19:16 2020: iteration 17, lowerbound -2.307580
, Fri Feb  7 19:19:16 2020: dropping number of Gaussions to 2
, Fri Feb  7 19:19:16 2020: iteration 18, lowerbound -2.302921
, Fri Feb  7 19:19:16 2020: iteration 19, lowerbound -2.299260
, Fri Feb  7 19:19:16 2020: iteration 20, lowerbound -2.299256
, Fri Feb  7 19:19:16 2020: iteration 21, lowerbound -2.299254
, Fri Feb  7 19:19:16 2020: iteration 22, lowerbound -2.299254
, Fri Feb  7 19:19:16 2020: iteration 23, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 24, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 25, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 26, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 27, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 28, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 29, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 30, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 31, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 32, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 33, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 34, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 35, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 36, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 37, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 38, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 39, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 40, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 41, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 42, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 43, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 44, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 45, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 46, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 47, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 48, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 49, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: iteration 50, lowerbound -2.299253
, Fri Feb  7 19:19:16 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398616, 178.04509222601382]
β = [95.95490777398616, 178.04509222601382]
m = [2.00022925777537 53.85198717246129; 4.250300733269911 79.28686694436185]
ν = [97.95490777398616, 180.04509222601382]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.37587636119484097 -0.008953123827346214; 0.0 0.01274866477740938], [0.18404155547484582 -0.007644049042327287; 0.0 0.00858170516633356]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000006
avll from stats: -0.9971307838719491
avll from llpg:  -0.9971307838719489
avll direct:     -0.9971307838719489
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9974984575068533
avll from llpg:  -0.9974984575068532
avll direct:     -0.9974984575068532
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
  0.0440035   0.0398014   -0.188915    -0.147529    -0.0983169   -0.0517579   0.197172    -0.0588146    0.0719598   -0.0564405   -0.128003    -0.00313126  -0.0329854   -0.0678224   -0.0377495   0.0954808    0.0372862    0.000306     0.140715      0.0714059     0.069523     0.0630677   -0.157098     0.115956    -0.0469821    0.0510361
 -0.0922456   0.0640793    0.135721    -0.007807    -0.0357914   -0.165955   -0.125353    -0.0739202    0.0461037   -0.214045    -0.10814      0.0894872    0.0627778    0.0840303    0.194963    0.0154281   -0.10359     -0.209638     0.0455317    -0.0249654     0.0703841   -0.046272     0.128535     0.185806    -0.131168    -0.0462906
  0.114452   -0.200843    -0.186656     0.0411107   -0.165338    -0.0267836  -0.199728     0.125441    -0.0887915   -0.0934141   -0.0090372   -0.0254958   -0.114383     0.115393    -0.0498647   0.0560933    0.0765871    0.329788     0.000551251  -0.184448     -0.0871586   -0.0642698   -0.0554851   -0.190427     0.100229    -0.0326711
  0.0675031   0.0428445    0.0400655    0.161764    -0.0576546    0.0799624   0.00263861  -0.0565007   -0.0167309   -0.147046    -0.0929257    0.00143735   0.00511304  -0.0700477    0.134278    0.0496731    0.0327495   -0.223568    -0.0386626     0.100059     -0.0709791    0.102233     0.0144368   -0.36206      0.0211001    0.0132714
  0.111333   -0.13522     -0.0211028   -0.296127     0.0805459   -0.188242   -0.0259136    0.00328356  -0.0586249   -0.0800754    0.0867393    0.0858611   -0.0198526   -0.119227     0.0416303  -0.0314078   -0.0520321    0.142473    -0.0434932     0.0782365     0.134909     0.0774782   -0.140832     0.100362    -0.0698899   -0.0645875
  0.116034    0.0384174   -0.109666    -0.117329    -0.017265    -0.0402474   0.147583    -0.0743454    0.0322443    0.041317    -0.0076396    0.0416798   -0.0319414    0.016161    -0.041379    0.0306465    0.00218927   0.0397768   -0.0506764    -0.0722284     0.0108919    0.0817508   -0.0755487   -0.0393525    0.304332     0.0806791
  0.167336   -0.0927892   -0.0655655    0.0174965   -0.189804    -0.0427936  -0.0389147    0.00487294  -0.069699    -0.0510967    0.146362     0.016781    -0.0264477   -0.0204361   -0.125479   -0.0178664   -0.0426328   -0.136288     0.222378      0.0197654     0.0420899    0.127982    -0.00952116   0.277473    -0.119924     0.0242221
  0.0417569   0.0850125    0.199517    -0.244248    -0.128184    -0.0982426   0.0746262    0.115845    -0.167118     0.0967347    0.0694445    0.0870051   -0.0295291   -0.182149    -0.109628    0.153167    -0.0381486    0.106712    -0.115339     -0.0102939    -0.0306211    0.0433698   -0.044789     0.0567221   -0.105875    -0.0353038
  0.0109047  -0.156657    -0.0125153    0.0382882   -0.0371508   -0.109024   -0.244242    -0.0396835    0.0769715   -0.0915732    0.31269      0.0903256    0.106548    -0.0462968    0.0449691   0.0709695    0.164294    -0.0403397   -0.232101     -0.00137775   -0.0985375    0.0456694   -0.04704     -0.16484      0.0377531    0.180146
  0.088109    0.0799753    0.0152774    0.060699    -0.109032     0.0905486  -0.220457     0.135182    -0.00128291   0.0223897   -0.0657938    0.0947407    0.175953     0.0653878   -0.0291686  -0.0277298   -0.0547167   -0.106633    -0.109242     -0.0398515     0.037975     0.0342317   -0.171802    -0.122255    -0.128565     0.0872026
  0.104597   -0.0277033    0.125165     0.113268     0.0583698   -0.17546    -0.0168981   -0.173579    -0.241058     0.00782389   0.0846857    0.107258    -0.0574497    0.0695937   -0.0300834  -0.0288402    0.069139    -0.0235125   -0.332159     -0.0709139     0.0873399   -0.0623936    0.166121    -0.133056     0.0620723   -0.139225
 -0.176258   -0.0107642    0.0254309    0.0721921    0.113513    -0.16115    -0.211615     0.116462     0.0398466    0.219363    -0.0114207    0.0731093    0.1329      -0.166594    -0.175027    0.0518641    0.00626111  -0.061638    -0.0179843     0.0315166     0.0613001    0.184317     0.0416524   -0.0140087    0.0681989    0.064802
  0.117151   -0.0159597   -0.0291243   -0.106808     0.147956    -0.0442661  -0.125761    -0.0873291    0.139005    -0.151768     0.128391    -0.0671711    0.0426178    0.097076     0.0942415  -0.234335    -0.0531056    3.47752e-5   0.144197     -0.00502952    0.00342514  -0.0653648   -0.106825    -0.00384244   0.101206     0.0328568
 -0.128884    0.085578     0.0347816    0.00530483   0.0482686    0.085373   -0.0307249   -0.123547     0.0840904   -0.118869     0.0901505   -0.0979013   -0.104353     0.0420152   -0.0635713   0.340694     0.0203753    0.109972    -0.0805177    -0.00359168    0.0450453    0.0249744   -0.0327884    0.120182     0.0433825   -0.174771
  0.055372   -0.0538695   -0.1625      -0.0302622    0.00819625  -0.0185792  -0.0279586   -0.0248154   -0.138814     0.0134361    0.0343442   -0.019491    -0.253216    -0.0307307    0.0338401   0.1224       0.0291127   -0.0693941    0.0597173    -0.030004      0.077381     0.06589      0.0637451    0.108108     0.0775611   -0.215595
  0.0782949  -0.0730572   -0.0132425   -0.033387    -0.0776044   -0.0883327  -0.162591     0.0327118   -0.0432063    0.00409316   0.0506119    0.0840454    0.124814    -0.00791564  -0.118468    0.0829839   -0.0176604    0.119773     0.0703982    -0.0743313    -0.0300302   -0.0515652   -0.0857692   -0.0189632   -0.197371     0.00655173
  0.0645382   0.0769148   -0.148698    -0.15524      0.0395195    0.0727978  -0.13594     -0.170588    -0.139329     0.0110576    0.119042     0.177763    -0.0141111    0.119164     0.0317941   0.0464713    0.0777733    0.111736     0.160206      0.00284272    0.0487306    0.144274     0.0276136    0.0974316    0.109626     0.00765164
 -0.0650906   0.0428163    0.168591     0.203034    -0.0513957    0.158234   -0.170129    -0.125343    -0.0937647    0.148562     0.0344236   -0.0300088   -0.168908     0.0866067    0.0139379  -0.0159766    0.224365    -0.057025    -0.0399198    -0.0212855     0.0463778   -0.0188396    0.151999    -0.168989    -0.0816862   -0.186304
  0.106124   -0.0287391    0.139728     0.00140046   0.160125    -0.119647    0.0778889   -0.118926    -0.10246      0.0609036    0.177797    -0.125765    -0.16187      0.00549596  -0.0632338  -0.0645305    0.0260764    0.0160739   -0.0658003    -0.0423713    -0.203637     0.00703492  -0.0335927    0.244019     0.0265961   -0.0470108
 -0.158703   -0.00966736  -0.00168436  -0.107431     0.105886     0.0225838  -0.00933351   0.0906086    0.0544231   -0.04342     -0.102157    -0.120111    -0.0910149   -0.0316933   -0.106931   -0.0502617    0.0576418    0.00204079  -0.0176375     0.0959765    -0.017143     0.109908    -0.0640354   -0.0497413    0.0542299    0.124971
 -0.124934   -0.0631341   -0.138757     0.0276361   -0.0452241    0.0818219  -0.0119544    0.0162306   -0.0714121    0.0495722   -0.0722344   -0.00868508  -0.12287     -0.0622886    0.0563263   0.223209    -0.0189068   -0.0920213    0.0985203     0.0495453     0.0203989   -0.0430995    0.0237479    0.0461339    0.0405005   -0.0474911
  0.0540765  -0.17759     -0.0893514    0.0632931    0.0183043   -0.020802   -0.170807    -0.199851     0.08887      0.11619      0.0684168    0.155977     0.124151     0.0257104    0.0495256   0.00165722  -0.0873137    0.0702971    0.058536      0.196584      0.00270157  -0.112315    -0.0961852    0.109221    -0.101448    -0.0569905
 -0.0345346  -0.0411189    0.101322     0.223844    -0.0667281    0.104487    0.00987554   0.0756301   -0.114473     0.0424377    0.0673976   -0.00116636   0.0339289    0.0208843    0.042276   -0.0927792    0.165084    -0.025719     0.0167787     0.000467656   0.096867     0.0465833   -0.0118486    0.0287405    0.00436343   0.127109
 -0.0893352  -0.0558565    0.115034     0.046746     0.157318    -0.107732    0.0514423    0.00606291  -0.117312     0.014762    -0.076081     0.220626    -0.0639162   -0.256698     0.064126    0.0690565   -0.00268665   0.0350137   -0.18559       0.163209     -0.106396    -0.058714     0.201299     0.111503    -0.00683353   0.225813
 -0.206432   -0.0596088   -0.0994159    0.0918711    0.0387012   -0.0138332   0.0659598    0.0587294    0.0582808   -0.10221     -0.125403     0.117076    -0.10966      0.237705    -0.160066   -0.0118174    0.0810415   -0.0281357   -0.00895157   -0.101979     -0.0533781   -0.146564     0.0376223    0.00468651   0.0550868    0.0591589
  0.0786694  -0.122082    -0.119658    -0.187933    -0.00830237  -0.17082     0.151637     0.0772515    0.128259     0.059848    -0.178617    -0.00740909   0.134306     0.0752223    0.0389169  -0.0589179   -0.0604436   -0.145265     0.0560691     0.107722      0.142644     0.0783653   -0.167305     0.0222935    0.153982    -0.119263
 -0.112279   -0.043617    -0.0165931    0.0251868   -0.193964    -0.0086998   0.0530399    0.024596     0.0827059   -0.0518731    0.142884    -0.0416229   -0.00980628  -0.0114643    0.103758   -0.0505726   -0.0338921   -0.244684     0.00532049    0.0225763     0.0401773   -0.0604928    0.0424846   -0.0646628   -0.0459453   -0.0438242
 -0.0782964   0.0705551   -0.0412648   -0.148434    -0.0197163    0.0538424  -0.105971    -0.181002     0.145012    -0.0732698    0.00028154   0.0248502   -0.0985261   -0.112461    -0.158133    0.0274852    0.0160766   -0.0950281   -0.0771881    -0.14496      -0.120635    -0.0349327   -0.103696     0.0510699    0.162491    -0.0358703
  0.0739585  -0.0951796    0.0543096   -0.0912509   -0.0285498    0.0249863   0.00898902   0.160878     0.229266    -0.0601863   -0.0487219    0.011459     0.105992    -0.129528    -0.0888484   0.0260766    0.0944707   -0.15542     -0.0720795    -0.00574699    0.145606    -0.0172333   -0.136532     0.189999     0.0457758    0.0332147
 -0.0209276   0.0112871   -0.0411451   -0.0204764   -0.0546957    0.0801259   0.0411383    0.0229947   -0.0198134   -0.13332     -0.00471952   0.0104455   -0.103861    -0.0559101    0.0385811   0.069993     0.00418376   0.0266892   -0.0651204    -0.00957828   -0.0418582    0.00755873   0.0134437    0.0266797    0.0211581   -0.0655849
 -0.0136248  -0.113491     0.0799147   -0.186857    -0.14538      0.186968    0.0791294   -0.0299647   -0.156715     0.0485095    0.0246532    0.0193368    0.0127149    0.169007    -0.0477997   0.00121854  -0.137642    -0.0836038    0.0470058    -0.209083      0.208305    -0.0426572   -0.0364318   -0.159966     0.048188     0.0958113
 -0.0281886  -0.139496     0.0909701    0.0116245    0.0629753    0.0542221  -0.0840201    0.074815    -0.0357463   -0.11927     -0.174856     0.0205456    0.0376341    0.0917863    0.0363581  -0.0726247    0.0582053   -0.0999428   -0.00822342   -0.122704     -0.0927562   -0.163809    -0.214516     0.0526206    0.0679544    0.0475029kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3734029549646314
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.373479
[ Info: iteration 2, average log likelihood -1.373362
[ Info: iteration 3, average log likelihood -1.371400
[ Info: iteration 4, average log likelihood -1.353312
[ Info: iteration 5, average log likelihood -1.332926
[ Info: iteration 6, average log likelihood -1.330568
[ Info: iteration 7, average log likelihood -1.330230
[ Info: iteration 8, average log likelihood -1.330070
[ Info: iteration 9, average log likelihood -1.329968
[ Info: iteration 10, average log likelihood -1.329888
[ Info: iteration 11, average log likelihood -1.329811
[ Info: iteration 12, average log likelihood -1.329738
[ Info: iteration 13, average log likelihood -1.329674
[ Info: iteration 14, average log likelihood -1.329621
[ Info: iteration 15, average log likelihood -1.329580
[ Info: iteration 16, average log likelihood -1.329548
[ Info: iteration 17, average log likelihood -1.329524
[ Info: iteration 18, average log likelihood -1.329505
[ Info: iteration 19, average log likelihood -1.329488
[ Info: iteration 20, average log likelihood -1.329474
[ Info: iteration 21, average log likelihood -1.329461
[ Info: iteration 22, average log likelihood -1.329450
[ Info: iteration 23, average log likelihood -1.329440
[ Info: iteration 24, average log likelihood -1.329431
[ Info: iteration 25, average log likelihood -1.329422
[ Info: iteration 26, average log likelihood -1.329414
[ Info: iteration 27, average log likelihood -1.329405
[ Info: iteration 28, average log likelihood -1.329397
[ Info: iteration 29, average log likelihood -1.329390
[ Info: iteration 30, average log likelihood -1.329383
[ Info: iteration 31, average log likelihood -1.329376
[ Info: iteration 32, average log likelihood -1.329370
[ Info: iteration 33, average log likelihood -1.329364
[ Info: iteration 34, average log likelihood -1.329359
[ Info: iteration 35, average log likelihood -1.329355
[ Info: iteration 36, average log likelihood -1.329351
[ Info: iteration 37, average log likelihood -1.329347
[ Info: iteration 38, average log likelihood -1.329344
[ Info: iteration 39, average log likelihood -1.329341
[ Info: iteration 40, average log likelihood -1.329338
[ Info: iteration 41, average log likelihood -1.329336
[ Info: iteration 42, average log likelihood -1.329334
[ Info: iteration 43, average log likelihood -1.329332
[ Info: iteration 44, average log likelihood -1.329331
[ Info: iteration 45, average log likelihood -1.329329
[ Info: iteration 46, average log likelihood -1.329328
[ Info: iteration 47, average log likelihood -1.329327
[ Info: iteration 48, average log likelihood -1.329326
[ Info: iteration 49, average log likelihood -1.329326
[ Info: iteration 50, average log likelihood -1.329325
┌ Info: EM with 100000 data points 50 iterations avll -1.329325
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.373478734894827
│     -1.3733621086489556
│      ⋮
└     -1.3293251078131234
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.329432
[ Info: iteration 2, average log likelihood -1.329317
[ Info: iteration 3, average log likelihood -1.328601
[ Info: iteration 4, average log likelihood -1.322486
[ Info: iteration 5, average log likelihood -1.307182
[ Info: iteration 6, average log likelihood -1.296769
[ Info: iteration 7, average log likelihood -1.292768
[ Info: iteration 8, average log likelihood -1.290889
[ Info: iteration 9, average log likelihood -1.289768
[ Info: iteration 10, average log likelihood -1.288919
[ Info: iteration 11, average log likelihood -1.288067
[ Info: iteration 12, average log likelihood -1.287039
[ Info: iteration 13, average log likelihood -1.285870
[ Info: iteration 14, average log likelihood -1.284750
[ Info: iteration 15, average log likelihood -1.283764
[ Info: iteration 16, average log likelihood -1.282889
[ Info: iteration 17, average log likelihood -1.282057
[ Info: iteration 18, average log likelihood -1.281167
[ Info: iteration 19, average log likelihood -1.280286
[ Info: iteration 20, average log likelihood -1.279555
[ Info: iteration 21, average log likelihood -1.279048
[ Info: iteration 22, average log likelihood -1.278752
[ Info: iteration 23, average log likelihood -1.278587
[ Info: iteration 24, average log likelihood -1.278493
[ Info: iteration 25, average log likelihood -1.278431
[ Info: iteration 26, average log likelihood -1.278384
[ Info: iteration 27, average log likelihood -1.278343
[ Info: iteration 28, average log likelihood -1.278306
[ Info: iteration 29, average log likelihood -1.278270
[ Info: iteration 30, average log likelihood -1.278233
[ Info: iteration 31, average log likelihood -1.278196
[ Info: iteration 32, average log likelihood -1.278155
[ Info: iteration 33, average log likelihood -1.278109
[ Info: iteration 34, average log likelihood -1.278056
[ Info: iteration 35, average log likelihood -1.277994
[ Info: iteration 36, average log likelihood -1.277920
[ Info: iteration 37, average log likelihood -1.277828
[ Info: iteration 38, average log likelihood -1.277718
[ Info: iteration 39, average log likelihood -1.277591
[ Info: iteration 40, average log likelihood -1.277446
[ Info: iteration 41, average log likelihood -1.277271
[ Info: iteration 42, average log likelihood -1.277062
[ Info: iteration 43, average log likelihood -1.276827
[ Info: iteration 44, average log likelihood -1.276574
[ Info: iteration 45, average log likelihood -1.276304
[ Info: iteration 46, average log likelihood -1.276015
[ Info: iteration 47, average log likelihood -1.275720
[ Info: iteration 48, average log likelihood -1.275426
[ Info: iteration 49, average log likelihood -1.275138
[ Info: iteration 50, average log likelihood -1.274847
┌ Info: EM with 100000 data points 50 iterations avll -1.274847
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3294316113124047
│     -1.329316524369508
│      ⋮
└     -1.274847072918708
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.274670
[ Info: iteration 2, average log likelihood -1.274157
[ Info: iteration 3, average log likelihood -1.273110
[ Info: iteration 4, average log likelihood -1.266591
[ Info: iteration 5, average log likelihood -1.247345
[ Info: iteration 6, average log likelihood -1.231605
[ Info: iteration 7, average log likelihood -1.224693
[ Info: iteration 8, average log likelihood -1.220784
[ Info: iteration 9, average log likelihood -1.218053
[ Info: iteration 10, average log likelihood -1.215604
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.213077
[ Info: iteration 12, average log likelihood -1.220953
[ Info: iteration 13, average log likelihood -1.214380
[ Info: iteration 14, average log likelihood -1.211981
[ Info: iteration 15, average log likelihood -1.210891
[ Info: iteration 16, average log likelihood -1.210443
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.210173
[ Info: iteration 18, average log likelihood -1.219660
[ Info: iteration 19, average log likelihood -1.213523
[ Info: iteration 20, average log likelihood -1.211340
[ Info: iteration 21, average log likelihood -1.210464
[ Info: iteration 22, average log likelihood -1.210140
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.209950
[ Info: iteration 24, average log likelihood -1.219491
[ Info: iteration 25, average log likelihood -1.213372
[ Info: iteration 26, average log likelihood -1.211218
[ Info: iteration 27, average log likelihood -1.210355
[ Info: iteration 28, average log likelihood -1.210041
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.209855
[ Info: iteration 30, average log likelihood -1.219389
[ Info: iteration 31, average log likelihood -1.213270
[ Info: iteration 32, average log likelihood -1.211127
[ Info: iteration 33, average log likelihood -1.210264
[ Info: iteration 34, average log likelihood -1.209957
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.209778
[ Info: iteration 36, average log likelihood -1.219307
[ Info: iteration 37, average log likelihood -1.213203
[ Info: iteration 38, average log likelihood -1.211079
[ Info: iteration 39, average log likelihood -1.210227
[ Info: iteration 40, average log likelihood -1.209932
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.209760
[ Info: iteration 42, average log likelihood -1.219283
[ Info: iteration 43, average log likelihood -1.213190
[ Info: iteration 44, average log likelihood -1.211073
[ Info: iteration 45, average log likelihood -1.210221
[ Info: iteration 46, average log likelihood -1.209927
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.209755
[ Info: iteration 48, average log likelihood -1.219271
[ Info: iteration 49, average log likelihood -1.213183
[ Info: iteration 50, average log likelihood -1.211066
┌ Info: EM with 100000 data points 50 iterations avll -1.211066
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2746699096612626
│     -1.2741568849919487
│      ⋮
└     -1.211066157331238
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.210429
[ Info: iteration 2, average log likelihood -1.209814
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.207786
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.194737
[ Info: iteration 5, average log likelihood -1.168014
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.144176
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.128907
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.136268
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.129320
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.125193
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.119443
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.130365
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.124940
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.121838
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.117175
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.128312
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.122947
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.120148
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.115939
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.127547
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.122690
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.120132
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.115976
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.127550
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.122668
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.120117
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.115920
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.127567
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.122643
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.120106
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.115863
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.127585
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.122619
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.120107
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.115819
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.127605
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.122594
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.120118
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.115783
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.127626
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.122568
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.120134
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.115751
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.127648
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.122541
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.120153
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.115721
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.127670
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.122514
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.120172
┌ Info: EM with 100000 data points 50 iterations avll -1.120172
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2104292929979303
│     -1.209813573694907
│      ⋮
└     -1.1201723153193301
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.115938
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.115543
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│      4
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.113283
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.088912
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.033629
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      4
│     10
│     14
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.034575
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      3
│      6
│      ⋮
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.017040
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.025596
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      6
│     10
│     14
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.010944
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      5
│      ⋮
│     24
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.001483
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      4
│      6
│     14
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.031622
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      5
│     10
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.002368
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     14
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.008613
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      5
│     22
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.012828
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      6
│     10
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.010185
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.004889
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      6
│     22
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.021079
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      5
│     10
│      ⋮
│     23
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.003529
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     14
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.013320
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      5
│     22
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.016504
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      6
│      ⋮
│     23
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.011192
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      3
│      5
│     13
│     14
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.009197
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      4
│      6
│      ⋮
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.010096
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      5
│     10
│     16
│     23
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.006234
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.004590
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      5
│     21
│     22
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.021117
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      4
│      6
│     10
│     16
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.020290
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -0.998326
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      4
│      6
│     23
│     24
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.014216
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.010200
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.003897
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.025179
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      4
│      6
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.009043
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     24
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -0.998886
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      4
│      6
│     22
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.023713
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.012571
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     14
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.012353
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.014719
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      6
│      ⋮
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -0.991854
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     24
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.006164
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      4
│      6
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.027224
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.000742
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     14
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.020075
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.018173
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      6
│      ⋮
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -0.994256
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     24
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.006189
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      4
│      6
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.027246
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.000772
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     14
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.020083
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.018171
┌ Info: EM with 100000 data points 50 iterations avll -1.018171
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.11593751675267
│     -1.1155432508426018
│      ⋮
└     -1.0181710756698483
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3734029549646314
│     -1.373478734894827
│     -1.3733621086489556
│     -1.3714002880933562
│      ⋮
│     -1.0007720918634468
│     -1.020083248094885
└     -1.0181710756698483
32×26 Array{Float64,2}:
  0.0803061    0.138026    -0.17264     0.0859538    -0.188569      0.0486692   -0.16604      0.252284      0.0307142     0.0278565    0.0700815    0.0991667    0.184025     0.0669696   -0.0213801    0.296239    -0.0551632   -0.136014     -1.02353     -0.0419414    0.0648341    0.0407972   -0.214711    -0.121146    -0.129766     0.0878991
  0.0900932    0.0220015    0.171809    0.0457342    -0.0431236     0.126382    -0.219858    -0.0160288    -0.0175153     0.0207715   -0.301029     0.085294     0.200776     0.0661474   -0.0370118   -0.281413    -0.0564585   -0.0953985     0.751166    -0.0447271    0.0304765    0.0207224   -0.195968    -0.122515    -0.133134     0.0824329
 -0.00215005  -0.184973     0.0357394   0.0333348    -0.0575828    -0.0990783   -0.227926    -0.0530116     0.120677     -0.0974868    0.280847     0.123794     0.104527     0.00578607   0.064099     0.0660398    0.141025     0.0164787    -0.213515     0.0078522   -0.129596     0.0413784   -0.0425829   -0.164112     0.0233313    0.171799
  0.0175979   -0.519799     2.08855    -0.420278     -0.474372      0.427686     1.67465      0.201496     -0.0250754     0.11171     -0.659158    -0.0165415    2.41516     -0.0856726   -0.177201    -3.85093     -0.0348904   -0.767014     -0.843672     0.934394    -0.0744594   -0.163066    -0.0865688   -0.12547     -0.0959821    0.350608
 -0.0780025    0.0689447   -0.05508    -0.149404     -0.0111863     0.0481181   -0.0679859   -0.156971      0.155702     -0.0613993   -0.00257828   0.0182675   -0.12635     -0.1164      -0.172901     0.0490412    0.00274502  -0.0955421    -0.0823065   -0.144945    -0.12669     -0.0355017   -0.105111     0.0515122    0.16612     -0.0695946
  0.0763478   -0.0822408   -0.0211333  -0.0159227    -0.0678088    -0.0884714   -0.125437     0.0696329    -0.0558318     0.00388909   0.0269179    0.095948     0.136741    -0.0074702   -0.129764     0.153638    -0.0182574    0.122649      0.0746657   -0.0935633   -0.0362822   -0.0413749   -0.0863899   -0.0201416   -0.198677     0.0025053
  0.0406554   -0.0332219    0.227318   -0.246111     -0.157976     -0.0783383   -0.0166088    0.0985189    -0.139739      0.0953746    0.0760338    0.0618855    0.0486247   -0.180352    -0.119053    -0.886942    -0.0295342    0.216214     -0.152823     0.00168954  -0.0189073   -0.0162475   -0.0413978    0.0607166   -0.0985905    0.0425329
  0.0438552    0.13193      0.171744   -0.244789     -0.124331     -0.07941      0.132432     0.11116      -0.186534      0.0973783    0.0739718    0.09855     -0.0706246   -0.184765    -0.111346     1.18962     -0.0435691    0.0516303    -0.0820316   -0.0209763   -0.022471     0.134542    -0.0488673    0.0539582   -0.128408    -0.0718716
  0.116091    -0.167249    -0.18357     0.0601574    -0.149064     -0.0285932   -0.195145     0.134042     -0.06685      -0.0997312   -0.0126976   -0.0266295   -0.100748     0.124904     0.00318663   0.0629932    0.0775463    0.328682     -0.0279151   -0.181887    -0.104353    -0.0571022   -0.047698    -0.179506     0.131794    -0.0317589
  0.116187    -0.0119619   -0.0324728  -0.124631      0.145891     -0.069882    -0.117363    -0.0840606     0.12616      -0.150612     0.128667    -0.0892939    0.0198599    0.107948     0.109484    -0.21098     -0.0713144   -0.000348249   0.146687    -0.0111682    0.00499542  -0.0488748   -0.0483104    0.00280026   0.128054     0.0513961
  0.0906265   -0.0352161   -0.0224424  -0.0545362     0.000797253  -0.0522776   -0.0164637   -0.0129971    -0.0231627    -0.115202     0.015269     0.0457509   -0.00457271  -0.0982952    0.0649447    0.00943861  -0.00158024  -0.0471399    -0.0402116    0.0869656   -0.00520991   0.0993656   -0.0242213   -0.059526    -0.0218488   -0.0252532
 -0.0327445    0.0265266    0.0958088   0.00445462    0.0988357    -0.012857     0.0147926   -0.129821     -0.000693325  -0.0357842    0.124685    -0.119785    -0.12723      0.0293634   -0.065721     0.145799     0.0218133    0.0654955    -0.0753772   -0.0140121   -0.100508     0.0240979   -0.027099     0.16115      0.0358344   -0.117119
  0.0997803   -0.0700245    0.0971716   0.101557      0.0419002    -0.170384    -0.0362095   -0.146485     -0.183259     -0.0104035    0.126182     0.107332    -0.0438681    0.0731527   -0.0159092    0.00128408   0.0794371   -0.0182308    -0.3379      -0.0520615   -0.0460302   -0.0586099    0.135461    -0.136149     0.0548008   -0.0897976
 -0.0579604    0.0110025    0.166808    0.185861     -0.058373      0.14917     -0.180192    -0.152546     -0.034104      0.159752     0.0469319   -0.0307297   -0.160005     0.0782767    0.0151205   -0.0139838    0.22443     -0.0727626    -0.0703712   -0.0204746    0.0590745    0.00996983   0.134356    -0.168359    -0.0658125   -0.151981
 -0.0357853   -0.0207509   -0.0890436  -0.052703      0.0538911    -0.00549417  -0.00213027   0.0235437    -0.0306989    -0.0218628   -0.0229463   -0.0970263   -0.18329     -0.0400526   -0.037691     0.0461445    0.0381773   -0.0301582     0.0226796    0.028465     0.0146155    0.0754305    0.0129458   -0.0274781    0.0710689   -0.0409972
 -0.0154811   -0.155231     0.0876884  -0.0117387     0.0444737     0.0778238   -0.0619828    0.018618     -0.0119266    -0.113408    -0.168856     0.00777937   0.0365038    0.0804824    0.0320967   -0.0688744    0.0473944   -0.0950612     0.0197322   -0.0816783   -0.0797415   -0.136629    -0.213736     0.0355746    0.0867547    0.04553
 -0.0971962   -0.0443551   -0.032316    0.0302407    -0.178585      0.00663883   0.0103231    0.0150304     0.111491     -0.0415228    0.150155    -0.0609691    0.00178272  -0.0405368    0.106549    -0.0420697   -0.0270221   -0.252993     -0.00442571   0.042883     0.02689     -0.061957     0.0449665   -0.056789    -0.0547003   -0.0371992
 -0.0583052   -0.072081     0.0520274   0.000979051   0.0379342    -0.0673817   -0.14015      0.140395      0.126584      0.0808741    0.00427749   0.0502171    0.112469    -0.110115    -0.112234     0.0447195    0.0537869   -0.114075     -0.0417944   -0.00639319   0.0852521    0.0877401   -0.0234801    0.0557581    0.055008     0.0556297
 -0.0337735   -0.0424224    0.102679    0.222641     -0.0607246     0.101309     0.0071191    0.0600229    -0.117622      0.0232656    0.074941    -0.0240594    0.0556762    0.00661509   0.00531192  -0.0896074    0.167022    -0.0430094    -0.0368539   -0.0230654    0.0913171    0.0527979   -0.00854373   0.0408513    0.00187834   0.112739
  0.0509112   -0.165359    -0.0987272   0.0557202     0.0242666    -0.021566    -0.171658    -0.182846      0.0847399     0.0948614    0.0703693    0.130771     0.110959     0.0265623    0.040328    -0.00918793  -0.0639528    0.0140535     0.0230838    0.198057    -0.00353636  -0.0818558   -0.0738895    0.0992125   -0.0829511   -0.0434574
  0.129252     0.10055     -0.104064   -0.109599     -0.01571      -0.0391045    0.154047    -0.0162566     0.026177      0.0320119   -0.00645464   0.0638221   -0.0348994    0.0147894   -0.0399789   -0.00955556   0.00218654   0.0367968    -0.0577475   -0.075479     0.0176311    0.081067    -0.151285    -0.0931488    0.261289     0.0483035
  0.0643862    0.0436083   -0.175008   -0.143202     -0.0980414    -0.0514327    0.204579    -0.0267765     0.0747379    -0.0220622   -0.126639    -0.0119753   -0.0617526   -0.0563499   -0.0403521    0.102842     0.0365474   -0.000351374   0.147683     0.0442974    0.0792928    0.0534245   -0.160849     0.112958    -0.0987414    0.0518111
 -0.0594973   -0.141596     0.114266   -0.0135623     0.209973     -0.0830132    0.0515375   -0.350049     -0.115384      0.0480699   -0.0480974    0.221317    -0.140161    -0.253334    -0.053849     0.101412    -0.00429171  -0.0998299    -0.2036       0.162999     0.0398413   -0.0603163    0.203078     0.115513    -0.0209837    0.35588
 -0.0959734    0.0360234    0.115054    0.0424563     0.0887247    -0.127486     0.0515076    0.370951     -0.11575       0.00961532  -0.0842415    0.221622    -0.00514106  -0.252688     0.139033     0.029974    -0.00448891   0.201847     -0.159723     0.160399    -0.343262    -0.0664947    0.215015     0.11567      0.0366691    0.1063
 -0.207687    -0.0691122   -0.0790543   0.0948883     0.0512074    -0.0112865    0.068728     0.0692562     0.0688639    -0.0852629   -0.116313     0.131827    -0.106375     0.257695    -0.160199    -0.00603354   0.0813862   -0.0283714    -0.0156748   -0.0966932   -0.0668613   -0.145144     0.0594343   -0.00426971  -0.00165165   0.0495925
  0.014502     0.00197954   0.0655041   0.00518446   -0.086693     -0.120974    -0.120284    -0.0595621     0.0224313    -0.182442     0.0580904    0.0705558    0.0397021    0.0446713    0.0798042    0.0122033   -0.117057    -0.171696      0.0835327    0.011281     0.0402718    0.00548856   0.0757408    0.186605    -0.105663     0.00970129
 -0.00706845   0.0162548   -0.0556369  -0.0565212    -0.0480615     0.0735714    0.0549742    0.0102225    -0.028345     -0.122535     0.0144198    0.028016    -0.0936606   -0.025405     0.0562062    0.0777635    0.00511325   0.0776968    -0.027599    -0.0349955   -0.0505924    0.00959793   0.0202888    0.0257391    0.00687065  -0.0549547
  0.110303     0.0749058   -0.148516   -0.157341      0.0443349     0.0678746   -0.132829    -0.188237     -0.159637     -0.0240082    0.135291     0.223925    -0.0370512    0.14403      0.0356594    0.0411003    0.0785893    0.105884      0.187879     0.00954515   0.0195695    0.198612     0.0264062    0.104617     0.133098     0.00847221
  0.0214672   -0.131081    -0.136735   -0.187961     -0.0645348    -0.00495448   0.130537     0.0714646     0.28081       0.0012334   -0.0683781   -0.0208208    0.187206     0.171357     0.0196273   -0.0923997   -0.0312635   -0.156013      0.0468985    0.129685     0.101345    -0.200944    -0.159325    -0.00665367  -0.179584    -0.115759
  0.100477    -0.116634    -0.0919833  -0.188233      0.0126455    -0.28362      0.160352     0.0820383    -0.0149433     0.0238507   -0.280455     0.00464839   0.107296    -0.0674809    0.060083    -0.0184642   -0.0869672   -0.134753      0.0731936    0.0916557    0.188455     0.401057    -0.172876     0.0257718    0.629115    -0.123352
 -0.107588    -0.0590995   -0.140571    0.0244652    -0.0196411     0.0691351   -0.0127633   -0.000969465  -0.0908289     0.0431671   -0.0465542   -0.00796089  -0.0423636   -0.0570092    0.052801     0.211215    -0.0208312   -0.0933761     0.0955879    0.0478845    0.0327287   -0.0376444    0.0188721    0.0492685    0.0381649   -0.0463833
  0.0117116   -0.0871399    0.0790607  -0.214884     -0.138699      0.181988     0.0886081   -0.0665983    -0.155505      0.0368911    0.0276857    0.0310869    0.00290256   0.144743    -0.0482701    0.00546572   0.00996578  -0.0794301     0.0460225   -0.221943     0.219428    -0.0481292   -0.0348275   -0.146901     0.0684324    0.0930948[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      6
│      ⋮
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -0.994253
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.962573
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      6
│      ⋮
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.993617
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.962685
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      6
│      ⋮
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.993617
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.962702
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      6
│      ⋮
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -0.993617
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.962704
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      6
│      ⋮
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.993617
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     26
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.962704
┌ Info: EM with 100000 data points 10 iterations avll -0.962704
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.018534e+05
      1       6.283196e+05      -1.735338e+05 |       32
      2       5.961319e+05      -3.218768e+04 |       32
      3       5.815332e+05      -1.459877e+04 |       32
      4       5.731571e+05      -8.376044e+03 |       32
      5       5.681238e+05      -5.033319e+03 |       32
      6       5.649217e+05      -3.202136e+03 |       32
      7       5.625851e+05      -2.336600e+03 |       32
      8       5.602724e+05      -2.312623e+03 |       32
      9       5.584479e+05      -1.824551e+03 |       32
     10       5.575570e+05      -8.909127e+02 |       32
     11       5.570407e+05      -5.162742e+02 |       32
     12       5.566695e+05      -3.712097e+02 |       32
     13       5.564006e+05      -2.688676e+02 |       32
     14       5.562220e+05      -1.786033e+02 |       32
     15       5.560797e+05      -1.423206e+02 |       32
     16       5.559513e+05      -1.283840e+02 |       32
     17       5.558410e+05      -1.102988e+02 |       32
     18       5.557672e+05      -7.382656e+01 |       32
     19       5.557183e+05      -4.892343e+01 |       30
     20       5.556834e+05      -3.485601e+01 |       31
     21       5.556587e+05      -2.472004e+01 |       32
     22       5.556352e+05      -2.345357e+01 |       28
     23       5.556112e+05      -2.404598e+01 |       31
     24       5.555871e+05      -2.406782e+01 |       32
     25       5.555626e+05      -2.452997e+01 |       30
     26       5.555401e+05      -2.247574e+01 |       29
     27       5.555096e+05      -3.052398e+01 |       32
     28       5.554859e+05      -2.370796e+01 |       31
     29       5.554663e+05      -1.954969e+01 |       30
     30       5.554483e+05      -1.798566e+01 |       28
     31       5.554296e+05      -1.872401e+01 |       32
     32       5.554112e+05      -1.845124e+01 |       32
     33       5.553932e+05      -1.800970e+01 |       31
     34       5.553745e+05      -1.865425e+01 |       29
     35       5.553506e+05      -2.390073e+01 |       32
     36       5.553233e+05      -2.731112e+01 |       31
     37       5.552961e+05      -2.714626e+01 |       32
     38       5.552675e+05      -2.863162e+01 |       32
     39       5.552330e+05      -3.452322e+01 |       32
     40       5.551936e+05      -3.935538e+01 |       32
     41       5.551373e+05      -5.634938e+01 |       31
     42       5.550731e+05      -6.421599e+01 |       32
     43       5.549811e+05      -9.197992e+01 |       31
     44       5.548585e+05      -1.226166e+02 |       32
     45       5.547387e+05      -1.197963e+02 |       32
     46       5.546034e+05      -1.352961e+02 |       32
     47       5.544544e+05      -1.489420e+02 |       32
     48       5.542976e+05      -1.568430e+02 |       32
     49       5.540659e+05      -2.317189e+02 |       32
     50       5.538161e+05      -2.497492e+02 |       32
K-means terminated without convergence after 50 iterations (objv = 553816.1294793752)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.261923
[ Info: iteration 2, average log likelihood -1.222873
[ Info: iteration 3, average log likelihood -1.188408
[ Info: iteration 4, average log likelihood -1.153486
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.109423
[ Info: iteration 6, average log likelihood -1.075370
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      5
│      9
│      ⋮
│     17
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.002387
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.092404
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     11
│     18
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.026860
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      9
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.048075
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      3
│     14
│     17
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.008978
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     12
│     18
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.045093
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.061474
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      9
│     11
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.001096
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│     12
│     13
│      ⋮
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -0.997970
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      7
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.102261
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.061247
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      3
│      9
│     17
│     21
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -0.993723
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│     11
│     12
│     14
│     18
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.026370
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.066805
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.020225
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│      9
│     21
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -0.995509
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      3
│      7
│     12
│     17
│     18
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.010090
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.072951
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.028104
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      7
│      9
│     21
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -0.998198
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     11
│     12
│     18
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.021231
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      4
│     14
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.033602
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     13
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.030185
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      5
│      9
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.049652
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     12
│     17
│     18
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.030107
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.054399
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│      5
│      7
│      9
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -0.995483
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     11
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.029590
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     12
│     17
│     21
│     22
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.029982
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.060405
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      5
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.009738
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│     11
│     20
│     21
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -0.999860
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     12
│     13
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.041154
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      7
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.040199
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     14
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.022963
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│     11
│     18
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -0.994234
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      5
│      7
│     12
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.035753
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     17
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.042581
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     13
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.036875
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     11
│     14
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.033528
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     12
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.029763
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     17
│     18
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.015582
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      9
│     13
│     22
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.013303
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     14
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.057634
┌ Info: EM with 100000 data points 50 iterations avll -1.057634
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0336894     0.0274334    0.146638    0.136146     0.0130401    0.0587322  -0.0510137   -0.110228    -0.0892125    0.185854    -0.00427671    0.0880083   -0.157561    -0.165063     0.0176083    0.0523127    0.125516     0.0356335   -0.109757     0.0602622    0.0342054    0.00203707   0.183695    -0.0586461   -0.086995     0.0351307
  0.0594484     0.0375028    0.0615617   0.0832013   -0.0729743    0.0860884  -0.16467      0.0766723    0.019833     0.00956844  -0.11498       0.0673857    0.107898     0.0595518   -0.011833    -0.0259499    0.0109674   -0.131707    -0.116956    -0.0502153    0.0416432    0.00376485  -0.130278    -0.115814    -0.0943857    0.0581404
  0.0687029     0.0379448   -0.180083   -0.146419    -0.098467    -0.0535376   0.204685    -0.0344522    0.0746903   -0.0196937   -0.12719      -0.0103222   -0.0632669   -0.0549738   -0.0422863    0.105233     0.0366094    0.00174757   0.154099     0.0466916    0.0853414    0.0531372   -0.160757     0.115761    -0.0997931    0.0516115
  0.00987029   -0.137336     0.0850965   0.0146155    0.027086     0.115699   -0.0512327    0.102187    -0.0297951   -0.114628    -0.154406      0.0172883    0.0313358    0.0827917    0.0669251   -0.0514144    0.0304765   -0.100583     0.0929318   -0.0972982   -0.091221    -0.0326226   -0.201244     0.0357142    0.0874817    0.04363
 -0.0778773     0.0573323    0.146946   -0.00555939  -0.0329919   -0.181391   -0.113998    -0.0830847    0.0488582   -0.230768    -0.0628646     0.0955721    0.0646185    0.0897396    0.203527     0.0177911   -0.182249    -0.197239     0.0416197    0.0114561    0.0801521   -0.0439421    0.132381     0.185086    -0.107931    -0.0240547
  0.115327     -0.167325    -0.175173    0.0649743   -0.150198    -0.0283518  -0.193384     0.129997    -0.0741258   -0.0996531   -0.0118955    -0.0229624   -0.100736     0.122126     0.00993692   0.0601393    0.076855     0.326575    -0.0319529   -0.17809     -0.114828    -0.0587665   -0.0479726   -0.185785     0.13575     -0.0319321
 -0.0952034    -0.0649098   -0.175946   -0.0867802    0.0320117    0.0668831  -0.0183897    0.0129826   -0.0632409    0.0375826   -0.0611164    -0.046191    -0.0979416   -0.0635104    0.0459406    0.181525    -0.0393988   -0.0775058    0.101358     0.0617607    0.046138    -0.0224336    0.0185681    0.0389474    0.0340156   -0.0900164
  0.178007     -0.0936715   -0.065253    0.0175363   -0.194179    -0.0232585  -0.0581871    0.00597241  -0.0717689   -0.0539429    0.159576      0.0291043   -0.0290012   -0.00665162  -0.151974    -0.0105862   -0.0368717   -0.126013     0.220732     0.020251     0.0449306    0.11484     -0.00951308   0.280461    -0.122087     0.0285115
  0.0807405    -0.0395336    0.124749    0.0624107    0.0803586   -0.163689   -0.0011734   -0.212933    -0.276403     0.0173219    0.0642897     0.122648    -0.0711283    0.0929773   -0.0197792   -0.00663935   0.0621814   -0.0146849   -0.450815    -0.035003    -0.240266    -0.110069     0.238237    -0.118566     0.0488904   -0.0824196
  0.0983889     0.0726618   -0.143666   -0.15776      0.0386611    0.0732067  -0.105995    -0.172451    -0.154011    -0.0266373    0.12485       0.211002    -0.0405242    0.142342     0.0339576    0.042699     0.0745873    0.0974211    0.182549     0.00302481   0.0187111    0.170226     0.0242624    0.0930492    0.122227    -0.000504622
 -0.0101117    -0.00744019  -0.160784   -0.159474    -0.00111528   0.0697132   0.00204848  -0.0289493    0.0839567   -0.104562     0.000595592  -0.0516708    0.0635346    0.061266    -0.00376433   0.0703677    0.050028     0.00916647   0.251211     0.0231874    0.010212    -0.035163    -0.12332      0.0716928   -0.0552113    0.0243509
  0.0400611    -0.123246     0.0730717  -0.0957133   -0.0529345    0.0309152   0.0131747    0.154251     0.238381    -0.065068    -0.0464569     0.00834579   0.100031    -0.10279     -0.0827447    0.0269732    0.0945612   -0.155773    -0.0733172   -0.0435001    0.136951    -0.0151446   -0.10839      0.192006     0.0475503    0.027803
 -0.0781411    -0.0710915    0.0378044  -0.0419605    0.200869    -0.113859    0.0242316   -0.00617252  -0.0964227    0.0387329   -0.0543716     0.207713    -0.134767    -0.15533      0.0159354    0.111556    -0.0207991    0.0292928   -0.101568     0.213101    -0.191246    -0.0723908    0.15378      0.0851291   -0.0110085    0.226984
 -0.000714365  -0.173439     0.0276993   0.0395958   -0.0450921   -0.108164   -0.264349    -0.0329891    0.111541    -0.0836152    0.319546      0.104298     0.103893    -0.0312289    0.0463013    0.0681147    0.165426    -0.0581907   -0.196838    -0.00161181  -0.0912776    0.0444921   -0.0409093   -0.169044     0.0368502    0.175962
 -0.207675     -0.0707146   -0.0791474   0.0925211    0.051179    -0.0107705   0.0690414    0.0745689    0.0692078   -0.0816042   -0.119842      0.131685    -0.101918     0.254761    -0.160186    -0.00757891   0.0797522   -0.0263904   -0.0166099   -0.0958637   -0.0675028   -0.144222     0.0591625   -0.00385139  -0.00598137   0.0509504
 -0.166734      0.0858302    0.046696    0.0113438    0.0428353    0.0853004  -0.030768    -0.134963     0.0496954   -0.110174     0.0891007    -0.0981777   -0.103199     0.0422803   -0.0655011    0.344415    -0.0132029    0.105912    -0.091231     0.0166491    0.00756147   0.0309277   -0.0340704    0.106331     0.0400928   -0.180977
 -0.0956353    -0.0320745    0.156509    0.191582    -0.038222     0.13485    -0.146983    -0.190906    -0.119842     0.157485     0.048054     -0.0152346   -0.149893     0.159013     0.00555973  -0.0486819    0.219788    -0.045355    -0.0480346   -0.0250053    0.0241469   -0.0780091    0.138903    -0.141216    -0.045745    -0.233323
  0.122902     -0.0321173    0.156249   -0.0107037    0.174406    -0.122437    0.0714063   -0.12263     -0.0707661    0.0407088    0.174624     -0.172238    -0.16447      0.00492115  -0.0630753   -0.0566094    0.0464093    0.0230537   -0.0630203   -0.0701443   -0.249366     0.0437993   -0.00447399   0.235219     0.039425    -0.0633979
  0.0681635     0.0464618   -0.0263357   0.105998    -0.0200887    0.0402904   0.00521111  -0.0319308    0.00578077  -0.137343    -0.060187      0.0131154   -0.0128794   -0.0881786    0.130872     0.0564752    0.0289501   -0.174607    -0.0592745    0.107825    -0.081946     0.0933366    0.044984    -0.283993     0.0144274    0.0339344
 -0.0101681    -0.111457     0.0871963  -0.0327449    0.0900603   -0.0166757  -0.0176695   -0.0610544    0.00278841  -0.0711131   -0.0887301     0.0184033   -0.0123591    0.0636017    0.026059    -0.0673024    0.0641855   -0.0577438    0.00293054  -0.0794092   -0.11116     -0.201783    -0.181217     0.104082     0.0767726    0.0324511
 -0.166571     -0.00394847   0.0433039   0.0771793    0.154383    -0.157978   -0.283904     0.140051     0.0388623    0.219089    -0.00480921    0.0814485    0.155184    -0.134159    -0.163706     0.0583571   -0.00491566  -0.0712623    0.00711968   0.0350591    0.0612009    0.184058     0.0508569   -0.0357116    0.0653834    0.0646
 -0.0678711    -0.0512881    0.0379305   0.234723    -0.0523475    0.101669    0.00981128   0.0665345   -0.117114     0.0469019    0.0195872    -0.0258575    0.0738801   -0.0439116    0.0387612    0.0181367    0.106927    -0.039954    -0.00685631   0.00427129   0.0973377    0.0112455    0.0240528    0.0490004    0.0189774    0.0989122
 -0.047143      0.0515261   -0.0328135  -0.142429     0.00561676   0.0273077  -0.077816    -0.142417     0.125068    -0.0651077    0.0100518     0.0388613   -0.152617    -0.114453    -0.165252     0.0346015    0.00532214  -0.0890352   -0.0901647   -0.100194    -0.117895    -0.0356708   -0.0939347    0.0431016    0.20711     -0.0549923
  0.116042      0.0464104   -0.071887   -0.129615     0.0645623   -0.0616807   0.0293297   -0.053332     0.072613    -0.0573752    0.053799     -0.00509331  -0.00217814   0.0552506    0.0499812   -0.115147    -0.0390753    0.0208079    0.0397599   -0.0390406    0.0172016    0.0238099   -0.10523     -0.0515655    0.207306     0.0464459
  0.0524209    -0.174642    -0.100525    0.0562858    0.0368553   -0.024829   -0.166765    -0.197728     0.0793223    0.130645     0.065829      0.147826     0.123118     0.0255362    0.0347845   -0.0101615   -0.075738     0.0209006    0.0584778    0.204467    -0.00426266  -0.0875788   -0.0617909    0.116245    -0.0893532   -0.0497403
 -0.102058     -0.0459241   -0.0394845   0.0293095   -0.184304     0.0101913   0.0231698    0.0162892    0.103278    -0.0373821    0.138345     -0.0689473   -0.00119966  -0.0351768    0.106808    -0.0428143   -0.0331095   -0.261276    -0.00175463   0.0463098    0.0332743   -0.0684655    0.0432729   -0.0512881   -0.0547217   -0.0432537
  0.00176106   -0.0795542    0.0789653  -0.216245    -0.13581      0.174321    0.0862704   -0.0604836   -0.156609     0.0358118    0.018935      0.0300999    0.00337603   0.138315    -0.0476742    0.0123936    0.00129286  -0.0809097    0.0440478   -0.215525     0.22073     -0.0556994   -0.0315628   -0.147535     0.0789113    0.0906048
 -0.0460311    -0.0209479   -0.0812902  -0.0566449    0.0620758   -0.0020359   0.00254839   0.0232961   -0.0334561   -0.0217954   -0.0279102    -0.0935785   -0.174569    -0.0374878   -0.0364683    0.0422429    0.0391564   -0.0299584    0.0189464    0.0368598    0.0181397    0.0750669    0.0075107   -0.0320784    0.0736501   -0.0406106
 -0.0179371     0.00965724  -0.0366006  -0.0128659   -0.0544426    0.0660779   0.0409813    0.0185562   -0.020094    -0.128496    -0.0141874     0.00150153  -0.105209    -0.0427667    0.0468187    0.0721321   -0.00729192   0.0534434   -0.0686199   -0.0199195   -0.0436568    0.00835888   0.0163992    0.0298531    0.00241376  -0.0646477
  0.0394106    -0.00366129   0.0713386  -0.131727    -0.0930097   -0.0679367  -0.0376282    0.0654529   -0.0748112    0.0364515    0.0392054     0.0793901    0.0562469   -0.0957291   -0.128694     0.15216     -0.0240312    0.102734    -0.0262342   -0.0647105   -0.0413229    0.00421037  -0.0668734    0.0204387   -0.14102     -0.00472308
  0.101244     -0.12063      0.0061587  -0.204616     0.0848028   -0.180959   -0.0245708    0.0206283   -0.0646138   -0.0945001    0.0680881     0.100474    -0.0125517   -0.132597     0.0495782   -0.0451063   -0.0526866    0.140464    -0.0174519    0.0710925    0.199271     0.0981927   -0.134122     0.224138    -0.0355355   -0.115316
  0.0589763    -0.122897    -0.11516    -0.187914    -0.0287022   -0.134639    0.14413      0.0759088    0.139476     0.0124677   -0.170389     -0.00852136   0.146429     0.0579327    0.0388782   -0.0578222   -0.0581373   -0.145634     0.060585     0.111279     0.145058     0.08493     -0.165609     0.00945472   0.20767     -0.119389[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      5
│     12
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.048613
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      7
│     12
│     17
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.979763
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.946234
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      5
│      7
│     11
│     12
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.028036
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      4
│      5
│     12
│     17
│     18
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.974001
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      5
│      7
│      9
│      ⋮
│     23
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.951229
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      4
│      5
│     11
│     12
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.015042
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      5
│      7
│     12
│     17
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.967060
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     23
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.951232
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      7
│     11
│     12
│     20
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.006778
┌ Info: EM with 100000 data points 10 iterations avll -1.006778
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.127847     0.164796     -0.0133269   -0.197645    -0.0194522   -0.0341568     0.0423372   -0.0133726    -0.103056    0.0631804   -0.174556    -0.0560789    0.00841734   -0.120331    -0.0956413     0.0731088    0.124497     0.0507809    0.0512341   -0.0940103    0.103847     0.0419571   -0.049681     0.0162132     0.016968     -0.0744769
  0.0814348    0.136405     -0.0379415   -0.0666119    0.0104781   -0.168243     -0.100851    -0.0776732    -0.0618821   0.0356196    0.0108123    0.0480804   -0.000390752  -0.113583     0.0322169    -0.0102934    0.0570151   -0.136874     0.0578824   -0.0512871    0.148649     0.0323874   -0.0133305    0.0663636     0.0527564    -0.000351379
  0.0706927    0.0546494     0.0039441    0.0679851    0.0400721   -0.0805064    -0.0512421   -0.0159159    -0.0371893  -0.0358158   -0.00864535  -0.0509382   -0.065915      0.106073    -0.000276257   0.0339461   -0.165692     0.00556771  -0.0671671    0.0633943   -0.00553911  -0.113531     0.0643591   -0.0588118    -0.0680999     0.0638769
 -0.154404    -0.151262      0.0443363   -0.0138402    0.0608917   -0.131228      0.109766     0.0372568    -0.039431   -0.120273     0.0711217   -0.05752     -0.0201994     0.00862952  -0.0550001    -0.165678     0.0683108   -0.0783408    0.0380066    0.072965    -0.1098      -0.145666     0.0617162    0.261597      0.000913692  -0.107865
  0.0011087   -0.174026      0.17036      0.0016672    0.0279633    0.0857859    -0.180599    -0.0909681    -0.136229   -0.061625    -0.041629     0.0275366    0.160763     -0.104028     0.0210008    -0.0702283   -0.0893731   -0.136916    -0.209168     0.0753839    0.115212     0.0156696    0.0427351    0.0984919    -0.0843906    -0.111608
 -0.0560295    0.144906      0.0569513    0.136044     0.109209    -0.0515061    -0.137496     0.000803296  -0.0739427  -0.068702     0.0784233    0.232856    -0.119554      0.0472042   -0.100759      0.0458817    0.00244361   0.0330709   -0.110346     0.0978078    0.00161751  -0.0276836   -0.134648     0.114452      0.121676     -0.137698
 -0.0270575    0.00875543    0.001458    -0.102129    -0.137906     0.0943039    -0.0831059    0.16988      -0.105688    0.0444797    0.101514     0.0601276    0.0434431    -0.187969    -0.0763079     0.223985     0.157013     0.0248396    0.00277421   0.0431333    0.0504576    0.0738055    0.152024    -0.0599834     0.0895943     0.0404755
  0.186961    -0.19755       0.0271863   -0.060448     0.0948844   -0.101572     -0.0868011   -0.128406     -0.0348748  -0.104077    -0.0490706    0.22452      0.0218275    -0.00902469   0.0661763     0.115935     0.0890209   -0.0861626    0.168048    -0.162099    -0.107094    -0.0577082    0.0487559    0.109814     -0.0952114     0.175098
  0.027874     0.222517     -0.119035    -0.06179     -0.0548951    0.225425      0.0881985    0.0237845     0.0239368  -0.0905029    0.0580977   -0.130205    -0.0856194    -0.0193724   -0.0208933    -0.0601471    0.0806052    0.0340743    0.0198656   -0.0579655   -0.0638289   -0.109389     0.186712     0.0102813     0.0579304     0.0187102
 -0.0716695    0.088332      0.0254453   -0.149724     0.129512     0.0563763     0.0402426   -0.00797567   -0.0402043  -0.125834    -0.220167    -0.0612245    0.0549518    -0.010197     0.0245086    -0.0321616    0.125258    -0.0993423   -0.235104     0.00506104  -0.041705     0.160123    -0.00880538   0.160481     -0.0968677    -0.10244
  0.0219858    0.160068     -0.00704523   0.187698     0.0738963   -0.0854891     0.0388357   -0.031227     -0.0734267   0.0421036   -0.119353    -0.11224      0.0286811     0.169175     0.146562     -0.0967528    0.0103897   -0.0127468   -0.062402     0.0760529    0.0848239    0.0467093   -0.094638     0.0684707     0.0455169     0.042144
 -0.00585205  -0.0597226    -0.0850016    0.0137967    0.127762     0.054004      0.0119481    0.0309808     0.0269671   0.0631391   -0.100083    -0.206851     0.0619725     0.077911    -0.0878891    -0.105538    -0.0217213   -0.202394    -0.0424341   -0.10607      0.110397    -0.0874543    0.0206076   -0.134292      0.144906      0.0363802
  0.0714282    0.0531508     0.107728     0.0382382    0.0431128   -0.0991345     0.0916431   -0.0286364    -0.0165804   0.199248     0.0656434    0.00309797  -0.0169475     0.0227307    0.0444866    -0.104328     0.0488023    0.0176139   -0.185813    -0.0129655    0.104432     0.0445587    0.189838    -0.00839128    0.111898      0.0527708
 -0.0213856   -0.109728     -0.105545     0.0552512   -0.160114    -0.0213013     0.123946     0.0791909    -0.0305007  -0.0360065    0.107086     0.0395664    0.0923886    -0.121696     0.0144189    -0.0485262   -0.165113     0.076149     0.0205577    0.175181     0.00700118   0.0197627    0.133866    -0.118893     -0.0476069    -0.26499
 -0.112675     0.0391958    -0.00655777   0.130135     0.125816     0.0614259    -0.134006     0.0041931     0.0633632  -0.0192495   -0.0136446    0.0972228    0.0881854    -0.198838     0.0714744     0.0497427    0.100058    -0.0763667    0.0294962   -0.0342736   -0.166699     0.117772     0.0317715   -0.0930388    -0.0126172    -0.106645
 -0.0954818   -0.0396383     0.0132113   -0.233819     0.064295     0.0756653    -0.107349     0.0506812    -0.100661   -0.117136     0.110533    -0.081178     0.0751909    -0.14588      0.231951     -0.118944    -0.104938     0.0047608    0.00584371  -0.0564499    0.0258898   -0.0678915    0.0977111   -0.0574479     0.0294306     0.0897565
  0.0238924   -0.116439     -0.218214     0.187474     0.164269     0.0360919     0.0578687    0.0144333    -0.0212238  -0.02002      0.00330457   0.00553226   0.0760339    -0.140285     0.202663     -0.0217656    0.0973891    0.131227     0.0372773   -0.0186436   -0.0463461   -0.0497931   -0.149456    -0.207832     -0.172808      0.0502943
 -0.00249381  -0.203296      0.191468    -0.0493228   -0.0520906    0.0176664     0.130241     0.0669777     0.0532067  -0.241973    -0.183005    -0.0714063   -0.176957      0.0519183    0.0537537     0.00346392  -0.0527117   -0.0133289   -0.0110885   -0.0474781   -0.0267667    0.225953     0.132632    -0.0759566    -0.0148587    -0.148079
  0.0271231   -0.0378277    -0.00857279   0.129414     0.205501    -0.151506     -0.143738    -0.00945643    0.154716   -0.0106598    0.104492    -0.244866    -0.105703     -0.223683    -0.0851352    -0.0314388    0.0272741   -0.068678     0.0407586   -0.230786     0.115084    -0.00792818   0.060305    -0.000627023   0.0478864    -0.212423
  0.0776865   -0.00457803   -0.131363    -0.246892    -0.0500514    0.169201      0.195056    -0.0287324     0.171223   -0.102238     0.0603811   -0.088519    -0.0234925     0.102933    -0.0043261     0.177713    -0.101808    -0.00907909   0.155962    -0.159563    -0.018163    -0.029131     0.0702914   -0.0343665     0.0903019    -0.0887472
  0.0743552   -0.0902831     0.0967719    0.153501    -0.153737    -0.0629188     0.104429    -0.032887     -0.0401568  -0.051724    -0.0198551    0.0896452   -0.0239743     0.00705486   0.114904      0.22486      0.0833054    0.0920655   -0.0139952   -0.126247    -0.0710767   -0.076853    -0.0479274   -0.221374      0.0705805     0.0233975
  0.133254    -0.135295     -0.229308    -0.0180489    0.0224662   -0.154695     -0.0976563   -0.0152189     0.0392056  -0.179741     0.212757    -0.200443     0.165472     -0.137785    -0.0348295     0.00358505  -0.0725075    0.0346782   -0.0307877    0.0381898    0.0547054   -0.0712724   -0.0501281    0.041961     -0.0784829    -0.0622182
  0.152018     0.0878519     0.0788702    0.00437553   0.00357927  -0.0468933     0.0589725    0.105664     -0.0122361  -0.213645    -0.0677508    0.034807     0.0365546    -0.138852     0.121482      0.158018     0.030551    -0.0392532   -0.0304413    0.022102    -0.0758109   -0.109986    -0.0345498    0.0701746     0.15783      -0.110026
  0.148408     0.0170148    -0.0285677   -0.0114282    0.0750641    0.0567478    -0.044866    -0.0696565     0.0607469  -0.0557383   -0.0144442    0.0587892    0.10125       0.039853    -0.0819032    -0.107267    -0.0551358    0.200804     0.156689    -0.0239035   -0.00205804  -0.0108595    0.215333    -0.217654      0.0757427     0.0523258
  0.0906921   -0.147486     -0.104282    -0.0136235    0.109457     0.161156     -0.0472518   -0.0687734    -0.0739206  -0.123821    -0.051414    -0.137396    -0.0384189    -0.0201522    0.00555335    0.0494412   -0.0197768    0.0538629    0.0393097   -0.0127374    0.165008     0.0375855   -0.138671     0.112873     -0.108173     -0.0122884
 -0.0420339    0.000712662   0.0794682    0.124111    -0.0957099    0.0407592     0.183694     0.0766225     0.31212    -0.0261181   -0.031551    -0.00350147  -0.0367554     0.163687     0.0246871    -0.054711     0.150152     0.152696     0.0289145   -0.141017    -0.017822    -0.00830017   0.0173924    0.0339298     0.120537      0.167125
  0.00654177  -0.199094      0.00472256   0.00694223   0.108299     0.167287      0.151843    -0.0217305    -0.201315   -0.201229    -0.0168937    0.0341605    0.0568431     0.00702936   0.0501646    -0.123455     0.0570994    0.156453    -0.0396149   -0.0333417    0.163712    -0.133515    -0.0347241    0.149492     -0.0143718     0.038051
  0.00274878   0.122509      0.146177     0.0696093   -0.0132082   -0.125403      0.0595726   -0.0264457    -0.152885   -0.0290501   -0.171766    -0.0777554    0.0812166    -0.114741    -0.0273025    -0.1704       0.0733284    0.0145124    0.141018     0.0139511    0.187053    -0.123124    -0.0200967    0.211336     -0.115953      0.114932
  0.148153    -0.0748995     0.0802127   -0.06471     -0.0117957    0.000318994  -0.0197573   -0.0112153    -0.109877   -0.13545     -0.0318363    0.0157852   -0.155516     -0.0568965    0.0671619    -0.00748879  -0.264512    -0.0437965   -0.0721402    0.171424    -0.0154406   -0.13619      0.179055    -0.0761186    -0.032266     -0.152252
  0.0496587    0.124277      0.116945     0.0478571   -0.0418382    0.135221     -0.00937609  -0.0811777     0.0823655   0.00791095  -0.00998729   0.00125697  -0.0861103    -0.102124    -0.087607     -0.0621865    0.0663939   -0.00758001   0.11444     -0.0472357    0.24265     -0.0101982    0.0237148    0.188819      0.105786      0.0493456
  0.0127457    0.0374936     0.0195657   -0.0890153   -0.00865267   0.0728843     0.0994837   -0.0834487    -0.151962   -0.039298     0.177707    -0.0882464   -0.126992      0.0364176    0.109438      0.118332    -0.226002     0.0562969    0.0315064    0.0342109   -0.0026339   -0.00658899  -0.159007     0.0143433     0.027011      0.0967974
 -0.103646     0.00343742   -0.0811737    0.0060325    0.0660395   -0.0622918     0.0285383   -0.0518584     0.018348    0.0221383    0.00844275   0.0347153   -0.115043     -0.143669    -0.0887587    -0.106534    -0.101962    -0.16572     -0.159175     0.0266524    0.0494741   -0.136876     0.179425    -0.0777951    -0.0747938     0.0736604kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4236165310354008
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423635
[ Info: iteration 2, average log likelihood -1.423575
[ Info: iteration 3, average log likelihood -1.423532
[ Info: iteration 4, average log likelihood -1.423485
[ Info: iteration 5, average log likelihood -1.423425
[ Info: iteration 6, average log likelihood -1.423345
[ Info: iteration 7, average log likelihood -1.423217
[ Info: iteration 8, average log likelihood -1.422977
[ Info: iteration 9, average log likelihood -1.422488
[ Info: iteration 10, average log likelihood -1.421586
[ Info: iteration 11, average log likelihood -1.420337
[ Info: iteration 12, average log likelihood -1.419214
[ Info: iteration 13, average log likelihood -1.418570
[ Info: iteration 14, average log likelihood -1.418300
[ Info: iteration 15, average log likelihood -1.418199
[ Info: iteration 16, average log likelihood -1.418162
[ Info: iteration 17, average log likelihood -1.418148
[ Info: iteration 18, average log likelihood -1.418142
[ Info: iteration 19, average log likelihood -1.418139
[ Info: iteration 20, average log likelihood -1.418138
[ Info: iteration 21, average log likelihood -1.418138
[ Info: iteration 22, average log likelihood -1.418137
[ Info: iteration 23, average log likelihood -1.418137
[ Info: iteration 24, average log likelihood -1.418136
[ Info: iteration 25, average log likelihood -1.418136
[ Info: iteration 26, average log likelihood -1.418136
[ Info: iteration 27, average log likelihood -1.418136
[ Info: iteration 28, average log likelihood -1.418136
[ Info: iteration 29, average log likelihood -1.418135
[ Info: iteration 30, average log likelihood -1.418135
[ Info: iteration 31, average log likelihood -1.418135
[ Info: iteration 32, average log likelihood -1.418135
[ Info: iteration 33, average log likelihood -1.418135
[ Info: iteration 34, average log likelihood -1.418135
[ Info: iteration 35, average log likelihood -1.418135
[ Info: iteration 36, average log likelihood -1.418135
[ Info: iteration 37, average log likelihood -1.418135
[ Info: iteration 38, average log likelihood -1.418135
[ Info: iteration 39, average log likelihood -1.418134
[ Info: iteration 40, average log likelihood -1.418134
[ Info: iteration 41, average log likelihood -1.418134
[ Info: iteration 42, average log likelihood -1.418134
[ Info: iteration 43, average log likelihood -1.418134
[ Info: iteration 44, average log likelihood -1.418134
[ Info: iteration 45, average log likelihood -1.418134
[ Info: iteration 46, average log likelihood -1.418134
[ Info: iteration 47, average log likelihood -1.418134
[ Info: iteration 48, average log likelihood -1.418134
[ Info: iteration 49, average log likelihood -1.418134
[ Info: iteration 50, average log likelihood -1.418134
┌ Info: EM with 100000 data points 50 iterations avll -1.418134
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4236353038264868
│     -1.4235747409311368
│      ⋮
└     -1.4181341288496103
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418149
[ Info: iteration 2, average log likelihood -1.418094
[ Info: iteration 3, average log likelihood -1.418053
[ Info: iteration 4, average log likelihood -1.418006
[ Info: iteration 5, average log likelihood -1.417952
[ Info: iteration 6, average log likelihood -1.417889
[ Info: iteration 7, average log likelihood -1.417819
[ Info: iteration 8, average log likelihood -1.417744
[ Info: iteration 9, average log likelihood -1.417669
[ Info: iteration 10, average log likelihood -1.417595
[ Info: iteration 11, average log likelihood -1.417525
[ Info: iteration 12, average log likelihood -1.417458
[ Info: iteration 13, average log likelihood -1.417397
[ Info: iteration 14, average log likelihood -1.417342
[ Info: iteration 15, average log likelihood -1.417295
[ Info: iteration 16, average log likelihood -1.417255
[ Info: iteration 17, average log likelihood -1.417222
[ Info: iteration 18, average log likelihood -1.417194
[ Info: iteration 19, average log likelihood -1.417169
[ Info: iteration 20, average log likelihood -1.417148
[ Info: iteration 21, average log likelihood -1.417130
[ Info: iteration 22, average log likelihood -1.417114
[ Info: iteration 23, average log likelihood -1.417101
[ Info: iteration 24, average log likelihood -1.417089
[ Info: iteration 25, average log likelihood -1.417079
[ Info: iteration 26, average log likelihood -1.417070
[ Info: iteration 27, average log likelihood -1.417063
[ Info: iteration 28, average log likelihood -1.417056
[ Info: iteration 29, average log likelihood -1.417051
[ Info: iteration 30, average log likelihood -1.417046
[ Info: iteration 31, average log likelihood -1.417042
[ Info: iteration 32, average log likelihood -1.417039
[ Info: iteration 33, average log likelihood -1.417035
[ Info: iteration 34, average log likelihood -1.417033
[ Info: iteration 35, average log likelihood -1.417030
[ Info: iteration 36, average log likelihood -1.417028
[ Info: iteration 37, average log likelihood -1.417026
[ Info: iteration 38, average log likelihood -1.417024
[ Info: iteration 39, average log likelihood -1.417022
[ Info: iteration 40, average log likelihood -1.417021
[ Info: iteration 41, average log likelihood -1.417019
[ Info: iteration 42, average log likelihood -1.417018
[ Info: iteration 43, average log likelihood -1.417017
[ Info: iteration 44, average log likelihood -1.417015
[ Info: iteration 45, average log likelihood -1.417014
[ Info: iteration 46, average log likelihood -1.417013
[ Info: iteration 47, average log likelihood -1.417012
[ Info: iteration 48, average log likelihood -1.417011
[ Info: iteration 49, average log likelihood -1.417010
[ Info: iteration 50, average log likelihood -1.417009
┌ Info: EM with 100000 data points 50 iterations avll -1.417009
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4181490143158046
│     -1.4180940279913963
│      ⋮
└     -1.4170088005245434
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417019
[ Info: iteration 2, average log likelihood -1.416965
[ Info: iteration 3, average log likelihood -1.416915
[ Info: iteration 4, average log likelihood -1.416853
[ Info: iteration 5, average log likelihood -1.416773
[ Info: iteration 6, average log likelihood -1.416672
[ Info: iteration 7, average log likelihood -1.416549
[ Info: iteration 8, average log likelihood -1.416411
[ Info: iteration 9, average log likelihood -1.416270
[ Info: iteration 10, average log likelihood -1.416140
[ Info: iteration 11, average log likelihood -1.416032
[ Info: iteration 12, average log likelihood -1.415946
[ Info: iteration 13, average log likelihood -1.415882
[ Info: iteration 14, average log likelihood -1.415832
[ Info: iteration 15, average log likelihood -1.415791
[ Info: iteration 16, average log likelihood -1.415757
[ Info: iteration 17, average log likelihood -1.415726
[ Info: iteration 18, average log likelihood -1.415698
[ Info: iteration 19, average log likelihood -1.415673
[ Info: iteration 20, average log likelihood -1.415649
[ Info: iteration 21, average log likelihood -1.415628
[ Info: iteration 22, average log likelihood -1.415609
[ Info: iteration 23, average log likelihood -1.415591
[ Info: iteration 24, average log likelihood -1.415575
[ Info: iteration 25, average log likelihood -1.415560
[ Info: iteration 26, average log likelihood -1.415547
[ Info: iteration 27, average log likelihood -1.415535
[ Info: iteration 28, average log likelihood -1.415524
[ Info: iteration 29, average log likelihood -1.415513
[ Info: iteration 30, average log likelihood -1.415504
[ Info: iteration 31, average log likelihood -1.415495
[ Info: iteration 32, average log likelihood -1.415487
[ Info: iteration 33, average log likelihood -1.415480
[ Info: iteration 34, average log likelihood -1.415473
[ Info: iteration 35, average log likelihood -1.415467
[ Info: iteration 36, average log likelihood -1.415461
[ Info: iteration 37, average log likelihood -1.415455
[ Info: iteration 38, average log likelihood -1.415450
[ Info: iteration 39, average log likelihood -1.415445
[ Info: iteration 40, average log likelihood -1.415440
[ Info: iteration 41, average log likelihood -1.415435
[ Info: iteration 42, average log likelihood -1.415431
[ Info: iteration 43, average log likelihood -1.415427
[ Info: iteration 44, average log likelihood -1.415423
[ Info: iteration 45, average log likelihood -1.415419
[ Info: iteration 46, average log likelihood -1.415415
[ Info: iteration 47, average log likelihood -1.415412
[ Info: iteration 48, average log likelihood -1.415408
[ Info: iteration 49, average log likelihood -1.415405
[ Info: iteration 50, average log likelihood -1.415401
┌ Info: EM with 100000 data points 50 iterations avll -1.415401
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4170189120637309
│     -1.4169652666139578
│      ⋮
└     -1.4154012382689516
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415406
[ Info: iteration 2, average log likelihood -1.415347
[ Info: iteration 3, average log likelihood -1.415290
[ Info: iteration 4, average log likelihood -1.415222
[ Info: iteration 5, average log likelihood -1.415138
[ Info: iteration 6, average log likelihood -1.415034
[ Info: iteration 7, average log likelihood -1.414910
[ Info: iteration 8, average log likelihood -1.414772
[ Info: iteration 9, average log likelihood -1.414628
[ Info: iteration 10, average log likelihood -1.414486
[ Info: iteration 11, average log likelihood -1.414355
[ Info: iteration 12, average log likelihood -1.414236
[ Info: iteration 13, average log likelihood -1.414132
[ Info: iteration 14, average log likelihood -1.414042
[ Info: iteration 15, average log likelihood -1.413965
[ Info: iteration 16, average log likelihood -1.413899
[ Info: iteration 17, average log likelihood -1.413841
[ Info: iteration 18, average log likelihood -1.413791
[ Info: iteration 19, average log likelihood -1.413746
[ Info: iteration 20, average log likelihood -1.413706
[ Info: iteration 21, average log likelihood -1.413670
[ Info: iteration 22, average log likelihood -1.413637
[ Info: iteration 23, average log likelihood -1.413607
[ Info: iteration 24, average log likelihood -1.413580
[ Info: iteration 25, average log likelihood -1.413554
[ Info: iteration 26, average log likelihood -1.413529
[ Info: iteration 27, average log likelihood -1.413506
[ Info: iteration 28, average log likelihood -1.413485
[ Info: iteration 29, average log likelihood -1.413464
[ Info: iteration 30, average log likelihood -1.413445
[ Info: iteration 31, average log likelihood -1.413427
[ Info: iteration 32, average log likelihood -1.413409
[ Info: iteration 33, average log likelihood -1.413393
[ Info: iteration 34, average log likelihood -1.413377
[ Info: iteration 35, average log likelihood -1.413362
[ Info: iteration 36, average log likelihood -1.413348
[ Info: iteration 37, average log likelihood -1.413334
[ Info: iteration 38, average log likelihood -1.413321
[ Info: iteration 39, average log likelihood -1.413309
[ Info: iteration 40, average log likelihood -1.413297
[ Info: iteration 41, average log likelihood -1.413286
[ Info: iteration 42, average log likelihood -1.413276
[ Info: iteration 43, average log likelihood -1.413265
[ Info: iteration 44, average log likelihood -1.413256
[ Info: iteration 45, average log likelihood -1.413247
[ Info: iteration 46, average log likelihood -1.413238
[ Info: iteration 47, average log likelihood -1.413229
[ Info: iteration 48, average log likelihood -1.413221
[ Info: iteration 49, average log likelihood -1.413213
[ Info: iteration 50, average log likelihood -1.413206
┌ Info: EM with 100000 data points 50 iterations avll -1.413206
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4154064721165978
│     -1.41534693994898
│      ⋮
└     -1.4132060387607301
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413208
[ Info: iteration 2, average log likelihood -1.413140
[ Info: iteration 3, average log likelihood -1.413073
[ Info: iteration 4, average log likelihood -1.412993
[ Info: iteration 5, average log likelihood -1.412893
[ Info: iteration 6, average log likelihood -1.412772
[ Info: iteration 7, average log likelihood -1.412633
[ Info: iteration 8, average log likelihood -1.412482
[ Info: iteration 9, average log likelihood -1.412328
[ Info: iteration 10, average log likelihood -1.412176
[ Info: iteration 11, average log likelihood -1.412033
[ Info: iteration 12, average log likelihood -1.411901
[ Info: iteration 13, average log likelihood -1.411783
[ Info: iteration 14, average log likelihood -1.411679
[ Info: iteration 15, average log likelihood -1.411587
[ Info: iteration 16, average log likelihood -1.411506
[ Info: iteration 17, average log likelihood -1.411435
[ Info: iteration 18, average log likelihood -1.411371
[ Info: iteration 19, average log likelihood -1.411314
[ Info: iteration 20, average log likelihood -1.411262
[ Info: iteration 21, average log likelihood -1.411213
[ Info: iteration 22, average log likelihood -1.411168
[ Info: iteration 23, average log likelihood -1.411126
[ Info: iteration 24, average log likelihood -1.411086
[ Info: iteration 25, average log likelihood -1.411049
[ Info: iteration 26, average log likelihood -1.411013
[ Info: iteration 27, average log likelihood -1.410978
[ Info: iteration 28, average log likelihood -1.410945
[ Info: iteration 29, average log likelihood -1.410913
[ Info: iteration 30, average log likelihood -1.410882
[ Info: iteration 31, average log likelihood -1.410853
[ Info: iteration 32, average log likelihood -1.410825
[ Info: iteration 33, average log likelihood -1.410798
[ Info: iteration 34, average log likelihood -1.410772
[ Info: iteration 35, average log likelihood -1.410747
[ Info: iteration 36, average log likelihood -1.410724
[ Info: iteration 37, average log likelihood -1.410701
[ Info: iteration 38, average log likelihood -1.410680
[ Info: iteration 39, average log likelihood -1.410659
[ Info: iteration 40, average log likelihood -1.410639
[ Info: iteration 41, average log likelihood -1.410620
[ Info: iteration 42, average log likelihood -1.410602
[ Info: iteration 43, average log likelihood -1.410585
[ Info: iteration 44, average log likelihood -1.410568
[ Info: iteration 45, average log likelihood -1.410552
[ Info: iteration 46, average log likelihood -1.410537
[ Info: iteration 47, average log likelihood -1.410522
[ Info: iteration 48, average log likelihood -1.410508
[ Info: iteration 49, average log likelihood -1.410494
[ Info: iteration 50, average log likelihood -1.410481
┌ Info: EM with 100000 data points 50 iterations avll -1.410481
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4132083855198523
│     -1.4131401683142015
│      ⋮
└     -1.4104812272777658
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4236165310354008
│     -1.4236353038264868
│     -1.4235747409311368
│     -1.4235323673641718
│      ⋮
│     -1.4105078873903472
│     -1.4104942890364565
└     -1.4104812272777658
32×26 Array{Float64,2}:
 -0.245336    0.672189   -0.479925    -0.284723   -0.456448   -0.223085     -0.185675    -0.189306   -0.491028     0.142741     -0.448297    -0.631369    -0.41096     -0.170288   -0.119825    -0.449002   -0.44999     0.0258677  -0.300732     0.123237   -0.360221   -0.292274   -0.272795     0.197109    0.114371    -0.203645
  0.138763    0.326938   -0.31226     -0.0163097  -0.671324    0.817904     -0.170144    -0.206154   -0.456034     0.922613     -0.235485     0.260715     0.0960174   -0.734688   -0.224367    -0.566701   -0.365928   -0.0810461  -0.328967     0.206573    0.516268    0.616868    0.253465    -0.539651    0.0892005   -0.902638
 -0.350806    0.102681   -0.041716    -0.164973    0.292745    0.406718      0.365649     0.0465397   0.303286    -0.214716     -0.329622    -0.28947      0.190547    -0.099441   -0.00257088   0.0751226  -0.577204    0.204202    0.448478    -0.183418   -0.582427    0.982012    0.00809817   0.19242    -0.569339     0.194855
  0.243107    0.069247   -0.251364     0.160916   -0.0126796  -0.106247      0.128313     0.119289    0.0660204   -0.160346     -0.170683    -0.456207     0.00951575   0.206052    0.390721     0.0600222  -0.789634    0.502742    0.442897    -0.201441    0.109545    0.280739   -0.231358    -0.50408    -0.117994    -0.37667
 -0.0963704  -0.0906943   0.298077    -0.179223    0.223716   -0.0347419     0.0447918   -0.102893   -0.102531    -0.0879043    -0.135162    -0.0462518    0.208185    -0.183528    0.0509369   -0.216345    0.0275173   0.2104     -0.0166066    0.211559    0.0858929   0.172156    0.162858     0.076772    0.0252641   -0.0206651
  0.017846   -0.0204238  -0.196079     0.16408    -0.0109299   0.0124438     0.0203332   -0.0686224   0.0891908   -0.0384813     0.1139      -0.0770067   -0.0393463   -0.168798   -0.0946025    0.264465    0.0375198  -0.0914712  -0.1172      -0.0685016  -0.0869494  -0.144651    0.289132     0.143267    0.046459    -0.145172
 -0.11952     0.147025    0.157222     0.270284   -0.189818   -0.162094     -0.0653001   -0.0467464   0.182106     0.129241     -0.127594     0.16977     -0.0151256   -0.070233    0.0492702   -0.287854    0.0847587  -0.312089   -0.259204    -0.335047    0.11863    -0.136372   -0.522858    -0.355674   -0.0295014    0.231569
  0.0232837   0.364089   -0.278702     0.348776   -0.0990292   0.425387     -0.133004     0.958906   -0.321432    -0.182333      0.0413146    0.18379      0.110885    -0.169153    0.360998     0.104846    0.175481   -0.239936    0.0331059   -0.080392    0.0299242  -0.234288   -0.541392    -0.041688   -0.0762898    0.440334
 -0.204839    0.0127578   0.0625563   -0.023353   -0.247643   -0.736522     -0.315141     0.240518    0.533382    -0.734136      0.311114     0.101129    -0.468749     0.103313    0.216134     0.467796    0.560964   -0.304338    0.273965    -0.0793072  -0.331446   -0.621652   -0.0279969    0.450772    0.102899     0.0818384
  0.0603072  -0.0957007  -0.332732    -0.488531    0.0110573  -0.221881      0.408958    -0.0193909  -0.210997    -0.17109       0.162577    -0.107952    -0.528051     0.64882    -0.0154976    0.078007    0.321349   -0.136447    0.113451    -0.143587   -0.10262     0.0925772   0.0879908    0.139705    0.21755     -0.23993
  0.746957   -0.252692   -0.00166232   0.318727   -0.0813829  -0.147594     -0.00166223  -0.0488489  -0.301989     0.000976599   0.35015      0.0797123    0.110199     0.214117   -0.172519    -0.0493926   0.490457    0.179548   -0.145933     0.0454104   0.747546   -0.670817   -0.0180783   -0.263315    0.596124    -0.141866
  0.245887    0.6329     -0.955194    -0.330353   -0.282504   -0.325346      0.135424    -0.37281    -0.342636    -0.593728      0.401253    -0.340013    -0.102996     0.484684   -0.101613     0.0231691   0.0470777   0.142611   -0.257815    -0.246458    0.811598   -0.0128958   0.408296     0.685772    0.073328     0.354829
  0.714677   -0.12507     0.656554    -0.257539    0.025022   -0.0309346     0.282293     0.168942    0.0645533   -0.429365      0.152113     0.27496     -0.107512     0.442865   -0.200081     0.294902   -0.0234446   0.0459476   0.773693     0.296744    0.647989    0.381331   -0.168811    -0.199264    0.0625849    0.0557783
  0.328689   -0.0791836   0.202007    -0.456241   -0.251771    0.31813      -0.402136    -0.31641     0.227706     0.276188      0.215133     0.467375    -0.0844168    0.25001    -0.247149     0.404893   -0.0435872  -0.119932    0.684358    -0.183851    0.487061    0.142707    0.0114268    0.0510412  -0.317138     0.441039
  0.0861529  -0.627299    0.511985     0.149913    0.286811    0.425251      0.448089    -0.33997    -0.00317495  -0.423118      0.152555     0.544839    -0.125069     0.308048    0.251625    -0.161743    0.0421004  -0.14968    -0.187845    -0.0454926  -0.443384   -8.6764e-5   0.310307    -0.0188603  -0.242868    -0.00763267
  0.425526   -0.23858     0.0469926   -0.320744    0.150501    0.57953       0.160837     0.234172   -0.316977     0.577392     -0.133353     0.237176     0.00360019   0.35796     0.506778     0.0746141  -0.280145    0.514263   -0.325597     0.010832   -0.0745199  -0.33296    -0.414968     0.0218982  -0.273131     0.224229
  0.17232    -0.311518    0.342857     0.220593    0.838869    0.21015      -0.288271     0.0869174  -0.361268    -0.441565     -0.512439    -0.950897    -0.0229991   -0.268125   -0.00467455  -0.162466   -0.0545508  -0.401616    0.113794    -0.264276   -0.417632    0.0402922   0.649041    -0.371695    0.577853    -0.0261438
 -0.266577    0.201237    0.209738     0.412441    0.015115   -0.492149     -0.217385    -0.38696     0.12799     -0.626918      0.319737    -0.190539    -0.081479    -0.663176   -0.321161    -0.291686   -0.114956   -0.41448    -0.00849939   0.356988    0.0619862   0.292011    0.682051     0.0724797   0.232846    -0.274252
 -0.270977   -0.534604    0.435496     0.226519    0.404129   -0.13397      -0.115439     0.0401908   0.0643209   -0.204903      0.159576     0.469365     0.141483    -0.206204    0.0192527    0.0945047   0.98108    -0.286364   -0.683665     0.114145   -0.0372661  -1.02258    -0.180721     0.280289    0.00851042   0.293691
  0.254566   -0.0617675   0.439246     0.771213    0.432733    0.193195     -0.00090595   0.3774     -0.329676    -0.290789      0.365425     0.941463     0.247584    -0.459865   -0.328097     0.323873    1.00005    -0.248874   -0.182366     0.5014     -0.420821    0.657581    0.860952     0.541624    0.378832     0.499726
  0.559908   -0.202429    0.439222    -0.317228    0.257775   -0.338526      0.258276    -1.4135      0.310446     0.272033     -0.166032    -0.0519973   -0.481663     0.208382   -0.365218     0.438516   -0.171495    0.634958    0.0959605    0.358922    0.0713891   0.0629091   0.578058     0.304609   -0.149162    -0.307375
 -0.475989   -0.696381    0.357009    -0.709792    0.309378   -0.346737      0.324644    -0.270276   -0.126804    -0.465715     -0.0827679   -0.0145842    0.210821     0.169794    0.0800077   -0.372014   -0.143602    0.64326    -0.0420537    0.401895   -0.097477    0.429973    0.352574     0.215993    0.164046    -0.610308
  0.387378    0.0141629  -0.494285    -0.138149   -0.218308    0.367866      0.275677     0.386414   -0.309241    -0.00805808   -0.0658988   -0.212425    -0.24182     -0.0729098  -0.0313363    0.494789    0.205329    0.163397    0.42728      0.0669112  -0.420289   -0.078291    0.0675363    0.883127    0.0552756   -0.319788
  0.391793    0.431939   -0.947433    -0.37196    -0.587371    0.609899      0.134792     0.285464   -0.271098     0.303894      0.0980253   -0.52941      0.220808    -0.355941    0.437742    -0.358208   -1.00259     1.0227      0.691493     0.0829452   0.680233    0.86936     0.369415    -0.191805    0.0904404   -0.552464
  0.0273585   0.125696    0.0457549    0.0836097  -0.106904   -0.942794     -0.0504433   -0.120785    0.111194    -0.13753       0.0600986   -0.00367081  -0.0335879    0.503086    0.133551    -0.485184   -0.0615241  -0.0162645  -0.0536904   -0.323489    0.449074   -0.023175   -0.39271     -0.629924    0.172643     0.00746045
  0.297371   -0.0755795   0.256498     0.205047   -0.0438937   0.714543      0.0442468    0.254534   -0.06897      0.246329     -0.178981     0.225976     0.154199    -0.0667793   0.003205    -0.0768996  -0.0936275  -0.183297   -0.0154857   -0.0881883   0.270028   -0.0127291  -0.333295    -0.704645    0.013757     0.200203
 -0.261567   -0.323311    0.385495     0.159781    0.0316648   0.237924      0.0469254    0.181162    0.515521     0.4627       -0.340952     0.0894828    0.358208    -0.786189   -0.718114    -0.103705    0.326813   -0.327884    0.453592     0.0218242   0.053932    0.133145   -0.297054    -0.10546     0.47862     -0.337132
 -0.605961    0.723039   -0.258722    -0.0403011  -0.126051   -0.262767      0.257492     0.560463   -0.0360023    0.00595982    0.0543973   -0.299478     0.127223    -1.07199    -0.21541      0.104931    0.655212    0.211708   -0.197616     0.196888    0.165823    0.108262   -0.0232822   -0.0418049   0.644691     0.0344656
 -0.834982    0.172089   -0.636217    -0.428226   -0.0273701  -0.000144312   0.226806    -0.119865    0.452756     0.506659     -0.409657    -0.385378     0.135498    -0.254471   -0.518487    -0.062522   -0.0780222   0.136122   -0.374052    -0.311878   -0.178981   -0.110053   -0.0943611    0.304696   -0.172198    -0.146991
 -0.355557    0.334256   -0.064828    -0.0452972   0.0862217   0.0112152    -0.141818     0.0607622  -0.130991    -0.0607159    -0.240451     0.107477     0.153663    -0.0952155   1.39969     -0.0492145  -0.0129182   0.132768   -0.280337    -0.0497755  -0.611088   -0.13315    -0.168331     0.246765   -0.421707     0.427311
 -0.502008    0.178328   -0.610103     0.260354    0.505363    0.486548     -0.75081      0.0235576  -0.122205     0.00789554    0.318153    -0.408563    -0.787417     0.0359368   0.276089    -0.0197222  -0.504119   -0.436196   -0.611629    -0.0417415  -0.676115   -0.246057    0.994127     0.0848196  -0.740868     0.103941
 -0.141832   -0.198614   -0.23589      0.41207     0.0841194  -0.0394883    -0.635027    -0.347467    0.209724     0.155867     -0.00253848  -0.156015     0.605013    -0.31922    -0.00302511   0.286209   -0.560945   -0.309088   -0.119662    -0.383698    0.24743    -0.397464    0.283829    -0.0220137  -0.69912      0.0530565[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410469
[ Info: iteration 2, average log likelihood -1.410457
[ Info: iteration 3, average log likelihood -1.410445
[ Info: iteration 4, average log likelihood -1.410434
[ Info: iteration 5, average log likelihood -1.410423
[ Info: iteration 6, average log likelihood -1.410413
[ Info: iteration 7, average log likelihood -1.410403
[ Info: iteration 8, average log likelihood -1.410393
[ Info: iteration 9, average log likelihood -1.410384
[ Info: iteration 10, average log likelihood -1.410375
┌ Info: EM with 100000 data points 10 iterations avll -1.410375
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.034091e+05
      1       7.068477e+05      -1.965614e+05 |       32
      2       6.928487e+05      -1.399896e+04 |       32
      3       6.872103e+05      -5.638409e+03 |       32
      4       6.843602e+05      -2.850165e+03 |       32
      5       6.825794e+05      -1.780777e+03 |       32
      6       6.812695e+05      -1.309895e+03 |       32
      7       6.802200e+05      -1.049437e+03 |       32
      8       6.794267e+05      -7.933795e+02 |       32
      9       6.787775e+05      -6.491702e+02 |       32
     10       6.782423e+05      -5.351770e+02 |       32
     11       6.778028e+05      -4.395452e+02 |       32
     12       6.774199e+05      -3.828870e+02 |       32
     13       6.771116e+05      -3.083366e+02 |       32
     14       6.768564e+05      -2.551736e+02 |       32
     15       6.766464e+05      -2.099782e+02 |       32
     16       6.764763e+05      -1.700520e+02 |       32
     17       6.763206e+05      -1.557380e+02 |       32
     18       6.761680e+05      -1.526280e+02 |       32
     19       6.760187e+05      -1.492949e+02 |       32
     20       6.758952e+05      -1.234815e+02 |       32
     21       6.757894e+05      -1.057865e+02 |       32
     22       6.756714e+05      -1.180246e+02 |       32
     23       6.755594e+05      -1.120412e+02 |       32
     24       6.754562e+05      -1.031663e+02 |       32
     25       6.753489e+05      -1.072992e+02 |       32
     26       6.752443e+05      -1.046025e+02 |       32
     27       6.751364e+05      -1.078960e+02 |       32
     28       6.750351e+05      -1.012771e+02 |       32
     29       6.749478e+05      -8.728509e+01 |       32
     30       6.748605e+05      -8.729883e+01 |       32
     31       6.747765e+05      -8.406901e+01 |       32
     32       6.746989e+05      -7.754031e+01 |       32
     33       6.746281e+05      -7.082486e+01 |       32
     34       6.745607e+05      -6.740791e+01 |       32
     35       6.744931e+05      -6.754329e+01 |       32
     36       6.744348e+05      -5.838035e+01 |       32
     37       6.743779e+05      -5.685520e+01 |       32
     38       6.743222e+05      -5.574760e+01 |       32
     39       6.742749e+05      -4.724574e+01 |       32
     40       6.742352e+05      -3.970156e+01 |       32
     41       6.741961e+05      -3.907490e+01 |       32
     42       6.741616e+05      -3.452308e+01 |       32
     43       6.741309e+05      -3.070110e+01 |       32
     44       6.741086e+05      -2.233523e+01 |       32
     45       6.740929e+05      -1.564885e+01 |       32
     46       6.740784e+05      -1.455366e+01 |       32
     47       6.740631e+05      -1.530634e+01 |       32
     48       6.740463e+05      -1.675943e+01 |       32
     49       6.740313e+05      -1.501358e+01 |       32
     50       6.740200e+05      -1.128468e+01 |       31
K-means terminated without convergence after 50 iterations (objv = 674020.0097780895)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422095
[ Info: iteration 2, average log likelihood -1.417055
[ Info: iteration 3, average log likelihood -1.415605
[ Info: iteration 4, average log likelihood -1.414492
[ Info: iteration 5, average log likelihood -1.413410
[ Info: iteration 6, average log likelihood -1.412533
[ Info: iteration 7, average log likelihood -1.411984
[ Info: iteration 8, average log likelihood -1.411681
[ Info: iteration 9, average log likelihood -1.411504
[ Info: iteration 10, average log likelihood -1.411385
[ Info: iteration 11, average log likelihood -1.411295
[ Info: iteration 12, average log likelihood -1.411221
[ Info: iteration 13, average log likelihood -1.411158
[ Info: iteration 14, average log likelihood -1.411102
[ Info: iteration 15, average log likelihood -1.411052
[ Info: iteration 16, average log likelihood -1.411007
[ Info: iteration 17, average log likelihood -1.410964
[ Info: iteration 18, average log likelihood -1.410925
[ Info: iteration 19, average log likelihood -1.410888
[ Info: iteration 20, average log likelihood -1.410853
[ Info: iteration 21, average log likelihood -1.410821
[ Info: iteration 22, average log likelihood -1.410789
[ Info: iteration 23, average log likelihood -1.410760
[ Info: iteration 24, average log likelihood -1.410732
[ Info: iteration 25, average log likelihood -1.410705
[ Info: iteration 26, average log likelihood -1.410680
[ Info: iteration 27, average log likelihood -1.410655
[ Info: iteration 28, average log likelihood -1.410632
[ Info: iteration 29, average log likelihood -1.410610
[ Info: iteration 30, average log likelihood -1.410589
[ Info: iteration 31, average log likelihood -1.410568
[ Info: iteration 32, average log likelihood -1.410549
[ Info: iteration 33, average log likelihood -1.410530
[ Info: iteration 34, average log likelihood -1.410513
[ Info: iteration 35, average log likelihood -1.410495
[ Info: iteration 36, average log likelihood -1.410479
[ Info: iteration 37, average log likelihood -1.410463
[ Info: iteration 38, average log likelihood -1.410448
[ Info: iteration 39, average log likelihood -1.410434
[ Info: iteration 40, average log likelihood -1.410420
[ Info: iteration 41, average log likelihood -1.410406
[ Info: iteration 42, average log likelihood -1.410393
[ Info: iteration 43, average log likelihood -1.410381
[ Info: iteration 44, average log likelihood -1.410369
[ Info: iteration 45, average log likelihood -1.410357
[ Info: iteration 46, average log likelihood -1.410346
[ Info: iteration 47, average log likelihood -1.410335
[ Info: iteration 48, average log likelihood -1.410324
[ Info: iteration 49, average log likelihood -1.410314
[ Info: iteration 50, average log likelihood -1.410304
┌ Info: EM with 100000 data points 50 iterations avll -1.410304
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0650563   0.00893604   0.0600476  -0.162238    -0.0231073    0.0157179  -0.0303736  -0.17759      0.0553002    0.0122922   -0.0985375   -0.115996     0.115055   -0.124085   -0.0719928   0.0164393   -0.170055    0.0650841   0.142839     0.103474    0.133383    0.206225     0.117392     0.0358651  -0.085785    -0.0636776
  0.0454471   0.00637665   0.0418774  -0.464153     0.066362     0.847638    0.595733    0.236626    -0.290775     0.81086     -0.34761      0.1058       0.170236    0.0750322   0.439356   -0.214149     0.0145714   0.165723   -0.959954     0.191233   -0.0861298  -0.312756    -0.469488    -0.380553   -0.119364     0.271174
 -0.229807    0.121725    -0.180536   -0.0657735   -0.0868628   -0.462456   -0.189605    0.0670146    0.290314    -0.703641     0.271147    -0.105047    -0.507481    0.0837488   0.152906    0.517967     0.582585   -0.325088    0.222613    -0.10036    -0.308644   -0.27645      0.31688      0.471841    0.111476     0.0360372
 -0.106612    0.0345045   -0.202832   -0.203202     0.127967     0.241641    0.329847    0.350688    -0.222709    -0.10152     -0.112999    -0.0906267   -0.121684   -0.208228   -0.0382372   0.332823     0.619106   -0.0244201   0.00383052   0.0245357  -0.415515    0.135795     0.0650522    0.400588    0.277977    -0.0982352
 -0.222933    0.782048    -0.723054    0.47639     -0.696675    -0.794811    0.0995871   0.618162     0.565296     0.605661    -1.24217     -0.734386    -0.193659    0.0592717  -0.145738    0.115285     0.851446    0.458245    0.475869    -0.112812    0.0269872   0.100854    -0.558674     0.222032    1.01643      0.355354
  0.0579181  -0.353591     0.0337259  -0.393803     0.193686    -0.0596258   0.322356   -0.956053     0.557076     0.443206    -0.189249    -0.159774    -0.244278   -0.165919   -0.350523    0.449185    -0.132563    0.60284     0.108357     0.222626   -0.0890188  -0.0867534    0.685818     0.535314   -0.269028    -0.395298
 -0.702803    0.219277    -0.82047     0.24097      0.324417     0.107575   -0.252296    0.00143188  -0.183869     0.154208    -0.160215    -0.497569    -0.0636536  -0.12516     0.0277774  -0.118955    -0.270758   -0.473981   -0.739785    -0.30196    -0.572178   -0.288568     0.606709     0.259526   -0.143894    -0.187203
 -0.407135    0.734091    -0.174345   -0.572634    -0.519024    -0.256099   -0.263564   -0.259199    -0.408304     0.172511    -0.673382    -0.709765    -0.442119   -0.253692   -0.0293038  -0.583753    -0.566966    0.26513    -0.218858     0.0950432  -0.323438   -0.307851    -0.515074     0.144916    0.00462863  -0.112777
  0.151317    0.804432    -1.11925    -0.387494    -0.520986    -0.0102066   0.443934   -0.103996    -0.334998    -0.377221     0.392471    -0.680312    -0.21248     0.152562   -0.106258    0.0358824   -0.241585    0.131455    0.0632333   -0.0754854   0.390207    0.238909     0.265276     0.555433   -0.0285065    0.0571625
 -0.0246042  -0.078117    -0.38501    -0.211417     0.205371    -0.114772    0.179883    0.137319     0.10795     -0.0735671   -0.247199    -0.593046    -0.0393303   0.379704    0.307447    0.0168791   -0.751839    0.521732    0.471406    -0.280068   -0.0140581   0.31657     -0.289387    -0.435093   -0.172753    -0.47486
  0.217711   -0.0985264   -0.0702231   0.362328    -0.427714    -0.0152926  -0.0791651  -0.0658065    0.423664     0.0841449    0.0189917    0.298556    -0.341118    0.139243   -0.120086    0.168184    -0.220825   -0.471741   -0.171387    -0.330227    0.0332752  -0.229001    -0.344082    -0.351304   -0.31003     -0.124501
  0.376922   -0.145436    -0.0865909  -0.536278     0.149951    -0.177508    0.0894378  -0.321996    -0.376201    -0.0895595    0.161244     0.597151    -0.516445    0.811286    0.281122   -0.0439202    0.125743    0.14209    -0.16708     -0.0334944  -0.102413   -0.0497993   -0.172748     0.27676    -0.18341     -0.170471
  0.26628    -0.215001    -0.045661    0.00593273   0.0314667   -0.16016     0.0935195  -0.0788934   -0.148753    -0.0898112    0.239136    -0.0668918   -0.0196141   0.0411825  -0.328434    0.088107     0.459681    0.0134786  -0.123093    -0.0151934   0.360207   -0.424852     0.189609     0.0560724   0.527015    -0.170888
 -0.175169    0.036405     0.111401    0.249582    -0.193759    -0.336438    0.162744   -0.212121     0.0751662    0.474122     0.0476111    0.229141     0.157757    0.307089   -0.368589   -0.746452     0.347639   -0.109269    0.00806355  -1.13752     0.50239     0.104956    -0.558412    -0.611049    0.425784     0.14386
  0.106969    0.0995044   -0.258897    0.330494    -0.00837077   0.561442   -0.296554    0.331878    -0.286657     0.0752569   -0.185266     0.0724615    0.481564   -0.314017    0.354741    0.342924     0.015958    0.22799    -0.129435    -0.233363   -0.148183   -0.384976    -0.34568      0.20185    -0.338795     0.272718
  0.15033    -0.160324     0.567465    0.360858     0.688528    -0.0164142  -0.424458    0.0232169   -0.276534    -0.689482    -0.298867    -0.99964     -0.120566   -0.380371    0.0626688  -0.271941    -0.129989   -0.475387    0.245309    -0.129274   -0.364114    0.145926     0.606576    -0.528016    0.697042     0.000749201
  0.486479   -0.0573479    0.25003    -0.643013    -0.223932     0.385218   -0.326168   -0.273605     0.143097     0.277906     0.303674     0.383645    -0.154734    0.387762   -0.182486    0.595135    -0.0759077  -0.0747408   0.814179    -0.241114    0.548402    0.145948     0.0532004   -0.0768257  -0.3772       0.586389
 -0.106621   -0.581526     0.457753   -0.0269331    0.386474     0.566816   -0.0627878   0.20737      0.395517     0.387941    -0.413684     0.096049     0.317722   -0.530157   -0.566495    0.0813798    0.343164   -0.283964    0.44634     -0.0497925  -0.151375    0.241619    -0.13174      0.0758204   0.398002    -0.244701
  0.536263    0.233235    -0.167653    0.339282    -0.363363     0.161768   -0.141643    0.750557    -0.677561    -0.235541     0.137064     0.111734     0.058446    0.17397     0.334474   -0.19331      0.222223   -0.198766    0.0123529    0.222143    0.409493   -0.489023    -0.775965    -0.199926    0.36929      0.480139
 -0.338459   -0.413096     0.558881    0.27608      0.407464    -0.245074   -0.195502    0.00329408   0.131015    -0.197521     0.0863649    0.499678     0.116193   -0.196809    0.148933   -0.00956575   0.962748   -0.341951   -0.628815     0.0365585  -0.0835627  -0.88803     -0.257527     0.142309   -0.0920199    0.335538
  0.174178   -0.132858    -0.25475     0.183846    -0.149181    -0.716279   -0.0377327  -0.275442     0.172198    -0.306237     0.555314    -0.234077     0.155891    0.467192    0.142816   -0.368681    -0.259748    0.322825   -0.2334      -0.130885    0.599895   -0.318237     0.121456    -0.214197    0.181832    -0.198424
 -0.109621    0.106653     0.0880556   0.159987     0.238374     0.0491376   0.108401    0.279887    -0.0173236   -0.0649762    0.00262113   0.109139    -0.0800505  -0.0773863   0.396088   -0.157217     0.0857301  -0.0831966  -0.198782    -0.140042   -0.217089   -0.00594758  -0.135241    -0.0472061  -0.0558397    0.195974
  0.136408   -0.300928     0.623428   -0.0660405    0.479265     0.104935    0.549519   -0.0240789   -0.00816479  -0.430892    -0.0370805    0.0576025    0.128083    0.565713    0.442386    0.0837528   -0.101491    0.392262    0.306637    -0.0355764  -0.262437   -0.0484982    0.0869869    0.15699    -0.380783     0.611005
  0.778546   -0.101063     0.754983   -0.302943     0.0756831   -0.562781    0.209751   -0.406894    -0.152365    -0.246612    -0.207839     0.0890578    0.0423457   0.305612   -0.531786    0.0999628    0.369702    0.0211408   0.201882     0.432304    1.03493     0.156846    -0.118847    -0.332378    0.535362    -0.114186
  0.488514   -0.351618     0.225055    0.841829     0.568603     0.180755    0.0111418   0.0388417   -0.0140546   -0.281672     0.780053     0.976403     0.202895    0.0289289  -0.0469015   0.30737      0.386689   -0.393009    0.0218397    0.238837    0.0244594   0.362744     0.865255    -0.162568    0.075387     0.0478196
 -0.23437     0.0766405   -0.120235    0.0322585    0.0698257    0.308599   -0.388638   -0.00479859   0.198933     0.147971    -0.16686     -0.00242614   0.128652   -0.214211    0.310683    0.048831    -0.875825   -0.0786943   0.222514    -0.273758   -0.176129    0.169698     0.0393691   -0.0614385  -0.827637     0.263303
  0.542692    0.0931137    0.0206684   0.245117     0.24593      0.220637    0.537916   -0.094677    -0.458236     0.059207    -0.223854    -0.369016     0.0704875  -0.199132   -0.13955     0.0571067   -0.355204    0.429595    0.146525     0.106351   -0.0890614   0.682511     0.626826    -0.0347951   0.0915632   -0.123038
  0.292528   -0.170499     0.654738   -0.335629    -0.439299     0.0947027   0.459908    0.42969      0.254525    -0.360302     0.0156938    0.564553    -0.0999529   0.177602    0.0855432  -0.109297    -0.187303    0.485217    0.612007     0.699991    0.119594    0.34892     -0.556797    -0.161542    0.336913    -0.363744
 -0.417248   -0.434652     0.331872   -0.272333     0.170415    -0.179748    0.370461   -0.440535    -0.23353     -0.665166    -0.1521       0.0345759    0.203988   -0.136054    0.18252    -0.674166    -0.0152572   0.166961   -0.450331     0.254088   -0.37414     0.584945     0.654409     0.22542     0.0403355   -0.687839
 -0.12009    -0.19378      0.277716    0.184924     0.0690378   -0.332949   -0.799258   -0.559959    -0.0481861   -0.288533     0.190266    -0.0942939    0.0129263  -0.300264   -0.297831   -0.309201    -0.541427   -0.253259   -0.236217     0.401732    0.189087   -0.243556     0.600184     0.0567313  -0.344066    -0.216633
 -0.593805    0.503637    -0.0387697   0.295721    -0.332711    -0.233445    0.057178    0.145621     0.296511    -0.00848694   0.0528491   -0.0776503    0.236539   -1.12037    -0.350322   -0.162269     0.264923   -0.284796   -0.103411     0.227906    0.296737    0.0804274    0.00368099  -0.0877746   0.329784     0.015079
  0.350814    0.350126    -0.85996    -0.1843      -0.775627     0.930594   -0.207757    0.110602    -0.508886     0.89793     -0.147178    -0.00982156   0.0994763  -0.776322    0.112094   -0.634208    -0.580771    0.559882    0.13611      0.200326    0.698698    0.804263     0.317173    -0.470001    0.217233    -1.00295[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410294
[ Info: iteration 2, average log likelihood -1.410285
[ Info: iteration 3, average log likelihood -1.410276
[ Info: iteration 4, average log likelihood -1.410266
[ Info: iteration 5, average log likelihood -1.410258
[ Info: iteration 6, average log likelihood -1.410249
[ Info: iteration 7, average log likelihood -1.410240
[ Info: iteration 8, average log likelihood -1.410232
[ Info: iteration 9, average log likelihood -1.410224
[ Info: iteration 10, average log likelihood -1.410215
┌ Info: EM with 100000 data points 10 iterations avll -1.410215
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
