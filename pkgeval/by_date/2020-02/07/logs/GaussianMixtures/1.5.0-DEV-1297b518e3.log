Julia Version 1.5.0-DEV.247
Commit 1297b518e3 (2020-02-07 18:46 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed GaussianMixtures ─── v0.3.0
  Installed SortingAlgorithms ── v0.3.1
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed Missings ─────────── v0.4.3
  Installed ScikitLearnBase ──── v0.5.0
  Installed CMake ────────────── v1.1.2
  Installed QuadGK ───────────── v2.3.1
  Installed Distributions ────── v0.22.4
  Installed FillArrays ───────── v0.8.4
  Installed Parameters ───────── v0.12.0
  Installed CMakeWrapper ─────── v0.2.3
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed StatsFuns ────────── v0.9.3
  Installed Arpack ───────────── v0.4.0
  Installed Rmath ────────────── v0.6.0
  Installed PDMats ───────────── v0.9.11
  Installed DataAPI ──────────── v1.1.0
  Installed FileIO ───────────── v1.2.1
  Installed OrderedCollections ─ v1.1.0
  Installed Distances ────────── v0.8.2
  Installed NearestNeighbors ─── v0.4.4
  Installed SpecialFunctions ─── v0.9.0
  Installed Compat ───────────── v2.2.0
  Installed BinaryProvider ───── v0.5.8
  Installed Arpack_jll ───────── v3.5.0+2
  Installed StatsBase ────────── v0.32.0
  Installed LegacyStrings ────── v0.4.1
  Installed Blosc ────────────── v0.5.1
  Installed URIParser ────────── v0.4.0
  Installed Clustering ───────── v0.13.3
  Installed JLD ──────────────── v0.9.2
  Installed BinDeps ──────────── v1.0.0
  Installed HDF5 ─────────────── v0.12.5
  Installed DataStructures ───── v0.17.9
  Installed StaticArrays ─────── v0.12.1
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                                                                                                    0.2%##                                                                         3.4%#####                                                                      7.1%#####                                                                      7.2%#######                                                                   10.3%##########                                                                14.7%###############                                                           21.4%####################                                                      28.7%##########################                                                37.3%###################################                                       49.2%###########################################                               60.8%########################################################                  78.5%######################################################################## 100.0%
#=#=#                                                                         ###############################################                           65.6%######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_8pzBWr/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -1.0149915124382572e7, [96005.55500811877, 3994.444991881232], [-458.0836444282399 -4855.932202786764 -4012.057642137507; 660.5116496345418 4700.878900264576 4030.4528583677884], [[88387.4698903694 -4274.343709419271 2943.229991912568; -4274.343709419271 89991.80706227376 -2297.630863196314; 2943.229991912568 -2297.630863196314 90534.05798404313], [11957.831801277283 4112.5064118893915 -3134.8648341970325; 4112.5064118893915 10038.29969689695 2208.5034977797923; -3134.8648341970325 2208.5034977797923 8963.534284431717]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.157129e+03
      1       1.019215e+03      -1.379135e+02 |        7
      2       9.371699e+02      -8.204521e+01 |        2
      3       9.300065e+02      -7.163371e+00 |        2
      4       9.259918e+02      -4.014748e+00 |        2
      5       9.095888e+02      -1.640299e+01 |        0
      6       9.095888e+02       0.000000e+00 |        0
K-means converged with 6 iterations (objv = 909.5887731531047)
┌ Info: K-means with 272 data points using 6 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.074036
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.853024
[ Info: iteration 2, lowerbound -3.722202
[ Info: iteration 3, lowerbound -3.579758
[ Info: iteration 4, lowerbound -3.416215
[ Info: iteration 5, lowerbound -3.247134
[ Info: iteration 6, lowerbound -3.091449
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.960232
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.843716
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.744882
[ Info: iteration 10, lowerbound -2.673237
[ Info: dropping number of Gaussions to 4
[ Info: iteration 11, lowerbound -2.624158
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.567562
[ Info: iteration 13, lowerbound -2.515667
[ Info: iteration 14, lowerbound -2.470192
[ Info: iteration 15, lowerbound -2.429328
[ Info: iteration 16, lowerbound -2.393172
[ Info: iteration 17, lowerbound -2.360943
[ Info: iteration 18, lowerbound -2.333209
[ Info: iteration 19, lowerbound -2.313800
[ Info: iteration 20, lowerbound -2.307426
[ Info: dropping number of Gaussions to 2
[ Info: iteration 21, lowerbound -2.302932
[ Info: iteration 22, lowerbound -2.299260
[ Info: iteration 23, lowerbound -2.299256
[ Info: iteration 24, lowerbound -2.299254
[ Info: iteration 25, lowerbound -2.299254
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sat Feb  8 00:55:10 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sat Feb  8 00:55:18 2020: K-means with 272 data points using 6 iterations
11.3 data points per parameter
, Sat Feb  8 00:55:20 2020: EM with 272 data points 0 iterations avll -2.074036
5.8 data points per parameter
, Sat Feb  8 00:55:22 2020: GMM converted to Variational GMM
, Sat Feb  8 00:55:31 2020: iteration 1, lowerbound -3.853024
, Sat Feb  8 00:55:31 2020: iteration 2, lowerbound -3.722202
, Sat Feb  8 00:55:31 2020: iteration 3, lowerbound -3.579758
, Sat Feb  8 00:55:31 2020: iteration 4, lowerbound -3.416215
, Sat Feb  8 00:55:31 2020: iteration 5, lowerbound -3.247134
, Sat Feb  8 00:55:31 2020: iteration 6, lowerbound -3.091449
, Sat Feb  8 00:55:31 2020: dropping number of Gaussions to 7
, Sat Feb  8 00:55:31 2020: iteration 7, lowerbound -2.960232
, Sat Feb  8 00:55:31 2020: dropping number of Gaussions to 6
, Sat Feb  8 00:55:31 2020: iteration 8, lowerbound -2.843716
, Sat Feb  8 00:55:31 2020: dropping number of Gaussions to 5
, Sat Feb  8 00:55:31 2020: iteration 9, lowerbound -2.744882
, Sat Feb  8 00:55:31 2020: iteration 10, lowerbound -2.673237
, Sat Feb  8 00:55:31 2020: dropping number of Gaussions to 4
, Sat Feb  8 00:55:31 2020: iteration 11, lowerbound -2.624158
, Sat Feb  8 00:55:31 2020: dropping number of Gaussions to 3
, Sat Feb  8 00:55:31 2020: iteration 12, lowerbound -2.567562
, Sat Feb  8 00:55:31 2020: iteration 13, lowerbound -2.515667
, Sat Feb  8 00:55:31 2020: iteration 14, lowerbound -2.470192
, Sat Feb  8 00:55:31 2020: iteration 15, lowerbound -2.429328
, Sat Feb  8 00:55:31 2020: iteration 16, lowerbound -2.393172
, Sat Feb  8 00:55:31 2020: iteration 17, lowerbound -2.360943
, Sat Feb  8 00:55:31 2020: iteration 18, lowerbound -2.333209
, Sat Feb  8 00:55:31 2020: iteration 19, lowerbound -2.313800
, Sat Feb  8 00:55:31 2020: iteration 20, lowerbound -2.307426
, Sat Feb  8 00:55:31 2020: dropping number of Gaussions to 2
, Sat Feb  8 00:55:31 2020: iteration 21, lowerbound -2.302932
, Sat Feb  8 00:55:31 2020: iteration 22, lowerbound -2.299260
, Sat Feb  8 00:55:31 2020: iteration 23, lowerbound -2.299256
, Sat Feb  8 00:55:31 2020: iteration 24, lowerbound -2.299254
, Sat Feb  8 00:55:31 2020: iteration 25, lowerbound -2.299254
, Sat Feb  8 00:55:31 2020: iteration 26, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: iteration 27, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: iteration 28, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: iteration 29, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: iteration 30, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: iteration 31, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: iteration 32, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: iteration 33, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: iteration 34, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: iteration 35, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: iteration 36, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: iteration 37, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: iteration 38, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: iteration 39, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: iteration 40, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: iteration 41, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: iteration 42, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: iteration 43, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: iteration 44, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: iteration 45, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: iteration 46, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: iteration 47, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: iteration 48, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: iteration 49, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: iteration 50, lowerbound -2.299253
, Sat Feb  8 00:55:31 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601502, 95.95490777398503]
β = [178.04509222601502, 95.95490777398503]
m = [4.250300733269899 79.28686694436169; 2.000229257775361 53.85198717246123]
ν = [180.04509222601502, 97.95490777398503]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484463 -0.007644049042327635; 0.0 0.008581705166333248], [0.3758763611948567 -0.008953123827346258; 0.0 0.01274866477740925]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -1.0164901386616716
avll from llpg:  -1.016490138661606
avll direct:     -1.016490138661606
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9865959090083635
avll from llpg:  -0.9865959090083634
avll direct:     -0.9865959090083632
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
  0.0505155    0.0430059     0.01453     -0.0207105   -0.130612    0.0505835    0.0234154    0.0551195   -0.0121581     0.036141     0.0216918    0.0130992    -0.10811      -0.0757605    0.177358     0.0396863    0.071747      0.0421507     0.024073    -0.00615918  -0.0233141    0.0135505    0.0153939   -0.0311694   -0.00401787   0.0644057
  0.0547428    0.0459883     0.0413961    0.133945    -0.134454    0.0677788    0.128623     0.0633043   -0.0269992    -0.159292     0.136315    -0.05587      -0.0523403    -0.229897     0.0462689   -0.0543545    0.00440165   -0.0261234     0.00548986  -0.00685773  -0.134203    -0.186023     0.0660073   -0.104551    -0.0596541   -0.117047
 -0.0579325   -0.127632     -0.210403    -0.0188917    0.010792    0.080794    -0.0434526    0.0506797    0.0659552    -0.0745863   -0.0707151   -0.119212     -0.112225      0.0156357    0.0843851   -0.0230182   -0.194508      0.0254675     0.0633358    0.0805997   -0.0276895   -0.0206715   -0.133487     0.0177915    0.0626137    0.00150342
  0.0450493   -0.152327     -0.169728     0.00820311   0.0136105   0.170552     0.103214    -0.031429     0.0790551    -0.0837279   -0.0614969    0.0918871     0.0599757     0.0419047    0.0278179   -0.102548     0.115933      0.0533333    -0.0442459   -0.268758    -0.0346137   -0.0712555   -0.173079    -0.163043    -0.216438     0.112344
  0.125981     0.061336      0.0200267   -0.107018    -0.0741973   0.0999442    0.123294    -0.0439149   -0.0383995     0.0394456   -0.016077    -0.0428983     0.0537038     0.0300411    0.0106196   -0.110816    -0.0770238     0.298385      0.14459      0.0144868    0.0410306   -0.0269873    0.0941231    0.0957388    0.0380824    0.101825
  0.0531034   -0.019774     -0.070632     0.12311     -0.223987   -0.0877617   -0.0360828    0.0709226   -0.0220739    -0.102381     0.104421     0.210883     -0.0400829    -0.0223022    0.101055     0.0742535   -0.0535003    -0.0120247    -0.0092693    0.0276741   -0.213626     0.00858399   0.063217    -0.0486174   -0.0508153   -0.0270054
 -0.13402      0.157834      0.0470448   -0.153375    -0.0846583  -0.0568138   -0.0211906   -0.116454    -0.0564489    -0.120836     0.0324547   -0.0026261     0.0684987    -0.163104    -0.0789375   -0.236959     0.0302341    -0.0077626     0.0473763   -0.0421899    0.0200613   -0.0593201   -0.0418285   -0.0144248   -0.0815693    0.0496326
 -0.083659     0.0098742     0.0427691   -0.11367      0.330989   -0.0264848    0.00419491  -5.26232e-5  -0.0462403     0.0821433    0.00852247   0.0701022    -0.0451282     0.0537059    0.113132    -0.105705    -0.183028     -0.0152373    -0.120177     0.101132    -0.0893097   -0.0429685    0.0877376    0.0393361   -0.145027    -0.0755533
  0.060555    -0.0160965    -0.0719118    0.147075    -0.052038   -0.0936198   -0.163175    -0.0764887   -0.0323865    -0.0146162    0.0895404    0.0194442     0.00655958    0.00900222  -0.039462    -0.00982514  -0.0545013     0.0108069    -0.032637    -0.0256511    0.203594    -0.043018    -0.0331503    0.0333284   -0.0621253    0.0254445
 -0.00832265  -0.0268404    -0.0492325   -0.0158648   -0.0334361   0.0501036    0.0531595    0.0376225   -0.0738266    -0.0441585    0.0754827   -0.0143671     0.0223127     0.00767151   0.0714196    0.0507755   -0.000901323   0.0746658    -0.0127211    0.00554342  -0.180407    -0.181887     0.0651556    0.0883446   -0.0591545   -0.0685444
 -0.0349551    0.00260549   -0.0759518   -0.0894646    0.0794834  -0.0588251   -0.183565    -0.179219    -0.214771     -0.0625772   -0.0795777    0.0750399    -0.11088       0.10855      0.0284001   -0.0129981    0.0432827    -0.00413251   -0.00250399  -0.12271      0.0607163    0.100405     0.134267     0.00599768   0.0133045    0.038939
  0.0385174   -0.043985      0.0745663    0.234263    -0.0264613  -0.187452    -0.0263489    0.114009    -0.174816     -0.122003     0.152021     0.0560156     0.147641      0.00506037   0.187982     0.0776457   -0.255606      0.0242216    -0.175351    -0.0780861   -0.102404    -0.0606322   -0.00136847  -0.00446801   0.00377434  -0.0601465
  0.281066     0.0692042    -0.102775    -0.0421625    0.0533967   0.153326    -0.0445821   -0.0292408   -0.101382     -0.0843163   -0.0295681    0.0161868    -0.215449      0.0588745    0.22964      0.0506388   -0.0424132    -0.0225244    -0.0480236   -0.0915406    0.0266988   -0.0837821   -0.00884017  -0.123951     0.0584832    0.0362231
 -0.167442    -0.00773789    0.11165     -0.0699991   -0.0745957  -0.100553     0.162048     0.0487432   -0.0307148     0.0627299    0.115355     0.0383445     0.0480475    -0.125933    -0.0218312   -0.0169893   -0.00877563   -0.0209735    -0.122902     0.0257349   -0.0619876    0.152703    -0.15779      0.0556803   -0.0364071    0.0639184
 -0.059569    -0.0584409    -0.011837    -0.00851501   0.0396549  -0.00126665  -0.0851672   -0.0909974    0.0011513    -0.153913     0.009591     0.0457825     0.0115134     0.138106     0.115179    -0.0180988   -0.0709137    -0.149502     -0.0569772   -0.06966      0.0195202    0.073166     0.0212394   -0.0989148   -0.0977972    0.0493695
  0.0782712   -0.0346131     0.0720307    0.0392922   -0.018384    0.182229     0.032337    -0.0254946    0.127074      0.00968483  -0.0672152    0.0364132     0.110482      0.018116     0.0439927   -0.0236404   -0.141463      0.0911327     0.0687518   -0.231263    -0.00232122   0.0151682   -0.0130429   -0.0586854    0.0857709    0.0965348
  0.072557    -0.0231032    -0.20379      0.0487596    0.257089    0.00127016  -0.0189369    0.0452822    0.0111038    -0.144508     0.0703186    0.056796      0.153991     -0.0488214    0.132255     0.00790969  -0.0160356     0.128639     -0.123587    -0.0262626   -0.0642913    0.111787    -0.0269491    0.00286722  -0.0371817   -0.0186223
 -0.0563907   -0.00253258   -0.0616184   -0.167203    -0.0254188   0.131152    -0.0155731   -0.0912322   -0.0461882     0.0450454    0.0781085    0.0112099     0.0502606     0.0526409    0.152513     0.0314959    0.07118      -0.0174506     0.0621201    0.145455     0.014152    -0.0346047    0.144887    -0.00159407  -0.0350065   -0.0282932
  0.0373854   -0.0596441    -0.0440761   -0.150299    -0.0718719   0.184786     0.176267    -0.15702     -0.108622      0.150811     0.0303715   -0.0456674     0.000563573   0.0594207    0.0316946   -0.381868     0.0454615     0.157066      0.0145844    0.102456     0.0492195    0.103857     0.114647     0.065092     0.0951364    0.0040729
 -0.0206574    0.102031      0.0263748    0.103082     0.0456037   0.106594     0.161148    -0.0747874   -0.00254529    0.298411     0.0493779   -0.0326183    -0.0951306     0.0137719   -0.108753    -0.161608     0.0500119     0.226171     -0.0926152   -0.0659151    0.101732     0.142741     0.201143     0.0414377   -0.211228     0.0334656
  0.0130233    0.139017     -0.0901132    0.078197     0.121317    0.0312706   -0.122805     0.119697    -0.157551      0.0158961    0.122989     0.035026     -0.0374217     0.0675524    0.0526641   -0.0297137    0.0255524     0.106494      0.0241978   -0.179946    -0.121963    -0.0609061   -0.207439    -0.0278363   -0.225941    -0.136225
 -0.141711    -0.178667      0.0481214    0.0618054   -0.14794    -0.0557148    0.0447403   -0.238767     0.0932987    -0.236691     0.148852    -0.0505313    -0.0574106     0.148866     0.128346     0.0143442    0.0768048    -0.0299004     0.133733     0.135994    -0.0455971   -0.0122215   -0.136179    -0.124303     0.0370212   -0.141961
 -0.167383     0.00561469   -0.0255809   -0.100763     0.040072    0.0258901   -0.187391    -0.0118602   -0.0582908     0.0121568    0.0835469   -0.0696753    -0.132805      0.114621    -0.0955788   -0.0261487   -0.176649     -0.084552      0.0752543   -0.0277489   -0.15618     -0.0174924    0.0175344    0.179042    -0.0230282    0.0295049
  0.27777      0.272197     -0.0314913    0.0295381    0.101514   -0.058426    -0.103237     0.0565092    0.000631241   0.0684867    0.0805546   -0.0657232    -0.0479503     0.0576472    0.0718844    0.309353    -0.00166172    0.145854     -0.170161    -0.0195078    0.0426201    0.0443145    0.0919466    0.0156377    0.0801753    0.00501833
 -0.0357772   -0.102568      0.131475     0.101583     0.115732    0.0716314   -0.0452378    0.196625    -0.0303042    -0.0339798    0.247829    -0.0361581    -0.00193175   -0.0458616   -0.117997    -0.0362889   -0.216929      0.0836655     0.175419    -0.0330525   -0.0802905   -0.0818873    0.0917301   -0.00762727   0.0623408   -0.19913
  0.0591712   -0.0128641     0.0187918   -0.0726882    0.102277    0.193047    -0.05541     -0.101904     0.0318261    -0.189665     0.154702     0.0617743    -0.00410085   -0.147003    -0.00225376   0.00705821  -0.00955359    0.164978     -0.0559656    0.0938644    0.0273681   -0.0684484    0.180048    -0.146505    -0.0168322    0.0517654
 -0.0288384   -0.000545769  -0.0876925   -0.18414      0.0571012   0.0075149   -0.0790846   -0.17925     -0.0289604    -0.0319214    0.0085854   -0.000512548   0.0661007     0.0322435   -0.0870333    0.0101737    0.0829649     0.0670901     0.210074    -0.0945389   -0.0747332    0.00692437  -0.0337745   -0.0256341   -0.038526     0.0256943
  0.0500553    0.0325634     0.126356    -0.118422     0.0270978   0.121325     0.0136502    0.0301101   -0.127423     -0.0874033   -0.00222318  -0.0128638     0.0651888    -0.115993    -0.0104004   -0.0903598   -0.0111049     0.0503222    -0.13428     -0.0387365    0.0448228   -0.0230536   -0.0770759   -0.0243964   -0.00687453   0.014585
  0.0466072    0.00263565    0.135582     0.186402    -0.0730974  -0.16953     -0.119914    -0.0034869   -0.0713332     0.0344355   -0.241047    -0.0139676    -0.070167     -0.10409     -0.0972026   -0.100611     0.000653547  -0.186088      0.0749652    0.240461    -0.183708     0.105989    -0.220247    -0.131832     0.075042     0.00798775
  0.144939    -0.202311     -0.0446718   -0.181246    -0.26039     2.92316e-5  -0.0566167   -0.0206611   -0.0585357    -0.0873495    0.0279703    0.0527268    -0.0821013    -0.109553     0.017565    -0.179492     0.0374508     0.00438504   -0.0762712    0.0222446   -0.0877442   -0.0433002    0.0343377    0.0104033   -0.0632601    0.120159
  0.0090967   -0.031224      0.00448845   0.0135953   -0.0887902  -0.0101253   -0.117013     0.037039    -0.02137       0.0825539    0.0212643    0.0399521    -0.066757      0.0680143    0.0123531   -0.0432265    0.00735845    0.143033      0.163313     0.069681     0.0278413   -0.0220706   -0.00701357  -0.00277171  -0.0353434    0.00864529
  0.116669    -0.0202222    -0.0109298   -0.0449232    0.21214    -0.0596229   -0.0339924    0.039851    -0.158053     -0.063426    -0.0321706    0.126234      0.111093     -0.0194661   -0.0590471    0.0940604   -0.0515915     0.000333005   0.0312208    0.00782594  -0.171195     0.0471565   -0.166571     0.125463     0.0553435    0.126317kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4031163762832033
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.403234
[ Info: iteration 2, average log likelihood -1.403135
[ Info: iteration 3, average log likelihood -1.402533
[ Info: iteration 4, average log likelihood -1.396022
[ Info: iteration 5, average log likelihood -1.380612
[ Info: iteration 6, average log likelihood -1.374135
[ Info: iteration 7, average log likelihood -1.372652
[ Info: iteration 8, average log likelihood -1.371988
[ Info: iteration 9, average log likelihood -1.371583
[ Info: iteration 10, average log likelihood -1.371292
[ Info: iteration 11, average log likelihood -1.371070
[ Info: iteration 12, average log likelihood -1.370906
[ Info: iteration 13, average log likelihood -1.370789
[ Info: iteration 14, average log likelihood -1.370703
[ Info: iteration 15, average log likelihood -1.370640
[ Info: iteration 16, average log likelihood -1.370592
[ Info: iteration 17, average log likelihood -1.370554
[ Info: iteration 18, average log likelihood -1.370525
[ Info: iteration 19, average log likelihood -1.370500
[ Info: iteration 20, average log likelihood -1.370481
[ Info: iteration 21, average log likelihood -1.370465
[ Info: iteration 22, average log likelihood -1.370451
[ Info: iteration 23, average log likelihood -1.370441
[ Info: iteration 24, average log likelihood -1.370432
[ Info: iteration 25, average log likelihood -1.370424
[ Info: iteration 26, average log likelihood -1.370418
[ Info: iteration 27, average log likelihood -1.370413
[ Info: iteration 28, average log likelihood -1.370409
[ Info: iteration 29, average log likelihood -1.370406
[ Info: iteration 30, average log likelihood -1.370403
[ Info: iteration 31, average log likelihood -1.370401
[ Info: iteration 32, average log likelihood -1.370400
[ Info: iteration 33, average log likelihood -1.370398
[ Info: iteration 34, average log likelihood -1.370397
[ Info: iteration 35, average log likelihood -1.370396
[ Info: iteration 36, average log likelihood -1.370396
[ Info: iteration 37, average log likelihood -1.370395
[ Info: iteration 38, average log likelihood -1.370395
[ Info: iteration 39, average log likelihood -1.370394
[ Info: iteration 40, average log likelihood -1.370394
[ Info: iteration 41, average log likelihood -1.370394
[ Info: iteration 42, average log likelihood -1.370394
[ Info: iteration 43, average log likelihood -1.370394
[ Info: iteration 44, average log likelihood -1.370394
[ Info: iteration 45, average log likelihood -1.370393
[ Info: iteration 46, average log likelihood -1.370393
[ Info: iteration 47, average log likelihood -1.370393
[ Info: iteration 48, average log likelihood -1.370393
[ Info: iteration 49, average log likelihood -1.370393
[ Info: iteration 50, average log likelihood -1.370393
┌ Info: EM with 100000 data points 50 iterations avll -1.370393
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4032343500938491
│     -1.4031347074985296
│      ⋮
└     -1.3703932267304513
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.370527
[ Info: iteration 2, average log likelihood -1.370405
[ Info: iteration 3, average log likelihood -1.369723
[ Info: iteration 4, average log likelihood -1.364553
[ Info: iteration 5, average log likelihood -1.354028
[ Info: iteration 6, average log likelihood -1.346733
[ Info: iteration 7, average log likelihood -1.343368
[ Info: iteration 8, average log likelihood -1.341063
[ Info: iteration 9, average log likelihood -1.338900
[ Info: iteration 10, average log likelihood -1.336672
[ Info: iteration 11, average log likelihood -1.334393
[ Info: iteration 12, average log likelihood -1.332209
[ Info: iteration 13, average log likelihood -1.330384
[ Info: iteration 14, average log likelihood -1.329116
[ Info: iteration 15, average log likelihood -1.328231
[ Info: iteration 16, average log likelihood -1.327545
[ Info: iteration 17, average log likelihood -1.326964
[ Info: iteration 18, average log likelihood -1.326463
[ Info: iteration 19, average log likelihood -1.326039
[ Info: iteration 20, average log likelihood -1.325667
[ Info: iteration 21, average log likelihood -1.325334
[ Info: iteration 22, average log likelihood -1.325033
[ Info: iteration 23, average log likelihood -1.324763
[ Info: iteration 24, average log likelihood -1.324523
[ Info: iteration 25, average log likelihood -1.324315
[ Info: iteration 26, average log likelihood -1.324131
[ Info: iteration 27, average log likelihood -1.323964
[ Info: iteration 28, average log likelihood -1.323816
[ Info: iteration 29, average log likelihood -1.323689
[ Info: iteration 30, average log likelihood -1.323582
[ Info: iteration 31, average log likelihood -1.323488
[ Info: iteration 32, average log likelihood -1.323401
[ Info: iteration 33, average log likelihood -1.323320
[ Info: iteration 34, average log likelihood -1.323243
[ Info: iteration 35, average log likelihood -1.323165
[ Info: iteration 36, average log likelihood -1.323085
[ Info: iteration 37, average log likelihood -1.323000
[ Info: iteration 38, average log likelihood -1.322915
[ Info: iteration 39, average log likelihood -1.322834
[ Info: iteration 40, average log likelihood -1.322762
[ Info: iteration 41, average log likelihood -1.322700
[ Info: iteration 42, average log likelihood -1.322648
[ Info: iteration 43, average log likelihood -1.322604
[ Info: iteration 44, average log likelihood -1.322568
[ Info: iteration 45, average log likelihood -1.322537
[ Info: iteration 46, average log likelihood -1.322512
[ Info: iteration 47, average log likelihood -1.322491
[ Info: iteration 48, average log likelihood -1.322473
[ Info: iteration 49, average log likelihood -1.322457
[ Info: iteration 50, average log likelihood -1.322443
┌ Info: EM with 100000 data points 50 iterations avll -1.322443
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.370527461997099
│     -1.3704050620823378
│      ⋮
└     -1.3224429670977575
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.322605
[ Info: iteration 2, average log likelihood -1.322431
[ Info: iteration 3, average log likelihood -1.322048
[ Info: iteration 4, average log likelihood -1.318676
[ Info: iteration 5, average log likelihood -1.305824
[ Info: iteration 6, average log likelihood -1.289855
[ Info: iteration 7, average log likelihood -1.280850
[ Info: iteration 8, average log likelihood -1.276841
[ Info: iteration 9, average log likelihood -1.275048
[ Info: iteration 10, average log likelihood -1.274021
[ Info: iteration 11, average log likelihood -1.273216
[ Info: iteration 12, average log likelihood -1.272464
[ Info: iteration 13, average log likelihood -1.271810
[ Info: iteration 14, average log likelihood -1.271381
[ Info: iteration 15, average log likelihood -1.271153
[ Info: iteration 16, average log likelihood -1.271029
[ Info: iteration 17, average log likelihood -1.270942
[ Info: iteration 18, average log likelihood -1.270863
[ Info: iteration 19, average log likelihood -1.270776
[ Info: iteration 20, average log likelihood -1.270668
[ Info: iteration 21, average log likelihood -1.270532
[ Info: iteration 22, average log likelihood -1.270378
[ Info: iteration 23, average log likelihood -1.270222
[ Info: iteration 24, average log likelihood -1.270075
[ Info: iteration 25, average log likelihood -1.269938
[ Info: iteration 26, average log likelihood -1.269808
[ Info: iteration 27, average log likelihood -1.269690
[ Info: iteration 28, average log likelihood -1.269588
[ Info: iteration 29, average log likelihood -1.269506
[ Info: iteration 30, average log likelihood -1.269440
[ Info: iteration 31, average log likelihood -1.269388
[ Info: iteration 32, average log likelihood -1.269346
[ Info: iteration 33, average log likelihood -1.269310
[ Info: iteration 34, average log likelihood -1.269278
[ Info: iteration 35, average log likelihood -1.269248
[ Info: iteration 36, average log likelihood -1.269217
[ Info: iteration 37, average log likelihood -1.269185
[ Info: iteration 38, average log likelihood -1.269147
[ Info: iteration 39, average log likelihood -1.269101
[ Info: iteration 40, average log likelihood -1.269041
[ Info: iteration 41, average log likelihood -1.268962
[ Info: iteration 42, average log likelihood -1.268858
[ Info: iteration 43, average log likelihood -1.268722
[ Info: iteration 44, average log likelihood -1.268543
[ Info: iteration 45, average log likelihood -1.268324
[ Info: iteration 46, average log likelihood -1.268098
[ Info: iteration 47, average log likelihood -1.267889
[ Info: iteration 48, average log likelihood -1.267697
[ Info: iteration 49, average log likelihood -1.267502
[ Info: iteration 50, average log likelihood -1.267289
┌ Info: EM with 100000 data points 50 iterations avll -1.267289
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3226052701552629
│     -1.3224305951393938
│      ⋮
└     -1.26728922893131
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.267334
[ Info: iteration 2, average log likelihood -1.266911
[ Info: iteration 3, average log likelihood -1.265797
[ Info: iteration 4, average log likelihood -1.255104
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.224949
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.206217
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.196908
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.185393
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      2
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.177439
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.189947
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.183736
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│      5
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.177261
[ Info: iteration 13, average log likelihood -1.195608
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.177534
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      2
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.171847
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.187578
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.177187
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     2
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.169962
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.178994
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.176318
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     2
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.171167
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.180361
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.171077
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     2
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.161687
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.172035
[ Info: iteration 26, average log likelihood -1.183664
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     2
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.160159
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.171426
[ Info: iteration 29, average log likelihood -1.162683
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.146831
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.183863
[ Info: iteration 32, average log likelihood -1.176324
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     2
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.157309
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.169783
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.161827
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.168247
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.168144
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.161194
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.162831
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.169831
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.175454
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.164310
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.166714
[ Info: iteration 44, average log likelihood -1.167686
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      2
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.150515
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      6
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.169607
[ Info: iteration 47, average log likelihood -1.177828
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.163551
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.165249
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.167386
┌ Info: EM with 100000 data points 50 iterations avll -1.167386
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2673337549935715
│     -1.2669111754874158
│      ⋮
└     -1.1673863095774395
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.164379
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      9
│     10
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.155891
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      9
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.152414
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.122426
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.106851
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     19
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.089393
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     15
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.072999
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.078954
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.089567
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     19
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.075491
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.060210
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     19
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.093107
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     24
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.071825
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.078035
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     15
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.074091
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.077906
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.073668
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     19
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.069237
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.053046
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.079889
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.081476
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     19
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.060843
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.075233
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.084844
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.062250
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.075302
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     15
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.083651
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.063379
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.080198
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.080232
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.060354
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.081236
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     10
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.085114
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.057284
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.078688
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.086142
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.061777
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.075299
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     15
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.083613
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.063250
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.080191
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.080214
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.060308
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.081230
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     10
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.085107
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     20
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.057262
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.078685
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.086137
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.061767
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.075296
┌ Info: EM with 100000 data points 50 iterations avll -1.075296
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1643788417258174
│     -1.1558908351107615
│      ⋮
└     -1.0752961555940113
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4031163762832033
│     -1.4032343500938491
│     -1.4031347074985296
│     -1.4025330453366873
│      ⋮
│     -1.0861373214194328
│     -1.0617671300951803
└     -1.0752961555940113
32×26 Array{Float64,2}:
  0.0110395     0.0447408     0.0387577     0.108099      0.129927    0.0603232    -0.0453938   0.1944      -0.0344723   -0.449279     0.256763     -0.0306902   -0.119396   -0.0717163   -0.132437    -0.180272    -0.231373     0.0788709     0.205374    -0.0351429   -0.0816247   -0.0430969    0.135905    -0.0306018     0.0541571   -0.154774
 -0.0701203    -0.298305      0.274962      0.0917545     0.0995091   0.0530542    -0.0455576   0.197762    -0.0282442    0.405283     0.247203     -0.0503281    0.122268   -0.00607887  -0.0392551    0.155531    -0.196674     0.0784213     0.159923    -0.0331274   -0.0875743   -0.104067     0.0376814    0.0131492     0.060599    -0.245524
  0.191517      0.15315      -0.000684675   0.0375667     0.138177   -0.0481215    -0.112598    0.0565118    0.0637461    0.340936    -0.0553831    -0.089195    -0.0667376  -0.503268     0.123327     0.361666     0.00557049   0.146427     -0.17064     -0.0266822    0.14456      0.139972     0.0897343    0.0145391     0.0133475   -0.00966377
  0.418878      0.378083     -0.0550474     0.00647156    0.0511868  -0.0337077    -0.096135    0.0564479   -0.195762    -0.129543     0.319532      0.039402    -0.0382105   0.623135     0.0424536    0.268981    -0.0251176    0.144059     -0.169678    -0.0106525   -0.0631915   -0.0406308    0.0917486    0.0201224     0.100382     0.0274243
  0.105703     -0.0190276    -0.00828974   -0.0542152     0.197317   -0.0543342    -0.0305689   0.0406783   -0.157409    -0.0961761   -0.0410075     0.110858     0.092209   -0.00991452  -0.062548     0.0589066   -0.0492195    0.036453      0.0294229   -0.00596596  -0.164669     0.0455217   -0.16143      0.0908239     0.014485     0.123808
 -0.0246662     0.000767038  -0.0654076    -0.18898       0.0643719   0.00566934   -0.0746212  -0.179906    -0.0292099   -0.0503684   -0.0304984     0.0213973    0.0617541   0.0439614   -0.0870872   -0.0542035    0.0647854    0.0952        0.208697    -0.0852261   -0.0735649    0.0189441    0.00279965  -0.023427     -0.0542517    0.0300995
 -0.0014502     0.117726     -0.0613103     0.0649856     0.104367    0.000533698  -0.0883695   0.103349    -0.138881     0.02377      0.118915      0.0383147    0.0168392   0.0281346    0.0793487   -0.0322284    0.0170788    0.0960707    -0.0047354   -0.200355    -0.107135    -0.0319099   -0.20257     -0.0190107    -0.219661    -0.105817
  0.00502891   -0.0144538    -0.0536336     0.0177573    -0.0457926   0.00779717   -0.0795011  -0.0890957   -0.0323507    0.00292528   0.0909765     0.0106906    0.0533935   0.015398     0.043616     0.00999723   0.0234325   -0.0149682     0.00447569   0.12665      0.149247    -0.0487681    0.0435025    0.0153158    -0.0464602    0.00198834
  0.106228      0.217586      0.0650573     0.0609903    -0.0183168   0.180485      0.0330201  -0.0467361    0.129172    -0.00533011  -0.0692141    -0.0950594   -0.188384    0.0241932   -0.0171305   -0.0614628   -0.140541     0.164644      0.131783    -0.240516    -0.00974061  -0.152691     0.128727    -0.0614062     0.084603     0.0896097
  0.0658574    -0.338654      0.0690027     0.0196635    -0.0164645   0.180856      0.0384341   0.0138783    0.168948     0.0698514   -0.0692532     0.146279     0.49816     0.0156258    0.103229    -0.0143886   -0.140163     0.0572801     0.0709656   -0.217029     0.00747931   0.121149    -0.286943    -0.0616412     0.0851023    0.121985
  0.317537      0.10923      -0.0929297    -0.14362      -0.0257031   0.051956     -0.0656036   0.0425888   -0.0352259    0.134734    -0.0488946     0.00991664  -0.215247   -0.138819     0.123464     0.054696    -0.0471659    0.00742712   -0.0483491   -0.708848     0.0274095    0.147163     0.106753    -0.337539      0.0654825    0.0863148
  0.259167      0.0435508    -0.104105      0.000441877   0.0589652   0.20283      -0.0277902  -0.0974742   -0.112697    -0.195762    -0.0204263     0.0170817   -0.214567    0.0994247    0.252678     0.0298484   -0.0412072   -0.0267121    -0.0382734    0.192811     0.0219201   -0.141331    -0.0320876   -0.0181659     0.0605138    0.0236829
 -0.0315279    -0.108587     -0.133274     -0.0786064    -0.0193496   0.126278      0.0688924  -0.0273669   -0.0150606    0.0596444   -0.0222107    -0.0710419   -0.0584698   0.0484586    0.0560578   -0.220354    -0.0752571    0.0956688     0.0331524    0.0929436    0.00631464   0.0621735   -0.00687156   0.0429032     0.0739534   -0.00316086
  0.0385247    -0.0405745     0.0517006     0.216575     -0.0322008  -0.166592     -0.0157549   0.118922    -0.175445    -0.121765     0.163099      0.0323223    0.143878    0.0135043    0.190294     0.0702988   -0.251217     0.0217377    -0.171963    -0.107341    -0.120137    -0.0520173   -0.00302048  -0.000293756   0.00494387  -0.0601327
  0.0123134    -0.014592     -0.0617589    -0.048877      0.10161     0.200279     -0.0546529  -0.102318     0.0293584   -0.19063      0.14838       0.0784905   -0.0456731  -0.122582    -0.00143377   0.00525001  -0.0605041    0.169012     -0.0561433    0.0944672    0.0456959   -0.0556051    0.14705     -0.131242     -0.00299846   0.0874568
  0.122379      0.0974982     0.00447846   -0.11307      -0.0730723   0.110857      0.114282   -0.0495164   -0.0463064    0.0556699   -0.0179794    -0.0443019    0.0792811   0.0322512    0.0136607   -0.144349    -0.0793265    0.302135      0.136701     0.0144102    0.0556461   -0.0203678    0.0853       0.0651488     0.0179935    0.0295674
  0.0247351     0.0124939     0.105247     -0.126601      0.100056    0.121489      0.0294216  -0.00121495  -0.100951    -0.517659     0.0194194    -0.0720632    0.124413   -0.213793    -0.00884418  -0.101324     0.0183514    0.0268105    -0.088884    -0.0370905    0.0302607   -0.033925    -0.186639    -0.00160996   -0.0246259    0.00371742
  0.0687979     0.0606762     0.134342     -0.136114     -0.0117431   0.118578      0.0257381   0.107091    -0.148508     0.428387     0.000529129   0.0440311    0.0121975  -0.0452317   -0.0197839   -0.0888725   -0.053222     0.0236454    -0.124655    -0.0399356    0.0512853   -0.00384849   4.26235e-6  -0.0566982    -0.00170007   0.0351152
 -0.185989      0.00979042   -0.134101     -0.45539       0.238728   -0.0213247     0.220568   -0.0185214    0.00106472   0.0136107    0.196862      0.0762716   -0.0519553   0.0522839    0.243902    -0.107156    -0.259217     0.0943954    -0.611939     0.0964473   -0.0771112   -0.0466479    0.123328     0.163944     -0.150149    -0.00203442
 -0.0525525     0.0104872     0.162626      0.164861      0.390872   -0.0241149    -0.122364   -0.00467883  -0.0529214    0.125389    -0.123283      0.0606036   -0.0557612   0.0523258    0.0770768   -0.10445     -0.153605    -0.162402      0.275557     0.118812    -0.104941    -0.0849372    0.0727931   -0.0301104    -0.140875    -0.116951
  0.00290071   -0.0406735    -0.066067     -0.0145475    -0.0235836   0.0413422     0.081233    0.0405794   -0.0823432   -0.0364222    0.0676722    -0.0227522    0.0264271   0.0119159    0.104267     0.0500711   -0.00141783   0.0712866    -0.0696901   -0.00402924  -0.184641    -0.172125     0.0596098    0.0639176    -0.0356794   -0.0753413
  0.000241125  -0.0396122     0.00677938    0.0182323    -0.0797725  -0.0300842    -0.0728217   0.0308401   -0.0147815    0.069323     0.0213815     0.0393942   -0.0681268   0.10968      0.0153579   -0.0416558    0.00757637   0.140298      0.154285     0.0719476    0.0262341   -0.0229875    0.0111478   -0.00132623   -0.024428     0.00946453
  0.048975      0.0421489    -0.00153302   -0.0133407    -0.130176    0.0396148     0.0659721   0.0734086   -0.00224931   0.0293642    0.0209714     0.0127748   -0.108339   -0.0582505    0.224959     0.0414441    0.065312     0.0427992     0.0249141   -0.00544756  -0.0372456    0.0113225    0.00368346  -0.0311099     0.0102766    0.0432101
  0.00897321   -0.104837      0.023967     -0.128223     -0.186624   -0.0372181     0.0384125   0.0176727   -0.0389871   -0.0332807    0.0759859     0.0431413   -0.0409357  -0.141415    -0.00272504  -0.126619    -0.00275001  -0.0088612    -0.109408     0.0232892   -0.0868804    0.0313316   -0.0426764    0.0507187    -0.0434632    0.0944769
 -0.0644282    -0.00194693   -0.0687701    -0.00261522   -0.0916481  -0.028385     -0.115361    0.018436    -0.033069    -0.036159     0.110717      0.0550296   -0.0993796   0.0490812    0.00577307   0.0187327   -0.106115    -0.0492201     0.0370528   -0.00746611  -0.189258     0.0110631    0.0481441    0.0631908    -0.0338425    0.00323233
  0.0282502     0.069088      0.0217924     0.115865     -0.0650546   0.0950002     0.131792    0.00367626  -0.0237158    0.0677545    0.0884329    -0.0343103   -0.0827546  -0.112671     0.010732    -0.142111     0.00974538   0.0695326    -0.0151213   -0.024486    -0.0409717   -0.0334485    0.121227     0.00985452   -0.12351     -0.0479063
  0.0498994     0.00493747    0.148354      0.230574     -0.0415037  -0.181158     -0.12723     0.0228711   -0.0762728    0.0355387   -0.236643     -0.0144774   -0.087132   -0.106314    -0.0979354   -0.0922645    0.00218387  -0.179316      0.0824896    0.236879    -0.195735     0.10279     -0.221812    -0.119127      0.0313771   -0.00857085
 -0.134166     -0.187137      0.0481162     0.0787666    -0.156127   -0.0592938     0.0392956  -0.238269     0.0745031   -0.202979     0.145641     -0.0490373   -0.0443199   0.140854     0.144642     0.0199026    0.0764826   -0.0127034     0.123972     0.121676    -0.00175761  -0.0088816   -0.136148    -0.116801      0.027834    -0.165365
 -0.106935      0.0614705     0.0453311    -0.0966537    -0.0592639  -0.0103632    -0.0502604  -0.114642    -0.0307623   -0.135967     0.0178048     0.00371269   0.0195982  -0.00211771   0.0231298   -0.133271    -0.00636265  -0.0713737     0.0216115   -0.062067     0.0330976   -0.0198695   -0.00610863  -0.0643126    -0.0813589    0.0279952
  0.0518786    -0.013589     -0.19236       0.0467657     0.237565   -0.00784603   -0.0277069   0.0155156    0.0112995   -0.142688     0.0655446     0.0692756    0.13861    -0.0299473    0.16824     -0.0151217    0.00254381   0.102141     -0.119214    -0.0253331   -0.0486079    0.108588    -0.0263733   -0.00850912   -0.0469288    0.0212041
  0.0437145    -0.138333     -0.167541      0.00897213    0.0164096   0.170722      0.0889966  -0.0185575    0.075856    -0.0744177   -0.0345181     0.0633842    0.0599502   0.0624635    0.0306532   -0.103028     0.113731     0.0561029    -0.0480804   -0.24616     -0.057807    -0.0841908   -0.143743    -0.164054     -0.229329     0.150649
 -0.0454323    -0.00933772   -0.0701399    -0.0733643     0.0788109  -0.0664523    -0.186671   -0.185059    -0.21644     -0.0407551   -0.0588315     0.0424785   -0.0945554   0.11589      0.0262718    0.00334967   0.0374331   -0.000198064  -0.0281258   -0.132314     0.0669491    0.092614     0.122446     0.00668861    0.00653948   0.0292392[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     15
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.083610
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     28
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.046686
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.070366
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.060137
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.069095
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     28
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.046886
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     15
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.083557
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     28
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.045395
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.070304
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     22
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.060000
┌ Info: EM with 100000 data points 10 iterations avll -1.060000
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.801099e+05
      1       6.755513e+05      -2.045586e+05 |       32
      2       6.462330e+05      -2.931830e+04 |       32
      3       6.259214e+05      -2.031162e+04 |       32
      4       6.146530e+05      -1.126833e+04 |       32
      5       6.081281e+05      -6.524917e+03 |       32
      6       6.034273e+05      -4.700849e+03 |       32
      7       5.999310e+05      -3.496300e+03 |       32
      8       5.975789e+05      -2.352078e+03 |       32
      9       5.958891e+05      -1.689790e+03 |       32
     10       5.947456e+05      -1.143539e+03 |       32
     11       5.939472e+05      -7.983401e+02 |       32
     12       5.933804e+05      -5.668365e+02 |       32
     13       5.929442e+05      -4.361530e+02 |       32
     14       5.926797e+05      -2.645183e+02 |       32
     15       5.925353e+05      -1.443834e+02 |       32
     16       5.924469e+05      -8.840242e+01 |       32
     17       5.923832e+05      -6.373807e+01 |       32
     18       5.923318e+05      -5.142194e+01 |       32
     19       5.922878e+05      -4.396951e+01 |       32
     20       5.922518e+05      -3.598478e+01 |       32
     21       5.922226e+05      -2.919389e+01 |       31
     22       5.922011e+05      -2.148453e+01 |       31
     23       5.921768e+05      -2.438125e+01 |       31
     24       5.921531e+05      -2.361528e+01 |       31
     25       5.921243e+05      -2.886829e+01 |       32
     26       5.920929e+05      -3.137475e+01 |       30
     27       5.920565e+05      -3.640195e+01 |       32
     28       5.920210e+05      -3.550576e+01 |       31
     29       5.919886e+05      -3.239049e+01 |       32
     30       5.919562e+05      -3.240202e+01 |       32
     31       5.919301e+05      -2.605669e+01 |       30
     32       5.919070e+05      -2.317514e+01 |       31
     33       5.918834e+05      -2.357304e+01 |       29
     34       5.918562e+05      -2.718995e+01 |       32
     35       5.918270e+05      -2.919896e+01 |       32
     36       5.917899e+05      -3.706080e+01 |       32
     37       5.917507e+05      -3.922626e+01 |       32
     38       5.917108e+05      -3.990562e+01 |       31
     39       5.916688e+05      -4.205234e+01 |       31
     40       5.916344e+05      -3.434788e+01 |       31
     41       5.916015e+05      -3.288298e+01 |       32
     42       5.915676e+05      -3.390548e+01 |       31
     43       5.915361e+05      -3.149076e+01 |       31
     44       5.915066e+05      -2.953290e+01 |       32
     45       5.914733e+05      -3.331214e+01 |       32
     46       5.914517e+05      -2.157632e+01 |       29
     47       5.914414e+05      -1.030402e+01 |       26
     48       5.914356e+05      -5.806732e+00 |       27
     49       5.914316e+05      -3.963426e+00 |       27
     50       5.914297e+05      -1.939583e+00 |       21
K-means terminated without convergence after 50 iterations (objv = 591429.6905147601)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.318781
[ Info: iteration 2, average log likelihood -1.289449
[ Info: iteration 3, average log likelihood -1.260468
[ Info: iteration 4, average log likelihood -1.228289
[ Info: iteration 5, average log likelihood -1.191721
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.144287
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      5
│     24
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.118039
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      6
│     17
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.134155
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.117199
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     13
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.105539
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     18
│     19
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.092038
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.109996
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     12
│     15
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.128180
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.115899
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      7
│     21
│     22
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.058021
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      6
│     16
│     18
│     19
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.112390
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.119821
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│      7
│     13
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.083912
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     22
│     24
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.087537
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      6
│     12
│     16
│     18
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.103107
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     15
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.112580
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     13
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.097032
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     12
│     17
│     22
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.077761
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      4
│      6
│      7
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.094447
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.123858
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.074770
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     12
│     13
│     17
│     19
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.072083
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      6
│      7
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.105638
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      5
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.121480
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.093522
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      7
│     12
│      ⋮
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.019137
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     19
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.146523
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.149325
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.094175
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      6
│      7
│     12
│      ⋮
│     18
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.045283
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     15
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.137969
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.123247
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     16
│     19
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.072978
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      6
│     12
│     13
│     17
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.067455
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     15
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.116347
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.107546
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     12
│     16
│     17
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.060605
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      5
│      6
│     13
│      ⋮
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.063556
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     19
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.153089
[ Info: iteration 45, average log likelihood -1.125666
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     12
│     16
│     17
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.040400
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      4
│      5
│      6
│      ⋮
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.043383
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.179034
[ Info: iteration 49, average log likelihood -1.127443
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     16
│     17
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.052175
┌ Info: EM with 100000 data points 50 iterations avll -1.052175
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0445644   -0.142009     -0.170086     0.00890588   0.0162017    0.17208       0.0889305  -0.0191249   0.0781631   -0.0758764   -0.0369775    0.0676874    0.0599382    0.062951     0.0295165    -0.103164     0.114166      0.0605617   -0.0464134  -0.243282    -0.0589605    -0.0847032   -0.143369    -0.163241    -0.232965      0.149408
  0.203036     0.0202567    -0.0869131   -0.0284846    0.0327386    0.145411     -0.0455632  -0.032359   -0.0714132   -0.124693    -0.0373492   -0.00286688  -0.193722     0.0379235    0.199226      0.0288101   -0.0588967    -0.0133488   -0.0205097  -0.0239997    0.0142158    -0.0547484   -0.0176366   -0.0831833    0.0597824     0.0277685
  0.047255    -0.0380883     0.0604725    0.221471    -0.0193861   -0.177704     -0.0212406   0.129166   -0.177212    -0.127012     0.166828     0.0307336    0.147463     0.0131397    0.193469      0.0875891   -0.255556      0.0219885   -0.177649   -0.11111     -0.124772     -0.0587864   -0.0098566    0.00127208   0.00421419   -0.064372
  0.0633375    0.0431459     0.0217726    0.135507    -0.141644     0.0551806     0.105662    0.0738988  -0.0233371   -0.166154     0.12068     -0.0503765   -0.0680811   -0.214021     0.0779778    -0.102572    -0.0137747    -0.03644      0.0309239   0.00684012  -0.138827     -0.174899     0.0532145   -0.0239177   -0.0573494    -0.111432
 -0.133113    -0.190106      0.0444818    0.0818508   -0.148306    -0.0560949     0.0383549  -0.249779    0.0746495   -0.213327     0.14729     -0.0480006   -0.0447553    0.141492     0.151494      0.0217127    0.0757468    -0.00669017   0.122456    0.118274     0.00443125   -0.0102967   -0.133539    -0.118063     0.0284446    -0.166795
 -0.163757    -0.0105206     0.110882    -0.0699082   -0.0642372   -0.0934096     0.139927    0.072251   -0.0310886    0.057844     0.1247       0.0670751    0.0503618   -0.133361     0.00308601   -0.0261158   -0.0156893    -0.0305252   -0.150436    0.026484    -0.0742656     0.160845    -0.151826     0.0493414   -0.0403534     0.0636889
 -0.0165382   -0.00171213   -0.0755852   -0.167324     0.0897552    0.00793155   -0.0648041  -0.167746   -0.0258623   -0.0620192   -0.0224441    0.0134747    0.0715054    0.0366793   -0.0787656    -0.0564048    0.0470371     0.0975978    0.177602   -0.0808158   -0.0751575     0.0282596    0.00845798  -0.0225843   -0.0483515     0.0272935
  0.0149832   -0.0957565    -0.0566212   -0.0107943   -0.0592881    0.0159991     0.0569197   0.0489576  -0.165304    -0.0316671    0.113344    -0.0244231    0.0365643    0.0243939    0.0677889     0.0601061   -0.00230453    0.0787879   -0.0772136  -0.0206705   -0.169405     -0.151362     0.0771928   -0.0839872   -0.0751979    -0.124319
  0.0740839    0.045813     -0.0243084   -0.0818129    0.0174336    0.15588       0.0285775  -0.0760417  -0.00454305  -0.0735578    0.0666506    0.0174646    0.0309616   -0.0479906    0.00666321   -0.0619878   -0.07415       0.239374     0.0410707   0.060717     0.0542043    -0.0391812    0.121095    -0.0401521    0.00854497    0.0598199
 -0.157321     0.0037787    -0.0197195   -0.108017     0.0247171    0.031245     -0.187698   -0.0355523  -0.0349084    0.00452006   0.11812     -0.0700846   -0.176596     0.126709    -0.102987     -0.0294775   -0.166042     -0.0910924    0.0873868  -0.0273307   -0.168548     -0.00634886   0.0254164    0.189457    -0.0173293     0.0286076
  0.0492986    0.0377914     0.121208    -0.134787     0.0459159    0.120449      0.0277366   0.0501274  -0.123551    -0.0535388    0.00954323  -0.0162496    0.0717964   -0.131481    -0.0146319    -0.0949662   -0.0165876     0.0221452   -0.112175   -0.0390048    0.0392119    -0.0194747   -0.0943873   -0.0323526   -0.0136968     0.0180907
 -0.110136     0.0102964     0.0371697   -0.10203      0.327966    -0.0231979     0.0245829  -0.0104791  -0.0299986    0.0760038    0.0125711    0.0665956   -0.0536959    0.052223     0.150235     -0.105631    -0.200103     -0.052117    -0.10602     0.108078    -0.0926263    -0.0684083    0.0947727    0.0544137   -0.144768     -0.0676033
  0.0612616   -0.0186838    -0.0724441    0.149855    -0.0547955   -0.0919131    -0.150685   -0.0698002  -0.0367096   -0.0485361    0.100304     0.00156583   0.0406458   -0.0104818   -0.0373448    -0.0182298   -0.0534027     0.0166974   -0.0487016   0.0882789    0.244152     -0.0574107   -0.0289161    0.0394695   -0.0611787     0.0117756
 -0.00673899   0.101382      0.0165529    0.101055     0.0456005    0.115323      0.137309   -0.0755294  -0.0230947    0.290992     0.0508903   -0.023964    -0.0947547    0.0482352   -0.0761778    -0.183751     0.0359803     0.203154    -0.0709716  -0.0655634    0.0792997     0.142053     0.201802     0.0480142   -0.206503      0.0285917
  0.0993673   -0.0202177    -0.194054     0.0712426    0.277289    -0.0334289    -0.017713    0.069626    0.00786232  -0.144518     0.0740418    0.0931869    0.229035    -0.0317034    0.350476      0.0111342    0.0579238     0.137945    -0.153264   -0.0118836   -0.0719766     0.118389    -0.00263396   0.00649608  -0.0602252    -0.00960024
 -0.0629766   -0.0540741    -0.0210356    0.00101581   0.0374787    0.0369674    -0.0827239  -0.0888046   0.00320832  -0.154703     0.00950556   0.0400969    0.00174273   0.14232      0.115038     -0.0191931   -0.0588623    -0.121143    -0.055114   -0.0605876    0.0339946     0.0839608    0.0530779   -0.107909    -0.098667      0.0493387
  0.128188    -0.162249     -0.0406104   -0.16566     -0.248747     0.000158731  -0.0478846  -0.023021   -0.051298    -0.0896523    0.0433895    0.0388385   -0.0861954   -0.130736    -0.000912275  -0.185066     0.0185992     0.00748575  -0.0621859   0.0219201   -0.0890419    -0.0593499    0.0213176    0.0472271   -0.0618107     0.112716
  0.0503146    0.0491395     0.131826    -0.0106017   -0.127728     0.0363138     0.103097    0.018623    0.0378617    0.0274798    0.0155212    0.0110005   -0.108648    -0.0356986    0.138433      0.037452     0.0643476     0.0467999    0.0243086  -0.00552563  -0.0143755     0.00169517  -0.00926217  -0.0306933    0.0631466     0.0321002
  0.00763478  -0.0910048    -0.0398522   -0.154529    -0.0653289    0.183868      0.171239   -0.136656   -0.100962     0.203948     0.027173    -0.0433213    0.00672617   0.0687592    0.0324266    -0.447777     0.0385544     0.154258     0.0190179   0.0735749    0.0371843     0.112949     0.110553     0.0704731    0.091622      0.0082593
 -0.00963817   0.0121574    -0.0661575   -0.0183384    0.00995431   0.0663814     0.0936428   0.0323928   0.0173536   -0.035672     0.0256516   -0.0169408    0.00720937   0.00276322   0.139225      0.0382806   -0.000641399   0.0656971   -0.0421803   0.0240601   -0.188991     -0.187977     0.0517152    0.203492    -0.000173661  -0.0238587
  0.00342681  -0.0401815     0.00240383   0.0211361   -0.0813394   -0.0316115    -0.0839366   0.0308259  -0.012905     0.0776815    0.0174969    0.0391939   -0.0695698    0.101294     0.0135016    -0.0447999    0.0076068     0.144823     0.165214    0.0700815    0.0321809    -0.0260529    0.0130897    0.00146924  -0.0256486     0.0111891
 -0.0594729   -0.118589     -0.280238    -0.00986437   0.0271507    0.0799633    -0.0190955   0.075323    0.0759286   -0.0538333   -0.052275    -0.0937824   -0.088599     0.0037225    0.05957      -0.0238678   -0.244789      0.0477792    0.0456819   0.119654    -0.032282      0.0124272   -0.144917     0.0167103    0.0547639    -0.0255271
 -0.126348     0.153869      0.0402743   -0.163628    -0.0731102   -0.0542803    -0.0185176  -0.126446   -0.049173    -0.123671     0.0336702   -0.00912996   0.0628946   -0.146249    -0.0655351    -0.232139     0.0259076     0.00234614   0.0653107  -0.0515045    0.0218657    -0.0810066   -0.0569442   -0.0112708   -0.0429531     0.0316516
  0.151447     0.0800168     0.0565812    0.0598429    0.108012     0.00271949   -0.0763772   0.121594   -0.0465739    0.0406331    0.19268     -0.0336503   -0.0319914    0.0101434   -0.000523991   0.171225    -0.105716      0.114834    -0.0117366  -0.0260244   -0.0167546    -0.00480516   0.0907293    0.0075781    0.0618615    -0.0864558
  0.0324173    0.137108     -0.0843595    0.0724486    0.118139     0.0215491    -0.111945    0.108408   -0.156249     0.0147096    0.121835     0.0296183   -0.0108004    0.0391128    0.0835835    -0.0340143    0.00818548    0.113883     0.0205101  -0.225822    -0.134249     -0.0575213   -0.213945    -0.0133065   -0.217144     -0.130033
  0.0690463    0.0197197    -0.148229     0.0117238    0.00621166   0.00896717    0.0287275   0.112728   -0.0182661   -0.0320143    0.0406961    0.0316763   -0.0409599   -0.0749052    0.36052       0.0445306    0.102295      0.0726856   -0.0279018  -0.0113216   -0.0639664     0.0380997    0.00877552  -0.0192139   -0.0298848     0.062942
  0.0915728   -0.0500686     0.0633496    0.0434056   -0.0172518    0.180459      0.0322588  -0.0146291   0.148972     0.0264815   -0.066045     0.0202476    0.132882     0.0198636    0.0420372    -0.0373833   -0.139563      0.111158     0.100785   -0.2288      -0.000662062  -0.0204498   -0.0641828   -0.0608934    0.0832127     0.0997457
 -0.0387599   -0.0145435    -0.0804966   -0.0698698    0.0945464   -0.0644643    -0.182298   -0.175019   -0.217275    -0.052031    -0.0542428    0.0444856   -0.0920233    0.112811     0.0258149     0.00104667   0.0314997     0.00163015  -0.0265261  -0.133114     0.0784121     0.0884115    0.125478     0.00630519   0.00572955    0.01486
  0.105663    -0.0186506    -0.00881496  -0.0566379    0.197565    -0.052278     -0.0304741   0.0395666  -0.156762    -0.0977132   -0.043456     0.110288     0.0911641   -0.0113859   -0.0676607     0.0598808   -0.0490769     0.0325273    0.0298538  -0.00717605  -0.16459       0.0457776   -0.163403     0.0865113    0.0181969     0.126077
  0.0493141    0.00199789    0.150702     0.225598    -0.0459727   -0.176981     -0.122249    0.0248002  -0.0739676    0.0316814   -0.229425    -0.0184298   -0.086608    -0.100587    -0.0977516    -0.0876651    0.00390547   -0.174454     0.0839807   0.235773    -0.195497      0.102105    -0.220161    -0.119102     0.0299653    -0.0139856
 -0.0586576   -0.000841657  -0.0515618   -0.0981066   -0.0240029    0.139301     -0.0192293  -0.0933044  -0.0442501    0.0445933    0.0830601    0.0177225    0.0721363    0.0172637    0.136778      0.0380136    0.108455     -0.0321207    0.0645068   0.147857     0.0279574    -0.0577547    0.108205    -0.0180782   -0.0313018    -0.0245324
  0.03468     -0.0189183    -0.123582     0.120776    -0.228658    -0.0956961    -0.0357442   0.0836646  -0.0249494   -0.0931094    0.106666     0.19831     -0.0243469   -0.0283415    0.11687       0.0742832   -0.0472605    -0.00613951  -0.0143868   0.00740354  -0.217578      0.00905849   0.0824376   -0.0799484   -0.0467209    -0.0305[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.035133
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.997371
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      4
│      5
│      6
│      ⋮
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.985143
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.027085
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      4
│      5
│      6
│      ⋮
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.002877
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.978965
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.032049
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.995211
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      4
│      5
│      6
│      ⋮
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.984593
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.015489
┌ Info: EM with 100000 data points 10 iterations avll -1.015489
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.135942    -0.0855453    0.109248    -0.0195894    0.0215095    0.109852    -0.151094    -0.00692155  -0.0669301   -0.0945954   -0.0657359    0.0931505    0.146218   -0.106056     0.0417775    -0.0257478    0.102506     0.00947113   0.0799487   -0.289123      0.0284136    -0.179113     0.145584     0.0915613    0.178281     0.0561639
 -0.125077     0.186837    -0.214416     0.11252      0.00816482   0.0210054    0.0188056   -0.082399    -0.129377     0.101856    -0.0664882    0.137457    -0.108229    0.0593934   -0.047425     -0.0290881   -0.0415198   -0.0476295   -0.203534    -0.0109159     0.144269      0.168759    -0.0897441    0.0782249   -0.108878     0.0594587
  0.0147735   -0.138009    -0.140642     0.032452     0.00356468  -0.0133782    0.111426    -0.235619     0.0568274    0.00628458   0.0492661   -0.151981    -0.0314626  -0.106352    -0.0439809     0.099055     0.0804064    0.0161697    0.0315407    0.143872      0.063998     -0.200028    -0.0810116   -0.186794     0.083055     0.0143992
 -0.0117376   -0.0294924    0.0349511    0.0337585   -0.0774592   -0.0839055    0.00977019  -0.164914     0.108645     0.110541    -0.0199855   -0.0924892   -0.0586638   0.0884468    0.125237      0.0346344    0.0474245   -0.0731203   -0.115745    -0.0733736     0.115691     -0.0108971   -0.159111    -0.0968113   -0.0505379    0.110437
 -0.146926    -0.0603656    0.0227044   -0.0047646    0.203581     0.0605714    0.0394184   -0.0339075   -0.0792589    0.0387707   -0.124723     0.199592     0.231626    0.193437    -0.0109987    -0.103903    -0.133373    -0.0122962   -0.0868153   -0.0172164    -0.0130752    -0.0658183   -0.022883     0.0963583   -0.0419407    0.0958764
  0.02024      0.00794961  -0.00757292  -0.0836979    0.218027    -0.0682506    0.0845188   -0.0341145   -0.121657     0.108286    -0.101279     0.0873728   -0.0793636   0.139813    -0.07212       0.0749699    0.117648     0.156363    -0.093775    -0.0246471    -0.018857     -0.0873714    0.0572143   -0.03597      0.26086      0.180548
 -0.0222372    0.0205298   -0.0158306   -0.061935     0.041121     0.0944611    0.00337617  -0.282217    -0.0315732   -0.100746    -0.0720071   -0.0174891    0.0901122   0.035914    -0.000905808   0.0861384    0.140954     0.0889331    0.10088     -0.221639     -0.144293     -0.129844     0.0774571    0.176004    -0.141071    -0.00470147
  0.0474187   -0.0155548    0.186586    -0.034148    -0.00372684  -0.112121    -0.00987044  -0.118075     0.0224852    0.0711605   -0.186801     0.0153465   -0.0303561  -0.24314      0.115045      0.0304928    0.0903727    0.238661     0.0978162    0.0511187    -0.140942     -0.116082    -0.0314782   -0.053602    -0.115485     0.0709461
 -0.0453369    0.0332774   -0.132882     0.0134864    0.0167819    0.0440147    0.085006     0.0612943    0.03835      0.14217     -0.0298921    0.0967924   -0.0995574  -0.0583016    0.171935     -0.0587019   -0.175502     0.149043    -0.00463069  -0.0566686     0.136571     -0.00648398   0.040044     0.117279    -0.262409    -0.0274375
  0.00868579   0.156252     0.00708198   0.00324206   0.111755    -0.0960363   -0.0250943    0.0141259    0.147325    -0.0387163   -0.0290849    0.0399744    0.210567   -0.067373     0.141505     -0.112613    -0.157055     0.126563    -0.163133     0.0191012     0.021655      0.0710864   -0.0330085    0.217899     0.0592136    0.0712354
 -0.0657943    0.206841     0.0406852   -0.208064    -0.183534    -0.0584184    0.0755184   -0.0337576   -0.0729929   -0.0404719   -0.0604942   -0.0540854    0.171725    0.149384    -0.0326371     0.00749277   0.199574     0.135155    -0.0443085   -0.0283004    -0.037645     -0.166196     0.0511032    0.0282521   -0.117732    -0.112186
  0.0109939    0.148746     0.0512181    0.00916585   0.0544789    0.0478079    0.0418987   -0.0213223    0.062839    -0.0233926   -0.147326    -0.0379229    0.0576807   0.00818896  -0.0955185     0.0692085    0.0262778   -0.0552044   -0.0369742   -0.149182     -0.114049     -0.097355     0.0856039    0.105276    -0.0515365   -0.11865
 -0.106478     0.0205592    0.0358186   -0.023636    -0.094421    -0.148998    -0.146025    -0.0313865   -0.0307055   -0.018464     0.0132359    0.128814    -0.0309728   0.0844965    0.0345013    -0.0434276    0.0574299    0.0122354   -0.0473923   -0.0631149     0.0829753    -0.0437849    0.0855835   -0.0804513    0.124207    -0.0198493
 -0.102494    -0.0123952   -0.00399471   0.0307644   -0.134491    -0.0680271    0.268784    -0.0884145   -0.00447187  -0.0729251    0.131423    -0.136299     0.026091    0.0155094    0.0202179     0.0942007    0.0250509    0.0508607   -0.00404511  -0.0162079     0.077591     -0.172797    -0.124477     0.00929495  -0.00792329  -0.0756861
  0.0375473    0.00333624  -0.0511842   -0.0675036   -0.222432     0.0630554    0.0980908    0.038861     0.094179     0.00550521  -0.149973     0.0978046    0.0656449   0.0153124    0.129535      0.0450441   -0.0266409    0.0625277    0.020115    -0.0604059    -0.0311242    -0.0720935   -0.0749334    0.0778019   -0.111431     0.0148952
 -0.0278746    0.108148     0.194888    -0.0364553   -0.14165     -0.0661919   -0.0136758   -0.0481472   -0.0838526   -0.0638081   -0.0384849    0.1129      -0.0048415   0.0655848   -0.160023     -0.00249064  -0.118745    -0.0724239    0.0211427   -0.000708335   0.0218277    -0.0115785   -0.0454194   -0.0519025    0.0811794   -0.0931881
  0.0186758   -0.314461     0.0220312    0.0369545   -0.0806227    0.0679302    0.0572651   -0.0465438    0.069765     0.124277     0.0904179   -0.00520877   0.0713555   0.0129688    0.114757     -0.0173058    0.0239109   -0.0415705    0.0540006   -0.0308988     0.000233424  -0.0763186    0.150853     0.0489993   -0.00326097   0.0462086
  0.0330301   -0.0925673    0.161787     0.0290387    0.0183325    0.0142288   -0.0965801    0.0538993    0.00716938  -0.226276    -0.0129907    0.135441     0.0954207  -0.152546    -0.0213804     0.0262182    0.00961977  -0.0789578    0.0731012   -0.00870516   -0.019392      0.0870593    0.040171     0.0438694    0.0727802   -0.0834776
  0.0734293   -0.12005      0.0490576   -0.00357152  -0.0597972   -0.249096    -0.145879    -0.0673058   -0.110688     0.0308052    0.0144285   -0.0989802   -0.217401    0.195458     0.0514242    -0.118887     0.150495     0.021666    -0.0345148   -0.000241131  -0.00432034    0.192997    -0.071464    -0.155696    -0.0342509   -0.0192902
 -0.0724799   -0.00898517   0.057556    -0.110047     0.0722363   -0.0282529   -0.197424    -0.0675805   -0.0241349    0.0646164    0.0749001    0.0523263   -0.134924    0.0406823   -0.00889025   -0.129698     0.149756     0.0845726   -0.0187391   -0.111719     -0.195381      0.0629001   -0.0978809   -0.0810108   -0.00296129  -0.0321667
  0.0564374   -0.0276613   -0.167223    -0.0123028   -0.16568      0.00897932   0.25994     -0.118531     0.10901      0.106911     0.0775994   -0.121885     0.0624345  -0.106041     0.139258     -0.0764191    0.0178573    0.135814     0.0421764   -0.0303054    -0.0645982    -0.0045018    0.0647474    0.0983424    0.0835942   -0.130541
 -0.0342739   -0.0365628   -0.0323298   -0.0488577   -0.113677     0.0897255   -0.0484576    0.00424082   0.0981498   -0.00497208  -0.0142427   -0.236015     0.115999    0.0242945   -0.145874     -0.0180157    0.100976     0.208537     0.183506     0.029368     -0.106045      0.175039    -0.145712     0.152046     0.171394    -0.0195141
  0.00919807   0.0857997   -0.130748     0.0520993   -0.0605248   -0.242713    -0.185877    -0.102156    -0.144695    -0.0318353   -0.0490321   -0.0103221    0.0406357   0.00106618  -0.104688      0.108991     0.0697519   -0.0206374   -0.0824716    0.101239     -0.0589891     0.150794    -0.0405527   -0.101992     0.0465711   -0.102038
 -0.0293524    0.101978     0.0702191    0.10464      0.00529412  -0.0013614    0.0606986    0.183368     0.0623932   -0.0209767    0.175395     0.0300718   -0.0689549   0.0426682   -0.000274034   0.043441     0.0293125   -0.11854      0.0645132   -0.0995696    -0.015417      0.0727004    0.0164195    0.133116    -0.124931     0.112953
  0.0268755   -0.162541     0.150282     0.0332783    0.0806506    0.212906    -0.184975    -0.118723     0.144185     0.0782108    0.158516     0.0861465   -0.198088    0.0488101   -0.0399158    -0.0471488   -0.0725507    0.0248712    0.043326    -0.0221014    -0.00565765   -0.0326986    0.0758233   -0.0361322    0.0618028    0.128691
  0.047535    -0.167586    -0.0273031   -0.105778     0.135549     0.108112    -0.140193     0.0320543    0.0533164    0.0425866    0.0963737   -0.096175    -0.22455     0.104731    -0.0630576     0.237579    -0.0862013    0.0461016    0.0355113    0.0859864     0.0939466    -0.168175     0.0911638   -0.0839641   -0.0998415   -0.0773663
 -0.0428754    0.0549528   -0.0473416    0.0443894   -0.057875    -0.0465545    0.158025     0.0549765    0.137235     0.0354132    0.0458852    0.0619896   -0.0981949   0.0831222   -0.148804      0.0413991   -0.0678593    0.166842    -0.0222143   -0.0249497    -0.0599936     0.0180146    0.00753112   0.24158      0.020047     0.0726489
  0.163998    -0.0244491    0.0555747    0.00846153  -0.13114     -0.0731162    0.138795     0.0704444   -0.0087536   -0.0109845   -0.186181    -0.161346    -0.0882879  -0.00420225  -0.0141182    -0.0249984   -0.164332    -0.0016966   -0.121527    -0.114315     -0.00569994   -0.0146664   -0.0338746   -0.0686264   -0.00499636   0.182223
  0.0796442    0.227034     0.0684011   -0.0281506   -0.0101885    0.077642    -0.00254798   0.106511    -0.0713391   -0.166026     0.00604699   0.00090689  -0.133975   -0.0191215   -0.199505     -0.0271824   -0.100071    -0.0982636    0.0295084    0.105032      0.0333378     0.161073    -0.113583     0.0128069    0.0873278    0.0356212
  0.0209603    0.141579    -0.0627099   -0.00553979   0.108422     0.0761833   -0.0103039   -0.0158083    0.018505    -0.110712     0.0609978    0.0224069   -0.043478   -0.0940735    0.165939     -0.0806456    0.0614754    0.0323377   -0.146441     0.00773451   -0.113311     -0.237487    -0.101946     0.0598418   -0.0155217    0.0984123
  0.109931    -0.0674891    0.0909379   -0.03127      0.0562463   -0.205592     0.07681     -0.034407     0.0128147   -0.0536046    0.0456819   -0.130535     0.0353052   0.0874471   -0.131618     -0.0227196    0.0483798   -0.0949686    0.0310351   -0.165209     -0.0143494    -0.0339728    0.107863    -0.0112886    0.0215455   -0.00763135
  0.168542     0.0213638   -0.0485624   -0.00170776  -0.0411727   -0.0593071    0.126963     0.12522      0.0073781   -0.0763937    0.0384046   -0.026133    -0.0150158   0.0398121   -0.00720632   -0.0765283    0.0263033   -0.054202    -0.0873811   -0.0641999    -0.0574336    -0.0298179    0.0465488    0.131012    -0.0149599    0.00361277kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4251805392405659
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425200
[ Info: iteration 2, average log likelihood -1.425121
[ Info: iteration 3, average log likelihood -1.425062
[ Info: iteration 4, average log likelihood -1.424996
[ Info: iteration 5, average log likelihood -1.424920
[ Info: iteration 6, average log likelihood -1.424830
[ Info: iteration 7, average log likelihood -1.424721
[ Info: iteration 8, average log likelihood -1.424568
[ Info: iteration 9, average log likelihood -1.424314
[ Info: iteration 10, average log likelihood -1.423847
[ Info: iteration 11, average log likelihood -1.423049
[ Info: iteration 12, average log likelihood -1.421954
[ Info: iteration 13, average log likelihood -1.420894
[ Info: iteration 14, average log likelihood -1.420205
[ Info: iteration 15, average log likelihood -1.419881
[ Info: iteration 16, average log likelihood -1.419753
[ Info: iteration 17, average log likelihood -1.419703
[ Info: iteration 18, average log likelihood -1.419684
[ Info: iteration 19, average log likelihood -1.419677
[ Info: iteration 20, average log likelihood -1.419674
[ Info: iteration 21, average log likelihood -1.419672
[ Info: iteration 22, average log likelihood -1.419671
[ Info: iteration 23, average log likelihood -1.419671
[ Info: iteration 24, average log likelihood -1.419671
[ Info: iteration 25, average log likelihood -1.419670
[ Info: iteration 26, average log likelihood -1.419670
[ Info: iteration 27, average log likelihood -1.419670
[ Info: iteration 28, average log likelihood -1.419670
[ Info: iteration 29, average log likelihood -1.419670
[ Info: iteration 30, average log likelihood -1.419669
[ Info: iteration 31, average log likelihood -1.419669
[ Info: iteration 32, average log likelihood -1.419669
[ Info: iteration 33, average log likelihood -1.419669
[ Info: iteration 34, average log likelihood -1.419669
[ Info: iteration 35, average log likelihood -1.419669
[ Info: iteration 36, average log likelihood -1.419669
[ Info: iteration 37, average log likelihood -1.419669
[ Info: iteration 38, average log likelihood -1.419669
[ Info: iteration 39, average log likelihood -1.419669
[ Info: iteration 40, average log likelihood -1.419669
[ Info: iteration 41, average log likelihood -1.419669
[ Info: iteration 42, average log likelihood -1.419669
[ Info: iteration 43, average log likelihood -1.419669
[ Info: iteration 44, average log likelihood -1.419669
[ Info: iteration 45, average log likelihood -1.419669
[ Info: iteration 46, average log likelihood -1.419668
[ Info: iteration 47, average log likelihood -1.419668
[ Info: iteration 48, average log likelihood -1.419668
[ Info: iteration 49, average log likelihood -1.419668
[ Info: iteration 50, average log likelihood -1.419668
┌ Info: EM with 100000 data points 50 iterations avll -1.419668
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4252002702296067
│     -1.4251214662080263
│      ⋮
└     -1.419668423155546
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419688
[ Info: iteration 2, average log likelihood -1.419607
[ Info: iteration 3, average log likelihood -1.419545
[ Info: iteration 4, average log likelihood -1.419476
[ Info: iteration 5, average log likelihood -1.419398
[ Info: iteration 6, average log likelihood -1.419313
[ Info: iteration 7, average log likelihood -1.419230
[ Info: iteration 8, average log likelihood -1.419156
[ Info: iteration 9, average log likelihood -1.419095
[ Info: iteration 10, average log likelihood -1.419047
[ Info: iteration 11, average log likelihood -1.419008
[ Info: iteration 12, average log likelihood -1.418976
[ Info: iteration 13, average log likelihood -1.418946
[ Info: iteration 14, average log likelihood -1.418917
[ Info: iteration 15, average log likelihood -1.418885
[ Info: iteration 16, average log likelihood -1.418851
[ Info: iteration 17, average log likelihood -1.418812
[ Info: iteration 18, average log likelihood -1.418768
[ Info: iteration 19, average log likelihood -1.418720
[ Info: iteration 20, average log likelihood -1.418667
[ Info: iteration 21, average log likelihood -1.418613
[ Info: iteration 22, average log likelihood -1.418560
[ Info: iteration 23, average log likelihood -1.418511
[ Info: iteration 24, average log likelihood -1.418468
[ Info: iteration 25, average log likelihood -1.418432
[ Info: iteration 26, average log likelihood -1.418404
[ Info: iteration 27, average log likelihood -1.418381
[ Info: iteration 28, average log likelihood -1.418364
[ Info: iteration 29, average log likelihood -1.418351
[ Info: iteration 30, average log likelihood -1.418341
[ Info: iteration 31, average log likelihood -1.418334
[ Info: iteration 32, average log likelihood -1.418328
[ Info: iteration 33, average log likelihood -1.418323
[ Info: iteration 34, average log likelihood -1.418319
[ Info: iteration 35, average log likelihood -1.418315
[ Info: iteration 36, average log likelihood -1.418312
[ Info: iteration 37, average log likelihood -1.418310
[ Info: iteration 38, average log likelihood -1.418308
[ Info: iteration 39, average log likelihood -1.418306
[ Info: iteration 40, average log likelihood -1.418304
[ Info: iteration 41, average log likelihood -1.418302
[ Info: iteration 42, average log likelihood -1.418300
[ Info: iteration 43, average log likelihood -1.418299
[ Info: iteration 44, average log likelihood -1.418297
[ Info: iteration 45, average log likelihood -1.418296
[ Info: iteration 46, average log likelihood -1.418295
[ Info: iteration 47, average log likelihood -1.418293
[ Info: iteration 48, average log likelihood -1.418292
[ Info: iteration 49, average log likelihood -1.418291
[ Info: iteration 50, average log likelihood -1.418290
┌ Info: EM with 100000 data points 50 iterations avll -1.418290
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4196878988946269
│     -1.4196065792243746
│      ⋮
└     -1.4182899289939679
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418299
[ Info: iteration 2, average log likelihood -1.418245
[ Info: iteration 3, average log likelihood -1.418198
[ Info: iteration 4, average log likelihood -1.418143
[ Info: iteration 5, average log likelihood -1.418076
[ Info: iteration 6, average log likelihood -1.417997
[ Info: iteration 7, average log likelihood -1.417909
[ Info: iteration 8, average log likelihood -1.417816
[ Info: iteration 9, average log likelihood -1.417726
[ Info: iteration 10, average log likelihood -1.417641
[ Info: iteration 11, average log likelihood -1.417563
[ Info: iteration 12, average log likelihood -1.417492
[ Info: iteration 13, average log likelihood -1.417428
[ Info: iteration 14, average log likelihood -1.417371
[ Info: iteration 15, average log likelihood -1.417321
[ Info: iteration 16, average log likelihood -1.417277
[ Info: iteration 17, average log likelihood -1.417239
[ Info: iteration 18, average log likelihood -1.417206
[ Info: iteration 19, average log likelihood -1.417178
[ Info: iteration 20, average log likelihood -1.417152
[ Info: iteration 21, average log likelihood -1.417129
[ Info: iteration 22, average log likelihood -1.417107
[ Info: iteration 23, average log likelihood -1.417088
[ Info: iteration 24, average log likelihood -1.417070
[ Info: iteration 25, average log likelihood -1.417053
[ Info: iteration 26, average log likelihood -1.417037
[ Info: iteration 27, average log likelihood -1.417022
[ Info: iteration 28, average log likelihood -1.417008
[ Info: iteration 29, average log likelihood -1.416995
[ Info: iteration 30, average log likelihood -1.416982
[ Info: iteration 31, average log likelihood -1.416970
[ Info: iteration 32, average log likelihood -1.416959
[ Info: iteration 33, average log likelihood -1.416949
[ Info: iteration 34, average log likelihood -1.416938
[ Info: iteration 35, average log likelihood -1.416929
[ Info: iteration 36, average log likelihood -1.416920
[ Info: iteration 37, average log likelihood -1.416911
[ Info: iteration 38, average log likelihood -1.416903
[ Info: iteration 39, average log likelihood -1.416895
[ Info: iteration 40, average log likelihood -1.416888
[ Info: iteration 41, average log likelihood -1.416880
[ Info: iteration 42, average log likelihood -1.416873
[ Info: iteration 43, average log likelihood -1.416866
[ Info: iteration 44, average log likelihood -1.416860
[ Info: iteration 45, average log likelihood -1.416853
[ Info: iteration 46, average log likelihood -1.416847
[ Info: iteration 47, average log likelihood -1.416841
[ Info: iteration 48, average log likelihood -1.416835
[ Info: iteration 49, average log likelihood -1.416829
[ Info: iteration 50, average log likelihood -1.416823
┌ Info: EM with 100000 data points 50 iterations avll -1.416823
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.418299111443149
│     -1.4182453103581827
│      ⋮
└     -1.4168232623014747
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416826
[ Info: iteration 2, average log likelihood -1.416769
[ Info: iteration 3, average log likelihood -1.416719
[ Info: iteration 4, average log likelihood -1.416663
[ Info: iteration 5, average log likelihood -1.416597
[ Info: iteration 6, average log likelihood -1.416517
[ Info: iteration 7, average log likelihood -1.416423
[ Info: iteration 8, average log likelihood -1.416317
[ Info: iteration 9, average log likelihood -1.416205
[ Info: iteration 10, average log likelihood -1.416092
[ Info: iteration 11, average log likelihood -1.415985
[ Info: iteration 12, average log likelihood -1.415885
[ Info: iteration 13, average log likelihood -1.415794
[ Info: iteration 14, average log likelihood -1.415713
[ Info: iteration 15, average log likelihood -1.415641
[ Info: iteration 16, average log likelihood -1.415576
[ Info: iteration 17, average log likelihood -1.415517
[ Info: iteration 18, average log likelihood -1.415464
[ Info: iteration 19, average log likelihood -1.415416
[ Info: iteration 20, average log likelihood -1.415373
[ Info: iteration 21, average log likelihood -1.415333
[ Info: iteration 22, average log likelihood -1.415297
[ Info: iteration 23, average log likelihood -1.415264
[ Info: iteration 24, average log likelihood -1.415234
[ Info: iteration 25, average log likelihood -1.415205
[ Info: iteration 26, average log likelihood -1.415178
[ Info: iteration 27, average log likelihood -1.415153
[ Info: iteration 28, average log likelihood -1.415129
[ Info: iteration 29, average log likelihood -1.415106
[ Info: iteration 30, average log likelihood -1.415084
[ Info: iteration 31, average log likelihood -1.415063
[ Info: iteration 32, average log likelihood -1.415042
[ Info: iteration 33, average log likelihood -1.415022
[ Info: iteration 34, average log likelihood -1.415002
[ Info: iteration 35, average log likelihood -1.414983
[ Info: iteration 36, average log likelihood -1.414964
[ Info: iteration 37, average log likelihood -1.414945
[ Info: iteration 38, average log likelihood -1.414927
[ Info: iteration 39, average log likelihood -1.414909
[ Info: iteration 40, average log likelihood -1.414892
[ Info: iteration 41, average log likelihood -1.414875
[ Info: iteration 42, average log likelihood -1.414858
[ Info: iteration 43, average log likelihood -1.414842
[ Info: iteration 44, average log likelihood -1.414826
[ Info: iteration 45, average log likelihood -1.414811
[ Info: iteration 46, average log likelihood -1.414797
[ Info: iteration 47, average log likelihood -1.414783
[ Info: iteration 48, average log likelihood -1.414769
[ Info: iteration 49, average log likelihood -1.414757
[ Info: iteration 50, average log likelihood -1.414744
┌ Info: EM with 100000 data points 50 iterations avll -1.414744
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4168255993477115
│     -1.416769039904555
│      ⋮
└     -1.414744292423037
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414741
[ Info: iteration 2, average log likelihood -1.414670
[ Info: iteration 3, average log likelihood -1.414603
[ Info: iteration 4, average log likelihood -1.414525
[ Info: iteration 5, average log likelihood -1.414429
[ Info: iteration 6, average log likelihood -1.414309
[ Info: iteration 7, average log likelihood -1.414167
[ Info: iteration 8, average log likelihood -1.414006
[ Info: iteration 9, average log likelihood -1.413835
[ Info: iteration 10, average log likelihood -1.413665
[ Info: iteration 11, average log likelihood -1.413503
[ Info: iteration 12, average log likelihood -1.413356
[ Info: iteration 13, average log likelihood -1.413226
[ Info: iteration 14, average log likelihood -1.413112
[ Info: iteration 15, average log likelihood -1.413014
[ Info: iteration 16, average log likelihood -1.412929
[ Info: iteration 17, average log likelihood -1.412856
[ Info: iteration 18, average log likelihood -1.412792
[ Info: iteration 19, average log likelihood -1.412736
[ Info: iteration 20, average log likelihood -1.412687
[ Info: iteration 21, average log likelihood -1.412643
[ Info: iteration 22, average log likelihood -1.412603
[ Info: iteration 23, average log likelihood -1.412568
[ Info: iteration 24, average log likelihood -1.412536
[ Info: iteration 25, average log likelihood -1.412506
[ Info: iteration 26, average log likelihood -1.412479
[ Info: iteration 27, average log likelihood -1.412454
[ Info: iteration 28, average log likelihood -1.412431
[ Info: iteration 29, average log likelihood -1.412409
[ Info: iteration 30, average log likelihood -1.412388
[ Info: iteration 31, average log likelihood -1.412369
[ Info: iteration 32, average log likelihood -1.412350
[ Info: iteration 33, average log likelihood -1.412333
[ Info: iteration 34, average log likelihood -1.412316
[ Info: iteration 35, average log likelihood -1.412300
[ Info: iteration 36, average log likelihood -1.412284
[ Info: iteration 37, average log likelihood -1.412269
[ Info: iteration 38, average log likelihood -1.412255
[ Info: iteration 39, average log likelihood -1.412241
[ Info: iteration 40, average log likelihood -1.412228
[ Info: iteration 41, average log likelihood -1.412215
[ Info: iteration 42, average log likelihood -1.412203
[ Info: iteration 43, average log likelihood -1.412191
[ Info: iteration 44, average log likelihood -1.412179
[ Info: iteration 45, average log likelihood -1.412168
[ Info: iteration 46, average log likelihood -1.412157
[ Info: iteration 47, average log likelihood -1.412146
[ Info: iteration 48, average log likelihood -1.412135
[ Info: iteration 49, average log likelihood -1.412125
[ Info: iteration 50, average log likelihood -1.412115
┌ Info: EM with 100000 data points 50 iterations avll -1.412115
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.414741254673635
│     -1.4146700650739297
│      ⋮
└     -1.412114850512877
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4251805392405659
│     -1.4252002702296067
│     -1.4251214662080263
│     -1.4250623406636185
│      ⋮
│     -1.412135399925052
│     -1.4121250292559773
└     -1.412114850512877
32×26 Array{Float64,2}:
  0.191413     0.0621312  -0.190547    0.269405    0.232189     0.0993445    0.0378237   -0.179787   -0.44439      0.011328    -0.29678    -0.263734     0.012024    -0.196209     0.388531    -0.354231    -0.720738    -0.0113279   0.715902     -0.112628    -1.23108    -0.171419   -0.504356     0.237597     0.00300606   0.283094
  1.03718      0.239351    0.13046     0.395058   -0.157317     0.0172348   -0.0192235    0.208036   -0.490799    -0.332799    -0.5044     -0.783444    -0.305195    -0.129952    -0.140865    -0.556731    -0.661482     0.685938    0.576134     -0.228188     0.187832   -0.192067    0.383469     0.243528    -0.31215     -0.0846759
 -0.0122547    0.412132   -0.196959   -0.392032    0.19828      0.371848     0.827996     0.758023   -0.997647     0.375315     0.250269    0.574392    -0.0147563    0.305867    -0.00849317  -0.489831    -0.525514    -1.04391    -0.66659       0.565688    -0.51689     0.226341    0.0642096   -0.00660621   0.411642    -0.00839349
  0.00747086   0.20993    -0.110347   -0.163141    0.524454     0.0490554    0.733466     0.641822    0.0773083   -0.447657    -0.124298    0.615479    -0.075318    -0.168523     0.416862    -0.280818    -0.63511      0.0819287  -0.630902     -0.376366    -0.286932    0.0168966  -0.335303     0.010759    -0.82893      0.621625
  0.0807164   -0.12901    -0.113271    0.0651524   0.077271     0.142795    -0.00478216  -0.0749599   0.0574444   -0.142263    -0.23942     0.219223     0.255054     0.242906    -0.123531     0.331022     0.317622    -0.0320154   0.0497068    -0.0826494    0.166123    0.0482044  -0.0952391   -0.0123189   -0.273342    -0.362967
 -0.12252      0.270628    0.0129665   0.423846    0.224364    -0.217696    -0.237851     0.275541   -0.0829866    0.240837     0.040642    0.241797     0.451592    -0.0559796    0.00541047  -0.0394232   -0.0671714   -0.231758    0.190436     -0.274037    -0.111477    0.90503     0.237083     0.21622      0.110874     0.520329
 -0.198184    -0.66249    -0.392814    0.0466875  -0.137388     0.0319575   -0.590558    -0.152411   -0.00352667   0.108654    -0.0167869   0.506387     0.178296     0.0114414    0.828058    -0.391593     0.537499    -0.3224     -0.0878619    -0.393407    -0.422317    0.285925   -0.543525    -0.379124    -0.462588     0.175945
 -0.236067    -0.397447    0.115425   -0.0573439   0.0177801   -0.470541     0.791366     0.0883467   0.424303     0.231311    -0.0314905   0.00708852   0.175931    -0.446458     0.219326    -0.341023     0.224364     0.0627566  -0.324883     -0.277308     0.0425576   0.388976   -0.566789    -0.139158    -0.0500271    0.0349846
  0.153409    -0.168822    0.273761    0.566335    0.320729    -0.711915    -0.107045    -0.390843    0.0685543   -0.154221    -0.123307    0.169968    -0.217171     0.351767     0.0281351   -0.550387     0.16417      0.29493    -0.978678      0.233488    -0.0962055   0.170642   -0.114129    -0.467574     0.808201    -0.337253
 -0.341635    -0.0886841   0.281075   -0.0775747  -0.127483    -0.391855    -0.243198    -0.0586379  -0.395246    -0.237986    -0.552495   -0.268318     0.262554     0.151537    -0.0604409   -0.460237    -0.0261698   -0.0679567  -0.27621       0.457026    -0.138452   -0.659356   -0.412817    -0.371367     0.324352     0.288584
  0.0595183   -0.315464   -0.153043    0.121561   -0.201908    -0.544857    -0.545704    -0.741175    0.654293    -0.068991     0.0590404  -0.648527     0.228467     0.0297813   -0.12536      0.156884     0.523332     0.886386    0.279995     -0.325363     0.395559   -0.0613633  -0.0189326    0.0614417    0.0694191   -0.102944
 -0.169898     0.166341   -0.0757123  -0.721063   -0.212447    -0.566569     0.160202    -0.301293    0.907719     0.11134      0.315561    0.0227609    0.137796     0.300059    -0.293283     0.402379     0.678355    -0.316846   -0.752422     -0.250805     0.536585   -0.200177    0.426589    -0.259761    -0.167412     0.0811777
 -0.414396     0.0533136   0.109661    0.0731202  -0.698573     0.492157     0.784653     0.288187    0.241693     0.1479       0.36255    -0.268442    -0.379662    -0.430091     0.384806     0.642804     0.0700238    0.0489027  -0.206841     -0.230713    -0.0536699  -0.473627   -0.383474     0.198162     0.538701    -0.425772
 -0.914786     0.107546    0.645036   -0.122054   -0.431678    -0.00366476   0.211008    -0.0687652   0.403092     0.198899    -0.203701   -0.184126    -0.16817     -0.493345     0.106514     0.0649717   -0.399055     0.113755   -0.000461954  -0.176242     0.692677   -0.186629    0.783779     0.954847     0.626957    -0.140187
  0.195622     0.108545    0.56507    -0.387563   -0.215182     0.0120308    0.513679    -0.295639   -0.271935    -0.768887     1.00007    -0.488568    -0.731388    -0.00841913  -0.292001     0.0607352    0.0935402    0.401956   -0.537906     -0.0517727   -0.251341   -0.823944    0.0322017    0.594159     0.192855    -0.0534378
 -0.0793242   -0.188867    0.0532514  -0.45337    -0.467059    -0.0101419    0.23592     -0.408693    0.096842     0.491556     0.355802   -0.448903    -0.565708    -0.289602    -0.0723827   -0.355738    -0.353007     0.0987209  -0.00274333    0.33323     -0.161277   -0.606605    0.22785     -0.205231     0.215935     0.0257101
 -0.00994346  -0.0596582  -0.124134   -0.268589    0.282012    -0.181449     0.0301089   -0.0609668   0.0816209   -0.0725822    0.150946   -0.1224      -0.0810343    0.0444139   -0.278569    -0.117154    -0.31908     -0.430569   -0.106808      0.0880098   -0.224096   -0.394573   -0.00512621  -0.419148     0.138594     0.0559861
  0.0883847   -0.111433    0.196036   -0.247706   -0.280918    -0.177585     0.0344719   -0.352054    0.0673333    0.425695     0.295117   -0.241761    -0.502232    -0.183367     0.116283    -0.414755    -0.0860264    0.315548   -0.18379       0.215357     0.100167   -0.222395    0.158414    -0.107373     0.34664     -0.00906499
 -0.0576401   -0.358169    0.478275    0.143868   -0.057159    -0.198465     0.387803    -0.185026    0.16879     -0.191202    -0.0248414  -0.823163     0.0240424    0.411136     0.0285107   -0.582107    -0.181516     0.208439    0.0715801    -0.180386    -0.248225   -0.345061    0.160375     0.33687     -0.421699     0.205876
 -0.33317      0.416692    0.661593    0.0958581   0.20181     -0.120061     0.0319542   -0.184392   -0.173382    -0.128626     0.0179775  -0.0121165   -0.294432     0.117182     0.092238    -0.125503     0.0982598    0.0419329  -0.376376     -0.615857     0.0546331   0.217079    0.571107     0.628689    -0.0388548    0.0717318
  0.116141    -0.0747712  -0.221584   -0.149581   -0.0780625    0.465382     0.235201     0.158122   -0.0101121    0.145556     0.0586985   0.133785     0.0115089   -0.0766058    0.264187     0.559274    -0.0488324   -0.242234    1.01718      -0.364474    -0.0709232  -0.0943506   0.0703021    0.168906    -0.766828    -0.513413
 -0.177867    -0.121045   -0.550191   -0.897215    0.104697     0.259338     0.151876     0.155803    0.275388     0.0740645   -0.0858149  -0.216053     0.239148    -0.00351209  -0.033909     0.820975     0.151061     0.223905    0.862586      0.168222     0.230206   -0.559921   -0.470468     0.0468708   -0.508009     0.590368
  0.502669     0.896529   -0.503164   -0.480982   -0.165838     0.515475    -0.595696     0.0274324  -0.1189      -0.195589     0.013129    0.430767    -0.103426    -0.271894     0.171093     0.439823    -0.228569     0.177204    0.30404       0.00664319   0.126523   -0.129369    0.14321      0.0730734    0.0212107   -0.0576884
  0.2229       0.277597    0.14815    -0.408424   -0.0936445    0.296431     0.0874824   -0.428534    0.0145509    0.135594    -0.0888971   0.273964     0.0358538    0.686056    -0.160692    -0.0486203   -0.00434972   0.352532    0.189123      0.0331448   -0.496242   -0.617468    0.666375     0.532629     0.264803    -0.39642
  0.204197     0.0132934  -0.244783    0.236686    0.743241    -0.184548    -0.453392     0.155968    0.0655117   -0.294307    -0.603612    0.438125     0.360567     0.407829    -0.125568    -0.079066     0.142333    -0.109941   -0.145665     -0.259116     0.0363317   0.44601    -0.273993    -0.0558614   -0.399007     0.262935
  0.675514     0.0903361  -0.125515    0.658262    0.159613     0.111177    -0.633737    -0.467954   -0.523507    -0.203352     0.403649   -0.134944     0.329361    -0.0513006   -0.163504     0.0875275    0.445412    -0.253727    0.199824      0.0292506   -0.7151      0.238095   -0.307217    -0.357152    -0.0640138    0.0315943
  0.0364721    0.0965349   0.0693118   0.284436   -0.156168     0.206418    -0.00544309   0.0505723  -0.351       -0.0648862   -0.110662    0.179893     0.00327633   0.0577688    0.106077     0.147512    -0.0471173    0.0794983   0.0348754     0.138044    -0.0899061   0.0921271  -0.114091     0.077888    -0.0274797   -0.0513725
  0.0276615    0.0173642  -0.176415   -0.166072   -0.044533    -0.0829071   -0.0518108   -0.0279519   0.331506     0.00420892  -0.0802735  -0.0997397    0.131905    -0.0446981    0.0711494   -0.00998312   0.142716     0.0497792   0.033422     -0.313717     0.0777091   0.012766   -0.00296053   0.0914516   -0.153877     0.075143
 -0.0423014    0.0243436   0.484849    0.575      -0.00484697   0.246376     0.265652     1.23006    -0.355063    -0.482238    -0.446912    0.304141    -0.558554    -0.360493    -0.148592     0.1791      -0.0547891    0.106091    0.0203711     0.493951     0.466907    0.595041   -0.120516     0.159478     0.239717    -0.162475
  0.302451     0.0935475  -0.166346    0.0524838   0.0178237   -0.0491851    0.0668378    0.154742   -0.356623    -0.0390765    0.625299    0.14994     -0.458696     0.162605    -0.583264     0.511534    -0.0305236    0.0646032  -0.0684153    -0.00408499   0.430204    0.398655    0.504353     0.101706     0.196468    -0.17317
 -0.26081     -0.229209   -0.135675   -0.0788617  -0.0566688    0.00791342  -0.0924594    0.178865    0.275571     0.169611    -0.181775    0.478281     0.440245    -0.170048    -0.500755     0.268342     0.319043    -0.0989002  -0.0818868     0.572059     0.340069    0.323406   -0.123255    -0.232036     0.469652    -0.116707
 -0.58789      0.106916    0.195865    0.898243   -0.162827     0.525837    -0.228548     0.063638   -0.138251     0.265547    -0.349769   -0.00692891   0.264355     0.344065     0.329331     0.386755     0.370844    -0.0218573  -0.158394      0.116029     0.723142    0.0444326  -0.105213    -0.0677661   -0.0839814    0.1425[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412105
[ Info: iteration 2, average log likelihood -1.412095
[ Info: iteration 3, average log likelihood -1.412085
[ Info: iteration 4, average log likelihood -1.412076
[ Info: iteration 5, average log likelihood -1.412066
[ Info: iteration 6, average log likelihood -1.412057
[ Info: iteration 7, average log likelihood -1.412047
[ Info: iteration 8, average log likelihood -1.412038
[ Info: iteration 9, average log likelihood -1.412029
[ Info: iteration 10, average log likelihood -1.412020
┌ Info: EM with 100000 data points 10 iterations avll -1.412020
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.590592e+05
      1       7.062019e+05      -2.528573e+05 |       32
      2       6.939334e+05      -1.226855e+04 |       32
      3       6.893169e+05      -4.616434e+03 |       32
      4       6.869723e+05      -2.344632e+03 |       32
      5       6.854565e+05      -1.515820e+03 |       32
      6       6.843288e+05      -1.127694e+03 |       32
      7       6.834207e+05      -9.081148e+02 |       32
      8       6.826787e+05      -7.419948e+02 |       32
      9       6.820471e+05      -6.315815e+02 |       32
     10       6.815159e+05      -5.311839e+02 |       32
     11       6.810783e+05      -4.376555e+02 |       32
     12       6.807030e+05      -3.753020e+02 |       32
     13       6.803684e+05      -3.345949e+02 |       32
     14       6.800745e+05      -2.938775e+02 |       32
     15       6.797801e+05      -2.943768e+02 |       32
     16       6.795081e+05      -2.720234e+02 |       32
     17       6.792497e+05      -2.583405e+02 |       32
     18       6.790266e+05      -2.231538e+02 |       32
     19       6.788295e+05      -1.970543e+02 |       32
     20       6.786511e+05      -1.784793e+02 |       32
     21       6.784817e+05      -1.693841e+02 |       32
     22       6.783347e+05      -1.469248e+02 |       32
     23       6.782067e+05      -1.280694e+02 |       32
     24       6.780903e+05      -1.163503e+02 |       32
     25       6.779834e+05      -1.069321e+02 |       32
     26       6.778793e+05      -1.041119e+02 |       32
     27       6.777858e+05      -9.346503e+01 |       32
     28       6.776960e+05      -8.984198e+01 |       32
     29       6.776141e+05      -8.189253e+01 |       32
     30       6.775385e+05      -7.555504e+01 |       32
     31       6.774756e+05      -6.294630e+01 |       32
     32       6.774287e+05      -4.685019e+01 |       32
     33       6.773887e+05      -4.000694e+01 |       32
     34       6.773537e+05      -3.498202e+01 |       32
     35       6.773226e+05      -3.111271e+01 |       32
     36       6.772913e+05      -3.133777e+01 |       32
     37       6.772627e+05      -2.863389e+01 |       32
     38       6.772360e+05      -2.661197e+01 |       32
     39       6.772115e+05      -2.449749e+01 |       32
     40       6.771911e+05      -2.045626e+01 |       32
     41       6.771692e+05      -2.185951e+01 |       32
     42       6.771486e+05      -2.062619e+01 |       32
     43       6.771280e+05      -2.059643e+01 |       32
     44       6.771042e+05      -2.377811e+01 |       32
     45       6.770803e+05      -2.396594e+01 |       32
     46       6.770509e+05      -2.939240e+01 |       32
     47       6.770211e+05      -2.972772e+01 |       32
     48       6.769955e+05      -2.563150e+01 |       32
     49       6.769700e+05      -2.554206e+01 |       32
     50       6.769454e+05      -2.457386e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 676945.3967425846)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.424162
[ Info: iteration 2, average log likelihood -1.419107
[ Info: iteration 3, average log likelihood -1.417743
[ Info: iteration 4, average log likelihood -1.416707
[ Info: iteration 5, average log likelihood -1.415574
[ Info: iteration 6, average log likelihood -1.414498
[ Info: iteration 7, average log likelihood -1.413760
[ Info: iteration 8, average log likelihood -1.413360
[ Info: iteration 9, average log likelihood -1.413145
[ Info: iteration 10, average log likelihood -1.413009
[ Info: iteration 11, average log likelihood -1.412910
[ Info: iteration 12, average log likelihood -1.412832
[ Info: iteration 13, average log likelihood -1.412766
[ Info: iteration 14, average log likelihood -1.412709
[ Info: iteration 15, average log likelihood -1.412658
[ Info: iteration 16, average log likelihood -1.412613
[ Info: iteration 17, average log likelihood -1.412571
[ Info: iteration 18, average log likelihood -1.412532
[ Info: iteration 19, average log likelihood -1.412496
[ Info: iteration 20, average log likelihood -1.412462
[ Info: iteration 21, average log likelihood -1.412430
[ Info: iteration 22, average log likelihood -1.412399
[ Info: iteration 23, average log likelihood -1.412369
[ Info: iteration 24, average log likelihood -1.412340
[ Info: iteration 25, average log likelihood -1.412313
[ Info: iteration 26, average log likelihood -1.412286
[ Info: iteration 27, average log likelihood -1.412260
[ Info: iteration 28, average log likelihood -1.412236
[ Info: iteration 29, average log likelihood -1.412212
[ Info: iteration 30, average log likelihood -1.412189
[ Info: iteration 31, average log likelihood -1.412167
[ Info: iteration 32, average log likelihood -1.412146
[ Info: iteration 33, average log likelihood -1.412125
[ Info: iteration 34, average log likelihood -1.412106
[ Info: iteration 35, average log likelihood -1.412087
[ Info: iteration 36, average log likelihood -1.412069
[ Info: iteration 37, average log likelihood -1.412052
[ Info: iteration 38, average log likelihood -1.412036
[ Info: iteration 39, average log likelihood -1.412020
[ Info: iteration 40, average log likelihood -1.412005
[ Info: iteration 41, average log likelihood -1.411991
[ Info: iteration 42, average log likelihood -1.411978
[ Info: iteration 43, average log likelihood -1.411964
[ Info: iteration 44, average log likelihood -1.411952
[ Info: iteration 45, average log likelihood -1.411940
[ Info: iteration 46, average log likelihood -1.411928
[ Info: iteration 47, average log likelihood -1.411917
[ Info: iteration 48, average log likelihood -1.411907
[ Info: iteration 49, average log likelihood -1.411896
[ Info: iteration 50, average log likelihood -1.411886
┌ Info: EM with 100000 data points 50 iterations avll -1.411886
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0091505   -0.116313     0.00125029   0.476768   -0.0582065   0.0701814  -0.251317    -0.00937301    0.0615009   -0.0113257   -0.286405     0.205537    0.269584     0.138834   -0.0742465    0.204449     0.358116    0.195484   -0.102861     0.293731    0.354837     0.214148    -0.107555    -0.177167    0.137906   -0.112582
  0.262625    -0.0244288   -0.371182    -0.262588    0.0417297   0.306664   -0.0266579   -0.0324008    -0.0212845   -0.0512132    0.722423    -0.290485   -0.282715     0.118709    0.00910251   0.753794    -0.294427   -0.421601    0.669771    -0.266226   -0.481761    -0.596766     0.00882818  -0.124273   -0.587611    0.193334
 -1.21506      0.337549     0.733103    -0.766623   -0.523976   -0.0635516   0.623796    -0.462186      0.397137    -0.0518927   -0.23017     -0.215697   -0.332325    -0.308193    0.258969     0.615448    -0.49159     0.0824092   0.214777    -0.12859     0.653477    -0.524292     0.513695     0.619772    0.0347815  -0.0687815
  0.792203     0.437521    -0.366974    -0.142017   -0.391567    0.184601   -0.481446     0.0177772    -0.0899362   -0.624445    -0.113115    -0.222106   -0.0487571   -0.297304   -0.010215     0.21691     -0.0462851   0.633151    0.333156    -0.448807    0.400187    -0.203859     0.079596     0.158017   -0.373421    0.0331695
 -0.162032     0.150331    -0.170914     0.0762396   0.578452   -0.453264   -0.331514     0.332338      0.200082    -0.291801    -0.26936      0.302616   -0.0481075    0.315299    0.0793267   -0.101201     0.19739    -0.746239   -0.327312    -0.348647    0.237165     0.35074      0.21098     -0.187706   -0.166619    0.394195
 -0.0384494   -0.0472848    0.138264     0.0281092  -0.0210302  -0.122708    0.0760772   -0.0704432     0.0901279   -0.0590689   -0.09195     -0.328832   -0.06617      0.0769197   0.00604331  -0.183124    -0.0823055   0.0778957   0.00675536  -0.207764    0.0761652   -0.100156     0.0244382    0.146596   -0.192843    0.089731
 -0.313767    -0.204393     0.478162    -0.219762    0.0404715  -0.491395    0.575153     0.300738      0.0377459   -0.26291     -0.0263201    0.226897   -0.147823     0.0354013   0.680396    -0.628967     0.0679107   0.341836   -0.572981    -0.389585   -0.443129    -0.0522241   -0.361305     0.3185     -0.171811    0.498918
  0.0456374   -0.251863     0.113976    -0.359168   -0.18148    -0.355194    0.0419603   -0.51276       0.224186     0.54878      0.371634    -0.367837   -0.491689    -0.34671     0.103291    -0.686265    -0.0461127   0.195612   -0.220164     0.0904271   0.0417123   -0.104703     0.186396    -0.158986    0.358003   -0.0174574
  0.334848     0.0866581    0.138989     0.388792   -0.0981551   0.272673    0.331775     0.796889     -0.552968    -0.280181     0.0288536    0.519015   -0.501032    -0.102646   -0.243939     0.485758    -0.115892    0.0436826   0.0711928    0.358851    0.0833558    0.625781     0.0204203    0.154638    0.156738   -0.268386
 -0.0261847   -0.437116    -0.0628118    0.287105   -0.286267   -0.182353    0.887303    -0.0574313     0.353645     0.164001     0.111978    -0.0212865   0.176438    -0.293775    0.284205     0.314908     0.191362   -0.232284   -0.369395    -0.502123    0.00287595   0.28968     -0.613005    -0.279435    0.0198552  -0.676932
 -0.0544838   -0.156192     0.294187     0.412937    0.224132   -0.495126   -0.271191    -0.511052     -0.196891    -0.032905    -0.357659    -0.0948688  -0.101852     0.563172    0.0777671   -0.425842     0.164757    0.159219   -0.415964     0.592707   -0.277196    -0.324471    -0.386761    -0.638589    0.480591   -0.0432832
 -0.143404    -0.178103    -0.663006    -0.847217   -0.26531     0.512341    0.398398     0.488368      0.781032     0.376849    -0.506091     0.287084   -0.0185932   -0.211227    0.250017     0.53244     -0.137781    0.220924    0.450745    -0.0487551   0.690137    -0.172214     0.0655287    0.245479   -0.17366    -0.116497
 -0.0687699   -0.0225225    0.109714    -0.0228879  -0.0490743  -0.110128    0.0758778   -0.11455       0.0848643    0.0531092    0.00579784  -0.0261204   0.0153281   -0.0413954   0.166802    -0.0667985    0.222395    0.0607943  -0.0367247   -0.11378    -0.0972486   -0.00639809   0.0233724    0.0306737   0.0116392   0.015857
  0.365756     0.228403    -0.519395    -0.0572395   0.740982   -0.158173   -0.135045     0.176056      0.115491     0.115679    -0.055118     0.609145    0.423359     0.191309   -0.370195     0.00239288  -0.251223    0.0157081   0.0992643   -0.196183    0.0966957    0.76098      0.235101     0.382839   -0.235224    0.362607
  0.145211     0.313159     0.352424    -0.286707   -0.103209    0.206609    0.101607    -0.272682     -0.193551    -0.0509352   -3.02226e-5   0.112545   -0.224004     0.531049   -0.0841967   -0.07347     -0.147462    0.287659    0.0758259    0.0332582  -0.359912    -0.560495     0.601366     0.540435    0.254926   -0.25613
  0.487781     0.144747    -0.0660066    0.341868    0.345101    0.122906    0.179244     0.0555506    -0.665296    -0.126752    -0.459194    -0.290489   -0.317618    -0.266037    0.303126    -0.369192    -0.921065   -0.0412619   0.795915    -0.154546   -1.05505     -0.250855    -0.253644     0.405659   -0.0764906   0.162037
  0.133992     0.538879    -0.245635    -0.52941     0.379085    0.0704887   0.602859     0.559845     -0.614703     0.0447255    0.11282      0.395211   -0.00267001   0.07526     0.186096    -0.663562    -0.924656   -0.415162   -0.664592     0.400343   -0.35482     -0.138442    -0.0684083   -0.260972    0.0121199   0.391026
  0.240714     0.0734179   -0.189369    -0.491901   -0.409938    0.20156     0.0507237   -0.268726     -0.266736     0.104908     0.158184     0.0844937  -0.255543    -0.141955   -0.630661     0.0323093   -0.434273   -0.0350074   0.211774     0.707025    0.0140012   -0.544204     0.320973    -0.217637    0.313642   -0.754523
 -0.237215     0.295683     0.188742    -0.266427   -0.353904    0.366983    0.556322     0.162542      0.032342    -0.135906     0.977339    -0.309535   -0.74377     -0.474658   -0.0129093    0.722836     0.229479    0.134787   -0.422929    -0.118164    0.0278337   -0.644343     0.123734     0.556202    0.612572   -0.0685378
 -0.0485885    0.0952879   -0.146942     0.0205104  -0.0598866   0.183849   -0.416193    -0.210449      0.0836498    0.245495     0.733309     0.460541   -0.149274     0.164174    0.206479     0.516136     0.626568    0.101443    0.302117    -0.412844    0.649015     0.347549     0.381487     0.154372   -0.1669     -0.442422
 -0.457849    -0.138407     0.036429    -0.271838   -0.380595   -0.319168    0.113784    -0.130184      0.444057     0.238461     0.278154     0.146815    0.0514087    0.195804   -0.433783     0.412806     0.722194   -0.230428   -1.08452      0.335122    0.791855    -0.132838     0.190483    -0.531445    0.121432    0.158431
  0.215548    -0.607786    -0.53142      0.250505    0.115776    0.028179   -0.714421    -0.000613061  -0.194148    -0.00937074  -0.0853482    0.376461    0.358436     0.0105091   0.289764    -0.31502      0.315908   -0.271166    0.10083     -0.205581   -0.531474     0.341672    -0.86336     -0.729977   -0.30277     0.28189
  0.613745     0.398178     0.396911     0.999154    0.151549   -0.125547   -0.870121    -0.55406      -0.794321    -0.216855     0.361417    -0.0667862   0.28198      0.0300754  -0.21684     -0.4166       0.451259   -0.246727   -0.19985     -0.346775   -0.732573     0.489682     0.199596     0.0560747   0.175961   -0.0619685
 -0.277088    -0.512796     0.8806       0.382206    0.402942    0.139971    0.425169     0.310042      0.246293    -0.629093    -0.355289    -0.0523948   0.282426    -0.875945   -0.753863    -0.350738    -0.734395   -0.101286   -0.33453      0.159923   -0.368686     0.0198703   -0.310039    -0.267099    0.226235    0.102715
 -0.614035     0.126291     0.0480705    0.582506   -0.481229    0.335032   -0.310351     0.155889     -0.26652      0.288407    -0.0515855   -0.365199    0.0570038   -0.206057    0.219655    -0.0327386   -0.386846    0.0103033   0.0627184    0.141964    0.191519     0.0570449   -0.111319     0.189342    0.458503    0.480541
  0.0666601    0.0689593   -0.0562669   -0.0398209   0.0424914   0.376529    0.0974952   -0.172784     -0.0968626    0.148655    -0.406219    -0.0189231   0.329463    -0.0933666   0.445439    -0.132927    -0.0173676   0.0588      0.569454    -0.131337   -0.445477    -0.036783    -0.201554     0.0828715  -0.594137   -0.148115
  0.0856349    0.124082    -0.2276      -0.229851    0.0114213  -0.0302685   0.00399303   0.0473896    -0.0547004    0.0274697    0.232936     0.302881   -0.0187805   -0.109615   -0.146397     0.185257    -0.018653   -0.154714   -0.126822     0.117741   -0.126812     0.00526699   0.00535818  -0.143704    0.279186    0.031869
  0.160346    -0.304936     0.46881      0.3209     -0.14081    -0.266279    0.329364    -0.371658      0.228123    -0.221754     0.296272    -1.26814    -0.141645     0.335161   -0.385481    -0.291427     0.0264751   0.526053   -0.00474738  -0.297827    0.0822424   -0.265438     0.274384     0.272558   -0.229022    0.0768137
 -0.200086    -0.214581    -0.309988    -0.475913    0.221346   -0.344763   -0.212349     0.0525686     0.394332    -0.0315578   -0.253956    -0.198308    0.662004     0.0219846  -0.404076     0.312487     0.426582    0.198159    0.545489     0.392642    0.205857    -0.234176    -0.592195    -0.227218   -0.0267495   0.285793
 -0.15626      0.235555    -0.012476     0.790313    0.115427    0.521677   -0.222512     0.298746     -0.0814178   -0.127062    -0.619681     0.417428    0.507767     0.411264    0.150829     0.96061      0.431289   -0.264965    0.143793    -0.0552506   0.142505     0.286382    -0.278429     0.104125   -0.413334    0.0331562
 -0.508343    -0.00885224   0.879286     0.357511    0.0970268  -0.130893    0.00683888   0.516677     -0.00793047  -0.0822894   -0.747443     0.0605307  -0.221744    -0.27649    -0.194564    -0.561488     0.214571    0.297735   -0.358283     0.0192371   0.973158     0.492209     0.366324     0.371501    0.271805   -0.395866
 -0.00474535   0.0995919   -0.492775    -0.724966    0.0225875  -0.329584   -0.171999    -1.04933       0.812444     0.218164     0.0646993   -0.134607    0.648425     0.5017     -0.0882747    0.0485287    0.396134    0.0851428  -0.082265    -0.58623    -0.448845    -0.424508     0.117788     0.0366669   0.0454053  -0.00969977[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411877
[ Info: iteration 2, average log likelihood -1.411868
[ Info: iteration 3, average log likelihood -1.411859
[ Info: iteration 4, average log likelihood -1.411850
[ Info: iteration 5, average log likelihood -1.411842
[ Info: iteration 6, average log likelihood -1.411834
[ Info: iteration 7, average log likelihood -1.411826
[ Info: iteration 8, average log likelihood -1.411819
[ Info: iteration 9, average log likelihood -1.411812
[ Info: iteration 10, average log likelihood -1.411805
┌ Info: EM with 100000 data points 10 iterations avll -1.411805
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
