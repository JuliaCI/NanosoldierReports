Julia Version 1.5.0-DEV.252
Commit b52be3dc7e (2020-02-08 18:26 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed Arpack_jll ───────── v3.5.0+2
  Installed DataAPI ──────────── v1.1.0
  Installed GaussianMixtures ─── v0.3.0
  Installed PDMats ───────────── v0.9.11
  Installed Compat ───────────── v2.2.0
  Installed HDF5 ─────────────── v0.12.5
  Installed StatsBase ────────── v0.32.0
  Installed Distributions ────── v0.22.4
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed ScikitLearnBase ──── v0.5.0
  Installed QuadGK ───────────── v2.3.1
  Installed FillArrays ───────── v0.8.4
  Installed BinaryProvider ───── v0.5.8
  Installed DataStructures ───── v0.17.9
  Installed FileIO ───────────── v1.2.2
  Installed Distances ────────── v0.8.2
  Installed OrderedCollections ─ v1.1.0
  Installed URIParser ────────── v0.4.0
  Installed Blosc ────────────── v0.5.1
  Installed StatsFuns ────────── v0.9.3
  Installed StaticArrays ─────── v0.12.1
  Installed JLD ──────────────── v0.9.2
  Installed NearestNeighbors ─── v0.4.4
  Installed Arpack ───────────── v0.4.0
  Installed SpecialFunctions ─── v0.9.0
  Installed CMake ────────────── v1.1.2
  Installed BinDeps ──────────── v1.0.0
  Installed Rmath ────────────── v0.6.0
  Installed Parameters ───────── v0.12.0
  Installed SortingAlgorithms ── v0.3.1
  Installed Missings ─────────── v0.4.3
  Installed LegacyStrings ────── v0.4.1
  Installed CMakeWrapper ─────── v0.2.3
  Installed Clustering ───────── v0.13.3
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                         #                                                                          2.2%####                                                                       6.4%########                                                                  11.2%############                                                              17.7%##################                                                        25.8%#######################                                                   33.1%##################################                                        47.6%##############################################                            64.3%#############################################################             85.9%######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.2
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_j20r0T/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.2
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -5.404526735469635e6, [92126.5077054245, 7873.492294575502], [11349.944315578763 7986.395377100085 -5918.567839395341; -10950.928045657947 -8100.7469448350075 5427.685719333808], [[80142.44073775814 -8899.832096030654 5801.725803078326; -8899.832096030652 86448.8889472366 3522.1921726717987; 5801.725803078327 3522.1921726717983 89222.15798146564], [19394.691842731434 8526.932421957628 -5694.2787446237235; 8526.932421957628 14120.528113002638 -4345.401516207676; -5694.2787446237235 -4345.401516207676 10747.877422410817]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.472721e+03
      1       9.753173e+02      -4.974033e+02 |        3
      2       9.338992e+02      -4.141817e+01 |        0
      3       9.338992e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 933.8991669268971)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.071305
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.825103
[ Info: iteration 2, lowerbound -3.686396
[ Info: iteration 3, lowerbound -3.535986
[ Info: iteration 4, lowerbound -3.364087
[ Info: iteration 5, lowerbound -3.186037
[ Info: iteration 6, lowerbound -3.019493
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.862210
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.719793
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.600292
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.504238
[ Info: iteration 11, lowerbound -2.437234
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.385394
[ Info: iteration 13, lowerbound -2.346302
[ Info: iteration 14, lowerbound -2.321242
[ Info: iteration 15, lowerbound -2.308526
[ Info: dropping number of Gaussions to 2
[ Info: iteration 16, lowerbound -2.303133
[ Info: iteration 17, lowerbound -2.299264
[ Info: iteration 18, lowerbound -2.299258
[ Info: iteration 19, lowerbound -2.299255
[ Info: iteration 20, lowerbound -2.299254
[ Info: iteration 21, lowerbound -2.299253
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sun Feb  9 23:44:26 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sun Feb  9 23:44:34 2020: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Sun Feb  9 23:44:36 2020: EM with 272 data points 0 iterations avll -2.071305
5.8 data points per parameter
, Sun Feb  9 23:44:38 2020: GMM converted to Variational GMM
, Sun Feb  9 23:44:47 2020: iteration 1, lowerbound -3.825103
, Sun Feb  9 23:44:47 2020: iteration 2, lowerbound -3.686396
, Sun Feb  9 23:44:47 2020: iteration 3, lowerbound -3.535986
, Sun Feb  9 23:44:47 2020: iteration 4, lowerbound -3.364087
, Sun Feb  9 23:44:47 2020: iteration 5, lowerbound -3.186037
, Sun Feb  9 23:44:47 2020: iteration 6, lowerbound -3.019493
, Sun Feb  9 23:44:47 2020: dropping number of Gaussions to 7
, Sun Feb  9 23:44:47 2020: iteration 7, lowerbound -2.862210
, Sun Feb  9 23:44:47 2020: dropping number of Gaussions to 6
, Sun Feb  9 23:44:47 2020: iteration 8, lowerbound -2.719793
, Sun Feb  9 23:44:47 2020: dropping number of Gaussions to 5
, Sun Feb  9 23:44:47 2020: iteration 9, lowerbound -2.600292
, Sun Feb  9 23:44:47 2020: dropping number of Gaussions to 4
, Sun Feb  9 23:44:47 2020: iteration 10, lowerbound -2.504238
, Sun Feb  9 23:44:47 2020: iteration 11, lowerbound -2.437234
, Sun Feb  9 23:44:47 2020: dropping number of Gaussions to 3
, Sun Feb  9 23:44:47 2020: iteration 12, lowerbound -2.385394
, Sun Feb  9 23:44:47 2020: iteration 13, lowerbound -2.346302
, Sun Feb  9 23:44:47 2020: iteration 14, lowerbound -2.321242
, Sun Feb  9 23:44:47 2020: iteration 15, lowerbound -2.308526
, Sun Feb  9 23:44:47 2020: dropping number of Gaussions to 2
, Sun Feb  9 23:44:47 2020: iteration 16, lowerbound -2.303133
, Sun Feb  9 23:44:47 2020: iteration 17, lowerbound -2.299264
, Sun Feb  9 23:44:47 2020: iteration 18, lowerbound -2.299258
, Sun Feb  9 23:44:47 2020: iteration 19, lowerbound -2.299255
, Sun Feb  9 23:44:47 2020: iteration 20, lowerbound -2.299254
, Sun Feb  9 23:44:47 2020: iteration 21, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 22, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 23, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 24, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 25, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 26, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 27, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 28, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 29, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 30, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 31, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 32, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 33, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 34, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 35, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 36, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 37, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 38, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 39, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 40, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 41, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 42, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 43, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 44, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 45, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 46, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 47, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 48, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 49, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: iteration 50, lowerbound -2.299253
, Sun Feb  9 23:44:47 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398597, 178.04509222601408]
β = [95.95490777398597, 178.04509222601408]
m = [2.0002292577753686 53.85198717246128; 4.250300733269907 79.2868669443618]
ν = [97.95490777398597, 180.04509222601408]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763611948434 -0.008953123827346131; 0.0 0.012748664777409349], [0.18404155547484774 -0.007644049042327638; 0.0 0.008581705166333407]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999996
avll from stats: -0.9953726683684228
avll from llpg:  -0.9953726683684232
avll direct:     -0.995372668368423
sum posterior: 99999.99999999999
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9759509111779531
avll from llpg:  -0.9759509111779532
avll direct:     -0.9759509111779532
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
  0.173182     -0.0446401   -0.108182     0.154589     0.0292337  -0.104372     0.0892912     0.0540313   -0.0208372   -0.00175248   0.144028     -0.124818    -0.0183723    0.0459993   -0.0187933   -0.0654362  -0.109674     0.131079     0.202719     0.189929    -0.0936529   -0.0111524    0.106921     0.00662055    0.0483822   -0.0197453
  0.000795793  -0.0571143    0.0354599    0.00531511  -0.224673   -0.0735301   -0.0469601     0.0490886   -0.0296945    0.0386       0.0120677     0.161767    -0.112458    -0.0767314   -0.0294435   -0.0975947  -0.240308     0.102737    -0.146341    -0.0569245    0.0186587    0.0719219   -0.0849258    0.0954679    -0.0377092   -0.144172
 -0.306298     -0.0118573   -0.180697     0.0270176    0.0672599  -0.0125362   -0.00931167   -0.148176     0.191947     0.089979    -0.0410092     0.0829018   -0.0561137    0.0500954   -0.00292198  -0.155195   -0.14684      0.0617764   -0.0685896    0.0310613   -0.0206198    0.0690679    0.0514694   -0.103528      0.0317096   -0.0901451
 -0.10732      -0.0763723   -0.0492697    0.187148    -0.0169968  -0.00775606   0.172265      0.0338399   -0.0107032   -0.122564     0.0839163    -0.0541716   -0.0654926   -0.088686     0.0639639   -0.113456    0.0917179    0.0198182   -0.102711    -0.0129022   -0.0897344   -0.0162453   -0.00907988  -0.134332      0.080699    -0.0191151
 -0.0849841     0.0326022    0.0697271   -0.0429862   -0.121613    0.0191021    0.0733558     0.00490454  -0.0363017   -0.0568486   -0.0990951    -0.0809348    0.111308     0.0636145   -0.0639512    0.0696362  -0.024248     0.0912961   -0.0550481    0.143537     0.00671564  -0.0189537    0.129462     0.07118      -0.0562904    0.0406669
  0.147677     -0.00357309  -0.162616    -0.045743     0.0139328  -0.112723    -0.122802      0.190554    -0.147975     0.0961432    0.137221      0.154141    -0.0582977   -0.0329444   -0.109799     0.0544065   0.0236291    0.0446968    0.11816     -0.280339    -0.026054    -0.0899524    0.0784107   -0.0474881    -0.00751398   0.116725
  0.0139666     0.076191    -0.0646888   -0.12134      0.0380198   0.0792986   -0.0182563     0.0243686    0.0180404   -0.0437904    0.0406514     0.0808797    0.0429813   -0.085348    -0.097583    -0.0513891   0.0591298   -0.0329911    0.277002    -0.0247404    0.0251631    0.0650095    0.0275139   -0.105164     -0.0136718    0.148974
  0.142988     -0.146258    -0.192367     0.0428501    0.0342332   0.0836824   -0.173304      0.0806878   -0.0451104    0.120314     0.134261     -0.220912    -0.0216074    0.143149     0.119569    -0.0887356   0.0695765    0.0643436   -0.00376713  -0.0486195    0.00730185   0.096032     0.00885854   0.132293     -0.00442173   0.0635385
 -0.056329     -0.17217      0.0124647    0.148174    -0.17141    -0.00808686   0.00638528   -0.0190557    0.0359248   -0.166217     0.0579907     0.143554     0.163041    -0.0760168   -0.0789934   -0.0244288  -0.0670215   -0.0918087    0.0248639    0.0478328   -0.0625028   -0.00687931  -0.078931    -0.0390051     0.0365894    0.040833
  0.16804       0.216363    -0.147588     0.169594    -0.104353   -0.0415599   -0.0231597     0.0972318    0.124495    -0.0132192   -0.177031     -0.0361441   -0.00318069  -0.157482     0.0578808    0.0361743   0.00281701   0.0881635   -0.120106    -0.0229929    0.0398296   -0.030543    -0.0829371    0.0206227    -0.0689343   -0.180326
 -0.0356783    -0.018532    -0.104286     0.192446     0.101048   -0.00553409   0.18723      -0.148878     0.121919     0.0575173   -0.0441492     0.189438    -0.0513536   -0.0217304    0.0531846    0.070561   -0.060924    -0.181887    -0.0356172    0.138792    -0.00897081   0.0475971   -0.0766211   -0.0530962     0.0192977    0.178656
  0.110538      0.024632     0.0155655    0.0405332   -0.0106297   0.0359957    0.0231038    -0.151651     0.0708695    0.0187863    0.158808     -0.0419231   -0.0440783    0.122022    -0.0741668    0.0940084   0.203895    -0.189914    -0.0141691   -0.011257     0.0905715    0.248524     0.05423      0.120945      0.0153122    0.032448
  0.0323386     0.0796818   -0.0820112    0.0274998   -0.0382483  -0.0819315   -0.160787      0.0344546   -0.0678621   -0.129233     0.0336142     0.0538507    0.0515685    0.00845333  -0.03081      0.0541506   0.144762    -0.0987809    0.251955    -0.00113714   0.143257     0.063541    -0.0755175   -0.0107322    -0.133831    -0.099115
 -0.0875169     0.00873804  -0.0144045    0.234155     0.0994265   0.10776      0.0427477    -0.00476806   0.0396268   -0.0788652   -0.159149      0.00350958   0.13842     -0.00644523   0.115601    -0.0372019   0.0389812   -0.0591395   -0.0046016   -0.0419977   -0.0949942    0.0080104   -0.0470482   -0.0885441    -0.156329    -0.00407259
  0.0536065     0.0430877   -0.180929    -0.0502629    0.084587   -0.0656947    0.083962      0.119623    -0.0286501   -0.0178204   -0.0927573     0.115192     0.1611       0.175269     0.0405972   -0.15719     0.00334326  -0.0225935   -0.0313739    0.077013     0.0754529    0.00364553  -0.0584179   -0.122316      0.0881619    0.047471
 -0.1481       -0.00973433  -0.0658288   -0.108587     0.0800841   0.114582    -0.000907591  -0.100045    -0.0464754    0.0483671    0.0200896     0.0530025    0.00886156  -0.0860012   -0.0293591    0.0562327  -0.0825718    0.140617    -0.169786    -0.066883     0.0559998   -0.0061864    0.047485     0.0522007    -0.0624441    0.15868
 -0.0591615    -0.0246947   -0.0289426   -0.0410694    0.116713   -0.0167432    0.000799406   0.0549857   -0.101258     0.001101     0.00918965    0.0918594   -0.233411    -0.132281    -0.0317636    0.0449127  -0.0106417    0.0790337   -0.0991992    0.0989755   -0.00747538  -0.244518     0.0766037    0.0131825     0.0204533   -0.0394176
  0.0520083     0.00648562   0.039106    -0.00974869  -0.0983245  -0.129672     0.0011921     0.027165     0.0278034   -0.0426236    0.0569448    -0.0907731    0.0353557   -0.021933    -0.0494734    0.104079    0.0588848   -0.00367207  -0.0334694   -0.019925    -0.030046    -0.10716      0.0702196    0.000746661   0.0486984    0.101266
  0.0216753    -0.110253     0.0498191   -0.00516892   0.115973   -0.123012    -0.0934385    -0.0196272    0.084957     0.122827     0.000762809  -0.0209212    0.129951    -0.179208    -0.0480671   -0.0683335   0.117431     0.281012    -0.0842014   -0.142377    -0.0101484    0.00778152  -0.211924     0.175589      0.0606148    0.0604745
 -0.0520789     0.0533115   -0.0897345   -0.184713    -0.0681482   0.00697972   0.00738591   -0.0226989    0.0471586    0.146185    -0.109931      0.0688076   -0.0577484   -0.0445617    0.0260005   -0.0547217  -0.0560739   -0.125266    -0.151445     0.0785441    0.00219758  -0.0310349    0.0218799   -0.103896     -0.0845702    0.0240637
 -0.197072      0.123867    -0.00192729   0.0133954   -0.0815412  -0.0588586   -0.122318     -0.0869857   -0.261742     0.0308184   -0.0780931     0.00269155   0.105783     0.104126     0.0905196   -0.133       0.267288     0.010111     0.0105695    0.109596    -0.177764    -0.0793848    0.095203    -0.0404946     0.0278601   -0.0384675
  0.0222683    -0.0501295   -0.352235     0.0280708    0.107207   -0.0341278   -0.0214626    -0.020992    -0.114364     0.0853694    0.0780918    -0.0440039   -0.0487459   -0.104032     0.0831915   -0.0543644   0.0587872   -0.0642017   -0.214389    -0.092397    -0.088171     0.255853    -0.00860735  -0.0859737    -0.0140682   -0.128321
 -0.11813      -0.126434    -0.0258859   -0.236491     0.0524617   0.130189     0.0120919     0.163498    -0.00681317   0.0974855   -0.100725     -0.198306    -0.0328377   -0.19975     -0.0811527    0.0886158   0.0813039   -0.0503483    0.0150422   -0.0994186    0.0216059    0.0417828    0.167895    -0.14526       0.00167044  -0.0240468
 -0.0437341     0.0381807   -0.0323219    0.132201    -0.019227   -0.0563749    0.062169     -0.130309    -0.0368892    0.03923      0.0410833     0.0981378    0.23561     -0.112522     0.156007    -0.160399   -0.016018     0.134867    -0.0826684   -0.195731     0.152964    -0.0741206   -0.0352517   -0.169039     -0.162971     0.10093
 -0.0738097    -0.156894    -0.0257567    0.17055     -0.0566411  -0.0792368    0.0589011     0.100714    -0.0969921    0.0577635    0.114357     -0.0436904    0.0841371    0.0206312    0.173391    -0.156731   -0.0298308    0.0419405    0.0561113    0.153693    -0.113189     0.112561     0.0594246    0.0628798    -0.103019    -0.159291
 -0.0969634    -0.0712027    0.101426     0.0674058    0.0526273  -0.13394     -0.188018      0.1668      -0.0820793    0.0209958   -0.0917754    -0.00513396   0.0106785   -0.202654    -0.0726764    0.0109123  -0.0358206   -0.0288586   -0.0700464   -0.127167     0.194691    -0.0210095    0.0944843    0.137131     -0.0645515    0.0733484
 -0.226267     -0.0442689   -0.111157    -0.0284811   -0.118976    0.168235    -0.110648     -0.125322     0.0197775   -0.0747243    0.0074594    -0.0735858    0.164624    -0.153385    -0.0528057   -0.0929451   0.0380437    0.171646     0.0765785   -0.0324658    0.166437    -0.124113     0.0287701    0.0439171    -0.0680832    0.0440328
 -0.0156242    -0.0165099    0.099477    -0.113382     0.0801655   0.0380861   -0.0895733     0.0837481   -0.036067     0.0590317    0.00822439    0.103429    -0.0765175   -0.0124878    0.0777965   -0.131644    0.0804359   -0.0634339    0.0631547    0.0139482   -0.0162381   -0.0240623    0.103558     0.199522      0.199625     0.0082851
  0.153867      0.170496    -0.197973     0.0589071   -0.0467      0.0383272    0.106581     -0.13752     -0.0466922   -0.00251973   0.00492355    0.291322     0.0999027   -0.0544905    0.0338854   -0.0507184   0.0167685    0.00291442  -0.0190382   -0.0446545    0.0744378    0.113367    -0.00458566   0.0213888     0.0879931   -0.0108942
 -0.0629464    -0.00459207  -0.0153995    0.158949    -0.0662577  -0.0824789    0.156045      0.163623    -0.13615     -0.00594932  -0.00281607   -0.0578038    0.0849933    0.205836    -0.0438616    0.12426    -0.0709815    0.0803445    0.0603998   -0.0916916   -0.126641     0.138531    -0.204515    -0.13707       0.0619919   -0.0497055
 -0.130091     -0.0970335    0.109755    -0.0230719    0.0264697   0.0691886   -0.16337       0.0221083   -0.0391262    0.117478    -0.156449     -0.113323     0.077518    -0.00370708   0.134948    -0.179249   -0.131296     0.0667691   -0.0147116    0.171867    -0.113464    -0.0730997   -0.0342782    0.0618154    -0.0183983    0.118177
 -0.021738     -0.00301495  -0.133334    -0.0320419    0.0436205  -0.0218265    0.0524246    -0.0260426    0.0811851   -0.0826724   -0.0823356    -0.00495742   0.0932045    0.19231      0.0197965   -0.0108031   0.0334273   -0.0982028    0.0664878   -0.0811602   -0.0505426   -0.044705    -0.0842793   -0.0990551    -7.25411e-5  -0.00593499kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3904375419013244
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.390514
[ Info: iteration 2, average log likelihood -1.390430
[ Info: iteration 3, average log likelihood -1.389273
[ Info: iteration 4, average log likelihood -1.378400
[ Info: iteration 5, average log likelihood -1.360672
[ Info: iteration 6, average log likelihood -1.355497
[ Info: iteration 7, average log likelihood -1.354038
[ Info: iteration 8, average log likelihood -1.353181
[ Info: iteration 9, average log likelihood -1.352684
[ Info: iteration 10, average log likelihood -1.352408
[ Info: iteration 11, average log likelihood -1.352231
[ Info: iteration 12, average log likelihood -1.352093
[ Info: iteration 13, average log likelihood -1.351969
[ Info: iteration 14, average log likelihood -1.351849
[ Info: iteration 15, average log likelihood -1.351723
[ Info: iteration 16, average log likelihood -1.351574
[ Info: iteration 17, average log likelihood -1.351367
[ Info: iteration 18, average log likelihood -1.351008
[ Info: iteration 19, average log likelihood -1.350429
[ Info: iteration 20, average log likelihood -1.349821
[ Info: iteration 21, average log likelihood -1.349402
[ Info: iteration 22, average log likelihood -1.349148
[ Info: iteration 23, average log likelihood -1.349001
[ Info: iteration 24, average log likelihood -1.348918
[ Info: iteration 25, average log likelihood -1.348871
[ Info: iteration 26, average log likelihood -1.348844
[ Info: iteration 27, average log likelihood -1.348828
[ Info: iteration 28, average log likelihood -1.348817
[ Info: iteration 29, average log likelihood -1.348811
[ Info: iteration 30, average log likelihood -1.348807
[ Info: iteration 31, average log likelihood -1.348805
[ Info: iteration 32, average log likelihood -1.348803
[ Info: iteration 33, average log likelihood -1.348802
[ Info: iteration 34, average log likelihood -1.348801
[ Info: iteration 35, average log likelihood -1.348801
[ Info: iteration 36, average log likelihood -1.348801
[ Info: iteration 37, average log likelihood -1.348801
[ Info: iteration 38, average log likelihood -1.348800
[ Info: iteration 39, average log likelihood -1.348800
[ Info: iteration 40, average log likelihood -1.348800
[ Info: iteration 41, average log likelihood -1.348800
[ Info: iteration 42, average log likelihood -1.348800
[ Info: iteration 43, average log likelihood -1.348800
[ Info: iteration 44, average log likelihood -1.348800
[ Info: iteration 45, average log likelihood -1.348800
[ Info: iteration 46, average log likelihood -1.348800
[ Info: iteration 47, average log likelihood -1.348800
[ Info: iteration 48, average log likelihood -1.348800
[ Info: iteration 49, average log likelihood -1.348800
[ Info: iteration 50, average log likelihood -1.348800
┌ Info: EM with 100000 data points 50 iterations avll -1.348800
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3905139751521158
│     -1.3904301019055996
│      ⋮
└     -1.3488002062541409
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.348893
[ Info: iteration 2, average log likelihood -1.348791
[ Info: iteration 3, average log likelihood -1.347930
[ Info: iteration 4, average log likelihood -1.338486
[ Info: iteration 5, average log likelihood -1.318900
[ Info: iteration 6, average log likelihood -1.311066
[ Info: iteration 7, average log likelihood -1.308630
[ Info: iteration 8, average log likelihood -1.307154
[ Info: iteration 9, average log likelihood -1.306014
[ Info: iteration 10, average log likelihood -1.305187
[ Info: iteration 11, average log likelihood -1.304603
[ Info: iteration 12, average log likelihood -1.304189
[ Info: iteration 13, average log likelihood -1.303900
[ Info: iteration 14, average log likelihood -1.303704
[ Info: iteration 15, average log likelihood -1.303572
[ Info: iteration 16, average log likelihood -1.303477
[ Info: iteration 17, average log likelihood -1.303400
[ Info: iteration 18, average log likelihood -1.303324
[ Info: iteration 19, average log likelihood -1.303247
[ Info: iteration 20, average log likelihood -1.303187
[ Info: iteration 21, average log likelihood -1.303153
[ Info: iteration 22, average log likelihood -1.303135
[ Info: iteration 23, average log likelihood -1.303126
[ Info: iteration 24, average log likelihood -1.303121
[ Info: iteration 25, average log likelihood -1.303118
[ Info: iteration 26, average log likelihood -1.303117
[ Info: iteration 27, average log likelihood -1.303116
[ Info: iteration 28, average log likelihood -1.303115
[ Info: iteration 29, average log likelihood -1.303115
[ Info: iteration 30, average log likelihood -1.303115
[ Info: iteration 31, average log likelihood -1.303115
[ Info: iteration 32, average log likelihood -1.303114
[ Info: iteration 33, average log likelihood -1.303114
[ Info: iteration 34, average log likelihood -1.303114
[ Info: iteration 35, average log likelihood -1.303114
[ Info: iteration 36, average log likelihood -1.303114
[ Info: iteration 37, average log likelihood -1.303114
[ Info: iteration 38, average log likelihood -1.303114
[ Info: iteration 39, average log likelihood -1.303114
[ Info: iteration 40, average log likelihood -1.303114
[ Info: iteration 41, average log likelihood -1.303114
[ Info: iteration 42, average log likelihood -1.303114
[ Info: iteration 43, average log likelihood -1.303114
[ Info: iteration 44, average log likelihood -1.303114
[ Info: iteration 45, average log likelihood -1.303114
[ Info: iteration 46, average log likelihood -1.303114
[ Info: iteration 47, average log likelihood -1.303114
[ Info: iteration 48, average log likelihood -1.303114
[ Info: iteration 49, average log likelihood -1.303114
[ Info: iteration 50, average log likelihood -1.303114
┌ Info: EM with 100000 data points 50 iterations avll -1.303114
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3488926810341213
│     -1.3487911455403696
│      ⋮
└     -1.3031141172002803
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.303260
[ Info: iteration 2, average log likelihood -1.303100
[ Info: iteration 3, average log likelihood -1.302222
[ Info: iteration 4, average log likelihood -1.295003
[ Info: iteration 5, average log likelihood -1.278364
[ Info: iteration 6, average log likelihood -1.264625
[ Info: iteration 7, average log likelihood -1.257440
[ Info: iteration 8, average log likelihood -1.253656
[ Info: iteration 9, average log likelihood -1.251801
[ Info: iteration 10, average log likelihood -1.250783
[ Info: iteration 11, average log likelihood -1.250157
[ Info: iteration 12, average log likelihood -1.249759
[ Info: iteration 13, average log likelihood -1.249501
[ Info: iteration 14, average log likelihood -1.249321
[ Info: iteration 15, average log likelihood -1.249178
[ Info: iteration 16, average log likelihood -1.249048
[ Info: iteration 17, average log likelihood -1.248914
[ Info: iteration 18, average log likelihood -1.248756
[ Info: iteration 19, average log likelihood -1.248550
[ Info: iteration 20, average log likelihood -1.248273
[ Info: iteration 21, average log likelihood -1.247886
[ Info: iteration 22, average log likelihood -1.247334
[ Info: iteration 23, average log likelihood -1.246574
[ Info: iteration 24, average log likelihood -1.245478
[ Info: iteration 25, average log likelihood -1.243824
[ Info: iteration 26, average log likelihood -1.242265
[ Info: iteration 27, average log likelihood -1.241632
[ Info: iteration 28, average log likelihood -1.241416
[ Info: iteration 29, average log likelihood -1.241306
[ Info: iteration 30, average log likelihood -1.241231
[ Info: iteration 31, average log likelihood -1.241172
[ Info: iteration 32, average log likelihood -1.241123
[ Info: iteration 33, average log likelihood -1.241079
[ Info: iteration 34, average log likelihood -1.241035
[ Info: iteration 35, average log likelihood -1.240984
[ Info: iteration 36, average log likelihood -1.240907
[ Info: iteration 37, average log likelihood -1.240774
[ Info: iteration 38, average log likelihood -1.240490
[ Info: iteration 39, average log likelihood -1.239857
[ Info: iteration 40, average log likelihood -1.238678
[ Info: iteration 41, average log likelihood -1.237324
[ Info: iteration 42, average log likelihood -1.236815
[ Info: iteration 43, average log likelihood -1.236672
[ Info: iteration 44, average log likelihood -1.236584
[ Info: iteration 45, average log likelihood -1.236518
[ Info: iteration 46, average log likelihood -1.236466
[ Info: iteration 47, average log likelihood -1.236426
[ Info: iteration 48, average log likelihood -1.236397
[ Info: iteration 49, average log likelihood -1.236375
[ Info: iteration 50, average log likelihood -1.236359
┌ Info: EM with 100000 data points 50 iterations avll -1.236359
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3032603936785812
│     -1.3030998321608587
│      ⋮
└     -1.2363589828508206
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.236579
[ Info: iteration 2, average log likelihood -1.236302
[ Info: iteration 3, average log likelihood -1.235160
[ Info: iteration 4, average log likelihood -1.224709
[ Info: iteration 5, average log likelihood -1.191959
[ Info: iteration 6, average log likelihood -1.162882
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.148076
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.148450
[ Info: iteration 9, average log likelihood -1.161715
[ Info: iteration 10, average log likelihood -1.147689
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.140311
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.144151
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.148545
[ Info: iteration 14, average log likelihood -1.148103
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.138930
[ Info: iteration 16, average log likelihood -1.143205
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.133755
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.144939
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.145723
[ Info: iteration 20, average log likelihood -1.148064
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.137158
[ Info: iteration 22, average log likelihood -1.145333
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.138014
[ Info: iteration 24, average log likelihood -1.151959
[ Info: iteration 25, average log likelihood -1.146949
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.136513
[ Info: iteration 27, average log likelihood -1.145984
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.138418
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.144766
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.143765
[ Info: iteration 31, average log likelihood -1.147347
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.139188
[ Info: iteration 33, average log likelihood -1.145861
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.136290
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.138461
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.146014
[ Info: iteration 37, average log likelihood -1.148865
[ Info: iteration 38, average log likelihood -1.140194
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.133601
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.150730
[ Info: iteration 41, average log likelihood -1.150604
[ Info: iteration 42, average log likelihood -1.141073
[ Info: iteration 43, average log likelihood -1.134582
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.128962
[ Info: iteration 45, average log likelihood -1.159191
[ Info: iteration 46, average log likelihood -1.152650
[ Info: iteration 47, average log likelihood -1.143029
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.134835
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.143451
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.147256
┌ Info: EM with 100000 data points 50 iterations avll -1.147256
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2365790993280943
│     -1.2363024818054582
│      ⋮
└     -1.1472560286537605
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.147927
[ Info: iteration 2, average log likelihood -1.136495
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.127979
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.112764
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.037692
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     12
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.032581
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.021253
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     18
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.025586
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│     12
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.019433
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     18
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.028395
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.019682
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     12
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.033075
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.018599
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     12
│     18
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.024308
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│     26
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.022409
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.033445
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.012805
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.036441
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│     26
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.013039
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     12
│     18
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.029963
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.025951
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.026533
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.009744
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.042926
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.016084
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     12
│     18
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.023009
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│     26
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.022818
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.033279
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.012686
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.036153
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│     26
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.012640
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     12
│     18
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.029876
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.025846
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     12
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.026357
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.014449
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.039346
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│     12
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.014715
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     18
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.027993
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│     26
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.018722
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     12
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.031644
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.017709
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.032431
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.011122
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     18
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.034963
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.022012
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     12
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.024731
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.014357
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.039288
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│     12
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.014689
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     18
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.027956
┌ Info: EM with 100000 data points 50 iterations avll -1.027956
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.147926773504745
│     -1.136495025495332
│      ⋮
└     -1.0279557918360027
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3904375419013244
│     -1.3905139751521158
│     -1.3904301019055996
│     -1.3892725290650267
│      ⋮
│     -1.0392876179810555
│     -1.014689464686504
└     -1.0279557918360027
32×26 Array{Float64,2}:
 -0.0902506    0.0154321   -0.0587195   -0.08887     -0.0425345    0.11873      -0.0671714    -0.0430393    0.0213365   -0.0322058    0.0262891    0.0287841    0.0878012   -0.11604     -0.0744637    -0.0749622    0.0401844    0.0924906     0.177904     -0.0288183    0.0977586   -0.0391478    0.0148621   -0.0262791   -0.017854      0.0880399
 -0.0781239   -0.141718    -0.0228615   -0.0151313   -0.0469438   -0.00313932   -0.000848003   0.132846    -0.0559831    0.0507159    0.00495231  -0.0843807    0.0142585   -0.0999678    0.0336859    -0.0379084   -0.0254057    0.0155626    -0.000519458   0.0141643   -0.0218742    0.0799441    0.0873687   -0.00503407  -0.0528608    -0.109781
 -0.0577747    0.0329377    0.0771205   -0.0482709   -0.132967     0.00411393    0.067167      0.0117185   -0.0270546   -0.0527809   -0.0975472   -0.103598     0.104228     0.0603209   -0.0506961     0.0728048   -0.0297617    0.10367      -0.0592801     0.134053    -0.00972576  -0.0207971    0.119151     0.0731856   -0.055154      0.0341773
 -0.0353636   -0.0177861   -0.106828     0.21153      0.0981659   -0.00219046    0.195387     -0.158249     0.140412     0.071961    -0.0419144    0.195273    -0.0529695   -0.029505     0.0834212     0.0821217   -0.0585721   -0.178565     -0.0313166     0.140867     0.00115589   0.0491242   -0.0683623   -0.0423309   -0.000403575   0.181301
 -0.100117     0.00433259  -0.0221985    0.215701     0.101057     0.141312      0.041173      0.00404899   0.0374778   -0.0811963   -0.178184     0.033381     0.138718     0.00466228   0.104        -0.0117377    0.0323274   -0.0610042    -0.00423315   -0.0351384   -0.115383     0.00698516  -0.0506034   -0.0774739   -0.14503       0.000689176
  0.109881     0.0149921    0.0206248    0.0878859   -0.0200194    0.0144977     0.0176903    -0.137687     0.0577295    0.0259975    0.124533     0.0794289   -0.0465438    0.139565    -0.0639672     0.0717133    0.140113    -0.181974     -0.0288223    -0.0105838    0.0915168    0.237059     0.0722788    0.142891     0.0104283     0.0158488
 -0.148103     0.0132196   -0.0425474   -0.10767      0.0588519    0.118178      0.00154155   -0.108473    -0.0638997    0.0183271    0.00706963   0.0989388    0.0140968   -0.0827488    0.0069977     0.0588869   -0.0794236    0.152966     -0.148267     -0.064747     0.0619368   -0.00577856   0.0478066    0.0554593   -0.0617617     0.186694
  0.147769    -0.00240143  -0.15576     -0.0594329    0.0219914   -0.112578     -0.125595      0.175187    -0.159954     0.0958422    0.115305     0.144386    -0.0568337   -0.0298751   -0.102066      0.053118     0.0214007    0.0406575     0.11871      -0.272408    -0.031812    -0.0901165    0.1163      -0.0468269   -0.0175417     0.140761
 -0.0528738   -0.0346424   -0.00250601   0.301822    -0.266552    -0.0849579     0.0854329     0.166196    -0.135567     0.132657    -0.0150979   -0.0673241    0.0836645    0.175274     0.0247543     0.119098    -0.0708336    0.451027      0.0594746    -0.0833851   -0.125397     0.185565    -0.358547    -0.138246     0.253339     -0.0649865
 -0.0654338   -0.0183692   -0.0202728    0.0848241    0.107715    -0.0875926     0.187364      0.109258    -0.134646    -0.0777791   -0.0124335   -0.0159111    0.0858704    0.187875    -0.0550445     0.122542    -0.0709998   -0.225202      0.0593987    -0.094615    -0.125292     0.141649    -0.10588     -0.134617    -0.12224      -0.0304764
  0.00901082  -0.144071     0.0627859   -0.0119402    0.0676501   -0.114346     -0.0930712     0.047248     0.0901897    0.1215       0.0266142   -0.00995644   0.132732    -0.201979    -0.0462199    -0.0710153    0.117207     0.288479     -0.102605     -0.136375    -0.0019692    0.00714297  -0.23936      0.206196     0.0571707     0.0592061
  0.145805    -0.142647    -0.188432     0.0237729    0.0503815    0.0678327    -0.17123       0.0405051   -0.0527271    0.119046     0.0628187   -0.231807    -0.0146839    0.148317     0.124378     -0.086603     0.0829887    0.0587862     0.0246837    -0.0501788   -0.0041111    0.0928092   -0.0334489    0.172769     0.00918362    0.0498387
 -0.0543865    0.0535241   -0.0690768   -0.183831    -0.0711503    0.000807188   0.00790121   -0.0230732    0.0345475    0.107351    -0.0732579    0.0776498   -0.0658486   -0.0442709    0.0424301    -0.0649696   -0.0621627   -0.126702     -0.157307      0.0838869    0.00022993  -0.0436598    0.0354526   -0.0814914   -0.0353993     0.0174935
  0.199331     0.232978    -0.11171      0.169998    -0.10544     -0.0360657    -0.0308458     0.0838131    0.0972899   -0.00551229  -0.174166    -0.0372101   -0.0116033   -0.1465       0.0784273     0.037184     0.00169362   0.0927497    -0.114703     -0.0228964    0.028873    -0.0300234   -0.0982186    0.00872216  -0.0663043    -0.20243
 -0.0415647   -0.0959627    0.0551303    0.0408444   -0.0564013    0.0147841    -0.0403793     0.0638546   -0.00529217  -0.0506407    0.0288405    0.129231     0.0500219   -0.0383807   -0.0199382    -0.0532569   -0.0299926   -0.0681188     0.0400475     0.0395418   -0.0613401   -0.00866534   0.0168327    0.0832141    0.099343      0.0115024
 -0.0760643   -0.0587424    0.110792     0.0728781    0.0287225   -0.117706     -0.186431      0.170618    -0.0613985   -0.00345157  -0.094093     0.0177318    0.0222488   -0.21838     -0.0938007    -0.0685575   -0.0339874   -0.0378031    -0.100928     -0.106993     0.199238    -0.0252707    0.0943459    0.123093    -0.068248      0.0770031
 -0.0525154    0.0346088   -0.0123466    0.13329     -0.0138808   -0.0430437     0.0729401    -0.130523    -0.0403204    0.0422174    0.0322332    0.0790543    0.213973    -0.114656     0.156283     -0.144871    -0.0116634    0.153245     -0.0970504    -0.193954     0.145214    -0.0906738   -0.0413003   -0.175733    -0.170766      0.0965059
 -0.303522    -0.0115043   -0.198281     0.0576626    0.0725068   -0.0104212    -0.0310073    -0.143932     0.189945     0.0925414   -0.0444951    0.0551591   -0.0372502    0.0479164   -0.000641882  -0.157202    -0.1314       0.0415775    -0.0691562     0.0468319   -0.0068831    0.0625575    0.0446959   -0.0335016    0.025343     -0.0916247
  0.0929204    0.168616    -0.190613     0.051791    -0.0441593    0.0450788     0.062469     -0.136557    -0.0492092   -0.0103632    0.00621242   0.277893     0.0923312   -0.0410876    0.0341188    -0.0551842    0.0363778    0.0126889    -0.0433759    -0.0447383    0.0537247    0.136444    -0.00260369   0.0187907    0.0774645    -0.0231639
 -0.0157401   -0.034219    -0.129329    -0.0330682    0.0709257   -0.0252574     0.0602755    -0.00612792   0.0731853   -0.0655434   -0.0986023    0.00720051   0.113559     0.173416     0.0105772    -0.00968534  -0.00338064  -0.10543       0.0668133    -0.080948    -0.0857997   -0.0542656   -0.0583358   -0.100411     0.016133     -0.0117049
 -0.00881244   0.00383061  -0.0503237   -0.0185016    0.106487    -0.133602      0.0533412    -0.089412    -0.114749     0.00416603   0.0762941    0.089846    -0.289212    -0.138304    -0.0256422     0.15626     -0.4244       0.0807478     0.199125      0.18297     -0.0328012   -0.278641     0.0731531   -0.0242866   -0.0432266    -0.0178543
 -0.0238148   -0.0331472   -0.00532011  -0.0731078    0.12475     -0.0461066    -0.0756708     0.161151    -0.0730542   -0.00111926  -0.0580537    0.0947064   -0.184021    -0.129787    -0.0469116    -0.0586058    0.487659     0.0509258    -0.429557      0.0852943   -0.0683146   -0.185501     0.0778422    0.0413657    0.0886978    -0.00561501
 -0.0529212    0.129321    -0.051556     0.0767471    0.0826556    0.0475708    -0.343702      0.0747356    0.0549058   -0.125343     0.0390361   -0.0411265   -0.0677772   -0.0897138    0.0983776    -0.0983514   -0.0710793   -0.000676251   0.0208028     0.0053526   -0.0582172    0.0713333    0.0058587   -0.140166     0.295989     -0.0689487
 -0.145837    -0.301655    -0.0479593    0.149592    -0.0215091   -0.0658989     0.610674      0.00494316  -0.0623589   -0.120616     0.137229    -0.0783294   -0.0574178   -0.0842265    0.0451481    -0.11452      0.264923     0.0488548    -0.302629     -0.0307788   -0.100587    -0.136686    -0.0176746   -0.138723    -0.162142      0.0361905
  0.0344725   -0.0473875   -0.352717     0.0300173    0.106789    -0.0349548    -0.0309826    -0.0229392   -0.123988     0.0710834    0.101887    -0.0411761   -0.0489331   -0.090865     0.074435     -0.0542085    0.0111407   -0.0746834    -0.198975     -0.0788714   -0.100203     0.251254    -0.0123105   -0.0844249   -0.0141043    -0.130463
  0.0350151    0.0874395   -0.0805454    0.0853343   -0.0420355   -0.0820429    -0.15872       0.0346217   -0.0697883   -0.112131     0.037385     0.029779     0.0450374    0.00532238  -0.076963      0.0434178    0.126206    -0.0818735     0.258673     -0.00414329   0.141125     8.66912e-5  -0.071009     0.00806488  -0.13005      -0.0948371
 -0.0636751    0.0631691    0.0228295    0.00194166  -0.0874536   -0.122529     -0.0614578    -0.0350083   -0.113499    -0.00413323  -0.00484485  -0.044742     0.0683861    0.0235471    0.0130207    -0.00607528   0.160232     0.00814608   -0.014336      0.0493641   -0.105038    -0.0996967    0.0802465   -0.0370263    0.0373135     0.0336581
 -0.124088    -0.119697     0.110473    -0.0124156    0.00677079  -0.0211314    -0.159504      0.0185524   -0.052995     0.119842    -0.133977    -0.110008     0.0740482   -0.0198199    0.123687     -0.180678    -0.138739     0.0655508     0.00160351    0.169056    -0.0941927   -0.0871953   -0.038375     0.057045    -0.0204687     0.103877
  0.092989     0.0423512   -0.185729    -0.111553     0.0212995   -0.179405      0.0889676     0.121174    -0.0315137    0.0133214   -0.103767     0.0888198    0.195368     0.233583    -0.845998     -0.154895     0.124078    -0.0138453    -0.138004      0.106329     0.0827716   -0.418668    -0.0382976   -0.24169      0.230676      0.0801226
  0.00928281   0.0425558   -0.190704    -0.0391903    0.0258134    0.0186819     0.0640193     0.121929    -0.0354875    0.00682874  -0.0922897    0.142479     0.154985     0.122033     0.618952     -0.155909    -0.0866377   -0.0161419     0.0306992     0.0499439    0.0687797    0.485392    -0.0766097    0.0137801   -0.0258772     0.00735865
 -0.0937824   -0.0321358   -0.183992     0.143184    -0.0458247   -0.200265      0.0883953    -0.399927    -0.0226343    0.00513322   0.146559    -0.132475    -0.00560682   0.182987    -0.0250926    -0.121054    -0.11721      0.132135      0.235124      0.19032      0.274349    -0.00909207   0.0232176    0.013887     0.0122302    -0.0390133
  0.255434    -0.0758342   -0.0875022    0.162672     0.0548509   -0.133922      0.122         0.424259    -0.0037022    0.00881378   0.142243    -0.148371    -0.0173135   -0.00110403   0.00233808   -0.0236182   -0.108798     0.0327289     0.190388      0.190238    -0.415271    -0.0128646    0.0776739   -0.00643827   0.0736312    -0.0259986[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│     26
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.018601
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      6
│      7
│      9
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.998947
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.010563
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      6
│      7
│      9
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.004967
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│     26
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.012185
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      6
│      7
│      9
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.996821
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│     26
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.018460
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      6
│      7
│      9
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.998788
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.010383
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      6
│      7
│      9
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.004895
┌ Info: EM with 100000 data points 10 iterations avll -1.004895
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.424663e+05
      1       6.593382e+05      -1.831281e+05 |       32
      2       6.300676e+05      -2.927056e+04 |       32
      3       6.141950e+05      -1.587261e+04 |       32
      4       6.025422e+05      -1.165281e+04 |       32
      5       5.950357e+05      -7.506521e+03 |       32
      6       5.915862e+05      -3.449441e+03 |       32
      7       5.896411e+05      -1.945093e+03 |       32
      8       5.881521e+05      -1.489055e+03 |       32
      9       5.870433e+05      -1.108783e+03 |       32
     10       5.861584e+05      -8.848999e+02 |       32
     11       5.853042e+05      -8.541602e+02 |       32
     12       5.845322e+05      -7.720697e+02 |       32
     13       5.840356e+05      -4.965951e+02 |       32
     14       5.837368e+05      -2.988068e+02 |       32
     15       5.835389e+05      -1.978966e+02 |       32
     16       5.833774e+05      -1.615056e+02 |       32
     17       5.832065e+05      -1.709058e+02 |       32
     18       5.829493e+05      -2.571893e+02 |       32
     19       5.825725e+05      -3.767634e+02 |       32
     20       5.820230e+05      -5.495339e+02 |       32
     21       5.811598e+05      -8.631782e+02 |       32
     22       5.801007e+05      -1.059068e+03 |       32
     23       5.793255e+05      -7.752129e+02 |       32
     24       5.789672e+05      -3.583018e+02 |       32
     25       5.787857e+05      -1.815264e+02 |       32
     26       5.786927e+05      -9.294808e+01 |       32
     27       5.786316e+05      -6.109700e+01 |       32
     28       5.785825e+05      -4.915955e+01 |       31
     29       5.785439e+05      -3.857894e+01 |       32
     30       5.785174e+05      -2.646767e+01 |       30
     31       5.785022e+05      -1.523195e+01 |       31
     32       5.784899e+05      -1.226619e+01 |       31
     33       5.784795e+05      -1.041745e+01 |       26
     34       5.784695e+05      -1.007228e+01 |       30
     35       5.784545e+05      -1.498486e+01 |       30
     36       5.784286e+05      -2.591911e+01 |       28
     37       5.783927e+05      -3.587758e+01 |       31
     38       5.783626e+05      -3.006969e+01 |       31
     39       5.783288e+05      -3.380077e+01 |       28
     40       5.782833e+05      -4.547080e+01 |       28
     41       5.782291e+05      -5.425800e+01 |       32
     42       5.781805e+05      -4.853964e+01 |       32
     43       5.781378e+05      -4.268812e+01 |       31
     44       5.781113e+05      -2.652827e+01 |       31
     45       5.780996e+05      -1.171899e+01 |       28
     46       5.780911e+05      -8.503838e+00 |       26
     47       5.780830e+05      -8.060447e+00 |       28
     48       5.780766e+05      -6.436081e+00 |       30
     49       5.780741e+05      -2.523467e+00 |       23
     50       5.780723e+05      -1.739111e+00 |       15
K-means terminated without convergence after 50 iterations (objv = 578072.3354188057)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.294156
[ Info: iteration 2, average log likelihood -1.261657
[ Info: iteration 3, average log likelihood -1.227463
[ Info: iteration 4, average log likelihood -1.186148
[ Info: iteration 5, average log likelihood -1.132071
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     15
│     22
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.061353
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      5
│     12
│     17
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.072161
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.079076
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.034098
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     15
│     17
│     22
│     24
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.010242
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     14
│     21
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.071893
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      5
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.035376
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     11
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.030838
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     15
│     22
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.035911
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      5
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.067789
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     12
│     17
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.034174
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      9
│     11
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.036765
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.062264
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      5
│     17
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.044995
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│     12
│     14
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.034899
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     11
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.066857
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.053339
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│      5
│     17
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.023735
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     12
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.061951
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     11
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.039259
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     15
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.033591
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      3
│      5
│     17
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.021873
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.051345
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     11
│     14
│     21
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.012217
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     15
│     17
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.048604
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.061630
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     12
│     14
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.027593
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     22
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.030730
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      9
│     11
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.028943
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      5
│     14
│     21
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.026952
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.063891
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     22
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.030161
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      9
│     11
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.036714
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     12
│     14
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.033810
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      5
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.036102
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     21
│     22
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.029364
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     11
│     15
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.042402
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│      5
│     12
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.041795
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.056837
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     22
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.051623
[ Info: iteration 46, average log likelihood -1.045388
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      4
│      5
│      9
│      ⋮
│     15
│     17
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -0.973419
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     22
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.089549
[ Info: iteration 49, average log likelihood -1.098073
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     21
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.028739
┌ Info: EM with 100000 data points 50 iterations avll -1.028739
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0343189   -0.0474055   -0.352558     0.0300561    0.106806    -0.0349392    -0.0311302   -0.022906    -0.12381      0.0709365    0.102118    -0.0411069   -0.0490404   -0.0909175    0.0740083   -0.0542413    0.0114385    -0.0745234   -0.198645   -0.0790669   -0.0999951     0.251351    -0.0124261   -0.0843139   -0.014136    -0.130446
 -0.0267605   -0.0102379    0.0977078   -0.0823587    0.0439947    0.0326278    -0.0787278    0.0903964   -0.0266248    0.0432827    0.00393482   0.130325    -0.0396491   -0.0268995    0.06955     -0.0736222    0.0503918    -0.0635136    0.0604467   0.0414826   -0.0665178    -0.033152     0.0857021    0.17606      0.166248     0.00666579
 -0.0675286   -0.00960324  -0.00770895   0.201703    -0.0781602   -0.0881822     0.186198     0.157215    -0.130775    -0.00489513  -0.0209885   -0.0490179    0.082643     0.185018    -0.0207175    0.122674    -0.0740261     0.0136594    0.0582553  -0.0866596   -0.120636      0.177424    -0.210728    -0.133286     0.0183565   -0.0419506
 -0.00556271   0.0526181   -0.0549235   -0.121584     0.00697737   0.0782879    -0.0252034    0.0156973    0.0163441   -0.0197743    0.0362527    0.0785604    0.0510729   -0.095441    -0.087349    -0.0563382    0.0637353    -0.0113442    0.243882   -0.0156364    0.043786      0.00153619   0.0130469   -0.0834365    0.013099     0.122468
 -0.147703     0.0162754   -0.0413294   -0.10594      0.0635994    0.11623       0.00128543  -0.110359    -0.0673303    0.0215895    0.00687963   0.0928791    0.0124314   -0.0819378    0.00241758   0.0580245   -0.0833607     0.148153    -0.14721    -0.065353     0.05916      -0.00505603   0.0553545    0.0524587   -0.0642723    0.191675
 -0.0554887    0.0359215    0.0422585    0.0369031   -0.0737988   -0.0181626     0.0670136   -0.0592678   -0.0340162   -0.00578425  -0.0402054   -0.016253     0.160262    -0.0239053    0.0531037   -0.0394313   -0.0232111     0.132625    -0.0865478  -0.0294562    0.0669417    -0.0589528    0.0458543   -0.0448254   -0.116823     0.068417
 -0.0700008   -0.173308    -0.0392699    0.173055    -0.0498451   -0.0951723     0.045161     0.102997    -0.117918     0.0089258    0.114151    -0.0958607    0.081057     0.0209141    0.179951    -0.156434    -0.0175888     0.047161     0.0477757   0.163843    -0.108693      0.110812     0.0587119    0.0882118   -0.107538    -0.162114
 -0.0357628   -0.0167407   -0.106584     0.207043     0.0971372   -0.00256151    0.195301    -0.156192     0.135309     0.0675153   -0.0426996    0.193164    -0.0497825   -0.0262303    0.0788394    0.0812795   -0.0589327    -0.174347    -0.0304641   0.138847    -0.000101971   0.0485614   -0.0670376   -0.0414228   -0.00145922   0.177701
 -0.296192    -0.0153024   -0.190562     0.0595445    0.0450172    0.0356388    -0.0546554   -0.147035     0.161994     0.0829789   -0.0310106    0.0334252    0.011107     0.00935748  -0.0076011   -0.150718    -0.116114      0.0759025   -0.045311    0.0315262    0.0221142     0.027109     0.0440276   -0.0294969    0.00820093  -0.0690911
 -0.101179    -0.0913962   -0.0498242    0.114709     0.0307376   -0.0107475     0.141235     0.038361    -0.00492702  -0.12284      0.0895279   -0.0609652   -0.062104    -0.0866264    0.0726838   -0.105379     0.0983581     0.0244403   -0.142345   -0.0138079   -0.0798444    -0.0352865   -0.00594708  -0.139483     0.0636918   -0.0146797
 -0.262872    -0.0485476   -0.0447891   -0.10239     -0.114174     0.229302     -0.0942913   -0.168725     0.0299628   -0.105498     0.00902894  -0.0878255    0.15115     -0.152451    -0.0471078   -0.109123     0.0752807     0.349288     0.0728523  -0.0399884    0.201583     -0.117739     0.0609042    0.0685827   -0.0754404    0.0390178
 -0.134324    -0.119563     0.109304    -0.0162976    0.0244665   -0.00874934   -0.15786      0.0182902   -0.0533447    0.125735    -0.148398    -0.14002      0.0971305   -0.0101969    0.129117    -0.195308    -0.130384      0.05975      0.0128451   0.173966    -0.104903     -0.109324    -0.0347793    0.0467268   -0.0194638    0.133918
  0.0035997   -0.130729     0.0444478   -0.00100727   0.0681798   -0.106527     -0.078614     0.0489364    0.0538281    0.113435     0.018222    -0.0176428    0.12664     -0.135416    -0.0412193   -0.0434908    0.0909487     0.284426    -0.0747321  -0.130809    -0.0191146     0.0124906   -0.234793     0.155266     0.0629678    0.0460757
 -0.207972     0.130393     0.0143658    0.0136626   -0.0734474   -0.0882168    -0.122619    -0.112796    -0.277913     0.0385899   -0.0712316    0.00136529   0.113775     0.0994061    0.08202     -0.132383     0.282137      0.0066615    0.0297769   0.126121    -0.175819     -0.0909808    0.0973466   -0.0655959    0.0273953   -0.0219753
  0.110688     0.0195738    0.0165365    0.105408    -0.0028955    0.0218303     0.0164976   -0.156155     0.0638917    0.0259359    0.131669     0.0680252   -0.0388209    0.131892    -0.0664247    0.0893628    0.173744     -0.198359    -0.017705   -0.00950373   0.0964489     0.239666     0.0675597    0.13847      0.0143519    0.0285613
 -0.0164452   -0.0147614   -0.0286713   -0.0464047    0.115132    -0.0890492    -0.010329     0.0324059   -0.0939727    0.00253243   0.0101315    0.0920781   -0.23734     -0.134125    -0.035234     0.0517428    0.0200702     0.0660328   -0.105014    0.136235    -0.0485072    -0.231867     0.0752441    0.00876166   0.0196973   -0.0114615
  0.0320546    0.0851844   -0.0764429    0.0779392   -0.0381435   -0.0867501    -0.157775     0.0340906   -0.0699882   -0.111445     0.0352678    0.029209     0.0463721    0.006127    -0.0746437    0.0405795    0.13659      -0.0788248    0.254021   -0.00599194   0.137278     -0.00564334  -0.0751673    0.0115057   -0.128424    -0.0932455
 -0.0147145   -0.0382928   -0.132916    -0.031249     0.0662892   -0.024029      0.0607677   -0.00549567   0.0738001   -0.0651003   -0.102246     0.00791352   0.114869     0.170343     0.0145319   -0.00982831   0.000934748  -0.104811     0.0641184  -0.0790964   -0.0810776    -0.0506765   -0.0597072   -0.103527     0.0159585   -0.0115846
 -0.0758407   -0.0597092    0.110197     0.0730922    0.0266365   -0.117567     -0.19223      0.173923    -0.0618116   -0.00107592  -0.0986853    0.019022     0.0228595   -0.220812    -0.0952597   -0.0651021   -0.0308407    -0.0394026   -0.10186    -0.112777     0.203208     -0.022625     0.0941389    0.12384     -0.0683079    0.0788661
  0.147401    -0.00241076  -0.155517    -0.0596015    0.0226852   -0.112493     -0.125599     0.174729    -0.158961     0.095797     0.115252     0.144505    -0.0568353   -0.030095    -0.101754     0.052965     0.0213098     0.0407616    0.118486   -0.271978    -0.0316933    -0.0900085    0.116833    -0.0467864   -0.0177019    0.140463
  0.147134    -0.149308    -0.19198      0.0253702    0.0456657    0.0685735    -0.173564     0.0379673   -0.0540643    0.125414     0.0769777   -0.233444    -0.0157513    0.14731      0.126671    -0.0866642    0.0793589     0.0539496    0.0141296  -0.0482352   -0.000976448   0.0936593   -0.0259006    0.170393     0.0100826    0.0550576
 -0.0578213   -0.196462     0.00697282   0.194728    -0.173955    -0.00928589    0.00467026   0.0271808    0.0247473   -0.178188     0.0558228    0.130562     0.164934    -0.0528368   -0.135605    -0.0206435   -0.118657     -0.0846236    0.0223244   0.0409874   -0.0608776     0.0136061   -0.0636381   -0.034194     0.0175836    0.0116594
 -0.0546482    0.0536421   -0.0685128   -0.18401     -0.0714458    0.000734984   0.00787389  -0.0230569    0.0341657    0.1079      -0.0731447    0.0777717   -0.0654286   -0.0442663    0.0422881   -0.0652545   -0.0626005    -0.126693    -0.158862    0.0841057    0.000135302  -0.0439422    0.0351239   -0.0818775   -0.035687     0.0164443
  0.0951683   -0.0554327   -0.140514     0.156296    -0.00100724  -0.16289       0.103878     0.0266095   -0.0114678    0.0039782    0.144031    -0.142801    -0.00878176   0.0735487   -0.00625417  -0.0708998   -0.109075      0.0760235    0.210951    0.186744    -0.0785512    -0.0129897    0.054419     0.00267592   0.0392049   -0.0257718
  0.204923     0.233695    -0.114138     0.168956    -0.105844    -0.0370641    -0.0281666    0.0859904    0.100069    -0.00530446  -0.177798    -0.0390036   -0.00968662  -0.145549     0.0842778    0.037697     0.00529284    0.0932686   -0.114539   -0.0194087    0.0311542    -0.0302696   -0.097172     0.00774238  -0.0685814   -0.210846
  0.0953975    0.170116    -0.198299     0.0551743   -0.0363258    0.0470114     0.0650471   -0.143565    -0.0532873   -0.0101654    0.005627     0.283578     0.100502    -0.0415835    0.0355148   -0.0533644    0.0544089     0.00973298  -0.0373098  -0.0442324    0.054765      0.135383    -0.00201789   0.0107844    0.0828052   -0.0179083
  0.0394231    0.0426661   -0.209644    -0.0867053    0.118063    -0.0313734     0.16747      0.11359     -0.0370791    0.018222    -0.0982909    0.167815     0.317425     0.181325     0.00894366  -0.152389    -0.0112824    -0.00309132  -0.0333275   0.0669057    0.0601612     0.188268    -0.0514911   -0.149773     0.130878     0.00811777
 -0.100747     0.00444119  -0.021721     0.219023     0.100091     0.13592       0.0387968    0.00551887   0.037981    -0.0815133   -0.177363     0.0323651    0.138774     0.00407677   0.104809    -0.010082     0.0338961    -0.0613646   -0.004037   -0.0369548   -0.112595      0.00553924  -0.0506185   -0.0773611   -0.145104     0.00183218
 -0.115702    -0.161897    -0.0230495   -0.219213     0.0499355    0.123246     -0.00849118   0.205711    -0.0144732    0.10409     -0.111119    -0.187818     0.0169517   -0.19011     -0.056705     0.117858     0.0843313    -0.0608601    0.026356   -0.0846124    0.0411227     0.0652044    0.187228    -0.148689    -0.0030473   -0.0404521
  0.0497007    0.00985695   0.0327818   -0.00748872  -0.0894555   -0.156229     -0.00863622   0.0199383    0.0156443   -0.0376271    0.0458327   -0.0923987    0.0357767   -0.0361886   -0.0385209    0.0973075    0.0739209     0.00739358  -0.037561   -0.0101277   -0.0523759    -0.108026     0.0695278   -0.0241758    0.0474396    0.0855535
 -0.00720057  -0.0351256    0.0330441    0.0111474   -0.21363     -0.071585     -0.0672325    0.0511476   -0.0244981    0.029403     0.017134     0.15364     -0.0977701   -0.084299    -0.0424384   -0.089373    -0.269961      0.104538    -0.136302   -0.051186     0.0287357     0.075417    -0.0702854    0.109196    -0.0370385   -0.13459
  0.0411859    0.0430224   -0.186789    -0.0604829    0.00294456  -0.0783398     0.0609377    0.123092    -0.0323666    0.00338409  -0.09985      0.109198     0.152209     0.170484    -0.0363427   -0.156346     0.00787492   -0.0189331   -0.0402403   0.0769007    0.0795581     0.0687775   -0.0640579   -0.0934666    0.0783887    0.0446083[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│     11
│     12
│      ⋮
│     24
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -0.986557
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      ⋮
│     24
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.956684
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│     11
│     12
│      ⋮
│     24
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.957594
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      ⋮
│     24
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.966141
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│     11
│     12
│      ⋮
│     24
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.960097
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.937044
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      5
│     12
│     14
│      ⋮
│     24
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -0.983275
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      ⋮
│     24
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.949477
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│     11
│     12
│      ⋮
│     24
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.962723
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.958927
┌ Info: EM with 100000 data points 10 iterations avll -0.958927
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.153823    -0.25441      0.0647544   -0.0364188    0.149965    0.228049     0.0184456    -0.164952      0.11952       0.0144356  -0.164767    -0.125441     0.000146344  -0.0293373     0.0859274    0.110314    -0.218406      0.165914     0.073446    -0.00619151  -0.0634885    0.0213637   -0.0301007  -0.0569267    0.104625    -0.182731
  0.0965074    0.00927359   0.0319893   -0.0154317    0.0356616   0.173891    -0.0146104    -0.166491      0.130298      0.163698    0.00432034   0.0820676    0.108063     -0.0916674    -0.039247    -0.134025     0.0288749    -0.0829137   -0.0293308    0.04569     -0.00668059  -0.0221887   -0.0851647  -0.106508    -0.165572     0.10317
 -0.0946425    0.0676113   -0.0849126    0.125434    -0.169668    0.00518869   0.0319754     0.0918298     0.00712614    0.139504   -0.173563     0.0852062   -0.0304887    -0.0662375     0.115161    -0.165021    -0.00443979   -0.0792444    0.180652     0.0233755    0.0657586   -0.0890766    0.0620856  -0.0243607    0.0104662   -0.0865437
 -0.0421037    0.0513668    0.182057     0.115138    -0.0592725   0.00504804   0.109839     -0.240848     -0.00461253    0.181124    0.00244798  -0.102627    -0.0546633    -0.0003231    -0.143374    -0.0802033    0.0422929    -0.0067453    0.261212    -0.0423274    0.0719746    0.0575362    0.0660656  -0.0728679    0.0746494   -0.062244
 -0.0492866    0.0922263    0.0414249   -0.0247147    0.172353   -0.123763    -0.149686     -0.200961     -0.104366     -0.0216682   0.0574085   -0.0164398   -0.000296532   0.178244      0.034221    -0.00410717   0.0739357    -0.0668559   -0.025064    -0.001718    -0.146803     0.0425729   -0.133915    0.0105868    0.0181573   -0.037571
 -0.290177    -0.00751045  -0.00173189   0.0662002    0.0586428  -0.205248    -0.00273452   -0.00450827    0.0568837    -0.168514    0.342744    -0.0938678   -0.0181904     0.0584535    -0.123589    -0.0502499   -0.0156795    -0.162113     0.0753624    0.0644737   -0.058033    -0.0825134   -0.146002   -0.10241      0.0466008    0.116214
  0.0283329    0.041671     0.152316    -0.027371    -0.0591186   0.0830659   -0.175702     -0.0605267     0.0559169     0.0220185   0.00524911  -0.0769643   -0.0822635    -0.0785971    -0.0753919   -0.0450025   -0.354148      0.0347202    0.0775488   -0.060364    -0.013055    -0.16326      0.0574158   0.0528948   -0.112562     0.134752
 -0.00840969  -0.0802124   -0.0829093   -0.172625     0.06017     0.0372185   -0.107916     -0.0105512     0.0376046    -0.0278317   0.050898     0.00859439  -0.136267     -0.156624      0.00968196   0.0863452   -0.127367      0.175815    -0.105933     0.0760107   -0.0269805    0.148168     0.0289741  -0.169919     0.00856863   0.0171074
  0.107045    -0.0329339   -0.156848    -0.0713158    0.233824    0.142091     0.1587        0.00918514    0.0524946     0.0518092  -0.0128184    0.0286383   -0.142698      0.26007      -0.088363    -0.0309241    0.101434     -0.0156566    0.00358523   0.122197     0.059477    -0.130483     0.0459147   0.0494241   -0.0117538    0.0751132
 -0.0586751    0.193053     0.056111    -0.147314     0.202057    0.100057     0.12512      -0.00965197   -0.0465749    -0.0700561   0.104227     0.00571456  -0.0594065    -0.00720626   -0.0180771    0.0935268    0.103817      0.0618952   -0.0448449   -0.131744    -0.183385    -0.0325707    0.0296871  -0.186111    -0.204845     0.0423694
 -0.091933     0.238064    -0.0985293    0.0747182    0.0202448  -0.0837299   -0.0699735     0.00718172   -0.0362215    -0.15312     0.101725     0.164488     0.0109799    -0.0243745    -0.166178    -0.0857681    0.067561      0.0360166    0.144088    -0.0355723   -0.170033    -0.141249     0.0272562   0.10241     -0.0479223    0.0585757
 -0.0577428   -0.0733968    0.156775     0.169343    -0.0749746  -0.208335     0.00650035    0.00189459   -0.092538      0.0157741   0.0548965    0.026162    -0.0456795    -0.0207663     0.0374703   -0.120328    -0.0440692     0.0987086   -0.0430635   -0.0132556    0.095677     0.112772    -0.134822   -0.111757    -0.122074     0.0213233
 -0.147247     0.1002      -0.153054    -0.12098      0.0745671  -0.0379335   -0.0224373    -0.105713     -0.0612804    -0.0896488  -0.233549     0.271012    -0.154966     -0.10865      -0.159022     2.52495e-6  -0.0351004    -0.0407818    0.0782272    0.0319281   -0.177537     0.112478     0.11852    -0.134329     0.163269    -0.108971
 -0.166969    -0.0328968   -0.0316106   -0.0482581    0.265112   -0.0562242    0.014247     -0.0114238    -0.0693389    -0.0797972   0.119486    -0.0582754   -0.1423        0.0534401    -0.0141143   -0.0109949   -0.0348198     0.121153     0.0900206   -0.0380481    0.0259872   -0.0136414   -0.0526305  -0.122488     0.0367096   -7.03108e-7
  0.0439345   -0.119044    -0.15727      0.021419     0.0123478   0.0535915   -0.114904     -0.000653103  -0.114701      0.198012    0.0339999    0.0468025   -0.0652394    -0.0508476     0.0378213   -0.109444    -0.115293      0.150376    -0.0617159   -0.00865446   0.0471815    0.0135031   -0.116493    0.00317253   0.0120286    0.0809165
 -0.0026125    0.0788732    0.0617723   -0.13747     -0.0962912   0.186826     0.0425701    -0.0681668    -0.0350351    -0.0618873  -0.0427267   -0.0783893    0.0318319     0.155569      0.155473     0.0474764    0.0982139     0.0850896   -0.14395     -0.0204457   -0.117684    -0.0259037   -0.0481353  -0.181409     0.160567    -0.0249963
 -0.0709548   -0.0482496   -0.163806    -0.149534     0.0439609  -0.126191    -0.109481      0.0664522     0.000704845   0.051291   -0.069494    -0.10767     -0.0102949     0.000113039  -0.00538214  -0.213447     0.100451     -0.00866759   0.0972991    0.0807165    0.121601     0.00900473  -0.199027   -0.0152527    0.0751375   -0.016369
  0.11384     -0.0517907    0.0192939    0.0238758    0.0956264  -0.0203293    0.235521     -0.0867562    -0.0386211    -0.0996972   0.185504     0.0433988   -0.0656933     0.0932817     0.166334     0.0480218    0.147788      0.0445386    0.0379634   -0.107755    -0.186856     0.00145156   0.187204    0.071028    -0.0632884    0.0968067
  0.0114358    0.0231523    0.0845742    0.044348     0.0799825   0.116303    -0.223666     -0.139925     -0.0262773     0.0121857   0.0186852   -0.01482      0.195401      0.0862771     0.0272338    0.0443589   -0.101851      0.00396841  -0.0283584   -0.050944    -0.0415248   -0.0175235   -0.104458    0.0809442    0.0179371   -0.166186
 -0.0153958   -0.0327829    0.0186208   -0.00761531   0.0253188   0.0583089   -0.034235     -0.0134168     0.0947681     0.0384458  -0.273641    -0.0719308    0.0204317     0.0961463     0.0619735    0.00553171   0.000187136   0.0213928    0.00443003   0.0217679    0.0686862   -0.0480858   -0.225552    0.0149514    0.174782    -0.083028
 -0.270134     0.0745032   -0.011794     0.119628    -0.0778507  -0.117432     0.114267      0.114281     -0.149055     -0.0860714   0.15072      0.00619809   0.0690687     0.0466292     0.199824    -0.159378    -0.140978      0.00463622  -0.130172    -0.00342484  -0.0633665   -0.0109262   -0.0568979   0.0775733    0.237881     0.0525395
 -0.0246708    0.0784514    0.026241     0.0146618   -0.114409    0.0915811    0.0287715    -0.0976951    -0.103291      0.0649313   0.128959    -0.0558937   -0.314358      0.0767756     0.0488789    0.00401615  -0.0279607    -0.131643     0.0702484   -0.00342105   0.140365     0.158009     0.0634087  -0.0105374    0.183175    -0.030262
 -0.130313     0.0678696   -0.0103601    0.0933883    0.0450808  -0.0494018    0.00369398    0.0389275    -0.10439       0.190467   -0.0596407    0.0683137    0.190262     -0.112623     -0.149385    -0.215976    -0.0212037    -0.177055     0.0778678    0.00638933   0.0620581    0.0844042   -0.0320655   0.0734263   -0.0742808    0.0938337
  0.0282337   -0.100178    -0.0707132    0.119892    -0.111801   -0.10645      0.0807174     0.175649     -0.100457     -0.0561696  -0.0114745   -0.0415495   -0.0353874    -0.00929158    0.154298    -0.0571049    0.0434214    -0.101886     0.10467     -0.00418774   0.00577166  -0.0695734   -0.138153    0.0131722   -0.0243063   -0.00591077
  0.0691859    0.0531931   -0.0381175   -0.170057     0.113328   -0.167771    -0.145071     -0.00940308    0.141604     -0.0630096  -0.127805    -0.0280235    0.137581      0.01294       0.0632669   -0.0724052    0.0689205     0.0206975   -0.0109678   -0.152187     0.00768789  -0.0155116   -0.127218   -0.0454575   -0.127384    -0.182238
 -0.0211436   -0.0293124    0.142068    -0.0634427   -0.10624     0.132474    -0.0291834     0.0589869    -0.0722033    -0.0230628  -0.0771512    0.00646013  -0.0919734    -0.0481246    -0.0990143   -0.0438386   -0.0420894    -0.120902    -0.167199     0.0572512    0.0488152    0.0987322    0.0257047  -0.164984    -0.133805    -0.18886
 -0.0344029    0.10797      0.0577232   -0.0363747    0.106218   -0.190854    -0.0173216    -0.15204      -0.124174     -0.0350362  -0.21795     -0.102974     0.0151546     0.0106798     0.0755238   -0.0325385   -0.0807178     0.153943     0.105239    -0.201399    -0.035516    -0.028184     0.057795   -0.15211     -0.0376431   -0.191129
 -0.103552     0.320911     0.0232854   -0.114392    -0.076802    0.0952849   -0.0619619    -0.0521459     0.154833      0.0251331  -0.0321518    0.027048     0.028723     -0.108629     -0.145159    -0.00530331   0.184932     -0.0989391    0.0674794   -0.0885077   -0.00284455   0.0406809    0.0654304  -0.0346444   -0.14604      0.0897455
  0.0910935    0.0127809    0.161801     0.106216    -0.0844477  -0.0567266    0.0870761     0.159181     -0.1433       -0.171396   -0.145579    -0.0588458   -0.0703234     0.171528      0.0722339    0.0691742   -0.0574479     0.0407767   -0.117432    -0.118716     0.137687     0.2013      -0.0225394   0.195176     0.087979    -0.076276
 -0.00944044  -0.131729    -0.0474955   -0.0710543   -0.0813303  -0.0166181    0.000124412  -0.219888      0.0157123    -0.0173177   0.0187369   -0.0609671    0.0019262    -0.0123403     0.275337     0.0812318   -0.130492     -0.155772     0.060618     0.0487709    0.268484     0.023362     0.11055     0.117093    -0.110564     0.133036
  0.0382837   -0.0351723   -0.0348778   -0.00462808   0.0870137   0.150315     0.118733      0.113066      0.0386344    -0.10744    -0.230724    -0.0526337   -0.089124     -0.080587      0.106775    -0.086544     0.0224892    -0.0141803    0.0731201    0.150495    -0.105581    -0.154925    -0.103313   -0.0526322   -0.183345    -0.048978
  0.0695968   -0.0296182    0.0943693    0.0184884    0.038694   -0.0413189   -0.0534008    -0.00708289    0.0152682    -0.0203755  -0.0612553    0.0394063    0.150916     -0.103384      0.0168145    0.127148    -0.0975052    -0.110886    -0.0865277    0.0312718   -0.0478199   -0.178541     0.0510685   0.00757021  -0.0307876    0.0309383kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4286188648839544
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.428638
[ Info: iteration 2, average log likelihood -1.428551
[ Info: iteration 3, average log likelihood -1.428475
[ Info: iteration 4, average log likelihood -1.428381
[ Info: iteration 5, average log likelihood -1.428265
[ Info: iteration 6, average log likelihood -1.428130
[ Info: iteration 7, average log likelihood -1.427993
[ Info: iteration 8, average log likelihood -1.427870
[ Info: iteration 9, average log likelihood -1.427767
[ Info: iteration 10, average log likelihood -1.427674
[ Info: iteration 11, average log likelihood -1.427567
[ Info: iteration 12, average log likelihood -1.427404
[ Info: iteration 13, average log likelihood -1.427126
[ Info: iteration 14, average log likelihood -1.426660
[ Info: iteration 15, average log likelihood -1.425957
[ Info: iteration 16, average log likelihood -1.425086
[ Info: iteration 17, average log likelihood -1.424275
[ Info: iteration 18, average log likelihood -1.423720
[ Info: iteration 19, average log likelihood -1.423420
[ Info: iteration 20, average log likelihood -1.423277
[ Info: iteration 21, average log likelihood -1.423212
[ Info: iteration 22, average log likelihood -1.423184
[ Info: iteration 23, average log likelihood -1.423171
[ Info: iteration 24, average log likelihood -1.423165
[ Info: iteration 25, average log likelihood -1.423162
[ Info: iteration 26, average log likelihood -1.423160
[ Info: iteration 27, average log likelihood -1.423159
[ Info: iteration 28, average log likelihood -1.423159
[ Info: iteration 29, average log likelihood -1.423159
[ Info: iteration 30, average log likelihood -1.423158
[ Info: iteration 31, average log likelihood -1.423158
[ Info: iteration 32, average log likelihood -1.423158
[ Info: iteration 33, average log likelihood -1.423158
[ Info: iteration 34, average log likelihood -1.423157
[ Info: iteration 35, average log likelihood -1.423157
[ Info: iteration 36, average log likelihood -1.423157
[ Info: iteration 37, average log likelihood -1.423157
[ Info: iteration 38, average log likelihood -1.423157
[ Info: iteration 39, average log likelihood -1.423157
[ Info: iteration 40, average log likelihood -1.423157
[ Info: iteration 41, average log likelihood -1.423157
[ Info: iteration 42, average log likelihood -1.423157
[ Info: iteration 43, average log likelihood -1.423157
[ Info: iteration 44, average log likelihood -1.423157
[ Info: iteration 45, average log likelihood -1.423156
[ Info: iteration 46, average log likelihood -1.423156
[ Info: iteration 47, average log likelihood -1.423156
[ Info: iteration 48, average log likelihood -1.423156
[ Info: iteration 49, average log likelihood -1.423156
[ Info: iteration 50, average log likelihood -1.423156
┌ Info: EM with 100000 data points 50 iterations avll -1.423156
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4286376779006615
│     -1.428551325638598
│      ⋮
└     -1.4231562983236365
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423171
[ Info: iteration 2, average log likelihood -1.423087
[ Info: iteration 3, average log likelihood -1.423006
[ Info: iteration 4, average log likelihood -1.422903
[ Info: iteration 5, average log likelihood -1.422772
[ Info: iteration 6, average log likelihood -1.422621
[ Info: iteration 7, average log likelihood -1.422469
[ Info: iteration 8, average log likelihood -1.422336
[ Info: iteration 9, average log likelihood -1.422232
[ Info: iteration 10, average log likelihood -1.422156
[ Info: iteration 11, average log likelihood -1.422103
[ Info: iteration 12, average log likelihood -1.422065
[ Info: iteration 13, average log likelihood -1.422037
[ Info: iteration 14, average log likelihood -1.422018
[ Info: iteration 15, average log likelihood -1.422003
[ Info: iteration 16, average log likelihood -1.421991
[ Info: iteration 17, average log likelihood -1.421982
[ Info: iteration 18, average log likelihood -1.421974
[ Info: iteration 19, average log likelihood -1.421966
[ Info: iteration 20, average log likelihood -1.421959
[ Info: iteration 21, average log likelihood -1.421952
[ Info: iteration 22, average log likelihood -1.421945
[ Info: iteration 23, average log likelihood -1.421937
[ Info: iteration 24, average log likelihood -1.421930
[ Info: iteration 25, average log likelihood -1.421922
[ Info: iteration 26, average log likelihood -1.421914
[ Info: iteration 27, average log likelihood -1.421906
[ Info: iteration 28, average log likelihood -1.421897
[ Info: iteration 29, average log likelihood -1.421889
[ Info: iteration 30, average log likelihood -1.421880
[ Info: iteration 31, average log likelihood -1.421871
[ Info: iteration 32, average log likelihood -1.421862
[ Info: iteration 33, average log likelihood -1.421853
[ Info: iteration 34, average log likelihood -1.421844
[ Info: iteration 35, average log likelihood -1.421835
[ Info: iteration 36, average log likelihood -1.421826
[ Info: iteration 37, average log likelihood -1.421818
[ Info: iteration 38, average log likelihood -1.421809
[ Info: iteration 39, average log likelihood -1.421802
[ Info: iteration 40, average log likelihood -1.421794
[ Info: iteration 41, average log likelihood -1.421787
[ Info: iteration 42, average log likelihood -1.421781
[ Info: iteration 43, average log likelihood -1.421775
[ Info: iteration 44, average log likelihood -1.421769
[ Info: iteration 45, average log likelihood -1.421764
[ Info: iteration 46, average log likelihood -1.421759
[ Info: iteration 47, average log likelihood -1.421754
[ Info: iteration 48, average log likelihood -1.421750
[ Info: iteration 49, average log likelihood -1.421746
[ Info: iteration 50, average log likelihood -1.421743
┌ Info: EM with 100000 data points 50 iterations avll -1.421743
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4231712671735732
│     -1.4230867767055957
│      ⋮
└     -1.4217430971001135
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421750
[ Info: iteration 2, average log likelihood -1.421686
[ Info: iteration 3, average log likelihood -1.421625
[ Info: iteration 4, average log likelihood -1.421552
[ Info: iteration 5, average log likelihood -1.421462
[ Info: iteration 6, average log likelihood -1.421355
[ Info: iteration 7, average log likelihood -1.421239
[ Info: iteration 8, average log likelihood -1.421123
[ Info: iteration 9, average log likelihood -1.421014
[ Info: iteration 10, average log likelihood -1.420919
[ Info: iteration 11, average log likelihood -1.420837
[ Info: iteration 12, average log likelihood -1.420768
[ Info: iteration 13, average log likelihood -1.420712
[ Info: iteration 14, average log likelihood -1.420665
[ Info: iteration 15, average log likelihood -1.420628
[ Info: iteration 16, average log likelihood -1.420598
[ Info: iteration 17, average log likelihood -1.420573
[ Info: iteration 18, average log likelihood -1.420553
[ Info: iteration 19, average log likelihood -1.420537
[ Info: iteration 20, average log likelihood -1.420522
[ Info: iteration 21, average log likelihood -1.420510
[ Info: iteration 22, average log likelihood -1.420500
[ Info: iteration 23, average log likelihood -1.420490
[ Info: iteration 24, average log likelihood -1.420482
[ Info: iteration 25, average log likelihood -1.420474
[ Info: iteration 26, average log likelihood -1.420467
[ Info: iteration 27, average log likelihood -1.420460
[ Info: iteration 28, average log likelihood -1.420453
[ Info: iteration 29, average log likelihood -1.420447
[ Info: iteration 30, average log likelihood -1.420441
[ Info: iteration 31, average log likelihood -1.420435
[ Info: iteration 32, average log likelihood -1.420429
[ Info: iteration 33, average log likelihood -1.420424
[ Info: iteration 34, average log likelihood -1.420418
[ Info: iteration 35, average log likelihood -1.420413
[ Info: iteration 36, average log likelihood -1.420408
[ Info: iteration 37, average log likelihood -1.420403
[ Info: iteration 38, average log likelihood -1.420398
[ Info: iteration 39, average log likelihood -1.420393
[ Info: iteration 40, average log likelihood -1.420388
[ Info: iteration 41, average log likelihood -1.420383
[ Info: iteration 42, average log likelihood -1.420378
[ Info: iteration 43, average log likelihood -1.420373
[ Info: iteration 44, average log likelihood -1.420368
[ Info: iteration 45, average log likelihood -1.420363
[ Info: iteration 46, average log likelihood -1.420358
[ Info: iteration 47, average log likelihood -1.420353
[ Info: iteration 48, average log likelihood -1.420348
[ Info: iteration 49, average log likelihood -1.420343
[ Info: iteration 50, average log likelihood -1.420338
┌ Info: EM with 100000 data points 50 iterations avll -1.420338
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4217501615543917
│     -1.4216862674724784
│      ⋮
└     -1.420337988715521
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420342
[ Info: iteration 2, average log likelihood -1.420281
[ Info: iteration 3, average log likelihood -1.420223
[ Info: iteration 4, average log likelihood -1.420154
[ Info: iteration 5, average log likelihood -1.420068
[ Info: iteration 6, average log likelihood -1.419962
[ Info: iteration 7, average log likelihood -1.419838
[ Info: iteration 8, average log likelihood -1.419702
[ Info: iteration 9, average log likelihood -1.419563
[ Info: iteration 10, average log likelihood -1.419426
[ Info: iteration 11, average log likelihood -1.419296
[ Info: iteration 12, average log likelihood -1.419175
[ Info: iteration 13, average log likelihood -1.419067
[ Info: iteration 14, average log likelihood -1.418973
[ Info: iteration 15, average log likelihood -1.418894
[ Info: iteration 16, average log likelihood -1.418827
[ Info: iteration 17, average log likelihood -1.418773
[ Info: iteration 18, average log likelihood -1.418727
[ Info: iteration 19, average log likelihood -1.418689
[ Info: iteration 20, average log likelihood -1.418657
[ Info: iteration 21, average log likelihood -1.418630
[ Info: iteration 22, average log likelihood -1.418606
[ Info: iteration 23, average log likelihood -1.418584
[ Info: iteration 24, average log likelihood -1.418565
[ Info: iteration 25, average log likelihood -1.418547
[ Info: iteration 26, average log likelihood -1.418531
[ Info: iteration 27, average log likelihood -1.418516
[ Info: iteration 28, average log likelihood -1.418501
[ Info: iteration 29, average log likelihood -1.418488
[ Info: iteration 30, average log likelihood -1.418475
[ Info: iteration 31, average log likelihood -1.418463
[ Info: iteration 32, average log likelihood -1.418451
[ Info: iteration 33, average log likelihood -1.418439
[ Info: iteration 34, average log likelihood -1.418428
[ Info: iteration 35, average log likelihood -1.418417
[ Info: iteration 36, average log likelihood -1.418406
[ Info: iteration 37, average log likelihood -1.418396
[ Info: iteration 38, average log likelihood -1.418385
[ Info: iteration 39, average log likelihood -1.418375
[ Info: iteration 40, average log likelihood -1.418365
[ Info: iteration 41, average log likelihood -1.418355
[ Info: iteration 42, average log likelihood -1.418345
[ Info: iteration 43, average log likelihood -1.418336
[ Info: iteration 44, average log likelihood -1.418326
[ Info: iteration 45, average log likelihood -1.418317
[ Info: iteration 46, average log likelihood -1.418308
[ Info: iteration 47, average log likelihood -1.418299
[ Info: iteration 48, average log likelihood -1.418290
[ Info: iteration 49, average log likelihood -1.418281
[ Info: iteration 50, average log likelihood -1.418272
┌ Info: EM with 100000 data points 50 iterations avll -1.418272
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.420342112947594
│     -1.4202811988867328
│      ⋮
└     -1.418272420640441
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418273
[ Info: iteration 2, average log likelihood -1.418209
[ Info: iteration 3, average log likelihood -1.418147
[ Info: iteration 4, average log likelihood -1.418074
[ Info: iteration 5, average log likelihood -1.417984
[ Info: iteration 6, average log likelihood -1.417871
[ Info: iteration 7, average log likelihood -1.417734
[ Info: iteration 8, average log likelihood -1.417576
[ Info: iteration 9, average log likelihood -1.417406
[ Info: iteration 10, average log likelihood -1.417232
[ Info: iteration 11, average log likelihood -1.417065
[ Info: iteration 12, average log likelihood -1.416909
[ Info: iteration 13, average log likelihood -1.416768
[ Info: iteration 14, average log likelihood -1.416643
[ Info: iteration 15, average log likelihood -1.416533
[ Info: iteration 16, average log likelihood -1.416437
[ Info: iteration 17, average log likelihood -1.416353
[ Info: iteration 18, average log likelihood -1.416281
[ Info: iteration 19, average log likelihood -1.416218
[ Info: iteration 20, average log likelihood -1.416163
[ Info: iteration 21, average log likelihood -1.416115
[ Info: iteration 22, average log likelihood -1.416072
[ Info: iteration 23, average log likelihood -1.416035
[ Info: iteration 24, average log likelihood -1.416001
[ Info: iteration 25, average log likelihood -1.415970
[ Info: iteration 26, average log likelihood -1.415942
[ Info: iteration 27, average log likelihood -1.415916
[ Info: iteration 28, average log likelihood -1.415892
[ Info: iteration 29, average log likelihood -1.415869
[ Info: iteration 30, average log likelihood -1.415848
[ Info: iteration 31, average log likelihood -1.415827
[ Info: iteration 32, average log likelihood -1.415808
[ Info: iteration 33, average log likelihood -1.415789
[ Info: iteration 34, average log likelihood -1.415771
[ Info: iteration 35, average log likelihood -1.415754
[ Info: iteration 36, average log likelihood -1.415737
[ Info: iteration 37, average log likelihood -1.415721
[ Info: iteration 38, average log likelihood -1.415706
[ Info: iteration 39, average log likelihood -1.415691
[ Info: iteration 40, average log likelihood -1.415676
[ Info: iteration 41, average log likelihood -1.415662
[ Info: iteration 42, average log likelihood -1.415648
[ Info: iteration 43, average log likelihood -1.415635
[ Info: iteration 44, average log likelihood -1.415622
[ Info: iteration 45, average log likelihood -1.415610
[ Info: iteration 46, average log likelihood -1.415598
[ Info: iteration 47, average log likelihood -1.415586
[ Info: iteration 48, average log likelihood -1.415575
[ Info: iteration 49, average log likelihood -1.415564
[ Info: iteration 50, average log likelihood -1.415553
┌ Info: EM with 100000 data points 50 iterations avll -1.415553
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4182726148664693
│     -1.4182086526587288
│      ⋮
└     -1.415553177801847
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4286188648839544
│     -1.4286376779006615
│     -1.428551325638598
│     -1.4284754485165474
│      ⋮
│     -1.4155747500550557
│     -1.41556378743434
└     -1.415553177801847
32×26 Array{Float64,2}:
 -0.679684   -0.243213    -0.366686    -0.238694   -0.426327   -0.594621   -0.401259    -0.247886     0.0877634     0.0616647    0.306621    -0.332034     0.0268577  -0.371084   -0.176899   -0.296982    -0.199257    -0.394638      0.265311   -0.114074   -0.126248    -0.836784   -0.333813   -0.254304     0.172393     0.409858
  0.195747    0.0576236   -0.381709     1.06214    -0.0958395  -0.698015   -0.0653496   -0.173362     0.115224      0.484414    -0.0160001    0.181071     0.29191     0.337223   -0.278893   -0.018975    -0.00696467   0.264892     -0.180091   -0.829169    0.256164    -0.189645   -0.333468    0.141931     0.164327     0.176085
  0.372457   -0.28344      0.274799    -0.11931    -0.623437    0.752758   -0.142837    -0.720649     0.0099121     0.136135    -0.050944    -0.678328    -0.420257    0.112532   -0.0273861  -0.489832    -0.170525    -0.494409     -0.362998   -0.586974   -0.00234986  -0.255771   -0.123146    0.092687    -0.0522979    0.103722
  0.259025    0.232446    -0.00954589  -0.123961   -0.750195    0.109735    0.0693214   -0.399812    -0.0770132     0.195445     0.482937    -0.471395     0.603399    0.31173     0.11289    -0.37274     -0.0110558   -0.273302      0.5982     -0.0680381   0.855686    -0.0938101   0.264653   -0.111356    -0.108329     0.222404
  0.39175    -0.189829    -0.765216     0.144417   -0.0413029  -0.343005    0.0675862   -0.142914    -0.384507      0.250724    -0.665442     0.370214    -0.0605125  -0.203324    0.0981478   0.0287623   -0.324785    -0.403508     -0.389154    0.283587    0.625927     0.267453    0.472646   -0.0137949    0.231879    -0.0375033
  0.501841   -0.105915     0.0295332   -0.224916    0.285066    0.0514496   0.0998027    0.23463     -0.409627      0.303613     0.125612     0.207553     0.264898   -0.454552    0.156686    0.118687    -0.46306     -0.465284      0.770891    0.752222    0.466063     0.327768   -0.060115    0.31933      0.241549     0.0763906
  0.203562    0.632857    -0.321731    -0.23235     0.347015    0.185683    0.138665    -0.307973     0.632938      0.0180682   -0.404546    -0.0479935   -0.378497    0.577081    0.91459     0.124337     0.591101    -0.560048      0.0118408   0.103516    0.61214      0.10977    -0.112045   -0.391873     0.264815     0.313381
  0.3983      0.223067    -0.0914394   -1.00398     0.671982    0.218798    0.472225    -0.347474     0.517368     -0.209811     0.505191    -0.262913     0.703791   -0.202859    0.0539134   0.276511     0.614834     0.426646      0.15268     0.459143   -0.392469     0.0675498   0.133218   -0.0854198    0.440342     0.283206
 -0.53609     0.204058    -0.536647     0.468355    0.393332   -0.204782   -0.195649     0.363649     0.0167649    -0.00934332  -1.0412       0.493555    -0.809322   -0.100142   -0.1141      0.0363902   -0.37718     -0.000224417  -0.587513    0.0872091  -0.312959     0.0464385  -0.139594   -0.148863     0.225742    -0.115387
 -0.378965    0.0254504    0.142601     0.250427   -0.108873    0.0171551  -0.00115638  -0.0857622   -0.000440747  -0.307654    -0.262876     0.535746    -0.108381   -0.525237   -0.466023    0.0164389   -0.492536     0.0125489     0.332098   -0.0196409  -0.14168      0.220691    0.0787832  -0.00448549  -0.282593    -0.226724
 -0.785361    0.0838634    0.0646949   -0.503758   -0.927214    0.364398   -0.336986    -0.10184      0.0370774    -0.377479     0.1025      -0.0477915   -0.824306    0.206779   -0.0142768  -0.280736     0.55064      0.325874     -0.573902   -0.146173   -0.247589     0.326191    0.231076   -0.386637    -0.169461    -0.161047
 -0.373359    0.32114     -0.410417     0.503104    0.505111   -0.105205    0.195224    -0.274056     0.0943116    -0.160645     0.481138     0.234348    -0.248415   -0.0641963   1.03909    -0.618816     0.0246396    0.393231     -0.226134    0.274272   -0.0727992   -0.615788    0.424167   -0.40574      0.428257    -0.0168972
 -0.410705   -0.283656     0.588407    -1.13651     0.251802    0.163461   -0.111025    -0.086839    -0.145756     -0.0492769   -0.172579     0.0491975   -0.100079   -0.0175367  -0.161067    0.561878    -0.46085     -0.116052      0.746853    0.228912   -0.509939     0.550355   -0.258288   -0.0776134   -0.319338    -0.533386
  0.0346821  -0.327011     0.813108    -0.334133    0.297464    0.656788   -0.0706895    0.398785    -0.354588     -0.714765    -0.196243    -0.48903     -0.579313   -0.226944    0.277648    0.100732    -0.341       -0.40609       0.105777   -0.073468   -0.121455     0.0672415   0.493378    0.355501    -0.505812    -0.317247
 -0.272458   -0.374556     0.302095    -0.20924     0.35549    -0.569823   -0.0802871    0.574785    -0.0588354     0.133126     0.421565    -0.28258     -0.118795    0.165595   -0.084847    0.168897     0.614104     0.170964      0.0432287  -0.127773   -0.353344    -0.201484   -0.43513     0.227382    -0.384481     0.212948
  0.259329   -0.2819       0.49149      0.0320897  -0.121065    0.542678   -0.372635     0.351016    -0.185169     -0.412248     0.297456    -0.290653     0.805477   -0.0361758  -0.408218   -0.0903259    0.145411     0.450222      0.405275    0.0392899  -0.503604     0.0203817  -0.942237    0.298606    -0.350955    -0.106872
  0.011929   -0.0476337   -0.154653     0.0335514  -0.27436     0.187837    0.0346935   -0.402491     0.162064      0.0752293   -0.178573    -0.214896    -0.30817     0.143177    0.315306   -0.490027     0.027199    -0.080574     -0.332771   -0.432542    0.14359     -0.281592    0.154496   -0.239924     0.354691     0.0422201
  0.0107482  -0.116841     0.0854368   -0.655976   -0.182375   -0.139297    0.590024    -0.737653     0.179206      0.554681    -0.269043    -0.290031    -0.161444    0.572854   -0.0688967   0.43601     -0.384411     0.182008     -0.0187507  -0.590448   -0.146283    -0.162361    0.549258   -0.290804     0.361112    -0.0657371
  0.53568     0.153516    -0.268744    -0.205837    0.883046    0.227568    0.314469    -0.187729     0.445787     -0.128452    -0.00903865  -0.337151    -0.147461    0.212927    0.175079    0.396007     0.500102     0.134223     -0.453984   -0.0402819  -0.189189    -0.117037    0.0721729  -0.0609988   -0.0393003   -0.061417
  0.20507    -0.592029     0.0263187   -0.196028    0.654417    0.120073    0.131833    -0.0307559    0.619925      0.0373519   -0.694181     0.414228    -0.483274   -0.210821   -0.0679515   0.231679     0.0304767    0.16798      -0.0328996  -0.123249   -0.275795    -0.240375   -0.492215   -0.260454     0.00982148  -0.000205977
 -0.729662    0.742585    -0.587574     0.7315     -0.29359     0.204317   -0.418278    -0.119533     0.110688     -0.603111    -0.0705234    0.00552502  -0.296035   -0.133086    0.0649749  -0.285104    -0.0190759    0.0520087     0.0677004  -0.105273   -0.0232821    0.061713   -0.154273    0.396833     0.161406    -0.123186
 -1.00393     0.237041     0.763453     0.102706   -0.132833   -0.344964   -0.553886    -0.13252      0.374563     -0.527834    -0.146332     0.0175635    0.167704    0.389452    0.289631   -0.176125    -0.106149     0.158506      0.0470457  -0.0107214   0.205171    -0.135396   -0.0320743  -0.0798266   -0.044476    -0.534848
 -0.474499    0.00123358   0.240286     0.378317   -0.333685   -0.0552717   0.192898    -0.161394     0.0847339    -0.194022     0.0263505    0.70138     -0.247291   -0.352457   -0.419692   -0.20743     -0.666983    -0.151729      0.0935375  -0.249379   -0.214691     0.229238    0.459055   -0.280391    -0.111331     0.0066447
 -0.569479    0.307791    -0.193953     0.1635      0.192201   -0.50078     0.141149     0.453113     0.02532      -0.409112     0.359952     0.709448     0.0994762  -0.23441    -0.236396   -0.0144586    0.469764     0.0227224     0.0996942   0.297084   -0.305568     0.242425    0.104588   -0.184631     0.00498845   0.162993
 -0.0377621  -0.318148    -0.0426336    0.117251    0.0487732   0.157002   -0.287918     0.438319    -0.270441      0.0663605    0.0852503   -0.0325139   -0.237406   -0.5811     -0.167967   -0.0166922    0.0411206    0.156995     -0.254729   -0.0324206  -0.565909     0.033599   -0.340508    0.158935    -0.344438     0.137177
 -0.200189    0.118056     0.0236938    0.0610598   0.168852   -0.12646    -0.100066    -0.00183305   0.00463873   -0.0707339   -0.203205     0.0196723   -0.146017    0.131268   -0.150473   -0.00416307  -0.0129691    0.0468337    -0.150654   -0.111848   -0.226068    -0.0219373  -0.132442   -0.0891655   -0.0834589   -0.220142
  0.122476    0.0984412    0.0418464   -0.184661   -0.1567     -0.0259091   0.0612979    0.0297783    0.158775      0.0801868    0.124033    -0.106545     0.209062    0.078926   -0.498692    0.349659    -0.0962555   -0.184739      0.484608    0.0201184   0.430211     0.0068963   0.0861005  -0.0356239   -0.182155     0.200903
  0.143572   -0.0234589    0.215572    -0.0558895   0.0748482   0.255685    0.0537189   -0.0315187   -0.132934     -0.0310438    0.24044      0.0366211    0.283817   -0.0395668   0.454167   -0.12495     -0.0831031    0.00343195    0.216533    0.327133    0.149265     0.0587063   0.0173262   0.077419     0.0378275   -0.00204606
  0.138323    0.21994      0.0297637    0.209127   -0.146416    0.139856   -0.116637     0.471365    -0.539641      0.307923    -0.480221    -0.221858     0.227765    0.10365     0.44499    -0.312129     0.278907     0.472016     -0.536963    0.269472    0.209789     0.0792362  -0.512744    0.36872      0.163021    -0.78274
  0.618461    0.546132     0.259225     0.351741    0.405424    0.60734     0.156195     0.13371     -0.503179     -0.135076    -0.163759     0.353496     0.180431    0.240633   -0.117117   -0.0204697   -0.216305     0.524799     -0.391705    0.246564   -0.0856735    0.544253    0.493313    0.0888353   -0.231542    -0.446401
  0.642533    0.195606    -0.499686    -0.259785    0.0317895  -0.0280595  -0.0598818   -0.199124    -0.80817       0.837629     0.307599    -0.489125     0.19947     0.304869    0.0158851  -0.038059     0.371705    -0.262699      0.10465    -0.10258    -0.0186186   -0.202135   -0.0869981  -0.0901199    0.0640859    0.550825
  0.353327   -0.804448     0.827009    -0.323068    0.198593   -0.759313    0.520233     0.191858    -0.265924      0.590479     0.501731    -0.539253     0.329624    0.789315   -0.192517    0.177842    -0.11233     -0.25399       0.163731    0.0490501   0.165192     0.227008   -0.0443427  -0.114792    -0.0625692    0.279649[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415543
[ Info: iteration 2, average log likelihood -1.415533
[ Info: iteration 3, average log likelihood -1.415523
[ Info: iteration 4, average log likelihood -1.415514
[ Info: iteration 5, average log likelihood -1.415505
[ Info: iteration 6, average log likelihood -1.415496
[ Info: iteration 7, average log likelihood -1.415488
[ Info: iteration 8, average log likelihood -1.415480
[ Info: iteration 9, average log likelihood -1.415471
[ Info: iteration 10, average log likelihood -1.415464
┌ Info: EM with 100000 data points 10 iterations avll -1.415464
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.262169e+05
      1       7.127015e+05      -2.135154e+05 |       32
      2       6.987691e+05      -1.393238e+04 |       32
      3       6.934039e+05      -5.365240e+03 |       32
      4       6.905672e+05      -2.836666e+03 |       32
      5       6.888798e+05      -1.687382e+03 |       32
      6       6.877220e+05      -1.157852e+03 |       32
      7       6.867978e+05      -9.242037e+02 |       32
      8       6.860817e+05      -7.160550e+02 |       32
      9       6.855078e+05      -5.739462e+02 |       32
     10       6.850579e+05      -4.499214e+02 |       32
     11       6.846651e+05      -3.927663e+02 |       32
     12       6.842948e+05      -3.702938e+02 |       32
     13       6.839396e+05      -3.552498e+02 |       32
     14       6.836062e+05      -3.333429e+02 |       32
     15       6.832807e+05      -3.254633e+02 |       32
     16       6.829830e+05      -2.977625e+02 |       32
     17       6.827027e+05      -2.803087e+02 |       32
     18       6.824542e+05      -2.485245e+02 |       32
     19       6.822507e+05      -2.034178e+02 |       32
     20       6.820695e+05      -1.812460e+02 |       32
     21       6.818912e+05      -1.782693e+02 |       32
     22       6.817324e+05      -1.588427e+02 |       32
     23       6.815831e+05      -1.492262e+02 |       32
     24       6.814549e+05      -1.282420e+02 |       32
     25       6.813319e+05      -1.229634e+02 |       32
     26       6.812173e+05      -1.146590e+02 |       32
     27       6.811157e+05      -1.015576e+02 |       32
     28       6.810051e+05      -1.106034e+02 |       32
     29       6.808899e+05      -1.151745e+02 |       32
     30       6.807832e+05      -1.067292e+02 |       32
     31       6.806697e+05      -1.134747e+02 |       32
     32       6.805620e+05      -1.077754e+02 |       32
     33       6.804591e+05      -1.028586e+02 |       32
     34       6.803490e+05      -1.100973e+02 |       32
     35       6.802496e+05      -9.946096e+01 |       32
     36       6.801755e+05      -7.408409e+01 |       32
     37       6.801130e+05      -6.251763e+01 |       32
     38       6.800577e+05      -5.526765e+01 |       32
     39       6.800050e+05      -5.271055e+01 |       32
     40       6.799487e+05      -5.630894e+01 |       32
     41       6.798873e+05      -6.140268e+01 |       32
     42       6.798268e+05      -6.045688e+01 |       32
     43       6.797793e+05      -4.747753e+01 |       32
     44       6.797345e+05      -4.486915e+01 |       32
     45       6.796909e+05      -4.358546e+01 |       32
     46       6.796433e+05      -4.761655e+01 |       32
     47       6.796016e+05      -4.164550e+01 |       32
     48       6.795605e+05      -4.114230e+01 |       32
     49       6.795195e+05      -4.101375e+01 |       32
     50       6.794837e+05      -3.578955e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 679483.6644470012)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.427136
[ Info: iteration 2, average log likelihood -1.422212
[ Info: iteration 3, average log likelihood -1.420947
[ Info: iteration 4, average log likelihood -1.420037
[ Info: iteration 5, average log likelihood -1.419037
[ Info: iteration 6, average log likelihood -1.418011
[ Info: iteration 7, average log likelihood -1.417221
[ Info: iteration 8, average log likelihood -1.416747
[ Info: iteration 9, average log likelihood -1.416482
[ Info: iteration 10, average log likelihood -1.416321
[ Info: iteration 11, average log likelihood -1.416207
[ Info: iteration 12, average log likelihood -1.416119
[ Info: iteration 13, average log likelihood -1.416047
[ Info: iteration 14, average log likelihood -1.415986
[ Info: iteration 15, average log likelihood -1.415932
[ Info: iteration 16, average log likelihood -1.415885
[ Info: iteration 17, average log likelihood -1.415843
[ Info: iteration 18, average log likelihood -1.415805
[ Info: iteration 19, average log likelihood -1.415770
[ Info: iteration 20, average log likelihood -1.415738
[ Info: iteration 21, average log likelihood -1.415709
[ Info: iteration 22, average log likelihood -1.415682
[ Info: iteration 23, average log likelihood -1.415656
[ Info: iteration 24, average log likelihood -1.415632
[ Info: iteration 25, average log likelihood -1.415609
[ Info: iteration 26, average log likelihood -1.415588
[ Info: iteration 27, average log likelihood -1.415567
[ Info: iteration 28, average log likelihood -1.415548
[ Info: iteration 29, average log likelihood -1.415529
[ Info: iteration 30, average log likelihood -1.415511
[ Info: iteration 31, average log likelihood -1.415494
[ Info: iteration 32, average log likelihood -1.415477
[ Info: iteration 33, average log likelihood -1.415461
[ Info: iteration 34, average log likelihood -1.415445
[ Info: iteration 35, average log likelihood -1.415430
[ Info: iteration 36, average log likelihood -1.415415
[ Info: iteration 37, average log likelihood -1.415400
[ Info: iteration 38, average log likelihood -1.415386
[ Info: iteration 39, average log likelihood -1.415372
[ Info: iteration 40, average log likelihood -1.415359
[ Info: iteration 41, average log likelihood -1.415346
[ Info: iteration 42, average log likelihood -1.415333
[ Info: iteration 43, average log likelihood -1.415320
[ Info: iteration 44, average log likelihood -1.415308
[ Info: iteration 45, average log likelihood -1.415295
[ Info: iteration 46, average log likelihood -1.415283
[ Info: iteration 47, average log likelihood -1.415271
[ Info: iteration 48, average log likelihood -1.415260
[ Info: iteration 49, average log likelihood -1.415248
[ Info: iteration 50, average log likelihood -1.415237
┌ Info: EM with 100000 data points 50 iterations avll -1.415237
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.565812   -0.856376    0.161203     0.110368    -0.114564    0.669731    -0.326059    0.594232    -0.201893   -0.151336    -0.155724   -0.156686   -0.0984394   -0.399387   -0.346706    -0.21304       0.196672    0.160274     0.111876   -0.206161   -0.275136    0.0131623  -0.693277    0.248472   -0.512558    0.242424
 -0.247921    0.0780477   0.0844237   -0.244175    -0.48963     0.183973     0.0370144  -0.0782689    0.266034   -0.0228267    0.0545191   0.164125    0.0472299   -0.0836188  -0.416064     0.0940704    -0.351525   -0.418776     0.645915   -0.0720909   0.400126    0.0892524   0.240119   -0.210915    0.0424573   0.322089
  0.282331    0.943805   -0.149946    -0.171043     0.243248    0.443581     0.11216    -0.334898     0.740077   -0.0290651   -0.603893   -0.0903497  -0.430183     0.580933    0.718543     0.206734      0.546919   -0.585057     0.234934    0.0806345   0.491853    0.0799591  -0.158921   -0.6051      0.0039218   0.0900735
 -0.324748    0.0533283   0.0962855    0.124379     0.498637   -0.507742    -0.261201    0.568804    -0.0310503   0.285585     0.0424523  -0.580531   -0.224752     0.302069    0.266613    -0.0868636     0.569942    0.313104    -0.0891143  -0.302738   -0.384774   -0.324243   -0.73513     0.482298   -0.0945427  -0.107607
  0.644755    0.0339667  -0.995601    -0.0552787    0.236563    0.227687     0.308992   -0.39785      0.213897   -0.013762     0.114811   -0.806604    0.148735     0.117373    0.757354    -0.276878      0.808688   -0.00613264  -0.526314    0.166091    0.480803   -0.19344     0.264338   -0.0514827   0.272522    0.357246
  0.015525    0.0232029  -0.0774102    0.10439      0.101964   -0.0038437    0.0365758  -0.0573941    0.17181    -0.116173    -0.169079    0.0185483  -0.264756    -0.0537735  -0.14902      0.138475      0.0144121  -0.00673793  -0.28724    -0.16292    -0.124764   -0.0591198   0.0438308  -0.090049   -0.147872   -0.0887623
  0.179573    0.173187    0.554372    -0.218425     0.0269171   0.445524    -0.0605075   0.234593    -0.106764   -0.323872     0.423596   -0.23366     1.16889      0.176138   -0.110804     0.0796642     0.091569    0.385594     0.514211    0.315313   -0.134121    0.143797   -0.477957    0.315111   -0.160243   -0.23952
  0.521723    0.0109644  -0.114747     0.117958     0.0375766   0.21455     -0.106902    0.186558    -0.579716    0.286814     0.063016    0.246768    0.300395    -0.383422    0.183101     0.0111894    -0.530313   -0.205353     0.127505    0.688831    0.375552    0.270126    0.211332    0.0377745  -0.0553475  -0.133484
 -0.310118   -0.101141   -0.754353     0.344101     0.307299   -0.295548     0.0164511  -0.132754     0.299835    0.310141    -0.590583    0.195263   -0.973059     0.0178316   0.133808    -0.149735     -0.302499   -0.0272129   -0.653644   -0.215049   -0.0702534  -0.307845    0.210136   -0.374915    0.446887    0.190069
 -0.645376    0.271018   -0.11443     -0.28538     -0.487532    0.454928    -0.654056   -0.0482274   -0.20787    -0.219194    -0.0320872   0.147607   -0.470948    -0.322841    0.089748    -0.398443      0.182451    0.321655    -0.336324    0.257526   -0.481706    0.0866021   0.0204565  -0.370691   -0.0328768  -0.312976
  0.405594    0.448799    0.251918     0.330451     0.445396    0.566477     0.197294    0.250764    -0.345861   -0.205711    -0.347954    0.258533   -0.0697829    0.268029    0.00875698   0.0255536     0.0846021   0.589403    -0.691982    0.0973878  -0.126775    0.502573    0.212622    0.317741   -0.165556   -0.530645
 -0.675019   -0.219136    0.178723     0.19274     -0.859165   -0.0655167   -0.612627   -0.0594592   -0.15015    -0.540448     0.177109   -0.707223   -0.207287     0.28296    -0.111998    -0.0167648     0.419536   -0.230953    -0.430869   -0.454064    0.22287    -0.313292   -0.141686    0.392516    0.0650823   0.0826722
  0.323752   -0.214305    0.121668    -0.201314     0.158947    0.403805     0.127127   -0.506503    -0.042692    0.200859    -0.0940151  -0.253483   -0.104045     0.244147    0.520926    -0.338264     -0.0337805   0.2101      -0.340681   -0.429754   -0.185925   -0.397537    0.0720334  -0.251372    0.325359   -0.188655
  0.440799    0.689784   -0.443029    -0.0812722   -0.174362   -0.00864881   0.0891505  -0.212769    -0.656293    0.663733     0.447141   -0.43972     0.232443     0.302624   -0.0482867   -0.0347249     0.334898   -0.0755278    0.295464   -0.065965    0.0572423   0.142635    0.281548    0.0623809   0.359884    0.707962
 -0.211208    0.565161   -0.448786     0.309624     0.641668   -0.519686     0.431118   -0.00603657   0.258862   -0.414752     0.506762    0.685146    0.249188    -0.154476    0.295276    -0.0431164     0.255075    0.319015     0.198632    0.680517   -0.0969412  -0.210252    0.399361   -0.372739    0.360861    0.0738074
  0.374225   -0.813322    0.65565     -0.299627     0.154506   -0.63892      0.272821    0.229112    -0.385039    0.619276     0.632815   -0.497918    0.516143     0.471187   -0.118325     0.0924598     0.0392496  -0.277366     0.344002    0.187778    0.310422    0.0746642  -0.114312   -0.0548517  -0.242977    0.27061
 -0.283425   -0.371098    0.715329    -0.59039      0.371894    0.442006    -0.0293051   0.319356    -0.246069   -0.749282    -0.0866499  -0.302574   -0.476664    -0.228178    0.236055     0.290718     -0.377011   -0.428405     0.360514    0.196466   -0.35403     0.204854    0.424781    0.146012   -0.408999   -0.298711
  0.382185   -0.490678    0.0810074   -0.766907     0.84518    -0.018703     0.213843   -0.0700067    0.237088    0.0910148   -0.0472574   0.094121   -0.0523733   -0.220349   -0.167482     0.570418      0.307166    0.0499364    0.161937    0.143238   -0.427171   -0.0171189  -0.362875   -0.198151   -0.221403    0.10354
  0.0527617   0.0170267   0.158096     0.22001     -0.898647    0.462767    -0.115842   -0.660057     0.106463    0.0987276    0.255003   -0.193041   -0.0567699    0.0479184  -0.0594146   -0.81128      -0.278036   -0.390755     0.0440676  -0.689024    0.163629   -0.272019    0.168504   -0.272558   -0.331594    0.18997
 -0.469312   -0.240443   -0.36084     -0.261178    -0.377501   -0.551601    -0.299117   -0.325119    -0.0100675   0.282346     0.424377   -0.342608    0.123082    -0.262112   -0.0104583   -0.39268      -0.10995    -0.41587      0.371499   -0.101951    0.0274644  -0.820447   -0.27735    -0.297691    0.137255    0.430734
  0.104535    0.0168617   0.344349    -0.88652     -0.303121   -0.347163     0.5955     -0.666809     0.423781    0.279679     0.024777   -0.186524    0.168559     0.932418   -0.173751     0.671183      0.038297    0.115791     0.0735194  -0.365274    0.207908    0.0472349   0.451187   -0.271426    0.239249    0.166925
  0.462571   -0.0189908  -0.301757     0.474241     0.317818   -0.570682     0.425147   -0.0324265    0.137573    0.395689    -0.297883    0.189765    0.508074     0.145029    0.073116     0.104544     -0.268013   -0.490208    -0.124765   -0.272207    0.787463    0.0716607   0.0829206   0.34273     0.421819    0.194512
 -1.04409    -0.0758792   0.84244      0.177219    -0.0676028  -0.113854    -0.141556   -0.243407     0.842097   -0.640282    -0.124979    0.485077   -0.315347    -0.170798    0.386203    -0.218533     -0.423341    0.256295     0.0902222   0.0182477   0.212026   -0.0312875   0.228393   -0.189408   -0.280064   -0.661195
  0.692136   -0.189486    0.654005    -0.821731    -0.256303    0.663061     0.395048   -0.609826    -0.366555    0.522175    -0.304124   -0.851367   -0.728771     0.0275931  -0.20287     -0.073333     -0.809779   -0.587309     0.204767    0.0326256   0.308432    0.60911     0.019992    0.758764    0.0388232  -0.158743
 -0.707171    0.900683   -0.616945     0.909621    -0.17273     0.280385    -0.294323   -0.211425     0.176407   -0.739865    -0.066956    0.265311   -0.386751    -0.0970813   0.218529    -0.483267     -0.149424    0.0338742    0.0714075  -0.0181708  -0.0263838   0.196276   -0.0222771   0.393657    0.280388   -0.179734
  0.0939531   0.524507   -0.278249     0.794353    -0.385009   -0.377201    -0.596585   -0.145172     0.0714282   0.260837    -0.260131    0.0588211   0.598798     0.249208   -0.24399      0.000394298  -0.292905    0.557366    -0.238564   -0.388964    0.37915    -0.313398   -0.301834   -0.193335   -0.12815    -0.369651
 -0.646704    0.20756    -0.0102101    0.387825     0.337743   -0.296732    -0.464251    0.443617    -0.158202   -0.384833    -0.46947     0.410496    0.0739893   -0.730549   -0.632419     0.190101     -0.514028   -0.139248     0.228619    0.0982808  -0.777748    0.0200214  -0.335659    0.103638   -0.0934211  -0.0499018
 -0.884953   -0.0142821   0.204676     0.0282123   -0.211619   -0.529979     0.335661    0.399347     0.0190828  -0.112873     0.197218    0.582927   -0.312086     0.0447918  -0.450908    -0.0933828     0.0807622   0.209359     0.0268227  -0.318123   -0.650387    0.314317   -0.0373797  -0.0969959  -0.0201683   0.226001
 -0.0896142   0.0522833   0.150004    -0.00941649   0.0782321  -0.00727295  -0.0807428   0.0639013   -0.154469    0.00890719   0.0877432  -0.0373781   0.192095     0.0862735   0.122746    -0.0983746    -0.0528594  -0.0184125    0.206624    0.16321     0.0763117   0.087804   -0.0969223   0.0796421  -0.0170713  -0.0475657
  0.0118554  -0.741481    0.00532807   0.426879    -0.586453   -0.590023     0.523483   -0.556996    -0.595254    0.695715    -0.346953    0.299206   -0.180521    -0.217587   -0.922706     0.172975     -0.728665    0.893754     0.672492   -1.02917    -0.381456    0.176765    0.362663    0.0219002  -0.0470243  -0.662885
 -0.0602868  -0.289201   -0.39497      0.369488    -0.308236   -0.484859     0.256036    0.0385269   -0.776178   -0.0210984   -0.698139    0.998262   -0.533143    -0.196103   -0.130888    -0.351497      0.0454271  -0.615881    -0.0715179   0.158438    0.425402    0.581732   -0.0823101  -0.0134341  -0.0709871  -0.19948
 -0.0554513   0.101829   -0.125063    -0.253206     0.290859   -0.00274732   0.0521481   0.0488302    0.150021   -0.0215773    0.0950195   0.0610181  -0.00715418  -0.0847195   0.0961031    0.128551      0.167691    0.0644886    0.0787561   0.262468   -0.0620428   0.014341   -0.109146   -0.0429155   0.146561    0.0808642[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415226
[ Info: iteration 2, average log likelihood -1.415215
[ Info: iteration 3, average log likelihood -1.415204
[ Info: iteration 4, average log likelihood -1.415193
[ Info: iteration 5, average log likelihood -1.415183
[ Info: iteration 6, average log likelihood -1.415172
[ Info: iteration 7, average log likelihood -1.415162
[ Info: iteration 8, average log likelihood -1.415152
[ Info: iteration 9, average log likelihood -1.415143
[ Info: iteration 10, average log likelihood -1.415133
┌ Info: EM with 100000 data points 10 iterations avll -1.415133
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
