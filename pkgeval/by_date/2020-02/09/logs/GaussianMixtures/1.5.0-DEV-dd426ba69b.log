Julia Version 1.5.0-DEV.255
Commit dd426ba69b (2020-02-09 18:28 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed PDMats ───────────── v0.9.11
  Installed GaussianMixtures ─── v0.3.0
  Installed CMake ────────────── v1.1.2
  Installed Compat ───────────── v2.2.0
  Installed OrderedCollections ─ v1.1.0
  Installed HDF5 ─────────────── v0.12.5
  Installed DataStructures ───── v0.17.9
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed Blosc ────────────── v0.5.1
  Installed Missings ─────────── v0.4.3
  Installed JLD ──────────────── v0.9.2
  Installed Arpack_jll ───────── v3.5.0+2
  Installed Distances ────────── v0.8.2
  Installed QuadGK ───────────── v2.3.1
  Installed LegacyStrings ────── v0.4.1
  Installed ScikitLearnBase ──── v0.5.0
  Installed FillArrays ───────── v0.8.4
  Installed NearestNeighbors ─── v0.4.4
  Installed StatsFuns ────────── v0.9.3
  Installed StatsBase ────────── v0.32.0
  Installed DataAPI ──────────── v1.1.0
  Installed BinaryProvider ───── v0.5.8
  Installed CMakeWrapper ─────── v0.2.3
  Installed StaticArrays ─────── v0.12.1
  Installed Parameters ───────── v0.12.0
  Installed Arpack ───────────── v0.4.0
  Installed URIParser ────────── v0.4.0
  Installed FileIO ───────────── v1.2.2
  Installed Rmath ────────────── v0.6.0
  Installed SortingAlgorithms ── v0.3.1
  Installed BinDeps ──────────── v1.0.0
  Installed Distributions ────── v0.22.4
  Installed SpecialFunctions ─── v0.9.0
  Installed Clustering ───────── v0.13.3
#=#=#                                                                         #                                                                          2.4%#####                                                                      7.4%#########                                                                 13.1%##############                                                            20.4%###################                                                       27.8%############################                                              40.2%#######################################                                   55.0%#####################################################                     73.9%#######################################################################   98.7%######################################################################## 100.0%
#=#=#                                                                         ########################################################                  77.9%######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.2
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_hbSqPW/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.2
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -2.018673987888501e6, [26054.456462086982, 73945.54353791302], [-1249.19736369103 11560.631544618258 1529.9171647151684; 944.4796863610499 -11388.0061192746 -1527.0178740479307], [[26022.242182930953 2003.5486746204926 -1941.1919395741268; 2003.5486746204926 15047.460553283283 10485.877311235776; -1941.1919395741268 10485.877311235776 13802.08165084998], [74329.6098223817 -1733.4248569316915 1777.8766369329378; -1733.4248569316915 85148.44237176864 -10181.939914429815; 1777.8766369329383 -10181.939914429815 86001.1123744557]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.387488e+03
      1       9.240022e+02      -4.634860e+02 |        6
      2       8.598541e+02      -6.414810e+01 |        0
      3       8.598541e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 859.8540903466155)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.070865
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.767187
[ Info: iteration 2, lowerbound -3.614409
[ Info: iteration 3, lowerbound -3.453778
[ Info: iteration 4, lowerbound -3.287822
[ Info: iteration 5, lowerbound -3.138932
[ Info: iteration 6, lowerbound -3.022132
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.931828
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.866663
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.804805
[ Info: iteration 10, lowerbound -2.764888
[ Info: iteration 11, lowerbound -2.743346
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.720566
[ Info: iteration 13, lowerbound -2.692266
[ Info: iteration 14, lowerbound -2.661545
[ Info: iteration 15, lowerbound -2.625112
[ Info: iteration 16, lowerbound -2.584207
[ Info: iteration 17, lowerbound -2.540919
[ Info: iteration 18, lowerbound -2.497803
[ Info: iteration 19, lowerbound -2.457077
[ Info: iteration 20, lowerbound -2.419813
[ Info: iteration 21, lowerbound -2.385829
[ Info: iteration 22, lowerbound -2.354805
[ Info: iteration 23, lowerbound -2.328407
[ Info: iteration 24, lowerbound -2.311345
[ Info: iteration 25, lowerbound -2.307822
[ Info: dropping number of Gaussions to 2
[ Info: iteration 26, lowerbound -2.302917
[ Info: iteration 27, lowerbound -2.299259
[ Info: iteration 28, lowerbound -2.299256
[ Info: iteration 29, lowerbound -2.299254
[ Info: iteration 30, lowerbound -2.299254
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sun Feb  9 21:12:01 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sun Feb  9 21:12:09 2020: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Sun Feb  9 21:12:11 2020: EM with 272 data points 0 iterations avll -2.070865
5.8 data points per parameter
, Sun Feb  9 21:12:13 2020: GMM converted to Variational GMM
, Sun Feb  9 21:12:21 2020: iteration 1, lowerbound -3.767187
, Sun Feb  9 21:12:21 2020: iteration 2, lowerbound -3.614409
, Sun Feb  9 21:12:21 2020: iteration 3, lowerbound -3.453778
, Sun Feb  9 21:12:21 2020: iteration 4, lowerbound -3.287822
, Sun Feb  9 21:12:21 2020: iteration 5, lowerbound -3.138932
, Sun Feb  9 21:12:21 2020: iteration 6, lowerbound -3.022132
, Sun Feb  9 21:12:22 2020: dropping number of Gaussions to 7
, Sun Feb  9 21:12:22 2020: iteration 7, lowerbound -2.931828
, Sun Feb  9 21:12:22 2020: dropping number of Gaussions to 5
, Sun Feb  9 21:12:22 2020: iteration 8, lowerbound -2.866663
, Sun Feb  9 21:12:22 2020: dropping number of Gaussions to 4
, Sun Feb  9 21:12:22 2020: iteration 9, lowerbound -2.804805
, Sun Feb  9 21:12:22 2020: iteration 10, lowerbound -2.764888
, Sun Feb  9 21:12:22 2020: iteration 11, lowerbound -2.743346
, Sun Feb  9 21:12:22 2020: dropping number of Gaussions to 3
, Sun Feb  9 21:12:22 2020: iteration 12, lowerbound -2.720566
, Sun Feb  9 21:12:22 2020: iteration 13, lowerbound -2.692266
, Sun Feb  9 21:12:22 2020: iteration 14, lowerbound -2.661545
, Sun Feb  9 21:12:22 2020: iteration 15, lowerbound -2.625112
, Sun Feb  9 21:12:22 2020: iteration 16, lowerbound -2.584207
, Sun Feb  9 21:12:22 2020: iteration 17, lowerbound -2.540919
, Sun Feb  9 21:12:22 2020: iteration 18, lowerbound -2.497803
, Sun Feb  9 21:12:22 2020: iteration 19, lowerbound -2.457077
, Sun Feb  9 21:12:22 2020: iteration 20, lowerbound -2.419813
, Sun Feb  9 21:12:22 2020: iteration 21, lowerbound -2.385829
, Sun Feb  9 21:12:22 2020: iteration 22, lowerbound -2.354805
, Sun Feb  9 21:12:22 2020: iteration 23, lowerbound -2.328407
, Sun Feb  9 21:12:22 2020: iteration 24, lowerbound -2.311345
, Sun Feb  9 21:12:22 2020: iteration 25, lowerbound -2.307822
, Sun Feb  9 21:12:22 2020: dropping number of Gaussions to 2
, Sun Feb  9 21:12:22 2020: iteration 26, lowerbound -2.302917
, Sun Feb  9 21:12:22 2020: iteration 27, lowerbound -2.299259
, Sun Feb  9 21:12:22 2020: iteration 28, lowerbound -2.299256
, Sun Feb  9 21:12:22 2020: iteration 29, lowerbound -2.299254
, Sun Feb  9 21:12:22 2020: iteration 30, lowerbound -2.299254
, Sun Feb  9 21:12:22 2020: iteration 31, lowerbound -2.299253
, Sun Feb  9 21:12:22 2020: iteration 32, lowerbound -2.299253
, Sun Feb  9 21:12:22 2020: iteration 33, lowerbound -2.299253
, Sun Feb  9 21:12:22 2020: iteration 34, lowerbound -2.299253
, Sun Feb  9 21:12:22 2020: iteration 35, lowerbound -2.299253
, Sun Feb  9 21:12:22 2020: iteration 36, lowerbound -2.299253
, Sun Feb  9 21:12:22 2020: iteration 37, lowerbound -2.299253
, Sun Feb  9 21:12:22 2020: iteration 38, lowerbound -2.299253
, Sun Feb  9 21:12:22 2020: iteration 39, lowerbound -2.299253
, Sun Feb  9 21:12:22 2020: iteration 40, lowerbound -2.299253
, Sun Feb  9 21:12:22 2020: iteration 41, lowerbound -2.299253
, Sun Feb  9 21:12:22 2020: iteration 42, lowerbound -2.299253
, Sun Feb  9 21:12:22 2020: iteration 43, lowerbound -2.299253
, Sun Feb  9 21:12:22 2020: iteration 44, lowerbound -2.299253
, Sun Feb  9 21:12:22 2020: iteration 45, lowerbound -2.299253
, Sun Feb  9 21:12:22 2020: iteration 46, lowerbound -2.299253
, Sun Feb  9 21:12:22 2020: iteration 47, lowerbound -2.299253
, Sun Feb  9 21:12:22 2020: iteration 48, lowerbound -2.299253
, Sun Feb  9 21:12:22 2020: iteration 49, lowerbound -2.299253
, Sun Feb  9 21:12:22 2020: iteration 50, lowerbound -2.299253
, Sun Feb  9 21:12:22 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222607587, 95.95490777392425]
β = [178.04509222607587, 95.95490777392425]
m = [4.250300733269407 79.28686694435441; 2.0002292577748486 53.85198717245854]
ν = [180.04509222607587, 97.95490777392425]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547477966 -0.007644049042333876; 0.0 0.008581705166323977], [0.37587636119570556 -0.008953123827356597; 0.0 0.012748664777411668]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -1.0151502896588502
avll from llpg:  -1.01515028965885
avll direct:     -1.0151502896588502
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9884620976036126
avll from llpg:  -0.9884620976036126
avll direct:     -0.9884620976036126
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
 -0.126369     -0.00132486  -0.101602     0.144916    -0.103942     0.131864    -0.0158828     0.0727474    0.149046     -0.0346751    -0.036189     -0.144053    -0.130995    -0.037929     0.0814179    0.0492759   -0.0752606    0.136675     0.041975    -0.156067     0.140718     -0.100583    0.166147     -0.0265562   -0.137611      0.171561
  0.025131     -0.0978081    0.00524391  -0.0188284    0.0832704   -0.0196245    0.0421198    -0.187776    -0.184148      0.00181172    0.046051      0.0157198   -0.156335     0.158341     0.0793729    0.23751      0.0337232    0.0545062    0.00991029   0.0259151    0.0798615     0.15713     0.0540154     0.0913862   -0.177362     -0.105334
  0.0584953     0.062357    -0.0702743   -0.0374811    0.140071    -0.0996871   -0.148288     -0.0641762    0.0157109     0.000776894  -0.0881661    -0.0794919   -0.0759776    0.0144302   -0.0486643   -0.0823048   -0.0229747   -0.0838288    0.0443167    0.26442     -0.144209     -0.0191761  -0.103959     -0.0021816    0.0801063     0.058779
 -0.0563018     0.0866037   -0.0406102   -0.0219833    0.015863     0.123165     0.15936      -0.265411    -0.0948866     0.0063499    -0.0825762    -0.0467184    0.0686163   -0.0610108    0.00521203   0.0972932    0.0579451   -0.0155303   -0.00731437  -0.0175881    0.0107952    -0.0149363  -0.0590248    -0.0658077   -0.0464954     0.015049
  0.0329961     0.0321572   -0.0843954   -0.0766377   -0.0241783   -0.14945     -0.0685509     0.0834429   -0.244049      0.0213772    -0.00626192   -0.181898    -0.164243     0.0252244   -0.330058    -0.0234822   -0.230596    -0.155583     0.0783033   -0.0678404   -0.18293      -0.041247   -0.0508598    -0.107576     0.11251      -0.161126
  0.109793     -0.0229557    0.10998     -0.166168    -0.00568739   0.107487    -0.0321253    -0.0638648    0.0931602    -0.0535022     0.186326      0.00874492   0.157269    -0.0772398   -0.10942     -0.0762815    0.128725     0.101861     0.0010569    0.17406     -0.0203493    -0.0477912   0.142285      0.0493049   -0.000614891   0.0341922
  0.0507579     0.114532     0.00834341   0.0625404    0.0441982   -0.0501502   -0.0554429     0.105394     0.000530635   0.0980938    -0.0241942    -0.165099     0.180685     0.155161     0.194483     0.137102    -0.319621     0.0380582    0.119867    -0.0509261   -0.0847602    -0.0933304   0.0530184     0.0216376    0.0232896    -0.0952251
  0.000876494   0.0279813    0.0189348   -0.0467807    0.0962506    0.011495     0.0267676     0.0473741   -0.0977537     0.148712      0.0106428     0.0299373   -0.241741     0.0679414    0.0224656    0.00404656   0.0145752    0.105       -0.171019     0.192038     0.168988      0.0670336   0.117455      0.164852    -0.0336288     0.0816512
 -0.0780744     0.144635     0.0599522   -0.0336174    0.0331052    0.0723828    0.0508438    -0.0358892    0.0184414    -0.0386536    -0.0384563    -0.127249    -0.0163487   -0.0192849    0.137005    -0.0234154   -0.117796    -0.0113741   -0.0464898    0.0954672    0.0664955    -0.165889   -0.0286896     0.0151061   -0.211666      0.0212517
 -0.131838     -0.0356946   -0.0158095    0.0390022    0.0102063    0.0630459   -0.0427492    -0.0807424   -0.052338      0.116042     -0.0320617    -0.0711551   -0.06489      0.0791919    0.154977    -0.0941808    0.199644    -0.0429656    0.0093597    0.086549     0.00169311   -0.0804571  -0.122226     -0.282183    -0.0526956    -0.18418
 -0.0620137     0.128637     0.05162     -0.0723272   -0.037736    -0.0737963    0.186966     -0.0964884   -0.0444623    -0.117784     -0.0784602    -0.0915051   -0.101839     0.00716113  -0.1384      -0.0353587   -0.0271702   -0.205333    -0.0202423   -0.177739     0.117641     -0.0660987   0.0797873    -0.153432     0.027756      0.049319
  0.188972     -0.181521     0.0632542   -0.00353071   0.0603524    0.0427812    0.00892362    0.108797    -0.0489724     0.0181306    -0.195057     -0.0698105    0.0545146   -0.142734     0.0927381   -0.0425133    0.0102426   -0.0690447    0.0876453    0.153003    -0.0249081    -0.0808939   0.189948      0.0330262    0.0357194    -0.0365294
  0.160013      0.061586     0.201745     0.150399     0.075633     0.0680712    0.15879       0.175822     0.194088      0.0511484     0.0214357     0.0747904    0.197769     0.0265094    0.0228362    0.17703      0.0249763    0.0448805   -0.029536    -0.0121557   -0.114817      0.066547   -0.027068      0.0233478   -0.144124     -0.0888814
 -0.0109936     0.015158    -0.196392    -0.014778    -0.0413646    0.0412124   -0.0142471     0.185955     0.180789     -0.0977742    -0.019742      0.0116418    0.130101     0.0875543   -0.0126018   -0.0501045   -0.14991      0.0656192   -0.00426821   0.0386825    0.0665079    -0.0748681   0.0657939    -0.0305385    0.126155     -0.0479726
 -0.00770478    0.216391    -0.0541258    0.155497     0.122599    -0.121704     0.308726      0.00931388   0.0494955     0.0615056    -0.108         0.174581     0.12907     -0.00539262  -0.00228062   0.178849     0.0577551   -0.0580168    0.0616305   -0.0215848   -0.00964179   -0.0608757   0.0323347    -0.0334787   -0.0547084     0.193825
  0.00661295    0.116126    -0.0248525   -0.00864907   0.0903209    0.112541    -0.104426     -0.0790919   -0.0445374     0.16638       0.125293     -0.0612745    0.0314681   -0.110841     0.0497973    0.098598    -0.0148816   -0.0700696   -0.174319     0.115033     0.0712186     0.128916    0.026619      0.0459077    0.0858436    -0.060662
  0.0105571     0.100068    -0.129065     0.0467305   -0.0397977   -0.0244707   -0.0761635     0.0461044   -0.03958       0.0302348     0.0774992     0.0457019   -0.0192999   -0.141422    -0.0925261    0.00935282   0.0681088    0.0783961    0.0743837   -0.0486904    0.0803942     0.0403056  -0.00468185    0.0140044    0.174885     -0.0886338
 -0.0679592    -0.0305783    0.00660864   0.0374502   -0.0731965    0.0407533   -0.183598      0.338268    -0.0681563    -0.0680378     0.000989148   0.0662273   -0.118518     0.0272595    0.00492098   0.179993     0.208702     0.0330254   -0.0838188    0.0586983   -0.000747834   0.0664255  -0.0838511     0.182819    -0.0860331    -0.0105336
 -0.00391116   -0.0542044    0.0495823   -0.0320493   -0.0322947    0.0153334    0.00200829    0.137363     0.000716122   0.0397122    -0.131009      0.0011341   -0.0347456    0.0617996   -0.0181702   -0.105989     0.255708     0.131063    -0.100624    -0.0604092    0.141939      0.128693    0.16487      -0.0075405   -0.137894      0.0928292
  0.12099       0.0761114   -0.0208741    0.0251334   -0.0222377    0.139307     0.161648      0.112586    -0.159077      0.0615163     0.0935131    -0.135558    -0.190423     0.126246     0.0187152    0.0301218    0.0827166   -0.087672    -0.0134818   -0.00119427   0.00229606   -0.116788   -0.0382908    -0.0133393    0.0318277    -0.0952393
  0.00423556    0.0697233   -0.0638618    0.0285782    0.0277301    0.107983     0.0769214     0.128095     0.04554       0.0482762    -0.022296      0.00297053   0.0162446   -0.152504    -0.0667484    0.122047    -0.0861464    0.0947746   -0.036009    -0.0699373   -0.127234      0.124124    0.0970613     0.0560404   -0.0459394    -0.0540926
  0.0337146    -0.0313406   -0.0840448   -0.102401     0.068478     0.132974    -0.0214457     0.0660638    0.073188     -0.0146023    -0.0303168     0.00242373  -0.0375337   -0.0200485   -0.0644296    0.0976138   -0.0847651    0.0669378    0.0154007    0.0275891   -0.00161504    0.0627181   0.200887      0.0323156   -0.0159093    -0.0570125
 -0.17524       0.0586772   -0.0265124    0.0849422   -0.0906133   -0.0475285   -0.110099     -0.0350682   -0.181172      0.0161331    -0.0156934     0.169731     0.0736381    0.134971    -0.0349146    0.0499468   -0.224036     0.0776331    0.0645181   -0.0407234    0.117643     -0.0329978  -0.139901      0.168114    -0.0434531    -0.0700192
 -0.0252036     0.11872     -0.0188661    0.0780128    0.00878792   0.0769347    0.0766122    -0.156783    -0.107164     -0.0262784    -0.0429479    -0.131563    -0.0236871    0.00613548   0.05993      0.0416928    0.0406825    0.0598513   -0.00857853   0.124641    -0.0091005    -0.0821375  -0.00195883    0.00505068  -0.0218272     0.0414824
 -0.107819     -0.0482768    0.120812    -0.072727    -0.0206556   -0.0796858    0.0244134     0.0316236   -0.0290526     0.0128068     0.103814      0.0505049   -0.231648    -0.1184      -0.109663    -0.170724    -0.0807267   -0.0862465   -0.127115    -0.0574645   -0.0221222     0.210707   -0.0733184    -0.146095     0.0699201    -0.146237
 -0.051199      0.0419843    0.00385672  -0.206101     0.0842597    0.130298     0.0502668    -0.282831     0.0491933    -0.0841103     0.0868859     0.0463628    0.147406    -0.140471    -0.100342    -0.0956163   -0.147018    -0.164432     0.0394167    0.115612     0.14443      -0.18285    -0.0677034     0.137466     0.0318488    -0.0200543
  0.101498      0.231596     0.0548094    0.241971     0.125112    -0.331291     0.0136791    -0.148754    -0.275778     -0.14651      -0.0810493     0.151478    -0.168949     0.161721    -0.107832    -0.0363025    0.00305151   0.00832311  -0.0528089    0.0675298   -0.0541694     0.052352    0.000804131  -0.123988     0.1255       -0.0646398
  0.025169     -0.188787    -0.170473    -0.0462445   -0.0808748   -0.0872197   -0.239467      0.103368    -0.153296     -0.108144     -0.0340979     0.0251134    0.105366    -0.0802522    0.0601413    0.0312996   -0.116019    -0.0661168   -0.0829534   -0.0135794    0.0707019    -0.0570329   0.00650267   -0.0031411    0.114025     -0.0305746
  0.0951826    -0.0308431   -0.095644    -0.0277584   -0.0506672    0.00661748  -0.000647025   0.00219038  -0.0176377    -0.0520441    -0.0889121    -0.0192939   -0.0716892    0.0662643   -0.0383322   -0.00713316  -0.156336    -0.122547     0.142264    -0.165621     0.0959109     0.021971   -0.116507     -0.0320073    0.0899181     0.0539264
  0.116445      0.025166     0.0158167   -0.0328449    0.0164043   -0.129173    -0.00594977    0.055076     0.0651591     0.0534112     0.0402701     0.0281921    0.0977251   -0.0981644   -0.0227337   -0.155821    -0.0865565   -0.00104806  -0.172658    -0.14931     -0.227086      0.0424294  -0.243019      0.0241732    0.100128      0.0139925
 -0.0244035     0.0488444    0.0373917    0.0484923   -0.0754722    0.0411431   -0.126112      0.036194     0.052583      0.125347     -0.0551452    -0.0187155   -0.144886    -0.060943    -0.177117    -0.110161     0.146425     0.0792664   -0.07383     -0.102066     0.144409      0.13532    -0.208915      0.0398018    0.180876      0.115809
  0.0557887    -0.150217    -0.0678804    0.0552509    0.0880292    0.0198281   -0.170102      0.162538    -0.0474989    -0.0790846    -0.00312882   -0.00713261   0.00816159   0.0278762   -0.0142915   -0.170359    -0.138898    -0.0901138   -0.0247933   -0.072927     0.124762     -0.104847   -0.179175      0.0285079   -0.226479     -0.0202205kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4149214688819625
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414978
[ Info: iteration 2, average log likelihood -1.414910
[ Info: iteration 3, average log likelihood -1.414211
[ Info: iteration 4, average log likelihood -1.407063
[ Info: iteration 5, average log likelihood -1.391116
[ Info: iteration 6, average log likelihood -1.384745
[ Info: iteration 7, average log likelihood -1.383245
[ Info: iteration 8, average log likelihood -1.382348
[ Info: iteration 9, average log likelihood -1.381495
[ Info: iteration 10, average log likelihood -1.380441
[ Info: iteration 11, average log likelihood -1.379229
[ Info: iteration 12, average log likelihood -1.378144
[ Info: iteration 13, average log likelihood -1.377454
[ Info: iteration 14, average log likelihood -1.377045
[ Info: iteration 15, average log likelihood -1.376731
[ Info: iteration 16, average log likelihood -1.376511
[ Info: iteration 17, average log likelihood -1.376397
[ Info: iteration 18, average log likelihood -1.376326
[ Info: iteration 19, average log likelihood -1.376275
[ Info: iteration 20, average log likelihood -1.376234
[ Info: iteration 21, average log likelihood -1.376199
[ Info: iteration 22, average log likelihood -1.376166
[ Info: iteration 23, average log likelihood -1.376128
[ Info: iteration 24, average log likelihood -1.376073
[ Info: iteration 25, average log likelihood -1.375967
[ Info: iteration 26, average log likelihood -1.375750
[ Info: iteration 27, average log likelihood -1.375371
[ Info: iteration 28, average log likelihood -1.374907
[ Info: iteration 29, average log likelihood -1.374445
[ Info: iteration 30, average log likelihood -1.374028
[ Info: iteration 31, average log likelihood -1.373669
[ Info: iteration 32, average log likelihood -1.373368
[ Info: iteration 33, average log likelihood -1.373101
[ Info: iteration 34, average log likelihood -1.372846
[ Info: iteration 35, average log likelihood -1.372608
[ Info: iteration 36, average log likelihood -1.372409
[ Info: iteration 37, average log likelihood -1.372242
[ Info: iteration 38, average log likelihood -1.372087
[ Info: iteration 39, average log likelihood -1.371923
[ Info: iteration 40, average log likelihood -1.371754
[ Info: iteration 41, average log likelihood -1.371614
[ Info: iteration 42, average log likelihood -1.371524
[ Info: iteration 43, average log likelihood -1.371474
[ Info: iteration 44, average log likelihood -1.371445
[ Info: iteration 45, average log likelihood -1.371428
[ Info: iteration 46, average log likelihood -1.371419
[ Info: iteration 47, average log likelihood -1.371413
[ Info: iteration 48, average log likelihood -1.371410
[ Info: iteration 49, average log likelihood -1.371408
[ Info: iteration 50, average log likelihood -1.371407
┌ Info: EM with 100000 data points 50 iterations avll -1.371407
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.414978083280393
│     -1.4149102407202283
│      ⋮
└     -1.3714073787730445
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.371503
[ Info: iteration 2, average log likelihood -1.371397
[ Info: iteration 3, average log likelihood -1.370780
[ Info: iteration 4, average log likelihood -1.364663
[ Info: iteration 5, average log likelihood -1.347111
[ Info: iteration 6, average log likelihood -1.337290
[ Info: iteration 7, average log likelihood -1.334741
[ Info: iteration 8, average log likelihood -1.333674
[ Info: iteration 9, average log likelihood -1.333019
[ Info: iteration 10, average log likelihood -1.332553
[ Info: iteration 11, average log likelihood -1.332204
[ Info: iteration 12, average log likelihood -1.331910
[ Info: iteration 13, average log likelihood -1.331603
[ Info: iteration 14, average log likelihood -1.331279
[ Info: iteration 15, average log likelihood -1.330970
[ Info: iteration 16, average log likelihood -1.330700
[ Info: iteration 17, average log likelihood -1.330461
[ Info: iteration 18, average log likelihood -1.330237
[ Info: iteration 19, average log likelihood -1.330033
[ Info: iteration 20, average log likelihood -1.329854
[ Info: iteration 21, average log likelihood -1.329697
[ Info: iteration 22, average log likelihood -1.329557
[ Info: iteration 23, average log likelihood -1.329433
[ Info: iteration 24, average log likelihood -1.329329
[ Info: iteration 25, average log likelihood -1.329246
[ Info: iteration 26, average log likelihood -1.329183
[ Info: iteration 27, average log likelihood -1.329137
[ Info: iteration 28, average log likelihood -1.329103
[ Info: iteration 29, average log likelihood -1.329078
[ Info: iteration 30, average log likelihood -1.329058
[ Info: iteration 31, average log likelihood -1.329043
[ Info: iteration 32, average log likelihood -1.329030
[ Info: iteration 33, average log likelihood -1.329020
[ Info: iteration 34, average log likelihood -1.329011
[ Info: iteration 35, average log likelihood -1.329003
[ Info: iteration 36, average log likelihood -1.328997
[ Info: iteration 37, average log likelihood -1.328991
[ Info: iteration 38, average log likelihood -1.328985
[ Info: iteration 39, average log likelihood -1.328980
[ Info: iteration 40, average log likelihood -1.328975
[ Info: iteration 41, average log likelihood -1.328970
[ Info: iteration 42, average log likelihood -1.328965
[ Info: iteration 43, average log likelihood -1.328961
[ Info: iteration 44, average log likelihood -1.328956
[ Info: iteration 45, average log likelihood -1.328951
[ Info: iteration 46, average log likelihood -1.328946
[ Info: iteration 47, average log likelihood -1.328942
[ Info: iteration 48, average log likelihood -1.328937
[ Info: iteration 49, average log likelihood -1.328932
[ Info: iteration 50, average log likelihood -1.328927
┌ Info: EM with 100000 data points 50 iterations avll -1.328927
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3715025056968921
│     -1.3713965789071263
│      ⋮
└     -1.3289267144991983
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.329053
[ Info: iteration 2, average log likelihood -1.328873
[ Info: iteration 3, average log likelihood -1.327881
[ Info: iteration 4, average log likelihood -1.320202
[ Info: iteration 5, average log likelihood -1.301421
[ Info: iteration 6, average log likelihood -1.289611
[ Info: iteration 7, average log likelihood -1.285542
[ Info: iteration 8, average log likelihood -1.283139
[ Info: iteration 9, average log likelihood -1.281299
[ Info: iteration 10, average log likelihood -1.279949
[ Info: iteration 11, average log likelihood -1.279019
[ Info: iteration 12, average log likelihood -1.278335
[ Info: iteration 13, average log likelihood -1.277737
[ Info: iteration 14, average log likelihood -1.277128
[ Info: iteration 15, average log likelihood -1.276484
[ Info: iteration 16, average log likelihood -1.275873
[ Info: iteration 17, average log likelihood -1.275367
[ Info: iteration 18, average log likelihood -1.274977
[ Info: iteration 19, average log likelihood -1.274686
[ Info: iteration 20, average log likelihood -1.274461
[ Info: iteration 21, average log likelihood -1.274277
[ Info: iteration 22, average log likelihood -1.274115
[ Info: iteration 23, average log likelihood -1.273956
[ Info: iteration 24, average log likelihood -1.273793
[ Info: iteration 25, average log likelihood -1.273620
[ Info: iteration 26, average log likelihood -1.273435
[ Info: iteration 27, average log likelihood -1.273234
[ Info: iteration 28, average log likelihood -1.273014
[ Info: iteration 29, average log likelihood -1.272790
[ Info: iteration 30, average log likelihood -1.272586
[ Info: iteration 31, average log likelihood -1.272422
[ Info: iteration 32, average log likelihood -1.272301
[ Info: iteration 33, average log likelihood -1.272218
[ Info: iteration 34, average log likelihood -1.272163
[ Info: iteration 35, average log likelihood -1.272127
[ Info: iteration 36, average log likelihood -1.272100
[ Info: iteration 37, average log likelihood -1.272077
[ Info: iteration 38, average log likelihood -1.272055
[ Info: iteration 39, average log likelihood -1.272034
[ Info: iteration 40, average log likelihood -1.272013
[ Info: iteration 41, average log likelihood -1.271993
[ Info: iteration 42, average log likelihood -1.271973
[ Info: iteration 43, average log likelihood -1.271950
[ Info: iteration 44, average log likelihood -1.271922
[ Info: iteration 45, average log likelihood -1.271890
[ Info: iteration 46, average log likelihood -1.271852
[ Info: iteration 47, average log likelihood -1.271810
[ Info: iteration 48, average log likelihood -1.271765
[ Info: iteration 49, average log likelihood -1.271718
[ Info: iteration 50, average log likelihood -1.271662
┌ Info: EM with 100000 data points 50 iterations avll -1.271662
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3290531913016215
│     -1.3288732504574232
│      ⋮
└     -1.2716622873797767
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.271788
[ Info: iteration 2, average log likelihood -1.271486
[ Info: iteration 3, average log likelihood -1.270180
[ Info: iteration 4, average log likelihood -1.256207
[ Info: iteration 5, average log likelihood -1.218093
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.192148
[ Info: iteration 7, average log likelihood -1.190711
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.177150
[ Info: iteration 9, average log likelihood -1.189776
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.173911
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.177701
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.177633
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.178245
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.176841
[ Info: iteration 15, average log likelihood -1.178894
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.167928
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.173602
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.174840
[ Info: iteration 19, average log likelihood -1.186155
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.171609
[ Info: iteration 21, average log likelihood -1.176650
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.166242
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.182802
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.177982
[ Info: iteration 25, average log likelihood -1.179587
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.168683
[ Info: iteration 27, average log likelihood -1.174574
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.164346
[ Info: iteration 29, average log likelihood -1.191642
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.173189
[ Info: iteration 31, average log likelihood -1.177867
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.167507
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.173535
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.173508
[ Info: iteration 35, average log likelihood -1.186676
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.171377
[ Info: iteration 37, average log likelihood -1.176715
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.166568
[ Info: iteration 39, average log likelihood -1.182553
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.169272
[ Info: iteration 41, average log likelihood -1.184980
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.170203
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.175623
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.175364
[ Info: iteration 45, average log likelihood -1.177946
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.167636
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.173429
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.174637
[ Info: iteration 49, average log likelihood -1.185747
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.171694
┌ Info: EM with 100000 data points 50 iterations avll -1.171694
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2717882667320068
│     -1.2714863000844945
│      ⋮
└     -1.1716939554373766
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.177141
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.166881
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.171823
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     14
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.151545
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.116875
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│     13
│     14
│     15
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.073886
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.089562
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     14
│     15
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.078778
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.081777
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      6
│     13
│     15
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.066659
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     17
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.070809
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.083613
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.075264
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     15
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.059484
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     17
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.072127
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      6
│     14
│     15
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.065470
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.074825
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      6
│     15
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.060402
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     17
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.071978
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     14
│     15
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.065539
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.074846
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      6
│     15
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.060407
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     17
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.071924
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     14
│     15
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.065506
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.074816
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      6
│     15
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.060355
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     17
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.071860
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     14
│     15
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.065468
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.074782
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      6
│     15
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.060304
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     17
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.071799
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     14
│     15
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.065435
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.074744
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      6
│     15
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.060268
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     17
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.071740
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     14
│     15
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.065404
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.074692
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      6
│     15
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.060215
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     17
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.071625
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     14
│     15
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.065138
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.073424
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│      6
│     15
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.052508
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     17
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.071752
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     14
│     15
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.063618
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     13
│     14
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.064147
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.069323
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     17
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.064230
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│      6
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.064822
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     13
│     14
│     22
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.065997
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.072850
┌ Info: EM with 100000 data points 50 iterations avll -1.072850
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1771414148071655
│     -1.1668810069307654
│      ⋮
└     -1.0728503204901418
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4149214688819625
│     -1.414978083280393
│     -1.4149102407202283
│     -1.4142110358905333
│      ⋮
│     -1.0648215580109266
│     -1.0659966594759909
└     -1.0728503204901418
32×26 Array{Float64,2}:
 -0.0394297     0.0817081   -0.052178    -0.0326994    0.00200676   0.0961674     0.175523    -0.26885     -0.0880633    -0.0190989   -0.0477066   -0.0426206    0.058001   -0.0999072  -0.0319738   0.0948892    0.0637302   -0.0143631    0.00120339   0.00450155  -0.0229941   -0.0681532   -0.0959348   -0.108007    -0.0123022    0.00117181
  0.0675668     0.0625863   -0.0709727   -0.0391882    0.141742    -0.108791     -0.143164    -0.0573236    0.019611      0.00188579  -0.102059    -0.0801243   -0.0788147   0.0317642  -0.0249036  -0.0904954   -0.0218973   -0.115438     0.0523775    0.241858    -0.149221    -0.00589591  -0.103907    -0.0112276    0.0794827    0.0521628
  0.0765636     0.0903719    0.0104904    0.0232545   -0.0247949    0.12853       0.1589       0.112756    -0.145406      0.0720476    0.137016    -0.143931    -0.182431    0.118576    0.0210007   0.0410434    0.0791239   -0.07979      0.041702    -0.00166247  -0.0341621   -0.115759    -0.0456086   -0.00699147   0.0351178   -0.0878222
 -0.127409     -0.0382522   -0.0296843    0.0456558    0.0138379    0.109995     -0.0441392   -0.0823107   -0.0763467     0.118945    -0.0350782   -0.0700978   -0.0365477   0.0673802   0.14688    -0.0910137    0.189111    -0.0409934    0.0114302    0.0935953    0.021674    -0.0647351   -0.121568    -0.294226    -0.0476529   -0.16273
 -0.129672      0.00389464  -0.0743491    0.144828    -0.102035     0.133629      0.0169941    0.324273     0.148562      0.0254775   -0.0197025   -0.146719    -0.253775   -0.0427861   0.100646    0.0952041   -0.0420732    0.108543    -0.0458494   -0.161151     0.167979    -0.0983812    0.181067    -0.0178198   -0.136953     0.146921
 -0.129607     -0.00354132  -0.14729      0.144738    -0.102042     0.127488     -0.0654115   -0.223894     0.148543     -0.100157    -0.0319294   -0.1447      -0.0166746  -0.0706435   0.0930919   0.0192658   -0.123647     0.220672     0.0546545   -0.154987     0.134677    -0.0971528    0.138848    -0.0398309   -0.140203     0.224794
  0.137427     -0.0388952    0.131002    -0.0111859   -0.0710927   -0.00745255   -0.0133396    0.0057632   -0.0182835    -0.0636698   -0.171758    -0.0199087   -0.0720819   0.07445    -0.0218969  -0.010401    -0.0947874   -0.102288     0.0981149   -0.142244     0.0470783    0.0366497   -0.0715194   -0.49391      0.0602491    0.0333361
  0.0429918    -0.00886241  -0.303279    -0.0354818   -0.0256243    0.0257048     0.0337878   -0.00140344  -0.0168221    -0.0341394    0.00859771  -0.014912    -0.148128    0.0627667  -0.0170045  -0.00217863  -0.19717     -0.151849     0.201154    -0.195454     0.145953     0.00165682  -0.138656     0.600848     0.110097     0.0439059
 -0.0539491    -0.00321866  -0.192151     0.0777086   -0.0614573    0.0204841    -1.59825e-5   0.222039     0.118553     -0.0675013   -0.0536166    0.014629     0.110629    0.0426176  -0.0987797  -0.0590577   -0.170203     0.0620671   -0.00288508   0.139183     0.0806224   -0.0793376   -0.648978    -0.0325061    0.0892946   -0.152182
  0.0304622     0.0363773   -0.202319    -0.112478    -0.00850039   0.0598681    -0.0416918    0.16632      0.222165     -0.107312     0.0245564    0.010704     0.166748    0.160132    0.0254991  -0.0498453   -0.129727     0.0920272   -0.00673378  -0.0161175    0.0655498   -0.0835323    0.685997    -0.0255967    0.195115     0.122928
  0.0746274    -0.0857244    0.053179    -0.0701827    0.0388007   -0.0234088     0.0386404   -0.0333133   -0.0664192    -0.0568264   -0.164799    -0.0641954    0.0140227  -0.115171    0.0558827  -0.0811484    0.00030404  -0.120856     0.0646553    0.0559207    0.0247798   -0.0827576    0.166729    -0.161563     0.0670142   -0.0341985
 -0.0583952     0.128501     0.0677363   -0.0802114   -0.047303    -0.0656954     0.186259    -0.0984131   -0.0469533    -0.120012    -0.0793171   -0.104495    -0.118947    0.0141466  -0.164319    0.0150124   -0.0230829   -0.178869    -0.0224317   -0.179806     0.118097    -0.0580379    0.110831    -0.153049     0.0292847    0.0313385
 -0.184097      0.0666095   -0.0305665    0.065297    -0.114832    -0.0265316    -0.0936009   -0.0309183   -0.193278      0.0166511    0.0112061    0.175416     0.0863061   0.136181   -0.0294099   0.0439413   -0.258999     0.0696579    0.0514808   -0.040505     0.109587    -0.067916    -0.181044     0.165954    -0.0377413   -0.0657692
 -0.000973469  -0.0931861    0.00444164  -0.00884804   0.0809049   -0.000541607   0.0898742   -0.177657    -0.158527      0.00358361   0.0527514    0.0173459   -0.148338    0.153758    0.0714559   0.235474     0.0178235    0.0665293   -0.0133826    0.0229344    0.0722259    0.161334     0.0639293    0.0746089   -0.170526    -0.115572
  0.151304     -0.00140815   0.0923504   -0.0847208    0.0262896    0.123255     -0.0300218   -0.11085      0.0929103    -0.0538803    0.158025     0.0269238    0.158653   -0.0148016  -0.22115    -0.065848     0.157195     0.080019     0.0303376    0.104568    -0.02583     -0.0409891    0.149443     0.0418084   -0.00425717   0.0784085
  0.138167     -0.114813     0.289795    -0.428802    -0.143139     0.0430507    -0.0307839    0.126231     0.0932606    -0.0505378    0.270726    -0.128861     0.0906012  -0.394817    0.60098    -0.0231796   -0.131939     0.153539    -0.160086     0.607284    -0.0242293   -0.0525566    0.14579      0.0485104    0.0360686   -0.13765
  0.0396471    -0.0304575   -0.0898958   -0.0795719    0.0679149    0.139614     -0.0202464    0.071935     0.0837308    -0.0230656   -0.0404797    0.00444689  -0.0490716  -0.0258164  -0.0684143   0.0888454   -0.0810579    0.0887642    0.0185221    0.0338935   -0.00649263   0.0679466    0.204646     0.0270589   -0.0155586   -0.0561384
 -0.0534337     0.041899     0.00251044  -0.189314     0.082658     0.169574      0.0820217   -0.28936      0.0517417    -0.0728381    0.086698     0.0442998    0.155816   -0.138048   -0.0951451  -0.102731    -0.14445     -0.15888      0.0360283    0.130743     0.139328    -0.141076    -0.0597004    0.140673     0.0620272   -0.0203916
 -0.00279614    0.0436846   -0.0480738    0.0179293    0.0323431    0.104896      0.0793195    0.163674     0.0512351     0.0426998   -0.0244619    0.00234082   0.0147916  -0.14899    -0.0611635   0.135488    -0.0862571    0.0980912   -0.0436578   -0.0710992   -0.114569     0.117707     0.0919386    0.0500988   -0.0452097   -0.0477096
  0.0563155    -0.149145    -0.0711607    0.056982     0.0865977    0.0513301    -0.172535     0.166313    -0.0447823    -0.0580829    0.00558707  -0.0075695   -0.0197622   0.0279951  -0.0125415  -0.179526    -0.145182    -0.068871    -0.0680351   -0.0839057    0.135778    -0.095839    -0.169371     0.0260319   -0.229515    -0.0180294
  0.11723       0.0234821    0.00443334  -0.0500034    0.0181872   -0.10857      -0.0204181    0.048529     0.0359336     0.063957     0.0392114    0.0375824    0.0878708  -0.10158    -0.0217273  -0.149916    -0.0930024    0.00402981  -0.150888    -0.154428    -0.205615     0.0498026   -0.242278     0.0308422    0.0930767    0.00268605
 -0.0563674     0.0384948    0.0536345    0.0485713   -0.0729093    0.0504003    -0.12325      0.0353228    0.0480745     0.151887    -0.00824538  -0.0534272   -0.126657   -0.0979781  -0.141282   -0.0283483    0.153127     0.0912012   -0.0667526   -0.100092     0.123565     0.107364    -0.198471     0.0343323    0.176142     0.105765
  0.011266      0.0996975   -0.124514     0.0696391   -0.0750761   -0.0270448    -0.0554715    0.0502727   -0.0288849     0.0497843    0.0886411    0.0856675   -0.0078911  -0.141015   -0.0872188   0.0432267    0.0736277    0.0461349    0.0526204   -0.0316261    0.0800662    0.038215    -0.00334794   0.0229329    0.190916    -0.0825614
  0.0085457    -0.0486112    0.0185398   -0.00571663  -0.037249     0.0214233    -0.0685446    0.130304     0.000126964   0.0190073   -0.127723     0.00771653   0.0128612   0.0428584  -0.0218387  -0.0935497    0.247631     0.125093    -0.0993676   -0.0610979    0.151685     0.0989056    0.164834    -0.00556478  -0.136587     0.0912737
 -0.0731558     0.151419     0.0690199   -0.0307463    0.0241429    0.0680123     0.0825316   -0.0913248    0.0194855    -0.0388665   -0.024585    -0.0985684   -0.0228481  -0.0244731   0.135523   -0.0228024   -0.127926    -0.0119514   -0.080455     0.0898683    0.0629112   -0.166398    -0.0724058    0.0275959   -0.149445     0.00222078
  0.0453505     0.0420258    0.0801061    0.0920599   -0.00105791   0.0816031    -0.0148997    0.255182     0.0547        0.00122306   0.012915     0.0322658    0.0542679   0.0209294   0.0212866   0.203713     0.111481     0.0357782   -0.039007     0.0498148   -0.0743003    0.0721846   -0.0503261    0.0953806   -0.10448     -0.0428301
  0.0873632     0.243198     0.0504548    0.207037     0.12002     -0.28095       0.0310971   -0.20064     -0.239827     -0.121928    -0.0994425    0.0846195   -0.129979    0.16645    -0.0964164  -0.0408404   -0.00614198  -0.00792432  -0.0424369    0.0676035   -0.049966     0.0332901   -0.0407031   -0.149977     0.0946541   -0.0495516
  0.0304575     0.016526     0.0169707    0.0177406    0.0522078    0.112114      0.0196426   -0.0730755   -0.072471      0.0814368   -0.0164085   -0.081007     0.0404016  -0.109938    0.0692315   0.0571277    0.00885096  -0.0367609   -0.037383     0.110028     0.0264951   -0.00747068   0.0472912    0.0510128    0.0196797   -0.00383431
 -0.0429274    -0.117528    -0.0065541   -0.049846    -0.0507912   -0.0686759    -0.0996474    0.0528564   -0.0852915    -0.0604618    0.0504186    0.0402517   -0.0714619  -0.0627704  -0.054525   -0.0704484   -0.096892    -0.0829685   -0.102656    -0.0106793    0.0161938    0.0617145   -0.0627457   -0.065805     0.0881635   -0.0553959
  0.0234102     0.0999568   -0.0610706    0.018131     0.0429262   -0.124217      0.098909     0.049491    -0.11093       0.0472837   -0.0652991   -0.00738964  -0.0175861   0.0689128  -0.164055    0.0743568   -0.0992983   -0.100131     0.0624333   -0.0487219   -0.0993903   -0.0771143   -0.0186719   -0.0769776    0.0317175    0.00521477
 -0.0067436     0.0302023    0.0151105   -0.0396051    0.0938494   -0.00545881    0.0262932    0.0240958   -0.099447      0.12427      0.0136196    0.0296802   -0.234675    0.0843673   0.0103131   0.00384813   0.0239256    0.14846     -0.158521     0.184319     0.156938     0.076003     0.112167     0.145702    -0.00815589   0.0835494
  0.0491018     0.126063     0.0150302    0.0912431    0.0445781   -0.0391354    -0.0546739    0.124534    -0.00280759    0.0997932   -0.0220223   -0.0830605    0.173336    0.168591    0.200728    0.159339    -0.323648     0.0294516    0.10864     -0.0324302   -0.0583604   -0.134294     0.0354171   -0.0048953    0.0188069   -0.0941196[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     14
│     17
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.059103
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      5
│      6
│     14
│      ⋮
│     17
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.038440
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│     13
│     14
│     17
│     22
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.044443
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      5
│      6
│     14
│      ⋮
│     17
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.039160
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     14
│     17
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.045732
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      5
│      6
│     13
│      ⋮
│     22
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.030925
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     14
│     17
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.051215
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      5
│      6
│     14
│      ⋮
│     17
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.033744
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│     13
│     14
│     17
│     22
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.043159
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      5
│      6
│     14
│      ⋮
│     17
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.039071
┌ Info: EM with 100000 data points 10 iterations avll -1.039071
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.316889e+05
      1       6.825378e+05      -2.491511e+05 |       32
      2       6.506915e+05      -3.184629e+04 |       32
      3       6.361044e+05      -1.458713e+04 |       32
      4       6.273985e+05      -8.705838e+03 |       32
      5       6.216275e+05      -5.771066e+03 |       32
      6       6.179231e+05      -3.704327e+03 |       32
      7       6.158463e+05      -2.076877e+03 |       32
      8       6.144941e+05      -1.352155e+03 |       32
      9       6.131585e+05      -1.335635e+03 |       32
     10       6.114197e+05      -1.738743e+03 |       32
     11       6.094432e+05      -1.976547e+03 |       32
     12       6.079999e+05      -1.443303e+03 |       32
     13       6.072816e+05      -7.182934e+02 |       32
     14       6.069825e+05      -2.991230e+02 |       32
     15       6.068375e+05      -1.449672e+02 |       32
     16       6.067673e+05      -7.016683e+01 |       32
     17       6.067257e+05      -4.157385e+01 |       32
     18       6.066815e+05      -4.424662e+01 |       32
     19       6.066408e+05      -4.065038e+01 |       32
     20       6.066028e+05      -3.806584e+01 |       31
     21       6.065611e+05      -4.168262e+01 |       32
     22       6.065195e+05      -4.163312e+01 |       31
     23       6.064736e+05      -4.587461e+01 |       32
     24       6.064300e+05      -4.360639e+01 |       31
     25       6.063960e+05      -3.397463e+01 |       32
     26       6.063612e+05      -3.478643e+01 |       32
     27       6.063352e+05      -2.598399e+01 |       31
     28       6.063189e+05      -1.629874e+01 |       29
     29       6.063099e+05      -9.075904e+00 |       29
     30       6.063028e+05      -7.074269e+00 |       29
     31       6.062961e+05      -6.735645e+00 |       31
     32       6.062915e+05      -4.557971e+00 |       24
     33       6.062886e+05      -2.889296e+00 |       18
     34       6.062864e+05      -2.230054e+00 |       18
     35       6.062846e+05      -1.734695e+00 |       20
     36       6.062831e+05      -1.588358e+00 |       23
     37       6.062809e+05      -2.124725e+00 |       18
     38       6.062776e+05      -3.335439e+00 |       22
     39       6.062734e+05      -4.162443e+00 |       22
     40       6.062697e+05      -3.773287e+00 |       21
     41       6.062648e+05      -4.859399e+00 |       23
     42       6.062599e+05      -4.901324e+00 |       23
     43       6.062545e+05      -5.390023e+00 |       27
     44       6.062481e+05      -6.395873e+00 |       26
     45       6.062416e+05      -6.472756e+00 |       22
     46       6.062349e+05      -6.762180e+00 |       26
     47       6.062271e+05      -7.768128e+00 |       26
     48       6.062181e+05      -9.036568e+00 |       27
     49       6.062123e+05      -5.801472e+00 |       26
     50       6.062067e+05      -5.532414e+00 |       28
K-means terminated without convergence after 50 iterations (objv = 606206.7397032636)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.325087
[ Info: iteration 2, average log likelihood -1.297094
[ Info: iteration 3, average log likelihood -1.268713
[ Info: iteration 4, average log likelihood -1.229409
[ Info: iteration 5, average log likelihood -1.185259
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.129857
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     11
│     15
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.096897
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.105325
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     20
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.048092
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.061743
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     15
│     18
│     19
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.043330
[ Info: iteration 12, average log likelihood -1.095546
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     10
│     20
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.031083
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.069851
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     15
│     19
│     26
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.047813
[ Info: iteration 16, average log likelihood -1.101342
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     10
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.047389
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     20
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.036342
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     11
│     15
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.040424
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.087786
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     10
│     18
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.060075
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.069034
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     15
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.030669
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.059555
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     10
│     11
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.060931
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     20
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.063863
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.064975
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     26
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.052269
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     10
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.070946
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.069196
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.033553
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     10
│     20
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.006759
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.095626
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.063368
[ Info: iteration 35, average log likelihood -1.062757
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     10
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.019461
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     15
│     20
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.056030
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.065375
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.055055
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.058414
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.022773
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│     10
│     11
│     20
│     23
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.024993
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.096218
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.060711
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     15
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.011996
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     10
│     20
│     26
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.036224
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.101043
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.065998
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.044995
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     10
│     20
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -0.997669
┌ Info: EM with 100000 data points 50 iterations avll -0.997669
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0419335   -0.031732     -0.0907417    -0.0783461    0.0680099    0.142896    -0.0195814    0.0751067    0.0891101    -0.0249648   -0.0389071    0.00506583   -0.0510345  -0.029562    -0.0690995    0.0896967   -0.0828749    0.092894     0.0186318     0.0343919   -0.0023595    0.0717056    0.205532     0.0309452   -0.0155092   -0.0568068
 -0.0613535    0.0216522     0.000492678   0.0330307   -0.0762509    0.0556707   -0.185346     0.344062    -0.0686952    -0.0838325    0.00453639   0.0671868    -0.0963658   0.0264146    0.0214298    0.206638     0.216574     0.0251834   -0.0588595     0.0943626   -0.0250633    0.066228    -0.0853627    0.182351    -0.08169     -0.0092855
 -0.0195329    0.189104     -0.0537548     0.155285     0.108245    -0.108608     0.291041     0.00900083   0.0517606     0.081697    -0.10772      0.175443      0.12907     0.0727816   -0.00937829   0.178205     0.0349762   -0.0650047    0.067667     -0.0184277   -0.0257057   -0.0845211    0.0219027   -0.0407387   -0.0567334    0.189981
  0.0115252    0.0993565    -0.123297      0.0691773   -0.0730006   -0.0261318   -0.0583828    0.0516499   -0.0286543     0.047917     0.087982     0.0841237    -0.0079369  -0.140788    -0.0884042    0.0464317    0.0745623    0.0471782    0.0531765    -0.0335923    0.0795945    0.0370927   -0.00161598   0.0221046    0.186644    -0.0810658
  0.0816391    0.0905199     0.0122714     0.0229203   -0.0247715    0.129115     0.159489     0.11397     -0.144738      0.0730958    0.136793    -0.144232     -0.188818    0.121267     0.0194071    0.0396159    0.079441    -0.0787305    0.0396837    -0.0026425   -0.0350305   -0.116146    -0.0538472   -0.00178933   0.0337789   -0.0907754
  0.0304297   -0.192035     -0.121846     -0.027779    -0.0754321   -0.0669656   -0.237169     0.115452    -0.147075     -0.138637    -0.0171876    0.0274035     0.0960214  -0.0893931    0.0542564    0.0483687   -0.118414    -0.0778412   -0.0570503    -0.0121633    0.0774931   -0.0965693   -0.0276665    0.0225568    0.119521    -0.00132896
  0.0658277    0.0627353    -0.0713609    -0.0389464    0.135753    -0.107278    -0.139102    -0.0610629    0.0175351     0.00295069  -0.102568    -0.07819      -0.0760779   0.0181172   -0.0291274   -0.0826274   -0.019359    -0.109866     0.0525729     0.236912    -0.147724    -0.00809118  -0.104343    -0.00950057   0.0793573    0.0506755
  0.0919846   -0.024628     -0.0741663    -0.0221552   -0.0496634    0.00806998   0.00894717   0.00242425  -0.017457     -0.0498619   -0.0876426   -0.017598     -0.107863    0.0688818   -0.0198897   -0.00650368  -0.143665    -0.125697     0.146627     -0.163719     0.0940677    0.0201166   -0.10312      0.0229953    0.083741     0.0390218
 -0.0599462    0.122792      0.066642     -0.0796966   -0.0414551   -0.0682362    0.179019    -0.099051    -0.0560736    -0.117982    -0.0817007   -0.104455     -0.114844    0.0102445   -0.155983     0.00966189  -0.0218383   -0.180062    -0.0214564    -0.17454      0.112254    -0.0607981    0.113884    -0.152749     0.0355858    0.0328948
  0.147638    -0.0180165     0.12247      -0.136365     0.00149965   0.110433    -0.0295404   -0.0756915    0.0932141    -0.0534039    0.175459     0.00329656    0.151053   -0.0714363   -0.10413     -0.0575649    0.118335     0.0921397   -0.000225931   0.176308    -0.0251587   -0.0434797    0.148718     0.042377     0.00233761   0.0523863
  0.0532026    0.189038      0.0663351     0.237835     0.0498338   -0.267552     0.226096     0.00857193  -0.189586     -0.18422     -0.172268    -0.197243     -0.155561    0.101963    -0.0908986   -0.0414098   -0.0132623   -0.123532    -0.0317938     0.020835    -0.00836708  -0.244016    -0.194366    -0.236166     0.185809    -0.00697026
 -0.0730863    0.15001       0.0688153    -0.0307772    0.0248042    0.0675838    0.0812455   -0.0922429    0.0194702    -0.0390945   -0.0244065   -0.0956217    -0.0232102  -0.023246     0.134532    -0.0235633   -0.126505    -0.0120832   -0.0811326     0.0901171    0.0606945   -0.167104    -0.0762121    0.0311823   -0.153246     0.00220883
  0.175108    -0.174794      0.0676922    -0.00588615   0.0582912    0.0162943    0.00685878   0.0943081   -0.0767421     0.0092924   -0.173622    -0.028833      0.0443939  -0.147671     0.0868115   -0.0395022   -0.0203131   -0.0953635    0.0865405     0.147507    -0.00200901  -0.0800057    0.208234     0.0405652    0.0371242   -0.0381414
 -0.00325344   0.0421014    -0.0478655     0.0208533    0.0343828    0.105013     0.0802246    0.162476     0.0507447     0.0467563   -0.0242233    0.000671444   0.0163287  -0.148407    -0.0623408    0.137513    -0.0872045    0.0994833   -0.0446966    -0.0731094   -0.116107     0.120092     0.0912747    0.0523496   -0.0450389   -0.0456609
  0.0719174    0.0171158    -0.0719884    -0.106595    -0.0239216   -0.147441    -0.078643     0.089317    -0.244701      0.0221204   -0.0197918   -0.178476     -0.162029    0.0715253   -0.322508    -0.0239473   -0.230884    -0.137995     0.0683257    -0.0836815   -0.178096    -0.07942     -0.061283    -0.108785     0.117974    -0.170849
  0.0562092   -0.150074     -0.072795      0.0564101    0.0869955    0.0512971   -0.172224     0.166236    -0.0453647    -0.0569802    0.00596636  -0.0078968    -0.0191051   0.0279296   -0.0122063   -0.180863    -0.146528    -0.0693995   -0.0664943    -0.0839589    0.134707    -0.0962987   -0.16761      0.0261819   -0.229778    -0.0193292
  0.0491685    0.126234      0.0161297     0.0917322    0.0446462   -0.0387143   -0.0544061    0.128806    -0.00259638    0.0994862   -0.0226544   -0.0835479     0.17351     0.168311     0.201277     0.159194    -0.32485      0.0289926    0.110208     -0.0339769   -0.0579479   -0.132873     0.0364199   -0.00441251   0.0183825   -0.0940768
  0.116912     0.0200003    -0.00978253   -0.0496282    0.0198358   -0.112311    -0.0193363    0.0528265    0.0335876     0.0641755    0.0400301    0.0423736     0.0904667  -0.105505    -0.0220137   -0.148298    -0.0939089    0.00277506  -0.150935     -0.162201    -0.211335     0.05667     -0.242132     0.0287896    0.0918581    0.00831851
 -0.089491    -0.0207216    -0.013588      0.0293936   -0.0146853   -0.0150802    0.00377151  -0.109377    -0.179408      0.00782375   0.0290722    0.0932777    -0.0398992   0.146767     0.0219669    0.143406    -0.114137     0.0682674    0.0210405    -0.013952     0.0896613    0.0479436   -0.051091     0.120726    -0.109188    -0.0919027
 -0.0501664    0.0857843    -0.0379457     0.00219604   0.0119643    0.103085     0.162062    -0.259799    -0.0962932     0.0181888   -0.0497855   -0.0430302     0.0678499  -0.0527263    0.00161591   0.0875273    0.059205    -0.0189013   -0.00708127   -0.0204748    0.00115763  -0.0402155   -0.0609942   -0.0776127   -0.0320369    0.020727
 -0.0126838    0.0158776    -0.197412     -0.0143993   -0.0365596    0.0395614   -0.0198574    0.195884     0.169283     -0.0858957   -0.0180021    0.0125379     0.139326    0.0987847   -0.0386362   -0.0546849   -0.150838     0.0772772   -0.00459603    0.0636335    0.0733206   -0.0817892   -0.00715062  -0.0291154    0.138663    -0.0204305
 -0.0532209    0.041097      0.00486636   -0.191252     0.0816817    0.172073     0.0841674   -0.294134     0.0556972    -0.0739831    0.0886612    0.0441413     0.15731    -0.135063    -0.0978431   -0.103735    -0.147844    -0.162765     0.0417441     0.133367     0.141762    -0.146347    -0.0618943    0.142787     0.0531813   -0.0197758
  0.00869481  -0.0553272     0.0282963    -0.00497733  -0.0513199    0.0179963   -0.0693018    0.140586     0.000781266   0.0139762   -0.130599     0.0165517     0.0103222   0.0516792   -0.0234243   -0.10948      0.255598     0.137245    -0.0968327    -0.0689563    0.155975     0.0921301    0.165014    -0.00898678  -0.149845     0.100303
 -0.00631072   0.0301854     0.0159834    -0.0391898    0.0960316   -0.00651744   0.025172     0.0258808   -0.0999        0.124452     0.0138428    0.0310826    -0.235943    0.0857121    0.00923621   0.00383088   0.0221405    0.149313    -0.159273      0.183259     0.159154     0.0785613    0.111888     0.147253    -0.00717775   0.0835571
  0.0014491    0.116249     -0.0276629    -0.00101659   0.10602      0.144323    -0.109195    -0.0796636   -0.0600816     0.166481     0.134802    -0.0596341     0.0394672  -0.111761     0.046055     0.0829691   -0.0200713   -0.080371    -0.180679      0.125467     0.0739332    0.169191     0.0193642    0.0461843    0.0973256   -0.0610077
  0.13599      0.0688347     0.173501      0.149556     0.0691961    0.0931784    0.153997     0.174935     0.182222      0.0680857    0.0219204   -0.000260197   0.198453    0.0294116    0.0217314    0.190116     0.00986985   0.0499751   -0.0301835     0.00490048  -0.11884      0.0838992   -0.0282944    0.00767955  -0.114349    -0.0798224
 -0.12843      0.000922697  -0.106582      0.145576    -0.101459     0.124704    -0.0195712    0.0798888    0.145172     -0.0319897   -0.0289342   -0.144378     -0.150169   -0.0510506    0.0952249    0.0607463   -0.0822888    0.156647     0.00295361   -0.15417      0.151606    -0.0972764    0.164704    -0.0336603   -0.136116     0.178035
 -0.0538623    0.0360302     0.0570849     0.0490362   -0.0742574    0.0421778   -0.129315     0.0362328    0.0444325     0.1487      -0.0111523   -0.0602146    -0.133846   -0.0918618   -0.149122    -0.0389362    0.156217     0.100719    -0.0649137    -0.101028     0.121016     0.10232     -0.202882     0.0340547    0.177512     0.109226
 -0.128643    -0.0388402    -0.0276071     0.0461442    0.0148417    0.113484    -0.0439483   -0.0818131   -0.07696       0.120487    -0.0342477   -0.0705683    -0.0371124   0.0695615    0.14414     -0.0911338    0.190362    -0.0401856    0.0104987     0.0943845    0.0245447   -0.0620546   -0.122005    -0.294625    -0.0498862   -0.16282
  0.108335     0.261059      0.0644042     0.230667     0.149247    -0.340602    -0.00128712  -0.210918    -0.271253     -0.121257    -0.104233     0.138268     -0.158564    0.172853    -0.104647    -0.0576894   -0.0120022   -0.0144077   -0.0421625     0.0653221   -0.0441254    0.0577369   -0.019591    -0.161311     0.116732    -0.0750375
 -0.0180153    0.132257      0.0368592     0.0758643    0.0278595    0.0689044    0.0832613   -0.158959    -0.11081       0.0116868   -0.0197744   -0.140376     -0.0276494  -0.00427112   0.0531322    0.0376791    0.0342562    0.0596929   -0.0286616     0.129699    -0.0219258   -0.0777775   -0.034155     0.00776521  -0.0106653    0.033074
 -0.103636    -0.0499451     0.103881     -0.0701859   -0.0287473   -0.0755238    0.0244       0.00369708  -0.0265439     0.0124514    0.104365     0.05298      -0.22804    -0.0452802   -0.154279    -0.169958    -0.0845019   -0.0861522   -0.152827     -0.00692264  -0.0286014    0.211997    -0.101319    -0.140677     0.0652374   -0.103634[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.097565
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     15
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.055055
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.026728
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.999806
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.066939
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     23
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.030693
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.033908
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│     10
│     11
│     15
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.998902
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     15
│     23
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.042979
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     15
│     20
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.036466
┌ Info: EM with 100000 data points 10 iterations avll -1.036466
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.139519    -0.0951147    -0.121965     0.185307      0.0417206   -0.00933347   0.0161313     0.00422858  -0.0382359   -0.0434194   -0.105202   -0.0225      -0.0345835    0.054921     -0.198647   -0.0353376    -0.0800967    0.0649125    -0.129399     0.00619964  -0.0261117   -0.00925087    0.0651283   -0.0762147   -0.0172702   -0.0908343
  0.122311    -0.0167455    -0.200778    -0.269169      0.0970421   -0.06895     -0.0793211    -0.0185584   -0.0322719    0.018061     0.199197    0.0717648    0.020626     0.0125849     0.139912    0.125592     -0.0136609    0.0356938     0.0610306   -0.0557971   -0.0181149   -0.0109022     0.0499907    0.0743114   -0.0117285    0.0776837
 -0.0460899   -0.000197532  -0.218947    -0.132741     -0.0319827    0.0320937   -0.00427326   -0.0320539    0.00366008  -0.0206234    0.0442978  -0.147075    -0.0590941   -0.00517403    0.0130807  -0.0364473    -0.118738     0.0792821    -0.14714      0.101943     0.153477     0.0765537     0.0418598    0.148185     0.135627     0.170834
 -0.0990681    0.0266594    -0.10375     -0.153193     -0.0238521    0.0171576   -0.0198326    -0.00598152  -0.132689     0.0498941   -0.0562829   0.18471      0.11778      0.121729     -0.268851    0.0869708    -0.008311    -0.0825349    -0.0181519    0.0835214   -0.0977769    0.00286724   -0.0334913   -0.2474       0.208313    -0.12627
 -0.02908     -0.0368595    -0.0687157   -0.0927666     0.0150428    0.0971119   -0.159196     -0.0701621    0.0983672    0.165075     0.133856    0.150998     0.0174607    0.0217428    -0.057122    0.0370627     0.241066     0.271472     -0.0682424    0.134426    -0.144545    -0.00520518    0.161287     0.150546     0.152167    -0.0341301
  0.112612    -0.0425966    -0.138715     0.0942892     0.0373122   -0.0269062   -0.00508213   -0.0716722    0.0815773    0.168299     0.0308972  -0.104855    -0.159061    -0.0300645     0.0509862  -0.067376      0.0097912    0.120573     -0.121269     0.0665473    0.0603168   -0.118416      0.0910314   -0.0679837   -0.00328945   0.0612652
  0.0452508   -0.0180709    -0.00878097   1.18715e-5    0.109717    -0.0439937   -0.142788     -0.0432229   -0.100292     0.0858789    0.153374    0.171863     0.0832247   -0.00644417   -0.199961   -0.0413844    -0.101944     0.27904      -0.0394802    0.219267     0.0708469    0.149668      0.0662138    0.0466451   -0.0284702   -0.102381
 -0.00109078   0.152243      0.117031     0.171129     -0.101955     0.115584     0.24604      -0.0812058   -0.136856    -0.151803    -0.0706311   0.0954604   -0.22559      0.0234322     0.144037   -0.0896541     0.0142905    0.160243      0.030824     0.0808938    0.00268151   0.00546099   -0.0756965    0.0927561   -0.142514    -0.0154125
  0.0775736   -0.0788994    -0.0551849    0.0217737     0.0807532   -0.170393    -0.00675175    0.11524      0.0556598   -0.0822298   -0.0284419  -0.107294    -0.120982    -0.137503     -0.103126    0.196377     -0.162956    -0.0405893    -0.0603403    0.165932    -0.205288     0.0975782     0.100735    -0.15145     -0.0459843   -0.0201415
  0.14291      0.0903851    -0.0853349    0.0160749    -0.0361244   -0.0602012    0.000859133   0.0153769    0.170153     0.0705948   -0.0534448  -0.0267069    0.105789     0.168411      0.0138005  -0.116948     -0.0996781   -0.170635      0.00506276  -0.121555    -0.00651851  -0.0494473    -0.144617     0.0760085    0.0637732    0.0914362
 -0.0286416    0.0674717    -0.183699     0.00948036   -0.0899081   -0.177284    -0.121201      0.0939065   -0.0104447    0.108962     0.106391   -0.0281648    0.0563851    0.289082      0.067068   -0.0167399     0.014236    -0.0236676     0.0529739   -0.15027     -0.100856     0.018839     -1.30366e-5   0.0754489   -0.0408136   -0.121284
 -0.111352     0.245554      0.0985442    0.00985486   -0.343131    -0.0129575    0.0833957     0.0462528    0.171688    -0.0204121   -0.155033   -0.0775647   -0.172151     0.11037       0.047141   -0.0809889    -0.135965    -0.095822     -0.0730685   -0.0772266   -0.00978166   0.184842      0.0378675    0.0719826    0.013385    -0.0923518
  0.157929    -0.107781     -0.0351374   -0.0639847    -0.00221244   0.0842668    0.0402765     0.0560166   -0.109152     0.0433681    0.0180126  -0.0586053    0.177986    -0.0682979    -0.0368985   0.0576869     0.00532402  -0.0575694    -0.0935154    0.0128882   -0.130094     0.000119966  -0.102808     0.021684    -0.181906    -0.0538303
  0.0763373    0.0427227     0.0598915    0.0561992     0.137559     0.0716203   -0.146691     -0.054905    -0.127305     0.0550297   -0.221495   -0.181402    -0.0626623   -0.0214995     0.0937742   0.140515      0.17919     -0.00377957   -0.0659482   -0.040287     0.00539007  -0.101674      0.029517    -0.0573266   -0.0837882    0.0716794
 -0.0248087   -0.0185943    -0.148617     0.0292351    -0.0615744    0.125369    -0.0894112    -0.20469     -0.208128     0.0760177   -0.108159    0.367499    -0.0866138   -0.130178     -0.157043   -0.0471854    -0.0132748    0.122325     -0.0770771   -0.0688321   -0.0168703   -0.0945938    -0.0370225   -0.0854779   -0.216884    -0.204834
  0.0645504   -0.0909122     0.0503314   -0.000454328   0.106991    -0.081057     0.0226664    -0.0511447    0.103198    -0.0931644    0.0648615  -0.00619883  -0.00283405   0.124078      0.0467652   0.0204951     0.0611683    0.0586014    -0.0594125    0.164841     0.124163     0.112672     -0.170104    -0.115995    -0.104862    -0.0416884
 -0.119772    -0.116596      0.105374     0.0114738     0.0308481   -0.0314907   -0.00618671   -0.164183     0.0698004   -0.114096     0.181111    0.0129834   -0.0822916    0.0195331    -0.159175    0.268966     -0.0333534   -0.0979255     0.159603    -0.127737     0.132681     0.0319225     0.0513405    0.0752925   -0.0241308   -0.074853
 -0.0261425   -0.0300596    -0.00319581  -0.135719      0.0575096    0.0743809    0.191606     -0.00850932  -0.0415697    0.105796     0.106916    0.0946588    0.258387    -0.117344     -0.0512863  -0.000191049   0.0374833   -0.0283006    -0.0193588   -0.0394105    0.0969575    0.144175     -0.0584941    0.0404643    0.198818     0.111804
 -0.0616302    0.110817     -0.107037    -0.0635763    -0.0305594   -0.0762403   -0.0753878    -0.0302198    0.116238    -0.0794946    0.0242      0.0891651    9.04687e-5   0.0135266    -0.110145   -0.107498     -0.0249427   -0.0957803     0.0510011   -0.163519    -0.0681868    0.122274     -0.0966339    0.0565592   -0.139684     0.0142527
 -0.0913056    0.0692371     0.0303285   -0.0889332    -0.182044     0.164652     0.0268707    -0.215203     0.0268345   -0.118857     0.087467   -0.0206559   -0.0549355   -0.272499     -0.0123866   0.0104134     0.0690365    0.154992     -0.062933     0.0761642    0.0048083   -0.0473862    -0.120324    -0.0737433    0.0387739   -0.0861988
 -0.0102629    0.0317274    -0.205123     0.0891242    -0.17163     -0.0468239    0.0585326     0.057331     0.0188439    0.00475137  -0.0473019  -0.0406445    0.00420645  -0.107068     -0.0133723  -0.140467      0.0456157   -0.119035      0.0730065    0.0536494    0.0877043   -0.11625       0.0481126   -0.0943061    0.0141736   -0.110637
 -0.00138358   0.0369323     0.133729    -0.0734202     0.0577019   -0.129428     0.15525      -0.018593     0.0657385   -0.0217566   -0.0134323   0.0925915    0.0455381   -0.0159603     0.157448    0.0664251    -0.108673    -0.252895     -0.0410266    0.0577809    0.106033    -0.0311818    -0.0980303    0.209442     0.165295    -0.0396108
  0.0556158    0.170834     -0.09183      0.0311635    -0.0909031    0.0769643   -0.0555586    -0.0812346   -0.00262546   0.0752118    0.0841205   0.138684     0.125525    -0.000263507   0.204797    0.0858166     0.0331249   -0.00794728   -0.128145     0.0801293    0.0776183    0.139108     -0.114753    -0.15099     -0.0533835   -0.105022
  0.102669     0.0627484    -0.14751     -0.0357358    -0.0249554   -0.0352963    0.0322118     0.101734     0.173244     0.0433382    0.0744524  -0.0956228    0.125523     0.0549896    -0.16315     0.244799      0.113718     0.138459     -0.20993     -0.167073    -0.133279     0.0728179    -0.186893    -0.0753218   -0.050049    -0.00462847
 -0.0670248   -0.042105     -0.131065     0.0298964     0.0793927   -0.0754491   -0.0993248    -0.0361595    0.0509127    0.112252    -0.0609297  -0.142317     0.0996324   -0.0674383    -0.11745    -0.135943      0.0642488    0.0662433    -0.166921    -0.052887    -0.149695    -0.0167348     0.049499    -0.0561293   -0.148       -0.114386
 -0.101477    -0.0872945    -0.0609696    0.125036     -0.116716     0.156089    -0.14857       0.0586534   -0.107818     0.271911     0.141725   -0.0316542    0.0927338   -0.111379     -0.0305327  -0.136089     -0.0689134    0.175486     -0.0616254   -0.111278     0.0316457   -0.114668      0.0233365   -0.0690756   -0.026201    -0.0142537
 -0.031852     0.174491      0.130727    -0.144647      0.0784226   -0.0725999   -0.00366689    0.18539      0.228788     0.0555579    0.0665798  -0.00718394  -0.112203     0.0737638     0.0113807  -0.0809529     0.154411     0.134054      0.0325725    0.0710161    0.00397645   0.102342      0.0251124    0.111334    -0.0372223    0.210237
  0.0199414    0.0537653     0.00901408  -0.0355682    -0.0215434   -0.0510691    0.0151888     0.185184     0.177796     0.110094    -0.128296   -0.0088797    0.0502496   -0.0776575     0.0352954  -0.0808251    -0.0461554    0.142156     -0.200802    -0.0132417    0.104099    -0.0502838    -0.0428829    0.182259    -0.0748768   -0.0218493
  0.117465     0.0239894    -0.0939015   -0.00918158    0.0124567    0.204914    -0.0597263     0.0648991   -0.0184516    0.05835     -0.196167    0.0232014   -0.0418598    0.0872522     0.0824997   0.191046      0.100343     0.00859667   -0.112795    -0.00115056   0.0129807    0.126372     -0.087223    -0.0147232   -0.0502442   -0.0186055
  0.130511     0.0878355     0.0115881   -0.123767      0.0794539    0.0722344   -0.0704967    -0.0368643    0.00750099   0.0759536   -0.166085   -0.00684346   0.0266168   -0.0553135    -0.0856554   0.0556224     0.0118039   -0.0464656    -0.0551425    0.0694719   -0.00515845   0.141624     -0.127197     0.00748026  -0.0400402    0.0200113
 -0.0147581    0.0753131     0.0342607    0.0866827     0.130554    -0.103585    -0.248363      0.212387    -0.126382    -0.0807022    0.0374518  -0.108101     0.113069    -0.102531     -0.0582181   0.141799      0.064394     0.100446     -0.0907063   -0.148585    -0.0275615   -0.133182      0.0618152   -0.0430461   -0.0242363    0.0052444
  0.0662258   -0.0649951     0.0938069    0.112611      0.167376    -0.117754     0.0576056    -0.0860045    0.110132     0.149222     0.152179   -0.0759828   -0.015283    -0.0223721     0.0182289  -0.0167761     0.243026    -0.000902002  -0.0524965    0.16216     -0.0175556    0.0661938    -0.046752    -0.0149904   -0.10952     -0.0656501kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4276685338309827
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.427687
[ Info: iteration 2, average log likelihood -1.427637
[ Info: iteration 3, average log likelihood -1.427602
[ Info: iteration 4, average log likelihood -1.427561
[ Info: iteration 5, average log likelihood -1.427509
[ Info: iteration 6, average log likelihood -1.427440
[ Info: iteration 7, average log likelihood -1.427336
[ Info: iteration 8, average log likelihood -1.427149
[ Info: iteration 9, average log likelihood -1.426769
[ Info: iteration 10, average log likelihood -1.426020
[ Info: iteration 11, average log likelihood -1.424838
[ Info: iteration 12, average log likelihood -1.423588
[ Info: iteration 13, average log likelihood -1.422767
[ Info: iteration 14, average log likelihood -1.422398
[ Info: iteration 15, average log likelihood -1.422260
[ Info: iteration 16, average log likelihood -1.422209
[ Info: iteration 17, average log likelihood -1.422189
[ Info: iteration 18, average log likelihood -1.422182
[ Info: iteration 19, average log likelihood -1.422179
[ Info: iteration 20, average log likelihood -1.422177
[ Info: iteration 21, average log likelihood -1.422177
[ Info: iteration 22, average log likelihood -1.422176
[ Info: iteration 23, average log likelihood -1.422176
[ Info: iteration 24, average log likelihood -1.422176
[ Info: iteration 25, average log likelihood -1.422176
[ Info: iteration 26, average log likelihood -1.422176
[ Info: iteration 27, average log likelihood -1.422176
[ Info: iteration 28, average log likelihood -1.422175
[ Info: iteration 29, average log likelihood -1.422175
[ Info: iteration 30, average log likelihood -1.422175
[ Info: iteration 31, average log likelihood -1.422175
[ Info: iteration 32, average log likelihood -1.422175
[ Info: iteration 33, average log likelihood -1.422175
[ Info: iteration 34, average log likelihood -1.422175
[ Info: iteration 35, average log likelihood -1.422175
[ Info: iteration 36, average log likelihood -1.422175
[ Info: iteration 37, average log likelihood -1.422175
[ Info: iteration 38, average log likelihood -1.422175
[ Info: iteration 39, average log likelihood -1.422175
[ Info: iteration 40, average log likelihood -1.422175
[ Info: iteration 41, average log likelihood -1.422175
[ Info: iteration 42, average log likelihood -1.422175
[ Info: iteration 43, average log likelihood -1.422175
[ Info: iteration 44, average log likelihood -1.422175
[ Info: iteration 45, average log likelihood -1.422175
[ Info: iteration 46, average log likelihood -1.422175
[ Info: iteration 47, average log likelihood -1.422175
[ Info: iteration 48, average log likelihood -1.422175
[ Info: iteration 49, average log likelihood -1.422175
[ Info: iteration 50, average log likelihood -1.422175
┌ Info: EM with 100000 data points 50 iterations avll -1.422175
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.427686962035002
│     -1.4276366468457473
│      ⋮
└     -1.422174706453879
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422189
[ Info: iteration 2, average log likelihood -1.422135
[ Info: iteration 3, average log likelihood -1.422092
[ Info: iteration 4, average log likelihood -1.422041
[ Info: iteration 5, average log likelihood -1.421979
[ Info: iteration 6, average log likelihood -1.421902
[ Info: iteration 7, average log likelihood -1.421813
[ Info: iteration 8, average log likelihood -1.421718
[ Info: iteration 9, average log likelihood -1.421625
[ Info: iteration 10, average log likelihood -1.421541
[ Info: iteration 11, average log likelihood -1.421470
[ Info: iteration 12, average log likelihood -1.421413
[ Info: iteration 13, average log likelihood -1.421368
[ Info: iteration 14, average log likelihood -1.421333
[ Info: iteration 15, average log likelihood -1.421305
[ Info: iteration 16, average log likelihood -1.421282
[ Info: iteration 17, average log likelihood -1.421263
[ Info: iteration 18, average log likelihood -1.421246
[ Info: iteration 19, average log likelihood -1.421231
[ Info: iteration 20, average log likelihood -1.421217
[ Info: iteration 21, average log likelihood -1.421205
[ Info: iteration 22, average log likelihood -1.421192
[ Info: iteration 23, average log likelihood -1.421180
[ Info: iteration 24, average log likelihood -1.421168
[ Info: iteration 25, average log likelihood -1.421156
[ Info: iteration 26, average log likelihood -1.421145
[ Info: iteration 27, average log likelihood -1.421133
[ Info: iteration 28, average log likelihood -1.421121
[ Info: iteration 29, average log likelihood -1.421109
[ Info: iteration 30, average log likelihood -1.421098
[ Info: iteration 31, average log likelihood -1.421086
[ Info: iteration 32, average log likelihood -1.421074
[ Info: iteration 33, average log likelihood -1.421063
[ Info: iteration 34, average log likelihood -1.421052
[ Info: iteration 35, average log likelihood -1.421042
[ Info: iteration 36, average log likelihood -1.421031
[ Info: iteration 37, average log likelihood -1.421021
[ Info: iteration 38, average log likelihood -1.421012
[ Info: iteration 39, average log likelihood -1.421003
[ Info: iteration 40, average log likelihood -1.420995
[ Info: iteration 41, average log likelihood -1.420987
[ Info: iteration 42, average log likelihood -1.420980
[ Info: iteration 43, average log likelihood -1.420973
[ Info: iteration 44, average log likelihood -1.420967
[ Info: iteration 45, average log likelihood -1.420962
[ Info: iteration 46, average log likelihood -1.420956
[ Info: iteration 47, average log likelihood -1.420952
[ Info: iteration 48, average log likelihood -1.420947
[ Info: iteration 49, average log likelihood -1.420944
[ Info: iteration 50, average log likelihood -1.420940
┌ Info: EM with 100000 data points 50 iterations avll -1.420940
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4221892681110955
│     -1.4221352285381705
│      ⋮
└     -1.4209401705661815
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420947
[ Info: iteration 2, average log likelihood -1.420880
[ Info: iteration 3, average log likelihood -1.420815
[ Info: iteration 4, average log likelihood -1.420734
[ Info: iteration 5, average log likelihood -1.420630
[ Info: iteration 6, average log likelihood -1.420501
[ Info: iteration 7, average log likelihood -1.420353
[ Info: iteration 8, average log likelihood -1.420202
[ Info: iteration 9, average log likelihood -1.420063
[ Info: iteration 10, average log likelihood -1.419946
[ Info: iteration 11, average log likelihood -1.419854
[ Info: iteration 12, average log likelihood -1.419784
[ Info: iteration 13, average log likelihood -1.419730
[ Info: iteration 14, average log likelihood -1.419689
[ Info: iteration 15, average log likelihood -1.419657
[ Info: iteration 16, average log likelihood -1.419630
[ Info: iteration 17, average log likelihood -1.419607
[ Info: iteration 18, average log likelihood -1.419586
[ Info: iteration 19, average log likelihood -1.419566
[ Info: iteration 20, average log likelihood -1.419547
[ Info: iteration 21, average log likelihood -1.419529
[ Info: iteration 22, average log likelihood -1.419510
[ Info: iteration 23, average log likelihood -1.419491
[ Info: iteration 24, average log likelihood -1.419473
[ Info: iteration 25, average log likelihood -1.419453
[ Info: iteration 26, average log likelihood -1.419434
[ Info: iteration 27, average log likelihood -1.419415
[ Info: iteration 28, average log likelihood -1.419396
[ Info: iteration 29, average log likelihood -1.419377
[ Info: iteration 30, average log likelihood -1.419359
[ Info: iteration 31, average log likelihood -1.419342
[ Info: iteration 32, average log likelihood -1.419326
[ Info: iteration 33, average log likelihood -1.419311
[ Info: iteration 34, average log likelihood -1.419297
[ Info: iteration 35, average log likelihood -1.419284
[ Info: iteration 36, average log likelihood -1.419272
[ Info: iteration 37, average log likelihood -1.419261
[ Info: iteration 38, average log likelihood -1.419252
[ Info: iteration 39, average log likelihood -1.419243
[ Info: iteration 40, average log likelihood -1.419235
[ Info: iteration 41, average log likelihood -1.419228
[ Info: iteration 42, average log likelihood -1.419222
[ Info: iteration 43, average log likelihood -1.419216
[ Info: iteration 44, average log likelihood -1.419211
[ Info: iteration 45, average log likelihood -1.419206
[ Info: iteration 46, average log likelihood -1.419202
[ Info: iteration 47, average log likelihood -1.419198
[ Info: iteration 48, average log likelihood -1.419194
[ Info: iteration 49, average log likelihood -1.419191
[ Info: iteration 50, average log likelihood -1.419187
┌ Info: EM with 100000 data points 50 iterations avll -1.419187
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.420946862449199
│     -1.420879897258673
│      ⋮
└     -1.419187371719761
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419193
[ Info: iteration 2, average log likelihood -1.419136
[ Info: iteration 3, average log likelihood -1.419086
[ Info: iteration 4, average log likelihood -1.419029
[ Info: iteration 5, average log likelihood -1.418959
[ Info: iteration 6, average log likelihood -1.418874
[ Info: iteration 7, average log likelihood -1.418772
[ Info: iteration 8, average log likelihood -1.418658
[ Info: iteration 9, average log likelihood -1.418535
[ Info: iteration 10, average log likelihood -1.418410
[ Info: iteration 11, average log likelihood -1.418289
[ Info: iteration 12, average log likelihood -1.418177
[ Info: iteration 13, average log likelihood -1.418076
[ Info: iteration 14, average log likelihood -1.417988
[ Info: iteration 15, average log likelihood -1.417912
[ Info: iteration 16, average log likelihood -1.417847
[ Info: iteration 17, average log likelihood -1.417793
[ Info: iteration 18, average log likelihood -1.417746
[ Info: iteration 19, average log likelihood -1.417705
[ Info: iteration 20, average log likelihood -1.417670
[ Info: iteration 21, average log likelihood -1.417638
[ Info: iteration 22, average log likelihood -1.417609
[ Info: iteration 23, average log likelihood -1.417582
[ Info: iteration 24, average log likelihood -1.417557
[ Info: iteration 25, average log likelihood -1.417532
[ Info: iteration 26, average log likelihood -1.417509
[ Info: iteration 27, average log likelihood -1.417487
[ Info: iteration 28, average log likelihood -1.417465
[ Info: iteration 29, average log likelihood -1.417443
[ Info: iteration 30, average log likelihood -1.417423
[ Info: iteration 31, average log likelihood -1.417402
[ Info: iteration 32, average log likelihood -1.417383
[ Info: iteration 33, average log likelihood -1.417363
[ Info: iteration 34, average log likelihood -1.417344
[ Info: iteration 35, average log likelihood -1.417326
[ Info: iteration 36, average log likelihood -1.417309
[ Info: iteration 37, average log likelihood -1.417292
[ Info: iteration 38, average log likelihood -1.417276
[ Info: iteration 39, average log likelihood -1.417260
[ Info: iteration 40, average log likelihood -1.417245
[ Info: iteration 41, average log likelihood -1.417231
[ Info: iteration 42, average log likelihood -1.417217
[ Info: iteration 43, average log likelihood -1.417204
[ Info: iteration 44, average log likelihood -1.417191
[ Info: iteration 45, average log likelihood -1.417180
[ Info: iteration 46, average log likelihood -1.417168
[ Info: iteration 47, average log likelihood -1.417157
[ Info: iteration 48, average log likelihood -1.417147
[ Info: iteration 49, average log likelihood -1.417137
[ Info: iteration 50, average log likelihood -1.417127
┌ Info: EM with 100000 data points 50 iterations avll -1.417127
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4191932639448759
│     -1.4191364008264913
│      ⋮
└     -1.417127111488026
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417127
[ Info: iteration 2, average log likelihood -1.417056
[ Info: iteration 3, average log likelihood -1.416989
[ Info: iteration 4, average log likelihood -1.416910
[ Info: iteration 5, average log likelihood -1.416811
[ Info: iteration 6, average log likelihood -1.416687
[ Info: iteration 7, average log likelihood -1.416539
[ Info: iteration 8, average log likelihood -1.416371
[ Info: iteration 9, average log likelihood -1.416193
[ Info: iteration 10, average log likelihood -1.416016
[ Info: iteration 11, average log likelihood -1.415847
[ Info: iteration 12, average log likelihood -1.415692
[ Info: iteration 13, average log likelihood -1.415553
[ Info: iteration 14, average log likelihood -1.415430
[ Info: iteration 15, average log likelihood -1.415323
[ Info: iteration 16, average log likelihood -1.415229
[ Info: iteration 17, average log likelihood -1.415148
[ Info: iteration 18, average log likelihood -1.415078
[ Info: iteration 19, average log likelihood -1.415017
[ Info: iteration 20, average log likelihood -1.414964
[ Info: iteration 21, average log likelihood -1.414916
[ Info: iteration 22, average log likelihood -1.414874
[ Info: iteration 23, average log likelihood -1.414836
[ Info: iteration 24, average log likelihood -1.414802
[ Info: iteration 25, average log likelihood -1.414770
[ Info: iteration 26, average log likelihood -1.414741
[ Info: iteration 27, average log likelihood -1.414714
[ Info: iteration 28, average log likelihood -1.414689
[ Info: iteration 29, average log likelihood -1.414666
[ Info: iteration 30, average log likelihood -1.414643
[ Info: iteration 31, average log likelihood -1.414622
[ Info: iteration 32, average log likelihood -1.414602
[ Info: iteration 33, average log likelihood -1.414583
[ Info: iteration 34, average log likelihood -1.414564
[ Info: iteration 35, average log likelihood -1.414546
[ Info: iteration 36, average log likelihood -1.414529
[ Info: iteration 37, average log likelihood -1.414512
[ Info: iteration 38, average log likelihood -1.414495
[ Info: iteration 39, average log likelihood -1.414479
[ Info: iteration 40, average log likelihood -1.414464
[ Info: iteration 41, average log likelihood -1.414449
[ Info: iteration 42, average log likelihood -1.414434
[ Info: iteration 43, average log likelihood -1.414420
[ Info: iteration 44, average log likelihood -1.414406
[ Info: iteration 45, average log likelihood -1.414392
[ Info: iteration 46, average log likelihood -1.414379
[ Info: iteration 47, average log likelihood -1.414366
[ Info: iteration 48, average log likelihood -1.414353
[ Info: iteration 49, average log likelihood -1.414341
[ Info: iteration 50, average log likelihood -1.414329
┌ Info: EM with 100000 data points 50 iterations avll -1.414329
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4171267017366787
│     -1.4170561546231302
│      ⋮
└     -1.414328683736782
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4276685338309827
│     -1.427686962035002
│     -1.4276366468457473
│     -1.4276017619372003
│      ⋮
│     -1.414353028020359
│     -1.4143406989686573
└     -1.414328683736782
32×26 Array{Float64,2}:
 -0.584655     -0.608883     0.562482    -0.12487     -0.288839    -0.141197    0.0953523  -0.0247158   -0.288302   -0.226304    -0.398368   -0.213833    0.331886   -0.0601075    0.433455   -0.574955    0.021818    -0.101102   -0.368568   -0.645393    0.331295   -0.759539     0.11616    -0.260193    0.0565666  -0.0949542
 -0.267143     -0.416869     0.0235691   -0.0949193    0.0629401   -0.0747443   0.0131537   0.595906     0.0571788  -0.0291755    0.917378    0.0255241  -0.20994     0.0301513   -0.444537   -0.19499    -0.0860373   -0.186089    0.239687    0.10796    -0.107916   -1.03046     -0.111178   -0.46585    -0.179075    0.00189086
 -0.0727187     0.426524     0.411922    -0.294352    -0.363091    -0.301625   -0.199044    0.252865    -0.575776   -0.573728     0.309592    0.4271      0.0514485   0.531097    -0.336136   -0.356968   -0.19703     -0.167386    0.33029    -0.123991    0.269847    0.751565    -0.427926   -0.594264   -0.555901    0.320359
 -0.230312      0.74055     -0.00279081   0.10783      0.0196868    0.245527   -0.331737    0.606083    -0.639489   -0.0821122    0.38454     0.668089   -0.481323    0.24465      0.133847   -0.307919    0.454185    -0.0954758   0.106638    0.0805743   0.670271   -0.0546549   -0.761859   -0.0957169   0.75627     0.147584
 -0.299357      0.0879535    0.448456    -0.245549    -0.0349112   -0.3579     -0.138855    0.0697015    0.490317   -0.00146864   0.398603    0.0819209   0.0444275  -0.373524     0.143565    0.924733    0.0966992   -0.545809    0.489379    0.744986    0.412196    0.00515676   0.374043    0.235648   -0.0706518   0.322708
 -0.128364      0.0402872   -0.195274    -0.534255     0.430664    -0.432622   -0.588646   -0.512958     0.246607   -0.196324     0.474209   -0.225012    0.171266   -0.277638    -0.602524    0.739693   -0.298208     0.614348    0.0382965   0.819983    0.283308   -0.201448     0.905807   -0.197743    0.320591    0.109021
  0.168873      0.00953576   0.135117     0.471632    -0.275052    -0.223894   -0.178286    0.00607407  -0.130144    0.348945     0.0347236   0.249696   -0.658964   -0.580741    -0.0923198  -0.314053   -0.0356308    0.298272    0.0856853   1.04808    -0.303455   -0.614605    -0.073926    0.575612   -0.241742    0.398674
 -0.282276      0.013581     0.187402    -0.253775    -0.366352     0.670651   -0.291893   -0.013171     0.089009    0.179224    -0.684732    0.498467   -0.534057   -0.609604    -0.272181    0.504972    0.0312511   -0.399118    0.444417    0.948144   -0.331408   -0.0894337    0.574065   -0.66303     0.248674   -0.409678
  0.657576     -0.526973    -0.423864    -0.3643      -0.0144359    0.206831   -0.525415    0.356192     0.431648   -0.238631    -0.316989    0.0255483   0.34567    -0.25083      0.108726    0.572467   -0.412633     0.124752   -0.104338   -0.190229    0.0405987   0.411345     0.322393    0.170855   -0.430119   -0.223188
  0.252616     -0.59191     -0.0185598    0.190624    -0.172895    -0.0156573  -0.384613   -0.146538    -0.210914   -0.200035     0.239117   -0.245067    0.106531    0.158574    -0.0930273   0.109629   -0.0666422    0.318927   -0.193561   -0.0689062  -0.357907   -0.205976    -0.0493704  -0.505943   -0.868099    0.516457
  0.0167597    -0.0977554   -0.099726     0.291093     0.265769     0.0874991  -0.0204518  -0.506968    -0.651472    0.557526     0.444398    0.168819    0.258943   -0.169637     0.355652   -0.246751   -0.282896    -0.304995   -0.0584202  -0.316432   -0.74084     0.315978     0.590692   -0.0128703  -0.811915   -0.530646
 -0.407623     -0.181088    -0.142034    -0.00158291  -0.445327    -0.415817    0.70467    -0.710553     1.00474    -0.284259    -0.127775   -0.113901    0.38984    -0.419261     0.284782   -0.274556   -0.413841     0.353226    0.351018   -0.0136699  -0.724352    0.0479382    0.561329   -0.0140612  -1.10676    -0.335741
  0.516233      0.489426     0.182107     0.224303    -0.72687      0.0551773   0.213708    0.600703     0.169132    0.2612      -0.883012   -0.468757   -0.704396    0.300627    -0.155387   -0.0259835  -0.895273    -0.802908   -0.661411   -0.223055    0.324283    1.02916     -0.232507    0.278496    0.195972   -0.469229
  0.161646     -0.357184     0.191234     0.445542    -0.511256     0.537898    0.687459    0.207232     0.133306    0.0698852   -0.941664    0.267897   -0.238223    0.276932     0.59427    -0.279575    0.675152     0.391867   -0.344714   -0.804166   -0.489178    0.240343    -0.270321    0.668534    0.148162   -0.178251
  0.285344     -0.22957     -0.204063    -0.152633     0.0325575    0.142219   -0.542639    0.0987519   -0.109177    0.361359    -0.505509   -0.608906    0.036861   -0.057735    -0.245556    0.163977    0.184317     0.0292592   0.0148635   0.201192    0.160066    0.252642    -0.204774    0.0277375   0.319128   -0.0584603
  0.159467      0.488958    -0.352915     0.166457     0.336517    -0.0753196   0.47114    -0.470142     0.182659    0.143467     0.214126    0.391709   -0.0838068  -0.0887957    0.14174     0.0413162  -0.0561869    0.227428   -0.292785   -0.0102701  -0.340464    0.118814     0.126917    0.303232    0.0868482  -0.0519029
  0.408683      0.0150654   -0.0404654    0.118418     0.313915     0.37478    -0.167442    0.0902701   -0.534528    0.0633384   -0.351244   -0.156815   -0.0712578   0.0227967   -0.549887   -0.289194    0.148168     0.0152486  -0.622045   -0.293964    0.293338   -0.361991    -0.511728   -0.143867    0.51874    -0.0348039
 -0.0496848    -0.25812     -0.394372    -0.0117663   -0.352961     0.245825   -0.100765    0.0702014    0.284629    0.136072    -0.285006   -0.733619   -0.400462    0.293871    -0.508371   -0.12895     0.1237       0.619533   -0.148875   -0.0959983  -0.219209   -0.173613    -0.395911    0.0566636   0.626307   -0.136945
 -0.129264     -0.0408955   -0.454727     0.200578     0.229865    -0.753846   -0.0581821  -0.274394    -0.172656   -0.218434    -0.235952   -0.13736     0.824562    0.245891     0.301707    0.32008    -0.0786591    0.479845   -0.559785   -0.408207    0.259264    0.469905    -0.318466    0.345835   -0.0928803  -0.45614
  0.155711      0.584929    -0.434668     0.12006      0.288916     0.688506   -0.206211   -0.580617    -0.0177822  -0.324857     0.0236666  -0.230172    0.717706    0.475181     0.0159104   0.157436    0.200359     0.345323   -0.543875   -0.0903521   0.188732    0.908064    -0.284007   -0.237008    0.179196   -0.0585081
 -0.360573      0.368799    -0.103073     0.170529    -0.363915    -0.269522    0.12888     0.313836    -0.236271   -0.0261281   -0.0604248   0.384787    0.127337    0.316381     0.195814   -0.681725    0.47429     -0.669799    0.229753   -0.0288997  -0.126098    0.275204    -0.193653    0.473303   -0.228524   -0.179778
  0.00861267    0.177442    -0.348433     0.0260915    0.065511    -0.0147877   0.311473    0.156321    -0.0985892  -0.292379     0.208395    0.257098    0.111514    0.283388     0.208265   -0.658145    0.139233     0.412921   -0.27271    -0.683835   -0.0802341  -0.199527    -0.32631     0.0450193  -0.171061   -0.139266
 -0.25615      -0.0041908   -0.0356313   -0.649631     0.0554015   -0.616017    0.3727      0.0107465    0.0592725  -0.43796      0.133148   -0.0318483   0.105464    0.331625     0.0621827  -0.431051    0.44495      0.291375    0.432136    0.0525082  -0.118876    0.190124    -0.274118   -0.284502   -0.347371    0.581388
  0.520549      0.263086     0.315444    -0.535482     0.281054     0.0570259   0.367146    0.26812      0.878098    0.00416984   0.501514    0.0762725  -0.423413    0.219642     0.133363    0.0611768   0.239472     0.158543    0.302064   -0.284061   -0.0359952   0.210764    -0.0911257   0.646142   -0.236193    0.845
  0.0946646     0.472281    -0.297541     0.471111     0.247113     0.0906636  -0.320576    0.0978073    0.0233395  -0.0285767    0.652274    0.434234   -0.2604     -0.323186    -0.0369828   0.326498   -0.610114    -0.0621826   0.0404924  -0.0148074  -0.0192239  -0.00486193   0.264327   -0.0649793   0.0707275  -0.234506
 -0.245188      0.505552     0.162816     0.324289    -0.155866    -0.124326    0.615497   -0.416956    -0.160444    0.092019     0.444911    0.281728   -0.218408    0.140808    -0.0737843  -0.0567177   0.00237508  -0.0516912  -0.284752    0.443749   -0.0389968  -0.339496     0.0767556  -0.354891    0.154232    0.213723
 -0.232897      0.218463    -0.449532    -0.0788284    0.175042     0.15477     0.255785    0.123522     0.475346    0.300611    -0.388758   -0.110562   -0.0569037  -0.386608     0.206103    0.278428    0.135445    -0.273969   -0.112162    0.132282    0.102866   -0.145896     0.194299    0.542971    0.784743   -0.491327
  0.000482412  -0.278839     0.235401     0.408426     0.472067     0.225469    0.487801   -0.0353683    0.53818     1.06427     -0.144537   -0.171552    0.0839851  -0.257715    -0.0332634   0.524769    0.107623     0.199776   -0.52336     0.0387944  -0.299256   -0.320074     0.0745686   0.0493853  -0.211776   -0.541707
  0.110633     -0.167212     0.0957374   -0.510423    -0.0315633    0.0662499  -0.559852    0.0361997   -0.213073    0.15123     -0.266774   -0.258478    0.185111   -0.60066     -0.0315176  -0.253321    0.100381    -0.254005    0.658755   -0.0949087   0.347644    0.313206    -0.143239    0.146617    0.0243226  -0.0334819
  0.0528405    -0.265295     0.424052    -0.102876     0.0980573    0.0736265  -0.230045   -0.102648    -0.279384    0.641866    -0.211451   -0.336059    0.111016    0.52124     -0.368203    0.286522    0.0792505   -0.239855    0.0674804   0.230665    0.562856    0.539468    -0.0736855  -0.109607    0.34123     0.0349994
 -0.244651     -0.153022     0.109941    -0.0543642   -0.115211    -0.166357   -0.0655779   0.0935369    0.192644    0.0642116    0.0304133   0.0803702   0.0229456  -0.0743907    0.0595572   0.181805   -0.0610077   -0.0385655  -0.15859     0.138596   -0.0190237  -0.148315     0.0288694  -0.0407245  -0.0623411  -0.0125011
  0.308251      0.132316    -0.209158     0.0032819   -0.00434337   0.114309    0.0240294  -0.118238    -0.0468714  -0.0252164   -0.113967   -0.154954    0.0328534   0.00219028  -0.0790322   0.0686828   0.021965     0.175228    0.0140859  -0.0356063  -0.10465     0.271276     0.0432485  -0.0121992  -0.0835403  -0.0480082[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414317
[ Info: iteration 2, average log likelihood -1.414306
[ Info: iteration 3, average log likelihood -1.414294
[ Info: iteration 4, average log likelihood -1.414284
[ Info: iteration 5, average log likelihood -1.414273
[ Info: iteration 6, average log likelihood -1.414263
[ Info: iteration 7, average log likelihood -1.414253
[ Info: iteration 8, average log likelihood -1.414243
[ Info: iteration 9, average log likelihood -1.414234
[ Info: iteration 10, average log likelihood -1.414225
┌ Info: EM with 100000 data points 10 iterations avll -1.414225
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.568706e+05
      1       7.131450e+05      -2.437256e+05 |       32
      2       6.980918e+05      -1.505318e+04 |       32
      3       6.924026e+05      -5.689236e+03 |       32
      4       6.894010e+05      -3.001631e+03 |       32
      5       6.876060e+05      -1.794952e+03 |       32
      6       6.862852e+05      -1.320771e+03 |       32
      7       6.852060e+05      -1.079226e+03 |       32
      8       6.843191e+05      -8.868735e+02 |       32
      9       6.836074e+05      -7.117685e+02 |       32
     10       6.830303e+05      -5.770395e+02 |       32
     11       6.825465e+05      -4.838696e+02 |       32
     12       6.821431e+05      -4.033679e+02 |       32
     13       6.817696e+05      -3.734659e+02 |       32
     14       6.814334e+05      -3.361856e+02 |       32
     15       6.811258e+05      -3.076053e+02 |       32
     16       6.808569e+05      -2.689746e+02 |       32
     17       6.806002e+05      -2.566936e+02 |       32
     18       6.803620e+05      -2.381475e+02 |       32
     19       6.801296e+05      -2.323947e+02 |       32
     20       6.799016e+05      -2.280125e+02 |       32
     21       6.797071e+05      -1.945301e+02 |       32
     22       6.795298e+05      -1.772395e+02 |       32
     23       6.793687e+05      -1.611131e+02 |       32
     24       6.792183e+05      -1.503908e+02 |       32
     25       6.790822e+05      -1.361009e+02 |       32
     26       6.789656e+05      -1.166191e+02 |       32
     27       6.788657e+05      -9.990012e+01 |       32
     28       6.787755e+05      -9.024626e+01 |       32
     29       6.786911e+05      -8.439485e+01 |       32
     30       6.786070e+05      -8.407476e+01 |       32
     31       6.785250e+05      -8.197357e+01 |       32
     32       6.784493e+05      -7.574568e+01 |       32
     33       6.783802e+05      -6.912597e+01 |       32
     34       6.783083e+05      -7.187737e+01 |       32
     35       6.782406e+05      -6.771145e+01 |       32
     36       6.781813e+05      -5.931501e+01 |       32
     37       6.781246e+05      -5.667008e+01 |       32
     38       6.780639e+05      -6.071687e+01 |       32
     39       6.779987e+05      -6.520229e+01 |       32
     40       6.779341e+05      -6.459912e+01 |       32
     41       6.778732e+05      -6.083099e+01 |       32
     42       6.778118e+05      -6.142352e+01 |       32
     43       6.777558e+05      -5.597169e+01 |       32
     44       6.777042e+05      -5.163351e+01 |       32
     45       6.776502e+05      -5.397281e+01 |       32
     46       6.775968e+05      -5.343217e+01 |       32
     47       6.775449e+05      -5.189683e+01 |       32
     48       6.774923e+05      -5.265247e+01 |       32
     49       6.774372e+05      -5.506824e+01 |       32
     50       6.773787e+05      -5.851871e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 677378.6690064741)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425964
[ Info: iteration 2, average log likelihood -1.421016
[ Info: iteration 3, average log likelihood -1.419636
[ Info: iteration 4, average log likelihood -1.418539
[ Info: iteration 5, average log likelihood -1.417381
[ Info: iteration 6, average log likelihood -1.416375
[ Info: iteration 7, average log likelihood -1.415734
[ Info: iteration 8, average log likelihood -1.415393
[ Info: iteration 9, average log likelihood -1.415204
[ Info: iteration 10, average log likelihood -1.415081
[ Info: iteration 11, average log likelihood -1.414988
[ Info: iteration 12, average log likelihood -1.414914
[ Info: iteration 13, average log likelihood -1.414850
[ Info: iteration 14, average log likelihood -1.414794
[ Info: iteration 15, average log likelihood -1.414743
[ Info: iteration 16, average log likelihood -1.414697
[ Info: iteration 17, average log likelihood -1.414655
[ Info: iteration 18, average log likelihood -1.414616
[ Info: iteration 19, average log likelihood -1.414580
[ Info: iteration 20, average log likelihood -1.414545
[ Info: iteration 21, average log likelihood -1.414513
[ Info: iteration 22, average log likelihood -1.414483
[ Info: iteration 23, average log likelihood -1.414454
[ Info: iteration 24, average log likelihood -1.414427
[ Info: iteration 25, average log likelihood -1.414402
[ Info: iteration 26, average log likelihood -1.414379
[ Info: iteration 27, average log likelihood -1.414356
[ Info: iteration 28, average log likelihood -1.414336
[ Info: iteration 29, average log likelihood -1.414316
[ Info: iteration 30, average log likelihood -1.414298
[ Info: iteration 31, average log likelihood -1.414281
[ Info: iteration 32, average log likelihood -1.414264
[ Info: iteration 33, average log likelihood -1.414249
[ Info: iteration 34, average log likelihood -1.414234
[ Info: iteration 35, average log likelihood -1.414221
[ Info: iteration 36, average log likelihood -1.414207
[ Info: iteration 37, average log likelihood -1.414195
[ Info: iteration 38, average log likelihood -1.414183
[ Info: iteration 39, average log likelihood -1.414172
[ Info: iteration 40, average log likelihood -1.414161
[ Info: iteration 41, average log likelihood -1.414150
[ Info: iteration 42, average log likelihood -1.414141
[ Info: iteration 43, average log likelihood -1.414131
[ Info: iteration 44, average log likelihood -1.414122
[ Info: iteration 45, average log likelihood -1.414114
[ Info: iteration 46, average log likelihood -1.414105
[ Info: iteration 47, average log likelihood -1.414097
[ Info: iteration 48, average log likelihood -1.414090
[ Info: iteration 49, average log likelihood -1.414083
[ Info: iteration 50, average log likelihood -1.414076
┌ Info: EM with 100000 data points 50 iterations avll -1.414076
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.215779    0.410264   -0.15085      0.142613    0.501505   -0.303895      0.122935    0.257415    0.188691    -0.157454      0.693961    0.697586   -0.00836448  -0.0167648   0.021351    -0.292708    -0.0557285    0.149227     0.0243065  -0.292782    0.0405111   -0.332362   -0.0103425   0.137642   -0.0512208  -0.0232161
 -0.457835   -0.0886023   0.616429     0.523704    0.308728   -0.204968     -0.0483494   0.167911   -0.40226      0.326509      0.563725    0.550769   -0.34213      0.193007    0.843573     0.679862     0.223263    -0.554305    -0.010518   -0.162925   -0.355908     0.463661    0.55659     0.278503   -0.217705   -0.0684359
  0.664449    0.194748   -0.466286     0.271269    0.0785168   0.405381     -0.591605    0.153651    0.116075    -0.153436      0.173551   -0.117638   -0.546904    -0.236435   -0.361201     0.54669     -0.652139     0.0747868    0.0661374   0.0704038  -0.00758825   0.129381    0.144773    0.0136817   0.320214   -0.160861
 -0.0752578   0.267323   -0.142339     0.025115   -0.0982461   0.0496861     0.044393    0.0373877  -0.0907158   -0.0542604    -0.026348    0.0365424  -0.030151     0.0794871  -0.00235461  -0.400719     0.107457    -0.0814231    0.0121378  -0.0693442   0.0328022    0.0301233  -0.232107    0.0841802   0.086202   -0.0697609
 -0.0991578  -0.286534   -0.0622726   -0.758886   -0.173396   -0.132116     -0.404063    0.168307    0.78884     -0.0836706    -0.152015   -0.0909515   0.372784    -0.23958     0.195538     0.809833    -0.00918602  -0.00604376   0.261879    0.377326    0.326433     0.243366    0.384039    0.297947    0.038793   -0.145283
 -0.338272   -0.0125369   0.332889    -0.294053   -0.460724    0.668628     -0.132475    0.108497    0.201492     0.126136     -0.371701    0.551366   -0.742721    -0.513377   -0.276972     0.266425     0.109265    -0.39893      0.564262    0.80739    -0.297329    -0.360925    0.57074    -0.665168    0.267363   -0.235007
 -0.059789    0.224348   -0.12275      0.384555    0.339638    0.349547      0.244173    0.0600874   0.578935     0.817834     -0.20974    -0.035075   -0.0858003   -0.421076    0.0234192    0.399166     0.0783156   -0.216611    -0.297966    0.20631    -0.036525    -0.196918    0.142735    0.43591     0.452002   -0.563164
 -0.379805   -0.476208    0.533158    -0.375851   -0.0511128  -0.235239     -0.0245294  -0.141802   -0.303655    -0.0876406    -0.503054   -0.285198    0.719897    -0.279318    0.470388    -0.323837     0.0704221   -0.390293    -0.276965   -0.542039    0.693539    -0.516896    0.0439801  -0.138727    0.293815    0.0382961
  0.114639   -0.551857   -0.22112     -0.143656    0.183398    0.198568      0.0885482   0.276806    0.108882     0.179313     -0.0476006  -0.835019    0.0623218    0.0867595  -0.472244    -0.0615147    0.140465     0.307688    -0.458169   -0.0809064  -0.168411    -0.902939   -0.488189   -0.529963    0.0258487   0.0329584
  0.128093   -0.109071    0.168574    -0.144428    0.133717   -0.0356527     0.0242805  -0.150529    0.102401     0.159837     -0.0966008  -0.306191    0.0193939    0.286095   -0.216176     0.357323     0.174463     0.213757     0.0259799   0.122642    0.153187     0.310215   -0.0168858  -0.0344232   0.116808    0.0723957
 -0.112096   -0.0770932  -0.0772152    0.232572   -0.0622081  -0.0762192     0.0173807  -0.128817    0.0761633    0.0670821     0.227003    0.112075    0.0467116   -0.252532   -0.0177579    0.320386    -0.213706     0.0959441   -0.397011    0.280158   -0.221835    -0.292173    0.219805   -0.246346   -0.123743   -0.0031545
 -0.176783   -0.48783    -0.0708645   -0.0142363  -0.298761   -0.350331     -0.199915   -0.208135   -0.233659    -0.568523      0.270006   -0.395022    0.20467      0.69167     0.0129333   -0.27492      0.0588508    0.404333     0.015807   -0.24322    -0.268526     0.0336348  -0.233565   -0.399342   -0.55435     0.56498
  0.305374   -0.107747   -0.127502    -0.197542    0.263282   -0.143209      0.0627186  -0.378151    0.693407     0.24496      -0.182349   -0.212947   -0.0784122   -0.324392   -0.025114     0.682691    -0.0157996    0.518217    -0.133788    0.299873   -0.282136     0.0831214   0.421388    0.184503    0.0569197  -0.0223337
 -0.122466    0.225993   -0.57268      0.0668027   0.134969   -0.274403      0.135821   -0.0614384  -0.062284    -0.30449      -0.258544   -0.0337677   0.461853     0.0448822   0.50174      0.0659167   -0.0356377    0.410324    -0.337415   -0.737762    0.137499     0.406407   -0.182571    0.303491    0.0960614  -0.617132
 -0.51245    -0.698826    0.490443     0.271893    0.110691    0.0405707     0.642723   -0.12412    -0.0569013    0.000379709   0.016223    0.279578   -0.0488901    0.161787    0.153763    -0.443728    -0.382799     0.30175     -0.591048   -0.802839   -0.392173    -0.526182    0.433399   -0.319702   -0.304725   -0.912786
  0.443902   -0.358363    0.146161     0.697088   -0.324982    0.652211      0.649514    0.250911    0.322097     0.178598     -0.674298    0.267532   -0.154187     0.0909347   0.745616    -0.293075     0.794763     0.36442      0.0175244  -1.00161    -0.739962     0.03089    -0.594224    0.817049    0.153734    0.00984311
 -0.0108832   0.193122   -0.00493016  -0.0315578  -0.200715   -0.0452437    -0.274439    0.466305   -0.202766    -0.174724      0.176694    0.0585893  -0.116647     0.118777   -0.073802    -0.177249     0.0225593   -0.240487     0.211886   -0.0183525   0.239398    -0.0435176  -0.251693   -0.0915432   0.0215567   0.106293
 -0.321849    0.593445    0.103759     0.369167   -0.511692   -0.101581      0.814386   -0.25233    -0.156376     0.175397      0.140938    0.182261   -0.512448     0.767393   -0.200347    -0.261983     0.24331     -0.083764    -0.413818    0.413093    0.102502    -0.316179   -0.283865   -0.093641    0.607349    0.187016
 -0.138825   -0.342394    0.15132      0.133274   -0.237159   -0.907057      0.0414436   0.329711   -0.0369387    0.399405     -0.225578    0.142366   -0.789995    -0.705451    0.139353    -0.189055    -0.137384    -0.0992855    0.200043    0.571488   -0.091569    -0.735636   -0.0122288   0.698681    0.0199319   0.416346
 -0.41527     0.43102     0.303823    -0.338155   -0.180951   -0.429465     -0.126731    0.381928   -0.459928    -0.465645      0.235965    0.535843   -0.0184604    0.298519   -0.082163    -0.525516     0.178117    -0.266854     0.416516   -0.0934132   0.38865      0.526716   -0.75598    -0.380815   -0.222252    0.135066
 -0.573303   -0.31064    -0.180751     0.250406    0.807685    0.0994258    -1.01786     0.097459   -0.826361     0.210755     -0.566529    0.145742    0.945067    -0.38348    -0.481251     0.474737     0.105029     0.114653    -0.369378    0.528771    0.208037     0.346485   -0.77739    -0.48945     0.0258571  -0.730641
  0.318522    0.22941    -0.0222868    0.0856572  -0.715199    0.0764318     0.303051    0.562726    0.109528     0.100453     -0.987649   -0.344535   -0.497756     0.471271   -0.0582385   -0.108395    -0.422172    -0.602039    -0.690267   -0.281994    0.385255     0.895299   -0.265304    0.397705    0.225898   -0.495626
 -0.240473    0.250135   -0.286791    -0.115594   -0.458377   -0.437532      0.633008   -0.215234    0.550702    -0.393216      0.0314068   0.132003    0.108164    -0.0951226   0.296105    -0.341321     0.0878942    0.215642     0.5064      0.273549   -0.838477     0.0758991   0.187633   -0.0291708  -0.832215    0.113478
  0.322283    0.535365   -0.517681     0.139678    0.33871     0.418391     -0.10762    -0.532578    0.00764865  -0.368407     -0.0777294  -0.127457    0.816639     0.523529    0.0889104    0.11297      0.182932     0.485113    -0.763623   -0.232987    0.139021     0.711639   -0.332303   -0.0743375   0.187701   -0.00925896
  0.618451   -0.382508    0.00815925   0.124369   -0.0431314   0.175673     -0.56559     0.0793879  -0.15524     -0.150066      0.260291    0.302601    0.351575    -0.221974    0.00825045   0.228024    -0.416301     0.0396047   -0.0995186   0.0134629   0.0654024    0.116487    0.245776   -0.283731   -1.21382     0.234558
 -0.373505   -0.533768   -0.451055    -0.254717   -0.522634    0.396278     -0.572973    0.281892    0.195329     0.160727     -0.317793   -0.361417   -0.0907554   -0.0786249  -0.316947    -0.821326     0.481401     0.427104     0.264772   -0.422864    0.0321962    0.0375749  -0.295175    0.590167    0.426253   -0.115057
  0.24003    -0.0369185   0.204589    -0.0517289   0.138114    0.353541     -0.603499   -0.243689   -0.623958     0.662965     -0.4656     -0.578926    0.116124     0.0213286  -0.580598     0.0947879    0.119231    -0.292433     0.163129    0.326365    0.474658     0.611639   -0.125624   -0.186727    0.499319   -0.114961
  0.189376    0.236569   -0.380433     0.197301    0.18923     0.160953      0.305893   -0.969855   -0.266776     0.499707      0.289939    0.0761961   0.460983    -0.24912     0.115499    -0.370698    -0.286942    -0.256062    -0.191052   -0.133121   -0.581034     0.450599    0.343114    0.225711   -0.767912   -0.342062
  0.345965   -0.278788    0.0537497   -0.260549   -0.240011    0.000139123  -0.079245    0.228337   -0.0477408    0.27167      -0.415587   -0.0730815   0.0975737   -0.211647    0.226925     0.00334987   0.0785528   -0.143243     0.0845808  -0.220895   -0.243583     0.315926    0.0146705   0.0344001  -0.455938    0.00277026
  0.496339    0.106368    0.0765724   -0.820694    0.375409    0.0679452     0.52414     0.313565    0.196138    -0.0857676     0.366352    0.130804   -0.172764     0.625671   -0.0426185   -0.184112     0.289765     0.0938948    0.452291   -0.323035    0.258046     0.344496   -0.167814    0.447763   -0.0621062   0.711578
 -0.434479    0.417941    0.0801176   -0.275024    0.309465   -0.40962      -0.230619   -0.320094    0.0663655   -0.024572      0.837895    0.0224276   0.142334    -0.273655   -0.317224     0.467805    -0.152633    -0.172079     0.368883    0.927928    0.354568    -0.170931    0.41539    -0.185244    0.0976317   0.255617
  0.460348    0.365775    0.0399998    0.471728    0.0751038   0.455232     -0.0665482   0.0125063  -0.919527     0.107764      0.112467    0.288044   -0.47738     -0.171034   -0.313531    -0.609575     0.302086     0.285839    -0.478332   -0.109679    0.0276939   -0.440462   -0.35185    -0.172751    0.2026      0.179764[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414069
[ Info: iteration 2, average log likelihood -1.414062
[ Info: iteration 3, average log likelihood -1.414056
[ Info: iteration 4, average log likelihood -1.414050
[ Info: iteration 5, average log likelihood -1.414044
[ Info: iteration 6, average log likelihood -1.414039
[ Info: iteration 7, average log likelihood -1.414033
[ Info: iteration 8, average log likelihood -1.414028
[ Info: iteration 9, average log likelihood -1.414023
[ Info: iteration 10, average log likelihood -1.414018
┌ Info: EM with 100000 data points 10 iterations avll -1.414018
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
