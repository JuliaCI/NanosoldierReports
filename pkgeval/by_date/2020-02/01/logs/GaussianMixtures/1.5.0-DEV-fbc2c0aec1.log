Julia Version 1.5.0-DEV.221
Commit fbc2c0aec1 (2020-02-01 18:55 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed GaussianMixtures ─── v0.3.0
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed ScikitLearnBase ──── v0.5.0
  Installed Rmath ────────────── v0.6.0
  Installed Distances ────────── v0.8.2
  Installed FillArrays ───────── v0.8.4
  Installed Arpack_jll ───────── v3.5.0+2
  Installed HDF5 ─────────────── v0.12.5
  Installed CMake ────────────── v1.1.2
  Installed Blosc ────────────── v0.5.1
  Installed QuadGK ───────────── v2.3.1
  Installed URIParser ────────── v0.4.0
  Installed DataAPI ──────────── v1.1.0
  Installed CMakeWrapper ─────── v0.2.3
  Installed SortingAlgorithms ── v0.3.1
  Installed Missings ─────────── v0.4.3
  Installed Arpack ───────────── v0.4.0
  Installed StatsFuns ────────── v0.9.3
  Installed StatsBase ────────── v0.32.0
  Installed BinaryProvider ───── v0.5.8
  Installed JLD ──────────────── v0.9.2
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed LegacyStrings ────── v0.4.1
  Installed PDMats ───────────── v0.9.11
  Installed Compat ───────────── v2.2.0
  Installed NearestNeighbors ─── v0.4.4
  Installed OrderedCollections ─ v1.1.0
  Installed Parameters ───────── v0.12.0
  Installed DataStructures ───── v0.17.9
  Installed BinDeps ──────────── v1.0.0
  Installed SpecialFunctions ─── v0.9.0
  Installed FileIO ───────────── v1.2.1
  Installed StaticArrays ─────── v0.12.1
  Installed Clustering ───────── v0.13.3
  Installed Distributions ────── v0.22.4
#####                                                                      7.0%######################################################################## 100.0%
#######                                                                   10.8%######################################################################## 100.0%
                                                                           0.1%#########                                                                 12.6%#############################                                             40.9%######################################################                    75.9%######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_4U6eDZ/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -4.376196720335018e6, [71911.57034494338, 28088.42965505663], [13191.342339328248 -13928.639136476837 3353.019216195089; -13078.948040870197 13550.501664814545 -3436.990402855313], [[80465.26466026297 9736.058910190353 6574.270773047854; 9736.058910190353 81861.39474219298 8219.523622206267; 6574.270773047854 8219.523622206267 78315.1705416264], [19389.544889518027 -9334.639673822569 -6986.5508300028; -9334.639673822569 18059.867805863083 -7960.904397193791; -6986.5508300028 -7960.904397193791 21482.86232152189]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.330276e+03
      1       1.199498e+03      -1.307777e+02 |        4
      2       1.174219e+03      -2.527949e+01 |        2
      3       1.172923e+03      -1.295313e+00 |        0
      4       1.172923e+03       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 1172.9233930524624)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.070317
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.762026
[ Info: iteration 2, lowerbound -3.635999
[ Info: iteration 3, lowerbound -3.521744
[ Info: iteration 4, lowerbound -3.402300
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.261174
[ Info: iteration 6, lowerbound -3.105478
[ Info: iteration 7, lowerbound -2.959690
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.834080
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.722233
[ Info: iteration 10, lowerbound -2.628814
[ Info: dropping number of Gaussions to 4
[ Info: iteration 11, lowerbound -2.540288
[ Info: iteration 12, lowerbound -2.464767
[ Info: iteration 13, lowerbound -2.409772
[ Info: iteration 14, lowerbound -2.373545
[ Info: dropping number of Gaussions to 3
[ Info: iteration 15, lowerbound -2.340640
[ Info: iteration 16, lowerbound -2.315989
[ Info: iteration 17, lowerbound -2.307479
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.302966
[ Info: iteration 19, lowerbound -2.299261
[ Info: iteration 20, lowerbound -2.299257
[ Info: iteration 21, lowerbound -2.299255
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sun Feb  2 00:51:49 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sun Feb  2 00:51:57 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Sun Feb  2 00:52:00 2020: EM with 272 data points 0 iterations avll -2.070317
5.8 data points per parameter
, Sun Feb  2 00:52:02 2020: GMM converted to Variational GMM
, Sun Feb  2 00:52:10 2020: iteration 1, lowerbound -3.762026
, Sun Feb  2 00:52:10 2020: iteration 2, lowerbound -3.635999
, Sun Feb  2 00:52:10 2020: iteration 3, lowerbound -3.521744
, Sun Feb  2 00:52:10 2020: iteration 4, lowerbound -3.402300
, Sun Feb  2 00:52:11 2020: dropping number of Gaussions to 7
, Sun Feb  2 00:52:11 2020: iteration 5, lowerbound -3.261174
, Sun Feb  2 00:52:11 2020: iteration 6, lowerbound -3.105478
, Sun Feb  2 00:52:11 2020: iteration 7, lowerbound -2.959690
, Sun Feb  2 00:52:11 2020: dropping number of Gaussions to 6
, Sun Feb  2 00:52:11 2020: iteration 8, lowerbound -2.834080
, Sun Feb  2 00:52:11 2020: dropping number of Gaussions to 5
, Sun Feb  2 00:52:11 2020: iteration 9, lowerbound -2.722233
, Sun Feb  2 00:52:11 2020: iteration 10, lowerbound -2.628814
, Sun Feb  2 00:52:11 2020: dropping number of Gaussions to 4
, Sun Feb  2 00:52:11 2020: iteration 11, lowerbound -2.540288
, Sun Feb  2 00:52:11 2020: iteration 12, lowerbound -2.464767
, Sun Feb  2 00:52:11 2020: iteration 13, lowerbound -2.409772
, Sun Feb  2 00:52:11 2020: iteration 14, lowerbound -2.373545
, Sun Feb  2 00:52:11 2020: dropping number of Gaussions to 3
, Sun Feb  2 00:52:11 2020: iteration 15, lowerbound -2.340640
, Sun Feb  2 00:52:11 2020: iteration 16, lowerbound -2.315989
, Sun Feb  2 00:52:11 2020: iteration 17, lowerbound -2.307479
, Sun Feb  2 00:52:11 2020: dropping number of Gaussions to 2
, Sun Feb  2 00:52:11 2020: iteration 18, lowerbound -2.302966
, Sun Feb  2 00:52:11 2020: iteration 19, lowerbound -2.299261
, Sun Feb  2 00:52:11 2020: iteration 20, lowerbound -2.299257
, Sun Feb  2 00:52:11 2020: iteration 21, lowerbound -2.299255
, Sun Feb  2 00:52:11 2020: iteration 22, lowerbound -2.299254
, Sun Feb  2 00:52:11 2020: iteration 23, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 24, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 25, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 26, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 27, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 28, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 29, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 30, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 31, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 32, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 33, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 34, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 35, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 36, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 37, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 38, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 39, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 40, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 41, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 42, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 43, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 44, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 45, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 46, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 47, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 48, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 49, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: iteration 50, lowerbound -2.299253
, Sun Feb  2 00:52:11 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398598, 178.04509222601396]
β = [95.95490777398598, 178.04509222601396]
m = [2.000229257775369 53.85198717246128; 4.250300733269909 79.28686694436186]
ν = [97.95490777398598, 180.04509222601396]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.37587636119484175 -0.008953123827346006; 0.0 0.012748664777409345], [0.18404155547484535 -0.007644049042327626; 0.0 0.008581705166333763]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9965019596396569
avll from llpg:  -0.9965019596396573
avll direct:     -0.9965019596396574
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9776494841202177
avll from llpg:  -0.9776494841202177
avll direct:     -0.9776494841202177
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
 -0.100283    -0.00528096   0.0172974    0.0496229   -0.207986    -0.115919    0.00982945  -0.0102038    0.040408     -0.0692633    0.126432     0.128517    -0.0346149    0.0671008   -0.158662    -0.0260168  -0.116139    -0.0742115    -0.164178      0.0474582    0.0754023    0.0504242    -0.155032    -0.186412    0.0796624   -0.0674838
  0.0160128   -0.212129     0.167428    -0.0325211    0.0497536   -0.0224121   0.0235694    0.0106931   -0.0246861    -0.0923199   -0.0965989    0.0935653   -0.110683     0.108917    -0.0568253    0.058035   -0.00308461  -0.104125     -0.0248041     0.151102    -0.060028    -0.0494333    -0.088757    -0.0685004  -0.135989    -0.129526
 -0.0433236   -0.291577    -0.0631233    0.206619    -0.231588     0.062017    0.13878     -0.0415413   -0.0341        0.0909054    0.0317823   -0.00773703   0.0197478   -0.182369    -0.0416821   -0.0196644  -0.06237     -0.329062     -0.0155735     0.00823894   0.180801     0.0674107    -0.0690265    0.118268   -0.0910232   -0.132266
  0.0921469    0.0629693   -0.0155358    0.00323713   0.0872239   -0.0481028   0.0545689    0.0448228   -0.203295      0.238281    -0.111185    -0.017599    -0.059514     0.0404844   -0.0738464   -0.0197697   0.127862     0.0514746    -0.0155145    -0.164607    -0.146196    -0.0945991     0.0674604    0.0934524  -0.0803285   -0.00124526
  0.138314    -0.101226     0.127321    -0.0058719   -0.033139    -0.0219467  -0.0647901    0.0779271    0.236429      0.0703563    0.120991     0.0926976    0.116959     0.0724188    0.14984      0.0451923   0.0384853    0.186963      0.0419168     0.131265    -0.205079     0.32994       0.0810573    0.159549    0.0344696   -0.0146725
  0.0152504    0.102596    -0.132063    -0.0551617    0.0492086   -0.0902511   0.12244     -0.0295305    0.0977062    -0.0378854    0.030953     0.0889325    0.0221561    0.0997404   -0.0182377    0.167813   -0.035308    -0.0221503     0.0867657    -0.236846     0.0772356   -0.0342571     0.0488795    0.0565529   0.0474269   -0.0473805
 -0.00883271   0.0973869    0.0892382   -0.00116817   0.0657289    0.112256    0.0486406    0.225932     0.113829      0.141676    -0.0216066    0.0545118    0.0262952   -0.0478573    0.0198306   -0.135032    0.0732857    0.19089      -0.0231259     0.0549134    0.0577309    0.287501     -0.110609    -0.153653    0.0835931   -0.0943467
  0.0549598   -0.0260326   -0.0999579   -0.0850554   -0.0380875   -0.138054   -0.00539087   0.0593675    0.00439101   -0.00300604  -0.142602     0.00353386  -0.0498044    0.138499    -0.167194    -0.148262   -0.0682891   -0.134593      0.0393831     0.0892627   -0.0194755    0.101952     -0.143118    -0.0607749   0.141522    -0.154081
  0.00861684  -0.0199987    0.0833969   -0.0031813   -0.0331993    0.132938    0.191595     0.173288    -0.0160427    -0.0092812   -0.0859914   -0.00170793  -0.142167    -0.105023     0.00239971   0.0714844   0.100223     0.0201658    -0.0835492    -0.0788805    0.0379307    0.0322578    -0.047165     0.0744986  -0.129446    -0.00749052
 -0.0638622    0.0269304   -0.0611479    0.063044     0.070537     0.0670306  -0.0539007    0.180044    -0.202586     -0.239348    -0.127494     0.276245    -0.0498572   -0.0454558   -0.114024     0.0195477   0.0815685    0.0363489     0.0406384     0.00795215   0.113439     0.0509752    -0.0309801    0.0565208   0.079102    -0.0350811
  0.0503813    0.0642851    0.222288     0.204819     0.0568247   -0.166839    0.0939532    0.0418961   -0.0494317    -0.132711    -0.0317069   -0.111599    -0.035368     0.128255    -0.117235    -0.0509271  -0.106531    -0.0793552    -0.0563941     0.179435     0.00613488   0.0582122     0.0723402   -0.0532167   0.121011    -0.0194624
 -0.0649451   -0.125664    -0.107392     0.0496303    0.0549453   -0.124894   -0.0558569   -0.123894    -0.0467002     0.0799527    0.0516064    0.0275156   -0.0565453   -0.233687    -0.105396    -0.0181017   0.0259609    0.0862199     0.00737742    0.174166    -0.145581     0.0172368    -0.00037685  -0.0714437   0.085031    -0.00990915
  0.121521    -0.135418     0.0185049   -0.0978473    0.0208506   -0.0896474   0.0042217    0.0374104   -0.0336777    -0.03783     -0.194505     0.0286409    0.0339381   -0.0266167    0.0288714   -0.0111189   0.0701516    0.103535     -0.209446      0.135256     0.108399    -0.00947768    0.0702978    0.165033   -0.00304684   0.0957653
  0.116753     0.0208761   -0.0306707   -0.129518    -0.0178884    0.1231      0.118657    -0.0903193    0.150221      0.0985171    0.0507118   -0.0457014    0.11169     -0.0105816   -0.016716     0.0310028  -0.0760992   -0.0910822     0.0470691     0.0375137    0.0393011    0.0965942    -0.240182     0.246204   -0.0453407   -0.14839
  0.172758     0.106016    -0.190885     0.0289943    0.110671     0.0487625  -0.00513866  -0.13494      0.0326947     0.275447     0.0900879   -0.0961634    0.0432709    0.0594114   -0.0736079    0.0450088  -0.105745    -0.0463356    -0.0922186     0.0759204    0.116923     0.116822      0.0788371   -0.0908074   0.0130225   -0.10741
  0.119251    -0.00252349  -0.0428259   -0.0417196    0.223198    -0.112806   -0.140627    -0.109139    -0.0280807    -0.101422    -0.0487288    0.0256157    0.0643261    0.0314054    0.041741    -0.0456265  -0.122071     0.0953586     0.119712      0.0528677    0.0574532   -0.303049     -0.13606      0.112854   -0.0321187   -0.0355533
 -0.140997    -0.143459     0.0159133    0.0249677    0.146669    -0.180653    0.0527328   -0.0297871   -0.0384562    -0.026692     0.100221    -0.233892    -0.11537      0.0300264   -0.0719675   -0.0238207   0.0134774   -0.0634543     0.0294415    -0.102705     0.0387867    0.000610444   0.0750465   -0.0733616  -0.0253333    0.0378918
  0.0583195   -0.0797978   -0.129737     0.0152758   -0.052315     0.0213589   0.181866     0.173144    -0.0372569    -0.0726169   -0.0744494    0.124245     0.100515    -0.0100537    0.109445    -0.191912    0.0690457    0.12428       0.00730911   -0.0467981   -0.0181226   -0.034294     -0.00425015   0.0325625   0.206574    -0.0932354
 -0.16941     -0.0177696   -0.125856    -0.0925205    0.0270412   -0.110561    0.0407053    0.0535618    0.0199898    -0.00645074   0.205837     0.0829408   -0.0209571    0.00579333   0.170086    -0.0044544   0.083856    -0.00772309    0.0797518    -0.0163914    0.10899      0.101774      0.103416     0.0116067   0.0357408    0.159923
 -0.0639087    0.173593     0.00965621   0.022386     0.121179    -0.117945   -0.207966    -0.0219919   -0.0838322     0.0753372   -0.0214756   -0.0632577    0.0171774   -0.0443292    0.0579955   -0.182219    0.0741369   -0.151066     -0.0491382     0.0940608    0.0435959   -0.020078      0.020721    -0.0777756   0.0793662    0.0141247
  0.0152147   -0.0751989    0.165756    -0.0331397   -0.00165996  -0.223892    0.175585     0.020987    -0.0149967     0.115529    -0.0464394    0.0116413    0.253081     0.0586951   -0.0305044   -0.0494356  -0.0314433   -0.126751      0.0529394     0.07245      0.162197     0.0778512     0.040083    -0.0122279  -0.0655582   -0.0436467
 -0.00959277  -0.162901     0.0754493   -0.0712986    0.0194623   -0.117419   -0.0781503    0.253865     0.0141575     0.0180037    0.096386     0.0414415   -0.194592    -0.137414    -0.137093     0.0164562  -0.0876792    0.000965324   0.120161     -0.141626    -0.00203134   0.0437901     0.00020495  -0.210126    0.00357097  -0.0100602
  0.0607536   -0.043552    -0.0759705   -0.0627535   -0.107232    -0.134034    0.12923     -0.134118    -0.104366     -0.0386081   -0.130278     0.123804     0.124686     0.0560243   -0.105871     0.0967326  -0.261042     0.00313948   -0.0127007    -0.106491     0.202749    -0.0997072    -0.00451807  -0.188141   -0.0369111   -0.0507213
  0.129221     0.0296838   -0.0547894    0.0133693   -0.151195     0.227605   -0.225771    -0.015479    -0.0610993     0.0442147    0.00375903  -0.147115     0.00927088   0.0908371    0.00255177  -0.218652    0.056056     0.0233898     0.0714478     0.0435299   -0.139339     0.163555     -0.0202166   -0.0112411   0.0383082    0.0723338
  0.0213037   -0.057385    -0.126047    -0.1298       0.0648337   -0.0945672   0.0839426    0.07259     -0.0463131     0.259412     0.0045294    0.0774072    0.180392     0.0183062    0.081256    -0.0217284  -0.135515     0.0541234     0.0135925     0.0283911   -0.173315    -0.175843     -0.0881326   -0.0651919  -0.0106245    0.00151716
 -0.0412064    0.105528    -0.0798533   -0.031599    -0.0573289   -0.0268043  -0.102881    -0.00327336   0.203868      0.0445825   -0.220309     0.0411327   -0.0412446   -0.162959     0.0665636    0.131556    0.022408    -0.0495001    -0.000691084   0.0443937   -0.038641    -0.00891265    0.0325404    0.0195958  -0.134057    -0.00984266
 -0.0507864   -0.255165     0.159854    -0.0298216    0.165734     0.0625466  -0.0417987   -0.0920659   -0.000117832   0.0353176   -0.124766     0.0305884   -0.0657993    0.0698419    0.0369618    0.0314776   0.187379    -0.197059      0.15777       0.0172393    0.0266279    0.0696796     0.0441097    0.147681   -0.0751051   -0.0226942
 -0.123118     0.13486      0.0628151    0.0328973    0.0792669    0.106113   -0.143106    -0.142926     0.144426     -0.0449553   -0.0396473   -0.115308     0.140706    -0.135777    -0.117929     0.0565332   0.0564934   -0.16959      -0.092753      0.153465     0.0189441    0.0288028    -0.0427802    0.0105585  -0.0567685   -0.026606
 -0.0902849   -0.182144     0.0811844    0.182921     0.091865     0.137589   -0.155412    -0.00412293   0.0183976    -0.124648     0.0266084   -0.0307667   -0.0340743   -0.00197032   0.0903611   -0.165462    0.0469565    0.0261095    -0.207233     -0.111967     0.130597    -0.035114     -0.140452    -0.24477    -0.00993355  -0.0207425
  0.0635095   -0.0319537   -0.0487245    0.0540273    0.0230084    0.0143256  -0.0437075    0.120869     0.0455252     0.0839979   -0.0342051   -0.0937667   -0.0409687    0.0807347    0.0534034   -0.167564   -0.0526414    0.0286653    -0.0978913     0.143335    -0.193477     0.0589825    -0.23905      0.0411867   0.0171704    0.165773
  0.175713    -0.125813    -0.0348449    0.160299     0.00111308  -0.148765   -0.057852    -0.0556063   -0.00372268   -0.022226     0.152053     0.251738    -0.0444476   -0.182272    -0.0765166    0.0557096  -0.0488337   -0.158443      0.0477841    -0.193971     0.0797102    0.171209      0.0119348    0.0829203  -0.147806    -0.121861
  0.0864859   -0.0284706   -0.0933738    0.00339751   0.0933928    0.0720696   0.234643     0.0979634    0.0391671     0.207052    -0.156269    -0.0256147    0.0965593    0.00292043  -0.13037      0.0512237  -0.251015     0.0017073     0.0450749     0.0144456    0.00854906  -0.107071     -0.11563      0.0340787  -0.0873001   -0.0156104kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4282439357494598
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.428349
[ Info: iteration 2, average log likelihood -1.428241
[ Info: iteration 3, average log likelihood -1.427297
[ Info: iteration 4, average log likelihood -1.417956
[ Info: iteration 5, average log likelihood -1.399204
[ Info: iteration 6, average log likelihood -1.392537
[ Info: iteration 7, average log likelihood -1.391151
[ Info: iteration 8, average log likelihood -1.390689
[ Info: iteration 9, average log likelihood -1.390498
[ Info: iteration 10, average log likelihood -1.390404
[ Info: iteration 11, average log likelihood -1.390350
[ Info: iteration 12, average log likelihood -1.390314
[ Info: iteration 13, average log likelihood -1.390288
[ Info: iteration 14, average log likelihood -1.390267
[ Info: iteration 15, average log likelihood -1.390250
[ Info: iteration 16, average log likelihood -1.390235
[ Info: iteration 17, average log likelihood -1.390222
[ Info: iteration 18, average log likelihood -1.390210
[ Info: iteration 19, average log likelihood -1.390198
[ Info: iteration 20, average log likelihood -1.390187
[ Info: iteration 21, average log likelihood -1.390177
[ Info: iteration 22, average log likelihood -1.390165
[ Info: iteration 23, average log likelihood -1.390152
[ Info: iteration 24, average log likelihood -1.390137
[ Info: iteration 25, average log likelihood -1.390114
[ Info: iteration 26, average log likelihood -1.390078
[ Info: iteration 27, average log likelihood -1.390012
[ Info: iteration 28, average log likelihood -1.389887
[ Info: iteration 29, average log likelihood -1.389666
[ Info: iteration 30, average log likelihood -1.389379
[ Info: iteration 31, average log likelihood -1.389115
[ Info: iteration 32, average log likelihood -1.388914
[ Info: iteration 33, average log likelihood -1.388759
[ Info: iteration 34, average log likelihood -1.388635
[ Info: iteration 35, average log likelihood -1.388537
[ Info: iteration 36, average log likelihood -1.388456
[ Info: iteration 37, average log likelihood -1.388391
[ Info: iteration 38, average log likelihood -1.388342
[ Info: iteration 39, average log likelihood -1.388307
[ Info: iteration 40, average log likelihood -1.388283
[ Info: iteration 41, average log likelihood -1.388266
[ Info: iteration 42, average log likelihood -1.388255
[ Info: iteration 43, average log likelihood -1.388247
[ Info: iteration 44, average log likelihood -1.388241
[ Info: iteration 45, average log likelihood -1.388237
[ Info: iteration 46, average log likelihood -1.388235
[ Info: iteration 47, average log likelihood -1.388233
[ Info: iteration 48, average log likelihood -1.388232
[ Info: iteration 49, average log likelihood -1.388231
[ Info: iteration 50, average log likelihood -1.388230
┌ Info: EM with 100000 data points 50 iterations avll -1.388230
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4283485698816298
│     -1.428240919513783
│      ⋮
└     -1.3882301260442125
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.388343
[ Info: iteration 2, average log likelihood -1.388196
[ Info: iteration 3, average log likelihood -1.386945
[ Info: iteration 4, average log likelihood -1.377461
[ Info: iteration 5, average log likelihood -1.360499
[ Info: iteration 6, average log likelihood -1.352939
[ Info: iteration 7, average log likelihood -1.350548
[ Info: iteration 8, average log likelihood -1.349195
[ Info: iteration 9, average log likelihood -1.348116
[ Info: iteration 10, average log likelihood -1.347165
[ Info: iteration 11, average log likelihood -1.346417
[ Info: iteration 12, average log likelihood -1.345892
[ Info: iteration 13, average log likelihood -1.345554
[ Info: iteration 14, average log likelihood -1.345348
[ Info: iteration 15, average log likelihood -1.345224
[ Info: iteration 16, average log likelihood -1.345146
[ Info: iteration 17, average log likelihood -1.345095
[ Info: iteration 18, average log likelihood -1.345058
[ Info: iteration 19, average log likelihood -1.345030
[ Info: iteration 20, average log likelihood -1.345007
[ Info: iteration 21, average log likelihood -1.344987
[ Info: iteration 22, average log likelihood -1.344969
[ Info: iteration 23, average log likelihood -1.344952
[ Info: iteration 24, average log likelihood -1.344936
[ Info: iteration 25, average log likelihood -1.344920
[ Info: iteration 26, average log likelihood -1.344905
[ Info: iteration 27, average log likelihood -1.344890
[ Info: iteration 28, average log likelihood -1.344875
[ Info: iteration 29, average log likelihood -1.344860
[ Info: iteration 30, average log likelihood -1.344846
[ Info: iteration 31, average log likelihood -1.344831
[ Info: iteration 32, average log likelihood -1.344816
[ Info: iteration 33, average log likelihood -1.344801
[ Info: iteration 34, average log likelihood -1.344786
[ Info: iteration 35, average log likelihood -1.344769
[ Info: iteration 36, average log likelihood -1.344753
[ Info: iteration 37, average log likelihood -1.344735
[ Info: iteration 38, average log likelihood -1.344717
[ Info: iteration 39, average log likelihood -1.344697
[ Info: iteration 40, average log likelihood -1.344676
[ Info: iteration 41, average log likelihood -1.344653
[ Info: iteration 42, average log likelihood -1.344628
[ Info: iteration 43, average log likelihood -1.344600
[ Info: iteration 44, average log likelihood -1.344572
[ Info: iteration 45, average log likelihood -1.344542
[ Info: iteration 46, average log likelihood -1.344512
[ Info: iteration 47, average log likelihood -1.344483
[ Info: iteration 48, average log likelihood -1.344454
[ Info: iteration 49, average log likelihood -1.344425
[ Info: iteration 50, average log likelihood -1.344397
┌ Info: EM with 100000 data points 50 iterations avll -1.344397
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3883432144889247
│     -1.3881962975303965
│      ⋮
└     -1.3443969515113454
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.344522
[ Info: iteration 2, average log likelihood -1.344316
[ Info: iteration 3, average log likelihood -1.343334
[ Info: iteration 4, average log likelihood -1.336617
[ Info: iteration 5, average log likelihood -1.322262
[ Info: iteration 6, average log likelihood -1.311006
[ Info: iteration 7, average log likelihood -1.304701
[ Info: iteration 8, average log likelihood -1.299590
[ Info: iteration 9, average log likelihood -1.295083
[ Info: iteration 10, average log likelihood -1.291327
[ Info: iteration 11, average log likelihood -1.288409
[ Info: iteration 12, average log likelihood -1.286237
[ Info: iteration 13, average log likelihood -1.284679
[ Info: iteration 14, average log likelihood -1.283728
[ Info: iteration 15, average log likelihood -1.283201
[ Info: iteration 16, average log likelihood -1.282879
[ Info: iteration 17, average log likelihood -1.282666
[ Info: iteration 18, average log likelihood -1.282518
[ Info: iteration 19, average log likelihood -1.282407
[ Info: iteration 20, average log likelihood -1.282317
[ Info: iteration 21, average log likelihood -1.282237
[ Info: iteration 22, average log likelihood -1.282160
[ Info: iteration 23, average log likelihood -1.282087
[ Info: iteration 24, average log likelihood -1.282024
[ Info: iteration 25, average log likelihood -1.281980
[ Info: iteration 26, average log likelihood -1.281952
[ Info: iteration 27, average log likelihood -1.281936
[ Info: iteration 28, average log likelihood -1.281925
[ Info: iteration 29, average log likelihood -1.281916
[ Info: iteration 30, average log likelihood -1.281907
[ Info: iteration 31, average log likelihood -1.281899
[ Info: iteration 32, average log likelihood -1.281888
[ Info: iteration 33, average log likelihood -1.281874
[ Info: iteration 34, average log likelihood -1.281856
[ Info: iteration 35, average log likelihood -1.281831
[ Info: iteration 36, average log likelihood -1.281795
[ Info: iteration 37, average log likelihood -1.281741
[ Info: iteration 38, average log likelihood -1.281657
[ Info: iteration 39, average log likelihood -1.281536
[ Info: iteration 40, average log likelihood -1.281399
[ Info: iteration 41, average log likelihood -1.281313
[ Info: iteration 42, average log likelihood -1.281277
[ Info: iteration 43, average log likelihood -1.281254
[ Info: iteration 44, average log likelihood -1.281235
[ Info: iteration 45, average log likelihood -1.281219
[ Info: iteration 46, average log likelihood -1.281204
[ Info: iteration 47, average log likelihood -1.281191
[ Info: iteration 48, average log likelihood -1.281179
[ Info: iteration 49, average log likelihood -1.281168
[ Info: iteration 50, average log likelihood -1.281158
┌ Info: EM with 100000 data points 50 iterations avll -1.281158
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3445220211817963
│     -1.3443159962142295
│      ⋮
└     -1.2811577400077514
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.281372
[ Info: iteration 2, average log likelihood -1.281079
[ Info: iteration 3, average log likelihood -1.279068
[ Info: iteration 4, average log likelihood -1.258367
[ Info: iteration 5, average log likelihood -1.222301
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.194606
[ Info: iteration 7, average log likelihood -1.203713
[ Info: iteration 8, average log likelihood -1.192576
[ Info: iteration 9, average log likelihood -1.176901
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.168632
[ Info: iteration 11, average log likelihood -1.188595
[ Info: iteration 12, average log likelihood -1.184917
[ Info: iteration 13, average log likelihood -1.173389
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.167323
[ Info: iteration 15, average log likelihood -1.188099
[ Info: iteration 16, average log likelihood -1.184652
[ Info: iteration 17, average log likelihood -1.173120
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.167047
[ Info: iteration 19, average log likelihood -1.187876
[ Info: iteration 20, average log likelihood -1.184354
[ Info: iteration 21, average log likelihood -1.172677
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.166371
[ Info: iteration 23, average log likelihood -1.186827
[ Info: iteration 24, average log likelihood -1.182669
[ Info: iteration 25, average log likelihood -1.170233
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.163597
[ Info: iteration 27, average log likelihood -1.184400
[ Info: iteration 28, average log likelihood -1.180972
[ Info: iteration 29, average log likelihood -1.169434
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.163403
[ Info: iteration 31, average log likelihood -1.184366
[ Info: iteration 32, average log likelihood -1.180963
[ Info: iteration 33, average log likelihood -1.169431
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.163403
[ Info: iteration 35, average log likelihood -1.184358
[ Info: iteration 36, average log likelihood -1.180954
[ Info: iteration 37, average log likelihood -1.169422
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.163391
[ Info: iteration 39, average log likelihood -1.184332
[ Info: iteration 40, average log likelihood -1.180917
[ Info: iteration 41, average log likelihood -1.169371
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.163310
[ Info: iteration 43, average log likelihood -1.184177
[ Info: iteration 44, average log likelihood -1.180650
[ Info: iteration 45, average log likelihood -1.168900
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.162456
[ Info: iteration 47, average log likelihood -1.182791
[ Info: iteration 48, average log likelihood -1.179021
[ Info: iteration 49, average log likelihood -1.167489
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.161511
┌ Info: EM with 100000 data points 50 iterations avll -1.161511
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2813718975610302
│     -1.2810792431271523
│      ⋮
└     -1.1615107164214815
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.182611
[ Info: iteration 2, average log likelihood -1.178856
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.165642
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.142687
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     15
│     17
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.107140
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.119762
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     15
│     17
│     21
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.089750
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     15
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.095730
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     17
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.113581
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     15
│     23
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.087751
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     11
│     15
│     17
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.084503
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.121065
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     17
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.101841
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      9
│     10
│     15
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.076931
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     15
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.111773
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.100712
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     15
│     17
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.072338
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     15
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.094570
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     15
│     17
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.083397
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     15
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.075161
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.102191
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     15
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.079591
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     11
│     15
│     17
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.066807
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.106580
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     17
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.087818
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      9
│     10
│     15
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.062992
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     15
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.097772
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.091663
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     15
│     17
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.071144
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     15
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.094520
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     15
│     17
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.083432
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     15
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.075166
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.102267
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     15
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.079644
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     11
│     15
│     17
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.066798
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.106578
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     17
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.087819
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      9
│     10
│     15
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.062988
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     15
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.097765
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.091658
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     15
│     17
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.071138
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     15
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.094514
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     15
│     17
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.083426
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     15
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.075160
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.102262
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     15
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.079639
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     11
│     15
│     17
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.066793
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.106573
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     17
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.087814
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      9
│     10
│     15
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.062983
┌ Info: EM with 100000 data points 50 iterations avll -1.062983
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1826107241495418
│     -1.1788558201669048
│      ⋮
└     -1.0629831018678073
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4282439357494598
│     -1.4283485698816298
│     -1.428240919513783
│     -1.4272967410634114
│      ⋮
│     -1.1065732803437724
│     -1.0878144312237696
└     -1.0629831018678073
32×26 Array{Float64,2}:
 -0.0351593   -0.276936    -0.0458924    0.202471    -0.242153    0.0521459    0.154389     -0.0622284    -0.0267074    0.0905034    0.060027   -0.0217239    0.0160313   -0.166981    -0.0324805    0.00442081  -0.0638094   -0.340264     -0.0144672    0.0106581    0.190845     0.0440719   -0.0626248    0.124581    -0.090788    -0.227777
 -0.0630009   -0.146101    -0.117297     0.066085     0.0105083  -0.151089    -0.0527651    -0.108655     -0.0478624    0.0568626    0.0463117   0.0279457   -0.0614503   -0.228307    -0.10507     -0.0267147    0.032464     0.084658      0.0116795    0.160145    -0.149055     0.0209414   -0.00716389  -0.0736455    0.0834492    0.00417692
 -0.0438593    0.200171     0.0500157    0.0866492    0.0593079   0.136387    -0.140701     -0.114439     -0.793303    -0.0146397   -0.119679   -0.0835577    0.111116    -0.0435708   -0.114684     0.0589237    0.0848871   -0.168326     -0.146898     0.164169     0.0843262   -0.0328981   -0.0415107    0.0544739   -0.0808488   -0.045043
 -0.220454     0.0858942    0.0821725   -0.0600296    0.108559    0.105592    -0.141016     -0.187044      1.19804     -0.0900827    0.07773    -0.196743     0.183053    -0.152818    -0.136889     0.0442189    0.0500482   -0.171838     -0.0954757    0.155106    -0.0893216    0.0771303   -0.0450666   -0.0401665   -0.0189829   -0.0139845
  0.158439    -0.169817    -0.02299      0.15941     -0.0176619  -0.131608    -0.0469665    -0.0392998    -0.00645226  -0.0258493    0.1331      0.246889    -0.0421219   -0.184239    -0.0747692    0.0763817   -0.0366293   -0.164751      0.0453084   -0.199949     0.0120662    0.175491     0.0377249    0.114026    -0.143853    -0.14152
  0.11782     -0.00972743  -0.0238566   -0.038947     0.213917   -0.0953864   -0.128295     -0.0256715    -0.0336707   -0.101411    -0.0474884   0.0335694    0.0654909    0.0358705    0.0570668   -0.0252071   -0.126513     0.0825218     0.0972617    0.0486776    0.0468817   -0.311013    -0.135882     0.0963705   -0.0425319   -0.0130015
  0.170957     0.033153    -0.0171414   -0.0181198   -0.179892    0.270026    -0.228164     -0.0348579    -0.0681758   -0.0569972   -0.0311179  -0.0239495    0.035913     0.105646    -0.00887463  -0.486363    -0.00601393   0.0145374     0.0843702    0.0402094   -0.0954331    0.192354    -0.0312415   -0.542122     0.0384682    0.0521853
  0.121167     0.0247721   -0.153785     0.0215072   -0.12369     0.22733     -0.22946       0.00946198   -0.0534037    0.192719     0.0793684  -0.134774    -0.00766131   0.0699329    0.0180765   -0.0412771    0.140191     0.0274412     0.0483905    0.0128587   -0.180307     0.103445    -0.0711096    0.500087     0.0362893    0.0888247
  0.061125    -0.0720017   -0.0869563    0.012847    -0.0377248   0.0081582    0.182948      0.164798     -0.036407    -0.081086    -0.0656687   0.171693     0.100003     0.0126023    0.0758501   -0.182388     0.07903      0.122162      0.0145584   -0.0482135   -0.0196709   -0.0380279   -0.00575566   0.033436     0.203534    -0.115145
 -0.0475174   -0.235724     0.159545    -0.0179686    0.141477    0.0523063   -0.0322476    -0.0943665    -0.00530085   0.0246916   -0.124752    0.0318645   -0.0739257    0.0716004    0.0374044    0.00125743   0.23602     -0.19968       0.161268     0.0149907    0.0297563    0.0601608    0.0445794    0.144706    -0.0672563   -0.0228938
  0.013827    -0.0828543    0.148844    -0.0344618    0.0040787  -0.222909     0.178122      0.0386811    -0.0150653    0.122001    -0.0443547   0.0157908    0.225017     0.0574889   -0.0323538   -0.049276    -0.0173421   -0.135737      0.0466215    0.0724151    0.162434     0.0768309    0.0196141   -0.0145673   -0.0808255   -0.0550423
  0.0564409   -0.0122772   -0.0196282   -0.0304126   -0.067809    0.00682413   0.135934      0.0187651    -0.0593533   -0.0290014   -0.112592    0.0635809   -0.0199718   -0.0285824   -0.0275538    0.0896335   -0.0755108    0.0249905    -0.0406794   -0.0958912    0.101879    -0.0384238   -0.0310753   -0.0612176   -0.107914    -0.0301794
  0.0621716    0.0230374    0.0795635    0.041431     0.0765909  -0.119403    -0.0379837     0.0154403    -0.0338524   -0.0323112   -0.0907038  -0.0534499    0.0105057   -0.00437091  -0.00499118  -0.0723194    0.0067402   -0.0434074    -0.0960513    0.12271      0.0641051    0.00662077   0.0635083   -0.0027436    0.0710699    0.0422344
 -0.0111225   -0.0662647   -0.0443097    0.0206778    0.0819894  -0.0221735    0.0897509     0.0608628     0.0264732    0.0889472   -0.0238387  -0.121242    -0.0149353    0.0414584   -0.0437775   -0.0413065   -0.0945885   -0.0139562    -0.00104573   0.0147899   -0.0452494   -0.0109225   -0.0608529   -0.00938844  -0.0251039    0.0562231
 -0.0620063    0.0287004   -0.0442109    0.0577184    0.0745862   0.0755565   -0.0501393     0.175998     -0.192754    -0.229635    -0.106362    0.256168    -0.0520207   -0.0546862   -0.084051     0.0520864    0.0653284    0.033859      0.0126945    0.00828789   0.115199     0.0590528   -0.0236216    0.0777608    0.0676897   -0.0415381
 -0.0092939    0.0713447    0.0922925   -0.00432984   0.0664929   0.141204     0.0503618     0.220091      0.0857375    0.174206    -0.0265334   0.0197303    0.0439659   -0.0666594    0.0367065   -0.152509     0.108525     0.191627     -0.0307417    0.0551182    0.0412225    0.288392    -0.0826216   -0.15666      0.0933864   -0.0833266
  0.0787221    0.103383    -0.121747    -0.0617635    0.0514205  -0.0769386    0.130275     -0.0286262     0.110821    -0.0614439    0.018288    0.0887987    0.0163503    0.100989    -0.0154987    0.137581    -0.0329038   -0.112244      0.0395395   -0.224885     0.0824327   -0.0306421    0.0403636    0.0603144    0.0560319   -0.052279
 -0.113249    -0.203592     0.104785     0.184035     0.0915618   0.136084    -0.158216     -0.00481122    0.0289476   -0.0960543    0.0318767  -0.0327858   -0.0198818    0.00284904   0.0977687   -0.166777     0.0517105    0.00969622   -0.206848    -0.126014     0.192347    -0.0588176   -0.138834    -0.256756    -0.00687823  -0.00822096
 -0.00611164   0.10253     -0.244361    -0.00383549  -0.0318931  -0.0251381   -0.0391959     0.0467076     0.171824    -0.211633    -0.217451    0.0424279   -0.0702697   -0.17192     -0.0347086    0.131281     0.0227462   -0.0226038    -0.0383172    0.12175     -0.117793    -0.0974005    0.0272833    0.0121546   -0.101217    -0.0234629
 -0.0970088    0.0766743   -0.0603634   -0.0505612   -0.0963242  -0.0247212   -0.158419     -0.0470238     0.228274     0.312978    -0.223314    0.0481575   -0.00194013  -0.155644     0.123217     0.127597     0.026338    -0.0662018    -0.0380713    8.10872e-5   0.0114833    0.0817169    0.0321728   -0.00699124  -0.151161     0.0124228
 -0.0874076   -0.0080271    0.0187002    0.0498305   -0.236689   -0.109437     0.00956972   -0.00913907    0.0322301   -0.0718034    0.133292    0.128318    -0.0485344    0.0508529   -0.201259    -0.025777    -0.111599    -0.0542149    -0.165859     0.0492949    0.104323     0.0572561   -0.160122    -0.191534     0.0795109   -0.0725051
 -0.00923097  -0.160948     0.0747461   -0.0697417    0.0396817  -0.123284    -0.0813708     0.243071      0.0016167    0.0272542    0.0676624   0.0468426   -0.253485    -0.107434    -0.13797      0.00958514  -0.0908311    0.000648046   0.121155    -0.134741     0.00174205  -0.0224222    0.00124425  -0.180042     0.032429    -0.00769648
  0.0734435   -0.00804112  -0.107007    -0.0837171   -0.0383999  -0.16427      0.00274496    0.0590035    -0.0049629   -0.00191909  -0.14454     0.00369515  -0.0596298    0.130753    -0.167679    -0.129829    -0.0668362   -0.120726      0.0483071    0.0852195    0.0254135    0.151525    -0.142894    -0.0400022    0.194989    -0.155479
  0.0389408   -0.0555453   -0.139441    -0.12138      0.0529187  -0.0898059    0.0949641     0.0683644    -0.0513329    0.261218     0.0111151   0.0772765    0.18072      0.0396353    0.061278     0.00236833  -0.140213     0.0578831    -0.00198774   0.0274893   -0.204178    -0.159751    -0.159507    -0.0639808   -0.00511619  -0.00506701
  0.0620036   -0.0979428    0.00719204   0.0713786    0.0812336  -0.0747672   -0.0125206     0.0130231    -0.189109     0.264156    -0.847984   -0.050476    -0.0030781    0.0199799   -0.125502    -0.0872908    0.0452749    0.0452998     0.00745051  -0.127807    -0.181393     0.17876      0.0228722    0.0927868   -0.0754257    0.0245598
  0.14952      0.1561       0.0272653   -0.05485      0.13763    -0.0362556   -0.000793766   0.166966     -0.199617     0.245625     0.785579   -0.0750273   -0.0940539    0.062818    -0.0455324    0.0386764    0.0755446    0.00933739   -0.0116714   -0.126898    -0.190362    -0.292457     0.0690357    0.0954779   -0.0772964   -0.0427452
  0.00235018   0.104118    -0.183514    -0.0266506    0.118723    0.0743837   -0.00682261   -0.13974       0.0460738    0.299532     0.0735212  -0.0982333   -0.0487668    0.0615915   -0.117583     0.033091     0.0539131   -0.0879472    -0.084267    -0.752589     0.121402    -0.00413236   0.116597    -0.205954     0.0518875   -0.100282
  0.238862     0.108042    -0.142868     0.0886871    0.106301    0.0655395   -0.00398387   -0.172657      0.0310321    0.281196     0.0932816  -0.0937503    0.108479     0.0578779   -0.0348168    0.042809    -0.214645    -0.0195959    -0.0979534    0.72486      0.113672     0.270482     0.0400152   -0.0115676   -0.0166463   -0.113262
  0.0186375   -0.21478      0.187848    -0.0338361    0.0529651   0.00131073   0.0341353    -0.000718406  -0.0120195   -0.0957703   -0.0939767   0.0900041   -0.104467     0.111019    -0.0551938    0.0633796   -0.00260572  -0.0837149    -0.0274075    0.140427    -0.0578599   -0.0474303   -0.0989599   -0.0374628   -0.108981    -0.147807
 -0.167022    -0.00884881  -0.122823    -0.105068     0.0262235  -0.128309    -0.00437624    0.0528572    -0.00267669  -0.0377939    0.206822    0.0807534    0.0135913    0.0224894    0.1889      -0.0138201    0.0844793   -0.00743596    0.0799947    0.021752     0.121636     0.101827     0.105654    -0.0451693    0.0399462    0.134601
  0.200755    -0.126454     0.125205     0.00287758  -0.0195285  -0.0272645   -0.0517135     0.0773564     0.238062     0.129435     0.17305     0.112762     0.211384     0.0737441    0.139845     0.0493672    0.042183     0.192048      0.035977     0.143487    -0.227921     0.319167     0.0901107    0.177483     0.0545426   -0.00664492
  0.116671     0.0163444    0.0136432   -0.117341    -0.0200875   0.117682     0.107217     -0.0804199     0.156092     0.207124     0.0621301  -0.0611813    0.119092    -0.013759    -0.0164127    0.0312908   -0.0726766   -0.0763051     0.0567534    0.0586673    0.0530366    0.0950376   -0.223849     0.226693    -0.0473889   -0.158478[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     15
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.097761
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     15
│     17
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.072032
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     11
│     15
│     17
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.054144
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     11
│     15
│     17
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.078608
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     15
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.088657
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     10
│     11
│     15
│      ⋮
│     23
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.042150
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     15
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.093008
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     11
│     15
│     17
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.069773
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     11
│     15
│     17
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.058830
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     15
│     17
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.080860
┌ Info: EM with 100000 data points 10 iterations avll -1.080860
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.244086e+05
      1       7.060889e+05      -2.183197e+05 |       32
      2       6.791740e+05      -2.691492e+04 |       32
      3       6.668634e+05      -1.231059e+04 |       32
      4       6.573026e+05      -9.560812e+03 |       32
      5       6.507614e+05      -6.541146e+03 |       32
      6       6.462787e+05      -4.482713e+03 |       32
      7       6.416122e+05      -4.666503e+03 |       32
      8       6.388536e+05      -2.758599e+03 |       32
      9       6.377165e+05      -1.137122e+03 |       32
     10       6.370470e+05      -6.694549e+02 |       32
     11       6.364583e+05      -5.887464e+02 |       32
     12       6.356844e+05      -7.739089e+02 |       32
     13       6.344164e+05      -1.267954e+03 |       32
     14       6.332000e+05      -1.216425e+03 |       32
     15       6.327009e+05      -4.990760e+02 |       32
     16       6.324348e+05      -2.660985e+02 |       32
     17       6.322283e+05      -2.065275e+02 |       32
     18       6.320324e+05      -1.959052e+02 |       32
     19       6.318456e+05      -1.867337e+02 |       32
     20       6.316375e+05      -2.081425e+02 |       32
     21       6.313853e+05      -2.522346e+02 |       32
     22       6.310274e+05      -3.578236e+02 |       32
     23       6.305633e+05      -4.641123e+02 |       32
     24       6.300346e+05      -5.287232e+02 |       32
     25       6.295857e+05      -4.489181e+02 |       32
     26       6.291636e+05      -4.220432e+02 |       32
     27       6.287907e+05      -3.728990e+02 |       32
     28       6.285174e+05      -2.733086e+02 |       32
     29       6.283107e+05      -2.067057e+02 |       32
     30       6.281403e+05      -1.704103e+02 |       32
     31       6.280137e+05      -1.265876e+02 |       32
     32       6.279245e+05      -8.923630e+01 |       32
     33       6.278610e+05      -6.349816e+01 |       32
     34       6.278239e+05      -3.713138e+01 |       32
     35       6.277931e+05      -3.080478e+01 |       31
     36       6.277703e+05      -2.277040e+01 |       28
     37       6.277535e+05      -1.677562e+01 |       30
     38       6.277399e+05      -1.362806e+01 |       28
     39       6.277287e+05      -1.124148e+01 |       29
     40       6.277217e+05      -6.935549e+00 |       26
     41       6.277154e+05      -6.329883e+00 |       23
     42       6.277100e+05      -5.352142e+00 |       27
     43       6.277022e+05      -7.875696e+00 |       27
     44       6.276956e+05      -6.598070e+00 |       26
     45       6.276896e+05      -5.963518e+00 |       28
     46       6.276833e+05      -6.307237e+00 |       23
     47       6.276769e+05      -6.419865e+00 |       23
     48       6.276709e+05      -5.981751e+00 |       23
     49       6.276661e+05      -4.811808e+00 |       22
     50       6.276625e+05      -3.556423e+00 |       23
K-means terminated without convergence after 50 iterations (objv = 627662.5195554809)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.338189
[ Info: iteration 2, average log likelihood -1.308637
[ Info: iteration 3, average log likelihood -1.279116
[ Info: iteration 4, average log likelihood -1.243245
[ Info: iteration 5, average log likelihood -1.192618
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.124335
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.101387
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     22
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.073149
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.088530
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      8
│     10
│     14
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.063427
[ Info: iteration 11, average log likelihood -1.111429
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     22
│     24
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.053065
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     10
│     12
│     14
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.066174
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      8
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.097016
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.084685
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     22
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.058587
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     10
│     12
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.051845
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.091415
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.065054
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     10
│     20
│     22
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.044331
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     12
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.082450
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.094887
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      7
│     20
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.050821
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     12
│     14
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.049755
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.093645
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.080382
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      7
│     12
│     22
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.025135
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     10
│     14
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.069439
[ Info: iteration 29, average log likelihood -1.121188
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.066460
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│     10
│     12
│      ⋮
│     24
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -0.998002
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.122983
[ Info: iteration 33, average log likelihood -1.109739
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.054803
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      8
│     10
│      ⋮
│     24
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.000654
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.131823
[ Info: iteration 37, average log likelihood -1.105255
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.053947
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      8
│     10
│     12
│      ⋮
│     27
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -0.995001
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.135998
[ Info: iteration 41, average log likelihood -1.105355
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.048813
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      7
│      8
│     10
│      ⋮
│     27
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -0.994130
[ Info: iteration 44, average log likelihood -1.149568
[ Info: iteration 45, average log likelihood -1.104131
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.055339
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      8
│     10
│     12
│     14
│     24
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -0.999362
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.118351
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.101930
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.063911
┌ Info: EM with 100000 data points 50 iterations avll -1.063911
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0160621   -0.21292       0.184103     -0.0346383    0.054209     0.000483626   0.0358144   -0.00309462  -0.00645762  -0.0902897   -0.0882968   0.0893874   -0.100586     0.107334    -0.0494133    0.0629074    -0.00232423  -0.0838233   -0.0250973     0.14033     -0.056669    -0.0423249   -0.0996777    -0.0298582   -0.106584    -0.142715
 -0.087659    -0.00826284    0.0187597     0.0500347   -0.238463    -0.109972      0.00981287  -0.00734257   0.0311513   -0.0717586    0.133921    0.128105    -0.0491326    0.0529027   -0.201081    -0.0260329    -0.111754    -0.0530717   -0.165433      0.0481885    0.103771     0.0571785   -0.159667     -0.192321     0.0801113   -0.0723608
  0.0612698   -0.0721661    -0.0869128     0.00923784  -0.0367203    0.0120834     0.177938     0.159038    -0.0360622   -0.0823416   -0.0584242   0.167942     0.0997164    0.0120826    0.0760452   -0.180341      0.0737166    0.119704     0.012822     -0.0451425   -0.0195848   -0.0342488   -0.0108909     0.0378487    0.198172    -0.109216
  0.039857    -0.0591437    -0.144735     -0.123055     0.0544932   -0.093991      0.0932255    0.0721679   -0.0505008    0.256791     0.0101727   0.0773573    0.180361     0.040341     0.0691436    0.00111329   -0.139196     0.0621433    0.000255975   0.0269722   -0.218136    -0.164656    -0.165146     -0.0622061   -0.00865431  -0.00737596
  0.102436     0.0199974     0.00914843    0.0131763    0.10875     -0.0563074    -0.00766974   0.0854106   -0.196905     0.252693    -0.0860398  -0.0628061   -0.0471079    0.0375617   -0.0893781   -0.02943       0.0595624    0.0331682   -3.52989e-5   -0.13482     -0.190196    -0.0482376    0.044968      0.0944058   -0.0727242   -0.00680407
 -0.0338186   -0.275918     -0.0435361     0.200808    -0.242451     0.0525096     0.15283     -0.0655545   -0.0262587    0.0897913    0.0579104  -0.0211176    0.0166321   -0.165581    -0.0334687    0.00502327   -0.0638543   -0.343273    -0.0144135     0.0103219    0.191328     0.0432016   -0.0635886     0.121728    -0.0904514   -0.229922
  0.136018    -0.0576314    -0.0885258     2.32141e-5   0.0671064    0.153702      0.288528     0.100564     0.119052     0.396953    -0.211889   -0.00771546   0.107606     0.0132827   -0.127697     0.083547     -0.261786     0.0034156    0.0467035     0.00867209   0.0103894   -0.105625    -0.136112      0.0259142   -0.0933798   -0.0340322
  0.0101518   -0.0789285     0.232609     -0.0231782    0.0290751   -0.196925      0.159997     0.0147635   -0.00742031   0.124593    -0.0555519   0.0174452    0.214672     0.0612003   -0.0216759   -0.0431656     0.0159415   -0.154618     0.057874      0.0682672    0.141865     0.0749257    0.0366144     0.00264765  -0.0833337   -0.048849
 -0.0676093    0.114832      0.0222093     0.0214952    0.125586    -0.133287     -0.204944    -0.0203569   -0.0394984    0.0970344   -0.032593   -0.106329    -0.0107221   -0.101866     0.0714535   -0.181011      0.0636301   -0.166447    -0.0443273     0.0848643    0.0459114   -0.0246823    0.0155092    -0.10211      0.0814611    0.0143932
 -0.0542021    0.0434044    -0.0490301     0.0531661    0.071588     0.0672374    -0.0460568    0.173697    -0.205369    -0.235333    -0.104217    0.255484    -0.0407396   -0.0517743   -0.0817581    0.0598799     0.0469777    0.0336699    0.0145055     0.00748258   0.118162     0.0495151   -0.0164118     0.0731448    0.0657873   -0.0408428
  0.145721     0.0290426    -0.0882553     0.00272372  -0.151938     0.251269     -0.229365    -0.00983513  -0.0606395    0.072373     0.025636   -0.0815833    0.0133155    0.0871794    0.00500039  -0.260359      0.0689181    0.0210163    0.0685336     0.0249084   -0.138754     0.147366    -0.0496482    -0.0156054    0.0375258    0.0717986
  0.0720886   -0.00713216   -0.111523     -0.083475    -0.0382621   -0.162145      0.00276361   0.05799     -0.00371355  -0.00204432  -0.145426    0.00364742  -0.0578255    0.131296    -0.16749     -0.128875     -0.0675899   -0.120263     0.0486173     0.0846399    0.0224231    0.149641    -0.140761     -0.0358872    0.188269    -0.15542
  0.0879803   -0.0828101    -0.115748     -0.0631597   -0.103679    -0.13562       0.0957446   -0.129388    -0.102646    -0.0336693   -0.131863    0.129837     0.125127     0.0530043   -0.0736431    0.0711355    -0.232372     0.0132246   -0.00665414   -0.107632     0.186623    -0.0948248   -0.0024514    -0.200268    -0.0448165   -0.0550248
 -0.00964681  -0.160605      0.0740616    -0.0682083    0.0395971   -0.123482     -0.0796084    0.241428     0.00197469   0.0293011    0.0663738   0.0466614   -0.252136    -0.103444    -0.137016     0.00874085   -0.0901749   -6.62148e-5   0.120183     -0.133532     0.00544479  -0.0209418    0.000581009  -0.177406     0.0355138   -0.00789198
 -0.0528678    0.0881417    -0.145884     -0.0280084   -0.0683703   -0.0249308    -0.0990729   -0.00110424   0.200559     0.0610696   -0.21979     0.045166    -0.0349563   -0.161575     0.0467456    0.128825      0.024489    -0.0446289   -0.0388129     0.0568919   -0.0477499   -0.00340526   0.0296182     0.0011223   -0.128289    -0.00445807
 -0.125151     0.147852      0.0646607     0.0188937    0.0819158    0.120681     -0.140743    -0.148464     0.127759    -0.049942    -0.0279885  -0.137066     0.144951    -0.0960159   -0.124839     0.0524409     0.0698555   -0.169992    -0.122741      0.159886     0.00328918   0.0181564   -0.0432747     0.0105345   -0.0520428   -0.0303768
  0.0747683    0.0604331     0.196641      0.21147      0.068237    -0.153513      0.107335     0.0394398   -0.0466036   -0.132806    -0.0288525  -0.113536     0.0128209    0.14294     -0.115424    -0.0252537    -0.11043     -0.0745555   -0.0151995     0.132684     0.0216615    0.0610199    0.102128     -0.0459648    0.0980916   -0.0109713
  0.037561     0.0347557    -0.0855024    -0.00739819   0.0354567   -0.0310525     0.0498004    0.052456     0.060187     0.027874    -0.0102244  -0.00973831   0.00213111   0.0876667    0.0166243   -0.0156687    -0.0442784   -0.0442495    0.00606765   -0.0192139   -0.0654714    0.0168947   -0.0575912     0.0459393    0.0374682    0.0534119
  0.0194709    0.044301      0.0840565     0.00544864  -0.0303596    0.140376      0.180521     0.173688    -0.0165604   -0.0167263   -0.0881486  -0.0104613   -0.164368    -0.115128     0.0214221    0.0970092     0.101206     0.0310814   -0.0735788    -0.0801345    0.0258183    0.0247729   -0.0581025     0.0757999   -0.160661     0.000498787
  0.0511238   -0.0611751     0.134855     -0.0598935   -0.00696951  -0.151145      0.129057     0.0169347   -0.0179207    0.14083     -0.0265101   0.0405978    0.146389     0.0572134   -0.0265171   -0.0613802    -0.0647321   -0.201117     0.0416017     0.0131152    0.192357     0.0640427   -0.0457998     0.0180872   -0.044465    -0.0783556
 -0.00876042   0.067073      0.0899674    -6.9904e-6    0.0663269    0.135058      0.0485379    0.220631     0.0738777    0.158224    -0.0286465   0.0261434    0.0405503   -0.061307     0.0314248   -0.148924      0.105974     0.185485    -0.0310613     0.0535974    0.0449735    0.286197    -0.0807883    -0.141868     0.0940365   -0.0826794
  0.117861    -0.00887551   -0.0331308    -0.0487533    0.219075    -0.0999186    -0.122018     0.0146318   -0.0350647   -0.0951147   -0.0472198   0.0319345    0.0720365    0.0481588    0.0676999   -0.0258862    -0.136917     0.103449     0.109568      0.0529934    0.0426652   -0.356168    -0.170736      0.100629    -0.0388591   -0.0144867
 -0.111204    -0.187216      0.091813      0.1708       0.0917613    0.134878     -0.139295    -0.0065817    0.0309925   -0.103132     0.0308422  -0.0266114   -0.0173609    0.00692736   0.0911201   -0.156057      0.0465348   -0.0130882   -0.20404      -0.133694     0.188826    -0.0600842   -0.13583      -0.243355    -0.00800099  -0.0137995
 -0.164621    -0.000966651  -0.122601     -0.105363     0.0274605   -0.12248      -0.004018     0.054556    -0.00171598  -0.0439402    0.206239    0.0766178    0.0200204    0.0203158    0.181       -0.00988843    0.0797318   -0.00919086   0.07987       0.0252111    0.119201     0.100573     0.0980498    -0.0355969    0.0370309    0.128264
 -0.0550495   -0.147144     -0.116044      0.0645988    0.0171944   -0.154222     -0.0508247   -0.130177    -0.0503972    0.0500063    0.042831    0.0246213   -0.0594631   -0.214915    -0.104825    -0.0327131     0.0338515    0.0888663    0.0117447     0.157978    -0.141721     0.0253082   -0.0105597    -0.0740951    0.0827511    0.0053068
  0.212052    -0.109513      0.115226     -0.016388    -0.0132635   -0.019832     -0.0359581    0.0734585    0.229336     0.111141     0.176334    0.110995     0.20307      0.0732538    0.136506     0.0590285     0.0357041    0.181896     0.0338153     0.121054    -0.2038       0.298509     0.0738458     0.180699     0.043979    -0.0135012
 -0.142993    -0.130283     -0.00574512    0.022585     0.152124    -0.177163      0.0661897   -0.0164186   -0.00726499  -0.109728     0.103308   -0.264718    -0.0984677    0.00596109  -0.0785727   -0.0215781    -0.0152415   -0.0492844    0.0207436    -0.0832426    0.0401764   -0.0158236    0.0692673    -0.087459    -0.0370345    0.0307728
  0.161615    -0.169852     -0.0246726     0.160331    -0.0105078   -0.136812     -0.0539122   -0.0502055   -0.00592954  -0.0277572    0.137808    0.247796    -0.0410168   -0.182283    -0.0752741    0.0606308    -0.0369361   -0.163033     0.0406024    -0.198672     0.0117766    0.179245     0.0439272     0.115231    -0.143271    -0.148303
  0.113824     0.0233646     0.000427596  -0.1237      -0.036488     0.117734      0.12432     -0.101069     0.161448     0.256181     0.0599433  -0.0813259    0.112612    -0.0278374   -0.0417364    0.041549     -0.0807257   -0.0987798    0.0627019     0.0542079    0.0601132    0.0941387   -0.231178      0.236289    -0.0513583   -0.168397
  0.161476    -0.125061      0.0303577    -0.0984991    0.0427013   -0.0944902    -0.00330409   0.00739667  -0.0150325   -0.0597008   -0.19083     0.052332     0.035761    -0.0206836    0.0261763   -0.0066064     0.0555398    0.104246    -0.220393      0.143351     0.124546    -0.00794276   0.0748642     0.136093     0.0079314    0.118527
 -0.0561017   -0.276593      0.159293     -0.0299063    0.15056      0.0623685    -0.046611    -0.10501     -0.00928888   0.0244309   -0.12464     0.0322525   -0.0711563    0.0712167    0.035942     0.000439997   0.252366    -0.199228     0.170053      0.0166126    0.0282003    0.062373     0.0426648     0.155445    -0.0916285   -0.0212962
  0.1273       0.106175     -0.161939      0.0339115    0.112371     0.0688937    -0.00518072  -0.155747     0.0383553    0.288576     0.0833087  -0.0957727    0.0331397    0.0596401   -0.0740978    0.0382842    -0.089471    -0.0522374   -0.0911081     0.026712     0.117477     0.141        0.0765118    -0.102709     0.0168381   -0.107048[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     10
│     14
│     24
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.010404
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      7
│      8
│     10
│      ⋮
│     27
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.982511
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     10
│     12
│     14
│     24
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.992465
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      7
│      8
│     10
│      ⋮
│     27
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.992880
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      7
│     10
│     14
│     20
│     24
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.991470
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      8
│     10
│     12
│      ⋮
│     27
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.981427
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      7
│     10
│     14
│     24
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.006046
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      8
│     10
│     14
│      ⋮
│     27
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.975255
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      7
│     10
│     12
│     14
│     24
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.993897
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      8
│     10
│     14
│     22
│     24
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.995392
┌ Info: EM with 100000 data points 10 iterations avll -0.995392
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.042008     0.13838      0.139178     0.00386584   -0.0385491    0.0387193   -0.0594084    0.117549     -0.0339663   -0.0401153    0.169086    -0.00226982    0.0630253    0.0964434    0.188365    0.0386023    -0.134125     -0.0767992     0.00788223   0.154772     0.113448    -0.0596929  -0.0118684    0.0265927    0.0198879    -0.124543
  0.0647404   -0.102899     0.0895913    0.0141848    -0.0530339   -0.10688      0.00340447  -0.0427112     0.00481938  -0.0528273   -0.0139867   -0.0813325    -0.0581079    0.052214    -0.196754    0.0429816    -0.114557      0.00742264   -0.0261477    0.0396784   -0.32126      0.169781   -0.087106     0.0589372    0.000333915  -0.158084
 -0.0312607    0.174475    -0.0349762    0.102186      0.116103     0.0487627    0.108219    -0.0505822    -0.0282293    0.00660889  -0.00120157  -0.030935      0.134759     0.0171872   -0.170733    0.146141      0.000520706  -0.0400602    -0.131344     0.13971     -0.0853353    0.301978   -0.0575841   -0.00585799   0.115207      0.0829987
  0.0267225    0.0932484   -0.0203297    0.057704     -0.0236398   -0.035579    -0.0754887    0.0876105    -0.0202943    0.0301416    0.0907968   -0.110884      0.0231122    0.00681027  -0.0394903   0.128534      0.00205132   -0.0887963     0.0588835   -0.100607     0.0839193    0.147179    0.245668     0.0502099   -0.0795186     0.0960584
  0.00594338  -0.13661     -0.0334442   -0.0451439     0.0672307    0.146309    -0.0434798   -0.0214119     0.0498627   -0.152856     0.0189628   -0.066037      0.100177    -0.13825      0.215304    0.0536632     0.0459754     0.180856      0.153749     0.0880888    0.0952413    0.123681    0.0595612    0.0977024   -0.0813473    -0.031076
  0.0323874   -0.180734    -0.0437442   -0.0576472    -0.0277635    0.053098     0.0808433   -0.159795     -0.0498327   -0.0679365   -0.0456386    0.0959814     0.0650498   -0.108545     0.0867286  -0.000784868   0.0644222     0.316214      0.0682312    0.0659235    0.0388958   -0.0233785  -0.0177541   -0.139469     0.157931     -0.0486454
 -0.182163     0.0370497    0.0719697   -0.0522436    -0.087136    -0.0813254    0.0262898   -0.139839      0.0435495    0.0810391    0.0387783   -0.0127365    -0.0318122   -0.127947     0.0374701  -0.0476323    -0.0385136     0.00982887   -0.0997173    0.0325863    0.176898    -0.184867   -0.0158478    0.123766    -0.00383432   -0.0802502
  0.126566    -0.0492243    0.0628365   -0.154576      0.121714    -0.191302    -0.0220173    0.0363961    -0.0363932    0.0728864    0.0623883    0.071728      0.099213     0.102705    -0.0152458  -0.0174905    -0.0293088     0.120677      0.00747016   0.173951    -0.103454     0.116452    0.047184    -0.0858802    0.00802996    0.0324945
  0.00148615   0.0425925    0.0121419    0.0546878    -0.0457259   -0.254429     0.0432125   -0.0415608    -0.0346325    0.0973803    0.0179159    0.0582277     0.0565237   -0.128975    -0.190836   -0.00374661   -0.00911712    0.0503158    -0.0476668    0.08164     -0.0985755    0.0708793  -0.134416    -0.0278296    0.0816506    -0.0196224
  0.0319086    0.0341858   -0.0807794   -0.0328379     0.113578    -0.0945751   -0.0539354   -0.103981     -0.0632534    0.00877155  -0.0976559    0.233477      0.0220238   -0.0614455   -0.0730494   0.057565     -0.0443668    -0.105133      0.018103     0.0672701   -0.0332902   -0.0258898   0.0937921   -0.12778      0.162007      0.1335
 -0.0568175   -0.0163163   -0.0284854   -0.0446632     0.0918801   -0.115324     0.0490033    0.000343438  -0.0110866   -0.0406226   -0.0446761   -0.184694      0.155416     0.178013     0.117027   -0.175351      0.0401494     0.0931383    -0.00805327  -0.0816145   -0.0763416   -0.0535712   0.072071    -0.19297     -0.0413733     0.0379874
 -0.0478344   -0.0902762    0.0357393    0.144354     -0.0699707    0.00649102  -0.0309042    0.165062     -0.0176682    0.0368774   -0.0476225    0.116042     -0.0206303   -0.113952    -0.239678    0.109418     -0.00276563    0.000430665  -0.0336062   -0.0406719   -0.153131     0.01252     0.0603246    0.017488    -0.0220378     0.0459344
  0.0290649   -0.198432     0.0194795   -0.00468578   -0.0510188   -0.0367318    0.0208847   -0.0765844     0.00360372  -0.142508     0.166489     0.0694304     0.0410858   -0.143297    -0.0586754   0.113202     -0.0429518    -0.0671208     0.0462205   -0.0219458    0.128728     0.0285211   0.0143095    0.138975    -0.00517566   -0.011331
  0.0805784   -0.0520244   -0.217024     0.0343698    -0.106627     0.148308    -0.123073     0.0364608     0.0489432   -0.0473042   -0.0382737    0.0375762    -0.0381696    0.0474993    0.0124205  -0.144932     -0.301838     -0.00818674    0.0394407    0.0893236   -0.102283    -0.214418    0.137651    -0.102587     0.0684093    -0.0103186
 -0.0285064   -0.138409    -0.127113    -0.104085      0.0958063    0.09251     -0.00157313   0.0574086     0.0490772   -0.192071    -0.0326793    0.0328393    -0.0962697    0.00406515  -0.0911976  -0.0185787     0.142503     -0.0273553    -0.196129     0.196266     0.0348618   -0.142512    0.0512604    0.167012     0.173297     -0.0222583
  0.172216    -0.0574605    0.0475251   -0.174145     -0.0807496    0.047752     0.0282549    0.0601505     0.145672    -0.0427687   -0.263585     0.0236712     0.0685612   -0.0575213    0.0575521   0.129819     -0.0912898     0.128735     -0.104188     0.0699799    0.128858     0.0188756   0.175501     0.0838888   -0.0146856     0.0518115
  0.0430832    0.00873108  -0.128453     0.0648909     0.0745353   -0.100879     0.192375     0.0395545     0.00629661  -0.019366     0.06432     -0.0915344    -0.10209      0.0191443    0.099525   -0.0647947     0.0743055     0.112703      0.0234329    0.043008    -0.218033     0.0475986  -0.0569101    0.0151183    0.0170943     0.00743379
 -0.0370376    0.0841715    0.0299001    0.00926057    0.0665194    0.158626    -0.119745     0.221274     -0.0571173   -0.117763     0.0273896    0.075056      0.19288      0.0365524   -0.17587    -0.0826234    -0.00560163   -0.000123306  -0.0919984    0.0725442   -0.180836     0.102741   -0.112586    -0.0345274   -0.0474145    -0.111083
  0.0692349   -0.0513047   -0.0906521    0.128674      0.0815768   -0.0933318   -0.0280883   -0.173802      0.0276986    7.02817e-5  -0.0510597    0.0334947    -0.0787606    0.0811352    0.0174314   0.150143     -0.271322     -0.0549099     0.103458    -0.0106745    0.0550879   -0.0129313  -0.0459554   -0.0151004   -0.145346     -0.036022
  0.254239    -0.100552     0.0680896   -0.0639784     0.0292665   -0.0082625   -0.119944     0.310847     -0.0247299   -0.0912085    0.122532     0.176386      0.0617439   -0.0420336    0.0736955  -0.184851     -0.183268     -0.0029681    -0.163772    -0.136866     0.0445546    0.072839    0.00261421  -0.076866    -0.0291213     0.0840451
  0.0836763    0.0681986    0.154383    -0.00756708    0.0742274   -0.0545419   -0.00186933  -0.0520021     0.169611     0.0704518    0.104194    -0.0927874    -0.141313     0.0699911    0.021518    0.165882      0.06824       0.0750696    -0.149167    -0.0198443   -0.00727931  -0.0514174   0.199093    -0.0604484   -0.0036476     0.162162
  0.120571     0.049097    -0.0205883   -0.0556346     0.124365     0.01358     -0.0458707    0.00117041    0.0226921    0.110993    -0.0509772    0.109363     -0.00354609   0.0198679    0.107074    0.116586      0.138763     -0.00784141    0.0642917    0.0544974    0.00495882  -0.235658   -0.00362529   0.136997    -0.0646221     0.1248
  0.0958452    0.0788313   -0.0321928    0.134927     -0.129365    -0.175788     0.146215     0.0101498     0.0866664   -0.160332     0.02912      0.0555529     0.00817535   0.0741112   -0.0627398   0.0911065    -0.217874     -0.0924295     0.0970472    0.00653246   0.106204    -0.0719486   0.177394     0.00345864  -0.0231429    -0.0434283
  0.203831    -0.01851      0.0915437    0.142638     -0.00359814  -0.17943      0.0727228   -0.0125416    -0.0386626   -0.0842206   -0.0976513   -0.0792164    -0.0156553    0.0180902   -0.201749    0.070387      0.168361     -0.0246077     0.0315754   -0.0103981   -0.119061     0.0690766   0.0380695   -0.111097     0.10102       0.111341
 -0.00448554   0.0828499    0.0540267   -0.0501205     0.154867    -0.0513685    0.166391    -0.125905     -0.0445293    0.103124    -0.0896643    0.0610041     0.0098641   -0.0970553    0.0658431   0.171746     -0.28657      -0.0720107     0.0900055    0.187217    -0.194909     0.042872   -0.042313    -0.137806    -0.16411       0.0377952
 -0.0705271    0.0822379   -0.0684784    0.0971016     0.0362344    0.203476     0.072908    -0.0148465    -0.136439    -0.099892     0.0947982    0.000465011   0.146101    -0.145986     0.0928026   0.135308     -0.142144      0.111039     -0.110685     0.0305142   -0.018279     0.0273578   0.133097    -0.0574247    0.0291833    -0.0510941
  0.173542     0.104594     0.00189393  -0.00382698   -0.119752     0.00958829   0.0946902    0.075324     -0.125244    -0.141035     0.0328661    0.0703138     0.113223     0.0363751    0.127213   -0.0433731     0.0141619    -0.0116215    -0.0704413    0.0457411    0.00487424   0.030215   -0.0251081    0.00715773  -0.0585012     0.206301
 -0.0199346    0.0768891    0.0552237    0.0880682     0.174915    -0.0169864    0.0593487   -0.0107424     0.0942795   -0.230816     0.234575     0.0815899     0.0501033    0.0704232   -0.180326   -0.0312407     0.0600059     0.145204     -0.029072     0.0158482   -0.0935813    0.149538   -0.0192914   -0.0225712   -0.0860439     0.0787007
  0.0325494    0.0391427   -0.0337418    0.108009      0.0798749    0.0116355   -0.0087332   -0.221812      0.0622005    0.100956    -0.0621355   -0.142387     -0.125779     0.00162384  -0.0672192   0.0733612    -0.00809783    0.0479089     0.12522     -0.114278    -0.207264    -0.036914   -0.0416147   -0.0404997    0.019546     -0.0507852
  0.00398242   0.0902956    0.0860214   -0.0395716     0.0835212   -0.0802702   -0.0153934    0.0137074     0.0049171    0.120886    -0.128914    -0.0548401     0.182752    -0.162517     0.0184472  -0.0477512     0.0760304     0.0217737     0.0147166   -0.151828    -0.0495697   -0.0555742   0.0438327    0.0194361    0.0732954     0.0702587
 -0.103079    -0.0460754    0.0237935   -0.0812056     0.00847411  -0.298501     0.0486618   -0.155978      0.08028      0.11674     -0.0985487    0.0157288    -0.102645     0.0855552    0.12156     0.121324      0.058265      0.0127959     0.12002     -0.0808339    0.0329479   -0.11221     0.0580244   -0.0416947   -0.0584134     0.0851577
  0.0126884    0.15865      0.0688398    0.000203122  -0.0575138    0.0444841   -0.0487657   -0.0068636     0.0711365    0.0284032    0.0670337    0.116463     -0.0721785    0.00546819  -0.0997822  -0.0928335    -0.096202      0.125163      0.144884     0.0206151    0.0709128   -0.100279    0.00268851  -0.107586    -0.0353761    -0.0217424kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4226580547412735
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422678
[ Info: iteration 2, average log likelihood -1.422582
[ Info: iteration 3, average log likelihood -1.422502
[ Info: iteration 4, average log likelihood -1.422408
[ Info: iteration 5, average log likelihood -1.422297
[ Info: iteration 6, average log likelihood -1.422174
[ Info: iteration 7, average log likelihood -1.422041
[ Info: iteration 8, average log likelihood -1.421894
[ Info: iteration 9, average log likelihood -1.421702
[ Info: iteration 10, average log likelihood -1.421402
[ Info: iteration 11, average log likelihood -1.420907
[ Info: iteration 12, average log likelihood -1.420157
[ Info: iteration 13, average log likelihood -1.419235
[ Info: iteration 14, average log likelihood -1.418394
[ Info: iteration 15, average log likelihood -1.417841
[ Info: iteration 16, average log likelihood -1.417560
[ Info: iteration 17, average log likelihood -1.417436
[ Info: iteration 18, average log likelihood -1.417385
[ Info: iteration 19, average log likelihood -1.417364
[ Info: iteration 20, average log likelihood -1.417355
[ Info: iteration 21, average log likelihood -1.417351
[ Info: iteration 22, average log likelihood -1.417349
[ Info: iteration 23, average log likelihood -1.417348
[ Info: iteration 24, average log likelihood -1.417347
[ Info: iteration 25, average log likelihood -1.417347
[ Info: iteration 26, average log likelihood -1.417347
[ Info: iteration 27, average log likelihood -1.417346
[ Info: iteration 28, average log likelihood -1.417346
[ Info: iteration 29, average log likelihood -1.417346
[ Info: iteration 30, average log likelihood -1.417346
[ Info: iteration 31, average log likelihood -1.417345
[ Info: iteration 32, average log likelihood -1.417345
[ Info: iteration 33, average log likelihood -1.417345
[ Info: iteration 34, average log likelihood -1.417345
[ Info: iteration 35, average log likelihood -1.417345
[ Info: iteration 36, average log likelihood -1.417345
[ Info: iteration 37, average log likelihood -1.417345
[ Info: iteration 38, average log likelihood -1.417345
[ Info: iteration 39, average log likelihood -1.417345
[ Info: iteration 40, average log likelihood -1.417345
[ Info: iteration 41, average log likelihood -1.417344
[ Info: iteration 42, average log likelihood -1.417344
[ Info: iteration 43, average log likelihood -1.417344
[ Info: iteration 44, average log likelihood -1.417344
[ Info: iteration 45, average log likelihood -1.417344
[ Info: iteration 46, average log likelihood -1.417344
[ Info: iteration 47, average log likelihood -1.417344
[ Info: iteration 48, average log likelihood -1.417344
[ Info: iteration 49, average log likelihood -1.417344
[ Info: iteration 50, average log likelihood -1.417344
┌ Info: EM with 100000 data points 50 iterations avll -1.417344
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4226779382611712
│     -1.4225816308143806
│      ⋮
└     -1.417344133446444
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417364
[ Info: iteration 2, average log likelihood -1.417264
[ Info: iteration 3, average log likelihood -1.417180
[ Info: iteration 4, average log likelihood -1.417081
[ Info: iteration 5, average log likelihood -1.416967
[ Info: iteration 6, average log likelihood -1.416849
[ Info: iteration 7, average log likelihood -1.416743
[ Info: iteration 8, average log likelihood -1.416659
[ Info: iteration 9, average log likelihood -1.416598
[ Info: iteration 10, average log likelihood -1.416555
[ Info: iteration 11, average log likelihood -1.416523
[ Info: iteration 12, average log likelihood -1.416499
[ Info: iteration 13, average log likelihood -1.416478
[ Info: iteration 14, average log likelihood -1.416460
[ Info: iteration 15, average log likelihood -1.416443
[ Info: iteration 16, average log likelihood -1.416426
[ Info: iteration 17, average log likelihood -1.416410
[ Info: iteration 18, average log likelihood -1.416394
[ Info: iteration 19, average log likelihood -1.416378
[ Info: iteration 20, average log likelihood -1.416362
[ Info: iteration 21, average log likelihood -1.416345
[ Info: iteration 22, average log likelihood -1.416329
[ Info: iteration 23, average log likelihood -1.416313
[ Info: iteration 24, average log likelihood -1.416298
[ Info: iteration 25, average log likelihood -1.416284
[ Info: iteration 26, average log likelihood -1.416270
[ Info: iteration 27, average log likelihood -1.416258
[ Info: iteration 28, average log likelihood -1.416246
[ Info: iteration 29, average log likelihood -1.416236
[ Info: iteration 30, average log likelihood -1.416226
[ Info: iteration 31, average log likelihood -1.416217
[ Info: iteration 32, average log likelihood -1.416209
[ Info: iteration 33, average log likelihood -1.416202
[ Info: iteration 34, average log likelihood -1.416195
[ Info: iteration 35, average log likelihood -1.416189
[ Info: iteration 36, average log likelihood -1.416183
[ Info: iteration 37, average log likelihood -1.416178
[ Info: iteration 38, average log likelihood -1.416173
[ Info: iteration 39, average log likelihood -1.416169
[ Info: iteration 40, average log likelihood -1.416165
[ Info: iteration 41, average log likelihood -1.416161
[ Info: iteration 42, average log likelihood -1.416157
[ Info: iteration 43, average log likelihood -1.416154
[ Info: iteration 44, average log likelihood -1.416150
[ Info: iteration 45, average log likelihood -1.416147
[ Info: iteration 46, average log likelihood -1.416145
[ Info: iteration 47, average log likelihood -1.416142
[ Info: iteration 48, average log likelihood -1.416140
[ Info: iteration 49, average log likelihood -1.416137
[ Info: iteration 50, average log likelihood -1.416135
┌ Info: EM with 100000 data points 50 iterations avll -1.416135
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4173637417219727
│     -1.4172638564105149
│      ⋮
└     -1.4161351349832325
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416145
[ Info: iteration 2, average log likelihood -1.416075
[ Info: iteration 3, average log likelihood -1.416012
[ Info: iteration 4, average log likelihood -1.415936
[ Info: iteration 5, average log likelihood -1.415839
[ Info: iteration 6, average log likelihood -1.415720
[ Info: iteration 7, average log likelihood -1.415582
[ Info: iteration 8, average log likelihood -1.415437
[ Info: iteration 9, average log likelihood -1.415299
[ Info: iteration 10, average log likelihood -1.415179
[ Info: iteration 11, average log likelihood -1.415082
[ Info: iteration 12, average log likelihood -1.415005
[ Info: iteration 13, average log likelihood -1.414945
[ Info: iteration 14, average log likelihood -1.414899
[ Info: iteration 15, average log likelihood -1.414862
[ Info: iteration 16, average log likelihood -1.414832
[ Info: iteration 17, average log likelihood -1.414808
[ Info: iteration 18, average log likelihood -1.414788
[ Info: iteration 19, average log likelihood -1.414771
[ Info: iteration 20, average log likelihood -1.414757
[ Info: iteration 21, average log likelihood -1.414744
[ Info: iteration 22, average log likelihood -1.414733
[ Info: iteration 23, average log likelihood -1.414724
[ Info: iteration 24, average log likelihood -1.414715
[ Info: iteration 25, average log likelihood -1.414708
[ Info: iteration 26, average log likelihood -1.414701
[ Info: iteration 27, average log likelihood -1.414695
[ Info: iteration 28, average log likelihood -1.414689
[ Info: iteration 29, average log likelihood -1.414684
[ Info: iteration 30, average log likelihood -1.414679
[ Info: iteration 31, average log likelihood -1.414675
[ Info: iteration 32, average log likelihood -1.414670
[ Info: iteration 33, average log likelihood -1.414666
[ Info: iteration 34, average log likelihood -1.414662
[ Info: iteration 35, average log likelihood -1.414659
[ Info: iteration 36, average log likelihood -1.414655
[ Info: iteration 37, average log likelihood -1.414652
[ Info: iteration 38, average log likelihood -1.414649
[ Info: iteration 39, average log likelihood -1.414646
[ Info: iteration 40, average log likelihood -1.414643
[ Info: iteration 41, average log likelihood -1.414640
[ Info: iteration 42, average log likelihood -1.414637
[ Info: iteration 43, average log likelihood -1.414634
[ Info: iteration 44, average log likelihood -1.414631
[ Info: iteration 45, average log likelihood -1.414628
[ Info: iteration 46, average log likelihood -1.414626
[ Info: iteration 47, average log likelihood -1.414623
[ Info: iteration 48, average log likelihood -1.414620
[ Info: iteration 49, average log likelihood -1.414618
[ Info: iteration 50, average log likelihood -1.414615
┌ Info: EM with 100000 data points 50 iterations avll -1.414615
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.416145029121552
│     -1.4160747240809386
│      ⋮
└     -1.4146151713652944
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414622
[ Info: iteration 2, average log likelihood -1.414557
[ Info: iteration 3, average log likelihood -1.414495
[ Info: iteration 4, average log likelihood -1.414421
[ Info: iteration 5, average log likelihood -1.414328
[ Info: iteration 6, average log likelihood -1.414213
[ Info: iteration 7, average log likelihood -1.414079
[ Info: iteration 8, average log likelihood -1.413936
[ Info: iteration 9, average log likelihood -1.413793
[ Info: iteration 10, average log likelihood -1.413659
[ Info: iteration 11, average log likelihood -1.413537
[ Info: iteration 12, average log likelihood -1.413427
[ Info: iteration 13, average log likelihood -1.413330
[ Info: iteration 14, average log likelihood -1.413244
[ Info: iteration 15, average log likelihood -1.413169
[ Info: iteration 16, average log likelihood -1.413104
[ Info: iteration 17, average log likelihood -1.413048
[ Info: iteration 18, average log likelihood -1.413001
[ Info: iteration 19, average log likelihood -1.412960
[ Info: iteration 20, average log likelihood -1.412925
[ Info: iteration 21, average log likelihood -1.412895
[ Info: iteration 22, average log likelihood -1.412868
[ Info: iteration 23, average log likelihood -1.412844
[ Info: iteration 24, average log likelihood -1.412822
[ Info: iteration 25, average log likelihood -1.412802
[ Info: iteration 26, average log likelihood -1.412784
[ Info: iteration 27, average log likelihood -1.412766
[ Info: iteration 28, average log likelihood -1.412750
[ Info: iteration 29, average log likelihood -1.412735
[ Info: iteration 30, average log likelihood -1.412720
[ Info: iteration 31, average log likelihood -1.412707
[ Info: iteration 32, average log likelihood -1.412693
[ Info: iteration 33, average log likelihood -1.412681
[ Info: iteration 34, average log likelihood -1.412669
[ Info: iteration 35, average log likelihood -1.412657
[ Info: iteration 36, average log likelihood -1.412646
[ Info: iteration 37, average log likelihood -1.412635
[ Info: iteration 38, average log likelihood -1.412625
[ Info: iteration 39, average log likelihood -1.412615
[ Info: iteration 40, average log likelihood -1.412606
[ Info: iteration 41, average log likelihood -1.412597
[ Info: iteration 42, average log likelihood -1.412588
[ Info: iteration 43, average log likelihood -1.412579
[ Info: iteration 44, average log likelihood -1.412571
[ Info: iteration 45, average log likelihood -1.412563
[ Info: iteration 46, average log likelihood -1.412555
[ Info: iteration 47, average log likelihood -1.412548
[ Info: iteration 48, average log likelihood -1.412541
[ Info: iteration 49, average log likelihood -1.412534
[ Info: iteration 50, average log likelihood -1.412527
┌ Info: EM with 100000 data points 50 iterations avll -1.412527
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.414621585767909
│     -1.414556924368142
│      ⋮
└     -1.4125271906538928
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412529
[ Info: iteration 2, average log likelihood -1.412453
[ Info: iteration 3, average log likelihood -1.412377
[ Info: iteration 4, average log likelihood -1.412283
[ Info: iteration 5, average log likelihood -1.412164
[ Info: iteration 6, average log likelihood -1.412017
[ Info: iteration 7, average log likelihood -1.411848
[ Info: iteration 8, average log likelihood -1.411667
[ Info: iteration 9, average log likelihood -1.411484
[ Info: iteration 10, average log likelihood -1.411307
[ Info: iteration 11, average log likelihood -1.411143
[ Info: iteration 12, average log likelihood -1.410994
[ Info: iteration 13, average log likelihood -1.410861
[ Info: iteration 14, average log likelihood -1.410744
[ Info: iteration 15, average log likelihood -1.410640
[ Info: iteration 16, average log likelihood -1.410548
[ Info: iteration 17, average log likelihood -1.410466
[ Info: iteration 18, average log likelihood -1.410393
[ Info: iteration 19, average log likelihood -1.410329
[ Info: iteration 20, average log likelihood -1.410270
[ Info: iteration 21, average log likelihood -1.410218
[ Info: iteration 22, average log likelihood -1.410170
[ Info: iteration 23, average log likelihood -1.410126
[ Info: iteration 24, average log likelihood -1.410086
[ Info: iteration 25, average log likelihood -1.410049
[ Info: iteration 26, average log likelihood -1.410014
[ Info: iteration 27, average log likelihood -1.409982
[ Info: iteration 28, average log likelihood -1.409951
[ Info: iteration 29, average log likelihood -1.409922
[ Info: iteration 30, average log likelihood -1.409894
[ Info: iteration 31, average log likelihood -1.409868
[ Info: iteration 32, average log likelihood -1.409842
[ Info: iteration 33, average log likelihood -1.409817
[ Info: iteration 34, average log likelihood -1.409794
[ Info: iteration 35, average log likelihood -1.409771
[ Info: iteration 36, average log likelihood -1.409749
[ Info: iteration 37, average log likelihood -1.409728
[ Info: iteration 38, average log likelihood -1.409707
[ Info: iteration 39, average log likelihood -1.409687
[ Info: iteration 40, average log likelihood -1.409668
[ Info: iteration 41, average log likelihood -1.409649
[ Info: iteration 42, average log likelihood -1.409631
[ Info: iteration 43, average log likelihood -1.409613
[ Info: iteration 44, average log likelihood -1.409596
[ Info: iteration 45, average log likelihood -1.409579
[ Info: iteration 46, average log likelihood -1.409563
[ Info: iteration 47, average log likelihood -1.409547
[ Info: iteration 48, average log likelihood -1.409532
[ Info: iteration 49, average log likelihood -1.409517
[ Info: iteration 50, average log likelihood -1.409503
┌ Info: EM with 100000 data points 50 iterations avll -1.409503
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4125292703614296
│     -1.4124531893785763
│      ⋮
└     -1.4095027334838888
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4226580547412735
│     -1.4226779382611712
│     -1.4225816308143806
│     -1.4225015781296082
│      ⋮
│     -1.4095318303885547
│     -1.4095170465664963
└     -1.4095027334838888
32×26 Array{Float64,2}:
 -0.433493    -0.617534     0.327957   -1.14964     -0.0942615  -0.268942   -0.206581    -0.0801454   -0.112532     0.162511     0.0717396   0.224317    0.4413     -0.161441    -0.14428     0.0920252  -0.581849    0.0903696    0.290584     0.189094    -0.0599771  -0.565807      0.377839     0.0673931   -0.260255    -1.03112
  0.486822     0.0597794    0.569835   -0.437276     0.228819   -0.105177   -0.307917    -0.19678     -0.32519      0.106203     0.501704   -0.255332   -0.670158    0.269924    -0.324957    0.105704   -0.180497   -0.154933     0.0982311    0.276908     0.251249   -0.988385      0.177077    -0.171456     0.492895    -0.0786833
 -0.0817384    0.325818     0.174854   -0.581063    -0.494938   -0.0937419  -0.900371     0.300013     0.159362     0.217485    -0.252013    0.261321    0.258553   -0.450367    -0.671379   -0.152469    0.278781    0.0184853    0.0611301   -0.100288     0.531881    0.231517     -0.0633696   -0.17078      0.163568    -0.0241629
 -0.227858     0.68746      0.215696   -0.954585    -0.134695    0.0925035   0.215432    -0.132205     0.317217    -0.320947    -0.284183    0.11817     0.112919   -0.534702    -0.397488    0.123121   -0.126203   -0.436972    -0.0237185    0.289725    -0.333069   -0.222821     -0.314212    -0.235234     5.82948e-5   0.09421
  0.0213697   -0.528943    -0.329167    0.34873      0.428195   -0.365449    0.423221    -0.754856     0.0889327   -0.00613046  -0.111172   -0.595365   -0.126464    0.753718     0.290428    0.576944   -0.732471    0.185114     0.103895    -0.468756    -0.461737   -0.413097      0.0857568    0.541623    -0.306031    -0.610993
 -0.0489219   -0.172785     0.414887    0.121338    -0.193641   -0.0718821   0.068236    -0.143233    -0.277271     0.265314    -0.101444   -0.510851   -0.285454   -0.582947    -0.284588    0.16833     0.180334   -0.447703    -0.289371    -0.183651    -0.473194    0.247476      0.783303     0.697266     0.119676    -0.483804
 -0.456676    -0.44752     -0.77169     0.400654    -0.432162    0.331842    0.210676     0.193428    -0.0384826    0.439952    -0.423036    0.18818     1.11653    -0.51128      0.233077    0.116457   -0.425618    0.514567    -0.467092    -0.32665      0.0436802   0.631707      0.281916     0.149408    -0.121876    -0.379487
  0.834774    -0.136004     0.477239   -0.0170889   -0.288219    0.569285   -0.130773     0.811704     0.280817     0.374205     0.103023    0.0235308   0.340984    0.0888746    0.172792    0.0569955  -0.670235   -0.00702349  -0.291507    -0.341912     0.264129    0.289294     -0.115601     0.289919     0.116186    -0.912796
 -0.0506788    0.537302    -0.17116    -0.187509    -0.212268   -0.317945    0.139195    -0.0152253    0.272342     0.198898     0.0260581  -0.261846    0.611028    0.582937     0.0194007  -0.04442    -0.409355    0.149357     0.202969     0.657439    -0.178813    0.282234     -0.959426    -0.00837771  -0.0896924    0.0551918
 -0.589126     0.401122    -0.712609   -0.267077    -0.110553    0.131847   -0.0914543   -0.185113     0.173281    -0.223514     0.628858   -0.196298   -0.269359    0.402695     0.310868    0.0289839  -0.960134   -0.0237706   -0.0210885   -0.225184    -0.114092    0.189254      0.60162      0.216505    -0.452179    -0.182247
 -0.0904414    0.190045    -0.483094    0.211294    -0.056026   -0.523467    0.00284633  -0.246689    -0.0400185   -0.416121    -0.20129     0.449759   -0.107924   -0.0524102    0.120826    0.135572    0.349202    0.153155    -0.259414     0.382698    -0.654233   -0.208411     -0.0134035   -0.340875    -0.0185945    1.25587
 -0.0506561    0.18215      0.107422    0.00239835  -0.0393035   0.0340521  -0.127759    -0.0435431    0.0950769   -0.207274     0.148031    0.162004    0.0131875   0.0402789    0.0218736  -0.0111785   0.0393064   0.12423     -0.00574026   0.0750354    0.173734    0.0279894    -0.00661413  -0.0175023   -0.194222     0.0779648
  0.450031    -0.495599    -0.354858   -0.0414895   -0.736699   -0.248337   -0.147134    -0.518707     0.565364     0.847644    -0.0762209  -0.878915   -0.45697    -0.187446     0.0261396  -0.214444    0.121507    0.322412     0.317606    -0.182631     0.384856   -0.00353689    0.31586     -0.397581    -0.058696     0.0617814
  0.294572     0.128293    -0.0979393  -0.369257    -0.663023   -0.102793    0.40851      0.0251638    0.782163     0.0811602    0.121015   -0.38603     0.743973    0.443459     0.205697    0.115097    0.7372     -0.204262     0.953114     0.396822     1.05085    -0.345315      0.283292     0.166299     0.327167    -0.00981638
  0.603691    -0.395274    -1.24265     0.585735     0.324892    0.298173    0.398405     0.605702     0.0496301   -0.12881      0.0348421  -0.231864   -0.267706    0.0960656   -0.0131999  -0.539028   -0.0912182  -0.374024     0.133687     0.282416    -0.0433633  -0.0596717     0.0245293   -0.933629     0.483797     0.675352
  0.755799    -0.266331     0.622042    0.297079     0.447527   -0.126505   -0.0216836    0.16997     -0.185772     0.302384    -0.679885    0.0523885   0.240258   -0.289497    -0.263655   -0.10647     0.603164   -0.0410524    0.0382375    0.05006     -0.182113   -0.0220693    -0.412873    -0.376784     0.831447     0.169758
  0.185563     0.0926029   -0.155425   -0.154406    -0.128043   -0.134289   -0.163006     0.0844674    0.0104195    0.222843     0.0539846   0.221926    0.187377   -0.00332034   0.39731     0.125749   -0.482043    0.255267    -0.384516     0.0572033    0.0544953   0.0126402     0.203566     0.0058647    0.0169843   -0.203539
 -0.150641    -0.0180293    0.149483    0.0790403    0.0569589   0.1362      0.0431459   -0.06069     -0.0228236    0.056713     0.0816535  -0.112712    0.0624872   0.0460223   -0.129509   -0.0322083  -0.139089   -0.11899      0.198619    -0.0338405   -0.0984235   0.111137      0.17149      0.380245    -0.151368    -0.265456
 -0.0498882    0.418553    -0.149137   -0.0184584    0.251957   -0.0975393  -0.30721     -0.358875     0.475146    -0.671819     0.206706    0.169371    0.0886134   0.237847     0.0578937   0.0458906   0.175125    0.155002    -0.178394    -0.0279168   -0.0779964  -0.438433     -0.0100866   -0.269857    -0.0803364    0.185384
  0.274867    -0.00108796  -0.261054   -0.177206    -0.125065   -0.176006   -0.171373    -0.432183     0.158474     0.291909     0.0561367  -0.174244   -0.151997   -0.12544     -0.249225   -0.309917    0.0608504  -0.0283039    0.0116504   -0.146698     0.0756877  -0.207684      0.100075    -0.471089     0.247289     0.186781
  0.544795     0.14528      0.310821    0.402232     0.277706    0.263976   -0.00256186   0.0895329   -0.0253758    0.365573     0.130429    0.549996    0.0342056  -0.571562     0.696511    0.17385    -0.306786    0.526476    -0.121056     0.0093485    0.54609    -0.138517      0.14791      0.435829     0.206084     0.010849
  0.276613    -0.144821    -0.14126     0.837954     0.247692   -0.105761   -0.1174      -0.172403    -0.00477908   0.111499     0.455333    0.0607979  -0.244529    0.780186     0.478184   -0.268978   -0.0661443   0.527894     0.0132886   -0.0790138    0.419395    0.0428667    -0.0156727    0.0443957   -0.162991     0.0167509
  0.177464    -0.0722283   -0.296143    0.621303    -0.163295   -0.039261    0.478459     0.051098     0.0701591   -0.286623    -0.206616   -0.191371   -0.0264596  -0.216356     0.48718     0.409999    0.129272    0.0817588   -0.464505     0.0789257   -0.244257    0.575946      0.00460104   0.0597577   -0.350777     0.267482
  0.158961     0.195316    -0.275645    0.718031    -0.304765   -0.130594    0.288876    -0.0593836    0.261738    -0.341664    -0.400371    0.263469    0.370208    0.11168      0.317379    0.11196    -0.0786848  -0.141682     0.752333    -0.54858      0.0854182   0.293697     -0.199518     0.0267412   -0.492932     0.521011
 -0.46248      0.082546     0.114124   -0.00030636   0.68183    -0.285776   -0.491465     0.110427    -0.704263     0.0207571    0.213365    0.403404   -0.545931   -0.279132     0.150567   -0.33695    -0.635702    0.27394     -0.59841      0.0765726   -0.609349    0.0643819    -0.179582    -0.175619    -0.207509    -0.0963756
  0.00352802  -0.178044     0.306941   -0.00897966   0.688696    0.386382    0.219072     0.114264    -0.246407    -0.356704     0.168505    0.185676   -0.64996    -0.276362    -0.0798134   0.497247    0.436393    0.4891      -0.498148     0.241748    -0.200959   -0.0249879     0.17066     -0.36905     -0.185633    -0.0778311
 -0.425999     0.35948      0.522164    0.181266     0.486143    0.271917    0.0937327    0.287056    -0.288379    -0.836149     0.0902083   0.637953    0.392758    0.1637      -0.113014    0.596639   -0.166489   -0.251686    -0.348785    -0.181548    -0.713704    0.0859199    -0.0535939    0.794144    -0.0491297   -0.394865
 -0.152427    -0.277387     0.258787    0.323633     0.205663    0.207264    0.218786     0.0236593   -0.522384    -0.244031     0.298795    0.911053    0.220299   -0.148577    -0.596444   -0.382195    0.0397982  -0.528412     0.20387     -0.146374    -0.0414787  -0.22114       0.390445     0.39896     -0.157014     0.818483
 -0.238989    -0.44853      0.261666    0.00392582  -0.317403   -0.67146     0.272453     0.0281474    0.264757     0.11838     -0.114322    0.344844    0.0486223   0.0505913   -0.357178    0.277113    0.551564    0.268563     0.251283     0.210701    -0.0210878   0.000844377   0.058605     0.211512    -0.0563063   -0.0704597
  0.151762    -0.0299539    0.292163    0.00398088   0.252788    0.0609085   0.108154     0.321516    -0.342404    -0.144908    -0.232884    0.0858197   0.0144267  -0.109738    -0.139147    0.0631133   0.234608   -0.0783393    0.0544929    0.212543    -0.0781316  -0.00659976   -0.267209    -0.230283     0.299015     0.346209
 -0.125879    -0.245238     0.0682228  -0.305453     0.172389    0.72887     0.469006     0.305017    -0.322455    -0.0575621    0.206622   -0.606559   -0.275076   -0.499942     0.101065   -0.262188    0.178563   -0.191158     0.473516     0.00599337   0.510618    0.39207      -0.122833    -0.131342     0.10563     -0.019327
 -0.568826    -0.267585    -0.427698   -0.109221     0.148564   -0.0845305   0.114077    -0.00479484  -0.204267    -0.395117    -0.194076   -0.636196    0.0781641   0.739039    -0.510426    0.0185976   0.254637   -0.537906     0.0993959   -0.0250375   -0.517604    0.367033      0.0246462   -0.295569     0.0486402   -0.060554[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409489
[ Info: iteration 2, average log likelihood -1.409476
[ Info: iteration 3, average log likelihood -1.409463
[ Info: iteration 4, average log likelihood -1.409450
[ Info: iteration 5, average log likelihood -1.409438
[ Info: iteration 6, average log likelihood -1.409427
[ Info: iteration 7, average log likelihood -1.409415
[ Info: iteration 8, average log likelihood -1.409405
[ Info: iteration 9, average log likelihood -1.409394
[ Info: iteration 10, average log likelihood -1.409385
┌ Info: EM with 100000 data points 10 iterations avll -1.409385
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.067550e+05
      1       7.048159e+05      -2.019391e+05 |       32
      2       6.891172e+05      -1.569866e+04 |       32
      3       6.830843e+05      -6.032922e+03 |       32
      4       6.802537e+05      -2.830605e+03 |       32
      5       6.786080e+05      -1.645707e+03 |       32
      6       6.774964e+05      -1.111628e+03 |       32
      7       6.766097e+05      -8.866581e+02 |       32
      8       6.759288e+05      -6.808906e+02 |       32
      9       6.753666e+05      -5.621737e+02 |       32
     10       6.749260e+05      -4.406170e+02 |       32
     11       6.745641e+05      -3.619204e+02 |       32
     12       6.742662e+05      -2.978553e+02 |       32
     13       6.740187e+05      -2.475157e+02 |       32
     14       6.737869e+05      -2.318419e+02 |       32
     15       6.735611e+05      -2.257605e+02 |       32
     16       6.733684e+05      -1.927131e+02 |       32
     17       6.732087e+05      -1.597498e+02 |       32
     18       6.730642e+05      -1.444080e+02 |       32
     19       6.729277e+05      -1.365021e+02 |       32
     20       6.727948e+05      -1.329438e+02 |       32
     21       6.726582e+05      -1.366012e+02 |       32
     22       6.725329e+05      -1.252745e+02 |       32
     23       6.724128e+05      -1.201282e+02 |       32
     24       6.722983e+05      -1.144496e+02 |       32
     25       6.721754e+05      -1.229967e+02 |       32
     26       6.720657e+05      -1.096718e+02 |       32
     27       6.719571e+05      -1.086081e+02 |       32
     28       6.718585e+05      -9.859957e+01 |       32
     29       6.717603e+05      -9.814097e+01 |       32
     30       6.716701e+05      -9.024588e+01 |       32
     31       6.715848e+05      -8.531596e+01 |       32
     32       6.715142e+05      -7.061958e+01 |       32
     33       6.714541e+05      -6.005700e+01 |       32
     34       6.713971e+05      -5.701673e+01 |       32
     35       6.713375e+05      -5.955525e+01 |       32
     36       6.712824e+05      -5.510993e+01 |       32
     37       6.712336e+05      -4.883099e+01 |       32
     38       6.711903e+05      -4.323584e+01 |       32
     39       6.711485e+05      -4.186468e+01 |       32
     40       6.711100e+05      -3.848516e+01 |       32
     41       6.710689e+05      -4.109041e+01 |       32
     42       6.710256e+05      -4.327876e+01 |       32
     43       6.709890e+05      -3.666875e+01 |       32
     44       6.709462e+05      -4.280353e+01 |       32
     45       6.709021e+05      -4.409838e+01 |       32
     46       6.708549e+05      -4.710959e+01 |       32
     47       6.708135e+05      -4.146002e+01 |       32
     48       6.707711e+05      -4.236343e+01 |       32
     49       6.707293e+05      -4.181786e+01 |       32
     50       6.706927e+05      -3.658898e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 670692.7154378664)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421317
[ Info: iteration 2, average log likelihood -1.416265
[ Info: iteration 3, average log likelihood -1.414921
[ Info: iteration 4, average log likelihood -1.413955
[ Info: iteration 5, average log likelihood -1.412968
[ Info: iteration 6, average log likelihood -1.412044
[ Info: iteration 7, average log likelihood -1.411374
[ Info: iteration 8, average log likelihood -1.410982
[ Info: iteration 9, average log likelihood -1.410761
[ Info: iteration 10, average log likelihood -1.410622
[ Info: iteration 11, average log likelihood -1.410523
[ Info: iteration 12, average log likelihood -1.410443
[ Info: iteration 13, average log likelihood -1.410376
[ Info: iteration 14, average log likelihood -1.410316
[ Info: iteration 15, average log likelihood -1.410263
[ Info: iteration 16, average log likelihood -1.410215
[ Info: iteration 17, average log likelihood -1.410170
[ Info: iteration 18, average log likelihood -1.410128
[ Info: iteration 19, average log likelihood -1.410089
[ Info: iteration 20, average log likelihood -1.410053
[ Info: iteration 21, average log likelihood -1.410018
[ Info: iteration 22, average log likelihood -1.409986
[ Info: iteration 23, average log likelihood -1.409954
[ Info: iteration 24, average log likelihood -1.409925
[ Info: iteration 25, average log likelihood -1.409896
[ Info: iteration 26, average log likelihood -1.409868
[ Info: iteration 27, average log likelihood -1.409842
[ Info: iteration 28, average log likelihood -1.409816
[ Info: iteration 29, average log likelihood -1.409791
[ Info: iteration 30, average log likelihood -1.409767
[ Info: iteration 31, average log likelihood -1.409744
[ Info: iteration 32, average log likelihood -1.409721
[ Info: iteration 33, average log likelihood -1.409699
[ Info: iteration 34, average log likelihood -1.409678
[ Info: iteration 35, average log likelihood -1.409657
[ Info: iteration 36, average log likelihood -1.409637
[ Info: iteration 37, average log likelihood -1.409617
[ Info: iteration 38, average log likelihood -1.409598
[ Info: iteration 39, average log likelihood -1.409580
[ Info: iteration 40, average log likelihood -1.409563
[ Info: iteration 41, average log likelihood -1.409546
[ Info: iteration 42, average log likelihood -1.409529
[ Info: iteration 43, average log likelihood -1.409513
[ Info: iteration 44, average log likelihood -1.409497
[ Info: iteration 45, average log likelihood -1.409482
[ Info: iteration 46, average log likelihood -1.409468
[ Info: iteration 47, average log likelihood -1.409454
[ Info: iteration 48, average log likelihood -1.409440
[ Info: iteration 49, average log likelihood -1.409426
[ Info: iteration 50, average log likelihood -1.409413
┌ Info: EM with 100000 data points 50 iterations avll -1.409413
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.394614     0.482422     0.0494619  -0.895521   -0.197674    0.16813      0.42164     -0.366798    0.350538    -0.730768    -0.312594     0.082445     0.22899    -0.37564      0.0104782   0.302783    -0.30181     -0.445533    -0.0624078    0.154834     -0.527279    -0.316288    -0.204823     0.116295    -0.16525     -0.156084
 -0.211927    -0.107819     0.464642    0.375137    0.74137     0.236808     0.269667     0.556907   -0.699216    -0.621795    -0.221174     0.518827     0.235163   -0.148402    -0.352517    0.511295     0.0634594   -0.426842    -0.173242    -0.19907      -0.544627     0.0838307    0.116961     0.411103     0.174916     0.000688234
 -0.577091     0.811818    -0.227604    0.267559    0.50055     0.237676     0.171971     0.226818   -0.354419    -0.581614    -0.408949    -0.030453    -0.306762   -0.268817     1.15431     0.29079      0.344403    -0.0325998   -0.227899    -0.337104     -0.0236051    1.0936      -0.340177     0.325541    -0.0440137    1.06661
 -0.0769407    0.225067     0.230247   -0.581993   -0.53861    -0.00153334  -0.273068     0.270634    0.0574075    0.291184    -0.252038     0.274357     0.223974   -0.747419    -0.782992   -0.107657     0.283406    -0.25853      0.158606     0.0362511     0.281689     0.129992    -0.00581769  -0.21737      0.159119     0.178457
  0.226478     0.761936     0.490367   -0.281377    0.352355   -0.0438046   -0.301241     0.0952138  -0.0669166   -0.46957      0.205894     0.531986    -0.0085346   0.199635    -0.21674    -0.185181    -0.0813205    0.0171453    0.0339143    0.60647       0.159521    -0.557469    -0.400479    -0.807246     0.420868     0.456633
  0.44031     -0.15371      0.370013    0.133094    0.357505    0.404902     0.252008     0.165924    0.179064     0.243425     0.563663    -0.184374    -0.42316    -0.184496     0.371685   -0.12735      0.402202     0.660277    -0.00490697   0.170873      0.696872     0.278682    -0.211966    -0.202972     0.109858    -0.350471
 -0.806463     0.092222    -0.258975   -0.437927   -0.0895568  -0.0352644    0.00335499   0.0100936   0.0277866    0.0187729   -0.306073    -1.04451      0.181568    0.539902    -1.06545     0.222439     0.253709    -0.184504    -0.0861278    0.191997     -0.578293     0.547152    -0.0334519   -0.299539    -0.070113    -0.255942
 -0.394849     0.122778    -0.419454    0.138204    0.149653   -0.470251     0.102778    -0.821896   -0.218836    -0.803357     0.295698     0.43612     -0.217317    0.0988034   -0.196414   -0.165524     0.144186    -0.010919    -0.108615     0.301651     -0.589751    -0.545743     0.204416    -0.228111    -0.362513     1.00335
  0.342004     0.209259    -0.0835124  -0.413142   -0.631018   -0.0819937    0.451211     0.0829786   0.753983     0.0758568    0.1008      -0.420849     0.958122    0.513033     0.272477    0.130782     0.846472    -0.157122     1.03006      0.524341      1.12041     -0.389696     0.241558     0.161717     0.388692     0.0368159
  0.147459     0.0539079   -0.218821   -0.097949   -0.172144   -0.0653476   -0.0267708   -0.143922    0.187194     0.0538915    0.0210641   -0.133292    -0.0439456   0.0103458    0.0679715  -0.00621266  -0.0611599    0.0723818   -0.0664748   -0.017551      0.0896206    0.0240318    0.0775917   -0.207326     0.0125423    0.00787285
 -0.178596     0.14323      0.267144   -0.143947    0.407981   -0.148924    -0.136784     0.18096    -0.283086    -0.167173     0.0300685    0.237734     0.0612928  -0.00712734  -0.0900345   0.0164621   -0.0456893    0.0315842   -0.118832     0.263191     -0.301018    -0.0359526   -0.140421    -0.103987     0.142334     0.0875567
 -0.421547    -0.571259    -0.720381    0.387512   -0.453699    0.370383     0.251467     0.0804324  -0.0399879    0.55816     -0.478171     0.116107     1.23138    -0.644666     0.429019    0.0270971   -0.49146      0.667957    -0.65178     -0.347454      0.0611115    0.665135     0.181306     0.181231     4.62219e-5  -0.608289
 -0.278499    -0.441216     0.0315807   0.19785    -0.530695   -0.628531     0.236466    -0.0566208   0.307216     0.0141525   -0.0891851    0.1437       0.141742    0.185708    -0.271369    0.124383     0.449849    -0.0949384    0.236959    -0.0877597    -0.049441     0.0242626    0.249164     0.330141    -0.121925    -0.0225925
  0.308702    -0.0907019   -0.247101    1.00417    -0.422475    0.0403362    0.542784    -0.0828616   0.205511    -0.412201    -0.259543     0.0828499    0.183743   -0.0190848    0.444083    0.2938       0.0702024   -0.0125454    0.167548    -0.318087      0.02555      0.558477    -0.00505982  -0.00870492  -0.662149     0.361206
 -0.108416     0.331966    -0.319816    0.0153608  -0.153309   -0.449227    -0.578226    -0.313369    0.260286     0.143695     0.263958     0.189848     0.2054      0.51959      0.469717   -0.442982    -0.447466     0.386517     0.00422791  -0.000419741   0.210891    -0.0841905   -0.206751     0.105919    -0.291244     0.185571
 -0.330358    -0.702146     0.328199   -1.00065     0.108002   -0.203129    -0.189714    -0.106916   -0.02564      0.19538      0.176267     0.1875       0.450015   -0.052093    -0.295142   -0.0458425   -0.543403     0.134875     0.344667     0.205171      0.0455151   -0.693167     0.285363    -0.0530874   -0.159267    -1.11478
 -0.843625     0.213837    -0.471515   -0.286889   -0.129867    0.367308     0.0853387    0.222255   -0.119182    -0.332829     0.652458    -0.0290983   -0.0389646   0.301619     0.203501    0.0963234   -0.923187    -0.184244     0.0179914   -0.19075      -0.00494803   0.34249      0.528408     0.32939     -0.577857    -0.295103
 -0.0732755   -0.00194181   0.282794    0.228956    0.321047    0.399412     0.0717482   -0.0709805  -0.181129     0.0192618    0.123824    -0.0953397    0.130503    0.0344157   -0.202389   -0.143045    -0.10022     -0.304594     0.324614    -0.213809      0.0136443    0.0458613    0.1618       0.408099    -0.04105     -0.189865
  0.485359    -0.0619145    0.421317   -0.354901    0.187426   -0.0839272   -0.187832    -0.323864   -0.155499     0.212633     0.39827     -0.466257    -0.685128    0.108999    -0.316257    0.172179    -0.151682    -0.235434    -0.0739022    0.0909533     0.208771    -0.975224     0.311594    -0.0497931    0.462471    -0.268223
  0.290188    -0.136075    -0.440848    0.376864    0.0035358   0.0343363    0.146174     0.0570296   0.1223      -0.00248164  -0.0984328    0.00779866   0.0497155   0.077578    -0.0328349  -0.211461    -0.0715124   -0.131977     0.181427     0.0106985     0.0535937   -0.0620097   -0.066284    -0.176957     0.0545283    0.247614
  0.313815    -0.464008    -0.45842    -0.135497   -0.839394   -0.189485    -0.0626564   -0.514245    0.457729     0.841606    -0.00233161  -0.776469    -0.509631   -0.190952    -0.028264   -0.194905     0.0987202    0.225435     0.362896    -0.197851      0.352068     0.0640787    0.468198    -0.270716    -0.016951     0.0666553
  0.312978     0.595141    -0.256274    0.330201    0.299787    0.302863    -0.741362    -0.238356    0.674247    -0.567208     0.144471     0.228635     0.232902    0.0179201    0.0605169   0.205425     0.00558335   0.119205    -0.311824    -0.675161     -0.0632716   -0.198399     0.304524    -0.124881    -0.0313041   -0.13716
  0.316048    -0.0979498    0.131043    0.177901    0.0129459   0.104511     0.077566     0.328956   -0.233783     0.223587    -0.0581484    0.492838     0.132355   -0.17694      0.489017    0.447746    -0.415178     0.527449    -0.291819     0.191188      0.117144    -0.0699907    0.203244     0.352466    -0.0248114    0.0187151
 -0.210162     0.0191385    1.02581    -0.212628   -0.0520836  -0.128367    -0.169851    -0.202086   -0.084316     0.0678069    0.0702225    0.0339558    0.0594438  -0.0977517   -0.0808147   0.32042      0.123284     0.257426    -0.165682    -0.077384     -0.171415     0.191781     0.177404     0.67436     -0.114012    -0.603786
  0.193159     0.485083    -0.16425     0.186415   -0.142789   -0.390714     0.674624    -0.138333    0.213229     0.0729526    0.0412458   -0.129569     0.680092    0.467386     0.0309863   0.266535    -0.394684    -0.177605     0.19003      0.529869     -0.565839     0.358944    -0.777855     0.166764    -0.0563589    0.103766
 -0.219587    -0.0604385    0.256317    0.215792    0.474403    0.00210195  -0.336581    -0.09696    -0.563801     0.119636     0.139252     0.13357     -0.696621   -0.604583    -0.0233665  -0.1985      -0.292818     0.00404132  -0.708575    -0.133419     -0.603157     0.191651     0.24948      0.114462    -0.213895    -0.245474
  0.222502    -0.457803    -0.659162    0.145766    0.322176    0.360768     0.288834     0.548299   -0.28819     -0.236694     0.0792396   -0.343567    -0.148209    0.111648     0.0932065  -0.446007     0.0218192   -0.457316     0.20641      0.190726      0.0184033    0.142944     0.014154    -0.661953     0.446984     0.462913
 -0.0662972    0.203964    -0.361879   -0.0833321  -0.339843   -0.489094    -0.0769635    0.633835   -0.00770233   0.0127178   -0.234389     0.406262    -0.202592   -0.336371     0.429019    0.476664     0.253901     0.565542    -0.551928     0.691579     -0.277457     0.00521435   0.0445957   -0.47278      0.125119     0.658954
  0.945142    -0.382774     0.315842    0.396875    0.236135   -0.238171    -0.318495    -0.107205   -0.0124614    0.487764    -0.723681     0.0301148    0.137099   -0.164548    -0.22231    -0.264098     0.453931     0.0858524    0.024972    -0.156814     -0.166538    -0.114105    -0.428172    -0.517813     0.730721     0.479584
 -0.00990014  -0.177224     0.269425    0.0742538   0.498801   -0.0255492    0.325694    -0.152885    0.037443    -0.426098    -0.133939     0.0894883   -0.286572   -0.0924156   -0.429147    0.130886     0.9322       0.223607     0.157325     0.381754     -0.0642775   -0.100406    -0.316017    -0.18706     -0.0331551    0.521707
  0.727868    -0.00939131   0.391234   -0.114679   -0.385953    0.240484    -0.0832235    0.707317    0.0389916    0.64655     -0.0693327   -0.157499     0.285129   -0.092386     0.194202   -0.0815108   -0.676041    -0.115714     0.042175    -0.215142      0.286226     0.332735    -0.106049     0.419642     0.289373    -0.756422
  0.123932    -0.498353    -0.762292    0.470576    0.51746    -0.251479     0.299462    -0.470129   -0.114513    -0.0606696    0.0346043   -0.334375    -0.43687     0.836669     0.585693    0.49009     -0.531851     0.358654    -0.0391073   -0.248853     -0.242963    -0.187634     0.299316     0.216943    -0.437708    -0.285388[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409401
[ Info: iteration 2, average log likelihood -1.409388
[ Info: iteration 3, average log likelihood -1.409376
[ Info: iteration 4, average log likelihood -1.409365
[ Info: iteration 5, average log likelihood -1.409354
[ Info: iteration 6, average log likelihood -1.409343
[ Info: iteration 7, average log likelihood -1.409332
[ Info: iteration 8, average log likelihood -1.409322
[ Info: iteration 9, average log likelihood -1.409312
[ Info: iteration 10, average log likelihood -1.409303
┌ Info: EM with 100000 data points 10 iterations avll -1.409303
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
