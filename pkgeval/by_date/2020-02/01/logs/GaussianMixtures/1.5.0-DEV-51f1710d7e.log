Julia Version 1.5.0-DEV.212
Commit 51f1710d7e (2020-01-31 07:16 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed GaussianMixtures ─── v0.3.0
  Installed Missings ─────────── v0.4.3
  Installed Arpack_jll ───────── v3.5.0+2
  Installed DataAPI ──────────── v1.1.0
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed JLD ──────────────── v0.9.2
  Installed Rmath ────────────── v0.6.0
  Installed Blosc ────────────── v0.5.1
  Installed SpecialFunctions ─── v0.9.0
  Installed PDMats ───────────── v0.9.11
  Installed SortingAlgorithms ── v0.3.1
  Installed StatsBase ────────── v0.32.0
  Installed CMake ────────────── v1.1.2
  Installed Compat ───────────── v2.2.0
  Installed StaticArrays ─────── v0.12.1
  Installed FillArrays ───────── v0.8.4
  Installed BinaryProvider ───── v0.5.8
  Installed OrderedCollections ─ v1.1.0
  Installed URIParser ────────── v0.4.0
  Installed Distances ────────── v0.8.2
  Installed DataStructures ───── v0.17.9
  Installed Clustering ───────── v0.13.3
  Installed Arpack ───────────── v0.4.0
  Installed StatsFuns ────────── v0.9.3
  Installed Parameters ───────── v0.12.0
  Installed CMakeWrapper ─────── v0.2.3
  Installed HDF5 ─────────────── v0.12.5
  Installed NearestNeighbors ─── v0.4.4
  Installed QuadGK ───────────── v2.3.1
  Installed ScikitLearnBase ──── v0.5.0
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed LegacyStrings ────── v0.4.1
  Installed BinDeps ──────────── v1.0.0
  Installed FileIO ───────────── v1.2.1
  Installed Distributions ────── v0.22.4
#=#=#                                                                         #                                                                          2.1%####                                                                       6.4%########                                                                  11.9%##############                                                            19.6%####################                                                      29.0%#############################                                             40.6%########################################                                  56.5%#######################################################                   76.6%######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_ljUHeb/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -2.330285704913457e7, [377.4412668487145, 99622.55873315127], [-992.7631235013135 474.69934427598776 -233.76250065587686; 932.0005733251636 -680.7533349496954 164.97272464585507], [[2720.628166480129 -1109.1013197774241 546.494248139549; -1109.1013197774244 932.529097507058 -281.1523166186842; 546.494248139549 -281.1523166186842 533.2889788393528], [97987.37139331142 1023.3996710747858 -537.9913856621861; 1023.3996710747858 98834.4774486145 873.7059476306493; -537.9913856621861 873.7059476306493 99283.94269336274]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.067082e+02
      1       8.368076e+02      -6.990061e+01 |        6
      2       8.062915e+02      -3.051618e+01 |        0
      3       8.062915e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 806.2914536584112)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.059624
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.796653
[ Info: iteration 2, lowerbound -3.681240
[ Info: iteration 3, lowerbound -3.556272
[ Info: iteration 4, lowerbound -3.413580
[ Info: iteration 5, lowerbound -3.273867
[ Info: iteration 6, lowerbound -3.160936
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -3.081330
[ Info: iteration 8, lowerbound -3.035993
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.988107
[ Info: iteration 10, lowerbound -2.921773
[ Info: iteration 11, lowerbound -2.849723
[ Info: iteration 12, lowerbound -2.768034
[ Info: iteration 13, lowerbound -2.685800
[ Info: iteration 14, lowerbound -2.608628
[ Info: iteration 15, lowerbound -2.540024
[ Info: dropping number of Gaussions to 3
[ Info: iteration 16, lowerbound -2.468142
[ Info: iteration 17, lowerbound -2.408557
[ Info: iteration 18, lowerbound -2.365866
[ Info: iteration 19, lowerbound -2.334501
[ Info: iteration 20, lowerbound -2.314197
[ Info: iteration 21, lowerbound -2.307397
[ Info: dropping number of Gaussions to 2
[ Info: iteration 22, lowerbound -2.302939
[ Info: iteration 23, lowerbound -2.299261
[ Info: iteration 24, lowerbound -2.299257
[ Info: iteration 25, lowerbound -2.299255
[ Info: iteration 26, lowerbound -2.299254
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sat Feb  1 20:37:34 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sat Feb  1 20:37:42 2020: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Sat Feb  1 20:37:45 2020: EM with 272 data points 0 iterations avll -2.059624
5.8 data points per parameter
, Sat Feb  1 20:37:47 2020: GMM converted to Variational GMM
, Sat Feb  1 20:37:56 2020: iteration 1, lowerbound -3.796653
, Sat Feb  1 20:37:56 2020: iteration 2, lowerbound -3.681240
, Sat Feb  1 20:37:56 2020: iteration 3, lowerbound -3.556272
, Sat Feb  1 20:37:56 2020: iteration 4, lowerbound -3.413580
, Sat Feb  1 20:37:56 2020: iteration 5, lowerbound -3.273867
, Sat Feb  1 20:37:56 2020: iteration 6, lowerbound -3.160936
, Sat Feb  1 20:37:56 2020: dropping number of Gaussions to 7
, Sat Feb  1 20:37:56 2020: iteration 7, lowerbound -3.081330
, Sat Feb  1 20:37:56 2020: iteration 8, lowerbound -3.035993
, Sat Feb  1 20:37:56 2020: dropping number of Gaussions to 4
, Sat Feb  1 20:37:56 2020: iteration 9, lowerbound -2.988107
, Sat Feb  1 20:37:56 2020: iteration 10, lowerbound -2.921773
, Sat Feb  1 20:37:56 2020: iteration 11, lowerbound -2.849723
, Sat Feb  1 20:37:56 2020: iteration 12, lowerbound -2.768034
, Sat Feb  1 20:37:56 2020: iteration 13, lowerbound -2.685800
, Sat Feb  1 20:37:56 2020: iteration 14, lowerbound -2.608628
, Sat Feb  1 20:37:56 2020: iteration 15, lowerbound -2.540024
, Sat Feb  1 20:37:56 2020: dropping number of Gaussions to 3
, Sat Feb  1 20:37:56 2020: iteration 16, lowerbound -2.468142
, Sat Feb  1 20:37:56 2020: iteration 17, lowerbound -2.408557
, Sat Feb  1 20:37:56 2020: iteration 18, lowerbound -2.365866
, Sat Feb  1 20:37:56 2020: iteration 19, lowerbound -2.334501
, Sat Feb  1 20:37:56 2020: iteration 20, lowerbound -2.314197
, Sat Feb  1 20:37:56 2020: iteration 21, lowerbound -2.307397
, Sat Feb  1 20:37:56 2020: dropping number of Gaussions to 2
, Sat Feb  1 20:37:56 2020: iteration 22, lowerbound -2.302939
, Sat Feb  1 20:37:56 2020: iteration 23, lowerbound -2.299261
, Sat Feb  1 20:37:56 2020: iteration 24, lowerbound -2.299257
, Sat Feb  1 20:37:56 2020: iteration 25, lowerbound -2.299255
, Sat Feb  1 20:37:56 2020: iteration 26, lowerbound -2.299254
, Sat Feb  1 20:37:56 2020: iteration 27, lowerbound -2.299253
, Sat Feb  1 20:37:56 2020: iteration 28, lowerbound -2.299253
, Sat Feb  1 20:37:56 2020: iteration 29, lowerbound -2.299253
, Sat Feb  1 20:37:56 2020: iteration 30, lowerbound -2.299253
, Sat Feb  1 20:37:56 2020: iteration 31, lowerbound -2.299253
, Sat Feb  1 20:37:56 2020: iteration 32, lowerbound -2.299253
, Sat Feb  1 20:37:56 2020: iteration 33, lowerbound -2.299253
, Sat Feb  1 20:37:56 2020: iteration 34, lowerbound -2.299253
, Sat Feb  1 20:37:56 2020: iteration 35, lowerbound -2.299253
, Sat Feb  1 20:37:56 2020: iteration 36, lowerbound -2.299253
, Sat Feb  1 20:37:56 2020: iteration 37, lowerbound -2.299253
, Sat Feb  1 20:37:56 2020: iteration 38, lowerbound -2.299253
, Sat Feb  1 20:37:56 2020: iteration 39, lowerbound -2.299253
, Sat Feb  1 20:37:56 2020: iteration 40, lowerbound -2.299253
, Sat Feb  1 20:37:56 2020: iteration 41, lowerbound -2.299253
, Sat Feb  1 20:37:56 2020: iteration 42, lowerbound -2.299253
, Sat Feb  1 20:37:56 2020: iteration 43, lowerbound -2.299253
, Sat Feb  1 20:37:56 2020: iteration 44, lowerbound -2.299253
, Sat Feb  1 20:37:56 2020: iteration 45, lowerbound -2.299253
, Sat Feb  1 20:37:56 2020: iteration 46, lowerbound -2.299253
, Sat Feb  1 20:37:56 2020: iteration 47, lowerbound -2.299253
, Sat Feb  1 20:37:56 2020: iteration 48, lowerbound -2.299253
, Sat Feb  1 20:37:56 2020: iteration 49, lowerbound -2.299253
, Sat Feb  1 20:37:56 2020: iteration 50, lowerbound -2.299253
, Sat Feb  1 20:37:56 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601686, 95.95490777398311]
β = [178.04509222601686, 95.95490777398311]
m = [4.250300733269886 79.2868669443615; 2.0002292577753455 53.851987172461165]
ν = [180.04509222601686, 97.95490777398311]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.184041555474842 -0.0076440490423277324; 0.0 0.008581705166333132], [0.37587636119488627 -0.008953123827346676; 0.0 0.012748664777409591]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000003
avll from stats: -0.9926613162687681
avll from llpg:  -0.9926613162687722
avll direct:     -0.9926613162687722
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9866960995784221
avll from llpg:  -0.986696099578422
avll direct:     -0.986696099578422
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
 -0.0759472    0.142244    -0.0336858    0.0814561   -0.0300336    0.0305543   -0.0318587   0.151471    -0.0305534    -0.0644065   0.0699235    0.0828606   0.0218253     0.119965     -0.238962     -0.125855    -0.110783    -0.0801267    -0.144254     -0.0323344   0.0210223    0.100544     -0.156343      0.0808497   -0.0981145   0.00042603
 -0.0556054   -0.158855    -0.0914177    0.0159294    0.132569    -0.204506    -0.061244    0.0879674    0.00224514    0.0317786   0.0319923    0.0631711   0.0299256     0.060708     -0.128646      0.0117917    0.113218     0.120832     -0.0857178     0.0505531   0.0507939    0.127003      0.0603748    -0.0081991   -0.0294223   0.0564317
  0.0347993   -0.028121    -0.0203357   -0.192259     0.00221295  -0.0478834   -0.0937769   0.215346    -0.154241      0.0216018  -0.101118     0.0323258  -0.0474315    -0.0509664    -0.100145     -0.0768264    0.0157311    0.0770604    -0.0604404    -0.03998     0.170768    -0.161394      0.1219        0.0644353   -0.0210139   0.114235
  0.035051    -0.0775021   -0.0536765    0.00404489  -0.124749     0.0438607    0.0239301  -0.00884999   0.194887     -0.0789789   0.197147     0.230089    0.0362893     0.102608      0.0442873    -0.103931     0.00462352   0.0696661    -0.0661979    -0.128545   -0.114041     0.02059       0.0061742    -0.00913491   0.041576   -0.104124
 -0.0242735    0.012088     0.0570367   -0.298423     0.0140199   -0.0325529   -0.07951    -0.0287889   -0.0861226    -0.0278292   0.00469615  -0.0521348  -0.0782989    -0.12951       0.107104      0.0126157    0.0310644    0.0452515     0.0536224    -0.0453264  -0.100541     0.0110835    -0.175111      0.0908667    0.0104151   0.0879225
  0.245173     0.0270123   -0.0347184   -0.125645    -0.00579432   0.0334483   -0.0917671   0.184001     0.0114401    -0.0768823  -0.0193347   -0.118288   -0.0308686    -0.129223     -0.0846291    -0.147508     0.0632215   -0.115081     -0.0619266     0.0151513   0.0829453   -0.0416676     0.0908254    -0.0409474   -0.0620305  -0.0621221
  0.0115467   -0.0676386   -0.00296817   0.146465    -0.132954     0.0232087    0.0984011  -0.00909541   0.0204757     0.0528358  -0.0150674   -0.161599   -0.0945192    -0.125279     -0.0365795    -0.0916467   -0.101064    -0.000684482   0.146212      0.0182949  -0.018232     0.0442445    -0.199917     -0.0254063   -0.0331962   0.0476447
 -0.103231     0.183919    -0.0289214    0.0425974    0.0161333    0.0855094    0.108314    0.23285      0.146743     -0.0860435   0.106027    -0.0632633  -0.0704209     0.000918763   0.0209221     0.0608416    0.00161696  -0.00299906    0.0330694    -0.255156   -0.035537     0.0758005    -0.17963      -0.0289446    0.167732    0.0993927
 -0.00903896  -0.00834228  -0.0902373   -0.0331357   -0.0239821    0.0434602    0.0548498  -0.0981667   -0.0849637     0.0301439  -0.0778351   -0.204835    0.0541507     0.200124      0.0973719     0.0123662   -0.0817139    0.121664     -0.0238709    -0.0416524  -0.0763045    0.164075     -0.0823212    -0.0646993    0.0361815   0.152766
 -0.0981497    0.119839    -0.0950397   -0.0556132    0.152254    -0.0641556    0.055364    0.0213106   -0.0458645    -0.140873   -0.101277     0.0425379   0.0415552     0.0254944    -0.104458      0.00250971   0.0641223   -0.125375      0.0719722     0.0697148  -0.052548    -0.00699665    0.0177059    -0.00902046   0.0233946  -0.0633461
  0.0958589   -0.100035    -0.0753914    0.183895    -0.218193     0.0740485   -0.149645    0.0794248   -0.0263759    -0.219444    0.131164     0.0110385  -0.0907869    -0.0706838     0.0683202     0.00703166  -0.069048     0.0559861     0.0883199    -0.0871117  -0.101285    -0.0111823     0.0674729     0.164093     0.154253   -0.126872
 -0.196614     0.196518    -0.0117531    0.0673635    0.149621    -0.0423456   -0.0390097  -0.190991    -0.0396498     0.172796   -0.06374     -0.107639    0.0730666     0.0102233     0.0333742     0.101633    -0.0157088   -0.0372855     0.00698818    0.064307   -0.0331353   -0.0247856     0.0704888    -0.093924     0.102191    0.0956865
 -0.0822551    0.106058     0.0152802    0.00196089   0.168981     0.109952    -0.0596225   0.165255     0.0954061    -0.119263    0.014923    -0.0266055  -0.000770891  -0.0401429     0.0193598     0.0787089    0.163674     0.243794      0.10236      -0.0296029  -0.0284591    0.0496435     0.0565895     0.0600422    0.0487185   0.0139818
  0.247195     0.206799     0.0509348    0.197752     0.0647832   -0.0640342   -0.136612    0.0320907    0.100898      0.0688471   0.143201    -0.0298553  -0.04768      -0.155468     -0.0122526     0.0754378    0.0526664   -0.0709914    -0.015654      0.113055    0.0867823   -0.128799     -0.0520427     0.264702    -0.0771457  -0.0588769
 -0.0229406    0.0952034    0.08251      0.0180186    0.0541647   -0.0917804   -0.0336287   0.0564351   -0.000201214  -0.0515547  -0.135553    -0.0371484   0.0440635    -0.191016      0.0296653     0.0204142   -0.209822    -0.134246      0.143244     -0.140707    0.032748     0.0172775     0.0408487     0.0936669   -0.050625   -0.08837
 -0.0405628   -0.0779011   -0.0195224    0.0609631   -0.0292565    0.133816    -0.0669902  -0.00114357  -0.214234     -0.112953    0.131455     0.0485696   0.0237721    -0.124214      0.000291603  -0.202885     0.148894     0.0651264     0.0570248    -0.100029    0.00108641  -0.0646375     0.00240706    0.0279514   -0.133896   -0.146007
  0.0937215    0.0201552   -0.0549729    0.0462224   -0.128915     0.0865061   -0.172268    0.00240536  -0.0123107     0.0230749  -0.105102    -0.107298    0.0437221     0.00584168    0.0236215    -0.17416      0.117639    -0.136212     -0.0444278    -0.0177002  -0.0175752    0.136039      0.000846058  -0.0718008   -0.003875   -0.0622328
  0.221771    -0.0479654   -0.0439714   -0.00270183   0.180955    -0.138591     0.159861   -0.137013    -0.0936805    -0.0156025  -0.0387475   -0.0632474   0.0863137    -0.0870632    -0.142006      0.102575    -0.035349    -0.139947      0.128306     -0.066327   -0.129118    -0.064444      0.0793322    -0.200216    -0.141696   -0.0269432
  0.0456454    0.131241    -0.0539596    0.120852     0.133421     0.0184726    0.187276   -0.142818    -0.0548699    -0.1608      0.210451    -0.0285326  -0.244758      0.00619708   -0.0768839    -0.0120683   -0.0675754   -0.107332      0.221744      0.0946872  -0.158222     0.079913      0.00590667    0.0226004    0.152976    0.040792
 -0.0395182    0.0330444    0.0873975   -0.239386     0.0985443   -0.097412     0.0420913   0.060679    -0.120978     -0.0924582   0.0207659    0.10242    -0.146171     -0.109649      0.00571272   -0.0459384    0.138405     0.00576049    0.160953     -0.0248337   0.0944295    0.000276783   0.0778804    -0.104878    -0.107241    0.0388826
 -0.00994641  -0.0323574   -0.0976279    0.161671    -0.197094     0.0653285   -0.161298   -0.172055    -0.120579      0.160707    0.153536    -0.126124   -0.00588813   -0.0269629     0.257964     -0.00339403  -0.0345387   -0.0311124    -0.100473      0.0511156   0.169512     0.0993738     0.0431764     0.0160445   -0.0597656   0.15492
 -0.0631111   -0.121424    -0.11105      0.041581    -0.0294916   -0.00523422   0.0528991   0.0395864    0.0434942     0.0731876  -0.0125105   -0.0336605  -0.0798259    -0.112393     -0.0534139    -0.0527967    0.0599627   -0.106034      0.0509046    -0.0286139  -0.0700795   -0.15428       0.0580263     0.0261643   -0.0200746  -0.185459
  0.0640568   -0.0358086   -0.10464      0.0662187   -0.0541191    0.133532     0.237578    0.00906509   0.0163957    -0.0499988  -0.066945    -0.0228014  -0.131967     -0.0778725     0.326919     -0.186982    -0.0306101   -0.0756072     0.178234      0.0684553  -0.049671     0.00263094   -0.0875651    -0.136782    -0.0883826  -0.137744
  0.0407058   -0.162505     0.123372     0.127519     0.296599     0.0287139    0.068378    0.00305356   0.0451378    -0.0239925   0.0572399    0.108567   -0.148723     -0.0544854     0.0826334     0.0677879    0.0293076   -0.0449122    -0.0366869     0.144221   -0.128123    -0.0984104     0.106668      0.0459621   -0.237468    0.105404
  0.156773     0.037342    -0.00453142  -0.0893975    0.0276106    0.0213981   -0.0692778  -0.102792    -0.0203169    -0.0502271  -0.0576974    0.169644   -0.0483965     0.00608709   -0.0300549    -0.0405263   -0.170555     0.00700118   -0.0487287    -0.0286574  -0.14798     -0.227913      0.159787      0.10133     -0.0733051  -0.0671563
  0.155909    -0.0970238   -0.135366    -0.0801306   -0.0927246   -0.013483    -0.25701    -0.0249647    0.132295      0.0338404  -0.101275    -0.0980522  -0.0200115    -0.088188     -0.163148      0.164665     0.125972     0.123972     -0.0691458    -0.0232815  -0.0250324   -0.00522764    0.0218393     0.0764849    0.110165    0.0467169
  0.114491     0.0101426    0.0925726    0.0659621    0.0476464    0.146202    -0.107692   -0.0433775   -0.00955944    0.0124844   0.144337     0.133664   -0.116995      0.0621366    -0.125183     -0.0223771    0.154083    -0.0607765    -0.000481179  -0.0783806  -0.253993    -0.0640523    -0.0633616     0.036873    -0.0981499   0.00832317
  0.0893268   -0.0838554   -0.0230579   -0.00448874  -0.0979244    0.108235    -0.134033    0.155217    -0.0258456     0.0932061   0.0183857    0.0634155   0.0366922     0.0427753    -0.0294272    -0.132087     0.125017    -0.0936376     0.0308728    -0.0320753   0.026605    -0.0625492    -0.110626     -0.0412291   -0.0567588  -0.178075
 -0.143065    -0.04102     -0.240138     0.00540591   0.0164362    0.0088177   -0.158737   -0.0554062   -0.000564022   0.0153928   0.0607923    0.0661401  -0.0425004    -0.249151     -0.327862      0.101621    -0.167794    -0.143252     -0.108414      0.0299299   0.00787303   0.0378714    -0.0403923     0.0149191   -0.158399   -0.000577125
  0.00391269  -0.112878    -0.181733    -0.142166    -0.0970101   -0.103514     0.149842   -0.0212327    0.0843202    -0.0599674   0.0164269    0.0960419   0.0045707     0.0552722     0.0586744     0.0226475    0.0632743    0.129519      0.146323      0.164895    0.0369073   -0.0355323     0.158528      0.281041     0.0394498   0.110199
  0.224079    -0.0749104    0.323735     0.00174857  -0.170114     0.0416016    0.159133    0.113923     0.0361933     0.150403   -0.1249       0.168987    0.102051     -0.118845      0.0387327     0.0877012    0.0957841   -0.0961257    -0.219101     -0.115261   -0.0101596    0.0532574     0.158167     -0.0148821    0.10743     0.00856128
  0.0851644    0.13105      0.199978     0.0720463   -0.02535     -0.0209767   -0.0796586  -0.0324945    0.163891     -0.127303    0.0273806   -0.162522    0.0931303    -0.00891507    0.0726632    -0.112354     0.0605147   -0.0378841    -0.0416766     0.0503095  -0.0162658   -0.220299      0.104602     -0.131249     0.169367    0.0799782kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4121973070606288
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412285
[ Info: iteration 2, average log likelihood -1.412191
[ Info: iteration 3, average log likelihood -1.410879
[ Info: iteration 4, average log likelihood -1.399272
[ Info: iteration 5, average log likelihood -1.382245
[ Info: iteration 6, average log likelihood -1.377819
[ Info: iteration 7, average log likelihood -1.376843
[ Info: iteration 8, average log likelihood -1.376333
[ Info: iteration 9, average log likelihood -1.375982
[ Info: iteration 10, average log likelihood -1.375679
[ Info: iteration 11, average log likelihood -1.375392
[ Info: iteration 12, average log likelihood -1.375172
[ Info: iteration 13, average log likelihood -1.375030
[ Info: iteration 14, average log likelihood -1.374934
[ Info: iteration 15, average log likelihood -1.374863
[ Info: iteration 16, average log likelihood -1.374805
[ Info: iteration 17, average log likelihood -1.374756
[ Info: iteration 18, average log likelihood -1.374711
[ Info: iteration 19, average log likelihood -1.374672
[ Info: iteration 20, average log likelihood -1.374638
[ Info: iteration 21, average log likelihood -1.374610
[ Info: iteration 22, average log likelihood -1.374586
[ Info: iteration 23, average log likelihood -1.374566
[ Info: iteration 24, average log likelihood -1.374550
[ Info: iteration 25, average log likelihood -1.374536
[ Info: iteration 26, average log likelihood -1.374523
[ Info: iteration 27, average log likelihood -1.374510
[ Info: iteration 28, average log likelihood -1.374497
[ Info: iteration 29, average log likelihood -1.374483
[ Info: iteration 30, average log likelihood -1.374469
[ Info: iteration 31, average log likelihood -1.374453
[ Info: iteration 32, average log likelihood -1.374436
[ Info: iteration 33, average log likelihood -1.374418
[ Info: iteration 34, average log likelihood -1.374396
[ Info: iteration 35, average log likelihood -1.374371
[ Info: iteration 36, average log likelihood -1.374342
[ Info: iteration 37, average log likelihood -1.374309
[ Info: iteration 38, average log likelihood -1.374272
[ Info: iteration 39, average log likelihood -1.374233
[ Info: iteration 40, average log likelihood -1.374190
[ Info: iteration 41, average log likelihood -1.374138
[ Info: iteration 42, average log likelihood -1.374079
[ Info: iteration 43, average log likelihood -1.374014
[ Info: iteration 44, average log likelihood -1.373943
[ Info: iteration 45, average log likelihood -1.373870
[ Info: iteration 46, average log likelihood -1.373799
[ Info: iteration 47, average log likelihood -1.373734
[ Info: iteration 48, average log likelihood -1.373676
[ Info: iteration 49, average log likelihood -1.373625
[ Info: iteration 50, average log likelihood -1.373582
┌ Info: EM with 100000 data points 50 iterations avll -1.373582
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4122846871456314
│     -1.4121908954933529
│      ⋮
└     -1.3735818022306248
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.373687
[ Info: iteration 2, average log likelihood -1.373536
[ Info: iteration 3, average log likelihood -1.372962
[ Info: iteration 4, average log likelihood -1.366985
[ Info: iteration 5, average log likelihood -1.348080
[ Info: iteration 6, average log likelihood -1.336566
[ Info: iteration 7, average log likelihood -1.333375
[ Info: iteration 8, average log likelihood -1.330908
[ Info: iteration 9, average log likelihood -1.327458
[ Info: iteration 10, average log likelihood -1.323765
[ Info: iteration 11, average log likelihood -1.321746
[ Info: iteration 12, average log likelihood -1.320735
[ Info: iteration 13, average log likelihood -1.320106
[ Info: iteration 14, average log likelihood -1.319674
[ Info: iteration 15, average log likelihood -1.319344
[ Info: iteration 16, average log likelihood -1.319079
[ Info: iteration 17, average log likelihood -1.318880
[ Info: iteration 18, average log likelihood -1.318731
[ Info: iteration 19, average log likelihood -1.318615
[ Info: iteration 20, average log likelihood -1.318522
[ Info: iteration 21, average log likelihood -1.318442
[ Info: iteration 22, average log likelihood -1.318371
[ Info: iteration 23, average log likelihood -1.318310
[ Info: iteration 24, average log likelihood -1.318262
[ Info: iteration 25, average log likelihood -1.318227
[ Info: iteration 26, average log likelihood -1.318204
[ Info: iteration 27, average log likelihood -1.318187
[ Info: iteration 28, average log likelihood -1.318175
[ Info: iteration 29, average log likelihood -1.318166
[ Info: iteration 30, average log likelihood -1.318159
[ Info: iteration 31, average log likelihood -1.318153
[ Info: iteration 32, average log likelihood -1.318148
[ Info: iteration 33, average log likelihood -1.318144
[ Info: iteration 34, average log likelihood -1.318140
[ Info: iteration 35, average log likelihood -1.318137
[ Info: iteration 36, average log likelihood -1.318134
[ Info: iteration 37, average log likelihood -1.318131
[ Info: iteration 38, average log likelihood -1.318129
[ Info: iteration 39, average log likelihood -1.318126
[ Info: iteration 40, average log likelihood -1.318123
[ Info: iteration 41, average log likelihood -1.318121
[ Info: iteration 42, average log likelihood -1.318118
[ Info: iteration 43, average log likelihood -1.318116
[ Info: iteration 44, average log likelihood -1.318113
[ Info: iteration 45, average log likelihood -1.318111
[ Info: iteration 46, average log likelihood -1.318108
[ Info: iteration 47, average log likelihood -1.318105
[ Info: iteration 48, average log likelihood -1.318102
[ Info: iteration 49, average log likelihood -1.318100
[ Info: iteration 50, average log likelihood -1.318097
┌ Info: EM with 100000 data points 50 iterations avll -1.318097
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3736869548910942
│     -1.3735357780973656
│      ⋮
└     -1.3180969328743732
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.318263
[ Info: iteration 2, average log likelihood -1.318066
[ Info: iteration 3, average log likelihood -1.316703
[ Info: iteration 4, average log likelihood -1.302939
[ Info: iteration 5, average log likelihood -1.274537
[ Info: iteration 6, average log likelihood -1.262607
[ Info: iteration 7, average log likelihood -1.258491
[ Info: iteration 8, average log likelihood -1.255535
[ Info: iteration 9, average log likelihood -1.253476
[ Info: iteration 10, average log likelihood -1.251846
[ Info: iteration 11, average log likelihood -1.249838
[ Info: iteration 12, average log likelihood -1.248355
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.247502
[ Info: iteration 14, average log likelihood -1.258272
[ Info: iteration 15, average log likelihood -1.251737
[ Info: iteration 16, average log likelihood -1.250210
[ Info: iteration 17, average log likelihood -1.249096
[ Info: iteration 18, average log likelihood -1.248031
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.247221
[ Info: iteration 20, average log likelihood -1.258011
[ Info: iteration 21, average log likelihood -1.251581
[ Info: iteration 22, average log likelihood -1.250135
[ Info: iteration 23, average log likelihood -1.249057
[ Info: iteration 24, average log likelihood -1.248005
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.247192
[ Info: iteration 26, average log likelihood -1.257942
[ Info: iteration 27, average log likelihood -1.251543
[ Info: iteration 28, average log likelihood -1.250109
[ Info: iteration 29, average log likelihood -1.249029
[ Info: iteration 30, average log likelihood -1.247974
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.247163
[ Info: iteration 32, average log likelihood -1.257907
[ Info: iteration 33, average log likelihood -1.251517
[ Info: iteration 34, average log likelihood -1.250089
[ Info: iteration 35, average log likelihood -1.249006
[ Info: iteration 36, average log likelihood -1.247951
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.247142
[ Info: iteration 38, average log likelihood -1.257877
[ Info: iteration 39, average log likelihood -1.251491
[ Info: iteration 40, average log likelihood -1.250072
[ Info: iteration 41, average log likelihood -1.248994
[ Info: iteration 42, average log likelihood -1.247942
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.247132
[ Info: iteration 44, average log likelihood -1.257851
[ Info: iteration 45, average log likelihood -1.251470
[ Info: iteration 46, average log likelihood -1.250063
[ Info: iteration 47, average log likelihood -1.248992
[ Info: iteration 48, average log likelihood -1.247944
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.247132
[ Info: iteration 50, average log likelihood -1.257830
┌ Info: EM with 100000 data points 50 iterations avll -1.257830
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.318262738844563
│     -1.3180664201448948
│      ⋮
└     -1.257829998134765
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.251687
[ Info: iteration 2, average log likelihood -1.249966
[ Info: iteration 3, average log likelihood -1.247138
[ Info: iteration 4, average log likelihood -1.227910
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.189662
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.183611
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.186927
[ Info: iteration 8, average log likelihood -1.184390
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.155139
[ Info: iteration 10, average log likelihood -1.200829
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.174706
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.164354
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     3
│     5
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.169188
[ Info: iteration 14, average log likelihood -1.188771
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.156804
[ Info: iteration 16, average log likelihood -1.181406
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     3
│     5
│     6
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.160308
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.173909
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.175438
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.173612
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      6
│      7
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.146690
[ Info: iteration 22, average log likelihood -1.193884
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.168134
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.157045
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.165338
[ Info: iteration 26, average log likelihood -1.176927
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      6
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.144484
[ Info: iteration 28, average log likelihood -1.175412
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.152777
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.160355
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.168425
[ Info: iteration 32, average log likelihood -1.165297
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      6
│      7
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.137146
[ Info: iteration 34, average log likelihood -1.185063
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.159356
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.150315
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.162230
[ Info: iteration 38, average log likelihood -1.175457
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      6
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.143865
[ Info: iteration 40, average log likelihood -1.175097
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.152612
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.160268
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.168340
[ Info: iteration 44, average log likelihood -1.165122
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      6
│      7
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.137088
[ Info: iteration 46, average log likelihood -1.184934
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.159240
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.150190
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.162140
[ Info: iteration 50, average log likelihood -1.175308
┌ Info: EM with 100000 data points 50 iterations avll -1.175308
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.251687413541483
│     -1.249965905093736
│      ⋮
└     -1.1753075051248558
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.144031
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.140104
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.135982
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.117923
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.080099
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.055034
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.049438
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.050189
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.058852
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.044259
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.039353
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.062032
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.059374
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.037087
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.061592
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.051372
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.045117
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.046256
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.047300
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.042812
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.050248
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.046770
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.045794
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.047594
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.053313
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.031004
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.049163
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.053333
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.047359
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.042300
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.052989
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.039468
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.039076
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.055921
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.046258
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.046939
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.042768
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.038186
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.038140
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      5
│      6
│     10
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.032251
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.057509
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.045939
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.045385
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.033632
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.053784
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      6
│     10
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.033217
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.046132
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.040168
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.046888
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.048123
┌ Info: EM with 100000 data points 50 iterations avll -1.048123
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1440314214173772
│     -1.1401040917399419
│      ⋮
└     -1.048123362004997
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4121973070606288
│     -1.4122846871456314
│     -1.4121908954933529
│     -1.4108790255726018
│      ⋮
│     -1.0401682847388998
│     -1.046887955670222
└     -1.048123362004997
32×26 Array{Float64,2}:
 -0.0470474   -0.0771539    -0.0173539    0.06048     -0.00349872   0.139402     -0.0669816    -0.00178123  -0.196923    -0.110043    0.131627     0.0544865    0.0254219    -0.0902362   -0.00234152  -0.170927     0.146779    0.0579561    0.058379    -0.102939     0.0178384   -0.0587213     0.0127661   0.023008    -0.13192     -0.145012
  0.0937252    0.142781      0.175587     0.0616043    0.00548314  -0.0271571    -0.0878209    -0.0308397    0.166583    -0.129267    0.00868579  -0.116351     0.0696624    -0.00284186   0.0745815   -0.0804284    0.0809898  -0.0365158   -0.0452777    0.0517982   -0.0338015   -0.259193      0.0823359  -0.115469     0.176421     0.0846565
  0.0213872   -0.0326573     0.00368473   0.145596    -0.130896     0.0241941     0.114607     -0.0228171    0.0189355    0.107185   -0.0182829   -0.140266    -0.0955345    -0.130452    -0.0557946   -0.0856104   -0.0736907   0.00203732   0.14252      0.0104193   -0.0246995    0.0418557    -0.252289   -0.0210983   -0.0303094    0.0515257
 -0.188598     0.193874     -0.0168714    0.0674678    0.153338    -0.0425908    -0.0563792    -0.173848    -0.0452005    0.169737   -0.0669692   -0.0786887    0.0729447     0.0109491    0.0204767    0.0944845   -0.0136227  -0.0348649    0.0946963    0.0625956   -0.00283363  -0.0210422     0.0725746  -0.0905236    0.100245     0.093338
  0.0363018    0.153629     -0.0217591   -0.178135     0.0058312   -0.0408773    -0.108143      0.21509     -0.625753     0.0161331  -0.100733     0.0719703   -0.0426285    -0.0322779   -0.0889419   -0.0703134    0.0811789   0.10362     -0.0544883   -0.0395898    0.388207    -0.16175      -0.0969557   0.0691654    0.0235272    0.169345
  0.0327801   -0.291385     -0.015214    -0.207629     0.00323988  -0.0508876    -0.0987161     0.215228     0.311578     0.0234971  -0.100359     0.0285039   -0.0467246    -0.0734502   -0.100471    -0.0848596   -0.0512237   0.058437    -0.0596202   -0.0386474   -0.0904465   -0.161636      0.284003    0.070348    -0.0257262   -0.00392732
  0.231499    -0.0267373     0.24388      0.00457319   0.00516555   0.0755543     0.0435792     0.111156    -0.0853079    0.166455   -0.189117    -0.173962     0.0928879     0.0319971    0.0518323    0.0285685    0.0827703  -0.0594653   -0.271905    -0.173202    -0.0578391    0.0624614     0.201226   -0.320362     0.132283     0.0288312
  0.216915    -0.0705813     0.287369     0.00340325  -0.299771     0.020378      0.29182       0.115298     0.138247     0.119152   -0.087427     0.471368     0.121144     -0.180634     0.0403931    0.139057     0.0954618  -0.133299    -0.223224    -0.132885     0.0297843    0.0483801     0.169937    0.273146     0.0958689   -0.0206499
  0.26937      0.206872      0.0366944    0.203264     0.0614879   -0.0428249    -0.147364      0.038175     0.0901573    0.0703516   0.161518    -0.033507    -0.0394993    -0.174841    -0.0120296    0.0749307    0.0363016  -0.0838127   -0.0527517    0.118132     0.0985065   -0.126887     -0.0587403   0.278009    -0.0750898   -0.0323884
  0.0120525    0.114569      0.0266306    0.0841645    0.165655     0.0892889    -0.051137      0.158707     0.0877076   -0.133188    0.0486323   -0.0466631    0.0128086    -0.0404969    0.00292615   0.0774248    0.144301    0.323161     0.229263     0.0313332   -0.0372969   -0.0413297     0.0370186   0.0809927    0.012218     0.039901
  0.0352819    0.0898344     0.384159     0.0988704   -0.132392     0.00326538    0.0347021    -0.02663      0.207011    -0.0390507   0.231146     0.227944     0.029056     -0.718142     0.0428282    0.0981482   -0.0865115   0.331304    -0.143891    -0.181371    -0.112208     0.181359      0.0876081   0.00226537  -0.116176    -0.167853
  0.0348443   -0.199068     -0.405559    -0.066142    -0.121515     0.0632854    -0.000896329   0.00970921   0.182325    -0.0978472   0.194267     0.225324     0.04414       0.79176      0.0423698   -0.231367     0.0394782  -0.113793     0.149919    -0.106529    -0.115591    -0.131379     -0.0278341  -0.0729106    0.149212    -0.0605579
 -0.00406248   0.336458      0.165503     0.0574208    0.0420278   -0.168058     -0.040846      0.0513114    0.00130444  -0.0629588  -0.136541     0.00818139   0.0377455    -0.106604    -0.027227     0.0545948   -0.275061   -0.151397     0.0500889    0.0402898    0.0581001   -0.000755973   0.0179384   0.0661447   -0.0813785   -0.107869
  0.220211    -0.0465538    -0.0443982    0.00265      0.179664    -0.138719      0.155195     -0.137112    -0.0934519   -0.0137181  -0.0480952   -0.0172366    0.0871632    -0.119136    -0.137484     0.11429     -0.0274259  -0.130146     0.123141    -0.0503844   -0.157631    -0.0577055     0.0704546  -0.203093    -0.142742    -0.0324495
 -0.0311389   -0.134159     -0.0480651   -0.0370542    0.0627173    0.0805359    -0.11256       0.0620064   -0.00362634  -0.0455169  -0.136663    -0.115492     0.0572212    -0.27756      0.0716547   -0.0515193   -0.159014   -0.195111     0.0662739   -0.245392     0.0177363    0.0292662     0.0573402   0.154637    -0.0185186   -0.0595353
  0.0506389   -0.166721      0.126836     0.1013       0.28861      0.0369046     0.169517      0.0041833    0.0447308   -0.0296436   0.0512065    0.0981741   -0.143434     -0.0692093    0.0660979    0.0637221    0.0200759  -0.0564092   -0.0601076    0.130452    -0.124952    -0.0930627     0.104378    0.0451559   -0.225343     0.0612727
 -0.0507291    0.145455      0.0142599    0.0316679    0.0163067    0.0666347     0.0821016     0.236524     0.104377    -0.0783392   0.105189    -0.0508567   -0.120514     -0.0126526    0.0738349    0.0332018   -0.0143397  -0.025869    -0.00146081  -0.251648    -0.056741     0.0644925    -0.175443   -0.0272347    0.166906     0.100169
 -0.0280917    0.00619876   -0.103138     0.00574821   0.00757889   0.0373634    -0.0946831     0.033321    -0.0117979   -0.112451    0.0320811    0.0457224   -0.0364467    -0.0612321   -0.0810006    0.0509454   -0.042942   -0.0145687    0.00230728  -0.0106046   -0.0487698   -0.00805221    0.0453918   0.0741555   -0.00111631  -0.0301057
  0.0395377    0.126397     -0.013066     0.0157704    0.0134612    0.0318645    -0.0513415     0.159135    -0.0324115   -0.0749747   0.0405531    0.0296829    0.0103205     0.0360741   -0.174192    -0.138775    -0.0554383  -0.0938162   -0.107504    -0.00791265   0.0848801    0.0369425    -0.0924962   0.0459202   -0.0861282   -0.0191065
  0.175798    -0.0811712    -0.118384    -0.106064    -0.0818398    0.000734092  -0.21715       0.0205873    0.0873079    0.0174564  -0.0866766   -0.119602    -0.0186191    -0.109291    -0.149864     0.090669     0.130863    0.0660357   -0.0664753   -0.0111351   -0.00262054  -0.00982453    0.0871699   0.0365412    0.0575542    0.024958
 -0.0486694    0.0323806     0.099046    -0.235953     0.0615363   -0.126801      0.0550292     0.0515014   -0.105016    -0.0838434   0.0289448    0.0910157   -0.143748     -0.116708    -0.0217268   -0.0347578    0.1499      0.00438914   0.150663    -0.022251     0.0950225    0.013244      0.0277028  -0.0819331   -0.101632     0.0191729
 -0.0310299    0.00339473   -0.011349    -0.183289     0.00101244   0.0167857    -0.0260242    -0.0682204   -0.0673876    0.009193   -0.0586676   -0.130974     0.0164272     0.0111274    0.0935665    0.0156901   -0.0215193   0.0785551    0.00802852  -0.0398524   -0.0897971    0.0811393    -0.125694    0.0156743    0.0342403    0.121294
  0.0214978   -0.053462     -0.149736     0.159867    -0.184612     0.0643985    -0.150915     -0.147579    -0.142763     0.149799    0.131281    -0.118201     0.000904274  -0.041114     0.257426     0.00909947  -0.0228633  -0.0288025   -0.100976     0.0497086    0.15793      0.123786      0.0348731   0.0138325   -0.133234     0.15351
 -0.0426358   -0.080911     -0.0907248    0.0148932   -0.0112314   -0.00782642    0.058697      0.0519433    0.0296294    0.0515511  -0.0216853   -0.0135409   -0.048261     -0.121287    -0.0529147   -0.0478719    0.0527863  -0.0987569    0.105872    -0.0393691   -0.0880678   -0.156408      0.0608927   0.0236437   -0.0365138   -0.209663
  0.0594964   -0.034955     -0.199443     0.0311351   -0.521432     0.248155      0.237868      0.0085258    0.0172184   -0.0503028  -0.10136     -0.0947059   -0.161442     -0.0894241    0.323346    -0.210773    -0.0153427  -0.0182194    0.182723     0.0829181   -0.0408833   -0.0663384    -0.0875517  -0.140165    -0.0881596   -0.132656
  0.0586915   -0.0357152     0.00299881   0.0907913    0.30447     -0.0149543     0.237072      0.00851538   0.0132059   -0.0481196   0.0533761    0.0159638   -0.0926746    -0.0285019    0.32943     -0.149589    -0.0385421  -0.117624     0.176279     0.0754179   -0.0591018    0.0119185    -0.0873358  -0.132194    -0.0882184   -0.142798
  0.0262497   -0.230934     -0.183352     0.219253    -0.182773     0.00693501    0.227593      0.0281065    0.0559578   -0.0291858  -0.431029     0.0922523    0.0231835     0.074652    -0.0244688    0.0195987    0.0516616   0.128739     0.12118      0.0902745    0.125035    -0.158574      0.15727     0.273613     0.105067     0.148856
 -0.0137       0.0438271    -0.185079    -0.472184     0.0813969   -0.156877      0.0691418    -0.0819534    0.0945976   -0.0875246   0.409089     0.0915148   -0.0310522     0.0400581    0.153952    -0.00138505   0.0757246   0.128459     0.180356     0.216437    -0.0543687    0.153383      0.167419    0.288833    -0.0729835    0.115323
  0.114853     0.00830882    0.0809352    0.078137     0.0403298    0.134899     -0.096254     -0.00340551  -0.00870374   0.0175381   0.158748     0.134317    -0.0877674     0.0603207   -0.126454    -0.0278887    0.157923   -0.0857627   -0.005706    -0.109386    -0.260865    -0.0611061    -0.04411     0.035037    -0.093267     0.0267127
  0.0885628   -0.000359514  -0.0377127    0.00163189  -0.119417     0.091572     -0.150737      0.0682575   -0.0163721    0.0342675  -0.0885797   -0.00175624   0.0361294     0.0266115   -0.00630471  -0.161459     0.114233   -0.0919673   -0.0037282   -0.0246982    0.0233984    0.0381494    -0.0593832  -0.0586825   -0.0339849   -0.0979201
  0.0449687    0.131801     -0.0116217    0.130328     0.12541      0.0415891     0.191261     -0.151829    -0.0579391   -0.167929    0.212305    -0.0269897   -0.240784      0.00525952  -0.0711425    0.00768614  -0.0631287  -0.0729632    0.224602     0.106868    -0.157079     0.0768228     0.0226866   0.0192268    0.156848     0.0712427
 -0.0389079   -0.129881     -0.0852157    0.0156219    0.112388    -0.207208     -0.0612516     0.118548     0.00150928   0.028724    0.0331312    0.0701767    0.0590667     0.0692219   -0.121963    -0.0297915    0.11447     0.0923135   -0.0910192    0.0190981    0.0519845    0.126015      0.0597536   0.00737173  -0.051037     0.0635183[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.047786
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.026312
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      5
│      6
│     10
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.029588
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.034125
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.031881
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.021894
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     11
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.044305
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.021758
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      5
│      6
│     10
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.031544
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      5
│      6
│     11
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.034190
┌ Info: EM with 100000 data points 10 iterations avll -1.034190
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.721361e+05
      1       6.826207e+05      -1.895154e+05 |       32
      2       6.513814e+05      -3.123930e+04 |       32
      3       6.357769e+05      -1.560450e+04 |       32
      4       6.259924e+05      -9.784497e+03 |       32
      5       6.192016e+05      -6.790816e+03 |       32
      6       6.151398e+05      -4.061852e+03 |       32
      7       6.133559e+05      -1.783877e+03 |       32
      8       6.125138e+05      -8.420356e+02 |       32
      9       6.118838e+05      -6.299980e+02 |       32
     10       6.111585e+05      -7.253614e+02 |       32
     11       6.103807e+05      -7.777663e+02 |       32
     12       6.096625e+05      -7.182499e+02 |       32
     13       6.089781e+05      -6.843712e+02 |       32
     14       6.080966e+05      -8.814485e+02 |       32
     15       6.070817e+05      -1.014901e+03 |       32
     16       6.059836e+05      -1.098133e+03 |       32
     17       6.051161e+05      -8.675573e+02 |       32
     18       6.046537e+05      -4.623290e+02 |       32
     19       6.043168e+05      -3.369668e+02 |       32
     20       6.039297e+05      -3.870478e+02 |       32
     21       6.034844e+05      -4.453050e+02 |       32
     22       6.029657e+05      -5.186956e+02 |       32
     23       6.023856e+05      -5.800703e+02 |       32
     24       6.018356e+05      -5.500200e+02 |       32
     25       6.012413e+05      -5.943524e+02 |       32
     26       6.006468e+05      -5.944565e+02 |       32
     27       6.001154e+05      -5.314547e+02 |       32
     28       5.997734e+05      -3.419183e+02 |       32
     29       5.996213e+05      -1.521539e+02 |       32
     30       5.994966e+05      -1.246715e+02 |       32
     31       5.993423e+05      -1.543340e+02 |       31
     32       5.991523e+05      -1.900211e+02 |       32
     33       5.989406e+05      -2.117025e+02 |       32
     34       5.987626e+05      -1.779585e+02 |       32
     35       5.986369e+05      -1.257037e+02 |       32
     36       5.985637e+05      -7.324438e+01 |       32
     37       5.985156e+05      -4.805522e+01 |       32
     38       5.984805e+05      -3.511582e+01 |       32
     39       5.984574e+05      -2.312866e+01 |       32
     40       5.984451e+05      -1.221806e+01 |       31
     41       5.984373e+05      -7.787208e+00 |       29
     42       5.984330e+05      -4.303054e+00 |       25
     43       5.984314e+05      -1.600070e+00 |       23
     44       5.984297e+05      -1.758363e+00 |       16
     45       5.984287e+05      -9.828243e-01 |       18
     46       5.984273e+05      -1.372068e+00 |       19
     47       5.984261e+05      -1.206650e+00 |       19
     48       5.984251e+05      -1.048297e+00 |       15
     49       5.984240e+05      -1.106773e+00 |       19
     50       5.984225e+05      -1.440840e+00 |       15
K-means terminated without convergence after 50 iterations (objv = 598422.5267728684)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.306507
[ Info: iteration 2, average log likelihood -1.273475
[ Info: iteration 3, average log likelihood -1.241111
[ Info: iteration 4, average log likelihood -1.204586
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.160126
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      7
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.120745
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.096430
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.056211
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     11
│     12
│     16
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.024944
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.079201
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.054329
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.059786
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     11
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.033316
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      7
│     12
│     14
│     16
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.011643
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.080609
[ Info: iteration 16, average log likelihood -1.068198
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      7
│     11
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.011371
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      9
│     12
│     14
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.030406
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     16
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.067625
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│      7
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.051419
[ Info: iteration 21, average log likelihood -1.055000
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│     11
│     12
│     14
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -0.984722
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     16
│     18
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.055291
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.082259
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.040198
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      3
│      7
│     12
│     14
│     18
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -0.998844
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     16
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.061061
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.051431
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.034076
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      9
│     12
│     14
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.008391
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     11
│     16
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.051743
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     18
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.039288
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.042858
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│     12
│     14
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.018666
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     16
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.052920
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     11
│     18
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.027705
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.048680
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      3
│      7
│     12
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.017155
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     18
│     22
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.040161
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.054907
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      9
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.034536
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     12
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.024988
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│     14
│     18
│     22
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.024219
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.062204
[ Info: iteration 45, average log likelihood -1.046638
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│     11
│     12
│     18
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -0.988689
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      9
│     14
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.040598
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.082215
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.033949
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      7
│      9
│     12
│     18
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -0.992886
┌ Info: EM with 100000 data points 50 iterations avll -0.992886
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.196718    -0.0297751   -0.0767015   -0.101726    -0.0395707    0.0121967   -0.177148    0.0769684    0.0623666   -0.0168112   -0.0634642   -0.111612   -0.0189988   -0.110223    -0.134001     0.0131341    0.0978643   -0.00712144  -0.0710634   -0.00214167   0.0724904   -0.0201063    0.0692737   0.0180761    0.00123874   -0.00391515
  0.220822    -0.0465532   -0.044478     0.00336428   0.180522    -0.139413     0.15874    -0.13768     -0.0933989   -0.012886    -0.0471198   -0.0172042   0.0873824   -0.119074    -0.136916     0.114462    -0.0271237   -0.132312     0.125125    -0.0504326   -0.158606    -0.0556182    0.068375   -0.204709    -0.143003     -0.032604
 -0.0996104    0.173997    -0.0367013    0.06729      0.0279789    0.0375446   -0.050329    0.154804    -0.0622428   -0.0675273    0.0596814    0.0690965   0.00112436   0.101717    -0.124913     0.00574831  -0.0783846    0.0391279   -0.125856    -0.0533981    0.00781269   0.121635    -0.165095    0.0751314   -0.0527957    -0.0314478
  0.0549404   -0.18578      0.166943     0.114858     0.313662     0.0397277    0.201717   -0.00201498   0.0455892   -0.0287089    0.0498021    0.105497   -0.152307    -0.0593005    0.0670852    0.0676842    0.0211729   -0.0703301   -0.0863592    0.137334    -0.127751    -0.104911     0.109579    0.0403447   -0.261711      0.0888538
  0.0856315    0.0289936   -0.0485964    0.0256282   -0.156572     0.0847901   -0.187557    0.013703    -0.00169948  -0.00919757  -0.16356     -0.113718    0.0471197    0.00596309   0.0264333   -0.178434     0.131183    -0.124123    -0.0410926   -0.0188686    0.017419     0.153413    -0.0171835  -0.0825208   -0.006635     -0.0823012
 -0.053675     0.00998858   0.0566278   -0.314003     0.0195145   -0.0141422   -0.0916332  -0.043184    -0.0213826   -0.0262382   -0.00245955  -0.0744009  -0.0178459   -0.127504     0.111125     0.0139087    0.028606     0.0405963    0.0468251   -0.0484893   -0.0906818    0.00975674  -0.176523    0.0868593    0.033963      0.0998498
 -0.0842826    0.124936    -0.094264    -0.0677341    0.151626    -0.0535315    0.0549796   0.0515514   -0.0443717   -0.138927    -0.0997274    0.0421022   0.0379943    0.0264224   -0.070937    -0.0204961    0.054306    -0.13905      0.0687878    0.0697418   -0.0681577    0.0474897    0.0176069  -0.0133261   -0.000482846  -0.0379918
  0.0187146   -0.0302317    0.00174126   0.146853    -0.132093     0.0245407    0.11671    -0.0227028    0.0189268    0.111659    -0.0176208   -0.141597   -0.0965809   -0.13211     -0.0565833   -0.0854141   -0.0700175    0.00234738   0.145589     0.0101598   -0.0253302    0.0442167   -0.253435   -0.0212663   -0.029901      0.0537423
  0.0594268   -0.0352665   -0.0962986    0.0610939   -0.101396     0.113417     0.236951    0.00801876   0.0147646   -0.0493523   -0.0227176   -0.0383091  -0.125656    -0.058686     0.32578     -0.180045    -0.0269188   -0.0689912    0.180053     0.0792718   -0.049878    -0.0279426   -0.0870897  -0.136449    -0.0880106    -0.137352
 -0.0458694    0.032624     0.106825    -0.23689      0.063734    -0.133601     0.0598586   0.0527372   -0.10622     -0.0801322    0.0288678    0.0910773  -0.144965    -0.114564    -0.0139203   -0.0368216    0.154481     0.00279753   0.155763    -0.0239756    0.100243     0.0131173    0.0263762  -0.0853088   -0.101506      0.021899
 -0.0719084    0.155843    -0.0250998    0.071559    -0.0305857    0.0283989   -0.0243339   0.154269    -0.0527539   -0.0634013    0.0756367    0.0925858   0.0344135    0.119409    -0.257072    -0.124726    -0.109175    -0.0879491   -0.149281    -0.0193888    0.0213905    0.0892586   -0.178609    0.0807661   -0.0735856     0.0247254
  0.0905731    0.141181     0.203512     0.0625716   -0.00379751  -0.029673    -0.102774   -0.0247484    0.178931    -0.12713      0.0266155   -0.154661    0.0807251   -0.00753753   0.0774135   -0.086018     0.0977688   -0.037648    -0.047279     0.0500785   -0.0235973   -0.261625     0.079992   -0.139864     0.192969      0.0831918
  0.116924     0.00647648   0.0820842    0.0767327    0.0416431    0.1341      -0.0995763  -0.00683503  -0.00863548   0.0166944    0.157579     0.13386    -0.0884615    0.0602655   -0.125993    -0.0291728    0.158529    -0.0858551   -0.00585408  -0.111646    -0.262228    -0.0632274   -0.0416847   0.0340477   -0.0948484     0.0307042
  0.036162    -0.0661353   -0.0507636    0.0113487   -0.12531      0.0365555    0.0158178  -0.00672129   0.193037    -0.0736698    0.211616     0.226894    0.0349293    0.102158     0.0420963   -0.0814501   -0.0181196    0.0839298    0.0142451   -0.135064    -0.113498     0.00565293   0.0190841  -0.0397938    0.0298139    -0.104181
  0.221911    -0.0495745    0.273546     0.00461434  -0.165605     0.0414616    0.182       0.114792     0.0399006    0.140982    -0.133825     0.186184    0.109216    -0.0911385    0.0443652    0.0947852    0.0921433   -0.103412    -0.245934    -0.154681    -0.0106018    0.0527809    0.184056    0.0218132    0.114049     -0.0025177
 -0.101965     0.101854     0.0145635    6.24251e-6   0.181438     0.115219    -0.0648027   0.163695     0.101905    -0.129824     0.0257038   -0.0293576  -0.0153038   -0.0108228    0.0352023    0.0724313    0.161169     0.301752     0.128732    -0.0142026   -0.0354607    0.0417009    0.0778374   0.0585131    0.0768932     0.0687195
  0.112126    -0.0924333   -0.0944156    0.188947    -0.218145     0.0895168   -0.170857    0.0799739   -0.0366109   -0.176494     0.15803      0.0102852  -0.136046    -0.0324566    0.0736722    0.0126511   -0.0386708    0.035863     0.08511     -0.0981943   -0.0813174   -0.0297987    0.0642801   0.216302     0.145828     -0.110618
  0.00623179  -0.0948245   -0.184218    -0.125888    -0.0584414   -0.0728977    0.152418   -0.0251548    0.0772986   -0.0574801   -0.00537449   0.0925102  -0.00324795   0.0585874    0.0684858    0.00945356   0.0629607    0.128764     0.151204     0.154352     0.0367011   -0.00508048   0.161299    0.314894     0.0135797     0.137367
 -0.0410893   -0.13129     -0.0845303    0.0158405    0.113001    -0.206864    -0.0611567   0.121337     0.00150111   0.0289877    0.0333689    0.0707287   0.0589459    0.0699386   -0.122783    -0.0298189    0.119002     0.0924351   -0.0910844    0.0184928    0.0515222    0.125839     0.0591516   0.00715417  -0.0515026     0.0653449
 -0.016451     0.0833701    0.07085      0.0146567    0.058795    -0.044923    -0.065591    0.0564807    0.00367449  -0.0508982   -0.116511    -0.0423167   0.0325686   -0.186623     0.0256877    0.00760142  -0.19652     -0.156369     0.0468002   -0.0778062    0.0247519    0.0169209    0.0426529   0.106017    -0.0596161    -0.0875915
  0.0451851    0.131552    -0.0103089    0.130595     0.126471     0.0409762    0.193425   -0.155026    -0.0583504   -0.169684     0.212669    -0.0272394  -0.241516     0.00516185  -0.0693891    0.00544832  -0.0635242   -0.0767189    0.226582     0.107114    -0.158163     0.0779903    0.022725    0.0186578    0.157791      0.0723888
  0.0727665   -0.101197    -0.1661      -0.016844     0.0444534   -0.032705     0.106005   -0.076268     0.042394    -0.0461219   -0.0134095    0.0563084  -0.00536116   0.038946     0.0626189    0.0203821    0.0782648    0.14287      0.117258     0.119029    -0.0200338    0.0418379    0.105365   -0.164676     0.00696178    0.0901313
  0.0161619   -0.0565917   -0.151517     0.159866    -0.196689     0.0655166   -0.152757   -0.153173    -0.140833     0.147568     0.143528    -0.128468    0.00452961  -0.0565071    0.261599     0.00528793  -0.023548    -0.0298345   -0.0997418    0.0516107    0.157017     0.136019     0.0340148   0.0114592   -0.138434      0.152864
 -0.0623359    0.149426     0.0174525    0.0369831    0.0159461    0.0697811    0.0891565   0.253294     0.109692    -0.0733219    0.112211    -0.0637003  -0.124512    -0.0213277    0.0643617    0.0470123   -0.00531848  -0.0276647    0.00493708  -0.254796    -0.0388848    0.0753864   -0.183593   -0.0333524    0.171781      0.0986078
 -0.0470496   -0.0773229   -0.0154963    0.0603507   -0.00452876   0.140752    -0.0678701  -0.0037236   -0.197563    -0.109585     0.131151     0.0539173   0.0263789   -0.0916885   -0.00344763  -0.170503     0.150097     0.0582346    0.0595738   -0.103506     0.0182807   -0.0606119    0.011164    0.0227298   -0.131914     -0.144702
  0.160299     0.0343894   -0.0161446   -0.100525     0.0273497    0.0207015   -0.0770499  -0.103768    -0.0341189   -0.0440339   -0.0820142    0.171833   -0.0478871    0.0150021   -0.0150017    0.00720994  -0.168253     0.00653729  -0.083913    -0.036715    -0.157646    -0.252048     0.138365    0.0931209   -0.0631098    -0.0501571
  0.263448     0.204141     0.0385305    0.201251     0.0643045   -0.042043    -0.146102    0.0454077    0.0937056    0.0630262    0.157575    -0.0342991  -0.0352044   -0.172597    -0.0102542    0.0744435    0.0456932   -0.0707637   -0.0469218    0.11694      0.0926926   -0.124548    -0.0633252   0.270616    -0.0727975    -0.0302621
 -0.0451814   -0.10189     -0.10412      0.0229397   -0.0217386   -0.00593328   0.0572495   0.0526692    0.0221338    0.0508675   -0.0124259   -0.0237368  -0.0486943   -0.115231    -0.0493961   -0.0520185    0.0586172   -0.114478     0.0942406   -0.0364941   -0.0757785   -0.148815     0.0587209   0.019757    -0.0395806    -0.198114
 -0.188443     0.193933    -0.0173515    0.0674337    0.153685    -0.0425796   -0.0569359  -0.173575    -0.0456963    0.169979    -0.0672037   -0.0785571   0.0729058    0.0113827    0.0208572    0.0941974   -0.0134314   -0.0346512    0.0945905    0.0624891   -0.00410469  -0.0211062    0.0708768  -0.0912525    0.0998417     0.0932071
  0.0918207   -0.0434379   -0.0275227   -0.012632    -0.114501     0.100418    -0.134535    0.140133    -0.0244729    0.0955521    0.001839     0.0915278   0.0352783    0.0440205   -0.0400353   -0.137859     0.124873    -0.066646     0.0273574   -0.0264252    0.0432504   -0.0591641   -0.109198   -0.0439483   -0.0558321    -0.132625
 -0.151015    -0.044728    -0.245496    -0.0156758    0.0207227    0.0187857   -0.168013   -0.0373896   -0.00165931  -0.0407508    0.0647692    0.0731774  -0.0215932   -0.238763    -0.330024     0.100209    -0.182063    -0.128326    -0.107847     0.0308554    0.0693091    0.0415962   -0.0440534   0.0175831   -0.157144      0.0202478
  0.0180486   -0.0458116   -0.0543402   -0.111088    -0.00803216   0.00758639  -0.0262141   0.0655077   -0.150234     0.0382755   -0.115229    -0.0812532   0.00820123   0.0557718   -0.0100831   -0.0318354   -0.0314171    0.103496    -0.04662     -0.0334254    0.0296547   -3.25679e-5   0.0242835  -0.0132214    0.0206939     0.118975[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     14
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.052843
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     11
│     14
│     16
│     22
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.002451
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      7
│      9
│     11
│      ⋮
│     18
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.970520
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     11
│     12
│     14
│     23
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.008040
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     11
│     14
│     16
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.016572
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      7
│      9
│     11
│      ⋮
│     18
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.982310
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     11
│     14
│     16
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.016593
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      4
│     11
│     12
│      ⋮
│     23
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.974125
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      7
│      9
│     11
│      ⋮
│     22
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.999677
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     14
│     16
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.032799
┌ Info: EM with 100000 data points 10 iterations avll -1.032799
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0637732    0.0921303    0.072775      0.0113653   -0.0268909   -0.0564466    0.0680217    0.0824506     0.15169     -0.07176       0.0110885    0.192489     0.128332    -0.0604876   -0.0885323    -0.135931     -0.144169    0.0478145   -0.0101162   -0.143615    -0.0583116    0.0327287   -0.139847    -0.0265808   -0.122976    -0.0464783
 -0.0637074   -0.0287462    0.0383844     0.0499085    0.0357293    0.115941    -0.0667311    0.14857       0.143715     0.00789073   -0.0334889   -0.0566378    0.0151161    0.111019    -0.151595      0.166466      0.112526    0.0907069   -0.174499    -0.0295986    0.0291987   -0.0161856    0.0555841    0.0872208   -0.0208856    0.0419131
  0.0638123    0.021694    -0.0762183    -0.109958     0.0125767    0.122461     0.157568    -0.0283647     0.0291038    0.0671609    -0.0840605   -0.0438826    0.0441871   -0.0130777   -0.0802535    -0.000991317   0.0123017   0.146331     0.0421516    0.109063    -0.0696364   -0.0276151   -0.133919     0.0834176   -0.0696869    0.0679384
  0.00277911  -0.0660941    0.0903504    -0.139442    -0.0826547   -0.143652     0.0503769   -0.162972      0.0678282   -0.0924181    -0.0403147    0.0972211   -0.143298    -0.0755325    0.0509658    -0.106177      0.153096   -0.0857836    0.0210824    0.263119    -0.0464822   -0.0824624   -0.0620597    0.046143     0.0848403    0.0126114
  0.0233889    0.0492801    0.0806199    -0.0648261    0.0445512   -0.0139921   -0.0784979    0.00452207    0.0937665    0.0724023     0.10089      0.0146261   -0.0282617    0.0858831   -0.0766788    -0.0946407     0.0644701   0.0320449   -0.0340162   -0.0506952    0.0544718    0.0126546   -0.0153345    0.0938211    0.131776     0.0505619
  0.0124633   -0.103668    -0.0137264    -0.049392    -0.0152393   -0.0333473    0.00163055  -0.115096      0.1656      -0.117651      0.0828722    0.104083    -0.111213    -0.178606     0.00011788    0.0871825     0.028197   -0.113295     0.0825549    0.0851359    0.08988      0.205523    -0.103465     0.018854     0.0326791   -0.0583649
 -0.0342133    0.0965764   -0.0175594    -0.0337153   -0.117811     0.0136174    0.131239    -0.0321347     0.0229977    0.169961     -0.161625    -0.0561832    0.104223    -0.154438     0.0278474     0.0283025    -0.0972299   0.0227854    0.0566982   -0.0999296   -0.032591    -0.234917    -0.0175988   -0.037148    -0.0668392   -0.0364036
  0.0560107    0.0676675    0.150489      0.0131718    0.00604609  -0.0239727    0.0263917    0.0743649    -0.0618434    0.0538737    -0.19637     -0.289156    -0.118272     0.0767326   -0.105147      0.0870445    -0.0534562   0.0963002    0.049057     0.20365      0.0457834    0.140805    -0.0723021    0.124684    -0.201786     0.0725743
 -0.0324639   -0.0519746   -0.0802945     0.0460566    0.0734335    0.0442469   -0.0466464   -0.0871288    -0.0749507    0.0663589    -0.0162463    0.0251992   -0.0432691    0.0643093   -0.0721314    -0.0908158     0.0571557  -0.0779352    0.0602936   -0.158841    -0.0162271   -0.0687973   -0.0389195   -0.103733    -0.0175765   -0.120794
  0.00811782   0.038863    -0.204909      0.0244023    0.12457      0.0101649   -0.0671128   -0.0451661     0.0696122   -0.027688     -0.00149721  -0.0861245    0.0844106    0.0265559   -0.0151367     0.149063     -0.034008   -0.0912436    0.126493    -0.0500018    0.0710295   -0.0224963    0.0822661    0.0278382    0.0121218   -0.0858861
  0.16522     -0.0556247    0.0362887     0.00943303  -0.135629     0.0670367   -0.0741565   -0.136214     -0.120177    -0.105577     -0.0359658    0.0304343    0.102338     0.0587751   -0.000167553   0.0322639    -0.0718692  -0.0151243   -0.0730097   -0.00855422  -0.155846     0.0496037   -0.242713    -0.00124846  -0.0170439   -0.00842697
 -0.0219575   -0.0931641   -0.0314481     0.0908888    0.0146009   -0.168462    -0.0339072   -0.0457231    -0.151932     0.0662007    -0.160646    -0.0881382    0.0705042   -0.22585      0.139887     -0.070908     -0.0117069  -0.0617343    0.0502898   -0.0104184    0.0444467   -0.218186    -0.0152872    0.0900365    0.127616    -0.0469002
 -0.0282572   -0.177792    -0.00137246    0.0630151    0.0461037    0.101296     0.0820481    0.000228927   0.198115    -0.0452279     0.0554186   -0.125125     0.0316993   -0.0192      -0.116448      0.159491     -0.0268664  -0.210596    -0.0772611   -0.0110775    0.116919     0.155853     0.0557094   -0.131604    -0.0119292   -0.0868236
  0.0646122   -0.0295194    0.0328802    -0.218979    -0.240308     0.118619    -0.0724163   -0.17391       0.166246     0.0242532     0.103453     0.0224643    0.00161498   0.117315    -0.0419479    -0.117174     -0.035165    0.174528     0.00785846  -0.0832974   -0.00781001  -0.0165981    0.209143     0.061469     0.061427     0.0174316
  0.0851793   -0.0250384   -0.0447781     0.0365826    0.0017217    0.168008    -0.00722822  -0.0698177    -0.0827739   -0.0690322    -0.0600177    0.113492    -0.0569808    0.0105048    0.199149     -0.10658      -0.150449    0.0222973    0.181645     0.0335081    0.0239035    0.043201    -0.140791    -0.129087     0.0486664    0.0746038
  0.0255331   -0.15055      0.0356097     0.0919639    0.075658     0.0288495   -0.0277692    0.0755681     0.0369632    0.127104      0.0156118   -0.086672    -0.16052      0.0458159   -0.0839682     0.046352      0.147437    0.0591476   -0.0207819    0.173643     0.098753     0.0988616    0.0508906   -0.0794931   -0.0931084    0.032685
 -0.253105     0.112782    -0.0372094     0.113362     0.0229498   -0.0567052   -0.11094      0.0152676     0.00378038  -0.0407457     0.101789    -0.0278475   -0.219445    -0.0604743   -0.00712844   -0.0942701    -0.0895065  -0.0625214    0.111503    -0.131366     0.0306718   -0.189081     0.192411    -0.0583708   -0.0528049   -0.00148807
 -0.0345571    0.0122018   -0.135023      0.0929112    0.0469027   -0.0345853   -0.0249344   -0.0375906    -0.0644402   -0.181942      0.00219965  -0.00816305   0.163455    -0.134457    -0.0168192     0.197735     -0.175302    0.0275286   -0.14172      0.0555558   -0.246345    -0.0847389   -0.166781     0.0278342    0.0860502   -0.00972847
 -0.02673      0.173874    -0.20803       0.0474871   -0.0745054    0.0503453   -0.102607     0.0459738     0.127624    -0.0113249     0.118109     0.00460756  -0.227398     0.165804    -0.00162914   -0.0433195     0.13871    -0.152773    -0.0819509    0.0702717   -0.15338     -0.10148      0.00482023   0.00134336   0.0795587   -0.0717212
 -0.244326     0.0300439   -0.0209771    -0.0563789    0.0478816    0.0285983   -0.00639682  -0.00349979   -0.046034     0.103193     -0.115908     0.15185     -0.178589     0.1133       0.0611982     0.0760723    -0.0405024  -0.164296     0.012691     0.262828    -0.0291855   -0.105319     0.216483     0.167474    -0.00644901  -0.036273
 -0.0756747   -0.194898     0.0338864     0.0699037    0.150156    -0.119678     0.0350767   -0.17877       0.0262189    0.0600804     0.0744273   -0.0555186   -0.0380086   -0.0380477    0.0711532    -0.0504332    -0.0498185  -0.00491849  -0.0781108    0.166782     0.0337575   -0.167781     0.177966    -0.120573    -0.0681843   -0.0104442
  0.123545    -0.110069    -0.00656878   -0.0631065    0.102788    -0.0835973   -0.0540436   -0.000731814   0.0461616   -0.220238      0.0970303    0.085378    -0.0371429    0.0180859    0.180777     -0.0670337     0.144624   -0.235485    -0.0313089   -0.145944    -0.0768338   -0.138196     0.153238     0.043324    -0.122132    -0.0847373
 -0.0623359   -0.197199    -0.113096      0.0441275   -0.0225352    0.00238692  -0.0224167    0.0572245    -0.0122962    0.000859868  -0.193066    -0.125561    -0.285098    -0.0250394   -0.066432      0.0230125     0.0123187   0.0440075   -0.174997    -0.0388455    0.0291833   -0.0480817    0.168891     0.0851085   -0.0803271    0.132674
 -0.014321     0.168359    -0.0325294     0.0989421   -0.174193    -0.0107927   -0.128676    -0.0700922    -0.0175837    0.0281134    -0.045967    -0.0329275   -0.0799578    0.0115698   -0.0740194    -0.000951917  -0.128036   -0.0563161   -0.0408871    0.0512998    0.0172989    0.0761645    0.0885263   -0.0947861    0.133797    -0.0435016
  0.027526    -0.033724    -0.00948263    0.136995     0.0771204    0.0209224   -0.0202058   -0.157111     -0.0347283    0.111175     -0.148136    -0.13779      0.249193     0.124644    -0.0186969     0.0117091    -0.0357097  -0.141693    -0.100843     0.101346     0.101137    -0.0615959    0.0533881   -0.0819489   -0.0453348   -0.15737
  0.0766895    0.0771993   -0.0490812     0.0193739    0.0946456   -0.0501145   -0.0887613   -0.112869      0.0671402   -0.0555299     0.0164217   -0.101602     0.0444385    0.0711245    0.0554146     0.210056      0.0413591  -0.00514882   0.0813522    0.0861291    0.136353     0.242999     0.0340419   -0.0839304   -0.0107722    0.0627005
  0.154964     0.00658175  -0.208672      0.140327     0.110757     0.0061186   -0.159725     0.0561912     0.00862666  -0.0159557    -0.0610441   -0.0472013   -0.0606168    0.00115902  -0.265781     -0.00656446    0.105038   -0.134751     0.026527    -0.0375293   -0.00544687   0.0438962    0.0470879   -0.020076     0.132286    -0.133019
 -0.094647    -0.0779236   -0.0458519     0.0605184    0.107198     0.117875     0.133273    -0.0635065    -0.0216396    0.240525     -0.0864023   -0.140426     0.0864806    0.0683516   -0.0395583     0.0655848    -0.0647896   0.0527974   -0.200516    -0.0375307    0.179695     0.00417036   0.076692    -0.016571    -0.0498772   -0.108022
 -0.0801168    0.0110581   -0.0914462    -0.0377171    0.0549428    0.124984    -0.0446891    0.159915     -0.0539429   -0.15461      -0.148396     0.218007     0.111768     0.133666     0.150889     -0.0149862     0.0220798   0.12059     -0.173152     0.107414    -0.106785    -0.151675    -0.0486551   -0.217802     0.00856332  -0.137054
 -0.0264353   -0.00823006   0.0360273    -0.0160116    0.0678537   -0.111106     0.0900128    0.132191      0.0274032    0.0106936     0.105467    -0.159114     0.110317     0.173414    -0.105595     -0.104152      0.0649971   0.182158     0.065593    -0.0306139   -0.0893872   -0.0440856    0.0282424   -0.0229436   -0.100074    -0.123462
 -0.025412     0.0608952    0.000208328   0.0847097   -0.0256545    0.258967     0.0204446    0.168792      0.0799012   -0.0765043     0.0376259   -0.0504193    0.0752802    0.208793    -0.187785      0.254066     -0.0540404  -0.0193936    0.0332209   -0.0124522    0.0438993    0.0766188   -0.0813239   -0.0364779    0.112332    -0.158151
 -0.0605114    0.151396     0.051646      0.0655251   -0.00733873  -0.0410853    0.0206911    0.0411311     0.11391      0.0134653    -0.138423    -0.0461623    0.0521679    0.0409393    0.0118574     0.137076      0.0535293   0.140933     0.0888437   -0.0696218   -0.111993    -0.0974903    0.00956669   0.0179611   -0.162603    -0.015115kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4219428144375175
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421962
[ Info: iteration 2, average log likelihood -1.421907
[ Info: iteration 3, average log likelihood -1.421875
[ Info: iteration 4, average log likelihood -1.421844
[ Info: iteration 5, average log likelihood -1.421808
[ Info: iteration 6, average log likelihood -1.421756
[ Info: iteration 7, average log likelihood -1.421659
[ Info: iteration 8, average log likelihood -1.421434
[ Info: iteration 9, average log likelihood -1.420896
[ Info: iteration 10, average log likelihood -1.419824
[ Info: iteration 11, average log likelihood -1.418393
[ Info: iteration 12, average log likelihood -1.417296
[ Info: iteration 13, average log likelihood -1.416801
[ Info: iteration 14, average log likelihood -1.416637
[ Info: iteration 15, average log likelihood -1.416586
[ Info: iteration 16, average log likelihood -1.416569
[ Info: iteration 17, average log likelihood -1.416564
[ Info: iteration 18, average log likelihood -1.416561
[ Info: iteration 19, average log likelihood -1.416560
[ Info: iteration 20, average log likelihood -1.416560
[ Info: iteration 21, average log likelihood -1.416560
[ Info: iteration 22, average log likelihood -1.416560
[ Info: iteration 23, average log likelihood -1.416559
[ Info: iteration 24, average log likelihood -1.416559
[ Info: iteration 25, average log likelihood -1.416559
[ Info: iteration 26, average log likelihood -1.416559
[ Info: iteration 27, average log likelihood -1.416559
[ Info: iteration 28, average log likelihood -1.416559
[ Info: iteration 29, average log likelihood -1.416559
[ Info: iteration 30, average log likelihood -1.416559
[ Info: iteration 31, average log likelihood -1.416559
[ Info: iteration 32, average log likelihood -1.416559
[ Info: iteration 33, average log likelihood -1.416558
[ Info: iteration 34, average log likelihood -1.416558
[ Info: iteration 35, average log likelihood -1.416558
[ Info: iteration 36, average log likelihood -1.416558
[ Info: iteration 37, average log likelihood -1.416558
[ Info: iteration 38, average log likelihood -1.416558
[ Info: iteration 39, average log likelihood -1.416558
[ Info: iteration 40, average log likelihood -1.416558
[ Info: iteration 41, average log likelihood -1.416558
[ Info: iteration 42, average log likelihood -1.416558
[ Info: iteration 43, average log likelihood -1.416558
[ Info: iteration 44, average log likelihood -1.416558
[ Info: iteration 45, average log likelihood -1.416558
[ Info: iteration 46, average log likelihood -1.416558
[ Info: iteration 47, average log likelihood -1.416558
[ Info: iteration 48, average log likelihood -1.416558
[ Info: iteration 49, average log likelihood -1.416558
[ Info: iteration 50, average log likelihood -1.416558
┌ Info: EM with 100000 data points 50 iterations avll -1.416558
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4219623979151175
│     -1.4219065508265123
│      ⋮
└     -1.4165580739834471
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416574
[ Info: iteration 2, average log likelihood -1.416519
[ Info: iteration 3, average log likelihood -1.416483
[ Info: iteration 4, average log likelihood -1.416448
[ Info: iteration 5, average log likelihood -1.416409
[ Info: iteration 6, average log likelihood -1.416364
[ Info: iteration 7, average log likelihood -1.416314
[ Info: iteration 8, average log likelihood -1.416258
[ Info: iteration 9, average log likelihood -1.416198
[ Info: iteration 10, average log likelihood -1.416136
[ Info: iteration 11, average log likelihood -1.416074
[ Info: iteration 12, average log likelihood -1.416015
[ Info: iteration 13, average log likelihood -1.415962
[ Info: iteration 14, average log likelihood -1.415915
[ Info: iteration 15, average log likelihood -1.415876
[ Info: iteration 16, average log likelihood -1.415843
[ Info: iteration 17, average log likelihood -1.415816
[ Info: iteration 18, average log likelihood -1.415792
[ Info: iteration 19, average log likelihood -1.415770
[ Info: iteration 20, average log likelihood -1.415750
[ Info: iteration 21, average log likelihood -1.415730
[ Info: iteration 22, average log likelihood -1.415711
[ Info: iteration 23, average log likelihood -1.415693
[ Info: iteration 24, average log likelihood -1.415674
[ Info: iteration 25, average log likelihood -1.415656
[ Info: iteration 26, average log likelihood -1.415637
[ Info: iteration 27, average log likelihood -1.415618
[ Info: iteration 28, average log likelihood -1.415599
[ Info: iteration 29, average log likelihood -1.415580
[ Info: iteration 30, average log likelihood -1.415561
[ Info: iteration 31, average log likelihood -1.415543
[ Info: iteration 32, average log likelihood -1.415525
[ Info: iteration 33, average log likelihood -1.415509
[ Info: iteration 34, average log likelihood -1.415494
[ Info: iteration 35, average log likelihood -1.415480
[ Info: iteration 36, average log likelihood -1.415468
[ Info: iteration 37, average log likelihood -1.415457
[ Info: iteration 38, average log likelihood -1.415447
[ Info: iteration 39, average log likelihood -1.415439
[ Info: iteration 40, average log likelihood -1.415432
[ Info: iteration 41, average log likelihood -1.415425
[ Info: iteration 42, average log likelihood -1.415420
[ Info: iteration 43, average log likelihood -1.415415
[ Info: iteration 44, average log likelihood -1.415410
[ Info: iteration 45, average log likelihood -1.415407
[ Info: iteration 46, average log likelihood -1.415403
[ Info: iteration 47, average log likelihood -1.415400
[ Info: iteration 48, average log likelihood -1.415398
[ Info: iteration 49, average log likelihood -1.415396
[ Info: iteration 50, average log likelihood -1.415394
┌ Info: EM with 100000 data points 50 iterations avll -1.415394
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4165736302196121
│     -1.4165186315852412
│      ⋮
└     -1.4153935386521366
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415406
[ Info: iteration 2, average log likelihood -1.415351
[ Info: iteration 3, average log likelihood -1.415312
[ Info: iteration 4, average log likelihood -1.415274
[ Info: iteration 5, average log likelihood -1.415232
[ Info: iteration 6, average log likelihood -1.415185
[ Info: iteration 7, average log likelihood -1.415133
[ Info: iteration 8, average log likelihood -1.415079
[ Info: iteration 9, average log likelihood -1.415023
[ Info: iteration 10, average log likelihood -1.414966
[ Info: iteration 11, average log likelihood -1.414911
[ Info: iteration 12, average log likelihood -1.414858
[ Info: iteration 13, average log likelihood -1.414807
[ Info: iteration 14, average log likelihood -1.414760
[ Info: iteration 15, average log likelihood -1.414717
[ Info: iteration 16, average log likelihood -1.414678
[ Info: iteration 17, average log likelihood -1.414643
[ Info: iteration 18, average log likelihood -1.414612
[ Info: iteration 19, average log likelihood -1.414585
[ Info: iteration 20, average log likelihood -1.414561
[ Info: iteration 21, average log likelihood -1.414539
[ Info: iteration 22, average log likelihood -1.414518
[ Info: iteration 23, average log likelihood -1.414499
[ Info: iteration 24, average log likelihood -1.414482
[ Info: iteration 25, average log likelihood -1.414465
[ Info: iteration 26, average log likelihood -1.414449
[ Info: iteration 27, average log likelihood -1.414434
[ Info: iteration 28, average log likelihood -1.414419
[ Info: iteration 29, average log likelihood -1.414405
[ Info: iteration 30, average log likelihood -1.414392
[ Info: iteration 31, average log likelihood -1.414380
[ Info: iteration 32, average log likelihood -1.414368
[ Info: iteration 33, average log likelihood -1.414357
[ Info: iteration 34, average log likelihood -1.414346
[ Info: iteration 35, average log likelihood -1.414336
[ Info: iteration 36, average log likelihood -1.414327
[ Info: iteration 37, average log likelihood -1.414317
[ Info: iteration 38, average log likelihood -1.414309
[ Info: iteration 39, average log likelihood -1.414300
[ Info: iteration 40, average log likelihood -1.414292
[ Info: iteration 41, average log likelihood -1.414285
[ Info: iteration 42, average log likelihood -1.414277
[ Info: iteration 43, average log likelihood -1.414270
[ Info: iteration 44, average log likelihood -1.414263
[ Info: iteration 45, average log likelihood -1.414256
[ Info: iteration 46, average log likelihood -1.414250
[ Info: iteration 47, average log likelihood -1.414243
[ Info: iteration 48, average log likelihood -1.414237
[ Info: iteration 49, average log likelihood -1.414231
[ Info: iteration 50, average log likelihood -1.414225
┌ Info: EM with 100000 data points 50 iterations avll -1.414225
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4154057042704125
│     -1.415350500148232
│      ⋮
└     -1.4142251580852998
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414229
[ Info: iteration 2, average log likelihood -1.414167
[ Info: iteration 3, average log likelihood -1.414112
[ Info: iteration 4, average log likelihood -1.414051
[ Info: iteration 5, average log likelihood -1.413979
[ Info: iteration 6, average log likelihood -1.413893
[ Info: iteration 7, average log likelihood -1.413794
[ Info: iteration 8, average log likelihood -1.413686
[ Info: iteration 9, average log likelihood -1.413574
[ Info: iteration 10, average log likelihood -1.413464
[ Info: iteration 11, average log likelihood -1.413359
[ Info: iteration 12, average log likelihood -1.413263
[ Info: iteration 13, average log likelihood -1.413175
[ Info: iteration 14, average log likelihood -1.413095
[ Info: iteration 15, average log likelihood -1.413023
[ Info: iteration 16, average log likelihood -1.412958
[ Info: iteration 17, average log likelihood -1.412899
[ Info: iteration 18, average log likelihood -1.412845
[ Info: iteration 19, average log likelihood -1.412797
[ Info: iteration 20, average log likelihood -1.412752
[ Info: iteration 21, average log likelihood -1.412712
[ Info: iteration 22, average log likelihood -1.412675
[ Info: iteration 23, average log likelihood -1.412640
[ Info: iteration 24, average log likelihood -1.412608
[ Info: iteration 25, average log likelihood -1.412579
[ Info: iteration 26, average log likelihood -1.412551
[ Info: iteration 27, average log likelihood -1.412525
[ Info: iteration 28, average log likelihood -1.412501
[ Info: iteration 29, average log likelihood -1.412478
[ Info: iteration 30, average log likelihood -1.412456
[ Info: iteration 31, average log likelihood -1.412436
[ Info: iteration 32, average log likelihood -1.412416
[ Info: iteration 33, average log likelihood -1.412398
[ Info: iteration 34, average log likelihood -1.412381
[ Info: iteration 35, average log likelihood -1.412364
[ Info: iteration 36, average log likelihood -1.412348
[ Info: iteration 37, average log likelihood -1.412333
[ Info: iteration 38, average log likelihood -1.412319
[ Info: iteration 39, average log likelihood -1.412306
[ Info: iteration 40, average log likelihood -1.412293
[ Info: iteration 41, average log likelihood -1.412280
[ Info: iteration 42, average log likelihood -1.412269
[ Info: iteration 43, average log likelihood -1.412258
[ Info: iteration 44, average log likelihood -1.412247
[ Info: iteration 45, average log likelihood -1.412237
[ Info: iteration 46, average log likelihood -1.412227
[ Info: iteration 47, average log likelihood -1.412218
[ Info: iteration 48, average log likelihood -1.412209
[ Info: iteration 49, average log likelihood -1.412201
[ Info: iteration 50, average log likelihood -1.412193
┌ Info: EM with 100000 data points 50 iterations avll -1.412193
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4142287591558642
│     -1.4141671585929179
│      ⋮
└     -1.4121926171882826
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412194
[ Info: iteration 2, average log likelihood -1.412127
[ Info: iteration 3, average log likelihood -1.412065
[ Info: iteration 4, average log likelihood -1.411992
[ Info: iteration 5, average log likelihood -1.411900
[ Info: iteration 6, average log likelihood -1.411787
[ Info: iteration 7, average log likelihood -1.411654
[ Info: iteration 8, average log likelihood -1.411506
[ Info: iteration 9, average log likelihood -1.411352
[ Info: iteration 10, average log likelihood -1.411199
[ Info: iteration 11, average log likelihood -1.411055
[ Info: iteration 12, average log likelihood -1.410921
[ Info: iteration 13, average log likelihood -1.410800
[ Info: iteration 14, average log likelihood -1.410690
[ Info: iteration 15, average log likelihood -1.410590
[ Info: iteration 16, average log likelihood -1.410499
[ Info: iteration 17, average log likelihood -1.410415
[ Info: iteration 18, average log likelihood -1.410339
[ Info: iteration 19, average log likelihood -1.410268
[ Info: iteration 20, average log likelihood -1.410202
[ Info: iteration 21, average log likelihood -1.410142
[ Info: iteration 22, average log likelihood -1.410086
[ Info: iteration 23, average log likelihood -1.410035
[ Info: iteration 24, average log likelihood -1.409988
[ Info: iteration 25, average log likelihood -1.409944
[ Info: iteration 26, average log likelihood -1.409903
[ Info: iteration 27, average log likelihood -1.409866
[ Info: iteration 28, average log likelihood -1.409831
[ Info: iteration 29, average log likelihood -1.409799
[ Info: iteration 30, average log likelihood -1.409768
[ Info: iteration 31, average log likelihood -1.409740
[ Info: iteration 32, average log likelihood -1.409713
[ Info: iteration 33, average log likelihood -1.409687
[ Info: iteration 34, average log likelihood -1.409664
[ Info: iteration 35, average log likelihood -1.409641
[ Info: iteration 36, average log likelihood -1.409619
[ Info: iteration 37, average log likelihood -1.409599
[ Info: iteration 38, average log likelihood -1.409579
[ Info: iteration 39, average log likelihood -1.409561
[ Info: iteration 40, average log likelihood -1.409543
[ Info: iteration 41, average log likelihood -1.409526
[ Info: iteration 42, average log likelihood -1.409510
[ Info: iteration 43, average log likelihood -1.409495
[ Info: iteration 44, average log likelihood -1.409480
[ Info: iteration 45, average log likelihood -1.409466
[ Info: iteration 46, average log likelihood -1.409453
[ Info: iteration 47, average log likelihood -1.409440
[ Info: iteration 48, average log likelihood -1.409427
[ Info: iteration 49, average log likelihood -1.409415
[ Info: iteration 50, average log likelihood -1.409404
┌ Info: EM with 100000 data points 50 iterations avll -1.409404
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4121938671540004
│     -1.4121273986802554
│      ⋮
└     -1.409403665408437
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4219428144375175
│     -1.4219623979151175
│     -1.4219065508265123
│     -1.421875086178227
│      ⋮
│     -1.4094272399482228
│     -1.4094152389387522
└     -1.409403665408437
32×26 Array{Float64,2}:
 -0.324457    0.48439     -0.284361    -0.133004   -0.298058     0.678129    0.40379      0.119262    0.442183   -0.153227   -0.440179     0.302682     0.530761     0.266068    0.366185     0.0455739   0.0614142  -0.179664   -0.458351     -0.442068    0.0883042  -0.0671458   -0.564586    -0.239881     0.201934    0.386436
  0.0376023   0.199803     0.937444    -0.0147634   0.170475     0.978483    0.205084     0.200586    1.50038     0.477591    0.496441     0.311268     0.212605     0.890472    0.209221     0.44365     0.107306   -0.282811   -0.868468     -1.02814     0.344372    0.270551     0.00877421  -0.416592     0.0211871  -0.173656
  0.102697    0.149291    -0.697615    -0.172516    0.310412     0.817361   -0.254971     0.0414871   0.473913    0.314912   -0.625446    -0.0857602    0.155319     0.150964    0.116884    -0.0577791  -0.0509032   0.220303    0.618667     -0.14117     0.160389   -0.0145903   -0.600006     0.332986     0.0744946  -0.431835
 -0.151346   -0.0430714    0.505223     0.090598    0.0316772    0.149168   -0.201916     0.157717    0.273459    0.0567973   0.203237     0.0149727   -0.172822    -0.0639738  -0.0126263    0.058722   -0.257517   -0.389864    0.0698222    -0.253194   -0.161521   -0.00514336   0.0232463   -0.00659061   0.071421   -0.180124
  0.044761   -0.110963    -0.191574     0.27757    -0.284117     0.388537   -0.381569     0.106904    0.600115    0.251847    0.27011     -0.459044    -0.29723      0.0831423   0.0141108    0.0112407   0.31876    -0.0667222   0.0610883    -0.185651   -0.300084    0.333277    -0.0230072   -0.739846     0.61442     0.0444307
 -0.0101921  -0.290152    -0.621822     0.140856   -0.0666418    0.388357   -0.690926    -0.275923    0.198489    0.487378   -0.00363128  -0.405966    -0.0290609   -0.0850771  -0.0273311    0.421175   -0.134935    0.138519   -0.451052      0.637168   -0.126821   -0.0774003    0.302388     0.12325      0.577434   -0.236124
 -0.322827    0.694585    -0.355619     0.118158   -0.537658    -0.0956394   0.257541     0.216606    0.184595   -0.370199   -0.391329    -0.405912    -0.144054    -0.257585    0.227672     0.179711    0.394381   -0.572522   -0.326055     -0.0545128   0.435492   -0.168668     0.058952    -0.123315     0.990982    0.0904341
  0.512991    0.541549    -0.508835    -0.693389   -0.240993    -0.554234    0.0661203    0.223915    0.296121   -0.338593    0.263567    -0.663677     0.397066     0.156736   -0.0451029   -0.11        0.549194   -0.279548    0.319235      0.973436    0.352747    0.321956     0.587549     0.153785     1.18708    -0.513795
  0.380522    0.229265     0.276848    -0.193805   -0.262372    -0.162656   -0.219724    -0.0447607   0.186007   -0.369204    0.33054     -0.284856     0.214899    -0.163217   -0.369506    -0.358255   -0.659274    0.214411    0.260205      0.446621   -0.607287   -0.220476    -0.685472    -0.0953697    0.334186   -0.385524
 -0.0602172   0.307695     0.138419    -0.0108976   0.090999    -0.288159    0.527538    -0.106187   -0.381848    0.185638    0.0798679    0.224397    -0.0916178    0.0635865  -0.0691876    0.458215   -0.339578    0.472798    0.000480271  -0.0198056  -0.243273   -0.372044     0.550379    -0.0924049   -0.497764   -0.55319
 -0.0871799  -0.55053     -0.647553     0.216276   -0.18783     -0.217618    0.136464    -0.597911   -0.63462    -0.0652935  -0.507236    -0.139195     0.176664     0.156344   -0.285072     0.545767    0.776066    0.291431    0.0604557    -0.039643    0.430886   -0.332229    -0.0532641    0.546515    -0.096574   -0.0323313
  0.127029   -0.587393    -0.459499     0.214058    0.708924     0.221833    0.027321     0.173369   -0.0467193  -0.365098    0.793357    -0.0373895    0.138108    -0.0452722  -0.135772     0.149743    1.02611     0.145348    0.0608347    -0.239836    0.654296    0.375348    -0.0777086   -0.173695    -0.144768   -0.256793
 -0.591123   -0.213239     0.464022     0.505008    0.0960297    0.204748   -0.289848    -0.162773   -0.0881567   0.121611    0.024167     0.716031    -0.405801     0.0650933  -0.0125689    0.202361    0.0625649   0.253913   -0.670134     -0.946275   -0.248517   -0.228479    -0.605555    -0.194391    -0.84296     0.502537
  0.083562   -0.441962     0.196538     1.16385     0.142772    -0.797923   -0.055806     0.170313   -0.162629    0.322614   -0.165232     0.0344093    0.0835111   -0.530942    0.136103    -0.639887   -0.110203   -0.446034   -0.44586       0.236393   -0.386847   -0.37229      0.344273     0.0564772   -0.18118     0.436404
  0.320432   -0.178773    -0.142785    -0.550872   -0.212382    -0.0222531   0.0430859   -0.144182   -0.311561   -0.0515162  -0.249317    -0.0499046   -0.0942602    0.369136    0.157417    -0.0436754   0.210027    0.354948   -0.0912968     0.777326   -0.15873     0.261459     0.519192    -0.362165    -0.381367    0.879661
  0.703699    0.0423387   -0.450469    -0.0102769   0.165992    -0.0013424  -0.00413014   0.255394    0.015198    0.113275   -0.0736942    0.886286     0.26009      0.684594    0.43024     -0.743344   -0.203843   -0.223659   -0.151968     -0.0874851   0.493545    0.450623     0.0319325   -0.187657    -0.202179    0.739893
 -0.0988152   0.00338942   0.215917    -0.708794    0.0159921    0.128536    0.154855    -0.464908   -0.0242247  -0.143491   -0.0497829   -0.00105611  -0.037429    -0.0102324   0.0660082    0.0262764   0.320329    0.479234   -0.07207      -0.024273    0.442711    0.532268    -0.747457    -0.180891    -0.186566    0.154506
  0.252483   -0.470267     0.177503    -0.158929    0.133119     0.157699   -0.281847    -0.454462   -0.0247791  -0.254541    0.584959     0.135037     0.191141     0.176862   -0.240611     0.330422    0.169752    0.527422    0.043166      0.178269   -0.0595355  -0.105962     0.181163    -0.179476    -0.373267   -0.211168
  0.157125   -0.0714759    0.0244151   -0.461182    0.232429     0.285469    0.22024      0.583638    0.100475    0.0828668   0.400336     0.0333236   -0.00736218   0.2164     -0.33128     -0.117624   -0.30904     0.424093    0.386614     -0.0432167  -0.135564    0.609202     0.219893    -0.077134    -0.114365   -0.439802
  0.146642    0.00988848   0.590064     0.15549     0.639658    -0.16911    -0.00225376   0.424087   -0.126253   -0.289177   -0.0627289    0.129022    -0.16049      0.2906     -0.00778129  -0.242168    0.379022   -0.0859634   0.297713     -0.101934    0.0553171   0.157734     0.114685     0.0463747   -0.81873     0.331385
 -0.0798515   0.0264688    0.0185905    0.0367166   0.293339     0.110996   -0.0390694    0.0651814   0.0396719   0.0780245   0.0254619    0.015075    -0.046269    -0.0506046   0.0308295    0.0363909   0.100696    0.0486832  -0.0636571     0.0326393   0.0440711   0.0338901    0.0465016   -0.313255    -0.0191359  -0.0382156
  0.0623412  -0.0529573   -0.248178    -0.0778232  -0.324054     0.0606168  -0.0628137   -0.163288    0.141467   -0.0540051  -0.153328    -0.155869     0.039695     0.136366   -0.0725545    0.0117402  -0.0580471  -0.110832    0.0363032     0.048205    0.0792231   0.0473875   -0.0201466    0.256035     0.105845    0.0828184
  0.095268   -0.46301     -0.200892     0.553336    0.179563     0.357612   -0.505545    -0.24467     0.148866    0.552765   -0.100453    -0.0268602   -0.229207     0.559377   -0.0905117    0.187011   -0.2109     -0.0184217  -0.0525344    -0.250642   -0.273635   -0.210103     0.090811     0.021761    -0.513857   -0.141577
  0.257113    0.00420007  -0.064834     0.36115     0.207477     0.236409    0.411185     0.0405462  -0.386212    0.0150962  -0.37412      0.3749       0.716542     0.0912604  -0.0469149    0.0816345  -0.290063    0.199264    0.00392125   -0.189165    0.0927706  -0.559274     0.0275465    0.733975    -0.492427   -0.445554
 -0.245042    0.440611     0.383253     0.62739    -0.047815    -0.358646    0.108022    -0.574828    0.101381   -0.179722   -0.254053    -0.181796     0.248384    -0.492637    0.162839     0.164598   -0.220813   -0.414389   -0.355915      0.0965646   0.378462   -0.679899    -0.26117     -0.331791     0.346722   -0.393283
  0.0665777   0.219947    -0.114043    -0.021246   -0.126944    -0.331811    0.312823     0.501081   -0.0358404  -0.217655    0.266302     0.216997    -0.0881182   -0.810884    0.438861    -0.44441    -0.208602   -0.525079    0.127451     -0.0765882   0.478115    0.795893    -0.454628     0.261713     0.172282    0.108832
 -0.0949      0.639919     0.0647183   -0.526025   -0.450039    -0.30289    -0.122764    -0.400235    0.190018    0.288835   -0.102579     0.164756    -0.113801     0.445764    0.360808    -0.108365   -0.431949   -0.16666    -0.0731595     0.105893   -0.452079   -0.286633     0.351914    -0.0352097    0.284335    0.162423
  0.0797676   0.359627     0.146474     0.332673   -0.068749    -0.403856    0.281183     0.569184    0.0151428  -0.0362173   0.157351     0.255756    -0.0913699    0.0229312   0.0459922   -0.10556    -0.0943106  -0.250867    0.127676     -0.262333   -0.378108   -0.557262     0.152278    -0.018744     0.292959   -0.127863
 -0.613493   -0.305652     0.522396     0.128483    0.00459026   0.0182217  -0.204006    -0.0404271   0.149327   -0.0305379   0.119087    -0.326427    -0.562299    -0.556881   -0.362626     0.244286    0.0933567  -0.363569    0.0836238    -0.524728   -0.236509   -0.227772    -0.178605     0.585117     0.184779   -0.486091
 -0.49538    -0.343264     0.00176193   0.0321267  -0.0133096   -0.0782585   0.232529     0.207      -0.387257   -0.146077   -0.306721    -0.296333    -0.157823     0.114616   -0.351674     0.296888    0.32491    -0.497905   -0.194376     -0.113377    0.172167    0.314844     0.941609     0.30977     -0.251285    0.320579
 -0.535377   -0.187835     0.0847512   -0.367985    0.404474    -0.403833    0.059555    -0.445849   -0.460844   -0.370296   -0.645682     0.00818655   0.0848695   -0.348676   -0.337475    -0.293013   -0.586682   -0.181418   -0.145164      0.69916     0.3745     -0.0894652   -0.229051     0.280417    -0.492174    0.0297809
  0.124061    0.00813833  -0.261777     0.127094   -0.0665655   -0.527014    0.311088    -0.160828   -0.457834   -0.133385   -0.424368    -0.358611    -0.120131    -0.502409   -0.058581    -0.0226858   0.0702412   0.33402     0.277701      0.639162    0.0186808  -0.38586      0.0166901    0.154631     0.0119079   0.106113[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409392
[ Info: iteration 2, average log likelihood -1.409382
[ Info: iteration 3, average log likelihood -1.409371
[ Info: iteration 4, average log likelihood -1.409361
[ Info: iteration 5, average log likelihood -1.409351
[ Info: iteration 6, average log likelihood -1.409341
[ Info: iteration 7, average log likelihood -1.409332
[ Info: iteration 8, average log likelihood -1.409323
[ Info: iteration 9, average log likelihood -1.409314
[ Info: iteration 10, average log likelihood -1.409305
┌ Info: EM with 100000 data points 10 iterations avll -1.409305
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.133091e+05
      1       7.095288e+05      -2.037803e+05 |       32
      2       6.921144e+05      -1.741441e+04 |       32
      3       6.860657e+05      -6.048692e+03 |       32
      4       6.831810e+05      -2.884749e+03 |       32
      5       6.813995e+05      -1.781496e+03 |       32
      6       6.801974e+05      -1.202045e+03 |       32
      7       6.792863e+05      -9.111605e+02 |       32
      8       6.785741e+05      -7.121745e+02 |       32
      9       6.780000e+05      -5.741227e+02 |       32
     10       6.775506e+05      -4.493097e+02 |       32
     11       6.772044e+05      -3.462765e+02 |       32
     12       6.769149e+05      -2.894576e+02 |       32
     13       6.766759e+05      -2.390548e+02 |       32
     14       6.764820e+05      -1.938274e+02 |       32
     15       6.763232e+05      -1.588783e+02 |       32
     16       6.761769e+05      -1.462425e+02 |       32
     17       6.760355e+05      -1.414451e+02 |       32
     18       6.759070e+05      -1.284710e+02 |       32
     19       6.757858e+05      -1.211921e+02 |       32
     20       6.756681e+05      -1.176841e+02 |       32
     21       6.755572e+05      -1.108851e+02 |       32
     22       6.754520e+05      -1.052211e+02 |       32
     23       6.753503e+05      -1.016705e+02 |       32
     24       6.752507e+05      -9.960752e+01 |       32
     25       6.751533e+05      -9.738131e+01 |       32
     26       6.750600e+05      -9.332600e+01 |       32
     27       6.749591e+05      -1.009329e+02 |       32
     28       6.748646e+05      -9.448938e+01 |       32
     29       6.747716e+05      -9.297659e+01 |       32
     30       6.746760e+05      -9.562872e+01 |       32
     31       6.745846e+05      -9.140398e+01 |       32
     32       6.744921e+05      -9.251828e+01 |       32
     33       6.743979e+05      -9.421089e+01 |       32
     34       6.743068e+05      -9.111006e+01 |       32
     35       6.742327e+05      -7.408063e+01 |       32
     36       6.741628e+05      -6.992153e+01 |       32
     37       6.740993e+05      -6.343983e+01 |       32
     38       6.740404e+05      -5.886809e+01 |       32
     39       6.739801e+05      -6.031243e+01 |       32
     40       6.739202e+05      -5.991226e+01 |       32
     41       6.738619e+05      -5.832811e+01 |       32
     42       6.737974e+05      -6.451994e+01 |       32
     43       6.737339e+05      -6.349820e+01 |       32
     44       6.736799e+05      -5.394412e+01 |       32
     45       6.736325e+05      -4.745794e+01 |       32
     46       6.735825e+05      -4.995890e+01 |       32
     47       6.735361e+05      -4.644872e+01 |       32
     48       6.734931e+05      -4.298214e+01 |       32
     49       6.734597e+05      -3.334472e+01 |       32
     50       6.734308e+05      -2.890577e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 673430.8296068637)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421136
[ Info: iteration 2, average log likelihood -1.416185
[ Info: iteration 3, average log likelihood -1.414906
[ Info: iteration 4, average log likelihood -1.413983
[ Info: iteration 5, average log likelihood -1.412979
[ Info: iteration 6, average log likelihood -1.411993
[ Info: iteration 7, average log likelihood -1.411266
[ Info: iteration 8, average log likelihood -1.410845
[ Info: iteration 9, average log likelihood -1.410611
[ Info: iteration 10, average log likelihood -1.410464
[ Info: iteration 11, average log likelihood -1.410355
[ Info: iteration 12, average log likelihood -1.410268
[ Info: iteration 13, average log likelihood -1.410193
[ Info: iteration 14, average log likelihood -1.410127
[ Info: iteration 15, average log likelihood -1.410067
[ Info: iteration 16, average log likelihood -1.410013
[ Info: iteration 17, average log likelihood -1.409963
[ Info: iteration 18, average log likelihood -1.409917
[ Info: iteration 19, average log likelihood -1.409873
[ Info: iteration 20, average log likelihood -1.409832
[ Info: iteration 21, average log likelihood -1.409794
[ Info: iteration 22, average log likelihood -1.409757
[ Info: iteration 23, average log likelihood -1.409722
[ Info: iteration 24, average log likelihood -1.409688
[ Info: iteration 25, average log likelihood -1.409656
[ Info: iteration 26, average log likelihood -1.409625
[ Info: iteration 27, average log likelihood -1.409596
[ Info: iteration 28, average log likelihood -1.409567
[ Info: iteration 29, average log likelihood -1.409539
[ Info: iteration 30, average log likelihood -1.409512
[ Info: iteration 31, average log likelihood -1.409486
[ Info: iteration 32, average log likelihood -1.409461
[ Info: iteration 33, average log likelihood -1.409436
[ Info: iteration 34, average log likelihood -1.409412
[ Info: iteration 35, average log likelihood -1.409389
[ Info: iteration 36, average log likelihood -1.409367
[ Info: iteration 37, average log likelihood -1.409346
[ Info: iteration 38, average log likelihood -1.409325
[ Info: iteration 39, average log likelihood -1.409306
[ Info: iteration 40, average log likelihood -1.409287
[ Info: iteration 41, average log likelihood -1.409269
[ Info: iteration 42, average log likelihood -1.409251
[ Info: iteration 43, average log likelihood -1.409235
[ Info: iteration 44, average log likelihood -1.409219
[ Info: iteration 45, average log likelihood -1.409203
[ Info: iteration 46, average log likelihood -1.409189
[ Info: iteration 47, average log likelihood -1.409175
[ Info: iteration 48, average log likelihood -1.409161
[ Info: iteration 49, average log likelihood -1.409149
[ Info: iteration 50, average log likelihood -1.409136
┌ Info: EM with 100000 data points 50 iterations avll -1.409136
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.376301     0.399638      0.24805    -0.235543     0.548887    -0.0996758    0.475145     0.0252322   -0.420808   -0.104759   -0.157305    0.527353     0.456708    -0.0607268   -0.187011    -0.039233    -0.599955     0.224785    0.0473344    0.121709    0.317645   -0.528574     0.214341    0.322152    -0.550211    -0.530027
 -0.171412     0.665023      0.677734   -0.264202    -0.305776    -0.362271    -0.00883118  -0.332973     0.323826   -0.438699    0.0198285  -0.591015     0.26854     -0.605639    -0.131879    -0.26344     -0.619003    -0.255627    0.116461     0.358045   -0.439268   -0.247462    -0.64488    -0.159468     0.704516    -0.3114
  0.16471     -0.530858     -0.0714183   0.0014823    0.338719     0.21623      0.097134     0.303706     0.120215   -0.137549    0.739746   -0.089627     0.0985915   -0.364821    -0.0016097    0.0657482    0.491531     0.134809    0.145311    -0.130558    0.450203    0.875986    -0.0864144  -0.207784     0.044824    -0.219453
  0.107108     0.383327     -0.0441389   0.435417    -0.0772942   -0.250532     0.0704538    0.782373     0.10978     0.149115   -0.135203    0.487063     0.0955246   -0.161903     0.470655    -0.699174    -0.425573    -0.631305    0.0886892   -0.306704    0.120615    0.195219    -0.378435    0.115898     0.296757     0.169364
 -0.231373    -0.217657     -0.569719   -0.56492     -0.112986     0.680384     0.030844    -0.00413312   0.0843586   0.33237    -0.360109   -0.198103     0.129909     0.48665     -0.262019     0.180974     0.106279     0.496488   -0.0954779   -0.201358   -0.010037    0.563964    -0.036034    0.312305    -0.249106    -0.169524
  0.100471    -0.0370847     0.544556   -0.00305326  -0.207629     0.741017    -0.31887      0.151084     0.828482    0.0822623   0.676216   -0.05166      0.33051      0.660842    -0.247506     0.204167    -0.146976    -0.134673   -0.369295    -0.448398   -0.139858    0.370699     0.0688495  -0.625532     0.211499     0.00814766
  0.0202676   -1.01946       0.320842    0.325286     0.486937    -0.151544    -0.649317    -0.417839    -0.106336    0.333049    0.224915    0.0831204   -0.108686    -0.252575    -0.462877    -0.153649    -0.380312     0.176454   -0.014477     0.380511   -0.301405   -0.00892266  -0.276697    0.173645    -0.528017    -0.0537907
 -0.379501    -0.0227668     0.231899   -0.782492    -0.107527    -0.157123     0.203976    -0.226173    -0.334386   -0.608673   -0.200751    0.0138805   -0.0487445   -0.470642     0.105063    -0.288767    -0.00104089  -0.0212542  -0.130402     0.380622    0.516723    0.647655    -0.585374    0.00395938  -0.238687     0.476122
  0.434229     0.589721     -0.52989    -0.616771    -0.242973    -0.395817     0.0474832    0.338021     0.335308   -0.300969    0.159072   -0.657591     0.397108     0.141283    -0.00536344  -0.0467352    0.486914    -0.323212    0.329828     0.910316    0.369915    0.309005     0.557698    0.125704     1.23988     -0.425909
 -0.469442    -0.157708      0.422761    0.481389     0.058501     0.245134    -0.171354    -0.129317    -0.0677551   0.161297   -0.026743    0.665107    -0.309552     0.0682093   -0.0282264    0.144508     0.129787     0.222468   -0.661541    -1.03788    -0.22815    -0.195378    -0.638717   -0.185294    -0.837709     0.496139
 -0.0106128    0.0357099     0.474088    0.105778     0.402295    -0.184714     0.264066     0.423657    -0.102014   -0.614504   -0.175435   -0.0191596    0.0206518    0.253328    -0.181998    -0.186914     0.566663    -0.370356    0.410684    -0.456161    0.233358    0.166434     0.195334    0.294511    -0.744292     0.344061
 -0.077495    -0.138815     -0.126811    0.157429    -0.554721    -0.358195     0.445514    -0.136546    -0.333742    0.145786    0.293419    0.00695538  -0.0991655    0.238094     0.0268156    0.916229     0.197438    -0.144938   -0.254484    -0.57705     0.0751163  -0.0466616    0.997453    0.0634917   -0.208272    -0.190197
  0.852958    -0.241738     -0.621019   -0.130475     0.13121      0.249742    -0.0689611    0.0227573   -0.180115    0.0722558  -0.112568    0.578969     0.220949     0.69442      0.403933    -0.314258     0.0147799    0.183776   -0.0647238    0.317865    0.516038    0.478794     0.211785   -0.314941    -0.295739     0.798972
  0.183372    -0.344276     -0.628985    0.191574    -0.247583     0.320818    -0.819111    -0.207713     0.256552    0.519033    0.120484   -0.441147    -0.102474    -0.119173    -0.0842691    0.33984     -0.209103     0.0472943  -0.328983     0.493169   -0.200005   -0.0905695    0.268423    0.150373     0.809457    -0.244685
  0.00292576  -0.0470184     0.0230281   0.287855    -0.0223584   -0.137812     0.0338702   -0.0306996   -0.103669    0.138831   -0.147093    0.0347405   -0.0959078    0.210712    -0.0365109   -0.00469243  -0.135134    -0.128345   -0.0445872   -0.147674   -0.149259   -0.235018     0.13702     0.179992    -0.177036     0.0614643
 -0.39748      0.548315     -0.46818    -0.0884086   -0.298826     0.632334     0.379296     0.0972001    0.527396   -0.0106152  -0.588678    0.18703      0.40987      0.216316     0.471826     0.104156     0.179751    -0.209025   -0.466908    -0.396282    0.239865   -0.13428     -0.405269   -0.235831     0.474683     0.232036
 -0.153084     0.315335      0.150668   -0.366319    -0.0725867    0.151574    -0.272812     0.103308     0.280184    0.432199    0.257819    0.0967294   -0.609398     0.38637      0.270498    -0.104443    -0.752597     0.359394   -0.0347145    0.420684   -0.604596    0.178992     0.331815   -0.569737     0.0429059   -0.0726848
  0.0589538   -0.526232     -0.128588    0.215558     0.800385     0.527166    -0.278413    -0.142659     0.0768821   0.103801    0.391762    0.310644     0.0171807    0.507198     0.209943     0.368998     0.547334     0.263022    0.0676521   -0.288199    0.271071   -0.309236     0.145427   -0.217416    -0.335985    -0.28749
  0.0776217   -0.495175     -0.308665   -0.0432267   -0.183113    -0.373463     0.140448    -0.0891479   -0.988318   -0.537787    0.0337637  -0.351296    -0.157579    -0.213324    -0.624773     0.211382    -0.0178151    0.337337    0.599963     0.60038    -0.0398115  -0.11158      0.0739525   0.465066    -0.0734052   -0.248842
 -0.42844     -0.245206     -0.276749    0.363026     0.259983     0.0171588    0.053729    -0.0301267   -0.378597    0.0128878  -0.670739   -0.582072    -0.154267    -0.34252     -0.17524      0.0844207    0.233269    -0.260876   -0.247697     0.56037     0.200375    0.00467975   0.471302    0.0256353   -0.145077     0.239985
 -0.244526     0.0624536    -0.329992    0.18524     -0.268692     0.139153    -0.46269      0.0201982    0.563977    0.0813578  -0.0500208  -0.809991    -0.794691     0.0276079   -0.0226882   -0.175295     0.638693    -0.329624    0.125033    -0.242749   -0.237096    0.219634    -0.0613665  -0.533063     0.67906      0.228874
  0.566036     0.311708      0.0795685  -0.193017    -0.330064    -0.868983     0.64755      0.00556489  -0.33       -0.349866    0.167207    0.105789     0.00419191  -0.0605943    0.0486974   -0.327351     0.321421     0.333731   -0.197727     0.364858   -0.426162   -0.203426     0.15229    -0.339813     0.200975     0.090656
 -0.338604     0.24743       0.0780169   0.881255    -0.00639482  -0.15584     -0.174959    -0.450097    -0.0392383  -0.0739215  -0.308177   -0.274394     0.155471    -0.300074     0.00638337   0.482587     0.120525    -0.0593274  -0.678793     0.0976253   0.0396957  -0.88225     -0.295617   -0.170253     0.265093    -0.583091
  0.678014     0.272272     -0.132634   -0.303706    -0.204066    -0.101012     0.243254    -0.149109     0.426493   -0.27322     0.510926    0.4723      -0.132136     0.224891    -0.375562    -0.059367    -0.448067     0.32354     0.585051    -0.649854    0.0463947  -0.0283579   -0.693301    0.0291782    0.0438589   -0.538178
 -0.0163198   -0.110267     -0.16801     0.0990878    0.272772     0.261181    -0.116123     0.0071215    0.133223    0.0291799  -0.10621    -0.0077626    0.0136355   -0.00787178  -0.0719068    0.0279571    0.117729     0.0626933   0.102597    -0.0357758   0.0819899  -0.00862375  -0.225853    0.0273411   -0.00523797  -0.14882
 -0.157002    -0.159278      0.413841    0.646046     0.013318    -1.0132       0.193184     0.215469    -0.196972    0.0807971  -0.0622949   0.275884    -0.107614    -0.27506      0.0674204   -0.548866    -0.264006    -0.560981   -0.467102     0.250656   -0.348589   -0.27232      0.775137   -0.0143644   -0.280607     0.674297
  0.164226    -0.000505065  -0.123322   -0.289367    -0.317195    -0.00672969  -0.312216    -0.762071     0.229197   -0.123006   -0.510015   -0.130161     0.390899     0.530772     0.0588133    0.0820942   -0.103277     0.0118696  -0.138727     0.357828   -0.0412425  -0.512817     0.167381    0.302692    -0.236528     0.479042
 -0.21834      0.293911     -0.126424   -0.0415616   -0.326971    -0.290355     0.224614    -0.143481     0.0753159  -0.0902651  -0.057512   -0.0841752   -0.0807032   -0.390156     0.0942562    0.10678     -0.0877946   -0.322037    0.00141031   0.0597986   0.18077    -0.169871    -0.127261    0.0848524    0.55643     -0.143529
 -0.409086    -0.213119      0.539351    0.0876442    0.0597272    0.360722    -0.133646     0.251847     0.230539    0.309945   -0.0174266  -0.171949    -0.592199    -0.151969    -0.189878     0.244692    -0.0501836   -0.607962    0.173804    -0.94037    -0.364512   -0.304618     0.204901    0.601831     0.117102    -0.59684
  0.206717     0.309532      0.28925    -0.281574     0.68494     -0.270628     0.255793    -0.23796     -0.741718    0.759718   -0.8142     -0.0284265   -0.603363     0.0127914    0.341529     0.476927     0.397563     0.571202    0.159186     0.580151    0.214875    0.187563    -0.137163   -0.0283425   -0.726697     0.0562857
  0.823592     0.13519      -0.212386    0.307963     0.0639791    0.328744     0.0188662    0.279863     0.185011    0.344337   -0.061549   -0.202075     0.514352    -0.0242797   -0.0267518   -0.266662    -0.211408     0.488798    0.623234     0.346716   -0.677106   -0.401959     0.0377073   0.179765    -0.358339    -0.511711
  0.11268     -0.0160572     0.0765779  -0.164819     0.117393     0.18935     -0.167858     0.0239836    0.172933   -0.119754    0.169051   -0.0100645    0.0707025    0.0449146   -0.0509201    0.0488199    0.0825315    0.180295    0.0948028    0.1369      0.0252974   0.123045     0.0208386  -0.210216    -0.0605327   -0.0328183[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409125
[ Info: iteration 2, average log likelihood -1.409113
[ Info: iteration 3, average log likelihood -1.409102
[ Info: iteration 4, average log likelihood -1.409092
[ Info: iteration 5, average log likelihood -1.409082
[ Info: iteration 6, average log likelihood -1.409072
[ Info: iteration 7, average log likelihood -1.409063
[ Info: iteration 8, average log likelihood -1.409054
[ Info: iteration 9, average log likelihood -1.409046
[ Info: iteration 10, average log likelihood -1.409037
┌ Info: EM with 100000 data points 10 iterations avll -1.409037
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
