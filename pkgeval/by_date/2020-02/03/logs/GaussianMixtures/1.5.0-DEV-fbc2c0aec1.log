Julia Version 1.5.0-DEV.221
Commit fbc2c0aec1 (2020-02-01 18:55 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed DataAPI ──────────── v1.1.0
  Installed GaussianMixtures ─── v0.3.0
  Installed Rmath ────────────── v0.6.0
  Installed ScikitLearnBase ──── v0.5.0
  Installed OrderedCollections ─ v1.1.0
  Installed Parameters ───────── v0.12.0
  Installed DataStructures ───── v0.17.9
  Installed BinaryProvider ───── v0.5.8
  Installed SortingAlgorithms ── v0.3.1
  Installed URIParser ────────── v0.4.0
  Installed Arpack_jll ───────── v3.5.0+2
  Installed Blosc ────────────── v0.5.1
  Installed HDF5 ─────────────── v0.12.5
  Installed QuadGK ───────────── v2.3.1
  Installed FillArrays ───────── v0.8.4
  Installed StatsBase ────────── v0.32.0
  Installed Arpack ───────────── v0.4.0
  Installed PDMats ───────────── v0.9.11
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed JLD ──────────────── v0.9.2
  Installed NearestNeighbors ─── v0.4.4
  Installed StatsFuns ────────── v0.9.3
  Installed StaticArrays ─────── v0.12.1
  Installed Compat ───────────── v2.2.0
  Installed Clustering ───────── v0.13.3
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed LegacyStrings ────── v0.4.1
  Installed CMake ────────────── v1.1.2
  Installed Missings ─────────── v0.4.3
  Installed Distances ────────── v0.8.2
  Installed BinDeps ──────────── v1.0.0
  Installed FileIO ───────────── v1.2.1
  Installed CMakeWrapper ─────── v0.2.3
  Installed SpecialFunctions ─── v0.9.0
  Installed Distributions ────── v0.22.4
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                                                                                                    0.3%##                                                                         3.8%######                                                                     9.0%###########                                                               15.3%#################                                                         24.6%#######################                                                   32.1%############################                                              39.2%#####################################                                     52.2%#################################################                         68.8%##################################################################        91.7%######################################################################## 100.0%
#=#=#                                                                         ##############################                                            42.5%######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_chAt9s/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -2.568386538435965e6, [21168.35000395293, 78831.64999604707], [-20621.898659826504 11061.694033983258 12236.539861065483; 20606.570493250474 -11516.223120758297 -12093.915305571953], [[29019.357056031928 -5179.661231097083 -5546.792807670558; -5179.661231097083 24392.490989542464 3112.3119862129024; -5546.792807670558 3112.3119862129024 24820.5933809059], [70287.3780855396 5337.544933234519 6062.933812577088; 5337.544933234519 75530.55754787376 -3297.4603669570924; 6062.933812577088 -3297.4603669570924 76363.73024806328]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.120227e+03
      1       8.638706e+02      -2.563562e+02 |        7
      2       8.442317e+02      -1.963891e+01 |        2
      3       8.414941e+02      -2.737565e+00 |        0
      4       8.414941e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 841.494134004889)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.084819
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.864254
[ Info: iteration 2, lowerbound -3.755707
[ Info: iteration 3, lowerbound -3.638244
[ Info: iteration 4, lowerbound -3.491452
[ Info: iteration 5, lowerbound -3.335710
[ Info: iteration 6, lowerbound -3.205955
[ Info: iteration 7, lowerbound -3.127953
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -3.081028
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -3.034208
[ Info: iteration 10, lowerbound -2.982342
[ Info: iteration 11, lowerbound -2.931527
[ Info: iteration 12, lowerbound -2.882614
[ Info: iteration 13, lowerbound -2.843301
[ Info: iteration 14, lowerbound -2.818768
[ Info: iteration 15, lowerbound -2.810214
[ Info: dropping number of Gaussions to 3
[ Info: iteration 16, lowerbound -2.803284
[ Info: iteration 17, lowerbound -2.795075
[ Info: iteration 18, lowerbound -2.788778
[ Info: iteration 19, lowerbound -2.779858
[ Info: iteration 20, lowerbound -2.767150
[ Info: iteration 21, lowerbound -2.749269
[ Info: iteration 22, lowerbound -2.724825
[ Info: iteration 23, lowerbound -2.692842
[ Info: iteration 24, lowerbound -2.653291
[ Info: iteration 25, lowerbound -2.607526
[ Info: iteration 26, lowerbound -2.558307
[ Info: iteration 27, lowerbound -2.509218
[ Info: iteration 28, lowerbound -2.463486
[ Info: iteration 29, lowerbound -2.422808
[ Info: iteration 30, lowerbound -2.387050
[ Info: iteration 31, lowerbound -2.355396
[ Info: iteration 32, lowerbound -2.328806
[ Info: iteration 33, lowerbound -2.311538
[ Info: iteration 34, lowerbound -2.307766
[ Info: dropping number of Gaussions to 2
[ Info: iteration 35, lowerbound -2.302917
[ Info: iteration 36, lowerbound -2.299259
[ Info: iteration 37, lowerbound -2.299256
[ Info: iteration 38, lowerbound -2.299254
[ Info: iteration 39, lowerbound -2.299254
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Mon Feb  3 19:15:30 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Mon Feb  3 19:15:39 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Mon Feb  3 19:15:41 2020: EM with 272 data points 0 iterations avll -2.084819
5.8 data points per parameter
, Mon Feb  3 19:15:43 2020: GMM converted to Variational GMM
, Mon Feb  3 19:15:52 2020: iteration 1, lowerbound -3.864254
, Mon Feb  3 19:15:52 2020: iteration 2, lowerbound -3.755707
, Mon Feb  3 19:15:52 2020: iteration 3, lowerbound -3.638244
, Mon Feb  3 19:15:52 2020: iteration 4, lowerbound -3.491452
, Mon Feb  3 19:15:52 2020: iteration 5, lowerbound -3.335710
, Mon Feb  3 19:15:52 2020: iteration 6, lowerbound -3.205955
, Mon Feb  3 19:15:52 2020: iteration 7, lowerbound -3.127953
, Mon Feb  3 19:15:53 2020: dropping number of Gaussions to 6
, Mon Feb  3 19:15:53 2020: iteration 8, lowerbound -3.081028
, Mon Feb  3 19:15:53 2020: dropping number of Gaussions to 4
, Mon Feb  3 19:15:53 2020: iteration 9, lowerbound -3.034208
, Mon Feb  3 19:15:53 2020: iteration 10, lowerbound -2.982342
, Mon Feb  3 19:15:53 2020: iteration 11, lowerbound -2.931527
, Mon Feb  3 19:15:53 2020: iteration 12, lowerbound -2.882614
, Mon Feb  3 19:15:53 2020: iteration 13, lowerbound -2.843301
, Mon Feb  3 19:15:53 2020: iteration 14, lowerbound -2.818768
, Mon Feb  3 19:15:53 2020: iteration 15, lowerbound -2.810214
, Mon Feb  3 19:15:53 2020: dropping number of Gaussions to 3
, Mon Feb  3 19:15:53 2020: iteration 16, lowerbound -2.803284
, Mon Feb  3 19:15:53 2020: iteration 17, lowerbound -2.795075
, Mon Feb  3 19:15:53 2020: iteration 18, lowerbound -2.788778
, Mon Feb  3 19:15:53 2020: iteration 19, lowerbound -2.779858
, Mon Feb  3 19:15:53 2020: iteration 20, lowerbound -2.767150
, Mon Feb  3 19:15:53 2020: iteration 21, lowerbound -2.749269
, Mon Feb  3 19:15:53 2020: iteration 22, lowerbound -2.724825
, Mon Feb  3 19:15:53 2020: iteration 23, lowerbound -2.692842
, Mon Feb  3 19:15:53 2020: iteration 24, lowerbound -2.653291
, Mon Feb  3 19:15:53 2020: iteration 25, lowerbound -2.607526
, Mon Feb  3 19:15:53 2020: iteration 26, lowerbound -2.558307
, Mon Feb  3 19:15:53 2020: iteration 27, lowerbound -2.509218
, Mon Feb  3 19:15:53 2020: iteration 28, lowerbound -2.463486
, Mon Feb  3 19:15:53 2020: iteration 29, lowerbound -2.422808
, Mon Feb  3 19:15:53 2020: iteration 30, lowerbound -2.387050
, Mon Feb  3 19:15:53 2020: iteration 31, lowerbound -2.355396
, Mon Feb  3 19:15:53 2020: iteration 32, lowerbound -2.328806
, Mon Feb  3 19:15:53 2020: iteration 33, lowerbound -2.311538
, Mon Feb  3 19:15:53 2020: iteration 34, lowerbound -2.307766
, Mon Feb  3 19:15:53 2020: dropping number of Gaussions to 2
, Mon Feb  3 19:15:53 2020: iteration 35, lowerbound -2.302917
, Mon Feb  3 19:15:53 2020: iteration 36, lowerbound -2.299259
, Mon Feb  3 19:15:53 2020: iteration 37, lowerbound -2.299256
, Mon Feb  3 19:15:53 2020: iteration 38, lowerbound -2.299254
, Mon Feb  3 19:15:53 2020: iteration 39, lowerbound -2.299254
, Mon Feb  3 19:15:53 2020: iteration 40, lowerbound -2.299253
, Mon Feb  3 19:15:53 2020: iteration 41, lowerbound -2.299253
, Mon Feb  3 19:15:53 2020: iteration 42, lowerbound -2.299253
, Mon Feb  3 19:15:53 2020: iteration 43, lowerbound -2.299253
, Mon Feb  3 19:15:53 2020: iteration 44, lowerbound -2.299253
, Mon Feb  3 19:15:53 2020: iteration 45, lowerbound -2.299253
, Mon Feb  3 19:15:53 2020: iteration 46, lowerbound -2.299253
, Mon Feb  3 19:15:53 2020: iteration 47, lowerbound -2.299253
, Mon Feb  3 19:15:53 2020: iteration 48, lowerbound -2.299253
, Mon Feb  3 19:15:53 2020: iteration 49, lowerbound -2.299253
, Mon Feb  3 19:15:53 2020: iteration 50, lowerbound -2.299253
, Mon Feb  3 19:15:53 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.0450923157378, 95.95490768426211]
β = [178.0450923157378, 95.95490768426211]
m = [4.2503007325421835 79.2868669336595; 2.0002292570217173 53.85198716853639]
ν = [180.0450923157378, 97.95490768426211]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155537449657 -0.0076440490518865905; 0.0 0.00858170515288228], [0.375876362447669 -0.008953123842220065; 0.0 0.012748664781221532]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.009438861446798
avll from llpg:  -1.009438861446798
avll direct:     -1.009438861446798
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -1.0068366394010486
avll from llpg:  -1.0068366394010486
avll direct:     -1.0068366394010484
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
  0.12182     -0.149513     0.267462     -0.0548576   -0.0630044   -0.025978    -0.00796192   0.118994     0.0108775     0.170092     -0.0302331    0.023363     0.127151    -0.178201     0.00720152   0.0128607   -0.0739998     0.0631597    0.0850981    0.0164012    0.0671926   -0.0951947   -0.00475759  -0.0597912   -0.0680322    -0.168087
  0.0354942   -0.0179784   -0.0590716    -0.0483938   -7.2024e-5    0.0899818   -0.0952608   -0.0477452   -0.0675384    -0.0254983    -0.0465357   -0.110575     0.0518504    0.149001    -0.0722593    0.0102501   -0.000841369   0.179274    -0.110654     0.0485213   -0.0578192    0.0445565    0.110178     0.129457    -0.00479755   -0.134387
  0.0278521    0.0328433    0.238536     -0.176413    -0.00824513   0.0712735   -0.126482     0.186534    -0.0646716    -0.218631      0.119559    -0.0868037   -0.0187877   -0.101974    -0.0262981   -0.192033    -0.0283892    -0.0605001    0.0893725    0.0122912   -0.227003    -0.0295988    0.0294811    0.00925253  -0.297766      0.173312
  0.0959096    0.0364642   -0.0698329     0.00164391  -0.100057     0.203527     0.0293375    0.0920309    0.0736904    -0.180811     -0.129633    -0.0146854   -0.117113    -0.0851312    0.165831    -0.0477994   -0.188334      0.159277    -0.1466       0.120932    -0.0823944   -0.0653249    0.142128    -0.177429     0.16224       0.171712
  0.107395     0.0505635   -0.00763184   -0.205561    -0.0393189   -0.0063069   -0.0277236    0.188729     0.0617201     0.137546      0.0290272    0.0220346    0.22933     -0.0589272    0.0201093    0.0142971    0.0398458     0.195964    -0.0772727   -0.028373    -0.0338749   -0.134512     0.0193904   -0.118182    -0.138294     -0.162902
 -0.0239746    0.0280532    0.0278798    -0.10312      0.134389     0.0999313    0.0922776    0.11217      0.000111513   0.0930887    -0.08306     -0.00201345  -0.147889    -0.257652     0.0442594   -0.0904764    0.0089161     0.245398    -0.0596597   -0.052177    -0.00183215  -0.00684108  -0.0639685   -0.152628    -0.025464      0.0280555
 -0.113634     0.026269    -0.0215212    -0.0277709   -0.139633     0.0280104    0.151942     0.0204332   -0.124326      0.0115383     0.0999096    0.0313119    0.0322836   -0.0506156   -0.0776391   -0.0679827   -0.115779     -0.0456071    0.0545803    0.116111     0.0594382   -0.0375982   -0.0078892    0.0930677    0.110595      0.0851865
 -0.0460125    0.0220103    0.087022     -0.172823     0.144807     0.00877885   0.120727     0.10897     -0.179405     -0.000205073  -0.0243781   -0.0191614    0.0998838    0.00149849   0.206817     0.152569     0.00328571    0.0632355    0.0771576   -0.0925548    0.0576445   -0.0292312   -0.092671     0.081772    -0.0770028     0.072561
 -0.108834     0.121698    -0.0966542    -0.0504112    0.230948     0.163075    -0.0102377   -0.051838     0.290295      0.0361398    -0.032387    -0.0748681    0.0394334    0.112221     0.145557    -0.0955801    0.0516528     0.0322091    0.0690115    0.0420369   -0.165874     0.109059    -0.104641     0.12498     -0.0631876    -0.0922691
  0.114928     0.0359084   -0.00674351    0.229761    -0.0202054    0.0102933    0.0972692    0.0902306   -0.129556     -0.0641894    -0.00962468  -0.146044    -0.0575636    0.0377975    0.129919    -0.0111149    0.0433685     0.0624145    0.013177    -0.147121    -0.0364917   -0.0997304    0.0262835    0.262113    -0.139514     -0.119032
 -0.0662586    0.0563568   -0.00973968   -0.037309    -0.163086    -0.0567838    0.172818     0.0706173   -0.0568145     0.257933      0.204817    -0.0625471    0.0328845   -0.0353858   -0.00109652   0.0554136    0.0182112     0.189861    -0.0768227   -0.0355737    0.0200922   -0.0203206   -0.00889121   0.178139     0.0536467     0.0378458
 -0.13683      0.0805855    0.102219      0.0181915    0.204344     0.120709    -0.0153332   -0.103667     0.103027      0.0803132     0.0430785    0.0247823   -0.206549     0.0130467   -0.00718328  -0.0527862    0.0669793    -0.0207927    0.155628    -0.0301518   -0.0612628   -0.214184     0.104369    -0.0182493    0.112845     -0.0425548
 -0.214997    -0.108176     0.108609     -0.112017     0.0446793    0.134684     0.0790443    0.0212792    0.0372117    -0.0343553    -0.17631     -0.13242     -0.0149487   -0.00158971  -0.0180505    0.0597245    0.0618602    -0.0290226    0.0467392    0.159925     0.0583725   -0.127705     0.00639146   0.011823     0.0946951     0.0960025
  0.0163984    0.0818546    0.0520599    -0.0424049    0.0594315    0.120069     0.0603302    0.00175849   0.0331777    -0.207631      0.056399     0.0365594   -0.0507046    0.09761      0.0141663    0.0167969   -0.0771927     0.192514     0.209729     0.12666     -0.0232512    0.0789525    0.0622597    0.0432091    0.0539323     0.066435
 -0.0138548    0.0339254   -0.0347204     0.0222722    0.0204734   -0.0138195    0.0363796   -0.163122     0.060451     -0.0605488    -0.12013      0.0513296    0.0318551    0.0281308   -0.00895294   0.0925809   -0.0641713     0.219483    -0.202187    -0.0574349   -0.0108774    0.0384639   -0.0669579   -0.076628    -0.100035      0.01505
  0.141834     0.0347852   -0.0181896     0.0818271   -0.157029     0.0846468    0.0492133    0.22407     -0.208302     -0.0119301    -0.0518154    0.0939362   -0.0962455   -0.0946984   -0.0921984    0.0661658   -0.0928474     0.0314223    0.110103     0.111115    -0.0309066    0.181374     0.0896625   -0.0688589   -0.0529958     0.0984328
 -0.0567206    0.00777134  -0.104631      0.159917    -0.00734955  -0.0377929   -0.106593    -0.0481726   -0.015472      0.0835639     0.012898     0.0890229   -0.080817    -0.0148557    0.161667    -0.0595077    0.0700064    -0.141808     0.0391411   -0.0395844    0.00360511  -0.0567343   -0.137871    -0.105379     0.124483      0.063093
  0.0437712    0.0116427   -0.0816086    -0.0314968   -0.0412882    0.0385815   -0.0141675    0.0404741   -0.00297143    0.114984      0.125679     0.117064    -0.249021     0.0630704    0.103327    -0.00696255  -0.0537716     0.0040042   -0.0408098   -0.121716    -0.0405011   -0.0040403   -0.0913047   -0.11227     -0.26185       0.00551552
  0.0346665    0.039888    -0.0217881     0.0664991    0.0857646    0.0415355    0.214502     0.103588    -0.0233913    -0.103969      0.0247249    0.0808058   -0.0208006   -0.0681095   -0.0145091   -0.0582937    0.108763     -0.0126009    0.0517027    0.184504    -0.0611157   -0.171305    -0.00914851  -0.149245     0.0368697     0.00186318
 -0.152053    -0.0605405   -0.0732103     0.1592      -0.110395     0.117686    -0.0397186   -0.0566647    0.100161      0.175356     -0.12876      0.113903    -0.166087    -0.0740106    0.330496     0.0529555    0.168899     -0.132718     0.173515    -0.0831125   -0.0130305   -0.08599      0.0717194   -0.0054538    0.000139864   0.0405703
  0.0248541   -0.00231516  -0.0351195     0.0838451    0.0303398    0.0120213   -0.0928132   -0.0329943   -0.153036     -0.0415674    -0.0483139   -0.0358476   -0.0570543   -0.0651067   -0.113909    -0.124057    -0.0469275     0.0205828   -0.0255003   -0.0400681   -0.0565884   -0.00596626  -0.0332733   -0.183344    -0.185606      0.158297
 -0.0525759   -0.117798     0.0152545     0.102734    -0.100346     0.147385     0.0145962   -0.224288    -0.000720399   0.0479201     0.0512028   -0.196547     0.135158     0.162396     0.0607781    0.146725    -0.00670964   -0.165046     0.00280613  -0.0693837   -0.0448938   -0.126011    -0.00931768   0.047936    -0.150626     -0.0740417
  0.00451077  -0.0691418   -0.00758557    0.103135    -0.125769     0.0404852    0.0861762   -0.144345    -0.0931286    -0.00575624    0.0796731   -0.0777269   -0.0552579   -0.0707095   -0.174649     0.168446     0.0513818     0.0408963    0.203121     0.0866483    0.0767846    0.0255569    0.141546    -0.157357    -0.0152294    -0.150168
  0.0624377   -0.181723     0.0400869     0.0206505   -0.12072      0.0199938   -0.019729    -0.029628     0.0159159     0.0725762     0.180386     0.241442    -0.00898252   0.188283    -0.09462     -0.0695975    0.0445839     0.0343869    0.229993    -0.119459    -0.0182315    0.0812315    0.160295    -0.153592     0.0293711    -0.0209818
 -0.113245    -0.0159233    0.0289873    -0.0852386   -0.0701575    0.124955     0.010839    -0.0461246   -0.200915     -0.0620419    -0.0747914    0.117596    -0.117113    -0.0340699   -0.0159024    0.0761187    0.126677     -0.117485     0.185266    -0.103732     0.227341     0.13065     -0.026205    -0.0897038   -0.0310603    -0.0313364
  0.0329046   -0.0386747   -0.0156197    -0.0489097   -0.104281     0.0750341   -0.0920305   -0.126127    -0.0857822     0.247603     -0.0922254   -0.119419     0.0191803   -0.110323    -0.0245235    0.0868858   -0.124821     -0.114873    -0.0680862   -0.00662066   0.0625275    0.0944825   -0.0248073   -0.038519     0.108105     -0.0152278
 -0.0497117    0.0635541   -0.0420708     0.0990328    0.0823707   -0.0933107    0.0072904   -0.0956258    0.0244117    -0.112356     -0.0311778    0.0109312    0.0269039    0.219401    -0.083239     0.200455     0.10846      -0.158647     0.124503    -0.0231482    0.246826    -0.0328665    0.0180492    0.0553987    0.260465     -0.000862651
  0.0226003   -0.0445747    0.000663253   0.0844481    0.126666    -0.0225686    0.0210099   -0.0779069    0.0403826    -0.0915919     0.0676904    0.0942074   -0.0962426    0.0918288    0.125253     0.0522842   -0.0965089     0.00738908   0.00872638   0.212178    -0.0407082   -0.304474    -0.0216903    0.00922675   0.10733       0.0345475
 -0.0173591   -0.0733626   -0.0740631     0.15335      0.068406    -0.0345418    0.0406119    0.0125645   -0.0623027     0.111672      0.0635137   -0.00105802   0.0150885    0.0570499    0.0244214   -0.0228999   -0.0556018     0.0430651    0.145652    -0.0190645   -0.125159    -0.100236    -0.0308898    0.115901     0.0378525     0.0867146
  0.127913     0.110344     0.155574      0.235469     0.0250661    0.0290696    0.170564     0.2616       0.0409295    -0.0734122    -0.0292045    0.0743174    0.00417267  -0.143367    -0.0427417   -0.0583545   -0.0244816    -0.0811219   -0.0101102    0.0439881   -0.0561823   -0.0133896   -0.0661554   -0.00771649   0.0153275     0.0966424
 -0.0716137   -0.105917     0.12475       0.171708    -0.141068     0.0875023    0.0139824    0.200484    -0.0958045    -0.0968314     0.0627786   -0.114539    -0.256335    -0.0921751   -0.170528    -0.0589966    0.00370422    0.020041     0.174258     0.0693636    0.146041     0.154338    -0.0675884    0.247337    -0.0149876    -0.0124359
 -0.0486293   -0.222468    -0.0155387     0.0211821   -0.105096    -0.00278851  -0.127688     0.071954     0.239906      0.00515404   -0.00315639   0.111736    -0.0235027    0.0865384   -0.00112539   0.0941471   -0.178498     -0.0196368    0.102616     0.0885429   -0.0115335    0.00802895   0.0857751   -0.0211633    0.0636921     0.00661307kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4023975160156892
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.402458
[ Info: iteration 2, average log likelihood -1.402402
[ Info: iteration 3, average log likelihood -1.402029
[ Info: iteration 4, average log likelihood -1.397517
[ Info: iteration 5, average log likelihood -1.384189
[ Info: iteration 6, average log likelihood -1.376079
[ Info: iteration 7, average log likelihood -1.372918
[ Info: iteration 8, average log likelihood -1.370085
[ Info: iteration 9, average log likelihood -1.367085
[ Info: iteration 10, average log likelihood -1.364794
[ Info: iteration 11, average log likelihood -1.363539
[ Info: iteration 12, average log likelihood -1.362915
[ Info: iteration 13, average log likelihood -1.362585
[ Info: iteration 14, average log likelihood -1.362377
[ Info: iteration 15, average log likelihood -1.362218
[ Info: iteration 16, average log likelihood -1.362077
[ Info: iteration 17, average log likelihood -1.361950
[ Info: iteration 18, average log likelihood -1.361837
[ Info: iteration 19, average log likelihood -1.361743
[ Info: iteration 20, average log likelihood -1.361667
[ Info: iteration 21, average log likelihood -1.361608
[ Info: iteration 22, average log likelihood -1.361562
[ Info: iteration 23, average log likelihood -1.361526
[ Info: iteration 24, average log likelihood -1.361499
[ Info: iteration 25, average log likelihood -1.361477
[ Info: iteration 26, average log likelihood -1.361460
[ Info: iteration 27, average log likelihood -1.361446
[ Info: iteration 28, average log likelihood -1.361435
[ Info: iteration 29, average log likelihood -1.361426
[ Info: iteration 30, average log likelihood -1.361419
[ Info: iteration 31, average log likelihood -1.361414
[ Info: iteration 32, average log likelihood -1.361409
[ Info: iteration 33, average log likelihood -1.361406
[ Info: iteration 34, average log likelihood -1.361403
[ Info: iteration 35, average log likelihood -1.361400
[ Info: iteration 36, average log likelihood -1.361399
[ Info: iteration 37, average log likelihood -1.361397
[ Info: iteration 38, average log likelihood -1.361396
[ Info: iteration 39, average log likelihood -1.361395
[ Info: iteration 40, average log likelihood -1.361394
[ Info: iteration 41, average log likelihood -1.361394
[ Info: iteration 42, average log likelihood -1.361393
[ Info: iteration 43, average log likelihood -1.361393
[ Info: iteration 44, average log likelihood -1.361392
[ Info: iteration 45, average log likelihood -1.361392
[ Info: iteration 46, average log likelihood -1.361392
[ Info: iteration 47, average log likelihood -1.361392
[ Info: iteration 48, average log likelihood -1.361392
[ Info: iteration 49, average log likelihood -1.361391
[ Info: iteration 50, average log likelihood -1.361391
┌ Info: EM with 100000 data points 50 iterations avll -1.361391
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.402457961826485
│     -1.4024023646531165
│      ⋮
└     -1.3613913718609183
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.361497
[ Info: iteration 2, average log likelihood -1.361399
[ Info: iteration 3, average log likelihood -1.361056
[ Info: iteration 4, average log likelihood -1.357548
[ Info: iteration 5, average log likelihood -1.344333
[ Info: iteration 6, average log likelihood -1.332030
[ Info: iteration 7, average log likelihood -1.327226
[ Info: iteration 8, average log likelihood -1.325094
[ Info: iteration 9, average log likelihood -1.323797
[ Info: iteration 10, average log likelihood -1.322840
[ Info: iteration 11, average log likelihood -1.322055
[ Info: iteration 12, average log likelihood -1.321365
[ Info: iteration 13, average log likelihood -1.320747
[ Info: iteration 14, average log likelihood -1.320201
[ Info: iteration 15, average log likelihood -1.319699
[ Info: iteration 16, average log likelihood -1.319200
[ Info: iteration 17, average log likelihood -1.318686
[ Info: iteration 18, average log likelihood -1.318146
[ Info: iteration 19, average log likelihood -1.317619
[ Info: iteration 20, average log likelihood -1.317180
[ Info: iteration 21, average log likelihood -1.316827
[ Info: iteration 22, average log likelihood -1.316533
[ Info: iteration 23, average log likelihood -1.316289
[ Info: iteration 24, average log likelihood -1.316096
[ Info: iteration 25, average log likelihood -1.315947
[ Info: iteration 26, average log likelihood -1.315833
[ Info: iteration 27, average log likelihood -1.315745
[ Info: iteration 28, average log likelihood -1.315679
[ Info: iteration 29, average log likelihood -1.315631
[ Info: iteration 30, average log likelihood -1.315594
[ Info: iteration 31, average log likelihood -1.315566
[ Info: iteration 32, average log likelihood -1.315543
[ Info: iteration 33, average log likelihood -1.315525
[ Info: iteration 34, average log likelihood -1.315510
[ Info: iteration 35, average log likelihood -1.315496
[ Info: iteration 36, average log likelihood -1.315485
[ Info: iteration 37, average log likelihood -1.315474
[ Info: iteration 38, average log likelihood -1.315465
[ Info: iteration 39, average log likelihood -1.315457
[ Info: iteration 40, average log likelihood -1.315449
[ Info: iteration 41, average log likelihood -1.315442
[ Info: iteration 42, average log likelihood -1.315435
[ Info: iteration 43, average log likelihood -1.315429
[ Info: iteration 44, average log likelihood -1.315423
[ Info: iteration 45, average log likelihood -1.315417
[ Info: iteration 46, average log likelihood -1.315411
[ Info: iteration 47, average log likelihood -1.315405
[ Info: iteration 48, average log likelihood -1.315399
[ Info: iteration 49, average log likelihood -1.315394
[ Info: iteration 50, average log likelihood -1.315388
┌ Info: EM with 100000 data points 50 iterations avll -1.315388
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.361496724942887
│     -1.3613992804927753
│      ⋮
└     -1.3153878210510486
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.315530
[ Info: iteration 2, average log likelihood -1.315390
[ Info: iteration 3, average log likelihood -1.315067
[ Info: iteration 4, average log likelihood -1.312183
[ Info: iteration 5, average log likelihood -1.299165
[ Info: iteration 6, average log likelihood -1.280310
[ Info: iteration 7, average log likelihood -1.268209
[ Info: iteration 8, average log likelihood -1.262475
[ Info: iteration 9, average log likelihood -1.259816
[ Info: iteration 10, average log likelihood -1.258249
[ Info: iteration 11, average log likelihood -1.257227
[ Info: iteration 12, average log likelihood -1.256493
[ Info: iteration 13, average log likelihood -1.255879
[ Info: iteration 14, average log likelihood -1.255331
[ Info: iteration 15, average log likelihood -1.254864
[ Info: iteration 16, average log likelihood -1.254474
[ Info: iteration 17, average log likelihood -1.254151
[ Info: iteration 18, average log likelihood -1.253871
[ Info: iteration 19, average log likelihood -1.253611
[ Info: iteration 20, average log likelihood -1.253354
[ Info: iteration 21, average log likelihood -1.253072
[ Info: iteration 22, average log likelihood -1.252774
[ Info: iteration 23, average log likelihood -1.252507
[ Info: iteration 24, average log likelihood -1.252326
[ Info: iteration 25, average log likelihood -1.252215
[ Info: iteration 26, average log likelihood -1.252139
[ Info: iteration 27, average log likelihood -1.252081
[ Info: iteration 28, average log likelihood -1.252035
[ Info: iteration 29, average log likelihood -1.251997
[ Info: iteration 30, average log likelihood -1.251964
[ Info: iteration 31, average log likelihood -1.251934
[ Info: iteration 32, average log likelihood -1.251903
[ Info: iteration 33, average log likelihood -1.251867
[ Info: iteration 34, average log likelihood -1.251822
[ Info: iteration 35, average log likelihood -1.251759
[ Info: iteration 36, average log likelihood -1.251670
[ Info: iteration 37, average log likelihood -1.251542
[ Info: iteration 38, average log likelihood -1.251368
[ Info: iteration 39, average log likelihood -1.251164
[ Info: iteration 40, average log likelihood -1.250972
[ Info: iteration 41, average log likelihood -1.250817
[ Info: iteration 42, average log likelihood -1.250713
[ Info: iteration 43, average log likelihood -1.250651
[ Info: iteration 44, average log likelihood -1.250612
[ Info: iteration 45, average log likelihood -1.250588
[ Info: iteration 46, average log likelihood -1.250573
[ Info: iteration 47, average log likelihood -1.250563
[ Info: iteration 48, average log likelihood -1.250557
[ Info: iteration 49, average log likelihood -1.250553
[ Info: iteration 50, average log likelihood -1.250550
┌ Info: EM with 100000 data points 50 iterations avll -1.250550
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3155300298016748
│     -1.3153899502936888
│      ⋮
└     -1.2505497907215064
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.250744
[ Info: iteration 2, average log likelihood -1.250528
[ Info: iteration 3, average log likelihood -1.249901
[ Info: iteration 4, average log likelihood -1.243729
[ Info: iteration 5, average log likelihood -1.219979
[ Info: iteration 6, average log likelihood -1.190075
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.176349
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.189170
[ Info: iteration 9, average log likelihood -1.183168
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.167433
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.170937
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.181321
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.170986
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.170078
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.166922
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.169372
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.167851
[ Info: iteration 18, average log likelihood -1.164004
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.155292
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.173361
[ Info: iteration 21, average log likelihood -1.167198
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.157020
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.162000
[ Info: iteration 24, average log likelihood -1.173419
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.160397
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.163818
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.162107
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.166549
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.167117
[ Info: iteration 30, average log likelihood -1.163904
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.155233
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.173295
[ Info: iteration 33, average log likelihood -1.167165
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.156971
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.161926
[ Info: iteration 36, average log likelihood -1.173320
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.160314
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.163692
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.161936
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.166348
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.170477
[ Info: iteration 42, average log likelihood -1.163752
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.154987
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.172986
[ Info: iteration 45, average log likelihood -1.170386
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.156636
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.161512
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.173001
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.163546
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.163363
┌ Info: EM with 100000 data points 50 iterations avll -1.163363
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2507436507757428
│     -1.250528476328734
│      ⋮
└     -1.1633627576614822
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.161837
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.154619
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.154721
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     25
│     27
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.132455
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     18
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.087016
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     17
│     26
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.058280
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     18
│     25
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.045671
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.072222
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     18
│     26
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.053982
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     25
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.052209
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.045226
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     18
│     26
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.053217
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     25
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.055472
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     18
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.046287
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     25
│     26
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.037898
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     17
│     18
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.054354
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     25
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.065103
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     26
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.049078
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     18
│     25
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.034660
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     17
│     26
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.062112
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     18
│     25
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.053886
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.047270
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     17
│     18
│     26
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.037313
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     25
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.066192
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.060755
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     18
│     26
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.037662
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     17
│     25
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.038015
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     18
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.059015
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     26
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.062179
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     17
│     18
│     25
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.040109
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.047905
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     26
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.059661
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     18
│     25
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.047265
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     17
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.047045
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     18
│     25
│     26
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.041953
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.067041
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     17
│     18
│     25
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.049491
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     26
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.050556
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     25
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.040827
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     18
│     26
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.052445
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.064074
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     18
│     25
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.044122
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     26
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.042818
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     17
│     18
│     25
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.055432
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.060539
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     26
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.042854
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     18
│     25
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.040394
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     17
│     26
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.063000
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     18
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.057626
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     25
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.045857
┌ Info: EM with 100000 data points 50 iterations avll -1.045857
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1618368775101966
│     -1.1546187240065897
│      ⋮
└     -1.0458572848430203
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4023975160156892
│     -1.402457961826485
│     -1.4024023646531165
│     -1.4020294223091938
│      ⋮
│     -1.0630004394623045
│     -1.0576257461502474
└     -1.0458572848430203
32×26 Array{Float64,2}:
  0.0055905   -0.0754304  -0.062326     0.16433     -0.113402     0.040528     0.0908074    -0.113978   -0.10397     -0.0184964    0.0773731   -0.0798316   -0.0595918   -0.0502396   -0.14096       0.174979     0.052629     0.0521992    0.215618     0.113137     0.0770333    0.023484      0.140174    -0.154714    -0.0152515   -0.148367
 -0.112939    -0.0165817   0.0145755   -0.0649084   -0.0832077    0.147067     0.0090123    -0.0515449  -0.208444    -0.0618077   -0.071442     0.116894    -0.10282     -0.0361084   -0.00340754    0.0755407    0.157134    -0.115268     0.185742    -0.146692     0.223119     0.131641     -0.0202224   -0.101069    -0.0339802   -0.0522773
 -0.0563738   -0.2174      0.00501341   0.0131163   -0.0836361   -0.00963545  -0.120936      0.0473169   0.231745     0.00633654  -0.00311839   0.110598    -0.0226673    0.0917687   -0.000389752   0.0915435   -0.171137    -0.0273144    0.105304     0.0887892   -0.0156459    0.00758265    0.0813229   -0.0325226    0.0492393    0.00685942
  0.0591326   -0.0216867  -0.0286172    0.0249791    0.0679946    0.00117554   0.0205767    -0.018051    0.0213786    0.0149597    0.102756     0.0962569   -0.154034     0.0814981    0.119055      0.0162628   -0.075807     0.0065573   -0.0262779    0.0413228   -0.0414866   -0.150503     -0.0545815   -0.0403495   -0.0711609    0.0424856
  0.112673     0.0357505   0.0224941    0.213233     0.00865538   0.00644785   0.0927947     0.08845    -0.153742    -0.073142    -0.00690663  -0.144417    -0.0590754    0.0462508    0.100303     -0.022403     0.0633047    0.0612835    0.0114465   -0.145408    -0.0164298   -0.0883389     0.0256701    0.274916    -0.14604     -0.167801
 -0.0405327    0.0331113  -0.0163133    0.020418    -0.0239114    0.029854     0.179988      0.0609377  -0.0634791   -0.0370194    0.0859382    0.0543559    0.00992979  -0.068012    -0.0448878    -0.0749548    0.00510968  -0.0269771    0.0649112    0.148987    -0.0274915   -0.113092     -0.012029    -0.0550501    0.0862307    0.0725843
 -0.0308555    0.0609423  -0.0424352    0.0626212    0.0732547   -0.104405    -0.0111258    -0.0959883   0.0175648   -0.10689     -0.0304579   -0.00124359   0.0195288    0.232924     0.0073753     0.193353     0.103303    -0.162437     0.130636    -0.0269837    0.262801    -0.0368831    -0.00283029   0.0507593    0.261457    -0.00714472
 -0.149176     0.0652574   0.106804     0.0194385    0.221244     0.117403    -0.021762     -0.103692    0.0646075    0.0599555    0.0313671    0.0340291   -0.201828     0.0153846    0.0803195    -0.0266931    0.0672131   -0.020086     0.151779    -0.0351669   -0.0613843   -0.212733      0.105245    -0.0854487    0.130131    -0.0748774
  0.10733     -0.0277764   0.105092    -0.142825    -0.0506493   -0.0130687   -0.0342438     0.162833    0.0152235    0.138596     0.00567824   0.02107      0.171538    -0.122921     0.00433086    0.0129805   -0.0037477    0.132117     0.0121555   -0.0210759    0.0170932   -0.128047     -0.0141319   -0.0551874   -0.109428    -0.144642
 -0.03023     -0.0112699  -0.032759     0.0476699   -0.036462    -0.0471589    0.102958      0.0412223  -0.0456789    0.18169      0.128536    -0.0427493    0.0213964    0.00529886   0.0130813     0.00838273   0.0121421    0.104247     0.00738413  -0.0249245   -0.0496358   -0.0236083    -0.0218845    0.151456     0.0397505    0.0462204
 -0.0576458   -0.112947    0.0433368    0.1001      -0.0884534    0.139474     0.0126906    -0.206253   -0.00232397   0.0526218    0.0431254   -0.170995     0.163071     0.13672      0.0592506     0.155889    -0.0318719   -0.132986     0.00177237  -0.0515482   -0.0516637   -0.101801      0.00493755   0.0443741   -0.11609     -0.039537
 -0.0251543    0.0357202   0.0374498   -0.105465     0.134108     0.0982126    0.0904768     0.113978   -0.0134482    0.0922753   -0.0829741    0.0116622   -0.141423    -0.238972     0.0381335    -0.0860213    0.00930338   0.24347     -0.0533606   -0.0881154    0.0452434    0.0141461    -0.0647069   -0.130976    -0.0310828    0.00222197
 -0.223254    -0.146739   -0.0682008    0.0853228    0.0206051    0.0746197   -0.0482571    -0.0131003  -0.161105    -0.0499537   -0.116853    -0.0388705   -0.0436455   -0.233366    -0.136949     -0.159313    -0.0880539    0.139904    -0.00960798  -0.106624    -0.0297496   -0.0261934    -0.0286521   -0.177514    -0.190433     0.163247
  0.200861     0.122389    0.0102883    0.0783809    0.0325586   -0.0411316   -0.131563     -0.0481236  -0.16419     -0.035439     0.03233     -0.0330337   -0.0705804    0.0843604   -0.0968232    -0.0641336   -0.0260875   -0.0509338   -0.0412054    0.00707172  -0.0923488   -0.0184956    -0.046787    -0.176955    -0.174516     0.147477
  0.0417954    0.0226785  -0.18885      0.167738     0.00109818  -0.559831    -0.113171     -0.0340867  -0.00907858   0.0536042    0.185088     0.0659525   -0.0836518    0.0404726    0.173481      0.112604     0.0175136   -0.102492     0.0237466   -0.0353114    0.176453    -0.069963     -0.108233    -0.187666     0.0995107    0.135222
 -0.127305    -0.0170935  -0.0404828    0.151544    -0.0169521    0.489531    -0.100106     -0.0432822  -0.022578     0.124733    -0.13079      0.125279    -0.0787223   -0.0416345    0.165948     -0.220929     0.118356    -0.0763543    0.0434228   -0.0422845   -0.225022    -0.0142465    -0.159661    -0.0462835    0.140287    -0.0444851
 -0.172807    -0.108886    0.120693    -0.141508     0.0590054    0.150512     0.0726726     0.0236412   0.0488461   -0.0788866   -0.159352    -0.159154    -0.0248342   -0.00369958  -0.0342374     0.060441     0.0642933   -0.0427606    0.053166     0.16145      0.064235    -0.128691      0.00568553   0.00298413   0.0982473    0.106153
  0.0314837   -0.0138477  -0.0486809   -0.0790756    0.00345024   0.0595522   -0.100995     -0.0392408  -0.0736      -0.0372093   -0.0968303   -0.150521     0.0472665    0.145574    -0.0689382     0.0102983    0.0069148    0.171767    -0.0906901    0.0510206   -0.0715837    0.0387829     0.119404     0.117491    -0.00969191  -0.133375
 -0.0590252    0.0270707  -0.0191957    0.0174688    0.0220767   -0.00600387   0.0417891    -0.157257    0.0840664   -0.04345     -0.10873      0.0418891    0.0329944    0.0321744   -0.00941969    0.0662687   -0.0745897    0.243919    -0.191237    -0.00318396  -0.0200629    0.045697     -0.0699304   -0.0177559   -0.086466     0.00207401
  0.0418141    0.0702937   0.122304     0.040617     0.0787055    0.0234108    0.126635      0.186416   -0.041285    -0.0294255   -0.0324873    0.0541327    0.0234158   -0.0754615    0.0494699     0.0296188    0.00671185  -0.00858929   0.0111245   -0.00749255  -0.00847012  -0.0245716    -0.0749188    0.0290726   -0.0324097    0.0821703
  0.0818751    0.0452115  -0.0718537    0.00381111  -0.0856577    0.21867      0.0326359     0.0961503   0.0760715   -0.175019    -0.157707    -0.011204    -0.107009    -0.0652432    0.165209     -0.0454447   -0.18178      0.167822    -0.168776     0.132466    -0.0879045   -0.0619731     0.120551    -0.152201     0.20535      0.172789
 -0.053625     0.039858   -0.0545604   -0.0780523    0.0809951    0.11324     -0.0476871    -0.0893718   0.099648     0.144006    -0.0514486   -0.125377    -0.00106457   0.00372237   0.0507101    -0.00454569  -0.0420853   -0.0353058    0.00847983   0.0187097   -0.0545752    0.0912151    -0.062739     0.0325558    0.0497635   -0.0504432
  0.0781968    0.0588212   0.343768    -0.110367    -0.0110882    0.0659477   -0.128971      0.214226   -0.0647234   -0.213445     0.108519    -0.17821      0.0403852   -0.145771     0.00826018   -0.186748    -0.0236649   -0.0708869   -0.679609     0.0350811   -0.21816      0.0114736     0.0556563    0.00587129  -0.291781     0.22234
  0.00475278   0.0039198   0.138792    -0.168204    -0.00202107   0.0742095   -0.11481       0.217495   -0.0659944   -0.236308     0.139205    -0.0461358   -0.0745724   -0.00631005  -0.04586      -0.127308    -0.0252654   -0.0419426    0.786645    -0.0127211   -0.225338    -0.0524348    -0.0163404    0.00925489  -0.298681     0.128841
 -0.0734109   -0.106796    0.0979284    0.176228    -0.1324       0.0918888   -0.000644676   0.222787   -0.107531    -0.0310115    0.107291     0.0316707   -0.256231    -0.102049    -0.180901     -0.00612597   0.00326152   0.0340825    0.202009     0.0647527    0.148359     0.157369     -0.0442292    0.240027     0.0285327   -0.0286481
 -0.0641739   -0.113499    0.152376     0.178367    -0.134755     0.142984     0.0157121     0.222479   -0.116087    -0.133492     0.0522418   -0.242032    -0.254851    -0.0528522   -0.185373     -0.105843     0.0196974    0.0636236    0.0653744    0.0878686    0.136625     0.158941     -0.0634713    0.24112     -0.0231989   -0.0370685
 -0.151679     0.244854    0.131694     0.154707    -0.155819    -0.348342    -0.0679134     0.411112    0.0885191    0.224716    -0.0981071    0.113339    -0.152498    -0.0786578    0.226195      0.087825     0.123955     0.00701848   0.169168    -0.0855621   -0.103635    -0.0289119    -0.0702643    0.0179928    0.037763    -0.0265559
 -0.152649    -0.305572   -0.190517     0.169605    -0.0787302    0.515841    -0.00672879   -0.359126    0.172889     0.161733    -0.149959     0.113423    -0.169763    -0.0723299    0.424777      0.0346693    0.210145    -0.301694     0.171115    -0.0791943    0.0810728   -0.159255      0.218089    -0.0158066   -0.0746673    0.0980217
 -0.0858286   -0.203892    0.0518817   -0.20342      0.0649162    0.145657     0.0827144    -0.0184975   0.0408392   -0.21176      0.0659566    0.111039    -0.0817647    0.139131     0.0324141    -0.0617438   -0.538535     0.104505     0.156543     0.216399    -0.0632049    0.152538     -0.0302834    0.0434536    0.187463     0.0709699
  0.0962221    0.319515    0.0524504   -0.040818     0.0568216    0.107842     0.0421962     0.0333347   0.0303845   -0.192305     0.0465006   -0.00474308  -0.0487317    0.0678034   -0.00331765    0.0699567    0.262285     0.323556     0.266579     0.0879936    0.00810438   0.000532317   0.116195     0.0423185   -0.056639     0.0450722
  0.0619565   -0.203447    0.0264871    0.0673253   -0.114845     0.0137066   -0.0310742     0.0211897   0.0138762    0.0676867    0.187401     0.18896     -0.00174698   0.185911    -0.0942821    -0.0714083    0.043973    -0.0127367    0.227896    -0.126387    -0.016877     0.0803727     0.188275    -0.15252      0.0406116   -0.0288149
  0.138511     0.0387727   0.0112647    0.0735701   -0.166656     0.0910666    0.0522873     0.278155   -0.21689     -0.0129769   -0.0660386    0.120808    -0.109596    -0.103959    -0.0921302     0.0702233   -0.109001     0.012767     0.0892724    0.117508    -0.0388619    0.203804      0.0964066   -0.0685361   -0.0625696    0.102664[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     17
│     18
│     26
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.031986
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│     11
│     17
│     18
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.026695
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     17
│     18
│     26
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.030452
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│     11
│     17
│     18
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.026489
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│     17
│     18
│     25
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.030402
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│     11
│     17
│     18
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.026557
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     17
│     18
│     26
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.030439
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│     11
│     17
│     18
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.026470
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     17
│     18
│     26
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.030427
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│     11
│     17
│     18
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.026467
┌ Info: EM with 100000 data points 10 iterations avll -1.026467
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.386801e+05
      1       6.658227e+05      -1.728573e+05 |       32
      2       6.352791e+05      -3.054366e+04 |       32
      3       6.217661e+05      -1.351302e+04 |       32
      4       6.144287e+05      -7.337325e+03 |       32
      5       6.105347e+05      -3.894041e+03 |       32
      6       6.080919e+05      -2.442748e+03 |       32
      7       6.061118e+05      -1.980156e+03 |       32
      8       6.042477e+05      -1.864107e+03 |       32
      9       6.026666e+05      -1.581048e+03 |       32
     10       6.014719e+05      -1.194713e+03 |       32
     11       6.006702e+05      -8.017718e+02 |       32
     12       6.000807e+05      -5.894174e+02 |       32
     13       5.995370e+05      -5.437090e+02 |       32
     14       5.988688e+05      -6.682058e+02 |       32
     15       5.980957e+05      -7.730989e+02 |       32
     16       5.974392e+05      -6.565117e+02 |       32
     17       5.970601e+05      -3.790943e+02 |       32
     18       5.967295e+05      -3.306005e+02 |       32
     19       5.963082e+05      -4.212796e+02 |       32
     20       5.957815e+05      -5.267243e+02 |       32
     21       5.954956e+05      -2.858951e+02 |       32
     22       5.954043e+05      -9.127297e+01 |       32
     23       5.953691e+05      -3.523492e+01 |       32
     24       5.953513e+05      -1.781293e+01 |       32
     25       5.953372e+05      -1.411958e+01 |       31
     26       5.953236e+05      -1.354630e+01 |       30
     27       5.953074e+05      -1.619458e+01 |       30
     28       5.952923e+05      -1.513146e+01 |       28
     29       5.952780e+05      -1.430662e+01 |       30
     30       5.952623e+05      -1.570547e+01 |       29
     31       5.952468e+05      -1.547773e+01 |       31
     32       5.952270e+05      -1.983522e+01 |       31
     33       5.952010e+05      -2.596779e+01 |       30
     34       5.951641e+05      -3.690637e+01 |       30
     35       5.951167e+05      -4.743877e+01 |       32
     36       5.950728e+05      -4.384366e+01 |       32
     37       5.950317e+05      -4.111745e+01 |       32
     38       5.949918e+05      -3.992859e+01 |       32
     39       5.949554e+05      -3.633534e+01 |       32
     40       5.949220e+05      -3.341888e+01 |       32
     41       5.949007e+05      -2.131461e+01 |       29
     42       5.948879e+05      -1.279110e+01 |       32
     43       5.948758e+05      -1.215854e+01 |       29
     44       5.948647e+05      -1.103207e+01 |       30
     45       5.948561e+05      -8.656155e+00 |       28
     46       5.948494e+05      -6.654994e+00 |       27
     47       5.948441e+05      -5.355519e+00 |       19
     48       5.948386e+05      -5.429186e+00 |       25
     49       5.948325e+05      -6.121250e+00 |       23
     50       5.948252e+05      -7.275996e+00 |       24
K-means terminated without convergence after 50 iterations (objv = 594825.2303741167)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.311934
[ Info: iteration 2, average log likelihood -1.282841
[ Info: iteration 3, average log likelihood -1.251106
[ Info: iteration 4, average log likelihood -1.209768
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.165838
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.143176
[ Info: iteration 7, average log likelihood -1.117763
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     15
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.070989
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     21
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.086782
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.108379
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.093878
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.070231
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     15
│     21
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.081185
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     13
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.087577
[ Info: iteration 15, average log likelihood -1.107893
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     17
│     25
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.047494
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     13
│     20
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.070444
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     12
│     15
│     21
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.070669
[ Info: iteration 19, average log likelihood -1.114081
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     25
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.055259
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     11
│     13
│     17
│     20
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.042884
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     12
│     15
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.082000
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.095554
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.064787
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     13
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.060214
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     15
│     17
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.059681
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.094149
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.076004
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     13
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.067179
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     15
│     17
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.061281
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     11
│     12
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.057860
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.099056
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     13
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.058270
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     20
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.053202
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     11
│     12
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.061534
[ Info: iteration 36, average log likelihood -1.099082
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      8
│     13
│     17
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.036705
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.083318
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     11
│     12
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.079133
[ Info: iteration 40, average log likelihood -1.094411
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     13
│     17
│     27
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.034228
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.092119
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      7
│     11
│     12
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.061944
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.082721
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     13
│     27
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.046525
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.096683
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     12
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.058100
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.059243
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      8
│     13
│     27
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.043006
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.097293
┌ Info: EM with 100000 data points 50 iterations avll -1.097293
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0392027    0.0299167    0.238993    -0.140021    -0.00630932   0.0704282   -0.123611      0.213485    -0.0657014   -0.226887     0.129795    -0.112537    -0.0206056   -0.0728184   -0.0213324   -0.157981    -0.0247024   -0.0557886    0.0946972     0.0129655   -0.222397    -0.0239725    0.0197128     0.0075331   -0.295551    0.173767
 -0.0296841    0.0628785   -0.0424198    0.0637944    0.0742024   -0.10513     -0.00529432   -0.0956992    0.0150069   -0.106277    -0.0302138   -0.00323566   0.0208805    0.238826     0.00323576   0.193814     0.10335     -0.160703     0.129598     -0.0277191    0.261015    -0.0366756    0.000916472   0.0519318    0.260166   -0.00654644
  0.099064    -0.135784     0.259693    -0.0493169   -0.0611373   -0.0217526   -0.00904028    0.11271     -0.00721779   0.172485    -0.030442     0.0200158    0.125627    -0.192731    -0.00925301   0.0148354   -0.0736441    0.0631125    0.0825222     0.0135398    0.101995    -0.0994737   -0.0328927    -0.0586496   -0.0568187  -0.160649
 -0.0316502   -0.120392    -0.0132711    0.0535444   -0.0309325    0.00448995  -0.107557      0.00461217   0.0463372   -0.0165375   -0.0191789    0.0389213   -0.038521     0.0193637   -0.0545682   -0.00417941  -0.119567     0.00714698   0.0470039     0.0243323   -0.0376553   -0.0102056    0.0212617    -0.0976848   -0.0594446   0.0777078
 -0.0339858   -0.118438     0.114237     0.212091    -0.124721     0.11265     -0.00368056    0.247854    -0.107498    -0.0715733    0.142429    -0.235806    -0.183576    -0.0219615   -0.193553    -0.0580797    0.00599766   0.0903495    0.179412      0.0223328    0.0982052    0.161761    -0.0376544     0.135145     0.0216074  -0.063435
 -0.152727     0.0638914    0.10524      0.0214348    0.226146     0.11704     -0.0219158    -0.100685     0.0738518    0.0597695    0.0352556    0.0340727   -0.203261     0.0148531    0.0740229   -0.028497     0.0718049   -0.0197479    0.153545     -0.0358832   -0.0606218   -0.210188     0.100318     -0.0818351    0.127697   -0.0803583
 -0.114276     0.0514347   -0.0221946   -0.0254642   -0.134988     0.0302055    0.157253      0.00665362  -0.121962     0.010611     0.104424     0.0282159    0.0276875   -0.0711076   -0.0797086   -0.106609    -0.118856    -0.0407726    0.0703758     0.113357     0.0500182   -0.0422001   -0.00789727    0.0661937    0.140876    0.132817
 -0.00501911  -0.105742    -0.0440172    0.188137     0.0511819   -0.0315871    0.0277667     0.0291849   -0.0387278    0.0907946    0.0343175   -0.00914678  -0.0513143    0.0295778    0.0120998   -0.00821237  -0.0100673    0.0399324    0.13417      -0.0236313   -0.0943238    0.0920772   -0.0306991     0.145176     0.0279684   0.144467
 -0.0467021    0.00224458  -0.10984      0.157651    -0.0108054   -0.0218199   -0.106985     -0.0332243   -0.0161708    0.0913597    0.0234329    0.0933953   -0.0840802   -0.00341115   0.167118    -0.0524371    0.065339    -0.089321     0.0349007    -0.0404057   -0.0323022   -0.0407338   -0.135926     -0.115511     0.120771    0.0446644
  0.0818036    0.0437456   -0.0680663    0.00467794  -0.0883418    0.217914     0.0306988     0.0930041    0.0820353   -0.169543    -0.163291    -0.00938873  -0.109282    -0.0689645    0.15984     -0.0395466   -0.183477     0.164765    -0.165076      0.130307    -0.0869051   -0.0597494    0.119997     -0.152639     0.202425    0.172973
 -0.168872    -0.102174     0.0935142   -0.125618     0.0520648    0.125788     0.0408982     0.0100038    0.0400651   -0.0630953   -0.161123    -0.122381    -0.0230314   -0.0145069   -0.052035     0.0645826    0.0323552   -0.042964     0.0430912     0.142996     0.0628801   -0.090556     0.00520551    0.0117018    0.0934721   0.0946352
 -0.0426841    0.0243477    0.0563737   -0.22146      0.138138    -0.0094591    0.159415      0.115791    -0.184158     0.0236219   -0.0271788   -0.00948702   0.00633213   0.0237007    0.235945     0.126242     0.0254142    0.0560454    0.120055     -0.0693647    0.0574018   -0.0280201   -0.0908774     0.079632    -0.0856386   0.102429
  0.126516     0.0125259    0.01736      0.0549878   -0.155576     0.0746919    0.0611948     0.372338    -0.267621    -0.00247244  -0.0214544    0.181791    -0.095315    -0.0635105   -0.0905808    0.0682265   -0.124882     0.00522145   0.108412      0.0852644   -0.022262     0.187161     0.115131     -0.072637    -0.091196    0.103452
  0.00350771  -0.073965    -0.0645944    0.152944    -0.113659     0.0393658    0.0817367    -0.106933    -0.103329    -0.0228644    0.0760897   -0.0746635   -0.0515381   -0.0490135   -0.13285      0.173089     0.0504464    0.0523007    0.212635      0.111828     0.0751598    0.0268699    0.136436     -0.152192    -0.0154985  -0.142799
  0.00922241   0.0684851    0.0522527   -0.111733     0.0603926    0.126056     0.0602553     0.00852656   0.035613    -0.201104     0.0559866    0.0493746   -0.0641254    0.101594     0.0127776    0.00617063  -0.12089      0.218133     0.214362      0.148036    -0.0257163    0.0747006    0.0474695     0.0424364    0.0614224   0.0574761
 -0.0906886    0.0344706   -0.0212466   -0.0195738   -0.11628     -0.0585178    0.163162      0.0616002   -0.0767782    0.244867     0.19163     -0.0727721    0.0138317   -0.0217183    0.00463004   0.0266001    0.0287394    0.15033     -0.0477564    -0.0270736   -9.3161e-5   -0.0347901   -0.015432      0.181647     0.0402852   0.0471384
 -0.0612434   -0.11513      0.0218001    0.102713    -0.102824     0.150519     0.0105913    -0.223438     0.0069359    0.0515123    0.0489222   -0.190692     0.164271     0.165337     0.0645397    0.159685    -0.0322284   -0.148641     0.000954884  -0.0488278   -0.0531208   -0.105203     0.00749319    0.0538387   -0.128603   -0.0405206
 -0.0709132    0.0234938   -0.0360914    0.0370195    0.0100073   -0.0293439    0.0429949    -0.169115     0.0890635   -0.0925549   -0.125484     8.67287e-5  -0.00131408   0.00411044  -0.0175531    0.0997593   -0.0513778    0.2453      -0.157493     -0.0194934   -0.0018865    0.0824843   -0.140818     -0.015468    -0.0803751   0.00539038
  0.110357     0.0351429    0.0163011    0.213713     0.00834419   0.00762901   0.0915245     0.0826325   -0.155391    -0.0699104   -0.00493822  -0.146634    -0.0634245    0.0440003    0.0999392   -0.0149404    0.0656245    0.0618905    0.0130457    -0.144466    -0.0211671   -0.0846586    0.026108      0.276652    -0.149173   -0.165846
  0.0567687   -0.0403727   -0.00927145  -0.0669051   -0.0964073    0.0701402   -0.0777078    -0.134357    -0.085174     0.269649    -0.077498    -0.226531     0.00993875  -0.104073    -0.0201753    0.0876568   -0.109607    -0.11272     -0.0568624    -0.00253484   0.0618186    0.0924273   -0.0182069    -0.0831336    0.26285    -0.00908535
  0.0691907    0.0429369    0.0637829    0.0973667    0.0118521    0.0519503    0.025154      0.115062     0.00228543  -0.0557195   -0.0453271    0.00314621   0.00990209   0.00145774  -0.0865703   -0.0346944    0.00662274   0.0458573   -0.0670079     0.0514709   -0.0592863    0.00670939   0.0180877     0.0561192    0.0065764  -0.0152692
 -0.112888    -0.0169351    0.0145004   -0.0654098   -0.0853421    0.147622     0.0116513    -0.054756    -0.209091    -0.0617537   -0.0731555    0.117664    -0.107484    -0.0361962   -0.00518372   0.0712918    0.156936    -0.11537      0.185638     -0.151657     0.224072     0.131906    -0.0209864    -0.100994    -0.0334042  -0.0494408
 -0.0236762    0.0420618    0.0327633   -0.106517     0.132976     0.098627     0.0911637     0.116433    -0.00592737   0.095297    -0.0833228    0.0167477   -0.136882    -0.238754     0.0365693   -0.0858767    0.0158635    0.248644    -0.05454      -0.088241     0.0455443    0.0111576   -0.061356     -0.138797    -0.0332398  -0.00313606
  0.0814782   -0.00348831  -0.0734386   -0.0433635   -0.0333618    0.0335684    0.000665628   0.0522592   -0.00949336   0.118395     0.119461     0.114163    -0.231658     0.0576055    0.106533    -0.00454289  -0.0454696    0.00302944  -0.0385218    -0.140348    -0.0435187    0.00590138  -0.0855364    -0.110477    -0.257515    0.0328354
 -0.0442726    0.0269096    0.0913121   -0.155936     0.144271     0.0269704    0.084603      0.101591    -0.173649    -0.0147535   -0.0242653   -0.0219385    0.0882984   -0.0165553    0.181391     0.14511      0.00511965   0.0549318    0.0405312    -0.0736552    0.0479963   -0.0285113   -0.0667805     0.0742093   -0.0778168   0.0622952
 -0.0233434    0.0356102    0.0535582    0.0225449   -0.0030696    0.327364    -0.0143252    -0.0983451    0.118466     0.173585    -0.0126119    0.330055     0.032138     0.0409902    0.106583    -0.101541    -0.194101     0.246025    -0.151497      0.178931    -0.0744002   -0.0893912    0.595762      0.105213    -0.0937396   0.013765
  0.117444     0.086773    -0.021895    -0.147719    -0.033045    -0.0218149   -0.0474799     0.164658     0.0671587    0.106514     0.0241495    0.00572747   0.20973     -0.0452515    0.0154072    0.00914754   0.0486111    0.164028    -0.06486      -0.0392176   -0.0918912   -0.170578    -0.00905891   -0.0422396   -0.103365   -0.171869
  0.0280802    0.00825254  -0.0160236    0.0631143    0.0678269    0.0224091    0.196612      0.103796    -0.017531    -0.0700739    0.0549738    0.0793752   -0.0140268   -0.0691465   -0.0156859   -0.0434728    0.124537    -0.0198116    0.048324      0.182306    -0.0912445   -0.176431    -0.018803     -0.168441     0.0324714   0.0101163
 -0.118318     0.120657    -0.0962855   -0.100605     0.238773     0.164245    -0.00301749   -0.0496191    0.28452      0.0378684   -0.0412954   -0.0842621   -0.0036688    0.119169     0.137335    -0.0912102    0.0508838    0.0375043    0.0770794     0.046122    -0.181874     0.0861287   -0.102819      0.12472     -0.0751131  -0.0915645
 -0.120772    -0.0647429   -0.0628808    0.160464    -0.108667     0.227737    -0.0370981    -0.121594     0.159104     0.215395    -0.11873      0.103327    -0.158328    -0.0475389    0.313389     0.0579986    0.168026    -0.236756     0.168581     -0.0756556    0.0272378   -0.116203     0.0939409     0.00915042  -0.0385414   0.0758005
  0.0380463   -0.0461842    0.00779635   0.0861027    0.162088    -0.0422762    0.0248831    -0.0755547    0.0558628   -0.0767382    0.0723305    0.0775737   -0.0683992    0.0980901    0.125635     0.0440156   -0.103354     0.00947249  -0.0289279     0.216309    -0.0400495   -0.298351    -0.022125      0.0248541    0.106144    0.0530209
  0.0229656   -0.236856     0.0455844    0.045531    -0.119118    -0.00742009  -0.0459957    -0.0367603    0.0153211    0.0592725    0.141922     0.315411    -0.0625128    0.0825673   -0.0690228   -0.115949     0.0693953   -0.00945368   0.206383     -0.100845    -0.00624057   0.0960512    0.202791     -0.0958131    0.0539273  -0.0440644[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     12
│     17
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.045453
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     11
│     12
│     17
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.996838
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      7
│      8
│     12
│      ⋮
│     27
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.974030
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     11
│     12
│     17
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.032707
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     12
│     17
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.005236
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      7
│      8
│     11
│      ⋮
│     27
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.964068
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     12
│     17
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.039878
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      7
│     11
│     12
│     17
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.985254
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      5
│      7
│      8
│      ⋮
│     27
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.965919
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      7
│     11
│     12
│     17
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.025232
┌ Info: EM with 100000 data points 10 iterations avll -1.025232
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0278682    -0.0534456   -0.012466    -0.0555147    0.0571509    0.017233    -0.174055     0.023773    -0.0282076    0.0349686     0.103896     0.039237    -0.207453    0.0685969    0.144167     -0.164317   -0.105246     0.00156901  -0.0781846   0.0539477    0.0183269   -0.146717     0.07801      0.0485193   -0.090918      0.190329
  0.00282509   -0.0171775   -0.0237028   -0.0740226    0.168005    -0.0212136   -0.105009    -0.0104916   -0.00386001  -0.00839415   -0.03109     -0.036298    -0.0880302  -0.0063193   -0.11844       0.147153    0.0192736   -0.149884     0.0363879  -0.148032    -0.0721116   -0.0367061    0.0440671   -0.0479634   -0.103176     -0.00426022
 -0.00268345    0.0869108    0.0912006    0.0582685   -0.0759597   -0.0683081    0.0413495    0.125702     0.0592291    0.0537627     0.101022    -0.0177004    0.0721735   0.0515958    0.0245873    -0.0779648  -0.0888715   -0.184906    -0.066696    0.0325711   -0.113626     0.0930636    0.0878664   -0.0616385    0.0285761    -0.116161
  0.0826097     0.222167     0.200125     0.141092     0.0406978   -0.109745     0.0315997    0.018523     0.0669402    0.0467858     0.14988      0.00312614   0.0846094  -0.0301811    0.218832     -0.131538    0.16895     -0.0129194    0.153183   -0.0461784    0.214504    -0.0131977   -0.127641     0.0376747   -0.0600922     0.102937
 -0.0175072     0.0140115    0.0640931    0.0970851    0.11548      0.136569     0.0819965    0.109841     0.275914    -0.000541959  -0.160742    -0.12984      0.132106    0.124549     0.146394      0.108105   -0.0746388    0.0855438   -0.121771   -0.0772731   -0.00796794  -0.0427203   -0.0825313    0.0631315   -0.0644463     0.103673
 -0.0208955    -0.00677965   0.00735932   0.0739475    0.0509596   -0.041852     0.0723287   -0.0035158    0.0413461   -0.101874      0.10435      0.0624023    0.131549   -0.0944277    0.168659      0.0304734  -0.161277    -0.134204    -0.0181889  -0.126577    -0.0286469   -0.122949     0.00318596   0.115114     0.0760235    -0.00839828
  0.0307713    -0.00992184   0.1005       0.0815176    0.0595281   -0.00971918  -0.0894711    0.125088    -0.174563    -0.0257499     0.015435     0.02927     -0.0555458   0.0527701    0.00745553   -0.0459179   0.0610819    0.043506     0.27915     0.217486     0.142711     0.045184    -0.123218     0.0910417    0.00952169   -0.0021819
  0.101722      0.00677076   0.136136    -0.0823511    0.0437801    0.0537215    0.0672803   -0.186975     0.0723107    0.0980667    -0.00493773   0.0149868    0.0522399   0.017859    -0.121091      0.0506402  -0.076262    -0.127765    -0.0883535   0.0490161    0.0964899    0.0906083   -0.0560705    0.185846     0.0333502     0.0362725
  0.000846129  -0.0878525   -0.173978     0.0435491    0.0670916   -0.0279439    0.00589772  -0.0259113    0.077282     0.0693626     0.116404     0.0166805    0.10124    -0.028101     0.041583     -0.0496806   0.0758429    0.15498     -0.0790896  -0.159076     0.0400694    0.109667    -0.0681028    0.0248101    0.121205     -0.0547874
 -0.0501021     0.0387054    0.0771409   -0.129967     0.0345208    0.0011576   -0.0729649   -0.0926619   -0.0425367    0.0599783     0.00668722   0.0479698   -0.237171   -0.110515    -0.114211      0.140966    0.0531959   -0.00982584  -0.112553    0.257381    -0.0114658   -0.0829627   -0.171507     0.105583    -0.129957      0.135897
 -0.00378361    0.102129    -0.190976    -0.0670552   -0.110966     0.0393663    0.123684    -0.124934     0.0477921    0.0861756     0.0672714   -0.242187     0.0799212   0.127817     0.0362284     0.0671051   0.0689562   -0.196202     0.167343   -0.135471     0.128331     0.0731532    0.152161     0.0307875   -0.0021913    -0.0344795
  0.00553917   -0.0438082    0.0852441    0.191065     0.0918878   -0.210762     0.121045     0.0534611   -0.249752    -0.130541      0.0509699    0.10553     -0.120811    0.132815     0.0744524     0.0527514   0.0235269    0.0912591    0.0692941   0.129242     0.053592    -0.040781     0.120607     0.124068     0.0283547    -0.162261
  0.129895     -0.310197    -0.0219298    0.0111174    0.0640438   -0.0586463    0.0905668    0.041542     0.0280203    0.1264        0.131031     0.0884061   -0.0214127   0.0999205    0.171226      0.0256518   0.228013     0.109528     0.0738554   0.0357204    0.0804401   -0.0235439    0.0496      -0.191701     0.0163645    -0.168659
  0.0691012    -0.0739621    0.181207     0.0231939   -0.116342    -0.0883525   -0.180111     0.1615       0.174367     0.117974      0.0637173    0.0512554   -0.0671468  -0.0809451    0.0143762    -0.0143811   0.00580706  -0.117755     0.0529188  -0.0308796    0.0920206   -0.172051     0.152645    -0.182282    -0.107792     -0.188891
  0.140701     -0.097452    -0.00886708   0.242789    -0.0178972   -0.126144     0.0828862    0.0498208    0.0724106   -0.179089     -0.100672    -0.133305    -0.136229   -0.040982    -0.0266366     0.0173995   0.0475616    0.0485037   -0.0764121  -0.095605     0.183288    -0.0759942    0.00368182  -0.0197099   -0.0512043    -0.0830163
 -0.140933     -0.0206466    0.0389357   -0.114282     0.0408395   -0.0168979   -0.0128904    0.126001    -0.0495703   -0.0510711    -0.0542461    0.0386825   -0.185257   -0.0810189   -0.0498043    -0.0928774  -0.0812062   -0.00914452   0.0993737   0.0443133   -0.00140693   0.0313999   -0.0296531   -0.0248898    0.000775314   0.015283
  0.0690949    -0.00795676  -0.016528    -0.14809      0.033458    -0.0633365    0.174959    -0.0850104    0.0807665    0.126138      0.0735714   -0.0210915    0.0546814   0.125514    -0.130674      0.148888    0.163332     0.178007     0.101271   -0.0386907   -0.0528673    0.132868     0.0257628   -0.00558605  -0.0440094    -0.2883
  0.0860991     0.12451      0.0765676   -0.126543     0.0147965    0.0158248    0.00955722  -0.167618     0.0432763    0.0317709     0.0178912   -0.166032    -0.0333382   0.122391    -0.152968     -0.0798582   0.124808     0.0306043    0.168082   -0.098047    -0.102898     0.0055478   -0.00895901   0.0242346    0.0456416    -0.0705818
  0.14508      -0.075567     0.081146     0.0163935    0.0915173    0.15514     -0.0166794    0.00424669  -0.137016     0.109168     -0.0637664   -0.0709669    0.0641991  -0.0154119   -0.0766556    -0.0594306   0.174896     0.183491    -0.17464     0.0699487   -0.114149     0.125519    -0.128153    -0.189741    -0.280725     -0.00321251
  0.0160657    -0.0928544    0.0619839   -0.00819768   0.146164     0.207797    -0.0857122   -0.0891502    0.0272752    0.122068     -0.0579025   -0.17129     -0.12375    -0.0975618    0.000713184   0.169922   -0.075787     0.0108282    0.0263404   0.139341     0.0935707    0.0661256    0.191725    -0.235935     0.0350919    -0.237137
  0.107156     -0.109274     0.0392428   -0.0446047    0.0105547    0.0484383    0.00796308  -0.0648848   -0.0914315    0.112428     -0.0379295   -0.0935862   -0.167599   -0.0676048   -0.163351     -0.0287961  -0.0604255    0.0529413    0.054286    0.165162    -0.0203948   -0.0249711    0.130049     0.0323502    0.0168312     0.0138656
  0.0636494     0.0428993    0.0285756   -0.127989    -0.0607829   -0.110063    -0.0199132    0.152749     0.0977255    0.0598291    -0.102608     0.220395     0.0232028   0.0978917   -0.14268       0.139068    0.0902581    0.00566956   0.0199728   0.00518075  -0.0594012    0.0265599   -0.0635297    0.058715    -0.0904155    -0.0096591
 -0.014251      0.140926    -0.0992093   -0.138667    -0.0208916   -0.0944999    0.105057    -0.0271747    0.0433907   -0.130355     -0.0031237   -0.0189253    0.134769   -0.123303    -0.106147      0.161208   -0.0626022   -0.0576852    0.105638    0.00611495   0.0879501   -0.017637    -0.0602306   -0.133921     0.136079     -0.0102022
 -0.0622508    -0.0446622    0.0898351   -0.106655    -0.129301    -0.00481425  -0.189613    -0.0255187   -0.120315     0.109547     -0.10454     -0.15375      0.0634989  -0.0659215    0.0828744     0.051828   -0.275401     0.0532429    0.0942108  -0.0916703    0.0828059   -0.0603025    0.121175    -0.14453      0.123196      0.0890692
 -0.12884       0.0361708   -0.076798    -0.00281871   0.0108004    0.0923352   -0.0659047    0.00695387  -0.142972    -0.0146418     0.0446484    0.0231823   -0.0722569   0.0620469   -0.166348      0.127544    0.070422    -0.141091    -0.0215395  -0.033768    -0.0508051   -0.0178859   -0.0141158    0.0338615    0.151315     -0.153282
 -0.170339     -0.15551     -0.0646822    0.0869538    0.123613     0.11118      0.0356333   -0.221301     0.0582887   -0.0167643     0.246255    -0.125701    -0.0127659  -0.212127     0.0081086    -0.129815   -0.191745     0.0817932   -0.0693354  -0.218295     0.0979626    0.0923232    0.0533505    0.285325     0.0636003     0.0588471
 -0.0531584    -0.138961    -0.0726946   -0.0433319   -0.14507     -0.155089    -0.296636    -0.0582297   -0.182576    -0.0164538    -0.0170664   -0.0521106    0.148592   -0.141248    -0.0194938     0.0757083  -0.254942     0.0160559    0.136753   -0.018678    -0.126005    -0.153702    -0.0903001    0.0255644   -0.0727293     0.124406
  0.0108113     0.0881392   -0.103633     0.176114     0.0768931    0.00958166   0.019647    -0.00142109  -0.114586    -0.0299331    -0.201758     0.0524738   -0.0424577  -0.0397247   -0.14448       0.0950222  -0.00448829  -0.103119    -0.124335   -0.024406    -0.0319204   -0.0234923   -0.209407    -0.0738999   -0.0146504    -0.0431522
 -0.0569583     0.123915    -0.044183    -0.115163    -0.0700909    0.0133046   -0.0283811   -0.0763544   -0.114553    -0.0132095    -0.108981    -0.0883399    0.0224193   0.0267069    0.0373338     0.0188433   0.133726    -0.0500641   -0.0134138  -0.00271008  -0.00602842   0.0183157    0.0094243   -0.0534329    0.0972134     0.0942321
 -0.113362     -0.0291487   -0.118866     0.0079155   -0.00983222  -0.164416    -0.146682     0.0957973    0.0465606   -0.010234     -0.129298     0.00100533   0.094653    0.195276     0.00163547   -0.121072    0.0201462    0.167776     0.0623638  -0.0202822    0.101259    -0.0326811    0.0298413   -0.0643228   -0.0482695    -0.138931
  0.0439707    -0.0794692    0.00539308   0.0870927   -0.0201297    0.0259759    0.151726    -0.10206      0.177124     0.017439      0.00637794  -0.100462    -0.139051   -0.00178254   0.195279      0.0419991   0.0496394   -0.0158679    0.141215    0.115019    -0.0414903    0.00588463   0.0759015    0.00465888   0.0325779     0.0563998
  0.0197738    -0.168402    -0.0406868   -0.0886841   -0.103759    -0.123876    -0.0999683    0.157937    -0.0749164   -0.0498572     0.0146294   -0.0368121    0.213804   -0.0123899    0.0478766     0.0391639   0.0261646    0.0048821   -0.0191842  -0.109957     0.0822296   -0.022209    -0.0507145    0.0760043    0.133207      0.099948kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4233033563962496
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423322
[ Info: iteration 2, average log likelihood -1.423264
[ Info: iteration 3, average log likelihood -1.423226
[ Info: iteration 4, average log likelihood -1.423185
[ Info: iteration 5, average log likelihood -1.423139
[ Info: iteration 6, average log likelihood -1.423083
[ Info: iteration 7, average log likelihood -1.423009
[ Info: iteration 8, average log likelihood -1.422889
[ Info: iteration 9, average log likelihood -1.422647
[ Info: iteration 10, average log likelihood -1.422116
[ Info: iteration 11, average log likelihood -1.421101
[ Info: iteration 12, average log likelihood -1.419724
[ Info: iteration 13, average log likelihood -1.418575
[ Info: iteration 14, average log likelihood -1.417979
[ Info: iteration 15, average log likelihood -1.417751
[ Info: iteration 16, average log likelihood -1.417671
[ Info: iteration 17, average log likelihood -1.417642
[ Info: iteration 18, average log likelihood -1.417632
[ Info: iteration 19, average log likelihood -1.417628
[ Info: iteration 20, average log likelihood -1.417626
[ Info: iteration 21, average log likelihood -1.417626
[ Info: iteration 22, average log likelihood -1.417625
[ Info: iteration 23, average log likelihood -1.417625
[ Info: iteration 24, average log likelihood -1.417625
[ Info: iteration 25, average log likelihood -1.417625
[ Info: iteration 26, average log likelihood -1.417625
[ Info: iteration 27, average log likelihood -1.417625
[ Info: iteration 28, average log likelihood -1.417625
[ Info: iteration 29, average log likelihood -1.417625
[ Info: iteration 30, average log likelihood -1.417625
[ Info: iteration 31, average log likelihood -1.417625
[ Info: iteration 32, average log likelihood -1.417625
[ Info: iteration 33, average log likelihood -1.417625
[ Info: iteration 34, average log likelihood -1.417624
[ Info: iteration 35, average log likelihood -1.417624
[ Info: iteration 36, average log likelihood -1.417624
[ Info: iteration 37, average log likelihood -1.417624
[ Info: iteration 38, average log likelihood -1.417624
[ Info: iteration 39, average log likelihood -1.417624
[ Info: iteration 40, average log likelihood -1.417624
[ Info: iteration 41, average log likelihood -1.417624
[ Info: iteration 42, average log likelihood -1.417624
[ Info: iteration 43, average log likelihood -1.417624
[ Info: iteration 44, average log likelihood -1.417624
[ Info: iteration 45, average log likelihood -1.417624
[ Info: iteration 46, average log likelihood -1.417624
[ Info: iteration 47, average log likelihood -1.417624
[ Info: iteration 48, average log likelihood -1.417624
[ Info: iteration 49, average log likelihood -1.417624
[ Info: iteration 50, average log likelihood -1.417624
┌ Info: EM with 100000 data points 50 iterations avll -1.417624
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4233221481925393
│     -1.4232641445863534
│      ⋮
└     -1.4176242364257754
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417639
[ Info: iteration 2, average log likelihood -1.417573
[ Info: iteration 3, average log likelihood -1.417521
[ Info: iteration 4, average log likelihood -1.417463
[ Info: iteration 5, average log likelihood -1.417395
[ Info: iteration 6, average log likelihood -1.417317
[ Info: iteration 7, average log likelihood -1.417234
[ Info: iteration 8, average log likelihood -1.417151
[ Info: iteration 9, average log likelihood -1.417076
[ Info: iteration 10, average log likelihood -1.417010
[ Info: iteration 11, average log likelihood -1.416956
[ Info: iteration 12, average log likelihood -1.416912
[ Info: iteration 13, average log likelihood -1.416877
[ Info: iteration 14, average log likelihood -1.416849
[ Info: iteration 15, average log likelihood -1.416828
[ Info: iteration 16, average log likelihood -1.416811
[ Info: iteration 17, average log likelihood -1.416797
[ Info: iteration 18, average log likelihood -1.416785
[ Info: iteration 19, average log likelihood -1.416775
[ Info: iteration 20, average log likelihood -1.416766
[ Info: iteration 21, average log likelihood -1.416757
[ Info: iteration 22, average log likelihood -1.416748
[ Info: iteration 23, average log likelihood -1.416740
[ Info: iteration 24, average log likelihood -1.416731
[ Info: iteration 25, average log likelihood -1.416722
[ Info: iteration 26, average log likelihood -1.416713
[ Info: iteration 27, average log likelihood -1.416704
[ Info: iteration 28, average log likelihood -1.416696
[ Info: iteration 29, average log likelihood -1.416687
[ Info: iteration 30, average log likelihood -1.416678
[ Info: iteration 31, average log likelihood -1.416669
[ Info: iteration 32, average log likelihood -1.416661
[ Info: iteration 33, average log likelihood -1.416652
[ Info: iteration 34, average log likelihood -1.416644
[ Info: iteration 35, average log likelihood -1.416636
[ Info: iteration 36, average log likelihood -1.416628
[ Info: iteration 37, average log likelihood -1.416620
[ Info: iteration 38, average log likelihood -1.416613
[ Info: iteration 39, average log likelihood -1.416606
[ Info: iteration 40, average log likelihood -1.416599
[ Info: iteration 41, average log likelihood -1.416592
[ Info: iteration 42, average log likelihood -1.416585
[ Info: iteration 43, average log likelihood -1.416579
[ Info: iteration 44, average log likelihood -1.416573
[ Info: iteration 45, average log likelihood -1.416567
[ Info: iteration 46, average log likelihood -1.416562
[ Info: iteration 47, average log likelihood -1.416556
[ Info: iteration 48, average log likelihood -1.416551
[ Info: iteration 49, average log likelihood -1.416546
[ Info: iteration 50, average log likelihood -1.416541
┌ Info: EM with 100000 data points 50 iterations avll -1.416541
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4176389299184338
│     -1.4175728118390167
│      ⋮
└     -1.4165411679544404
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416547
[ Info: iteration 2, average log likelihood -1.416480
[ Info: iteration 3, average log likelihood -1.416422
[ Info: iteration 4, average log likelihood -1.416354
[ Info: iteration 5, average log likelihood -1.416274
[ Info: iteration 6, average log likelihood -1.416180
[ Info: iteration 7, average log likelihood -1.416077
[ Info: iteration 8, average log likelihood -1.415973
[ Info: iteration 9, average log likelihood -1.415874
[ Info: iteration 10, average log likelihood -1.415786
[ Info: iteration 11, average log likelihood -1.415709
[ Info: iteration 12, average log likelihood -1.415642
[ Info: iteration 13, average log likelihood -1.415586
[ Info: iteration 14, average log likelihood -1.415538
[ Info: iteration 15, average log likelihood -1.415496
[ Info: iteration 16, average log likelihood -1.415461
[ Info: iteration 17, average log likelihood -1.415429
[ Info: iteration 18, average log likelihood -1.415401
[ Info: iteration 19, average log likelihood -1.415375
[ Info: iteration 20, average log likelihood -1.415352
[ Info: iteration 21, average log likelihood -1.415331
[ Info: iteration 22, average log likelihood -1.415311
[ Info: iteration 23, average log likelihood -1.415293
[ Info: iteration 24, average log likelihood -1.415276
[ Info: iteration 25, average log likelihood -1.415259
[ Info: iteration 26, average log likelihood -1.415244
[ Info: iteration 27, average log likelihood -1.415229
[ Info: iteration 28, average log likelihood -1.415215
[ Info: iteration 29, average log likelihood -1.415202
[ Info: iteration 30, average log likelihood -1.415189
[ Info: iteration 31, average log likelihood -1.415177
[ Info: iteration 32, average log likelihood -1.415166
[ Info: iteration 33, average log likelihood -1.415155
[ Info: iteration 34, average log likelihood -1.415144
[ Info: iteration 35, average log likelihood -1.415134
[ Info: iteration 36, average log likelihood -1.415125
[ Info: iteration 37, average log likelihood -1.415116
[ Info: iteration 38, average log likelihood -1.415107
[ Info: iteration 39, average log likelihood -1.415098
[ Info: iteration 40, average log likelihood -1.415090
[ Info: iteration 41, average log likelihood -1.415081
[ Info: iteration 42, average log likelihood -1.415073
[ Info: iteration 43, average log likelihood -1.415065
[ Info: iteration 44, average log likelihood -1.415057
[ Info: iteration 45, average log likelihood -1.415049
[ Info: iteration 46, average log likelihood -1.415041
[ Info: iteration 47, average log likelihood -1.415033
[ Info: iteration 48, average log likelihood -1.415026
[ Info: iteration 49, average log likelihood -1.415018
[ Info: iteration 50, average log likelihood -1.415010
┌ Info: EM with 100000 data points 50 iterations avll -1.415010
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4165471870514972
│     -1.4164804825783424
│      ⋮
└     -1.4150096026076115
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415011
[ Info: iteration 2, average log likelihood -1.414945
[ Info: iteration 3, average log likelihood -1.414886
[ Info: iteration 4, average log likelihood -1.414819
[ Info: iteration 5, average log likelihood -1.414737
[ Info: iteration 6, average log likelihood -1.414637
[ Info: iteration 7, average log likelihood -1.414519
[ Info: iteration 8, average log likelihood -1.414385
[ Info: iteration 9, average log likelihood -1.414243
[ Info: iteration 10, average log likelihood -1.414100
[ Info: iteration 11, average log likelihood -1.413963
[ Info: iteration 12, average log likelihood -1.413836
[ Info: iteration 13, average log likelihood -1.413723
[ Info: iteration 14, average log likelihood -1.413623
[ Info: iteration 15, average log likelihood -1.413536
[ Info: iteration 16, average log likelihood -1.413460
[ Info: iteration 17, average log likelihood -1.413396
[ Info: iteration 18, average log likelihood -1.413340
[ Info: iteration 19, average log likelihood -1.413291
[ Info: iteration 20, average log likelihood -1.413249
[ Info: iteration 21, average log likelihood -1.413211
[ Info: iteration 22, average log likelihood -1.413178
[ Info: iteration 23, average log likelihood -1.413147
[ Info: iteration 24, average log likelihood -1.413120
[ Info: iteration 25, average log likelihood -1.413094
[ Info: iteration 26, average log likelihood -1.413071
[ Info: iteration 27, average log likelihood -1.413049
[ Info: iteration 28, average log likelihood -1.413028
[ Info: iteration 29, average log likelihood -1.413009
[ Info: iteration 30, average log likelihood -1.412991
[ Info: iteration 31, average log likelihood -1.412974
[ Info: iteration 32, average log likelihood -1.412958
[ Info: iteration 33, average log likelihood -1.412943
[ Info: iteration 34, average log likelihood -1.412929
[ Info: iteration 35, average log likelihood -1.412915
[ Info: iteration 36, average log likelihood -1.412902
[ Info: iteration 37, average log likelihood -1.412890
[ Info: iteration 38, average log likelihood -1.412878
[ Info: iteration 39, average log likelihood -1.412866
[ Info: iteration 40, average log likelihood -1.412856
[ Info: iteration 41, average log likelihood -1.412845
[ Info: iteration 42, average log likelihood -1.412835
[ Info: iteration 43, average log likelihood -1.412826
[ Info: iteration 44, average log likelihood -1.412817
[ Info: iteration 45, average log likelihood -1.412808
[ Info: iteration 46, average log likelihood -1.412799
[ Info: iteration 47, average log likelihood -1.412791
[ Info: iteration 48, average log likelihood -1.412783
[ Info: iteration 49, average log likelihood -1.412775
[ Info: iteration 50, average log likelihood -1.412767
┌ Info: EM with 100000 data points 50 iterations avll -1.412767
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.415010867701393
│     -1.4149452659494797
│      ⋮
└     -1.4127673410127384
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412768
[ Info: iteration 2, average log likelihood -1.412703
[ Info: iteration 3, average log likelihood -1.412639
[ Info: iteration 4, average log likelihood -1.412563
[ Info: iteration 5, average log likelihood -1.412467
[ Info: iteration 6, average log likelihood -1.412348
[ Info: iteration 7, average log likelihood -1.412207
[ Info: iteration 8, average log likelihood -1.412050
[ Info: iteration 9, average log likelihood -1.411886
[ Info: iteration 10, average log likelihood -1.411724
[ Info: iteration 11, average log likelihood -1.411569
[ Info: iteration 12, average log likelihood -1.411426
[ Info: iteration 13, average log likelihood -1.411296
[ Info: iteration 14, average log likelihood -1.411179
[ Info: iteration 15, average log likelihood -1.411074
[ Info: iteration 16, average log likelihood -1.410982
[ Info: iteration 17, average log likelihood -1.410900
[ Info: iteration 18, average log likelihood -1.410828
[ Info: iteration 19, average log likelihood -1.410764
[ Info: iteration 20, average log likelihood -1.410707
[ Info: iteration 21, average log likelihood -1.410655
[ Info: iteration 22, average log likelihood -1.410608
[ Info: iteration 23, average log likelihood -1.410565
[ Info: iteration 24, average log likelihood -1.410526
[ Info: iteration 25, average log likelihood -1.410489
[ Info: iteration 26, average log likelihood -1.410455
[ Info: iteration 27, average log likelihood -1.410423
[ Info: iteration 28, average log likelihood -1.410393
[ Info: iteration 29, average log likelihood -1.410365
[ Info: iteration 30, average log likelihood -1.410339
[ Info: iteration 31, average log likelihood -1.410314
[ Info: iteration 32, average log likelihood -1.410290
[ Info: iteration 33, average log likelihood -1.410268
[ Info: iteration 34, average log likelihood -1.410247
[ Info: iteration 35, average log likelihood -1.410227
[ Info: iteration 36, average log likelihood -1.410208
[ Info: iteration 37, average log likelihood -1.410191
[ Info: iteration 38, average log likelihood -1.410174
[ Info: iteration 39, average log likelihood -1.410158
[ Info: iteration 40, average log likelihood -1.410143
[ Info: iteration 41, average log likelihood -1.410128
[ Info: iteration 42, average log likelihood -1.410114
[ Info: iteration 43, average log likelihood -1.410101
[ Info: iteration 44, average log likelihood -1.410088
[ Info: iteration 45, average log likelihood -1.410076
[ Info: iteration 46, average log likelihood -1.410064
[ Info: iteration 47, average log likelihood -1.410052
[ Info: iteration 48, average log likelihood -1.410041
[ Info: iteration 49, average log likelihood -1.410031
[ Info: iteration 50, average log likelihood -1.410020
┌ Info: EM with 100000 data points 50 iterations avll -1.410020
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4127684778531155
│     -1.4127025150436028
│      ⋮
└     -1.4100201217187325
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4233033563962496
│     -1.4233221481925393
│     -1.4232641445863534
│     -1.4232260896944975
│      ⋮
│     -1.4100413501638998
│     -1.4100305802074922
└     -1.4100201217187325
32×26 Array{Float64,2}:
 -0.518138   -0.98822     -0.266443   -0.0627598  -0.619285    -0.387592   -0.995203    0.633248     0.262117     -0.312162    -0.191845   -0.1969      0.110073    0.0691603    0.344149   -0.106018   -0.261444      0.9101     -0.254242    0.0898183  -0.207131    0.196372      0.0538152    0.269553    -0.511365   -0.656218
 -0.333681   -0.652052     0.0575454   0.283427    0.173527     0.346935   -0.101433   -0.123396     0.51349      -0.591774    -0.55379    -0.082485   -0.0395503  -0.771482    -0.249616    0.700532   -0.160045     -0.0187425  -0.121836    0.8899     -0.194362   -0.222518     -0.483851    -0.0543651    0.195346   -0.6344
  0.116065    0.00238705  -0.384814    0.0457735   0.0973087    0.0828968   0.339588    0.687188    -0.274889     -0.383844     0.0899615  -0.324242    0.600004   -0.0502208    0.311597   -0.252584    0.30918       0.458821   -0.0246284  -0.133396   -0.0384165  -0.195153     -0.00976149  -0.17483      0.415475   -0.30402
 -0.375573   -0.285888    -0.0785133   0.145383    0.574419     0.0417267   0.333909    0.362795     0.609801     -0.43735     -0.543628   -0.197161    0.184507    0.303474     0.412189    0.0612352   0.0498916     0.34637    -0.707016   -0.275048   -0.5066      0.109853     -0.302592    -0.406544    -0.272049    0.652611
 -0.15949     0.172144    -0.205665   -0.362431    0.450431    -0.223109   -0.502792    0.474466    -0.196113      0.330143    -0.344652    0.0491307  -0.188421    0.305995    -0.665167   -0.237305   -0.272164      0.0972289  -0.694021   -0.782831    0.570499   -0.283015      0.951475     0.10406      0.010703    0.486253
  0.0827606  -0.0607515   -0.609325   -0.0940064   0.161146    -0.163376    0.149271   -0.141157    -0.276203      0.481026     0.828745    0.203565   -0.126509    0.410218     0.228091   -0.429988    0.171043      0.0451059   0.629499   -0.76443     0.935694    0.205335      0.368252     0.00813047   0.224927   -0.100203
 -0.437082    0.565799    -1.22189    -0.795543   -0.473595    -1.2238      0.12867    -0.188109     0.230395     -0.231445    -0.641053    0.536902    0.598614   -1.1532      -0.692046    0.291456    0.37755       0.297357    0.963128    0.344825    0.587534   -0.631714     -0.427923     1.12242      0.0949296  -1.0115
  0.843577   -0.482483    -0.322061   -0.594203   -0.378956    -0.219447   -0.435688    0.101935     0.179326     -0.45631     -0.067156    0.585829   -0.142714   -0.348243     0.0596702   0.30162     0.275937     -0.114721    0.559478    0.0417074   0.615908   -0.704528      0.00728281   0.299246     0.0825411  -0.924154
  0.123168   -0.451123     0.0556522  -0.349394    0.375245    -0.0266676  -0.0763305  -0.50347      0.320472     -0.332424     0.220745    0.165724   -0.866649   -0.110268     0.356612   -0.185798   -0.0197061    -0.0494198   0.187899   -0.0635679  -0.813555   -0.338983      0.37433      0.00358975  -0.358852    0.022169
  0.0826635  -0.728265     0.736917   -0.293113   -0.289128    -0.124284   -0.230699   -0.205935    -0.0861531    -0.0159187   -0.0359067   0.280101   -0.251983    0.258052    -0.25666    -0.125843   -0.143332     -0.547599    0.673107    0.684284    0.446187    0.186113      0.266989     0.017691    -0.186476    0.36529
 -0.206484    0.594767     0.633538    0.0908178  -0.00893706  -0.618246    0.180311   -0.425005     0.268844      0.109384     0.429451    0.195317   -0.355422    0.455856     0.160839    0.473403   -0.1541       -0.63881     0.284498    0.27712    -0.145667   -0.205134      0.104809     0.352784    -0.169197   -0.0648435
  0.290017    0.832482     0.282815   -0.13284     0.433752     0.428017    0.274865   -0.455621    -0.476276      0.298564     0.0357512   0.364598   -0.0806729   0.144171    -0.0312273   0.0981503  -0.068383     -0.844781    0.33943     0.0994614  -0.0871365  -0.371074      0.0524692   -0.171669     0.183034    0.832185
 -0.10721     0.169935    -0.0232836  -0.738724   -0.554523    -0.220769    0.0482172  -0.0943015    0.03104       0.292852    -0.364984   -0.520724    0.316142    0.281827    -0.179321    0.121606   -0.317589     -0.307812   -0.0774992   0.348394    0.33015     0.322075      0.1934       0.10201     -0.0303679  -0.218762
  0.200376    0.100023     0.127002    0.202285    0.215971    -0.161886   -0.214467   -0.306599    -0.0502917     0.332814     0.282187    0.176822   -0.469991    0.0381851   -0.223171    0.33427     0.104441     -0.0674458  -0.0493883   0.0409137  -0.183041   -0.000831139  -0.252855     0.213959    -0.369526    0.0101924
 -0.198556   -0.058762     0.352212   -0.207368   -0.260209     0.421216    0.243496   -0.0681257    0.116557     -0.220472     0.214113    0.458439   -0.0818026  -0.642888     0.14331    -0.491075   -0.261478     -0.857972    0.0864312  -0.581101    0.366123   -0.495432     -0.171293     0.104518     0.665202   -0.758579
  0.0705077   0.0832003    0.52193     0.470877   -0.161426     0.617112   -0.184152   -0.607954    -0.304314      0.101573    -0.187146    0.0375406  -0.094911   -0.792236     0.203458   -0.547734   -0.430405      0.310486    0.380137   -0.172755    0.296983    0.199569      0.388581    -0.287101     0.521178    0.660063
 -0.218093    0.039867    -0.569395   -0.636989    0.403227    -0.541346    0.0440524   0.531766     0.443938     -0.0822771   -0.0393023   0.109634    0.0217937   0.391988    -0.310516    0.387378    0.173442     -0.312142   -0.51612     0.254637   -0.311782   -0.362701     -0.123417    -0.0977963   -0.500205   -0.426261
 -0.0837136  -0.0463415   -0.239797   -0.62753     0.523825     0.628      -0.111498    0.232896    -0.363323      0.11803     -0.22977     0.0740472   0.156965   -0.13322     -0.246087   -0.115789    0.193929     -0.098594   -0.535987    0.172594   -0.392373   -0.222353      0.233711    -0.277452     0.0856244  -0.115785
  0.0247937  -0.0225268    0.0871415   0.101462   -0.0119596    0.0654671   0.107333    0.0117625    0.0111791    -0.0380694   -0.042977   -0.149364    0.0576776  -0.00747065  -0.0381969   0.10222    -0.0286994     0.0114072  -0.0924269   0.0527597  -0.110424    0.101827     -0.220351    -0.00277339   0.0455595   0.0410545
 -0.0255063   0.0267072   -0.11649    -0.0934359   0.05429     -0.169412   -0.211167   -0.0118968    0.00205814    0.0922192    0.019118    0.158379   -0.185224    0.0857126   -0.0591322   0.0761571  -0.0261602    -0.0795128   0.273602    0.0297388   0.213934   -0.114839      0.315904     0.0764431   -0.104937   -0.11596
 -0.179143    0.187833     0.0830305   0.52438     0.0898154   -0.139257   -0.180474   -0.169365     0.359169      0.419391     0.186368    0.606947   -0.615265   -0.747539    -0.0141669   0.0145969  -0.325395      0.193132    0.0901645  -0.260533    0.132891   -0.0329217    -0.406636     0.398895    -0.0524952  -0.217232
  0.0674121   0.112386    -0.26547     0.243203    0.3533       0.0558038   0.232808   -0.0578786    0.249513      0.282064     0.433919    0.229075    0.261367    0.0508899   -0.375432    0.180174    0.636337      0.665042    0.129446   -0.0685713  -0.0631612   0.312949     -0.647857    -0.23985     -0.411511   -0.222238
  0.38835    -0.489252    -0.171313   -0.435436   -0.150112    -0.405446    0.0862512   0.216187    -0.124302     -0.235288     0.273206   -0.42406     0.0973057   0.709509     0.173544    0.299726    0.62267       0.0182309  -0.0013547   0.346767    0.103868    0.181131      0.179073     0.181909    -0.2928     -0.354113
  0.0620743   0.0579874   -0.149367    0.600498   -0.0527118   -0.785895   -0.0787383   0.00718864  -0.0573502     0.317133    -0.27131    -0.427708   -0.0899992   0.547671    -0.237641    0.732396   -0.000876482   0.413475    0.176525    0.547599    0.112098    0.38688       0.168925     0.363747    -0.462829    0.118194
 -0.200821    0.168108     0.729189    0.348718   -0.040108     0.190871   -0.0989087  -0.0558926   -0.347512      0.520884     0.21095    -0.545761   -0.206933    0.40855     -0.0804943  -0.262039   -0.388081     -0.171898   -0.566172   -0.425245   -0.497886    0.576829     -0.0881352   -0.629258     0.0918385   0.535296
  0.224223    0.0449245    0.409979   -0.0946403  -0.350796     0.225812   -0.368735   -0.267786    -0.000944968  -0.1966      -0.513208   -0.460246    0.216032   -0.177492    -0.102295    0.31669    -0.242341     -0.120192   -0.0297489   0.648186   -0.901194   -0.0881578    -0.0828669   -0.233713    -0.183049    0.462503
 -0.104253    0.461474     0.227469    0.104986   -0.92884     -0.146017    0.239363    0.0651018   -0.0854886    -0.0149785   -0.10195    -0.175933    0.693138   -0.210908    -0.0338854  -0.161063   -0.210347     -0.234763    0.286215   -0.131792    0.649602    0.108266     -0.117665     0.112367     0.227662   -0.174819
  0.313891    0.159248    -0.160815    0.494844   -0.333806    -0.0132539  -0.245394    0.0491417   -0.454578      0.22811      0.101192   -0.0876103   0.410139    0.0250451   -0.417204    0.6813     -0.322761     -0.260773   -0.438469   -0.0652938   0.595455   -0.0384768    -0.398244    -0.238676     0.26159     0.0916991
  0.117687    0.0172311   -0.128667    0.0564648  -0.181583     0.0313376   0.068892    0.0299392    0.120302      0.00455278  -0.408015   -0.336268    0.0183375  -0.119771    -0.120243   -0.621202   -0.243665      0.431777    0.0296454  -0.563925    0.147461    0.131548      0.211456    -0.184361     0.0185532  -0.121933
 -0.264343   -0.495309    -0.166027   -0.122212   -0.0960784    0.127443    0.211173   -0.00661077   0.290841     -0.276928     0.422661    0.099808    0.104699   -0.0485255    0.44159    -0.184007   -0.00935076   -0.0610834  -0.3572     -0.856071    0.357077    0.145332     -0.0728992   -0.318705     0.185496   -0.108222
 -0.010591   -0.157416     0.238943    0.261398    0.533442    -0.0114009   0.0176349   0.124864    -0.167913      0.0927819    0.0250652   0.150555   -0.0512887  -0.161914     0.488147   -0.424248    0.506568      0.450247    0.515692    0.323418   -0.0794763  -0.0295459     0.139505     0.113674     0.279092    0.10376
  0.128059    0.363558     0.107508    0.274671    0.146844     0.702328    0.307574    0.0163711   -0.329566     -0.261117     0.134205   -0.533115   -0.0305151  -0.339367     0.481721   -0.283009    0.178808      0.149982    0.28592     0.0276271  -0.512602   -0.0256902    -0.282401     0.643879     0.453196    0.00153342[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410010
[ Info: iteration 2, average log likelihood -1.410000
[ Info: iteration 3, average log likelihood -1.409990
[ Info: iteration 4, average log likelihood -1.409981
[ Info: iteration 5, average log likelihood -1.409972
[ Info: iteration 6, average log likelihood -1.409963
[ Info: iteration 7, average log likelihood -1.409954
[ Info: iteration 8, average log likelihood -1.409945
[ Info: iteration 9, average log likelihood -1.409937
[ Info: iteration 10, average log likelihood -1.409929
┌ Info: EM with 100000 data points 10 iterations avll -1.409929
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.010966e+06
      1       7.077138e+05      -3.032526e+05 |       32
      2       6.933520e+05      -1.436179e+04 |       32
      3       6.881821e+05      -5.169888e+03 |       32
      4       6.855811e+05      -2.600973e+03 |       32
      5       6.839246e+05      -1.656509e+03 |       32
      6       6.826553e+05      -1.269308e+03 |       32
      7       6.816482e+05      -1.007082e+03 |       32
      8       6.808403e+05      -8.079293e+02 |       32
      9       6.801738e+05      -6.665252e+02 |       32
     10       6.795916e+05      -5.821808e+02 |       32
     11       6.790883e+05      -5.033512e+02 |       32
     12       6.786398e+05      -4.484629e+02 |       32
     13       6.782348e+05      -4.049913e+02 |       32
     14       6.778541e+05      -3.807340e+02 |       32
     15       6.774910e+05      -3.630696e+02 |       32
     16       6.771585e+05      -3.325021e+02 |       32
     17       6.768743e+05      -2.842248e+02 |       32
     18       6.766439e+05      -2.303855e+02 |       32
     19       6.764545e+05      -1.894295e+02 |       32
     20       6.762961e+05      -1.583585e+02 |       32
     21       6.761568e+05      -1.392990e+02 |       32
     22       6.760254e+05      -1.313703e+02 |       32
     23       6.758989e+05      -1.265693e+02 |       32
     24       6.757828e+05      -1.160825e+02 |       32
     25       6.756763e+05      -1.064495e+02 |       32
     26       6.755815e+05      -9.488006e+01 |       32
     27       6.754858e+05      -9.568213e+01 |       32
     28       6.754030e+05      -8.274761e+01 |       32
     29       6.753350e+05      -6.806517e+01 |       32
     30       6.752733e+05      -6.162383e+01 |       32
     31       6.752154e+05      -5.789315e+01 |       32
     32       6.751653e+05      -5.016301e+01 |       32
     33       6.751168e+05      -4.850496e+01 |       32
     34       6.750767e+05      -4.002697e+01 |       32
     35       6.750359e+05      -4.086833e+01 |       32
     36       6.749973e+05      -3.859127e+01 |       32
     37       6.749519e+05      -4.538736e+01 |       32
     38       6.749060e+05      -4.593224e+01 |       32
     39       6.748641e+05      -4.185782e+01 |       32
     40       6.748225e+05      -4.165524e+01 |       32
     41       6.747857e+05      -3.675322e+01 |       32
     42       6.747468e+05      -3.894697e+01 |       32
     43       6.747143e+05      -3.246244e+01 |       32
     44       6.746843e+05      -2.996323e+01 |       32
     45       6.746583e+05      -2.603685e+01 |       32
     46       6.746331e+05      -2.519281e+01 |       32
     47       6.746095e+05      -2.355779e+01 |       32
     48       6.745877e+05      -2.188054e+01 |       32
     49       6.745665e+05      -2.113994e+01 |       32
     50       6.745450e+05      -2.156188e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 674544.9594413888)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422129
[ Info: iteration 2, average log likelihood -1.417103
[ Info: iteration 3, average log likelihood -1.415723
[ Info: iteration 4, average log likelihood -1.414655
[ Info: iteration 5, average log likelihood -1.413508
[ Info: iteration 6, average log likelihood -1.412459
[ Info: iteration 7, average log likelihood -1.411756
[ Info: iteration 8, average log likelihood -1.411376
[ Info: iteration 9, average log likelihood -1.411171
[ Info: iteration 10, average log likelihood -1.411045
[ Info: iteration 11, average log likelihood -1.410954
[ Info: iteration 12, average log likelihood -1.410883
[ Info: iteration 13, average log likelihood -1.410823
[ Info: iteration 14, average log likelihood -1.410771
[ Info: iteration 15, average log likelihood -1.410724
[ Info: iteration 16, average log likelihood -1.410681
[ Info: iteration 17, average log likelihood -1.410642
[ Info: iteration 18, average log likelihood -1.410604
[ Info: iteration 19, average log likelihood -1.410569
[ Info: iteration 20, average log likelihood -1.410535
[ Info: iteration 21, average log likelihood -1.410503
[ Info: iteration 22, average log likelihood -1.410472
[ Info: iteration 23, average log likelihood -1.410443
[ Info: iteration 24, average log likelihood -1.410415
[ Info: iteration 25, average log likelihood -1.410387
[ Info: iteration 26, average log likelihood -1.410361
[ Info: iteration 27, average log likelihood -1.410336
[ Info: iteration 28, average log likelihood -1.410312
[ Info: iteration 29, average log likelihood -1.410289
[ Info: iteration 30, average log likelihood -1.410267
[ Info: iteration 31, average log likelihood -1.410245
[ Info: iteration 32, average log likelihood -1.410225
[ Info: iteration 33, average log likelihood -1.410205
[ Info: iteration 34, average log likelihood -1.410187
[ Info: iteration 35, average log likelihood -1.410169
[ Info: iteration 36, average log likelihood -1.410151
[ Info: iteration 37, average log likelihood -1.410134
[ Info: iteration 38, average log likelihood -1.410118
[ Info: iteration 39, average log likelihood -1.410102
[ Info: iteration 40, average log likelihood -1.410086
[ Info: iteration 41, average log likelihood -1.410071
[ Info: iteration 42, average log likelihood -1.410055
[ Info: iteration 43, average log likelihood -1.410041
[ Info: iteration 44, average log likelihood -1.410026
[ Info: iteration 45, average log likelihood -1.410011
[ Info: iteration 46, average log likelihood -1.409996
[ Info: iteration 47, average log likelihood -1.409982
[ Info: iteration 48, average log likelihood -1.409967
[ Info: iteration 49, average log likelihood -1.409953
[ Info: iteration 50, average log likelihood -1.409938
┌ Info: EM with 100000 data points 50 iterations avll -1.409938
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0433753    -0.415799   -0.186708   -0.611592     0.389924    -0.197416   -0.498493    -0.400439      0.292604   -0.0883468   0.166607     0.385311    -0.39849      0.246285   -0.0688844    0.676677    0.192702    -0.467319   -0.085075     0.40108    -0.163355   -0.20451     0.0965812  -0.0373035   -0.693141     0.265733
 -0.0158112    -0.264998    0.323052   -0.42129      0.696987     0.537963    0.0137831   -0.00757344   -0.17858     0.245052   -0.231932    -0.210588    -0.240783    -0.0578467   0.180496    -0.335592   -0.122272    -0.0457361  -0.514846     0.0804103  -0.971083   -0.0492213   0.0842405  -0.53213      0.0594084    0.208656
  0.174154      0.49125    -0.365537    0.124349    -0.72039     -0.387468   -0.335134     0.000487515  -0.48789     0.172212    0.0983425   -0.00994209   0.508966    -0.202811   -0.176377     0.361651   -0.248745    -0.0291841   0.375814     0.112212    0.90386    -0.0326217   0.131505    0.211035     0.195707    -0.258716
  0.0185586     0.0963547   0.124931    0.052624    -0.054012    -0.328894    0.212652    -0.208286      0.221746   -0.0242079   0.349825     0.0442329   -0.25559     -0.0135454   0.0801103    0.172078    0.00621041  -0.0316604   0.336404     0.110171    0.0854925   0.0104933  -0.12324     0.339677    -0.101729    -0.279032
 -0.0773776     0.113933   -0.0184172   0.0340078    0.0778423    0.213391   -0.059405     0.110302     -0.0475564   0.17478    -0.18829     -0.0492087    0.0798061   -0.0722611  -0.172439    -0.0284799  -0.0410223    0.0519824  -0.0813856   -0.0246991  -0.0692172   0.100668   -0.0981388  -0.102398     0.0672323    0.0430388
 -0.028705     -0.63743     0.156695    0.736275    -0.0646818    0.277301   -0.308317    -0.3759        0.205271   -0.188058   -0.0590106    0.341273    -0.121546    -0.727219   -0.0671276    0.514362   -0.0647816    0.331678    0.136459     0.480891   -0.403056    0.183154   -0.75191    -0.167357     0.113644    -0.186457
  0.217014      0.0815131  -0.538816   -0.617294     0.235129    -0.445914    0.370505     0.444678     -0.0376031   0.0454229   0.106631    -0.286044     0.558487     0.346116   -0.537012     0.0752027   0.464466    -0.177452   -0.204229     0.358586    0.0100686  -0.46242     0.0584286  -0.420417    -0.119913    -0.776176
  0.0291954     0.529822    0.471687    0.0143774    0.0846653   -0.203717   -0.170149    -0.613741      0.0126615   0.580654    0.635603     0.0975442   -0.890685    -0.120093   -0.329991    -0.124023   -0.330358    -0.0265069   0.0723036   -0.426392   -0.286666   -0.0800972  -0.194127    0.161383    -0.623697     0.0400095
  0.116368     -0.119579    0.0862919  -0.175184    -0.0105394    0.0626188  -0.0606044   -0.00342065   -0.372865   -0.32356    -0.14821     -0.378968     0.165853     0.215373    0.106478     0.187932    0.234306    -0.0533152   0.122316     0.419846   -0.264208   -0.103221    0.329938    0.0877115   -0.0876012    0.265431
 -0.327406     -0.601475   -0.344643   -0.134529     0.196672     0.502716    0.0832936   -0.137432     -0.202918   -0.06034     0.224678     0.108006    -0.0817123   -0.156219    0.389594    -0.357379    0.146362    -0.075948    0.0296364   -0.631265    0.720046    0.342138    0.363146   -0.0744384    0.336466    -0.0694758
  0.0734805     0.342088    0.23139     0.407732     0.0805766    0.78209     0.448575     0.120337     -0.329698   -0.338       0.129171    -0.382421     0.348287    -0.489891    0.595767    -0.408387    0.196361     0.274859    0.287341     0.0579108  -0.317545    0.0527679  -0.303743    0.577136     0.724121     0.133176
  0.085731     -0.0906533  -0.132954    0.118795    -0.393585     0.065378    0.446676    -0.0486855     0.419096   -0.270314    0.0546595   -0.391835     0.236739     0.13871     0.259622    -0.112053    0.129356     0.322072   -0.268117    -0.475853    0.0178366   0.538658   -0.601593   -0.206474    -0.281661    -0.0645892
  0.599954     -0.493885    0.310848   -0.471893    -0.311244     0.35956    -0.263728    -0.239919     -0.204783   -0.347051    0.441569     0.530001    -0.210613    -0.314995    0.0565017   -0.182342    0.102314    -0.711381    0.408613    -0.0573368   0.338925   -0.755187   -0.0501178   0.280692     0.302288    -0.586636
 -0.244512      0.395939    0.739544    0.729886     0.423124    -0.369541   -0.390092     0.11137      -0.0587396   0.0486739  -0.0306582    0.398872    -0.69909      0.13266     0.713186     0.578672   -0.478128    -0.415928    0.0182222    0.428047   -0.227569   -0.204691    0.314864    0.441824     0.60634      0.633729
 -0.050599     -0.162587   -0.442478   -0.255372     0.67683     -0.138005   -0.367697     0.449094      0.118642    0.17522    -0.317601     0.145659    -0.00471174   0.0412849  -0.635934     0.127587   -0.337315    -0.0543102  -1.30216     -0.404935    0.483615   -0.302943    0.2335      0.128247    -0.0153773    0.0153398
 -0.0598904    -0.0667148  -0.0922748   0.0137826    0.1417       0.0755298   0.0576251    0.0318486    -0.0271358  -0.0512248  -0.13286     -0.097106     0.152519    -0.064294    0.197268    -0.0474874   0.0115198    0.0793071  -0.135107    -0.0745661   0.0908      0.0126743   0.0355607  -0.130441    -0.00610876   0.0912443
  0.213291      0.142842    0.0563144   0.331432    -0.116796     0.225504   -0.126981    -0.0465916    -0.365715    0.444876   -0.227084    -0.433168    -0.159129    -0.233911   -0.374547    -0.780323   -0.314783     0.740422    0.303388    -0.679713    0.221609    0.174896    0.584501    0.0720796    0.380499     0.199206
 -0.192724      0.247255   -0.717854   -0.631299    -0.205263    -0.445497    0.163568    -0.034232      0.29549    -0.264828   -0.571008     0.185275     0.223409    -0.772438   -0.469977     0.353809    0.29383      0.233112    0.51898      0.443887    0.520822   -0.353633   -0.273986    0.812578    -0.00571812  -1.01933
  0.198694     -0.475782   -0.340548    0.0935516    0.505671    -0.391999    0.406099     0.300111     -0.079349    0.186707    0.922593     0.214831    -0.0688338    0.28708     0.214597    -0.203603    0.734105     0.632978    0.379742    -0.363738    0.521422    0.14128    -0.0118669  -0.193749     0.0232402   -0.128094
  0.0579554     0.110822   -0.174122    0.527287     0.00619738  -0.749133    0.0284506   -0.04684      -0.0760288   0.443042   -0.239969    -0.511247    -0.0725039    0.692849   -0.287951     0.79212     0.168162     0.346521    0.0717618    0.489836    0.208601    0.540285    0.141885    0.320695    -0.536715     0.106147
  0.000382533  -0.0605039  -0.146069    0.227174     0.744297    -0.155881   -0.187261     0.073686      0.195446    0.232765    0.00071377   0.341446    -0.378944    -0.276003    0.342855    -0.29844     0.425885     0.475741    0.318651     0.0306352  -0.139114   -0.246937    0.0688755   0.263396    -0.0304196   -0.19913
  0.0914889     0.385297    0.486907   -0.00653943  -0.469202    -0.205776   -0.125966    -0.0175559     0.535408   -0.123893   -0.636618    -0.360916     0.0873404   -0.142235   -0.161142     0.286644   -0.655808     0.0551454  -0.0673576    0.693765   -0.876775   -0.294144   -0.0694801  -0.116648    -0.463656     0.202545
 -0.000568766  -0.0281261  -0.220827   -0.125063     0.597291     0.0167256   0.324391     0.560047      0.027075   -0.23363     0.0445852   -0.212405    -0.0746013    0.635824   -0.0288717    0.547665    0.61996      0.033794   -0.485902     0.0930255  -0.768196    0.103602   -0.591857    0.337628    -0.206283    -0.228928
 -0.424845      0.22086     0.317283    0.240665    -0.593065    -0.0581422   0.163358     0.0681529     0.43472     0.471551    0.362844     0.485558     0.244538    -0.388735   -0.00064607  -0.269637   -0.337091    -0.323314    0.0409465   -0.60652     0.835693    0.0462727  -0.539788    0.178865     0.367062    -0.535367
 -0.127061     -0.189949   -0.295292    0.0454544    0.0587575    0.158734   -0.0724735    0.650145      0.157901   -0.67139     0.146103     0.0178333    0.651282    -0.0288951   0.513228    -0.245842   -0.184806     0.119204   -0.462027    -0.719785   -0.238741   -0.676605    0.153679   -0.785988     0.535449    -0.0745746
  0.308019      0.749757    0.0658863   0.315987     0.286502     0.3323      0.379904    -0.523712     -0.251196    0.241384    0.0992205    0.222661     0.138674    -0.343145   -0.337844     0.260993   -0.0419986   -0.508032   -0.00321704  -0.103679    0.066444   -0.375136   -0.267731   -0.481384     0.406941     0.518001
 -0.229026      0.0672673   0.0447629  -0.291787    -0.289065    -0.0861318   0.464321    -0.165124      0.328192   -0.675044   -0.328276    -0.0958833   -0.424986    -0.196889    0.276225    -0.474881   -0.217384    -0.350471    0.273515    -0.475295   -0.0563526  -0.351316    0.692279   -0.0708379    0.135516    -0.262956
  0.0284502    -0.136572    0.631734    0.212305    -0.796866     0.0936256  -0.295001    -0.0337938    -0.506759    0.15284    -0.0787176   -0.63741      0.481273     0.266073   -0.422384     0.279875   -0.437625    -0.368151   -0.341445     0.0494863   0.244078    0.536549   -0.214856   -0.322762     0.371015     0.498424
  0.0747047    -0.226289    0.0271844  -0.0150563   -0.248631    -0.300567   -0.316137     0.0992486     0.101418    0.034405    0.0310054    0.225578    -0.113784     0.252423   -0.193277     0.103726   -0.30412     -0.17173    -0.0654126   -0.20872     0.320542   -0.0880584   0.139708   -0.148109    -0.205054    -0.0648368
  0.111404      0.734071   -0.123517   -0.346705     0.126961    -0.0277344   0.141238    -0.225558     -0.373031    0.69253     0.344103     0.237492     0.0242534    0.827193   -0.0068696   -0.210807   -0.0409098   -0.718895    0.182099    -0.278774    0.317216    0.205576    0.397052    0.0882252    0.00258015   0.371001
 -0.246953     -0.929172   -0.363865   -0.230247    -0.526761    -0.505683   -0.719272     0.603158      0.308856   -0.286049   -0.237508    -0.231734     0.08516      0.288523    0.182306    -0.041308   -0.056006     0.602677   -0.110237     0.203653    0.0300833   0.27786     0.180064    0.201456    -0.506662    -0.608941
 -0.0872884    -0.17592     0.824119   -0.260052    -0.180386     0.0569899  -0.00878659  -0.248399     -0.115785    0.0473523  -0.264859     0.178721    -0.210579    -0.0247746   0.0249761   -0.366762    0.0805292   -0.316679    1.25657      1.15595     0.113092    0.348211    0.320548    0.00464013  -0.0614003    0.303428[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409924
[ Info: iteration 2, average log likelihood -1.409910
[ Info: iteration 3, average log likelihood -1.409896
[ Info: iteration 4, average log likelihood -1.409882
[ Info: iteration 5, average log likelihood -1.409868
[ Info: iteration 6, average log likelihood -1.409854
[ Info: iteration 7, average log likelihood -1.409841
[ Info: iteration 8, average log likelihood -1.409828
[ Info: iteration 9, average log likelihood -1.409815
[ Info: iteration 10, average log likelihood -1.409803
┌ Info: EM with 100000 data points 10 iterations avll -1.409803
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
