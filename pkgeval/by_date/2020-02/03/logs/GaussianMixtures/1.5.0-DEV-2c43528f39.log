Julia Version 1.5.0-DEV.225
Commit 2c43528f39 (2020-02-03 15:22 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed SortingAlgorithms ── v0.3.1
  Installed GaussianMixtures ─── v0.3.0
  Installed URIParser ────────── v0.4.0
  Installed CMake ────────────── v1.1.2
  Installed Distances ────────── v0.8.2
  Installed OpenSpecFun_jll ──── v0.5.3+1
  Installed PDMats ───────────── v0.9.11
  Installed CMakeWrapper ─────── v0.2.3
  Installed Compat ───────────── v2.2.0
  Installed JLD ──────────────── v0.9.2
  Installed FileIO ───────────── v1.2.1
  Installed Parameters ───────── v0.12.0
  Installed Rmath ────────────── v0.6.0
  Installed QuadGK ───────────── v2.3.1
  Installed Arpack_jll ───────── v3.5.0+2
  Installed ScikitLearnBase ──── v0.5.0
  Installed Arpack ───────────── v0.4.0
  Installed Clustering ───────── v0.13.3
  Installed LegacyStrings ────── v0.4.1
  Installed NearestNeighbors ─── v0.4.4
  Installed BinDeps ──────────── v1.0.0
  Installed OpenBLAS_jll ─────── v0.3.7+5
  Installed Missings ─────────── v0.4.3
  Installed HDF5 ─────────────── v0.12.5
  Installed StatsBase ────────── v0.32.0
  Installed StatsFuns ────────── v0.9.3
  Installed OrderedCollections ─ v1.1.0
  Installed StaticArrays ─────── v0.12.1
  Installed DataAPI ──────────── v1.1.0
  Installed Blosc ────────────── v0.5.1
  Installed FillArrays ───────── v0.8.4
  Installed DataStructures ───── v0.17.9
  Installed BinaryProvider ───── v0.5.8
  Installed Distributions ────── v0.22.4
  Installed SpecialFunctions ─── v0.9.0
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                         ##                                                                         3.4%######                                                                     8.3%###########                                                               16.0%#################                                                         24.4%###########################                                               37.9%#######################################                                   54.3%######################################################                    75.5%######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.4
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
   Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
   Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
   Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
    Testing GaussianMixtures
Status `/tmp/jl_2UsTLR/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.9
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.22.4
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.4
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.2
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+5
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.11
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64 
  [ade2ca70] Dates 
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [b77e0a4c] InteractiveUtils 
  [76f85450] LibGit2 
  [8f399da3] Libdl 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [d6f4376e] Markdown 
  [a63ad114] Mmap 
  [44cfe95a] Pkg 
  [de0858da] Printf 
  [3fa0cd96] REPL 
  [9a3f8284] Random 
  [ea8e919c] SHA 
  [9e88b42a] Serialization 
  [1a1011a3] SharedArrays 
  [6462fe0b] Sockets 
  [2f01184e] SparseArrays 
  [10745b16] Statistics 
  [4607b0f0] SuiteSparse 
  [8dfed614] Test 
  [cf7118a7] UUIDs 
  [4ec0a83e] Unicode 
[ Info: Testing Data
(100000, -1.837875996723066e6, [78718.51705952616, 21281.48294047385], [-18068.434218076447 15007.16543605577 -16693.678084939304; 18012.137191728256 -15202.849365516993 16494.305747032424], [[70416.95794389553 7743.548214827122 -8451.997942132772; 7743.548214827122 71959.82355165355 6573.088243728756; -8451.997942132772 6573.088243728756 71108.64151474654], [29661.875639726048 -7712.792479828259 8408.367650229819; -7712.79247982826 27513.992533403547 -6193.39131213836; 8408.367650229819 -6193.39131213836 28474.299117441482]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.273411e+03
      1       1.061735e+03      -2.116763e+02 |        7
      2       9.717593e+02      -8.997575e+01 |        2
      3       9.200003e+02      -5.175898e+01 |        2
      4       9.131182e+02      -6.882073e+00 |        0
      5       9.131182e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 913.118234490416)
┌ Info: K-means with 272 data points using 5 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.084638
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.764614
[ Info: iteration 2, lowerbound -3.615325
[ Info: iteration 3, lowerbound -3.461850
[ Info: iteration 4, lowerbound -3.297173
[ Info: iteration 5, lowerbound -3.142753
[ Info: iteration 6, lowerbound -3.019439
[ Info: dropping number of Gaussions to 5
[ Info: iteration 7, lowerbound -2.917912
[ Info: iteration 8, lowerbound -2.830630
[ Info: iteration 9, lowerbound -2.783831
[ Info: iteration 10, lowerbound -2.766882
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.741324
[ Info: iteration 12, lowerbound -2.707065
[ Info: iteration 13, lowerbound -2.666956
[ Info: iteration 14, lowerbound -2.612147
[ Info: iteration 15, lowerbound -2.546037
[ Info: iteration 16, lowerbound -2.478213
[ Info: iteration 17, lowerbound -2.419315
[ Info: iteration 18, lowerbound -2.373755
[ Info: iteration 19, lowerbound -2.340098
[ Info: iteration 20, lowerbound -2.317329
[ Info: iteration 21, lowerbound -2.307633
[ Info: dropping number of Gaussions to 2
[ Info: iteration 22, lowerbound -2.303000
[ Info: iteration 23, lowerbound -2.299263
[ Info: iteration 24, lowerbound -2.299257
[ Info: iteration 25, lowerbound -2.299255
[ Info: iteration 26, lowerbound -2.299254
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Tue Feb  4 01:56:20 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Tue Feb  4 01:56:28 2020: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Tue Feb  4 01:56:30 2020: EM with 272 data points 0 iterations avll -2.084638
5.8 data points per parameter
, Tue Feb  4 01:56:32 2020: GMM converted to Variational GMM
, Tue Feb  4 01:56:41 2020: iteration 1, lowerbound -3.764614
, Tue Feb  4 01:56:41 2020: iteration 2, lowerbound -3.615325
, Tue Feb  4 01:56:41 2020: iteration 3, lowerbound -3.461850
, Tue Feb  4 01:56:41 2020: iteration 4, lowerbound -3.297173
, Tue Feb  4 01:56:41 2020: iteration 5, lowerbound -3.142753
, Tue Feb  4 01:56:41 2020: iteration 6, lowerbound -3.019439
, Tue Feb  4 01:56:41 2020: dropping number of Gaussions to 5
, Tue Feb  4 01:56:41 2020: iteration 7, lowerbound -2.917912
, Tue Feb  4 01:56:41 2020: iteration 8, lowerbound -2.830630
, Tue Feb  4 01:56:41 2020: iteration 9, lowerbound -2.783831
, Tue Feb  4 01:56:41 2020: iteration 10, lowerbound -2.766882
, Tue Feb  4 01:56:41 2020: dropping number of Gaussions to 3
, Tue Feb  4 01:56:41 2020: iteration 11, lowerbound -2.741324
, Tue Feb  4 01:56:41 2020: iteration 12, lowerbound -2.707065
, Tue Feb  4 01:56:41 2020: iteration 13, lowerbound -2.666956
, Tue Feb  4 01:56:41 2020: iteration 14, lowerbound -2.612147
, Tue Feb  4 01:56:41 2020: iteration 15, lowerbound -2.546037
, Tue Feb  4 01:56:41 2020: iteration 16, lowerbound -2.478213
, Tue Feb  4 01:56:41 2020: iteration 17, lowerbound -2.419315
, Tue Feb  4 01:56:41 2020: iteration 18, lowerbound -2.373755
, Tue Feb  4 01:56:41 2020: iteration 19, lowerbound -2.340098
, Tue Feb  4 01:56:41 2020: iteration 20, lowerbound -2.317329
, Tue Feb  4 01:56:41 2020: iteration 21, lowerbound -2.307633
, Tue Feb  4 01:56:41 2020: dropping number of Gaussions to 2
, Tue Feb  4 01:56:41 2020: iteration 22, lowerbound -2.303000
, Tue Feb  4 01:56:41 2020: iteration 23, lowerbound -2.299263
, Tue Feb  4 01:56:41 2020: iteration 24, lowerbound -2.299257
, Tue Feb  4 01:56:41 2020: iteration 25, lowerbound -2.299255
, Tue Feb  4 01:56:41 2020: iteration 26, lowerbound -2.299254
, Tue Feb  4 01:56:41 2020: iteration 27, lowerbound -2.299253
, Tue Feb  4 01:56:41 2020: iteration 28, lowerbound -2.299253
, Tue Feb  4 01:56:41 2020: iteration 29, lowerbound -2.299253
, Tue Feb  4 01:56:41 2020: iteration 30, lowerbound -2.299253
, Tue Feb  4 01:56:41 2020: iteration 31, lowerbound -2.299253
, Tue Feb  4 01:56:41 2020: iteration 32, lowerbound -2.299253
, Tue Feb  4 01:56:41 2020: iteration 33, lowerbound -2.299253
, Tue Feb  4 01:56:41 2020: iteration 34, lowerbound -2.299253
, Tue Feb  4 01:56:41 2020: iteration 35, lowerbound -2.299253
, Tue Feb  4 01:56:41 2020: iteration 36, lowerbound -2.299253
, Tue Feb  4 01:56:41 2020: iteration 37, lowerbound -2.299253
, Tue Feb  4 01:56:41 2020: iteration 38, lowerbound -2.299253
, Tue Feb  4 01:56:41 2020: iteration 39, lowerbound -2.299253
, Tue Feb  4 01:56:41 2020: iteration 40, lowerbound -2.299253
, Tue Feb  4 01:56:41 2020: iteration 41, lowerbound -2.299253
, Tue Feb  4 01:56:41 2020: iteration 42, lowerbound -2.299253
, Tue Feb  4 01:56:41 2020: iteration 43, lowerbound -2.299253
, Tue Feb  4 01:56:41 2020: iteration 44, lowerbound -2.299253
, Tue Feb  4 01:56:41 2020: iteration 45, lowerbound -2.299253
, Tue Feb  4 01:56:41 2020: iteration 46, lowerbound -2.299253
, Tue Feb  4 01:56:41 2020: iteration 47, lowerbound -2.299253
, Tue Feb  4 01:56:41 2020: iteration 48, lowerbound -2.299253
, Tue Feb  4 01:56:41 2020: iteration 49, lowerbound -2.299253
, Tue Feb  4 01:56:41 2020: iteration 50, lowerbound -2.299253
, Tue Feb  4 01:56:41 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398238, 178.04509222601757]
β = [95.95490777398238, 178.04509222601757]
m = [2.0002292577753393 53.851987172461136; 4.2503007332698814 79.28686694436142]
ν = [97.95490777398238, 180.04509222601757]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763611948982 -0.008953123827346858; 0.0 0.012748664777409666], [0.18404155547484016 -0.007644049042327424; 0.0 0.008581705166333076]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9968479588398108
avll from llpg:  -0.9968479588398094
avll direct:     -0.9968479588398094
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -1.010023195667192
avll from llpg:  -1.0100231956671917
avll direct:     -1.0100231956671917
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
  0.109121     0.0624604    0.0455358   -0.0181093    -0.133191   -0.14425     -0.0569855   -0.116601    -0.0829636    -0.0437069   -0.0889774  -0.136753   -0.114727   -0.0578911    0.0649685    0.100197    -0.0395091    -0.00281392   0.0639401   -0.00826473   0.140305     0.11196      -0.065488   -0.130978     0.126075     0.0306963
  0.210052    -0.137845     0.0629076   -0.281224      0.0413589  -0.168865     0.0456822    0.00151402   0.11924       0.106589    -0.118156   -0.0301846  -0.188988    0.0794287    0.130004    -0.030099     0.0147997     0.171584     0.0808821    0.147994    -0.121789    -0.0585298    -0.0639819   0.114933     0.0722552   -0.0659463
 -0.00903857   0.0862433   -0.0439518    0.0370275    -0.0175078  -0.0634011    0.053654     0.146043    -0.0249739    -0.082431    -0.0109771   0.0342639   0.0861172  -0.0569974   -0.237863    -0.0053182   -0.311314     -0.0471886   -0.0513481    0.0725539   -0.115941     0.0150325     0.102732   -0.0619552    0.0370108   -0.0757479
  0.146448     0.137732     0.0148708   -0.113062      0.0834328  -0.0216872    0.00560325   0.0875692    0.14534       0.162764     0.013557   -0.0960347   0.33551     0.11934      0.0915594   -0.00746705   0.0304411    -0.0375198    0.151413    -0.0378343   -0.0567375   -0.00710308   -0.219677    0.0447252   -0.229208     0.123495
 -0.182263    -0.0219953   -0.115794     0.0360144     0.0393837   0.00433412   0.045647    -0.0728252   -0.0520539     0.0261156   -0.0249667  -0.10217     0.0223004  -0.0103117   -0.110086    -0.175177     0.0471997     0.0397264   -0.0336916   -0.0978696    0.0863431   -0.13306      -0.116505    0.0758303   -0.0319955   -0.12974
 -0.165833     0.0315986    0.00049638   0.0518445     0.0147729   0.193514    -0.0508272    0.0773298   -0.050977      0.0347393    0.175092   -0.0261331  -0.035538   -0.0664819    0.107492     0.0391664   -0.140853      0.298873     0.0116203   -0.300264    -0.0240909   -0.000364362  -0.0227063  -0.0758444    0.0296176    0.0517557
 -0.169313     0.113328     0.0719713   -0.0282806     0.166935    0.0549101    0.0438148    0.00886545   0.15018       0.0736706   -0.0479433   0.243702   -0.126716    0.0207031   -0.024513    -0.0112122   -0.0314709     0.0161576    0.0327604    0.0601025    0.00835957  -0.0511379     0.115858    0.0748583   -0.0533716   -0.141588
 -0.0890786    0.189565     0.135284     0.0871924    -0.0274844   0.0791045    0.113034    -0.120907     0.132465      0.00299507  -0.0939392  -0.0993728   0.0214743  -0.0556421   -0.0314818    0.0601743   -0.0640847    -0.00598168  -0.0526081    0.1444       0.0497397   -0.0516457     0.136909   -0.0536038    0.082184     0.0050837
 -0.0662892   -0.136186     0.0595427    0.0607787    -0.138408   -0.0954945    0.0285736   -0.0323654   -0.0185131    -0.165821    -0.0409287   0.0353306  -0.117499    0.021466     0.116009     0.15718      0.0953132     0.0449886    0.159325     0.127927    -0.0259021   -0.110259     -0.0470622  -0.234647     0.0142847    0.113962
 -0.082254    -0.0379659    0.0102109   -0.249242     -0.0531406  -0.0211689    0.0331951   -0.0162376    0.0702412     0.0283202    0.0223422  -0.0753458   0.010861   -0.0342742    0.112914    -0.0751916    0.0145796     0.0352034    0.163198     0.0227192    0.0723356    0.0196692     0.0200766  -0.121194    -0.0813964   -0.0784639
 -0.087339     0.0610115   -0.126786     0.180113      0.0449636   0.157857     0.218341     0.168184     0.161106      0.113375    -0.0216379   0.201235    0.0388819   0.0516773   -0.177553     0.0179535   -0.0502081    -0.0522098    0.088716    -0.0687905    0.0572044   -0.110759      0.135448   -0.0294163    0.112198    -0.0107998
  0.143714     0.0438079   -0.115623    -0.00277746    0.0441257   0.0408899   -0.0348319    0.0737962   -0.0140364     0.0375407    0.0927567   0.0842521  -0.0558622  -0.0570773   -0.0748183   -0.124289     0.00971797    0.117394    -0.127161    -0.0556241   -0.0453436   -0.124357      0.0215701  -0.0415648   -0.129499    -0.0557793
  0.14254     -0.177087    -0.200905     0.0496536     0.0389987  -0.151386     0.185825     0.0585664   -0.124982      0.050079     0.055572   -0.0848284   0.0615186   0.0949418    0.101211    -0.105469     0.00669549    0.242259     0.00119605   0.0678424   -0.0942718   -0.118492     -0.0160086   0.107593     0.106516    -0.0291409
  0.151253     0.0684732   -0.0092808   -0.169199     -0.2514     -0.080661     0.104971     0.047909     0.0632225     0.111869    -0.0637556   0.0248131  -0.115336   -0.0979506    0.149747    -0.180228    -0.0934056    -0.195356    -0.0483821   -0.144149     0.0614621    0.147229     -0.0205262  -0.124482    -0.0944209    0.00390092
 -0.024071    -0.145248    -0.0468411    0.135771      0.135845    0.0436051    0.0447952    0.0641646    0.130225     -0.0453335   -0.011834   -0.106309   -0.12362     0.0968904   -0.250553     0.066669    -0.00299508   -0.0695415    0.195317    -0.0981055   -0.0784168   -0.105343      0.0157078   0.00585612   0.0197051    0.0751433
 -0.0882157   -0.0365065   -0.0267476    0.0505434     0.105292    0.0354105    0.0297332   -0.0486574   -0.0561974    -0.0133161    0.142173   -0.153214   -0.0694611  -0.119641     0.13019     -0.0771655   -0.039436     -0.129055    -0.204339     0.196966    -0.0126449    0.199886      0.0348251   0.0642507    0.06163      0.0321295
  0.0451898   -0.116184     0.20144     -0.00568259   -0.117879   -0.148737     0.140392     0.0243074    0.0265032     0.126886    -0.0421178  -0.0477615   0.0844682   0.0424628    0.125284    -0.16581      0.0776989    -0.105444     0.0572238   -0.0374007   -0.00311285   0.0410815    -0.101542    0.0430642    0.0478885   -0.0421834
 -0.0856313    0.170138     0.0717458   -0.0546231     0.0938506   0.0645922    0.159664     0.130371     0.133652      0.0230534    0.213383   -0.104696   -0.019143   -0.00250079  -0.0748623   -0.0326424   -0.215932      0.0565058    0.00860693  -0.0235565   -0.0359924   -0.100635     -0.0382554  -0.208817    -0.00873419   0.0708907
  0.135611     0.0445244    0.00378687  -0.00539603    0.0719195  -0.0683732    0.0779432    0.105228     0.0477092    -0.0904573   -0.0684164  -0.100991   -0.0549163   0.0987928   -0.00149786   0.143841    -0.0197437    -0.192313     0.0168054   -0.205981     0.05522     -0.07775       0.059114    0.0113864   -0.0691535   -0.0464907
  0.188308    -0.0218997   -0.0318427   -0.024064     -0.0532754  -0.0963811    0.118046    -0.0460045    0.0497044     0.014764    -0.116274    0.0469082  -0.0357482   0.0765152    0.0316869   -0.0469015   -0.0346724     0.145808    -0.0296518    0.0946806   -0.00966383  -0.0326337     0.235239    0.00288893  -0.00586451   0.0539635
 -0.08279      0.194021     0.104834     0.0739165     0.0282583  -0.154772     0.12701     -0.131123    -0.107423      0.128179    -0.0876365   0.114665    0.032507   -0.0377797   -0.0117165    0.0379598   -0.00977823    0.0269161   -0.0653378   -0.00758425  -0.074137     0.0583378    -0.134643    0.0678697   -0.0409925    0.0115642
  0.0749338   -0.064827    -0.071635    -0.0610673    -0.0065142   0.0899687    0.0460402    0.128295     0.00126232   -0.0152997    0.0785137  -0.014979   -0.14488    -0.085675     0.0452299    0.0032976    0.119607     -0.138552     0.0510282    0.123886    -0.100172     0.159255     -0.0546466  -0.121695     0.0962504   -0.0694509
 -0.0404486   -0.0755951   -0.129155     0.372809      0.0892804   0.107072     0.0389796   -0.0825539    0.142158     -0.00559723  -0.156254   -0.153646   -0.0137364   0.0392551    0.0168661    0.0781508   -0.0264051     0.00721499  -0.0891168   -0.0838016    0.063393     0.0742481     0.0495151   0.132225     0.295998    -0.0191427
  0.158396    -0.142598     0.237136    -0.0300189     0.234207   -0.120535    -0.169397     0.0469689   -0.00248257    0.11231      0.152583    0.0562148   0.18502     0.0137678    0.149113    -0.214825     0.0645135     0.122578     0.0227995    0.211844     0.0475815    0.0286878    -0.089916   -0.00521112  -0.106826     0.0923818
 -0.172411     0.0754175    0.229504     0.0320288     0.0962929   0.0787215   -0.0884306   -0.145633     0.000687817  -0.1802       0.066761    0.0605861   0.0402745   0.0561841   -0.0183273    0.00232638  -0.133135     -0.0638753   -0.00715283  -0.146516    -0.159556    -0.206786      0.104126    0.15537      0.137527    -0.107729
  0.13409     -0.0244548   -0.0172466   -0.0263912    -0.0222797  -0.0446194   -0.047884     0.110635     0.0599359    -0.053833     0.0897262   0.2024     -0.0959978  -0.195443     0.0578823   -0.00328265   0.120766     -0.157767    -0.134538    -0.0886557    0.0314372    0.0677282     0.101017    0.0153753   -0.124992     0.117735
  0.082919    -0.183172    -0.0721296    0.0423074     0.0544909   0.0211652   -0.162889     0.248053    -0.0920561     0.155698    -0.103624    0.0584017  -0.0557782  -0.0792768    0.0151041    0.228428    -0.179823      0.0395226    0.0908258    0.18776      0.145131    -0.00302605   -0.0150591   0.104261     0.0602451    0.101217
  0.0457617   -0.276571    -0.0519189   -0.000771268  -0.0277043  -0.162014     0.233606     0.132103     0.106361      0.0401374   -0.22858    -0.0514733  -0.139675   -0.025357    -0.211916     0.0136081   -0.000955224  -0.0806761    0.0398085    0.00726624  -0.189306     0.0262976    -0.0413839  -0.185883    -0.241188    -0.00728384
 -0.133801    -0.0584138   -0.00465948   0.110735     -0.0294712   0.0237249    0.0606933   -0.0469645    0.128734     -0.136094    -0.0108313  -0.0529409   0.0262177   0.124166    -0.0732414   -0.25541      0.0911717     0.125537     0.146292    -0.0884905   -0.0803214   -0.0215158    -0.136691   -0.0856874    0.0205085   -0.123752
 -0.13919      0.104778     0.132254    -0.0717543    -0.0356375  -0.242101    -0.0928928   -0.0724842    0.0343181     0.0946253    0.167437   -0.0949332   0.0536055   0.163182    -0.229369     0.0619991   -0.0364354     0.135782    -0.0979611   -0.193794    -0.00876935   0.0309772    -0.114206    0.0866395    0.0539601   -0.114152
  0.0176031    0.192935    -0.122141     0.05899       0.0149757   0.0383453    0.0992147   -0.263862    -0.0631134    -0.11388     -0.0337917   0.0348749   0.0806745  -0.0427688   -0.132713    -0.216148    -0.0465742    -0.130347    -0.0102207    0.127991     0.00341412  -0.0725597     0.0493636  -0.0317852   -0.0584952    0.0225583
 -0.0605294    0.00974262   0.0197794    0.0478049    -0.165649   -0.0865435   -0.0010125   -0.00632797  -0.12878      -0.0355367    0.261037    0.101812   -0.0375397  -0.0688014    0.033784    -0.0567309    0.0122055    -0.0398599   -0.0115198   -0.10875      0.166741     0.121422     -0.0529112  -0.0505201    0.080133     0.0817148kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3884290222620597
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.388494
[ Info: iteration 2, average log likelihood -1.388423
[ Info: iteration 3, average log likelihood -1.387776
[ Info: iteration 4, average log likelihood -1.381172
[ Info: iteration 5, average log likelihood -1.366318
[ Info: iteration 6, average log likelihood -1.359920
[ Info: iteration 7, average log likelihood -1.358363
[ Info: iteration 8, average log likelihood -1.357646
[ Info: iteration 9, average log likelihood -1.357215
[ Info: iteration 10, average log likelihood -1.356902
[ Info: iteration 11, average log likelihood -1.356608
[ Info: iteration 12, average log likelihood -1.356261
[ Info: iteration 13, average log likelihood -1.355695
[ Info: iteration 14, average log likelihood -1.354932
[ Info: iteration 15, average log likelihood -1.354237
[ Info: iteration 16, average log likelihood -1.353690
[ Info: iteration 17, average log likelihood -1.353260
[ Info: iteration 18, average log likelihood -1.352914
[ Info: iteration 19, average log likelihood -1.352650
[ Info: iteration 20, average log likelihood -1.352453
[ Info: iteration 21, average log likelihood -1.352310
[ Info: iteration 22, average log likelihood -1.352207
[ Info: iteration 23, average log likelihood -1.352132
[ Info: iteration 24, average log likelihood -1.352076
[ Info: iteration 25, average log likelihood -1.352035
[ Info: iteration 26, average log likelihood -1.352002
[ Info: iteration 27, average log likelihood -1.351975
[ Info: iteration 28, average log likelihood -1.351951
[ Info: iteration 29, average log likelihood -1.351927
[ Info: iteration 30, average log likelihood -1.351901
[ Info: iteration 31, average log likelihood -1.351868
[ Info: iteration 32, average log likelihood -1.351828
[ Info: iteration 33, average log likelihood -1.351775
[ Info: iteration 34, average log likelihood -1.351699
[ Info: iteration 35, average log likelihood -1.351614
[ Info: iteration 36, average log likelihood -1.351559
[ Info: iteration 37, average log likelihood -1.351525
[ Info: iteration 38, average log likelihood -1.351499
[ Info: iteration 39, average log likelihood -1.351479
[ Info: iteration 40, average log likelihood -1.351461
[ Info: iteration 41, average log likelihood -1.351446
[ Info: iteration 42, average log likelihood -1.351434
[ Info: iteration 43, average log likelihood -1.351424
[ Info: iteration 44, average log likelihood -1.351415
[ Info: iteration 45, average log likelihood -1.351408
[ Info: iteration 46, average log likelihood -1.351403
[ Info: iteration 47, average log likelihood -1.351398
[ Info: iteration 48, average log likelihood -1.351393
[ Info: iteration 49, average log likelihood -1.351389
[ Info: iteration 50, average log likelihood -1.351386
┌ Info: EM with 100000 data points 50 iterations avll -1.351386
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3884941178566719
│     -1.3884226559232957
│      ⋮
└     -1.3513858836585342
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.351463
[ Info: iteration 2, average log likelihood -1.351356
[ Info: iteration 3, average log likelihood -1.350409
[ Info: iteration 4, average log likelihood -1.343021
[ Info: iteration 5, average log likelihood -1.328698
[ Info: iteration 6, average log likelihood -1.317698
[ Info: iteration 7, average log likelihood -1.312869
[ Info: iteration 8, average log likelihood -1.310118
[ Info: iteration 9, average log likelihood -1.308268
[ Info: iteration 10, average log likelihood -1.307112
[ Info: iteration 11, average log likelihood -1.306395
[ Info: iteration 12, average log likelihood -1.305925
[ Info: iteration 13, average log likelihood -1.305591
[ Info: iteration 14, average log likelihood -1.305317
[ Info: iteration 15, average log likelihood -1.305067
[ Info: iteration 16, average log likelihood -1.304829
[ Info: iteration 17, average log likelihood -1.304596
[ Info: iteration 18, average log likelihood -1.304371
[ Info: iteration 19, average log likelihood -1.304163
[ Info: iteration 20, average log likelihood -1.303985
[ Info: iteration 21, average log likelihood -1.303851
[ Info: iteration 22, average log likelihood -1.303756
[ Info: iteration 23, average log likelihood -1.303691
[ Info: iteration 24, average log likelihood -1.303644
[ Info: iteration 25, average log likelihood -1.303608
[ Info: iteration 26, average log likelihood -1.303581
[ Info: iteration 27, average log likelihood -1.303559
[ Info: iteration 28, average log likelihood -1.303541
[ Info: iteration 29, average log likelihood -1.303526
[ Info: iteration 30, average log likelihood -1.303513
[ Info: iteration 31, average log likelihood -1.303501
[ Info: iteration 32, average log likelihood -1.303490
[ Info: iteration 33, average log likelihood -1.303480
[ Info: iteration 34, average log likelihood -1.303471
[ Info: iteration 35, average log likelihood -1.303464
[ Info: iteration 36, average log likelihood -1.303456
[ Info: iteration 37, average log likelihood -1.303450
[ Info: iteration 38, average log likelihood -1.303444
[ Info: iteration 39, average log likelihood -1.303439
[ Info: iteration 40, average log likelihood -1.303435
[ Info: iteration 41, average log likelihood -1.303431
[ Info: iteration 42, average log likelihood -1.303428
[ Info: iteration 43, average log likelihood -1.303425
[ Info: iteration 44, average log likelihood -1.303423
[ Info: iteration 45, average log likelihood -1.303420
[ Info: iteration 46, average log likelihood -1.303419
[ Info: iteration 47, average log likelihood -1.303417
[ Info: iteration 48, average log likelihood -1.303416
[ Info: iteration 49, average log likelihood -1.303415
[ Info: iteration 50, average log likelihood -1.303414
┌ Info: EM with 100000 data points 50 iterations avll -1.303414
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.35146308717948
│     -1.3513555604964589
│      ⋮
└     -1.3034136355042039
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.303562
[ Info: iteration 2, average log likelihood -1.303405
[ Info: iteration 3, average log likelihood -1.302832
[ Info: iteration 4, average log likelihood -1.296896
[ Info: iteration 5, average log likelihood -1.278431
[ Info: iteration 6, average log likelihood -1.265946
[ Info: iteration 7, average log likelihood -1.261312
[ Info: iteration 8, average log likelihood -1.259049
[ Info: iteration 9, average log likelihood -1.257543
[ Info: iteration 10, average log likelihood -1.256468
[ Info: iteration 11, average log likelihood -1.255733
[ Info: iteration 12, average log likelihood -1.255238
[ Info: iteration 13, average log likelihood -1.254885
[ Info: iteration 14, average log likelihood -1.254602
[ Info: iteration 15, average log likelihood -1.254314
[ Info: iteration 16, average log likelihood -1.253921
[ Info: iteration 17, average log likelihood -1.253336
[ Info: iteration 18, average log likelihood -1.252480
[ Info: iteration 19, average log likelihood -1.251189
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.249415
[ Info: iteration 21, average log likelihood -1.261556
[ Info: iteration 22, average log likelihood -1.256853
[ Info: iteration 23, average log likelihood -1.255430
[ Info: iteration 24, average log likelihood -1.255016
[ Info: iteration 25, average log likelihood -1.254771
[ Info: iteration 26, average log likelihood -1.254530
[ Info: iteration 27, average log likelihood -1.254249
[ Info: iteration 28, average log likelihood -1.253925
[ Info: iteration 29, average log likelihood -1.253561
[ Info: iteration 30, average log likelihood -1.253149
[ Info: iteration 31, average log likelihood -1.252665
[ Info: iteration 32, average log likelihood -1.252070
[ Info: iteration 33, average log likelihood -1.251305
[ Info: iteration 34, average log likelihood -1.250324
[ Info: iteration 35, average log likelihood -1.249058
[ Info: iteration 36, average log likelihood -1.247543
[ Info: iteration 37, average log likelihood -1.245711
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.243458
[ Info: iteration 39, average log likelihood -1.255497
[ Info: iteration 40, average log likelihood -1.250371
[ Info: iteration 41, average log likelihood -1.248384
[ Info: iteration 42, average log likelihood -1.247572
[ Info: iteration 43, average log likelihood -1.247083
[ Info: iteration 44, average log likelihood -1.246728
[ Info: iteration 45, average log likelihood -1.246468
[ Info: iteration 46, average log likelihood -1.246273
[ Info: iteration 47, average log likelihood -1.246109
[ Info: iteration 48, average log likelihood -1.245940
[ Info: iteration 49, average log likelihood -1.245721
[ Info: iteration 50, average log likelihood -1.245370
┌ Info: EM with 100000 data points 50 iterations avll -1.245370
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3035624976202884
│     -1.3034051707251808
│      ⋮
└     -1.2453704391724605
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.244901
[ Info: iteration 2, average log likelihood -1.243562
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.241423
[ Info: iteration 4, average log likelihood -1.240182
[ Info: iteration 5, average log likelihood -1.219764
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.188184
[ Info: iteration 7, average log likelihood -1.176282
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.166256
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.161447
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.167322
[ Info: iteration 11, average log likelihood -1.159971
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.153041
[ Info: iteration 13, average log likelihood -1.162543
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.152920
[ Info: iteration 15, average log likelihood -1.152601
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.148394
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.148821
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.153006
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.150207
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.156294
[ Info: iteration 21, average log likelihood -1.152709
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.148319
[ Info: iteration 23, average log likelihood -1.149722
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.145856
[ Info: iteration 25, average log likelihood -1.146147
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      5
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.141275
[ Info: iteration 27, average log likelihood -1.161445
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.148131
[ Info: iteration 29, average log likelihood -1.147185
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.142747
[ Info: iteration 31, average log likelihood -1.142924
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      5
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.137761
[ Info: iteration 33, average log likelihood -1.158290
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.145857
[ Info: iteration 35, average log likelihood -1.145220
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.140270
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.140232
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.146206
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.144250
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.150170
[ Info: iteration 41, average log likelihood -1.144990
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.139344
[ Info: iteration 43, average log likelihood -1.150328
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.143293
[ Info: iteration 45, average log likelihood -1.143540
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.138770
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.148893
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.149814
[ Info: iteration 49, average log likelihood -1.146696
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.142110
┌ Info: EM with 100000 data points 50 iterations avll -1.142110
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2449010501465112
│     -1.243562309477763
│      ⋮
└     -1.1421102295390801
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.142227
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.137044
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.139602
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      9
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.122241
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     18
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.085846
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      9
│     10
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.074549
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      5
│      6
│      9
│     10
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.056790
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     18
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.075468
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      5
│      9
│     10
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.062557
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│      9
│     10
│     23
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.064468
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      9
│     10
│     18
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.053688
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      9
│     10
│     15
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.072274
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      6
│      9
│     10
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.058270
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      9
│     10
│     18
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.071346
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│      9
│     10
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.065721
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      6
│      9
│     10
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.068482
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      9
│     10
│     18
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.061797
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     15
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.066430
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      6
│      9
│     10
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.052112
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      4
│      5
│      9
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.069072
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      9
│     10
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.068277
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      5
│      9
│     10
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.052978
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      4
│      6
│      9
│     10
│     18
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.052951
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      9
│     10
│     15
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.069561
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      6
│      9
│     10
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.047125
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│      9
│     10
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.068382
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      9
│     10
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.064709
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.051785
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      4
│      6
│      9
│     10
│     18
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.048331
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.073306
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      9
│     10
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.048836
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.050477
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      9
│     10
│     15
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.065893
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      9
│     10
│     23
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.064020
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      4
│      6
│      9
│     10
│     18
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.045427
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      5
│      9
│     10
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.067850
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      6
│      9
│     10
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.051929
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│      9
│     10
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.060739
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      6
│      9
│     10
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.054801
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      9
│     10
│     23
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.065057
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      6
│      9
│     10
│     18
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.053528
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.064368
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      6
│      9
│     10
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.045945
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      4
│      5
│      9
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.062218
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      9
│     10
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.061665
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      5
│      9
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.047016
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      6
│      9
│     10
│     15
│     18
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.052466
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      9
│     10
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.072046
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      4
│      6
│      ⋮
│     22
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.036483
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      9
│     10
│     18
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.067648
┌ Info: EM with 100000 data points 50 iterations avll -1.067648
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1422265862749832
│     -1.137044017762897
│      ⋮
└     -1.0676478773042573
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3884290222620597
│     -1.3884941178566719
│     -1.3884226559232957
│     -1.3877763513459311
│      ⋮
│     -1.0720457335982647
│     -1.0364827127613756
└     -1.0676478773042573
32×26 Array{Float64,2}:
 -0.0936447   0.193988     0.106364      0.0697892    0.0256117   -0.159731      0.146828    -0.110328     -0.100346     0.172807    -0.0802305    0.118346     0.0247338   -0.00291207  -0.0179413    0.00820312   -0.0166683     0.0312413   -0.0910114    -0.0871792   -0.0831822    0.0594772   -0.136959     0.121224    -0.0419496    0.0113427
  0.0172417   0.192915    -0.122919      0.0771581   -0.00187998   0.0764026     0.092597    -0.25246      -0.01894     -0.146444    -0.027511     0.052366     0.0584006   -0.051202    -0.127615    -0.179617     -0.0490581    -0.130716    -0.00483361    0.134526     0.0169709   -0.0586138    0.0385551   -0.0937095   -0.0983852    0.0257165
  0.148666    0.124965     0.0212915    -0.117427     0.0652518   -0.0233928     5.17321e-5   0.0846607     0.145823     0.163531     0.0177411   -0.124183     0.339542     0.100646     0.103766    -0.0137401     0.00381627    0.00482813   0.199168     -0.0442059   -0.0920431   -0.0256829   -0.21521      0.0635481   -0.221566     0.183828
 -0.137377    0.114357     0.0774937    -0.0449689    0.148408     0.0574692     0.0481301    0.00690102    0.194611     0.0770268   -0.0465245    0.209829    -0.118178     0.018809    -0.0288923   -0.00987464   -0.0647782     0.0746746    0.0374389     0.0667047   -0.0221482   -0.0532695    0.119184     0.14783     -0.0568059   -0.15046
  0.108726   -0.17999     -0.159241      0.0404645    0.0512268   -0.147162      0.181571     0.102292     -0.136969     0.0504062    0.0738899    0.0998288    0.0609064    0.0890719    0.103209    -0.106342      0.000612063   0.201777    -0.000528677   0.105959    -0.0965833   -0.101026    -0.0105073    0.0995303    0.258783    -0.408806
  0.289446   -0.164741    -0.308816      0.00928769  -0.0482437   -0.155559      0.166013     0.0415062    -0.108661     0.0468524    0.0223728   -0.15937      0.0641614    0.0979614    0.0938671   -0.0778676    -0.0418363     0.275041    -0.00116648    0.0253057   -0.103094    -0.144986    -0.0186606    0.101925    -0.384755     1.23647
 -0.0951679  -0.0380509   -0.0560217     0.0518281    0.149137     0.0307209     0.0338944   -0.0476121    -0.0701973   -0.0202582    0.14372     -0.157143    -0.0906389   -0.117964     0.103354    -0.0780019    -0.0400379    -0.127975    -0.206846      0.187947    -0.0200714    0.189031     0.0591659    0.0705668    0.139311     0.046544
 -0.0314684   0.128184     0.0224049    -0.0289307    0.0174187    0.0107006     0.113292     0.128163      0.0648347   -0.016475     0.0990329   -0.0276379    0.0377458   -0.0457988   -0.133287    -0.0281399    -0.261779     -0.0235516   -0.014071      0.0153315   -0.0772987   -0.0650991    0.01459     -0.135482     0.014566    -0.00926995
 -0.487363   -0.00628074  -0.116305     -0.0176642    0.0419332    0.0750624    -0.0229023    0.0742633    -0.0559584    0.0178442    0.101702     0.150414     0.115596    -0.218721    -0.074548    -0.130245     -0.0487642     0.0883447   -0.170807     -0.00197669  -0.00782952  -0.12586      0.0122085   -0.0839544   -0.409272    -0.0738932
  0.86252     0.0437906   -0.115844      0.0914544    0.029134     0.0178861    -0.0382465    0.0740863     0.0649963    0.00302462   0.0762438   -0.0791013   -0.330753     0.157662    -0.0743163   -0.125022     -0.0229114     0.0899638   -0.0991618    -0.0889162   -0.0580237   -0.0741091    0.0292609    0.0221731    0.233415    -0.0220916
 -0.161751   -0.485496     0.225054      0.0243864   -0.0231156    0.233099     -0.0799064   -0.188124     -0.0363758   -0.175011     0.0495903    0.0392571    0.0607547    0.0576235    0.0172827    0.000202232  -0.157703     -0.0338902    0.0112078    -0.265965    -0.0610727   -0.301878     0.125774     0.158027     0.094877    -0.111107
 -0.18868     0.66032      0.233197      0.0463359    0.214299    -0.0427816    -0.0893622   -0.115711      0.0341884   -0.183227     0.0768731    0.0786732    0.0748071    0.0545452   -0.0548012    0.027676     -0.0945072    -0.106405    -0.00661159   -0.091589    -0.330624    -0.0613585    0.0894075    0.151478     0.118521    -0.104821
  0.129877   -0.22237      0.016286     -0.148683     0.0032366   -0.176673      0.145225     0.0620422     0.124647     0.0579992   -0.169407    -0.0591054   -0.138491     0.0407673   -0.0472579   -0.00090376    0.0303749     0.0496955    0.0428551     0.110067    -0.144253    -0.0456187   -0.0363057   -0.0362878   -0.0777782   -0.0344394
  0.0791338  -0.012847     0.108281     -0.0894414   -0.00532525  -0.158364     -0.0728842   -0.00801361    0.0404217    0.105445     0.0755104    0.00292362   0.0353132    0.0407626    0.0219987   -0.111441     -0.0173712     0.0372187   -0.0238856    -0.00713348   0.01947      0.0651864   -0.0268322   -0.013278    -0.0503778    0.0100534
  0.0165877  -0.0383967   -0.124121      0.244871     0.0604794    0.0518544     0.0651714   -0.0641385     0.12687      0.0170509   -0.13691     -0.0997156   -0.0173678    0.0518565    0.020686     0.0368408    -0.0350542     0.0376182   -0.0668258    -0.0306404    0.0328645    0.0413597    0.0995121    0.0998805    0.214178    -0.0106504
 -0.149839   -0.0293204   -0.0952296     0.044729     0.0441442    0.000771751   0.0386709   -0.0383686    -0.0393524    0.0420503   -0.0146416   -0.0683908    0.006124    -0.0128333   -0.113291    -0.125645      0.0339019     0.0328372   -0.0118995    -0.0869944    0.0647672   -0.104321    -0.107771     0.0766826   -0.0332272   -0.111551
 -0.1631      0.035114    -0.000685966   0.0511682    0.0173573    0.209237     -0.0792127    0.0641031    -0.030576     0.0323355    0.0840429   -0.0218812   -0.0246655   -0.0606601    0.11058      0.0499605    -0.0646618     0.309471     0.000732142  -0.278706    -0.0180955   -0.00747385  -0.0224753   -0.090353     0.0521511    0.0532828
 -0.0551755  -0.195365     0.0591724     0.0599822   -0.129086    -0.0945305     0.0125749   -0.0119543    -0.0188761   -0.158808    -0.0343325    0.0367184   -0.134416     0.0216315    0.0974265    0.157094      0.115233      0.046202     0.136108      0.134999    -0.0237529   -0.18867     -0.0592856   -0.265632     0.00915261   0.117044
  0.102398    0.0539898    0.0400777    -0.0428649   -0.12878     -0.135279     -0.0617508   -0.105693     -0.0850611   -0.0167082   -0.0890608   -0.133941    -0.0979537   -0.0571116    0.061743     0.0962698    -0.0375105     0.0109854    0.0541736     0.00724597   0.134153     0.106598    -0.0763995   -0.158022     0.124347     0.0469349
  0.0792033  -0.0732671    0.0957248    -0.0122724   -0.0734342   -0.0943127     0.0531188    0.0753317     0.042031     0.0267674    0.0303557    0.0825234   -0.00641768  -0.0853816    0.0843443   -0.0692887     0.0992892    -0.125927    -0.0555767    -0.0642814    0.0255338    0.0627175    0.00426076   0.023067    -0.0479765    0.0461838
 -0.0878706  -0.0259374    0.00617033   -0.246971    -0.0508138   -0.0134149     0.0380374   -0.0178865     0.0756841    0.0138322    0.0089862   -0.0788451    0.0106151   -0.0188681    0.111848    -0.0914831     0.0344978     0.0342908    0.176849      0.0481776    0.0468546    0.0299259    0.0205957   -0.127798    -0.078788    -0.109681
  0.0812727  -0.18334     -0.0687662    -0.00268944   0.0527521    0.0155078    -0.186195     0.243961     -0.0965937    0.157346    -0.106961     0.0577516   -0.054911    -0.0590631    0.00985176   0.177505     -0.163215      0.0378522    0.0924727     0.209475     0.141712     0.00915552  -0.0180064    0.0861247    0.071715     0.120778
 -0.0177547  -0.113188    -0.0315708     0.14401      0.131949     0.0220401     0.0451017    0.0666796     0.16915     -0.0313442   -0.00875486  -0.101324    -0.129243     0.0969463   -0.236442     0.0613454    -0.00532869   -0.0555772    0.189856     -0.104204    -0.0765758   -0.114244     0.0260243   -0.00836311   0.034993     0.0810473
 -0.0646134   0.0298853    0.0452309     0.0516674   -0.173039    -0.092934     -0.00772089  -0.000938354  -0.148937    -0.029667     0.267785     0.101597    -0.0346629   -0.0928272    0.0593109   -0.0486424     0.0124298    -0.0366566   -0.000349375  -0.111492     0.175123     0.144302    -0.0885458    0.0348612    0.0733759    0.0827249
  0.0259899  -0.00984163  -0.0871136    -0.0740193    0.0137099    0.102552      0.0896335    0.0936005    -0.00651315  -0.366045     0.094012    -0.0883781   -0.142896    -0.0525992    0.118348    -1.00194       0.128131     -0.0696324    0.0113468     0.123442    -0.103981     0.201133    -0.0574384   -0.114553     0.133648    -0.0694647
  0.029196   -0.262489    -0.0688421    -0.0406661    0.954204     0.07408       0.00413935   0.275221      0.212165    -0.509331     0.311155     0.279675    -0.145742    -0.259845    -0.204424     1.03606      -0.337167      0.482736    -0.424214      0.125413    -0.110079     0.236848    -0.037115    -0.110504     0.0647066   -0.0694492
  0.137156   -0.651188     0.0511316    -0.0258351    0.275065     0.0735121    -0.8428       0.337158     -0.0810815    1.2019      -0.0451151    0.62627     -0.140875     0.38632      0.220512    -0.902821     -0.358602     -0.317628    -0.0425646     0.125097     0.088225     0.251031    -0.0590415   -0.129907    -0.0800112   -0.0694196
  0.0889938  -0.00110852  -0.0394164    -0.0575643   -0.151813     0.0959        0.0363694    0.128395      0.00795686   0.248843     0.0463051   -0.0925739   -0.143937    -0.154286     0.0719895    0.901401      0.178264     -0.26038      0.110231      0.123798    -0.129244     0.127461    -0.0510127   -0.122085     0.0760134   -0.069408
 -0.100902    0.192056     0.137959      0.0857326   -0.0502572    0.0844593     0.130038    -0.0540992     0.136831     0.00482473  -0.102889    -0.0991572    0.0205684   -0.102529    -0.00141712   0.0797887    -0.0631916    -0.00108847  -0.0687599     0.146549     0.0822517   -0.0547043    0.128153    -0.0539073    0.0929974    0.0016532
  0.130462    0.0462711    0.0045827    -0.00771359   0.0697219   -0.070908      0.0670092    0.0985011     0.0324725   -0.085479    -0.0776156   -0.083201    -0.0564121    0.119893    -0.0179742    0.132578     -0.00973304   -0.172662     0.034386     -0.188454     0.035433    -0.0709154    0.0477662    0.0116159   -0.0874936   -0.0495254
 -0.05223     0.0631639   -0.119395      0.161095     0.0408665    0.127277      0.222053     0.168806      0.127824     0.120578    -0.0495428    0.17343      0.0172073    0.0902224   -0.160093     0.0170474    -0.0410424    -0.0440397    0.108473     -0.0582094    0.0351397   -0.101658     0.121096    -0.0133264    0.0964086   -0.00268655
 -0.116704   -0.0589695   -0.00449153    0.106987    -0.0338573    0.020932      0.0655225   -0.00973617    0.124365    -0.137864    -0.0447802   -0.0477098    0.0267438    0.131094    -0.0818244   -0.261366      0.0902899     0.127056     0.178464     -0.0892622   -0.0855331   -0.0321776   -0.150012    -0.0917735    0.00449406  -0.122578[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      6
│      9
│     10
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.054193
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.031244
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      6
│      9
│     10
│     18
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.042393
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.036502
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      6
│      9
│     10
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.047985
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.025437
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      6
│      9
│     10
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.053560
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.031385
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      6
│      9
│     10
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.053476
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      4
│      6
│      ⋮
│     27
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.031481
┌ Info: EM with 100000 data points 10 iterations avll -1.031481
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.315263e+05
      1       6.559075e+05      -1.756187e+05 |       32
      2       6.316496e+05      -2.425795e+04 |       32
      3       6.163601e+05      -1.528949e+04 |       32
      4       6.054481e+05      -1.091196e+04 |       32
      5       5.977271e+05      -7.721036e+03 |       32
      6       5.928379e+05      -4.889177e+03 |       32
      7       5.891371e+05      -3.700832e+03 |       32
      8       5.866866e+05      -2.450505e+03 |       32
      9       5.847386e+05      -1.948017e+03 |       32
     10       5.830673e+05      -1.671322e+03 |       32
     11       5.820189e+05      -1.048316e+03 |       32
     12       5.815216e+05      -4.973218e+02 |       32
     13       5.811501e+05      -3.715318e+02 |       32
     14       5.807520e+05      -3.981224e+02 |       32
     15       5.803312e+05      -4.207721e+02 |       32
     16       5.799256e+05      -4.056184e+02 |       32
     17       5.795071e+05      -4.184427e+02 |       32
     18       5.789745e+05      -5.326628e+02 |       32
     19       5.782356e+05      -7.388631e+02 |       32
     20       5.773475e+05      -8.881371e+02 |       32
     21       5.768010e+05      -5.464568e+02 |       32
     22       5.766231e+05      -1.778647e+02 |       32
     23       5.765681e+05      -5.501435e+01 |       32
     24       5.765409e+05      -2.718478e+01 |       30
     25       5.765222e+05      -1.876228e+01 |       31
     26       5.765099e+05      -1.231862e+01 |       28
     27       5.764986e+05      -1.129109e+01 |       29
     28       5.764849e+05      -1.369560e+01 |       31
     29       5.764736e+05      -1.131205e+01 |       30
     30       5.764631e+05      -1.051016e+01 |       29
     31       5.764532e+05      -9.836487e+00 |       31
     32       5.764430e+05      -1.018016e+01 |       29
     33       5.764335e+05      -9.551803e+00 |       28
     34       5.764240e+05      -9.529296e+00 |       31
     35       5.764146e+05      -9.341470e+00 |       30
     36       5.764072e+05      -7.395095e+00 |       30
     37       5.763995e+05      -7.720875e+00 |       27
     38       5.763931e+05      -6.433700e+00 |       27
     39       5.763879e+05      -5.186627e+00 |       24
     40       5.763821e+05      -5.793730e+00 |       27
     41       5.763756e+05      -6.505123e+00 |       27
     42       5.763686e+05      -6.935520e+00 |       23
     43       5.763644e+05      -4.245113e+00 |       25
     44       5.763596e+05      -4.840198e+00 |       21
     45       5.763555e+05      -4.102470e+00 |       27
     46       5.763504e+05      -5.023509e+00 |       26
     47       5.763452e+05      -5.214129e+00 |       22
     48       5.763403e+05      -4.920874e+00 |       25
     49       5.763336e+05      -6.716019e+00 |       28
     50       5.763269e+05      -6.726425e+00 |       25
K-means terminated without convergence after 50 iterations (objv = 576326.8555455867)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.302829
[ Info: iteration 2, average log likelihood -1.275912
[ Info: iteration 3, average log likelihood -1.251092
[ Info: iteration 4, average log likelihood -1.215948
[ Info: iteration 5, average log likelihood -1.163054
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     12
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.105099
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.113333
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.091150
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.063490
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      8
│     12
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.063619
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.103848
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.073100
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.078133
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     12
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.055583
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.081331
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     2
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.062553
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     11
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.041932
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     12
│     15
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.046140
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.073618
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.070649
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      7
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.023000
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│     10
│     11
│     12
│     15
│     20
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.027938
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.116974
[ Info: iteration 24, average log likelihood -1.070790
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      7
│     12
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.009653
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     10
│     11
│     15
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.050074
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.102596
[ Info: iteration 28, average log likelihood -1.063894
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      7
│     10
│     12
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.002772
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     15
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.064903
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      5
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.091276
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.064303
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     10
│     12
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.023797
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     15
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.060412
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.086885
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.036829
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     10
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.040337
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     15
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.059097
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.088963
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     10
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.037337
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      5
│     12
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.037467
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     15
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.058080
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.085678
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     10
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.033291
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     12
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.038489
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     11
│     15
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.046972
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.089033
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     10
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.036291
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     12
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.041244
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     15
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.048168
┌ Info: EM with 100000 data points 50 iterations avll -1.048168
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0161389  -0.12436    -0.0272498    0.166915     0.107691    0.0207674    0.0399654     0.0645696    0.206418    -0.0219187   -0.019532    -0.11986     -0.112226     0.115311    -0.236129     0.0630273    -0.00215057  -0.06995       0.150832     -0.108587    -0.0567146   -0.124669     0.0745606   -0.0332012    0.0286034    0.0918368
 -0.0664725   0.069568   -0.114325     0.161595     0.0319207   0.15844      0.216181      0.155976     0.138738     0.107238    -0.0576807    0.177174     0.0135734    0.102145    -0.170481     0.0287617    -0.0420025   -0.0473106     0.107456     -0.0772573    0.0334966   -0.103914     0.10981      0.00833563   0.106284     0.00113082
 -0.0457695  -0.0488233  -0.1546       0.374429     0.0873938   0.13825      0.0413121    -0.0734421    0.137703     0.00543351  -0.149368    -0.163277    -0.0106827    0.0424916    0.0190862    0.0819956    -0.00999084  -0.0128497    -0.0798919    -0.0734844    0.0578524    0.0771865    0.0474777    0.134867     0.29226     -0.00986564
  0.18285    -0.136212    0.213633    -0.0319972    0.273535   -0.106603    -0.244356      0.0308207    0.00711095   0.111163     0.161522     0.062495     0.165455     0.0262111    0.163334    -0.214204      0.0637318    0.1449        0.0750532     0.212445     0.0263577    0.0222214   -0.0808574   -0.0113764   -0.0921706    0.108646
 -0.133337    0.0688702   0.115886    -0.0630777   -0.0336397  -0.236363    -0.0833589    -0.0710037    0.0445643    0.0823622    0.155283    -0.100505     0.0482766    0.166584    -0.222053     0.0666351    -0.0191979    0.117277     -0.0867522    -0.17244      0.00716121   0.0254166   -0.0798749    0.0813858    0.0615901   -0.0906644
  0.0472764  -0.274794   -0.0103705    0.00194192  -0.0304798  -0.155985     0.253901      0.133447     0.148199     0.0326482   -0.226872    -0.0801886   -0.0816121   -0.00186893  -0.221366     0.0166499     0.0458187   -0.0858863    -0.00322956    0.0617232   -0.181869     0.020464    -0.0264986   -0.19336     -0.238847    -0.00873726
 -0.0623466   0.160807    0.0849859    0.0710662    0.0165247  -0.155432     0.126284     -0.0929972   -0.110197     0.161046    -0.0951273    0.113936     0.021369    -0.00711293  -0.0265975    0.0441866    -0.00748647   0.0325654    -0.0818489    -0.0597539   -0.0599054    0.0527181   -0.128068     0.113717    -0.0517607    0.0106562
 -0.0921602  -0.037544   -0.0560472    0.0516096    0.149551    0.0315515    0.035149     -0.0461358   -0.0698036   -0.020785     0.143517    -0.158917    -0.0894777   -0.118732     0.104459    -0.0753085    -0.0412076   -0.131822     -0.207309      0.181439    -0.0161482    0.184865     0.0616388    0.068635     0.136964     0.0467411
 -0.146664   -0.0379661  -0.109055     0.0527764    0.0554702   0.0138644    0.0399077    -0.0245708   -0.0220166    0.0366377   -0.00748598  -0.0844974   -0.0105871   -0.0116987   -0.127462    -0.109062      0.0322293    0.0190001     0.0101274    -0.0882148    0.0506723   -0.107675    -0.107181     0.0711725   -0.02202     -0.10334
  0.150502    0.0396974  -0.00283082  -0.0202271    0.0622741  -0.0159395    0.0804774     0.101246     0.0245211   -0.076755    -0.0641863   -0.0651672   -0.0894443    0.112133     0.0203809    0.133347      0.00261364  -0.215579      0.0554128    -0.093732    -0.00136129  -0.0295134    0.0347336   -0.0291376   -0.0599361   -0.0545636
  0.109578    0.0165194  -0.11623      0.0286541    0.0360268   0.0515482   -0.0325474     0.0747286   -0.00563953   0.0121394    0.0869677    0.0466448   -0.0785669   -0.0492494   -0.0744201   -0.127556     -0.0375794    0.0877322    -0.138294     -0.0388331   -0.0281105   -0.104853     0.0179947   -0.0369349   -0.125582    -0.0507655
  0.0826852  -0.186169   -0.0628419   -0.00252934   0.0417099   0.00627109  -0.139867      0.21543     -0.108572     0.145073    -0.114471     0.0690352   -0.0593531   -0.0838909    0.0167794    0.175238     -0.181562     0.0301057     0.0952762     0.264153     0.114193     0.00631978   0.0143407    0.085701     0.0889408    0.159238
 -0.0822481  -0.336274    0.0236279   -0.268002    -0.053552    0.157086     0.0621036    -0.0119906   -0.15366      0.0578768   -0.15234     -0.0633608    0.0292662    0.350572     0.114084     0.0203629     0.141671     0.000179244   0.0446577     0.191173     0.287462     0.119226     0.030821    -0.102919    -0.0760876   -0.114206
  0.014519    0.081105   -0.0377595    0.0186195   -0.0235752  -0.0685968    0.0459197     0.120021    -0.018346    -0.0649797    0.00821743   0.0518422    0.0819848   -0.0580695   -0.232836    -0.000803397  -0.285306    -0.0412395    -0.0440702     0.0812746   -0.114573    -0.0287035    0.102059    -0.0557134    0.0482832   -0.0821005
  0.153569   -0.178118   -0.196951     0.0316645    0.0304295  -0.147969     0.180098      0.0877071   -0.127378     0.0502345    0.0617956    0.0322212    0.0611199    0.0924224    0.103323    -0.100552     -0.00505637   0.221119     -0.000254189   0.0887004   -0.0969336   -0.108591    -0.0143429    0.104093     0.102018    -0.00417317
  0.144986    0.0636806  -0.026823    -0.166646    -0.252199   -0.107755     0.107534      0.049822     0.0930773    0.116251    -0.0632826    0.0180478   -0.12111     -0.0720927    0.153       -0.171829     -0.0937978   -0.196536     -0.0382319    -0.1295       0.0639578    0.156375    -0.00441353  -0.12179     -0.094383     0.00167851
 -0.108135   -0.0810515   0.0296838    0.0561381   -0.0528714   0.0540403   -0.0318581     0.0265866   -0.024917    -0.0626974    0.0232307    0.00881189  -0.0777757   -0.016616     0.10446      0.105458      0.0234036    0.172677      0.0741977    -0.0714921   -0.0216664   -0.102726    -0.0423193   -0.177913     0.0316388    0.0836052
 -0.100964    0.191315    0.137662     0.0851671   -0.0490904   0.0835619    0.127538     -0.053325     0.136526     0.00535701  -0.104103    -0.099411     0.0195886   -0.101345    -0.00327979   0.0794413    -0.0631326   -0.000211967  -0.0691174     0.14649      0.082273    -0.0553195    0.12766     -0.0535995    0.0934529    0.00142923
 -0.0874566   0.0284835   0.00231939  -0.243511    -0.0499228  -0.0440412    0.0313634    -0.0179939    0.117024     0.00777845   0.0378842   -0.0804867    0.00661337  -0.0913742    0.111699    -0.111365      0.0156146    0.0397067     0.203545      0.0237227    0.00548434   0.0124837    0.0179456   -0.131961    -0.0786481   -0.106087
 -0.154498    0.113945    0.0773591   -0.035497     0.161916    0.0649568    0.0466777     0.0081066    0.1965       0.0752298   -0.0481615    0.221381    -0.127094     0.0134565   -0.0407869   -0.00887841   -0.0629759    0.0594289     0.039233      0.0746434   -0.016073    -0.0538901    0.127628     0.164502    -0.0538461   -0.165455
  0.211599   -0.160461    0.0639545   -0.293128     0.0416982  -0.180345     0.0582719    -0.00627035   0.116737     0.0675937   -0.153806    -0.0381261   -0.182014     0.0902981    0.12005     -0.00866043    0.0171041    0.227586      0.0652082     0.151644    -0.110755    -0.0601344   -0.0816088    0.124992     0.0728446   -0.0722619
  0.182369   -0.0842572   0.0388365   -0.343042     0.0390953  -0.205948    -0.000440953   0.0866368    0.129371     0.213841     0.075204    -0.0658671   -0.240515     0.0233617    0.148747    -0.0693403     0.132972    -0.176013      0.247355      0.132133    -0.0613277   -0.347119     0.076969     0.0758572    0.0706263   -0.0284234
  0.193759   -0.0296896  -0.0388756   -0.028258    -0.049624   -0.131562     0.0909651    -0.0376378    0.0571244    0.033611    -0.114274     0.085689    -0.0397964    0.0658585    0.0192615   -0.0597273    -0.095692     0.234124     -0.0251313     0.0879316   -0.0394257   -0.0355706    0.303889    -0.00143264   0.00481736  -0.0126316
 -0.0599606   0.0142104   0.0419053    0.0564397   -0.149119   -0.0869737   -0.00412992    0.00394993  -0.133426    -0.0289876    0.252247     0.100812    -0.0399541   -0.0841914    0.0391373   -0.0417448     0.0114694   -0.0368191     0.0118255    -0.110226     0.157053     0.124594    -0.0825223    0.0424685    0.0720693    0.0809446
  0.100624    0.045587    0.036414    -0.038772    -0.122398   -0.13142     -0.0711142    -0.0969214   -0.0861386   -0.00937568  -0.0900242   -0.129604    -0.0962044   -0.0580806    0.0619151    0.103018     -0.0413681    0.0117497     0.059892     -0.00453996   0.136979     0.108914    -0.0764201   -0.15219      0.124871     0.0514545
 -0.113187   -0.0591703  -0.00458349   0.105725    -0.0306129   0.0208674    0.0647951    -0.0068923    0.123218    -0.136807    -0.0452116   -0.0472437    0.0266426    0.130785    -0.0804084   -0.256177      0.0904231    0.125401      0.178094     -0.0880561   -0.0840097   -0.0312562   -0.147872    -0.0907292    0.00429881  -0.120971
 -0.17591     0.120443    0.229267     0.0358845    0.103378    0.0869228   -0.0846063    -0.149588     0.00046759  -0.179303     0.0642881    0.0600376    0.0677489    0.0560258   -0.0205265    0.0145958    -0.124031    -0.0713646     0.00157586   -0.173537    -0.203263    -0.17492      0.106647     0.15452      0.107285    -0.107775
  0.0328886  -0.111554   -0.0788112   -0.0718537   -0.0125487   0.0900961   -0.0282108     0.131421     0.015636     0.0153139    0.0659331   -0.0300645   -0.140533    -0.162785     0.126912    -0.108149      0.127604    -0.126426      0.02887       0.117207    -0.122176     0.204968    -0.0436615   -0.109724     0.0994513   -0.0673667
  0.0138921   0.193567   -0.11813      0.0674424    0.0160568   0.0568384    0.0941398    -0.252132    -0.0253107   -0.132638    -0.0336342    0.0649591    0.0547666   -0.0432732   -0.124382    -0.212668     -0.0447405   -0.134143     -0.00913719    0.127803     0.00908532  -0.0558852    0.0423078   -0.0674197   -0.0889959    0.0267528
 -0.0885716   0.170938    0.0826626   -0.0564557    0.0922084   0.0886303    0.171724      0.129276     0.121761     0.0248499    0.204472    -0.117092    -0.00492825  -0.0244823   -0.0730257   -0.0341774    -0.230939     0.055077      0.01309      -0.027525    -0.0461446   -0.11162     -0.0642817   -0.203029    -0.00826665   0.0604632
  0.136167    0.119889    0.0220668   -0.112742     0.0692418  -0.0227941    0.00198936    0.0800399    0.139387     0.158376     0.0120697   -0.0947126    0.306034     0.0975309    0.10351     -0.0121129    -0.00536654   0.0205548     0.183531     -0.0406582   -0.0876778   -0.0322719   -0.201458     0.0643247   -0.215388     0.159304
  0.0747556  -0.0766687   0.0774551   -0.00742069  -0.0658549  -0.0886704    0.0428715     0.0872649    0.0353019    0.0306422    0.0243008    0.0808479   -0.0108819   -0.0908992    0.0862983   -0.0630254     0.0827209   -0.112433     -0.0556324    -0.0524505    0.0330278    0.0611801    0.00532709   0.0233431   -0.0433593    0.0525951[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      5
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.077866
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      5
│      7
│     10
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.016855
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      5
│      7
│      ⋮
│     20
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.990526
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      5
│      7
│     10
│     15
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.038813
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      5
│      7
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.033183
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      5
│      7
│      ⋮
│     20
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.991963
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     5
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.050707
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      5
│      7
│     10
│     15
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.994587
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      3
│      5
│      7
│      ⋮
│     20
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.015218
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      5
│      7
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.054273
┌ Info: EM with 100000 data points 10 iterations avll -1.054273
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0309569  -0.0304534    0.00573634  -0.219851    -0.0108342     0.0237165    0.0745895   -0.0800641   -0.0131497    0.0072225     0.0434241   -0.0130769   -0.026282     0.118868   -0.0253409   -0.137876    -0.188279   -0.00923835   0.0623722    -0.186357    -0.0337612   0.0767876    0.0907371    0.406561    -0.0272289    0.00359035
 -0.0624482   0.0305756    0.0298477    0.00403514   0.0513033     0.245291    -0.166173     0.0769176   -0.0901216    0.0466761    -0.0620712    0.107095    -0.115031     0.0104439  -0.10268      0.285866    -0.0395544   0.149262    -0.0455559    -0.0736809   -0.0136542  -0.160693     0.0514114   -0.151672    -0.0768352    0.0232889
 -0.0573545  -0.136757    -0.141734     0.266653    -0.149114      0.192949     0.102033     0.238053     0.0266963    0.135058      0.0405217   -0.0182494    0.0622717    0.210628    0.207317     0.0567136    0.0112903  -0.080704    -0.101253      0.0980271    0.0693694   0.0172521    0.0298067    0.0285648    0.0130736   -0.018198
  0.212489   -0.107703    -0.0583176   -0.0150794    0.141019      0.0310188   -0.260019    -0.0162012   -0.0533858   -0.000809256   0.165108    -0.0522558    0.154997     0.0504765   0.0078525   -0.225092    -0.0900946   0.0871223   -0.000124142  -0.0436736   -0.218513   -0.0154267   -0.0406854    0.0114389   -0.11998      0.0107732
  0.0324168   0.0708638    0.128564     0.0324792   -0.0122776     0.108987     0.00556062   0.0156178   -0.00587833   0.0590997    -0.0183853    0.115201    -0.109671     0.155076   -0.119536    -0.336819     0.0197366  -0.184505    -0.026178     -0.0246963   -0.0353529  -0.0332848    0.209567     0.0351321    0.0375675   -0.0620944
 -0.102443   -0.110612     0.0326358    0.0229049   -0.118745     -0.173161    -0.0918743    0.111639     0.107722     0.205334      0.170546    -0.0248558   -0.0195075    0.0965122  -0.0822992    0.109873     0.0709071  -0.130622     0.0731912     0.0342945   -0.0692435   0.0756708    0.0371614   -0.0143895   -0.102676     0.0138372
 -0.180626   -0.161046    -0.162955    -0.126645     0.0445821    -0.190444    -0.0569836    0.201205     0.00571895   0.229395      0.00132799   0.0360818    0.117336    -0.0427637  -0.177947     0.050379     0.117816    0.0396805   -0.0703828     0.0657626    0.0437351   0.140675     0.07643      0.0638724   -0.0226308   -0.062851
 -0.0141731   0.027733    -0.0402648    0.0150923   -0.241065      0.245676     0.141741    -0.184367     0.0546402    0.147322      0.0873528   -0.00247847   0.0467942    0.243737    0.0400823    0.0897427   -0.0913396  -0.00170243  -0.188375     -0.106636     0.0547391  -0.126606     0.0859331    0.0153486    0.189541     0.0865874
  0.0251635   0.066705     0.0366834   -0.108581    -0.145352     -0.119197    -0.00535852  -0.0661428    0.0894066    0.0882974     0.0590991   -0.105866    -0.152122     0.0895576   0.104029    -0.0503786    0.0156364  -0.214278     0.0140705    -0.0855134    0.0902624  -0.0676616   -0.143974    -0.0276512    0.0221357    0.00614684
 -0.121779    0.0674289   -0.0577111    0.0945253    0.0681817    -0.0874284    0.0914507   -0.065179     0.0543516   -0.0497092    -0.0942515   -0.122937     0.0315667   -0.0601102   0.0308832   -0.0669285    0.207695   -0.0848845    0.0282631     0.0486696    0.0404902  -0.0311734    0.0102701   -0.0476274    0.0244622   -0.161692
 -0.0168446  -0.0826359   -0.0784634   -0.182684     0.00993614   -0.0906275    0.156902    -0.181542    -0.0164172   -0.0258655     0.0483748    0.0971862   -0.0268292    0.0212408   0.170415    -0.0733182   -0.167624   -0.062202    -0.082429     -0.0864932    0.105697    0.0168288   -0.0172236   -0.0468829    0.00241657   0.162445
  0.258017   -0.085174    -0.0239594   -0.0596075    0.0614068    -0.156345     0.0173652    0.00023062  -0.0890936    0.00915766   -0.0319062    0.120861    -0.0363782    0.0304999  -0.0402198    0.0115783   -0.0936877   0.0703293    0.0114743     0.086288    -0.0823926   0.0605076   -0.00541804  -0.140709    -0.00791042   0.0218164
 -0.0201307  -0.205162    -0.0290554   -0.166941    -0.00560383   -0.270393    -0.0570324    0.00229337  -0.0529181    0.175989      0.158783     0.00519566  -0.0118511    0.0396895   0.141478     0.0350574    0.0618557   0.106694     0.0276941     0.0450169   -0.192355    0.0138077   -0.0396272    0.100238    -0.180717     0.0339647
 -0.149085    0.0680015    0.0272852    0.0157743    0.127982     -0.0982642    0.129163    -0.0393024    0.1993      -0.00375661    0.0149682    0.0315236    0.0730361   -0.242322    0.00580976  -0.101476     0.192822    0.048927     0.00300796   -0.0492503    0.0688054  -0.0761654    0.108543     0.00365299  -0.0845739    0.017486
 -0.0973491   0.0358762   -0.097632     0.0686286    0.0241813     0.0705047   -0.0233229    0.244911    -0.0832012    0.10322       0.0561031    0.0809449    0.228277    -0.0671169  -0.0587691   -0.0119219   -0.163613   -0.0329365    0.0519181    -0.114701    -0.0484754   0.00325728  -0.00929039   0.0674288    0.212583     0.0424335
 -0.0415761  -0.0152763   -0.0159985   -0.0509986   -0.129746      0.233436    -0.0882547   -0.0383989    0.0647576   -0.0716462    -0.0164008   -0.0816047    0.151025     0.0242265  -0.133161     0.0599643   -0.107228   -0.0461879   -0.0643961    -0.0231647    0.0342277  -0.173043    -0.0774841   -0.135432     0.0588046   -0.0531906
 -0.0682183  -0.191103    -0.0296171   -0.0688161   -0.0484909    -0.0684245    0.210725     0.149234     0.0739861    0.141122     -0.109587     0.077698    -0.061558    -0.0192025  -0.276803    -0.0108808   -0.0895668  -0.135423     0.0946719     0.0565663    0.0997182   0.00216262  -0.00311135  -0.156737    -0.0235286    0.0918996
 -0.0480738  -0.00505756   0.117507    -0.0392334   -0.0593231     0.0145395   -0.00539197  -0.0514071    0.0970409   -0.0876381    -0.210929    -0.035304    -0.0270681    0.125685    0.221098    -0.0643233   -0.0270056   0.0283139    0.0804515    -0.0537171    0.183413    0.0206756    0.18342     -0.0105534    0.073173    -0.00665597
  0.075383   -0.11498     -0.0178884    0.0162939    0.0703481    -0.0317741   -0.0304026   -0.0664698   -0.0223349    0.174405     -0.0907065    0.06285      0.0400678   -0.0742044  -0.0665538    0.0605393    0.0231713  -0.0245476    0.104083     -0.0966006   -0.0607762  -0.210195    -0.061785    -0.0296246   -0.194051    -0.0280666
 -0.0432023   0.0141207    0.113558    -0.0429178    0.0421242     0.0282196    0.240929    -0.0506365    0.111084    -0.157789     -0.0911698   -0.130558    -0.00281047  -0.118545   -0.190161    -0.0561656    0.0911738   0.165207    -0.0575713     0.202604    -0.172402   -0.0902531    0.189306    -0.0992763    0.0658519   -0.0279594
 -0.112269    0.0397693   -0.104173     0.159576     0.156842     -0.036387     0.00170768  -0.150153     0.247265     0.0850189     0.111826     0.0925929    0.0361508   -0.0199979   0.0645821   -0.0606495    0.0797915  -0.0528678   -0.0157311     0.161177     0.152462   -0.116001     0.00230847   0.0276367    0.114316    -0.0423297
 -0.0721733   0.00735824   0.0110823   -0.0111488   -0.000530599  -0.179971     0.0632173   -0.0217762    0.0774686    0.0333668    -0.0318309   -0.110837    -0.131377     0.232165   -0.110907    -0.0405154    0.120849   -0.211375     0.0285036    -0.0276239   -0.130461   -0.177198    -0.110683    -0.0380258    0.11482     -0.0701918
  0.0021101  -0.0268535   -0.0157991    0.131686     0.0113149     0.0623166    0.123675    -0.101404     0.14873      0.142714      0.128242     0.0823644   -0.0812552    0.0398355   0.165313     0.197093    -0.0159064   0.0299971    0.057022      0.0685084   -0.0556717   0.0649617   -0.027396    -0.134819     0.101423    -0.132538
 -0.0190481   0.0786602    0.0286404   -0.0805994    0.00690443    0.159478     0.145292    -0.019215    -0.103889     0.0958215    -0.0466206    0.0582436    0.10335      0.206659    0.0806902    0.0108736    0.182       0.0211378   -0.0232477     0.103824    -0.0279591  -0.0596347   -0.145446    -0.0627162    0.0416555   -0.137959
 -0.0476582  -0.0544241   -0.0132521   -0.120206     0.0688145     0.157509    -0.0615445   -0.0187278   -0.0810118   -0.0423307     0.142344     0.0357272    0.0259668    0.0827392   0.224186    -0.0200066   -0.126926    0.0581349    0.187607     -0.107102     0.146664    0.0610983   -0.0379096    0.0276614   -0.0635343    0.10568
  0.0444258   0.016326     0.0385293   -0.0985924   -0.0848856     0.0545523    0.0258576    0.102937     0.00831366  -0.0448882    -0.0124624    0.0142779    0.0127599   -0.19578    -0.154103     0.0673912   -0.0893053  -0.0595242   -0.143379      0.0838124    0.0830023   0.0833365    0.123131     0.0976912    0.00651148  -0.0753499
 -0.111356    0.244654     0.00766151  -0.107222     0.136531     -0.104858    -0.0568687   -0.027186    -0.0128033    0.066591      0.0645987   -0.180733     0.0689634    0.020519    0.0577878    0.00606319  -0.0852237   0.0646398    0.0260747    -0.00552905   0.106756    0.082214     0.179394     0.14222     -0.104083    -0.119794
 -0.0806507   0.170886     0.105487     0.0512449   -0.0407674     0.104223    -0.0110754    0.0149499    0.015343    -0.0932095    -0.102633     0.0796981   -0.0670047    0.0539341  -0.095262     0.145293    -0.0487141  -0.074825    -0.088098      0.00414623   0.114795    0.00436877   0.0526586   -0.0928141    0.213441    -0.0254947
 -0.177265   -0.219461     0.155167     0.163793    -0.0360641     0.220071    -0.043455     0.0885443    0.128729     0.0197059    -0.0639972    0.029008    -0.0358817   -0.0781887  -0.0558437   -0.0384292    0.137363    0.170394     0.0347878     0.0186619   -0.089093   -0.123668    -0.0887834    0.166484     0.045383     0.0556775
  0.06599    -0.12231      0.0199363   -0.14284     -0.0034707    -0.0382553   -0.052255    -0.0138507   -0.132778    -0.101542      0.0202086    0.0401323   -0.0813098    0.0600057   0.0746617   -0.111278     0.0772858   0.0315365   -0.0305019     0.0302651   -0.0356955  -0.03184     -0.00338757   0.0546806   -0.00111758  -0.0721715
 -0.18435     0.0863106   -0.0879934    0.0273996   -0.229309      0.00900613  -0.105361    -0.0433945    0.0020035   -0.0384214    -0.0132191    0.0600375    0.023287     0.110785   -0.0718562   -0.154419     0.0541253  -0.0520415   -0.112707     -0.00273861   0.0657875  -0.0982877   -0.0393928    0.196642     0.0936542    0.092297
  0.0131502   0.0832812    0.163749    -0.219275    -0.0206082    -0.0819729    0.0479187   -0.0516221    0.0130198    0.0308294    -0.0792639   -0.0548698   -0.240964    -0.122093   -0.0147257    0.149944    -0.0200989  -0.0814517   -0.157924     -0.0702778    0.002453   -0.149425    -0.0901375   -0.0417766    0.033916    -0.0688194kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4196267166412138
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419646
[ Info: iteration 2, average log likelihood -1.419570
[ Info: iteration 3, average log likelihood -1.419504
[ Info: iteration 4, average log likelihood -1.419421
[ Info: iteration 5, average log likelihood -1.419311
[ Info: iteration 6, average log likelihood -1.419155
[ Info: iteration 7, average log likelihood -1.418909
[ Info: iteration 8, average log likelihood -1.418479
[ Info: iteration 9, average log likelihood -1.417741
[ Info: iteration 10, average log likelihood -1.416677
[ Info: iteration 11, average log likelihood -1.415563
[ Info: iteration 12, average log likelihood -1.414770
[ Info: iteration 13, average log likelihood -1.414366
[ Info: iteration 14, average log likelihood -1.414196
[ Info: iteration 15, average log likelihood -1.414129
[ Info: iteration 16, average log likelihood -1.414102
[ Info: iteration 17, average log likelihood -1.414092
[ Info: iteration 18, average log likelihood -1.414087
[ Info: iteration 19, average log likelihood -1.414085
[ Info: iteration 20, average log likelihood -1.414084
[ Info: iteration 21, average log likelihood -1.414084
[ Info: iteration 22, average log likelihood -1.414083
[ Info: iteration 23, average log likelihood -1.414083
[ Info: iteration 24, average log likelihood -1.414083
[ Info: iteration 25, average log likelihood -1.414082
[ Info: iteration 26, average log likelihood -1.414082
[ Info: iteration 27, average log likelihood -1.414082
[ Info: iteration 28, average log likelihood -1.414082
[ Info: iteration 29, average log likelihood -1.414082
[ Info: iteration 30, average log likelihood -1.414081
[ Info: iteration 31, average log likelihood -1.414081
[ Info: iteration 32, average log likelihood -1.414081
[ Info: iteration 33, average log likelihood -1.414081
[ Info: iteration 34, average log likelihood -1.414081
[ Info: iteration 35, average log likelihood -1.414081
[ Info: iteration 36, average log likelihood -1.414081
[ Info: iteration 37, average log likelihood -1.414081
[ Info: iteration 38, average log likelihood -1.414081
[ Info: iteration 39, average log likelihood -1.414081
[ Info: iteration 40, average log likelihood -1.414081
[ Info: iteration 41, average log likelihood -1.414081
[ Info: iteration 42, average log likelihood -1.414080
[ Info: iteration 43, average log likelihood -1.414080
[ Info: iteration 44, average log likelihood -1.414080
[ Info: iteration 45, average log likelihood -1.414080
[ Info: iteration 46, average log likelihood -1.414080
[ Info: iteration 47, average log likelihood -1.414080
[ Info: iteration 48, average log likelihood -1.414080
[ Info: iteration 49, average log likelihood -1.414080
[ Info: iteration 50, average log likelihood -1.414080
┌ Info: EM with 100000 data points 50 iterations avll -1.414080
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4196458593824306
│     -1.4195697216294887
│      ⋮
└     -1.4140802949927003
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414096
[ Info: iteration 2, average log likelihood -1.414039
[ Info: iteration 3, average log likelihood -1.413994
[ Info: iteration 4, average log likelihood -1.413944
[ Info: iteration 5, average log likelihood -1.413884
[ Info: iteration 6, average log likelihood -1.413813
[ Info: iteration 7, average log likelihood -1.413733
[ Info: iteration 8, average log likelihood -1.413648
[ Info: iteration 9, average log likelihood -1.413565
[ Info: iteration 10, average log likelihood -1.413488
[ Info: iteration 11, average log likelihood -1.413422
[ Info: iteration 12, average log likelihood -1.413369
[ Info: iteration 13, average log likelihood -1.413327
[ Info: iteration 14, average log likelihood -1.413295
[ Info: iteration 15, average log likelihood -1.413270
[ Info: iteration 16, average log likelihood -1.413250
[ Info: iteration 17, average log likelihood -1.413233
[ Info: iteration 18, average log likelihood -1.413219
[ Info: iteration 19, average log likelihood -1.413205
[ Info: iteration 20, average log likelihood -1.413193
[ Info: iteration 21, average log likelihood -1.413182
[ Info: iteration 22, average log likelihood -1.413171
[ Info: iteration 23, average log likelihood -1.413160
[ Info: iteration 24, average log likelihood -1.413150
[ Info: iteration 25, average log likelihood -1.413141
[ Info: iteration 26, average log likelihood -1.413132
[ Info: iteration 27, average log likelihood -1.413123
[ Info: iteration 28, average log likelihood -1.413114
[ Info: iteration 29, average log likelihood -1.413106
[ Info: iteration 30, average log likelihood -1.413098
[ Info: iteration 31, average log likelihood -1.413090
[ Info: iteration 32, average log likelihood -1.413083
[ Info: iteration 33, average log likelihood -1.413076
[ Info: iteration 34, average log likelihood -1.413068
[ Info: iteration 35, average log likelihood -1.413062
[ Info: iteration 36, average log likelihood -1.413055
[ Info: iteration 37, average log likelihood -1.413048
[ Info: iteration 38, average log likelihood -1.413042
[ Info: iteration 39, average log likelihood -1.413036
[ Info: iteration 40, average log likelihood -1.413030
[ Info: iteration 41, average log likelihood -1.413025
[ Info: iteration 42, average log likelihood -1.413019
[ Info: iteration 43, average log likelihood -1.413014
[ Info: iteration 44, average log likelihood -1.413008
[ Info: iteration 45, average log likelihood -1.413003
[ Info: iteration 46, average log likelihood -1.412999
[ Info: iteration 47, average log likelihood -1.412994
[ Info: iteration 48, average log likelihood -1.412989
[ Info: iteration 49, average log likelihood -1.412984
[ Info: iteration 50, average log likelihood -1.412980
┌ Info: EM with 100000 data points 50 iterations avll -1.412980
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4140960171329315
│     -1.4140387886639327
│      ⋮
└     -1.4129800026948247
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412987
[ Info: iteration 2, average log likelihood -1.412933
[ Info: iteration 3, average log likelihood -1.412887
[ Info: iteration 4, average log likelihood -1.412836
[ Info: iteration 5, average log likelihood -1.412776
[ Info: iteration 6, average log likelihood -1.412703
[ Info: iteration 7, average log likelihood -1.412619
[ Info: iteration 8, average log likelihood -1.412525
[ Info: iteration 9, average log likelihood -1.412426
[ Info: iteration 10, average log likelihood -1.412329
[ Info: iteration 11, average log likelihood -1.412238
[ Info: iteration 12, average log likelihood -1.412159
[ Info: iteration 13, average log likelihood -1.412091
[ Info: iteration 14, average log likelihood -1.412036
[ Info: iteration 15, average log likelihood -1.411992
[ Info: iteration 16, average log likelihood -1.411956
[ Info: iteration 17, average log likelihood -1.411927
[ Info: iteration 18, average log likelihood -1.411903
[ Info: iteration 19, average log likelihood -1.411883
[ Info: iteration 20, average log likelihood -1.411866
[ Info: iteration 21, average log likelihood -1.411851
[ Info: iteration 22, average log likelihood -1.411838
[ Info: iteration 23, average log likelihood -1.411825
[ Info: iteration 24, average log likelihood -1.411814
[ Info: iteration 25, average log likelihood -1.411804
[ Info: iteration 26, average log likelihood -1.411794
[ Info: iteration 27, average log likelihood -1.411785
[ Info: iteration 28, average log likelihood -1.411776
[ Info: iteration 29, average log likelihood -1.411768
[ Info: iteration 30, average log likelihood -1.411760
[ Info: iteration 31, average log likelihood -1.411753
[ Info: iteration 32, average log likelihood -1.411746
[ Info: iteration 33, average log likelihood -1.411739
[ Info: iteration 34, average log likelihood -1.411733
[ Info: iteration 35, average log likelihood -1.411726
[ Info: iteration 36, average log likelihood -1.411720
[ Info: iteration 37, average log likelihood -1.411715
[ Info: iteration 38, average log likelihood -1.411709
[ Info: iteration 39, average log likelihood -1.411703
[ Info: iteration 40, average log likelihood -1.411698
[ Info: iteration 41, average log likelihood -1.411693
[ Info: iteration 42, average log likelihood -1.411688
[ Info: iteration 43, average log likelihood -1.411683
[ Info: iteration 44, average log likelihood -1.411678
[ Info: iteration 45, average log likelihood -1.411673
[ Info: iteration 46, average log likelihood -1.411668
[ Info: iteration 47, average log likelihood -1.411663
[ Info: iteration 48, average log likelihood -1.411659
[ Info: iteration 49, average log likelihood -1.411654
[ Info: iteration 50, average log likelihood -1.411649
┌ Info: EM with 100000 data points 50 iterations avll -1.411649
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.412987087799385
│     -1.4129329855303914
│      ⋮
└     -1.4116491880281137
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411655
[ Info: iteration 2, average log likelihood -1.411603
[ Info: iteration 3, average log likelihood -1.411558
[ Info: iteration 4, average log likelihood -1.411507
[ Info: iteration 5, average log likelihood -1.411445
[ Info: iteration 6, average log likelihood -1.411370
[ Info: iteration 7, average log likelihood -1.411283
[ Info: iteration 8, average log likelihood -1.411185
[ Info: iteration 9, average log likelihood -1.411081
[ Info: iteration 10, average log likelihood -1.410976
[ Info: iteration 11, average log likelihood -1.410875
[ Info: iteration 12, average log likelihood -1.410781
[ Info: iteration 13, average log likelihood -1.410696
[ Info: iteration 14, average log likelihood -1.410623
[ Info: iteration 15, average log likelihood -1.410559
[ Info: iteration 16, average log likelihood -1.410505
[ Info: iteration 17, average log likelihood -1.410459
[ Info: iteration 18, average log likelihood -1.410420
[ Info: iteration 19, average log likelihood -1.410385
[ Info: iteration 20, average log likelihood -1.410355
[ Info: iteration 21, average log likelihood -1.410328
[ Info: iteration 22, average log likelihood -1.410304
[ Info: iteration 23, average log likelihood -1.410281
[ Info: iteration 24, average log likelihood -1.410261
[ Info: iteration 25, average log likelihood -1.410242
[ Info: iteration 26, average log likelihood -1.410225
[ Info: iteration 27, average log likelihood -1.410208
[ Info: iteration 28, average log likelihood -1.410193
[ Info: iteration 29, average log likelihood -1.410179
[ Info: iteration 30, average log likelihood -1.410165
[ Info: iteration 31, average log likelihood -1.410152
[ Info: iteration 32, average log likelihood -1.410139
[ Info: iteration 33, average log likelihood -1.410128
[ Info: iteration 34, average log likelihood -1.410116
[ Info: iteration 35, average log likelihood -1.410105
[ Info: iteration 36, average log likelihood -1.410095
[ Info: iteration 37, average log likelihood -1.410084
[ Info: iteration 38, average log likelihood -1.410074
[ Info: iteration 39, average log likelihood -1.410064
[ Info: iteration 40, average log likelihood -1.410055
[ Info: iteration 41, average log likelihood -1.410045
[ Info: iteration 42, average log likelihood -1.410036
[ Info: iteration 43, average log likelihood -1.410027
[ Info: iteration 44, average log likelihood -1.410018
[ Info: iteration 45, average log likelihood -1.410009
[ Info: iteration 46, average log likelihood -1.410000
[ Info: iteration 47, average log likelihood -1.409991
[ Info: iteration 48, average log likelihood -1.409983
[ Info: iteration 49, average log likelihood -1.409974
[ Info: iteration 50, average log likelihood -1.409966
┌ Info: EM with 100000 data points 50 iterations avll -1.409966
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4116547253746796
│     -1.41160301910018
│      ⋮
└     -1.40996555164883
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409966
[ Info: iteration 2, average log likelihood -1.409897
[ Info: iteration 3, average log likelihood -1.409831
[ Info: iteration 4, average log likelihood -1.409754
[ Info: iteration 5, average log likelihood -1.409660
[ Info: iteration 6, average log likelihood -1.409546
[ Info: iteration 7, average log likelihood -1.409413
[ Info: iteration 8, average log likelihood -1.409268
[ Info: iteration 9, average log likelihood -1.409119
[ Info: iteration 10, average log likelihood -1.408971
[ Info: iteration 11, average log likelihood -1.408831
[ Info: iteration 12, average log likelihood -1.408700
[ Info: iteration 13, average log likelihood -1.408578
[ Info: iteration 14, average log likelihood -1.408466
[ Info: iteration 15, average log likelihood -1.408363
[ Info: iteration 16, average log likelihood -1.408268
[ Info: iteration 17, average log likelihood -1.408182
[ Info: iteration 18, average log likelihood -1.408103
[ Info: iteration 19, average log likelihood -1.408032
[ Info: iteration 20, average log likelihood -1.407967
[ Info: iteration 21, average log likelihood -1.407909
[ Info: iteration 22, average log likelihood -1.407857
[ Info: iteration 23, average log likelihood -1.407809
[ Info: iteration 24, average log likelihood -1.407765
[ Info: iteration 25, average log likelihood -1.407725
[ Info: iteration 26, average log likelihood -1.407689
[ Info: iteration 27, average log likelihood -1.407655
[ Info: iteration 28, average log likelihood -1.407623
[ Info: iteration 29, average log likelihood -1.407593
[ Info: iteration 30, average log likelihood -1.407565
[ Info: iteration 31, average log likelihood -1.407539
[ Info: iteration 32, average log likelihood -1.407514
[ Info: iteration 33, average log likelihood -1.407491
[ Info: iteration 34, average log likelihood -1.407468
[ Info: iteration 35, average log likelihood -1.407447
[ Info: iteration 36, average log likelihood -1.407426
[ Info: iteration 37, average log likelihood -1.407407
[ Info: iteration 38, average log likelihood -1.407388
[ Info: iteration 39, average log likelihood -1.407370
[ Info: iteration 40, average log likelihood -1.407353
[ Info: iteration 41, average log likelihood -1.407336
[ Info: iteration 42, average log likelihood -1.407320
[ Info: iteration 43, average log likelihood -1.407304
[ Info: iteration 44, average log likelihood -1.407289
[ Info: iteration 45, average log likelihood -1.407275
[ Info: iteration 46, average log likelihood -1.407260
[ Info: iteration 47, average log likelihood -1.407246
[ Info: iteration 48, average log likelihood -1.407233
[ Info: iteration 49, average log likelihood -1.407220
[ Info: iteration 50, average log likelihood -1.407207
┌ Info: EM with 100000 data points 50 iterations avll -1.407207
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4099659705390402
│     -1.4098968278664827
│      ⋮
└     -1.4072066097182603
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4196267166412138
│     -1.4196458593824306
│     -1.4195697216294887
│     -1.4195040374054497
│      ⋮
│     -1.4072327398991396
│     -1.4072195154336518
└     -1.4072066097182603
32×26 Array{Float64,2}:
 -0.144722    -0.865513    0.192392    -0.028672     0.673153     0.657303      0.144488   -0.0562489  -0.338168     0.746169    -0.277037   -0.0501267   0.160263    0.122391    -0.122898     0.30137     -0.016038     0.032393     0.0319391  -0.0663918    -0.27131    -0.148965     -0.352091    -1.06593    -0.0867226   0.217338
  0.582997     0.548105    0.550205    -0.371069    -0.15153     -0.000862906  -0.144145    0.393842   -0.0374676    0.570525     0.105667   -0.34326     0.167283    0.0611702   -0.217262     0.0730136    0.592579     0.777103     0.277389   -0.306869     -0.151101   -0.250167     -0.0134051   -0.306666    0.388268   -0.842399
 -0.343262     0.191818    0.0838384   -0.475291    -0.095222     0.459331     -0.448915   -0.0497424  -0.250445     0.220711     0.220145   -0.270539   -0.302488    0.060843    -0.236564     0.231149    -0.70254      0.179373    -0.160164   -0.39526      -0.0763975  -0.174583     -0.454012     0.298233   -0.569069   -0.299021
  0.711932    -0.0918156   0.29073      0.550919     0.443349     0.250854      0.020837    0.209274   -0.160219     0.350225     0.214747    0.0554576   0.125274   -0.169591    -0.16482     -0.177018    -0.392493     0.340112    -0.446928   -0.675778      0.188102    0.275369     -0.00298899   0.539452   -0.0307004  -0.487213
  0.142386     0.523135   -0.564933    -0.178277    -1.02264     -0.12435       0.0362162   0.230182    0.00840392  -0.819983     0.132281   -0.310168    0.142612   -0.364756     0.414244    -0.284815    -0.0244287   -0.609877    -0.434559   -0.2123       -0.0123636  -0.0940547     0.173745     0.631046   -0.331551   -0.302908
 -0.0776779    0.156707    0.0246507    0.463881     0.673938    -0.524247      0.625202   -0.213256    0.136066    -0.478159     0.255499    0.447303    0.203492   -0.447876     0.222021    -0.452909     0.456125    -0.609879    -0.135735    0.161594      0.186996    0.394229      0.0957268    0.123742    0.352538   -0.0872175
  0.253487    -0.158334   -0.0320053    0.256514    -0.208163     0.372134      0.325141    0.19815     0.103597    -0.192604    -0.483538   -0.434389   -0.0357052  -0.169049     0.43183     -0.298587     0.316827     0.245136     0.213053    0.401377     -0.589396   -0.403243      0.538479     0.24275    -0.119581   -0.824583
 -0.00556527  -0.248869    0.00103169   0.0383015   -0.110652     0.398681     -0.10951     0.409048    0.255801    -0.096385     0.65004     0.145934    0.309469    0.0829976    0.38864      0.335069     0.463874     0.0350091    0.394406   -0.42497      -0.156577   -0.160736      0.494603     0.0891055  -0.511083    0.157068
 -0.209309    -0.109555    0.274127    -0.557077    -0.055708    -0.751197      0.260022    0.116628   -0.0157724   -0.0543806   -0.179987   -0.071448   -0.643451    0.218343     0.425903     0.0236498    0.519405    -0.252515    -0.295603   -0.060289      0.467931   -0.279194      0.129134    -0.639817    0.645658    0.174211
  0.142068    -0.016031   -0.012053    -0.00383545  -0.174573     0.0337608     0.0410169  -0.045496    0.156707    -0.0700623    0.0597736   0.0135629  -0.0345465   0.091099    -0.0981045   -0.14801     -0.0175654    0.00650127  -0.0210612  -0.053931      0.0283682   0.0859345     0.00505973   0.156131   -0.065839   -0.0448323
  0.723633     0.126481    0.266921    -0.31296     -0.53078      0.0961125    -0.195584   -0.148176    0.364281     0.293654     0.0776529   1.0414     -0.159282   -0.116868    -0.0506932   -0.230778     0.1161      -0.600151    -0.283154   -0.15125       0.465954    0.251763      0.0517769   -0.101099    0.0893923   0.221045
 -0.550767     0.391472    0.00179772  -0.245497     0.0528513   -0.681065     -0.360861    0.0124145  -0.130048     0.186633     0.0635084   0.0519188  -0.208368   -0.300806    -0.206887     0.59545     -0.505559     0.37547     -0.323152    0.447017      0.367064    0.313769     -0.0172924    0.132262    0.529848    0.247923
 -1.21955     -0.1851     -0.904001     0.99491      0.567839    -0.61543       0.27031     0.679468   -0.735853     0.454068    -0.793991   -0.0525842   0.387636    0.394007    -0.0462537    0.183734    -0.328776    -0.298059    -0.834399    0.914631      0.173671   -1.08759      -0.0472      -0.0141876  -0.542978    0.570994
 -1.13183      0.101336   -0.177141     0.303005     0.170431    -0.478036     -0.398142    0.801851   -0.698211     0.654138     0.514928    0.550651    0.340246    0.489835     0.0356688   -0.00316825   0.174937    -0.226613    -0.531863    0.648563      0.116255    0.248903     -0.505949    -0.165963   -0.145192   -0.140446
 -0.782237     0.276386   -0.527449    -0.196329     0.619876    -0.020785      0.522594   -0.486532   -0.315819    -0.0529436   -0.170201   -1.02847     0.0928789   0.195748    -0.409918     0.0319701    0.0472416    0.0922321    0.669672    0.174415     -0.636913   -0.445301     -0.272124    -0.114318    0.0647868   0.0859792
 -0.31988      0.28596    -0.395043     0.123647    -0.272366     0.282637     -0.609096   -0.150867    0.241758     0.0690812   -0.223267    0.252496    0.266269    0.00215513  -0.314328     0.101123    -0.390694     0.193836     0.799516    0.793046     -0.418027    0.000830217  -0.320127    -0.0311313  -0.169826   -0.187186
 -0.0921006   -0.34453     0.234946    -0.0982389    0.35001     -0.111861      0.468301   -0.405066   -0.504291     0.359378    -0.447727    0.248808   -0.217984   -0.519557    -0.773765    -0.093208    -0.167716     0.755713    -0.846615    0.192966      0.0345826   0.321775      0.243556    -0.502661    0.150246   -0.126057
 -0.479496    -0.22343     0.430148     0.301014     0.0923728   -0.0318988     0.104766   -0.0980211   0.0596829    0.312419    -0.287095    0.523058   -0.237771    0.140552    -0.490617    -0.204383     0.475449     0.396509     0.53951     0.699112      0.12349    -0.0743177    -0.344649    -0.457023    0.319679   -0.226222
  0.376522     0.160102    0.0740674   -0.148369     0.410863    -0.164842     -0.037609   -0.0220194   0.113466    -0.20721     -0.268353   -0.419503    0.0876004   0.12634     -0.362741    -0.363028    -0.382642    -0.0280732   -0.248822   -0.342147     -0.08072    -0.139929     -0.373276    -0.233696    0.479625   -0.366155
  0.399355     0.166029   -0.063859    -0.301094    -0.138319    -0.6945        0.101031   -0.0383236  -0.228384    -0.0954596   -0.50759     0.0347659   0.176266    0.130035    -0.147908    -0.597496     0.138688     0.0809399   -0.0746985   0.0214937    -0.0169838   0.338111     -0.0826429    0.589633   -0.131309   -0.131128
 -0.0718858    0.225608   -0.00656789   0.24967      0.684372     0.212977     -0.175544    0.294436    0.197125     0.151808     0.468871   -0.0542452   0.0349474  -0.059834     0.0749267   -0.127673     0.00162846  -0.0829124   -0.0353731   0.0176615    -0.154009   -0.0365753     0.292037    -0.410941    0.0952704  -0.39156
 -0.00627385  -0.0934972  -0.243318    -0.188126     0.497494    -0.113284     -0.0596732   0.153001    0.109003     0.289228     0.468877    0.0717774  -0.257079    0.124852    -0.160184     0.341116     0.222442    -0.0695684    0.0442816  -0.29564      -0.0407506  -0.230873     -0.132691    -0.369002    0.38649     0.551366
 -0.221629    -0.159025    0.194764     0.137158     0.167501    -0.279666     -0.174795    0.116904   -0.0463394    0.178518     0.0647135   0.124498    0.127579   -0.0245464    0.256712     0.315399     0.0994659    0.0356557   -0.0275057  -0.0202841     0.518625    0.418871     -0.0858794    0.276377    0.173967   -0.0659901
  0.112236     0.178342    0.495178     0.100922    -0.448212     0.00786664   -0.0162152   0.224757    0.510053    -0.0751404   -0.0190372   0.0986987   0.0646921  -0.0762461    0.287142    -0.0500743   -0.168003     0.129888    -0.165555    0.225767      0.508821    0.0772982     0.0169603   -0.0363161  -0.337066    0.1078
  0.0149027    0.100732   -0.0416369   -0.0108293   -0.00502856   0.100531      0.0117194  -0.0675651  -0.120281    -0.00898331   0.0700913   0.183718   -0.208516   -0.3602      -0.267221    -0.244459    -0.123127    -0.00659497  -0.0361703   0.000408164  -0.13411    -0.030359      0.0351451    0.233621   -0.0778933  -0.183003
 -0.146724    -0.171163   -0.17431     -0.14238     -0.157317     0.0699459    -0.0440633  -0.0935478  -0.00285903   0.00390933  -0.0765926  -0.0969118   0.0836073   0.310367     0.106825     0.115324     0.0677038   -0.100995     0.18771     0.0999429    -0.176051   -0.238444      0.0593072   -0.0921928  -0.0112403   0.134403
  0.320731    -0.050309    0.0100652    0.164065     0.117081     0.0362231     0.81397    -0.260939   -0.0338376    0.274431    -0.0809162  -0.368667   -0.0513388  -0.0740008    0.00109978  -0.159797     0.103293     0.292911    -0.162863   -0.547288     -0.338925   -0.406972      0.326993     0.142729   -0.0891739   0.185322
  0.0130802   -0.291444   -0.582502     0.159369    -0.413551     0.336015      0.503219   -0.429137   -0.485759     0.136025     0.0708951   0.19404    -0.203713   -0.308231     0.561795     0.0980944   -0.203105    -0.415593     0.0294947   0.236661     -0.18432     0.163742      0.286764     0.420216   -0.239542    0.374465
 -0.119783    -0.774408    0.390812    -0.262683    -0.645291     0.130727      0.187896   -0.146352    0.52243     -0.343102    -0.0862251  -0.412269   -0.0044576   1.00692      0.232784     0.176325     0.0979762   -0.370541     0.0138919  -0.0840628     0.310915   -0.119898      0.0066631   -0.295801   -0.0704962   0.269769
 -0.246555    -0.0402523   0.148885    -0.249135    -0.519774     0.441956     -0.0529094  -0.143247    0.0642573   -0.0358273   -0.621104    0.158964    0.575739    1.09783      0.252688    -0.133371    -0.145911    -0.646286    -0.339324    0.284536     -0.255665    0.0165187    -0.32252     -0.246606    0.337174    0.404674
 -0.51674     -0.224231   -0.276232    -0.361507    -0.536847    -0.511265     -0.490046   -0.280659    0.0226318   -0.58293     -0.22897     0.0439347   0.118439    0.267413     0.00388962   0.262468     0.197042    -0.0563935    0.614507    0.256502      0.503485   -0.233489      0.151386     0.322831    0.198657    0.298029
 -0.285295    -0.123043   -0.294713     0.00708768  -0.179465     0.362884     -0.376094   -0.502748    0.88253     -0.480477     0.271497   -0.0595742  -0.284334    0.0284054   -0.254034     0.22997     -0.298682    -0.597427     0.0745078  -0.199355      0.10704    -0.136556      0.414038     0.434302    0.0851337   0.841972[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407194
[ Info: iteration 2, average log likelihood -1.407182
[ Info: iteration 3, average log likelihood -1.407170
[ Info: iteration 4, average log likelihood -1.407158
[ Info: iteration 5, average log likelihood -1.407146
[ Info: iteration 6, average log likelihood -1.407135
[ Info: iteration 7, average log likelihood -1.407124
[ Info: iteration 8, average log likelihood -1.407113
[ Info: iteration 9, average log likelihood -1.407103
[ Info: iteration 10, average log likelihood -1.407092
┌ Info: EM with 100000 data points 10 iterations avll -1.407092
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.323822e+05
      1       7.013239e+05      -2.310583e+05 |       32
      2       6.875118e+05      -1.381207e+04 |       32
      3       6.823668e+05      -5.144991e+03 |       32
      4       6.797339e+05      -2.632947e+03 |       32
      5       6.780994e+05      -1.634450e+03 |       32
      6       6.769307e+05      -1.168731e+03 |       32
      7       6.759931e+05      -9.376183e+02 |       32
      8       6.751930e+05      -8.000908e+02 |       32
      9       6.745560e+05      -6.369866e+02 |       32
     10       6.740615e+05      -4.944924e+02 |       32
     11       6.736167e+05      -4.448510e+02 |       32
     12       6.732252e+05      -3.914971e+02 |       32
     13       6.728673e+05      -3.579061e+02 |       32
     14       6.725555e+05      -3.117536e+02 |       32
     15       6.722493e+05      -3.062011e+02 |       32
     16       6.719875e+05      -2.618207e+02 |       32
     17       6.717429e+05      -2.446139e+02 |       32
     18       6.715326e+05      -2.102729e+02 |       32
     19       6.713371e+05      -1.955099e+02 |       32
     20       6.711587e+05      -1.784306e+02 |       32
     21       6.709564e+05      -2.022462e+02 |       32
     22       6.707654e+05      -1.910365e+02 |       32
     23       6.705915e+05      -1.739114e+02 |       32
     24       6.704187e+05      -1.727577e+02 |       32
     25       6.702561e+05      -1.625787e+02 |       32
     26       6.701158e+05      -1.403614e+02 |       32
     27       6.699811e+05      -1.346423e+02 |       32
     28       6.698571e+05      -1.239883e+02 |       32
     29       6.697398e+05      -1.173481e+02 |       32
     30       6.696238e+05      -1.160156e+02 |       32
     31       6.695119e+05      -1.119177e+02 |       32
     32       6.694058e+05      -1.060187e+02 |       32
     33       6.693129e+05      -9.289461e+01 |       32
     34       6.692178e+05      -9.512089e+01 |       32
     35       6.691176e+05      -1.001856e+02 |       32
     36       6.690218e+05      -9.581234e+01 |       32
     37       6.689303e+05      -9.153319e+01 |       32
     38       6.688517e+05      -7.858506e+01 |       32
     39       6.687865e+05      -6.517053e+01 |       32
     40       6.687198e+05      -6.676327e+01 |       32
     41       6.686516e+05      -6.815840e+01 |       32
     42       6.685919e+05      -5.970391e+01 |       32
     43       6.685347e+05      -5.718890e+01 |       32
     44       6.684771e+05      -5.763935e+01 |       32
     45       6.684272e+05      -4.988368e+01 |       32
     46       6.683895e+05      -3.767911e+01 |       32
     47       6.683552e+05      -3.434886e+01 |       32
     48       6.683247e+05      -3.044729e+01 |       32
     49       6.682966e+05      -2.813110e+01 |       32
     50       6.682662e+05      -3.038704e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 668266.2091999941)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418896
[ Info: iteration 2, average log likelihood -1.413733
[ Info: iteration 3, average log likelihood -1.412177
[ Info: iteration 4, average log likelihood -1.410990
[ Info: iteration 5, average log likelihood -1.409914
[ Info: iteration 6, average log likelihood -1.409101
[ Info: iteration 7, average log likelihood -1.408600
[ Info: iteration 8, average log likelihood -1.408310
[ Info: iteration 9, average log likelihood -1.408128
[ Info: iteration 10, average log likelihood -1.408000
[ Info: iteration 11, average log likelihood -1.407902
[ Info: iteration 12, average log likelihood -1.407822
[ Info: iteration 13, average log likelihood -1.407756
[ Info: iteration 14, average log likelihood -1.407698
[ Info: iteration 15, average log likelihood -1.407648
[ Info: iteration 16, average log likelihood -1.407603
[ Info: iteration 17, average log likelihood -1.407563
[ Info: iteration 18, average log likelihood -1.407526
[ Info: iteration 19, average log likelihood -1.407492
[ Info: iteration 20, average log likelihood -1.407461
[ Info: iteration 21, average log likelihood -1.407432
[ Info: iteration 22, average log likelihood -1.407405
[ Info: iteration 23, average log likelihood -1.407380
[ Info: iteration 24, average log likelihood -1.407356
[ Info: iteration 25, average log likelihood -1.407334
[ Info: iteration 26, average log likelihood -1.407313
[ Info: iteration 27, average log likelihood -1.407293
[ Info: iteration 28, average log likelihood -1.407275
[ Info: iteration 29, average log likelihood -1.407257
[ Info: iteration 30, average log likelihood -1.407241
[ Info: iteration 31, average log likelihood -1.407226
[ Info: iteration 32, average log likelihood -1.407211
[ Info: iteration 33, average log likelihood -1.407197
[ Info: iteration 34, average log likelihood -1.407184
[ Info: iteration 35, average log likelihood -1.407171
[ Info: iteration 36, average log likelihood -1.407159
[ Info: iteration 37, average log likelihood -1.407147
[ Info: iteration 38, average log likelihood -1.407136
[ Info: iteration 39, average log likelihood -1.407126
[ Info: iteration 40, average log likelihood -1.407115
[ Info: iteration 41, average log likelihood -1.407105
[ Info: iteration 42, average log likelihood -1.407096
[ Info: iteration 43, average log likelihood -1.407086
[ Info: iteration 44, average log likelihood -1.407077
[ Info: iteration 45, average log likelihood -1.407068
[ Info: iteration 46, average log likelihood -1.407060
[ Info: iteration 47, average log likelihood -1.407051
[ Info: iteration 48, average log likelihood -1.407043
[ Info: iteration 49, average log likelihood -1.407035
[ Info: iteration 50, average log likelihood -1.407027
┌ Info: EM with 100000 data points 50 iterations avll -1.407027
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.397092    -0.0982186   -0.166823    0.303178   -0.199145   -0.221968    -0.436241     0.255762   -0.328828    0.447809    0.364611    0.726879     0.104163      0.0393655   0.670521    0.596823    -0.00547184  -0.347259    -0.305019    0.755258     0.706438    0.525003    -0.0268927   0.412926     0.173743     0.337042
  0.544186    -0.397233     0.450696   -0.469508   -0.335652   -0.0981901    0.255193     0.253454    0.0625122   0.226338    0.27748     0.548487    -0.446433      0.0870636   0.315947   -0.632455     0.368938    -0.162966    -0.523094   -0.474674     0.186914   -0.325657     0.510559   -0.150529     0.0469992    0.109607
 -0.134426     0.0683801    0.241599    0.618317    0.676965   -0.450569     0.582519     0.19618     0.167802   -0.499516    0.253452    0.337248     0.366504     -0.365196    0.53872    -0.664206     0.607267    -0.184425     0.188065    0.407391     0.272134    0.32178      0.50362    -0.185554     0.193379    -0.143238
 -0.142169    -0.204338     0.523272    0.0460703   0.246139    0.110632    -0.206345    -0.167199   -0.0702935   0.530808   -0.270123    0.413828    -0.118576      0.0300927  -0.740888   -0.0653141    0.0917643    0.667091     0.242406    0.398872     0.0777826  -0.0833752   -0.263736   -0.77893      0.465928    -0.094733
  0.106343     0.451455    -0.809409   -0.243977   -0.798773   -0.193054    -0.0801578    0.365526   -0.0478886  -0.748166    0.173064   -0.396569     0.249136     -0.289707    0.423061   -0.277529     0.0331156   -0.718241    -0.464614   -0.368373    -0.165352   -0.069346     0.167631    0.5692      -0.299109    -0.236368
 -0.487164    -0.559609    -0.0710094  -0.104823   -0.472696    0.168589    -0.218191    -0.296807    0.482027   -0.409849   -0.0146059  -0.241748    -0.0498696     0.626726    0.0262821   0.265506    -0.139153    -0.472448     0.116536    0.199413     0.245106   -0.209481     0.159113   -0.130467     0.173665     0.517604
 -0.361609    -0.249029     0.291311   -0.663861    0.202309   -0.434309     0.207298    -0.0785866  -0.17035     0.116665   -0.351895   -0.129449    -0.397314      0.399189    0.241422    0.0418528    0.395378    -0.480916    -0.397724   -0.0589142    0.353145   -0.241285    -0.375694   -0.966885     0.657316     0.298711
 -0.540103     0.0789538   -0.416617    0.0594415   0.0566762   0.233871    -0.192227    -0.27173    -0.148412    0.248098   -0.330179   -0.23998      0.212058      0.205746   -0.389847    0.105631    -0.275349     0.106827     0.399563    0.621728    -0.284761   -0.056996    -0.43032    -0.147824     0.0134171   -0.0178071
 -0.127582    -0.416249    -0.733087    0.288184    0.199594   -0.014993     0.706259    -0.666392    0.0556851  -0.262176   -0.0540539   0.00637456  -0.104596     -0.210605    0.368371   -0.0866996   -0.128003    -0.628455    -0.252852   -0.0109407   -0.315412    0.0968996    0.23789     0.694323    -0.095781     0.585184
  0.161877     0.112573    -0.199844   -0.504919   -0.460426    0.496984     0.00399478  -0.462436   -0.136659    0.10636    -0.31042    -0.325201    -0.0114057     0.470339   -0.261977   -0.2399      -0.505644     0.19166     -0.215957   -0.428707    -0.64741    -0.419601    -0.138203    0.32028     -0.0420785   -0.0359177
 -0.279165    -0.523356    -0.0463071  -0.0254407   0.425122    0.527735    -0.325469     0.314646   -0.0667534   0.280163    0.352453   -0.0983977    0.366132      0.326928    0.282279    0.530786    -0.0109852   -0.140191     0.172407   -0.391495    -0.462695   -0.208474     0.0686674  -0.417682    -0.276885     0.275365
 -0.340879     0.0309923   -0.525828   -0.461526   -0.595993    0.209282     0.191316    -0.278786   -0.0626976  -0.0828008   0.0596706   0.366326    -0.268244      0.11029     0.452855    0.244774     0.288513    -0.335465     0.844575    0.705838    -0.320811   -0.348632     0.132991   -0.31813     -0.398379     0.530924
  0.142413     0.308779    -0.114307   -0.0840879   0.130903   -0.0351954   -0.179541    -0.469959    0.227237    0.185866    0.221254    0.684844    -0.0386118    -0.224928   -0.554195    0.0427414   -0.0506596   -0.710397    -0.190093   -0.28305      0.242722    0.46627     -0.142191   -0.126888     0.384579     0.512046
  0.225866    -0.0630435    0.300688    0.0262326  -0.084003    0.241852     0.0840135    0.670109   -0.0461668  -0.0707813  -0.354166   -0.381181     0.205482      0.29417     0.235543   -0.286824     0.774492     0.125177     0.382902    0.442253    -0.666021   -0.550994     0.160102   -0.0409942    0.193216    -1.04017
 -0.00650746   0.0749666   -0.419437   -0.252768   -0.437623   -0.667387    -0.82958      0.246165    0.283173   -0.451228    0.268095    0.25957     -0.000732175  -0.0682235  -0.305487    0.425332     0.213052     0.360791     0.661931    0.0580349   -0.0290817  -0.110113     0.510006    0.205087     0.740663     0.299201
 -1.22052      0.00377455  -0.609281    0.539595    0.394198   -0.618        0.0272884    0.779327   -0.538454    0.436399   -0.181403    0.102947     0.23624       0.520889   -0.190846   -0.0216418   -0.0746564   -0.253058    -0.731881    0.875241     0.103579   -0.471352    -0.393798   -0.161276    -0.303108     0.258548
 -0.0758877   -0.0292618   -0.050843    0.459894   -0.181647    0.660406     0.068675    -0.0857113  -0.0888981   0.0515213   0.151317    0.178854     0.205212     -0.334334    0.0783334  -0.0661615   -0.404856     0.135401     0.138941    0.00845447  -0.156124    0.165578     0.122887    0.545749    -0.738509    -0.371893
  0.0177024    0.129631     0.015671   -0.203194   -0.167831   -0.566105     0.174991    -0.0885945  -0.0214826   0.0103854  -0.540074    0.238665    -0.141211     -0.019103   -0.378984   -0.620223     0.102399     0.033854    -0.0308475   0.538634     0.0752012   0.281465    -0.295687    0.160163    -0.0510722   -0.15881
  0.444832     0.0480379    0.122728    0.320701   -0.331999    0.276489     0.40007      0.297032    0.846818   -0.11516     0.246262   -0.523052    -0.0639625    -0.114705    0.189081    0.559799     0.339629     0.304447     0.296161   -0.612227    -0.027761   -0.30302      0.773323    0.199797    -0.22858      0.450554
 -0.0702229   -0.0977053   -0.0596776  -0.0611796  -0.244032   -0.070202     0.0164275   -0.136159   -0.113695   -0.0208421  -0.0491194   0.0256482    0.0773383     0.0435529   0.202757    0.0365364    0.0557851   -0.0148185    0.118079    0.0081798    0.0257285  -0.00357051   0.0788045   0.271105    -0.00890032   0.071162
 -0.56342      0.0847611    0.353043   -0.889353   -0.0383295  -0.88397     -0.0572875    0.0540489  -0.33733    -0.0962969  -0.104734   -0.503273    -0.165085     -0.398103    0.0590396   0.589448    -0.263203     0.766043    -0.508662    0.306987     0.299491    0.38654      0.121997    0.00607057  -0.00534285   0.101987
  0.33552      0.646968    -0.133673    0.386982   -0.773523   -0.179259     0.283611    -0.203068    0.233558   -0.346735    0.090736   -0.0264282   -0.364839     -0.722538    0.137288   -0.362392    -0.084985     0.323573    -0.032944    0.386844     0.205793   -0.0799022    0.465894    0.852165    -0.110641    -0.672742
  0.617377    -0.0560524    0.169667    0.171711    0.432691   -0.00965193   0.279309     0.0835478  -0.504775    0.399187   -0.16286    -0.16506      0.143757     -0.194219   -0.397286   -0.183366    -0.504995     0.457069    -0.891585   -0.43683     -0.113302    0.33564      0.0230893   0.0857145    0.143839    -0.438247
  0.0421636    0.065681    -0.131492    0.0289644   0.353552    0.0788748   -0.0130428    0.0871357   0.0140031   0.0194472   0.133822    0.0347035   -0.171764     -0.199201   -0.265189   -0.148581    -0.0763413   -0.0842279   -0.117539   -0.00958886  -0.220161   -0.104451     0.093459   -0.130423     0.126242    -0.150734
 -0.134151     0.284627    -0.180385   -0.211621    0.656531   -0.347786     0.380397    -0.36719     0.0314123  -0.209931   -0.307315   -0.819414     0.0660081     0.352999   -0.383646   -0.278742     0.1254      -0.00341513   0.606191   -0.447746    -0.234487   -0.474209    -0.0454944  -0.252646     0.345621    -0.269365
  0.0854793    0.306778     0.379394   -0.0883644  -0.118591    0.0331087   -0.393278     0.375823    0.431146    0.237672    0.216738   -0.0319648    0.111367      0.202182    0.210813   -0.00521805  -0.181665     0.119724    -0.116641    0.0427405    0.411868    0.0626771   -0.156788   -0.26465     -0.166781    -0.0801298
  0.223347    -0.111278     0.621005   -0.195738   -1.13964    -0.0575411    0.212673    -0.0429188   0.143336   -0.6081     -0.473977    0.239683     0.314102      0.398508    0.51446     0.061841     0.114438    -0.561739    -0.424773    0.0317421    0.598217    0.213273    -0.260272   -0.0412773   -0.00530184  -0.0409672
  0.603496    -0.00984448   0.346985   -0.0648648  -0.141014    0.308017    -0.0729031    0.204596    0.364608    0.0834722   0.417738    0.125664     0.0753423     0.142228    0.04731    -0.116661     0.132889     0.0363591   -0.0578334  -0.612513     0.10815     0.2373       0.106157    0.219601    -0.160397    -0.224131
  0.22879     -0.169494     0.305959    0.435661    0.684864   -0.221099    -0.272669     0.192829    0.160699   -0.115513    0.0696988   0.0418259    0.0953535     0.0404634  -0.0367217   0.139504     0.0078444    0.117501    -0.0993168  -0.51697      0.67119     0.175785    -0.360481    0.471148     0.413546    -0.225338
 -0.300534     0.467964    -0.0478445  -0.263626    0.411525    0.0638748   -0.0875851    0.167352   -0.375532    0.370648    0.725956   -0.171281    -0.609723     -0.581269   -0.251345    0.303685    -0.165498     0.407144     0.165648   -0.369615    -0.0702514  -0.357655    -0.23259     0.110188    -0.123202    -0.484864
 -0.137448    -0.398814     0.0991917   0.29964     0.39658     0.114431     0.642931    -0.162424   -0.120673    0.704995   -0.118093   -0.0317469   -0.110855     -0.0221941  -0.0148524   0.187082     0.297858     0.201489    -0.110861   -0.0202192   -0.10237    -0.0324451    0.0229624  -0.518993     0.0273571    0.126491
 -0.129544     0.626362     0.515056   -0.687022    0.139272    0.274155    -0.76073     -0.561162    0.63436    -0.886442   -0.11679     0.0740436    0.0345568     0.0636743  -0.423114   -0.285121    -0.0818173   -0.391916     0.559518   -0.23351      0.473511   -0.325332    -0.0888571   1.06107     -0.662105     0.403881[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407020
[ Info: iteration 2, average log likelihood -1.407012
[ Info: iteration 3, average log likelihood -1.407005
[ Info: iteration 4, average log likelihood -1.406997
[ Info: iteration 5, average log likelihood -1.406990
[ Info: iteration 6, average log likelihood -1.406983
[ Info: iteration 7, average log likelihood -1.406976
[ Info: iteration 8, average log likelihood -1.406969
[ Info: iteration 9, average log likelihood -1.406962
[ Info: iteration 10, average log likelihood -1.406956
┌ Info: EM with 100000 data points 10 iterations avll -1.406956
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
    Testing GaussianMixtures tests passed 
