Julia Version 1.4.0-DEV.668
Commit 0570202e5f (2019-12-28 22:20 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed CMakeWrapper ─────── v0.2.3
 Installed GaussianMixtures ─── v0.3.0
 Installed OpenBLAS_jll ─────── v0.3.7+1
 Installed ScikitLearnBase ──── v0.5.0
 Installed FillArrays ───────── v0.8.2
 Installed NearestNeighbors ─── v0.4.4
 Installed QuadGK ───────────── v2.3.1
 Installed DataStructures ───── v0.17.6
 Installed StatsBase ────────── v0.32.0
 Installed CMake ────────────── v1.1.2
 Installed Parameters ───────── v0.12.0
 Installed URIParser ────────── v0.4.0
 Installed Arpack ───────────── v0.4.0
 Installed Blosc ────────────── v0.5.1
 Installed JLD ──────────────── v0.9.1
 Installed BinaryProvider ───── v0.5.8
 Installed Missings ─────────── v0.4.3
 Installed Distances ────────── v0.8.2
 Installed PDMats ───────────── v0.9.10
 Installed SortingAlgorithms ── v0.3.1
 Installed StaticArrays ─────── v0.12.1
 Installed Compat ───────────── v2.2.0
 Installed OrderedCollections ─ v1.1.0
 Installed LegacyStrings ────── v0.4.1
 Installed Arpack_jll ───────── v3.5.0+2
 Installed DataAPI ──────────── v1.1.0
 Installed Clustering ───────── v0.13.3
 Installed SpecialFunctions ─── v0.9.0
 Installed Distributions ────── v0.21.11
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed FileIO ───────────── v1.2.0
 Installed Rmath ────────────── v0.6.0
 Installed BinDeps ──────────── v1.0.0
 Installed StatsFuns ────────── v0.9.3
 Installed HDF5 ─────────────── v0.12.5
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_lohNml/Project.toml`
 [no changes]
  Updating `/tmp/jl_lohNml/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_sscXgv/Project.toml`
 [no changes]
  Updating `/tmp/jl_sscXgv/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_zxvQzI/Project.toml`
 [no changes]
  Updating `/tmp/jl_zxvQzI/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_sQlHwa/Project.toml`
 [no changes]
  Updating `/tmp/jl_sQlHwa/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_JjSef4/Project.toml`
 [no changes]
  Updating `/tmp/jl_JjSef4/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_JjSef4/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.0
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -4.263040105660515e6, [6370.143965930976, 93629.85603406902], [-9374.76550157449 2333.197968959324 1909.6141445018302; 9314.125764799719 -2070.8114662502767 -2280.576950045434], [[14978.6261589972 -1879.5953825338752 -1066.1509756502735; -1879.5953825338752 7027.773085104507 305.97066390784744; -1066.1509756502737 305.97066390784744 6263.227938411503], [84566.54103393324 2259.5413829044055 1309.2975286007054; 2259.5413829044055 93642.79057034756 -319.447183730389; 1309.2975286007054 -319.44718373038893 93379.83408415093]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.245327e+03
      1       8.418461e+02      -4.034812e+02 |        6
      2       8.168186e+02      -2.502745e+01 |        2
      3       8.004156e+02      -1.640299e+01 |        0
      4       8.004156e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 800.4156175879843)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.047932
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.755340
[ Info: iteration 2, lowerbound -3.610872
[ Info: iteration 3, lowerbound -3.445229
[ Info: iteration 4, lowerbound -3.250533
[ Info: iteration 5, lowerbound -3.048622
[ Info: iteration 6, lowerbound -2.873822
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.747258
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.660244
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.581600
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.504746
[ Info: iteration 11, lowerbound -2.438273
[ Info: iteration 12, lowerbound -2.388185
[ Info: iteration 13, lowerbound -2.350719
[ Info: iteration 14, lowerbound -2.324025
[ Info: iteration 15, lowerbound -2.309426
[ Info: iteration 16, lowerbound -2.308636
[ Info: dropping number of Gaussions to 2
[ Info: iteration 17, lowerbound -2.302915
[ Info: iteration 18, lowerbound -2.299259
[ Info: iteration 19, lowerbound -2.299256
[ Info: iteration 20, lowerbound -2.299254
[ Info: iteration 21, lowerbound -2.299254
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Mon Dec 30 12:52:12 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Mon Dec 30 12:52:20 2019: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Mon Dec 30 12:52:23 2019: EM with 272 data points 0 iterations avll -2.047932
5.8 data points per parameter
, Mon Dec 30 12:52:25 2019: GMM converted to Variational GMM
, Mon Dec 30 12:52:34 2019: iteration 1, lowerbound -3.755340
, Mon Dec 30 12:52:34 2019: iteration 2, lowerbound -3.610872
, Mon Dec 30 12:52:34 2019: iteration 3, lowerbound -3.445229
, Mon Dec 30 12:52:34 2019: iteration 4, lowerbound -3.250533
, Mon Dec 30 12:52:34 2019: iteration 5, lowerbound -3.048622
, Mon Dec 30 12:52:34 2019: iteration 6, lowerbound -2.873822
, Mon Dec 30 12:52:35 2019: dropping number of Gaussions to 7
, Mon Dec 30 12:52:35 2019: iteration 7, lowerbound -2.747258
, Mon Dec 30 12:52:35 2019: dropping number of Gaussions to 5
, Mon Dec 30 12:52:35 2019: iteration 8, lowerbound -2.660244
, Mon Dec 30 12:52:35 2019: dropping number of Gaussions to 4
, Mon Dec 30 12:52:35 2019: iteration 9, lowerbound -2.581600
, Mon Dec 30 12:52:35 2019: dropping number of Gaussions to 3
, Mon Dec 30 12:52:35 2019: iteration 10, lowerbound -2.504746
, Mon Dec 30 12:52:35 2019: iteration 11, lowerbound -2.438273
, Mon Dec 30 12:52:35 2019: iteration 12, lowerbound -2.388185
, Mon Dec 30 12:52:35 2019: iteration 13, lowerbound -2.350719
, Mon Dec 30 12:52:35 2019: iteration 14, lowerbound -2.324025
, Mon Dec 30 12:52:35 2019: iteration 15, lowerbound -2.309426
, Mon Dec 30 12:52:35 2019: iteration 16, lowerbound -2.308636
, Mon Dec 30 12:52:35 2019: dropping number of Gaussions to 2
, Mon Dec 30 12:52:35 2019: iteration 17, lowerbound -2.302915
, Mon Dec 30 12:52:35 2019: iteration 18, lowerbound -2.299259
, Mon Dec 30 12:52:35 2019: iteration 19, lowerbound -2.299256
, Mon Dec 30 12:52:35 2019: iteration 20, lowerbound -2.299254
, Mon Dec 30 12:52:35 2019: iteration 21, lowerbound -2.299254
, Mon Dec 30 12:52:35 2019: iteration 22, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 23, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 24, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 25, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 26, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 27, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 28, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 29, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 30, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 31, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 32, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 33, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 34, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 35, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 36, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 37, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 38, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 39, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 40, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 41, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 42, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 43, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 44, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 45, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 46, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 47, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 48, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 49, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: iteration 50, lowerbound -2.299253
, Mon Dec 30 12:52:35 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601374, 95.95490777398624]
β = [178.04509222601374, 95.95490777398624]
m = [4.250300733269911 79.28686694436188; 2.000229257775371 53.8519871724613]
ν = [180.04509222601374, 97.95490777398624]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484485 -0.007644049042327337; 0.0 0.008581705166333612], [0.3758763611948365 -0.008953123827345925; 0.0 0.012748664777409425]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -1.0033095732832806
avll from llpg:  -1.0033095732832973
avll direct:     -1.0033095732832973
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9760360790646784
avll from llpg:  -0.9760360790646784
avll direct:     -0.9760360790646784
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.0360708     0.0161293     0.110406    -0.0546082  -0.112442     0.0049624    0.0492144   -0.140866    -0.123955     0.0524248     0.105425     0.051556    -0.154615   -0.0353851    0.0462343     0.0728811    0.0359777   -0.0205471     0.0479663    0.0221419   -0.103069      0.08696      -0.246479      0.0738396   -0.143493     0.0559321
 -0.0577525    -0.0549557     0.0469667    0.178575    0.152563     0.0457511   -0.0324387   -0.0797585    0.0954687    0.124098     -0.1025      -0.0631995   -0.0887567   0.10717      0.0238425    -0.0883699    0.0263172    0.0869146     0.183048    -0.114194     0.0881119     0.0206701     0.0590953    -0.0209877    0.190826    -0.053732
 -0.00915217    0.117729      0.0132329   -0.0539541   0.167749     0.0539954   -0.0054577    0.00212215  -0.199907    -0.0174035     0.0324882   -0.0908831   -0.0801697   0.0655329    0.160491      0.0248353    0.09605      0.0994184    -0.195931    -0.00460546   0.0352468    -0.0697879     0.0805002    -0.180069    -0.0890083    0.0891234
  0.0779589    -0.208717      0.144623    -0.146945    0.0642       0.129529     0.0195629    0.133376     0.12007      0.0272516     0.0380353   -0.0597659   -0.0548537  -0.0331557   -0.145317      0.0968308    0.164587     0.0322275    -0.043701    -0.00698867   0.103258     -0.0491252    -0.00316226    0.131454     0.0338041    0.0616306
  0.0791261    -0.0226        0.229815     0.0301015  -0.00456755  -0.0638971   -0.0942351   -0.0478221   -0.0080759   -0.00791266    0.103764     0.0185111   -0.0884219  -0.0264189   -0.00988938   -0.02832     -0.035425    -0.0232689    -0.0123651    0.0517549   -0.101207      0.000531712  -0.0344849    -0.0699488    0.0263697   -0.0166005
 -0.159902      0.0188296    -0.109326    -0.142969   -0.0796202    0.0609208   -0.0386407   -0.0508323    0.159622    -0.00574526   -0.176571     0.254454     0.063039    0.136808     0.173881     -0.290204    -0.018026    -0.0639378     0.129731    -0.235804    -0.157532     -0.251141      0.00382311    0.051984     0.0914033    0.0808694
  0.0687181    -0.0155989     0.0432688    0.149155   -0.0393865   -0.0281406    0.0109096    0.030348     0.166198     0.194059     -0.0847496    0.128517    -0.0160429   0.0125336    0.0275843     0.0647308    0.0367024    0.0121251     0.00463966   0.0163108    0.143063      0.0682034     0.120946      0.147122    -0.102721     0.229218
  0.150136     -0.10634       0.00212823   0.199734    0.0539302    0.0707513   -0.0817889    0.0114547   -0.177357    -0.0399929    -0.0766498    0.0785488   -0.117072   -0.0844224   -0.000636908   0.0682598    0.0587637   -0.263984      0.0227359   -0.0537909   -0.000572254   0.0529142    -0.236115     -0.076008    -0.148245     0.00355128
  0.0873181     0.0736012    -0.0168584    0.221948    0.0510766   -0.00826702   0.0425831    0.0793975   -0.0270524    0.0739543    -0.0708406   -0.0263435    0.11591     0.015863    -0.0229223    -0.00813513  -0.267586    -0.148338      0.0357465   -0.0318973   -0.0495905    -0.0372369     0.0660058    -0.1011      -0.0364821    0.0396393
  0.0313672     0.00993576    0.0318144   -0.0932494  -0.145913     0.0151404    0.0747663   -0.0728612    0.112419     0.155172      0.13884     -0.0307606   -0.0534745   0.0361171   -0.11814      -0.0480046   -0.082258    -0.188818      0.0308597    0.109633     0.026616     -0.193446     -0.0174597     0.0711305   -0.00982533  -0.0193115
 -0.109361     -0.0667846     0.022118     0.036547    0.0228965    0.0782135   -0.184857    -0.0111733    0.080247     0.185932     -0.0439301    0.0810711   -0.0355946  -0.0612788   -0.056431     -0.0292016    0.00368091   0.004374     -0.234993     0.0663377   -0.0684093     0.0452859    -0.11014      -0.0973075   -0.0449822    0.0143179
  0.0324104     0.0163931    -0.0409968   -0.203486   -0.152067     0.0788557    0.15599     -0.0113425    0.0940873    0.123341     -0.00856308  -0.0321168   -0.0191052  -0.00259615   0.0502574    -0.0120565    0.108475     0.0424354     0.080805    -0.0110086    0.0465625    -0.00689419    0.00219191    0.0393595   -0.0117142   -0.0392188
  0.187866     -0.0933988    -0.0892074    0.0622998  -0.0495571    0.12914      0.10783     -0.110308     0.0548031   -0.175276      0.0177851    0.0835409   -0.109744    0.112211    -0.106621     -0.034163    -0.0572996    0.11368      -0.0831122   -0.0972541    0.0885693    -0.00923134   -0.00606298    0.114666    -0.0582272   -0.000385758
 -0.0743803    -0.132367     -0.0423923    0.204409   -0.0182108    0.054762    -0.00600105   0.100793     0.00797871   0.119788      0.0706679   -0.0726907    0.112848   -0.112693     0.0862323    -0.310221     0.0870052    0.0748367     0.0849795    0.13202      0.13383      -0.00114798    0.0331563    -0.0268979    0.0746205   -0.017972
 -0.0427826     0.0338067    -0.125282    -0.0725625   0.0461961    0.0556728   -0.0567272   -0.0979547    0.0534641   -0.18746      -0.0497317    0.116171     0.0239524  -0.0406312   -0.0534733    -0.0966142   -0.0339837    0.0103694     0.00640712   0.0215491   -0.183482      0.0470811     0.00921325   -0.0301776    0.0396422   -0.058617
 -0.0216634     0.0605161     0.0608216   -0.0526632   0.0884504    0.0826008   -0.182937     0.0318286   -0.114986    -0.00215783    0.0526639   -0.0754248   -0.133622    0.0789958   -0.229855     -0.0410027   -0.076477     0.0843882     0.137522    -0.098773     0.0207112    -0.0321152    -0.000103256  -0.0290773    0.0322846    0.0934106
  0.0573438    -0.244315      0.0876059   -0.109987   -0.213296     0.0277894    0.0171449    0.101461     0.00579008  -0.10455       0.175523    -0.0410853    0.0742066   0.00105222  -0.0361582     0.123694    -0.0297639   -0.0061593     0.0204165    0.214258     0.131657     -0.0375529     0.167265      0.0207858   -0.166603     0.117641
 -0.0713136     0.121901     -0.00316811   0.053315   -0.149239     0.0359521   -0.255844    -0.129764     0.112941     0.0488054    -0.315008     0.0508632   -0.0762109  -0.0416922    0.0830727    -0.185722     0.131027    -0.0311784     0.096719     0.0346587   -0.110305      0.0424993     0.0974609    -0.00075834  -0.0963065   -0.0493189
 -0.0503955     0.0620005    -0.128565    -0.204294   -0.114779     0.0594551   -0.207481     0.186457     0.0846177    0.0144952    -0.170105    -0.052621    -0.0248332   0.0213376   -0.040688      0.0347885   -0.157413     0.000835212  -0.0878939    0.111966     0.085668     -0.0912795     0.0458368     0.0903918    0.163224    -0.102384
 -0.074722     -0.0393732     0.0543633    0.119118   -0.0814864    0.114543    -0.0154656    0.111698     0.0302389    0.0640105    -0.0745424   -0.00917305   0.0218956   0.0585488   -0.161324     -0.166514    -0.152436    -0.199734     -0.162118     0.0637794    0.102257      0.156332     -0.127394     -0.0977329   -0.0889515    0.0292534
 -0.000439926  -0.0923683    -0.165913    -0.119755    0.0136636    0.0657307    0.0699383   -0.1996      -0.264896     0.00550248    0.199204     0.0339038   -0.0403323   0.0722161    0.141809     -0.284963    -0.0546715    0.0765165     0.203359     0.0125909   -0.0505625     0.0857322    -0.00846683   -0.0851713   -0.0549894    0.0690593
 -0.145299      0.0994884    -0.127477    -0.159318    0.0463743    0.0230265    0.0939848    0.169121    -0.0157848   -0.0508308     0.204326    -0.0797843   -0.173501   -0.00208849  -0.0668819    -0.00657796   0.0736676    0.152554     -0.151928     0.00441746   0.0641043     0.0681083    -0.00529223    0.0300884    0.0558951    0.160592
  0.168902     -0.016525      0.170213    -0.0904388   0.0290641   -0.117548     0.0394571    0.0238677   -0.0286631    0.000480257   0.0366852   -0.0852926    0.0787263  -0.0833931    0.0302405     0.102105    -0.00269068   0.031514     -0.131996     0.108854    -0.0814597     0.0486091    -0.0698033     0.282357    -0.199309     0.0363484
  0.0628407     0.0927384     0.0886841    0.277574   -0.0601869    0.129414     0.0801232    0.117144    -0.0480939    0.0138089    -0.19409     -0.0346355   -0.0352368   0.156164     0.00027192    0.0455879   -0.0858139   -0.203034      0.0124799    0.0961774   -0.0342619     0.0157688    -0.120915      0.157541    -0.00154894   0.215885
  0.0162952    -0.095453     -0.161533     0.149031    0.184159    -0.0648084    0.00140285   0.0865036   -0.0751469   -0.118646      0.124018     0.00701948   0.0487154   0.040797     0.053462     -0.0512096    0.163265    -0.0119427    -0.118415     0.0458681   -0.0308186    -0.0402146    -0.0867329     0.00850064  -0.0106132   -0.033976
 -0.0764388     0.107569      0.040512     0.0167944  -0.103542    -0.195919     0.183608    -0.0699354    0.205927    -0.0630555     0.0436714    0.0468605   -0.0935445  -0.119077     0.103925     -0.0228388    0.0458788    0.100129      0.0337082    0.0201998    0.0249135     0.0666323     0.0412554    -0.246285    -0.0186535   -0.0305137
 -0.0219295     0.0765275     0.153736     0.0837692  -0.057467     0.0280715    0.0187431   -0.169411     0.0889734   -0.106469     -0.0173036    0.0608218   -0.0225234   0.0790607    0.0439054    -0.0188879   -0.0858267   -0.0591426     0.0322902   -0.161107    -0.110221     -0.0057997     0.199673     -0.0281319    0.0273335    0.172155
  0.137087     -0.0151323    -0.103719     0.150824    0.0811406   -0.0275644   -0.105334     0.0221182   -0.0314142    0.0724211     0.0316094    0.0743674   -0.0887669   0.0738612    0.0999577     0.0126848    0.139613    -0.0372136    -0.222815    -0.0194653   -0.0418634    -0.114249      0.0325158     0.115728     0.087911    -0.0798938
  0.0498197     0.0692444    -0.116538    -0.0982283  -0.1398      -0.0325901    0.0896587    0.00930815  -0.235418    -0.127985      0.136316    -0.134917    -0.0719397   0.0930031    0.0811216    -0.00682146   0.040045    -0.00724579   -0.0880357   -0.0505454    0.0108087     0.114403      0.0467579     0.0711145    0.0511365   -0.0189452
 -0.0580807    -0.0778655     0.128577     0.100795    0.0893799    0.0645452    0.166372    -0.107559     0.0569019    0.0406453    -0.0829015   -0.0219818   -0.109516    0.0854339    0.114276     -0.0505263   -0.0289355    0.0825804    -0.0672422    0.125243     0.125156     -0.0524184     0.186099     -0.208618    -0.161464    -0.109988
 -0.138881      0.133125      0.00940361  -0.0153977  -0.0716721   -0.0659313    0.0943014   -0.055573     0.214026    -0.117021     -0.0884667   -0.0274974   -0.0534853   0.00128642   0.0619957     0.0826327   -0.19293     -0.01358      -0.374757     0.0471534    0.253821      0.0214969     0.158786      0.19704      0.0738501    0.036217
 -0.0573985     0.000559558  -0.0871633    0.0245495  -0.0912211   -0.111971     0.156286    -0.113845     0.0120839   -0.100774     -0.177797     0.265722    -0.30934    -0.049611    -0.0128822    -0.036306    -0.026072     0.000353061  -0.0823973   -0.0755627    0.0330799     0.00692039    0.218272      0.0259684   -0.201104     0.113502kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4178855424956174
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417958
[ Info: iteration 2, average log likelihood -1.417899
[ Info: iteration 3, average log likelihood -1.417693
[ Info: iteration 4, average log likelihood -1.415243
[ Info: iteration 5, average log likelihood -1.403537
[ Info: iteration 6, average log likelihood -1.391695
[ Info: iteration 7, average log likelihood -1.387950
[ Info: iteration 8, average log likelihood -1.386528
[ Info: iteration 9, average log likelihood -1.385769
[ Info: iteration 10, average log likelihood -1.385391
[ Info: iteration 11, average log likelihood -1.385170
[ Info: iteration 12, average log likelihood -1.385002
[ Info: iteration 13, average log likelihood -1.384843
[ Info: iteration 14, average log likelihood -1.384653
[ Info: iteration 15, average log likelihood -1.384356
[ Info: iteration 16, average log likelihood -1.383891
[ Info: iteration 17, average log likelihood -1.383352
[ Info: iteration 18, average log likelihood -1.382890
[ Info: iteration 19, average log likelihood -1.382592
[ Info: iteration 20, average log likelihood -1.382428
[ Info: iteration 21, average log likelihood -1.382340
[ Info: iteration 22, average log likelihood -1.382291
[ Info: iteration 23, average log likelihood -1.382262
[ Info: iteration 24, average log likelihood -1.382245
[ Info: iteration 25, average log likelihood -1.382233
[ Info: iteration 26, average log likelihood -1.382226
[ Info: iteration 27, average log likelihood -1.382220
[ Info: iteration 28, average log likelihood -1.382217
[ Info: iteration 29, average log likelihood -1.382214
[ Info: iteration 30, average log likelihood -1.382212
[ Info: iteration 31, average log likelihood -1.382211
[ Info: iteration 32, average log likelihood -1.382210
[ Info: iteration 33, average log likelihood -1.382209
[ Info: iteration 34, average log likelihood -1.382208
[ Info: iteration 35, average log likelihood -1.382208
[ Info: iteration 36, average log likelihood -1.382208
[ Info: iteration 37, average log likelihood -1.382208
[ Info: iteration 38, average log likelihood -1.382207
[ Info: iteration 39, average log likelihood -1.382207
[ Info: iteration 40, average log likelihood -1.382207
[ Info: iteration 41, average log likelihood -1.382207
[ Info: iteration 42, average log likelihood -1.382207
[ Info: iteration 43, average log likelihood -1.382207
[ Info: iteration 44, average log likelihood -1.382207
[ Info: iteration 45, average log likelihood -1.382207
[ Info: iteration 46, average log likelihood -1.382207
[ Info: iteration 47, average log likelihood -1.382207
[ Info: iteration 48, average log likelihood -1.382207
[ Info: iteration 49, average log likelihood -1.382207
[ Info: iteration 50, average log likelihood -1.382207
┌ Info: EM with 100000 data points 50 iterations avll -1.382207
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4179577157363232
│     -1.4178989702976907
│      ⋮
└     -1.3822069303708917
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.382317
[ Info: iteration 2, average log likelihood -1.382206
[ Info: iteration 3, average log likelihood -1.381838
[ Info: iteration 4, average log likelihood -1.378556
[ Info: iteration 5, average log likelihood -1.366809
[ Info: iteration 6, average log likelihood -1.355561
[ Info: iteration 7, average log likelihood -1.351411
[ Info: iteration 8, average log likelihood -1.349802
[ Info: iteration 9, average log likelihood -1.348930
[ Info: iteration 10, average log likelihood -1.348302
[ Info: iteration 11, average log likelihood -1.347778
[ Info: iteration 12, average log likelihood -1.347328
[ Info: iteration 13, average log likelihood -1.346932
[ Info: iteration 14, average log likelihood -1.346589
[ Info: iteration 15, average log likelihood -1.346291
[ Info: iteration 16, average log likelihood -1.346029
[ Info: iteration 17, average log likelihood -1.345794
[ Info: iteration 18, average log likelihood -1.345580
[ Info: iteration 19, average log likelihood -1.345381
[ Info: iteration 20, average log likelihood -1.345191
[ Info: iteration 21, average log likelihood -1.345005
[ Info: iteration 22, average log likelihood -1.344822
[ Info: iteration 23, average log likelihood -1.344643
[ Info: iteration 24, average log likelihood -1.344468
[ Info: iteration 25, average log likelihood -1.344290
[ Info: iteration 26, average log likelihood -1.344106
[ Info: iteration 27, average log likelihood -1.343916
[ Info: iteration 28, average log likelihood -1.343715
[ Info: iteration 29, average log likelihood -1.343492
[ Info: iteration 30, average log likelihood -1.343239
[ Info: iteration 31, average log likelihood -1.342948
[ Info: iteration 32, average log likelihood -1.342597
[ Info: iteration 33, average log likelihood -1.342162
[ Info: iteration 34, average log likelihood -1.341637
[ Info: iteration 35, average log likelihood -1.341101
[ Info: iteration 36, average log likelihood -1.340710
[ Info: iteration 37, average log likelihood -1.340536
[ Info: iteration 38, average log likelihood -1.340461
[ Info: iteration 39, average log likelihood -1.340413
[ Info: iteration 40, average log likelihood -1.340370
[ Info: iteration 41, average log likelihood -1.340325
[ Info: iteration 42, average log likelihood -1.340275
[ Info: iteration 43, average log likelihood -1.340215
[ Info: iteration 44, average log likelihood -1.340141
[ Info: iteration 45, average log likelihood -1.340049
[ Info: iteration 46, average log likelihood -1.339936
[ Info: iteration 47, average log likelihood -1.339796
[ Info: iteration 48, average log likelihood -1.339632
[ Info: iteration 49, average log likelihood -1.339450
[ Info: iteration 50, average log likelihood -1.339266
┌ Info: EM with 100000 data points 50 iterations avll -1.339266
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3823170856378693
│     -1.3822063959300113
│      ⋮
└     -1.3392656303673272
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.339244
[ Info: iteration 2, average log likelihood -1.338977
[ Info: iteration 3, average log likelihood -1.338481
[ Info: iteration 4, average log likelihood -1.334012
[ Info: iteration 5, average log likelihood -1.318160
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.301620
[ Info: iteration 7, average log likelihood -1.308674
[ Info: iteration 8, average log likelihood -1.298595
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.290541
[ Info: iteration 10, average log likelihood -1.302915
[ Info: iteration 11, average log likelihood -1.294530
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.287613
[ Info: iteration 13, average log likelihood -1.300898
[ Info: iteration 14, average log likelihood -1.293099
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.286626
[ Info: iteration 16, average log likelihood -1.300164
[ Info: iteration 17, average log likelihood -1.292598
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.286309
[ Info: iteration 19, average log likelihood -1.299906
[ Info: iteration 20, average log likelihood -1.292439
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.286219
[ Info: iteration 22, average log likelihood -1.299811
[ Info: iteration 23, average log likelihood -1.292374
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.286177
[ Info: iteration 25, average log likelihood -1.299761
[ Info: iteration 26, average log likelihood -1.292332
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.286143
[ Info: iteration 28, average log likelihood -1.299726
[ Info: iteration 29, average log likelihood -1.292295
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.286107
[ Info: iteration 31, average log likelihood -1.299689
[ Info: iteration 32, average log likelihood -1.292249
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.286054
[ Info: iteration 34, average log likelihood -1.299636
[ Info: iteration 35, average log likelihood -1.292181
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.285972
[ Info: iteration 37, average log likelihood -1.299558
[ Info: iteration 38, average log likelihood -1.292079
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.285841
[ Info: iteration 40, average log likelihood -1.299417
[ Info: iteration 41, average log likelihood -1.291893
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.285600
[ Info: iteration 43, average log likelihood -1.299124
[ Info: iteration 44, average log likelihood -1.291463
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.284954
[ Info: iteration 46, average log likelihood -1.298262
[ Info: iteration 47, average log likelihood -1.290449
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.284001
[ Info: iteration 49, average log likelihood -1.297590
[ Info: iteration 50, average log likelihood -1.290032
┌ Info: EM with 100000 data points 50 iterations avll -1.290032
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3392437183392099
│     -1.3389771865321318
│      ⋮
└     -1.2900318151517023
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.283922
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.283641
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.282617
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.271943
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.240081
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      7
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.212272
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.213013
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      7
│      8
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.208672
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.214376
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      6
│      7
│      8
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.205369
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.220492
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      7
│      8
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.200415
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.218835
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.218216
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.207182
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      7
│      8
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.199865
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      7
│      8
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.204103
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      7
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.217779
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.216949
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     1
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.196722
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.205250
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      7
│      8
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.211655
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.221645
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      6
│      7
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.198943
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.217640
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      7
│      8
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.196785
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.207498
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      6
│      7
│      8
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.199003
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.219379
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      7
│      8
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.199233
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.217520
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     1
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.203471
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.211556
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      7
│      8
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.201868
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      8
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.207414
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      6
│      7
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.203966
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.221998
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.199484
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.195365
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      6
│      7
│      8
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.203825
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.230756
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      7
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.206171
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.208133
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      7
│      8
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.202447
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.210980
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      7
│      8
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.203179
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.206400
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      7
│      8
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.205019
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.220852
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     1
│     6
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.207337
┌ Info: EM with 100000 data points 50 iterations avll -1.207337
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2839223150383652
│     -1.2836411611320475
│      ⋮
└     -1.2073369928763835
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     13
│     14
│     15
│     16
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.211604
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     20
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.195249
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│     13
│     14
│     15
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.194809
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│     11
│     12
│     13
│      ⋮
│     20
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.178408
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│      ⋮
│     19
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.155918
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.132851
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      4
│     13
│      ⋮
│     19
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.130222
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.124958
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.120588
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│     11
│     12
│     13
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.118396
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│      ⋮
│     20
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.129202
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.110094
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      3
│      4
│     13
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.117306
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     20
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.128270
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.102802
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│     11
│     12
│     13
│      ⋮
│     20
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.113857
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.106704
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.116678
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      4
│     13
│      ⋮
│     20
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.117994
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.116959
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.100826
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│     11
│     12
│     13
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.111000
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│      ⋮
│     21
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.109632
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.102449
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│     13
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.103934
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.116671
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.099612
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│     11
│     12
│     13
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.101327
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.103637
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.110103
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      4
│     13
│      ⋮
│     20
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.109677
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.108745
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.093746
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│     11
│     12
│     13
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.108991
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│      ⋮
│     21
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.109336
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.102324
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│     13
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.103820
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.116628
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.099544
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│     11
│     12
│     13
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.101220
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.103569
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.110087
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      4
│     13
│      ⋮
│     20
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.109671
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.108723
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.093730
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│     11
│     12
│     13
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.108982
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│      ⋮
│     21
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.109329
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.102316
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      3
│      4
│     13
│      ⋮
│     23
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.103815
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.116624
┌ Info: EM with 100000 data points 50 iterations avll -1.116624
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2116040073071597
│     -1.1952490578592707
│      ⋮
└     -1.116624236252995
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4178855424956174
│     -1.4179577157363232
│     -1.4178989702976907
│     -1.417693418606605
│      ⋮
│     -1.102315560266431
│     -1.1038149784268612
└     -1.116624236252995
32×26 Array{Float64,2}:
 -0.0621402   -0.0197888   -0.00432706   0.0353584     0.0686118   0.0503344   -0.0598145     0.0156713   -0.0232787   0.0706267    0.0161244   -0.0259812    -0.0180602  -0.0142168    0.0641864   -0.0969355    0.05506      0.0430843   -0.126606     0.0516174    0.0355976   -0.000365054   0.00607182  -0.116862   -0.0239101    0.0494506
 -0.0829033   -0.0416785   -0.0793254    0.0194296    -0.121249   -0.0970958    0.185285     -0.102577     0.0115675  -0.0929897   -0.145787     0.216939     -0.293924   -0.0514825   -0.0333733   -0.031253    -0.0236826    0.00853685  -0.0757152   -0.0864896    0.0265661    0.0150697     0.204319     0.0263377  -0.194272     0.111105
  0.00128654  -0.00237579   0.0775283   -0.0636317    -0.0767655   0.019089     0.0510052    -0.136729    -0.078173    0.0536238    0.0959614    0.0462512    -0.141367   -0.0360861    0.0291437    0.0820296    0.0266862   -0.0183309    0.0480608    0.023112    -0.115895     0.0845172    -0.239674     0.0691597  -0.139235     0.0585628
  0.0834484   -0.193534     0.136773    -0.183169      0.0400817   0.1318       0.0158232     0.140394     0.10079     0.0159545    0.0176357   -0.0718443    -0.0484826  -0.0236153   -0.168943     0.0878065    0.165145     0.0437882   -0.0430085    0.0518224    0.106496    -0.0523138    -0.00548004   0.127309    0.062982     0.0636028
 -0.0870575   -0.0403296    0.0495308    0.142129     -0.0766905   0.115025    -0.0354338     0.108476     0.0273391   0.0656461   -0.0555486   -0.000860642   0.0261157   0.106192    -0.139702    -0.19221     -0.154714    -0.194816    -0.165195     0.0667967    0.0963812    0.146761     -0.124649    -0.100686   -0.0763417    0.0332498
 -0.0441139    0.0705597   -0.0656735   -0.0575611    -0.126719   -0.0470205    0.0870745    -0.0131814   -0.0645205  -0.105427     0.0470889   -0.0647093    -0.0399494   0.0627374    0.0617154    0.0351978   -0.0254972   -0.0168848   -0.205006    -0.00460648   0.110901     0.0766683     0.0854617    0.11027     0.0670583    0.0115184
 -0.0556117   -0.0868352    0.0353576    0.18159       0.143856    0.0515822   -0.0355037    -0.0814266    0.0949595   0.132956    -0.0901286   -0.10356      -0.15199     0.114047     0.0489284   -0.110031     0.0267553    0.0910348    0.19342     -0.11589      0.0800377    0.0240504     0.0376716   -0.0181981   0.155083    -0.0520658
 -0.0129266   -0.0278645   -0.0203668   -0.0601475     0.0514518   0.0628315   -0.0414145    -0.0821434   -0.133329   -0.00382531   0.108804    -0.013873     -0.0644755   0.0568093   -0.0019825   -0.191847    -0.0959609    0.0778683    0.180777    -0.0200155    0.00202753   0.0285411     0.0256558   -0.0515094  -0.00503367   0.0706771
  0.0626383   -0.100358     0.253865     0.032368     -0.0213899  -0.0473538   -0.0487041    -0.284461    -0.0296567  -0.0439538    0.145857     0.0114641    -0.0807535   0.00759725   0.00780638  -0.0234752   -0.0455198   -0.0199728   -0.0287936    0.059125    -0.0641661    0.0248171    -0.00344233  -0.0745313   0.00566472  -0.0369589
  0.061325     0.0474655    0.250919     0.0267491     0.0276092  -0.0892706   -0.136491      0.228952    -0.0200343   0.0637523    0.0447815    0.00975936   -0.0993505  -0.0346932   -0.00669702  -0.0402569   -0.0480564   -0.027581     0.00416771   0.0467933   -0.17254     -0.0126578    -0.0609052   -0.0463916   0.0504744   -0.00583869
 -0.0092421   -0.0200363   -0.0603747   -1.01277      -0.140872    0.0160511    0.0839567    -0.0920279    0.114972    0.157933     0.132453    -0.0314082    -0.0487318   0.133277    -0.12859     -0.0555762   -0.00968378  -0.188381     0.0124173    0.0969184    0.0262626   -0.222304     -0.0173235    0.0522553  -0.0155167   -0.0199721
  0.191372    -0.00499343   0.210175     0.912972     -0.161327    0.0128558    0.0668252    -0.0348244    0.102818    0.149131     0.151921    -0.0307766    -0.0277086   0.0602203   -0.114584    -0.0509715   -0.230415    -0.224252     0.020139     0.128451     0.0137108   -0.185852     -0.01393      0.0790259  -0.0215358   -0.0202721
  0.140915    -0.208763    -0.112817     0.182396      0.0809105  -0.0346521   -0.942936      0.025612    -0.209584    0.283968     0.0198748    0.0743322    -0.142704    0.0734068    0.165683     0.0251025    0.12428      0.096364    -0.24314     -0.36412     -0.0406821   -0.502235      0.0514286    0.115643    0.0883774   -0.0706148
  0.139359     0.0825095    0.469429     0.0499652     0.0820488  -0.0273029   -0.0081171     0.0162423   -0.207642    0.0277355    0.0542373    0.0744728    -0.0228019   0.0729439    0.0165187   -0.0543041    0.133708    -0.0926148   -0.217676    -0.0723643   -0.0755611   -0.0837013    -0.0734465    0.115661    0.0874836   -0.0770483
  0.137483     0.128214    -0.491065     0.216939      0.0791806  -0.0268196   -0.162516      0.0162985   -0.0125016   0.0995827    0.0283638    0.0744235    -0.120472    0.0761594   -0.0562785    0.0461563    0.160145     0.0260212   -0.216873     0.403805    -0.0423893    0.143814      0.0170029    0.115634    0.0869008   -0.0899259
  0.151645    -0.0548693   -0.29826      0.212159      0.079703   -0.0283095    0.632168      0.0107059    0.363508   -0.0184813    0.0325931    0.0743923    -0.0574161   0.0751523    0.294013     0.028754     0.18993     -0.183883    -0.24288     -0.0779898    0.0600235   -0.237508      0.164628     0.115567    0.0866443   -0.0791046
  0.0166735   -0.094589    -0.174232     0.149604      0.177057   -0.0585542    0.00386319    0.0804916   -0.0701449  -0.116627     0.120845     0.0318413     0.0414427   0.0291025    0.0529942   -0.0573394    0.128249    -0.00834918  -0.0950845    0.0539707   -0.0275159   -0.106114     -0.108461     0.0118188   1.38012e-5  -0.0471962
  0.167488    -0.0272898    0.172238    -0.0616939     0.0295581  -0.113135     0.0478441    -0.00973118  -0.0248082  -0.00681753   0.0328865   -0.0812182     0.122168   -0.106047     0.0282031    0.109798     0.0062446    0.0321318   -0.19072      0.120702    -0.0798084    0.022679     -0.0566433    0.299803   -0.200036     0.00335514
 -0.0589344    0.145055     0.034671     0.161113     -0.173211   -0.765426    -0.969382     -0.185769     0.116925    0.362897    -0.309669     0.0500364    -0.0976601  -0.0644663    0.117643    -0.198439     0.139367    -0.0302348    0.0732503    0.0408587   -0.108937    -0.149824      0.0199709   -0.169143    0.340779    -0.0462508
 -0.0813053    0.109929    -0.0251964    0.00126853   -0.182889    0.369271    -0.0437374    -0.0448331    0.131029   -0.122529    -0.293764     0.0503871    -0.0596406  -0.0378064    0.0693976   -0.180366     0.11514     -0.030076     0.164081     0.0358301   -0.110449     0.0714153     0.143073     0.0725985  -0.199888    -0.0672686
  0.153115    -0.0867251   -0.0974519    0.0181752    -0.0770536   0.131942     0.09674      -0.108557     0.0993753  -0.117266    -0.00136184   0.0899966    -0.0946062   0.101487    -0.0744032   -0.0641104   -0.0654435    0.101756    -0.0247076   -0.106461     0.0408744   -0.0496115    -0.00501163   0.110012   -0.0213146   -0.0562695
 -0.0519361    0.0632434   -0.0250822    0.0300453    -0.0299723   0.102771     0.0187308     0.00883582   0.0562387  -0.0531478   -0.162462     0.095741      0.0157803   0.0882496    0.0660453   -0.114256    -0.057174    -0.107026     0.0518356   -0.0506266   -0.153934    -0.0382747    -0.0353211    0.105274    0.0439507    0.0885582
  0.0513485   -0.201767     0.0974665   -0.132899     -0.175547    0.104494    -0.00542165    0.0636741    0.0203807  -0.0936398    0.143793    -0.0279095     0.0808577  -0.0179525   -0.0587196    0.0929471   -0.0162119   -0.0271488    0.0649884    0.216898     0.0948493   -0.0335569     0.151747     0.0339829  -0.180567     0.126191
  0.144395    -0.0974648    5.50136e-5   0.198578      0.130795    0.0706311   -0.0676328    -0.00272005  -0.185036   -0.065372    -0.0526043    0.0874683    -0.0909537  -0.102154     0.00237899   0.0666       0.039202    -0.258975     0.00275336  -0.0637281    0.0187255    0.0659082    -0.269497    -0.0744749  -0.145699    -0.00932197
  0.0291324    0.0185941   -0.0218754   -0.197747     -0.148699    0.0815782    0.156734     -0.00413552   0.0952344   0.122771    -0.00432192  -0.0149479    -0.0269948  -0.00170945   0.0404618   -0.00122229   0.103653     0.0426481    0.0543903   -0.0159265    0.0917577   -0.0102467     0.0106525    0.0447204  -0.0257487   -0.0486725
 -0.0564858   -0.0815652    0.117474     0.0767878     0.062512    0.0501369    0.162436     -0.0806629    0.054914    0.0393823   -0.0651901   -0.0243545    -0.0958351   0.0785457    0.0969454   -0.0445318   -0.0200671    0.0832435   -0.0569416    0.118253     0.120622    -0.0466374     0.166213    -0.20893    -0.170553    -0.10083
 -0.236912     0.0924167   -0.108036     0.437517      0.0473332  -0.00811163   0.0766323     0.0993011   -0.0270944  -0.0712679   -0.11331     -0.0595229     0.0511174   0.0154135   -0.0167769   -0.0108621   -0.267607    -0.149859     0.02334     -0.012239    -0.175706     0.146513      0.0684275    0.0448534  -0.0478584    0.0692397
  0.475808     0.0678399    0.0826482    0.0041886     0.0465297  -0.00603843  -0.000299794   0.0399155   -0.0201865   0.251294     0.0316958    0.0363836     0.155968    0.0155066   -0.00512873  -0.00856775  -0.26717     -0.159973     0.0379948   -0.0574008    0.156317    -0.300788      0.0705937   -0.279583   -0.0452821   -0.00434682
 -0.0614746    0.104361     0.0617475    0.0223472    -0.0898675  -0.184068     0.158755     -0.0275654    0.179624   -0.0368843    0.0258144    0.0468808    -0.0857407  -0.107129     0.0751576   -0.0226905    0.0601398    0.100945     0.0332536    0.0198572    0.0176202    0.0571452     0.0619051   -0.231046   -0.00336364  -0.0296041
 -0.024631     0.0585115   -0.0568856    0.000335966   0.0218831  -0.00812873   0.0384423     0.102912     0.0815317   0.0828024    0.0599395    0.0125725    -0.101215    0.00993592  -0.0279129    0.0280032    0.0573006    0.0918579   -0.0477568    0.0041382    0.0993384    0.0701483     0.048972     0.089457   -0.0180953    0.206476
 -0.0201125    0.0820668    0.153994     0.0856616    -0.0569315   0.0299211    0.0118462    -0.167281     0.0664804  -0.0847221   -0.0170168    0.0512527    -0.0228438   0.0840424    0.0497813   -0.0130034   -0.103982    -0.0615963    0.025121    -0.162631    -0.113543    -0.00620344    0.203187    -0.0443715   0.0480607    0.166265
 -0.0386397    0.0562889   -0.129752    -0.217453     -0.123407    0.0617332   -0.20856       0.170513     0.112901    0.023749    -0.156662    -0.0515295    -0.0504695   0.0389184   -0.0417074    0.0412467   -0.165188     0.00332223  -0.0889576    0.125492     0.0871485   -0.0934142     0.0382234    0.0961794   0.111788    -0.121107[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.099539
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      3
│      4
│     11
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.079470
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.091812
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      3
│      4
│     11
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.083437
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.094429
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      2
│      3
│      4
│     11
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.075449
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.099373
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      3
│      4
│     11
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.078369
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.091345
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      3
│      4
│     11
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.083418
┌ Info: EM with 100000 data points 10 iterations avll -1.083418
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.202431e+05
      1       7.037419e+05      -2.165012e+05 |       32
      2       6.731473e+05      -3.059461e+04 |       32
      3       6.532048e+05      -1.994251e+04 |       32
      4       6.422813e+05      -1.092342e+04 |       32
      5       6.366201e+05      -5.661200e+03 |       32
      6       6.333377e+05      -3.282461e+03 |       32
      7       6.308429e+05      -2.494787e+03 |       32
      8       6.290310e+05      -1.811864e+03 |       32
      9       6.279638e+05      -1.067227e+03 |       32
     10       6.274498e+05      -5.140012e+02 |       32
     11       6.271811e+05      -2.686693e+02 |       32
     12       6.270343e+05      -1.468604e+02 |       32
     13       6.269486e+05      -8.567400e+01 |       32
     14       6.268918e+05      -5.681841e+01 |       32
     15       6.268485e+05      -4.331812e+01 |       32
     16       6.268158e+05      -3.265083e+01 |       31
     17       6.267912e+05      -2.458830e+01 |       31
     18       6.267691e+05      -2.209701e+01 |       32
     19       6.267335e+05      -3.562973e+01 |       32
     20       6.266912e+05      -4.224569e+01 |       31
     21       6.266516e+05      -3.967750e+01 |       30
     22       6.266043e+05      -4.722464e+01 |       32
     23       6.265387e+05      -6.567562e+01 |       31
     24       6.264199e+05      -1.188062e+02 |       31
     25       6.262269e+05      -1.929765e+02 |       32
     26       6.259045e+05      -3.223422e+02 |       32
     27       6.255246e+05      -3.799272e+02 |       32
     28       6.251238e+05      -4.007836e+02 |       32
     29       6.248163e+05      -3.075195e+02 |       32
     30       6.246588e+05      -1.575430e+02 |       32
     31       6.245620e+05      -9.674242e+01 |       32
     32       6.244930e+05      -6.898471e+01 |       31
     33       6.244359e+05      -5.716285e+01 |       31
     34       6.243904e+05      -4.551556e+01 |       32
     35       6.243498e+05      -4.052966e+01 |       29
     36       6.243112e+05      -3.868274e+01 |       32
     37       6.242602e+05      -5.090897e+01 |       32
     38       6.242032e+05      -5.708826e+01 |       32
     39       6.241405e+05      -6.263495e+01 |       32
     40       6.240742e+05      -6.634329e+01 |       32
     41       6.240047e+05      -6.950925e+01 |       31
     42       6.239170e+05      -8.768004e+01 |       32
     43       6.238115e+05      -1.055161e+02 |       32
     44       6.236994e+05      -1.120295e+02 |       31
     45       6.236312e+05      -6.825748e+01 |       31
     46       6.235806e+05      -5.057050e+01 |       32
     47       6.235479e+05      -3.268034e+01 |       32
     48       6.235277e+05      -2.019653e+01 |       30
     49       6.235107e+05      -1.702747e+01 |       31
     50       6.234957e+05      -1.498756e+01 |       30
K-means terminated without convergence after 50 iterations (objv = 623495.7253115703)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.343764
[ Info: iteration 2, average log likelihood -1.314166
[ Info: iteration 3, average log likelihood -1.287399
[ Info: iteration 4, average log likelihood -1.258471
[ Info: iteration 5, average log likelihood -1.228113
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.192489
[ Info: iteration 7, average log likelihood -1.169639
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     16
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.125294
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.150086
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.135972
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.136195
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     10
│     16
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.097623
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      5
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.117466
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.125589
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      9
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.102110
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      6
│     16
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.087148
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.135668
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.116865
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.100750
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      5
│      6
│     16
│     24
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.075195
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.146779
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.108566
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     7
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.092553
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│      6
│     16
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.092334
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.140531
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.113467
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     7
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.102098
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.107168
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.112251
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      9
│     13
│     20
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.088589
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.139358
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.092410
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     16
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.106131
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.103307
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     13
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.107651
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      5
│      6
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.088090
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     16
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.123302
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.112542
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.101199
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     13
│     16
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.083423
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     20
│     24
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.117722
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.143070
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.113412
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      6
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.070943
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      9
│     13
│     16
│     24
│     25
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.075564
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.158429
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.115882
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      6
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.080955
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      9
│     16
│     24
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.088717
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.121526
┌ Info: EM with 100000 data points 50 iterations avll -1.121526
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0825624    -0.038899     -0.0830878    0.0469059   -0.122701    -0.0954368    0.179293    -0.0980017    0.0140516    -0.0863807   -0.152246      0.213943     -0.277344    -0.0448113   -0.0101165    -0.0361472    -0.0261549    0.00463362  -0.0602138   -0.0512992    0.0213036    0.0133585    0.199555      0.0296475   -0.211335     0.111388
 -0.00124749   -0.102132     -0.0974913   -0.105904     0.0218424    0.0430881    0.0550539   -0.203382    -0.246245      0.00204882   0.180153      0.0330158    -0.0376304    0.0745257    0.14277      -0.291106     -0.0649323    0.0820366    0.173056     0.0197313   -0.0428391    0.0803107    0.0398561    -0.0768508   -0.0573111    0.0661906
 -0.0547168    -0.0849439     0.0353721    0.181118     0.143302     0.0501267   -0.0341651   -0.0802343    0.0955084     0.130331    -0.0885965    -0.100941     -0.150327     0.113476     0.0469621    -0.110231      0.0266357    0.0909586    0.194677    -0.115055     0.078601     0.0241292    0.0398137    -0.0184747    0.152971    -0.0515883
  0.0467833     0.0696738    -0.117179    -0.0938089   -0.140037    -0.0405595    0.077107     0.0200884   -0.221914     -0.10607      0.139594     -0.0963157    -0.0517933    0.10907      0.100869      0.00545971    0.036952    -0.0210821   -0.0813084   -0.04723      0.0264687    0.122006     0.0463693     0.0446447    0.0514883   -0.0134329
 -0.0692866     0.262997      0.00200155   0.058641    -0.16435      0.0445555   -0.498126    -0.0542305    0.102903     -0.0329277   -0.199572      0.0257472    -0.0402966   -0.0470509    0.0706015    -0.2253        0.135685    -0.0234816    0.201143     0.0211134   -0.0829307   -0.00702836   0.122138      0.00488292  -0.0304185   -0.0312278
 -0.000556679   0.00317655    0.0784844   -0.0695586   -0.0712119    0.0243985    0.0476152   -0.121764    -0.0651276     0.0509585    0.107539      0.0341988    -0.126824    -0.0351849    0.0179124     0.0720437     0.0270406   -0.0160023    0.0408547    0.0192276   -0.109234     0.0777317   -0.230874      0.0689314   -0.135267     0.0572571
 -0.157019      0.0312019    -0.111305    -0.15176     -0.0579094    0.073918    -0.0364436   -0.0532099    0.137175     -0.0060425   -0.192647      0.23475       0.0605217    0.115652     0.180198     -0.280585     -0.0148381   -0.0707854    0.129085    -0.234518    -0.165517    -0.190974     0.00396275    0.0491526    0.102269     0.1099
 -0.0144549     0.108297      0.00547292  -0.0371111    0.181421     0.0597506   -0.00830813   0.00615191  -0.167022     -0.00635306   0.0340237    -0.0788164    -0.0762143    0.0596363    0.134649      0.0269785     0.0848002    0.0917668   -0.19606      0.00244259   0.0254756   -0.0610039    0.0729573    -0.178258    -0.0781622    0.11926
  0.011595      0.00224461   -0.0286341   -0.163409    -0.161604     0.0765494    0.132063     0.0124009    0.0805162     0.121003     0.0158132    -0.0561199     0.00912249  -0.00885093   0.0464246    -0.0295345     0.101454     0.0416073    0.0716424   -0.0166218    0.0921525   -0.0180693    0.0201127     0.0327396   -0.00867397  -0.0668585
  0.0588654    -0.0828314     0.101228    -0.11716      0.0371503    0.102127    -0.0551844    0.0906349    0.0166514     0.00976737   0.0416209    -0.0592217    -0.0868676    0.0315766   -0.179183      0.0114964     0.0335067    0.0351428    0.0585899   -0.00515171   0.0625153   -0.0506414   -0.00446299    0.0636589    0.0445874    0.064384
  0.0182081    -0.0931359    -0.174744     0.150818     0.179053    -0.0559757    0.00501035   0.0756505   -0.0687597    -0.115178     0.120839      0.0316021     0.0417874    0.0285632    0.0530836    -0.0570416     0.131026    -0.00658327  -0.0937128    0.054618    -0.027147    -0.10639     -0.107799      0.0130426    0.00238767  -0.0527012
  0.117151     -0.0720474    -0.00911235   0.183443    -0.199477     0.176461    -0.122322     0.0294117   -0.179988     -0.0220445    0.0481623    -0.000352139   0.0251223   -0.0296512    0.00422216    0.153949     -0.00813655  -0.252586     0.052855    -0.0514692    0.129795     0.0891118   -0.282612     -0.0705676   -0.172117    -0.0151442
  0.0815571    -4.41993e-5    0.0388845    0.144951    -0.0288466   -0.0235641    0.0140532    0.0395187    0.178979      0.191586    -0.0888344     0.124561     -0.0151379    0.0163121   -0.0040018     0.0627613     0.0320853    0.0320981    0.00929635   0.0194252    0.136775     0.0669861    0.105822      0.15031     -0.102882     0.24088
  0.0678344    -0.0278564     0.250031     0.0294188    0.00139643  -0.0682796   -0.0916761   -0.0279344   -0.0247557     0.0103691    0.0940796     0.0102943    -0.0894383   -0.013745     0.000329008  -0.032122     -0.0466394   -0.0238268   -0.012667     0.0526874   -0.117768     0.00557262  -0.0318541    -0.0604682    0.0277761   -0.0218948
 -0.0365889     0.0569818    -0.131736    -0.218969    -0.127015     0.061819    -0.207466     0.1706       0.114696      0.0261224   -0.15843      -0.0515199    -0.0539295    0.0389326   -0.0428382     0.0429258    -0.165462     0.00214362  -0.0891232    0.126886     0.0849309   -0.0935402    0.0381288     0.0964167    0.113356    -0.122261
  0.0316768    -0.271325      0.185751    -0.209853    -0.186965     0.101492     0.0166532    0.0655277    0.020662     -0.220245     0.127174     -0.0427013     0.0770701   -0.0213796   -0.0285519     0.189663      0.00607166  -0.017082     0.110883     0.281655     0.102179    -0.0222789    0.235038      0.0702635   -0.235675     0.120508
 -0.103976     -0.0688338     0.0308147    0.0376488   -0.0217961    0.0790885   -0.158936    -0.0222325    0.0894233     0.186017    -0.068182      0.0685166    -0.0367822   -0.0570952   -0.0316266    -0.0503817     0.0120257    0.00367588  -0.182866     0.0786751   -0.0716252    0.0460618   -0.112475     -0.0936845   -0.0273708   -0.00598892
  0.168545     -0.137058      0.00156703   0.200889     0.296573    -0.00222274  -0.00385136  -0.0248704   -0.149168     -0.110318    -0.118361      0.128696     -0.153154    -0.109962    -0.00425342   -0.000928429   0.0472421   -0.219126    -0.00480195  -0.0649683    0.0173825    0.0250509   -0.198141     -0.0474811   -0.145956    -0.00783356
 -0.0515241     0.0992977     0.0584764    0.0112773   -0.0920841   -0.160834     0.16615     -0.0288928    0.173063     -0.0249004    0.0251924     0.0513813    -0.0726121   -0.103753     0.0743324    -0.0202834     0.0685284    0.0902601    0.0499057    0.0174447    0.0149008    0.0514548    0.0595303    -0.207183    -0.00199863  -0.0303492
  0.141946     -0.000719289  -0.102778     0.163559     0.080813    -0.0289491   -0.117606     0.0176149   -0.0220468     0.0966826    0.0340093     0.0742111    -0.0853924    0.0743858    0.0952137     0.0101052     0.15127     -0.0385803   -0.228231    -0.0115276   -0.0274472   -0.154607     0.0348367     0.115523     0.0874885   -0.0794627
  0.159687     -0.0279175     0.171873    -0.0663528    0.00783544  -0.11618      0.0495907   -0.0210302   -0.00901328    0.00138182   0.000994894  -0.0669672     0.0978394   -0.0939796    0.0365435     0.0900943     0.0167503    0.0254599   -0.1659       0.111852    -0.0861707    0.0183915   -0.0457151     0.295841    -0.201616     0.00126066
 -0.0314726     0.0340278    -0.129466    -0.0762072    0.0180049    0.088103    -0.0451563   -0.095722     0.070581     -0.179026    -0.052242      0.107646      0.0418479   -0.044313    -0.0558724    -0.10818      -0.0313119    0.0123112    0.0159584   -0.007314    -0.172138     0.0533796    0.0112777    -0.0134262    0.0576822   -0.0556132
 -0.143286      0.113393     -0.129665    -0.15944      0.0466391    0.0165538    0.0998786    0.153622     0.000415012  -0.0274741    0.201544     -0.0996596    -0.19165     -0.00195822  -0.0517388    -0.00678788    0.0808523    0.147949    -0.109699    -0.017366     0.0618667    0.0580199   -0.0259277     0.0241195    0.0520559    0.143518
 -0.048247     -0.209984     -0.0807929    0.19357     -0.100698     0.0634495    0.00561375   0.072053     0.0421976     0.228309    -0.00489677   -0.0529368     0.0516102   -0.0600255    0.0663197    -0.372812      0.10224      0.023866     0.160484     0.125005     0.0765218    0.0192521    0.0637144    -0.0526601    0.0334076    0.0150423
  0.155216     -0.0858538    -0.0934004   -0.00491067  -0.0841116    0.133789     0.1327      -0.0982889    0.0902429    -0.134816     0.0648051     0.0565364    -0.0977589    0.0815821   -0.0960488    -0.053771     -0.0547182    0.109419    -0.0720031   -0.0856239    0.120292    -0.043084     0.0034125     0.119563    -0.0181975   -0.0560887
 -0.0873293    -0.0423717     0.0532255    0.141361    -0.0770198    0.112908    -0.0371673    0.112158     0.0258125     0.0665494   -0.0560162    -0.0039221     0.0254535    0.105866    -0.141915     -0.185971     -0.159239    -0.199876    -0.165594     0.0697151    0.0973673    0.150895    -0.125333     -0.10007     -0.0803841    0.0338573
 -0.145637      0.0831854     0.00525156  -0.0194099   -0.0671108   -0.0669058    0.110055    -0.0565881    0.200158     -0.122453    -0.0844285    -0.0389525    -0.0448324    0.00831533   0.0633034     0.0524373    -0.148369    -0.0198879   -0.366675     0.0606791    0.247352     0.0211842    0.16685       0.163724     0.0822274    0.0504818
 -0.0456943    -0.0709728     0.1057       0.0399342    0.0444152    0.0549065    0.161305    -0.0724145    0.061465      0.0499493   -0.0562524    -0.0253984    -0.0966497    0.069216     0.0869965    -0.0430258    -0.00617805   0.076715    -0.0565909    0.101374     0.118182    -0.0420162    0.15285      -0.179041    -0.138589    -0.0888492
  0.128187      0.0770837    -0.0150996    0.240227     0.0366152    0.0060082    0.00401106   0.0637339   -0.0196407     0.108544    -0.0341163    -0.0304204     0.118723     0.0150486   -0.00695837   -0.0153913    -0.249663    -0.144623     0.035647    -0.0373995   -0.00723785  -0.0884742    0.0684967    -0.123951    -0.0404793    0.0367126
  0.058401     -0.00904236    0.0668415   -0.110839    -0.131709     0.0136929    0.0760157   -0.0856716    0.104511      0.163859     0.158451     -0.0375711    -0.0174742    0.108785    -0.112578     -0.0685778    -0.204219    -0.228603     0.0040329    0.130463     0.020978    -0.218279    -0.000799939   0.0516976   -0.0116985   -0.00948882
 -0.0200961     0.0824023     0.153879     0.0852746   -0.0575272    0.0299402    0.0144899   -0.169076     0.0625311    -0.0881897   -0.0171203     0.053022     -0.023266     0.0846826    0.0488682    -0.0125699    -0.103057    -0.061688     0.026688    -0.163061    -0.115586    -0.00540381   0.208433     -0.0456294    0.0507719    0.165962
  0.0718161     0.0697836     0.0720766    0.206017    -0.0493746    0.136966     0.105505     0.099094    -0.03087      -0.0117073   -0.192917     -0.0073362    -0.0420606    0.125315     0.00377869    0.0344449    -0.0679369   -0.155924     0.0261295    0.0358572   -0.0828232    0.0284818   -0.106967      0.187842    -0.0396451    0.121002[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.116730
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      6
│      7
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.070434
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.051567
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      6
│      7
│     13
│     20
│     24
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.063506
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.087342
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.048192
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      6
│      7
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.082519
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.032337
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.115378
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      6
│      7
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.074461
┌ Info: EM with 100000 data points 10 iterations avll -1.074461
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.1194       0.144265     0.162964    -0.207321   -0.0108421    0.146377   -0.169113     0.0361404    -0.0470422    0.153303    -0.0392923   0.254519     -0.153184      0.119259    -0.11959      0.0433123    0.354859    -0.0403433   -0.13119      0.066962     0.0411127  -0.0780852    0.177998    -0.140941    -0.0736806   -0.0714032
  0.0928078   -0.123147     0.140233    -0.0838338   0.112758    -0.0852719  -0.172667    -0.0911497     0.0108688   -0.0710927   -0.0811694   0.0743759    -0.062181     -0.0372946    0.12183     -0.00414556   0.224659     0.154646     0.105846    -0.0651318   -0.12539    -0.00345606  -0.103183     0.103164    -0.0147612   -0.0699995
  0.165319    -0.179446    -0.0425017    0.199634    0.123862    -0.159478   -0.0220585   -0.0574859    -0.00654365  -0.0634581    0.017958    0.0320283    -0.0152161     0.0568605    0.0674945    0.107253    -0.0251094    0.142527     0.137535     0.0226767    0.344305    0.0815552   -0.0314136   -0.075056     0.0160071   -0.123803
 -0.00937134   0.0479169   -0.067567     0.044294   -0.0368504   -0.0220576  -0.126053     0.00943509   -0.202173    -0.277282    -0.043115    0.0546004     0.0170038    -0.109278    -0.132586     0.0190173    0.117357    -0.0228411    0.0596614   -0.0882024   -0.104942   -0.0679488   -0.124584    -0.00825384   0.0805409   -0.0951407
 -0.0595307   -0.0958086   -0.00438007   0.0494054   0.0521108    0.0356683   0.103157     0.0243305    -0.0642142   -0.00819839   0.130688    0.215609     -0.026351      0.0133839    0.0122126    0.202381     0.0274558   -0.0329436   -0.0530233   -0.0509844    0.0689826   0.0672951   -0.144409    -0.0308908   -0.0510363    0.1562
 -0.034884     0.0777459   -0.0733663   -0.111647   -0.0672769    0.13755     0.0231709    0.000595704  -0.106735    -0.0947023   -0.127091    0.0788222    -0.283021      0.218709     0.0743166    0.0242666   -0.0451199   -0.14119     -0.0371368   -0.0334659   -0.0819481  -0.101554     0.022737     0.141769     0.287695    -0.0870984
 -0.0509322   -0.0449713   -0.0107303    0.193349   -0.069712     0.0983915  -0.0385778   -0.0985365     0.074315     0.0555032    0.0909301   0.00759159    0.121022      0.202256     0.0999373   -0.0298672   -0.0704267   -0.0695456   -0.155778    -0.0786658    0.0520402  -0.251253     0.0902915    0.0471112    0.0779864   -0.0107146
  0.0385359   -0.0521217   -0.109874     0.0754514   0.0820227   -0.0717341   0.129427     0.0109127    -0.0643331   -0.16636      0.125187   -0.0965334    -0.0272923     0.0459173    0.033664     0.036498    -0.180928     0.0410002   -0.0563456   -0.059008    -0.136978   -0.0269577   -0.0872524    0.182152     0.145538     0.0879893
 -0.0234581    0.0319063   -0.0293539   -0.0784868   0.114389    -0.144335   -0.0015304    0.0434692    -0.0307569    0.045876    -0.157924    0.00517105    0.202519     -0.0168546    0.0281333   -0.0110371    0.0196017    0.077443    -0.0764804   -0.0213521   -0.0854302   0.105251    -0.00774626   0.0368659   -0.0757688   -0.0393276
 -0.0798056    0.0135011   -0.0171684    0.0984565  -0.0646466   -0.0173406  -0.0289006    0.0507178     0.00924893   0.0553686   -0.15612    -0.0109939    -0.0139473    -0.142998    -0.24013      0.0926612   -0.138883     0.0301057   -0.139777    -0.142459     0.0682664   0.126521    -0.0689327    0.0618489   -0.190333    -0.117187
  0.0787203   -0.0517532   -0.20667     -0.0557393  -0.075195     0.0273913  -0.0729418   -0.0491252     0.0334481   -0.14089     -0.236786   -0.021927      0.0413145    -0.0418567    0.0782641    0.0261719    0.0522837   -0.0827287   -0.0510022   -0.00232987  -0.0303704  -0.0308302    0.023757    -0.0332404    0.08747      0.0330836
 -0.126429    -0.238087    -0.08809     -0.107722   -0.149405    -0.136022   -0.00842121  -0.229214     -0.0885655    0.0329201   -0.0508587   0.230572      0.053279     -0.0239029   -0.163343     0.0320923    0.169816     0.0665005    0.031842    -0.0914384    0.0833888   0.0158364    0.151001    -0.089602    -0.0809219   -0.0379807
 -0.0801939    0.166377     0.088439    -0.0481443   0.0390439   -3.2847e-6   0.171436    -0.153706     -0.171807    -0.063335     0.0618262   0.0941625     0.043761      0.0542762   -0.0572439    0.156581    -0.172615     0.00634483  -0.141293     0.22254      0.0691978  -0.0758766   -0.0317699    0.0453032   -0.117485     0.0727193
  0.0699331    0.221046    -0.0871388   -0.0566805   0.0376403    0.188419   -0.0579708   -0.0757633    -0.0568649   -0.0342693   -0.296515    0.114652      0.00661849   -0.0758799   -0.0606291   -0.134725    -0.0742319   -0.164369    -0.104741    -0.125514    -0.0248005  -0.167823     0.00150613   0.031069    -0.0439132   -0.074939
 -0.125007     0.0242497    0.130136     0.124143   -0.00399942  -0.129995    0.0239667   -0.00507717   -0.10279     -0.18592     -0.127668    0.000660118  -0.103793      0.00417475   0.168478     0.0802745    0.0737403    0.10764      0.03616     -0.0177141    0.0730693   0.0496673   -0.178248     0.0786152   -0.00503579   0.00852359
  0.128461    -0.0776566   -0.140617     0.106838   -0.0724082   -0.0588502   0.0692967   -0.107072     -0.174633     0.0832492   -0.198318   -0.0354675     0.0334029    -0.015412    -0.0206516   -0.0598268   -0.125088     0.0963627    0.0965807   -0.00614143   0.0664336   0.0454686   -0.0256947    0.0454913   -0.105612     0.0743327
  0.0637299   -0.0104728   -0.0348078   -0.138448   -0.0810985    0.225016    0.167626     0.0206191    -0.0249425    0.101337     0.0476606   0.0692455    -0.0522477    -0.0194866    0.119724    -0.0421339   -0.142927    -0.101197    -0.054195    -0.0577264   -0.0219376   0.0201847   -0.152689    -0.10491     -0.0996002    0.179063
 -0.0235839   -0.0425131   -0.0158945   -0.113454   -0.0279505    0.0977617  -0.053991    -0.0433518     0.128348     0.0700623   -0.0140516  -0.211632     -0.155137      0.0104323   -0.0272027   -0.0916795   -0.0984824   -0.211385    -0.0994335   -0.0717983    0.0169374   0.168728    -0.0789339   -0.0839677   -0.0932054   -0.0890643
  0.0705889    0.0634619    0.133045     0.140924   -0.219924    -0.0565703   0.203893     0.144194     -0.313832    -0.0189998    0.0258665   0.0212166     0.05176      -0.0874964    0.0981747   -0.0825705    0.0534655    0.0430832    0.0805449   -0.0315735    0.0453429   0.0380382   -0.0347358    0.00907653  -0.0211342   -0.145886
 -0.170838     0.00326955   0.143946     0.0536991  -0.0586706   -0.0762882  -0.153975     0.0266423     0.0284719   -0.0181204   -0.0386085   0.00280151   -0.079467     -0.0455902   -0.00456915  -0.0797763    0.0295002   -0.137425     0.131768    -0.00705373  -0.053176    0.0187545   -0.0396728    0.0468264    0.0410829   -0.0728351
 -0.0569652    0.0709723   -0.0472795   -0.0631245  -0.0343711    0.0146692  -0.197807     0.109273     -0.0010574   -0.0865638    0.041154   -0.0616535    -0.0363292     0.0853103    0.121222     0.0346971   -0.161757    -0.0484013   -0.122854    -0.138006    -0.0325799   0.0462136   -0.0763778    0.0917998    0.200743     0.0483503
 -0.067318     0.0949525    0.0783789   -0.0187186  -0.0241324   -0.0105966   0.0545765    0.0482371    -0.0709974    0.141116    -0.0446903   0.212009     -0.0392347    -0.15842      0.0467993    0.143903    -0.0374746    0.148336     0.0880152    0.161161    -0.0641971   0.0440605   -0.00762888  -0.0509366   -0.218178     0.000395672
  0.12038      0.249707    -0.241543    -0.128967   -0.0932234   -0.0886376  -0.190864     0.182166      0.056146    -0.0142092   -0.121142   -0.0864838    -0.176363     -0.0840334    0.0970578    0.0269492   -0.0661275    0.0552348    0.0453516   -0.136771    -0.0622824  -0.0580393    0.0998613   -0.0147343    0.0639181    0.0105116
 -0.100875     0.149435     0.0540307   -0.0383718  -0.0337253   -0.110835   -0.0131305    0.134706     -0.0296048   -0.0667573   -0.056201    0.100182     -0.0309391    -0.112663    -0.0511262   -0.0452416    0.0979658   -0.196184     0.0474013    0.00344568   0.0444601  -0.106442     0.134955    -0.0269568   -0.133886     0.0369366
  0.0340881    0.0940572   -0.221456    -0.142658    0.27547     -0.0512274  -0.0891489    0.06169       0.0100932   -0.165027    -0.144739    0.115117      0.0649503    -0.0012345    0.0171322   -0.126958     0.345525     0.0890723    0.152232    -0.152157    -0.0889998   0.01191      0.120491    -0.0746657   -0.00703457  -0.0396692
 -0.21633      0.0261836   -0.122832     0.116761   -0.0196967   -0.0657378  -0.104284     0.0285408    -0.137254    -0.192562    -0.0696593   0.0352421     0.00250896    0.175672     0.135684    -0.0273487   -0.0877215   -0.123754    -0.117301    -0.126501     0.190717   -0.0168837   -0.0962111    0.165903     0.00290892  -0.152517
  0.182587    -0.0377261   -0.150499     0.018674    0.0891562   -0.0380301   0.118467    -0.270053      0.0684832   -0.0432283    0.0415351  -0.050779      0.000972224  -0.162703    -0.0780638   -0.0879647   -0.114841     0.0356698    0.00109053   0.132628     0.120121    0.256531     0.063894    -0.0918785    0.11465      0.0514719
 -0.0763203   -0.120728     0.00595551  -0.222348    0.0353178   -0.0182569   0.0302785   -0.118986      0.0163979   -0.0275502    0.176175   -0.0169565     0.0234152    -0.140164     0.154109    -0.0156935   -0.123863    -0.0504788    0.082459    -0.0228294   -0.0331677   0.018995    -0.0501147   -0.0569173    0.0952369   -0.0140673
  0.0931626    0.0245991    0.158718     0.0188133  -0.252388     0.0330847  -0.0567628    0.179153     -0.0116094    0.088738     0.0239703  -0.13802      -0.0275087     0.0422049   -0.134152    -0.100797    -0.0667263   -0.16286     -0.0827713   -0.0245551   -0.028698   -0.0180128    0.0558742    0.0207106   -0.113796     0.148148
 -0.00307271   0.00083318  -0.0173346    0.190185   -0.192014     0.106001    0.0142791   -0.0589223    -0.219147    -0.0501224   -0.0836596   0.151996      0.231987     -0.0063059    0.120198    -0.0840793   -0.00887165  -0.00852525  -0.0957459   -0.00130561  -0.0494503  -0.207034    -0.0192093    0.0948816    0.0165747    0.0036375
 -0.0583137   -0.0318665    0.1688       0.0116194  -0.0681141    0.193593    0.0728787   -0.108932     -0.053826    -0.0410396   -0.039707   -0.215568      0.0695976     0.0648626   -0.0872394   -0.0429701    0.165119    -0.149599     0.106238    -0.0224304   -0.0286353  -0.0877647   -0.0512042    0.0667708   -0.097465    -0.0441485
  0.0125892    0.123251    -0.254897    -0.0410844   0.104373    -0.0155483  -0.0247579   -0.00167889   -0.108717     0.0182897    0.0149217   0.0783647     0.00932645   -0.0282515    0.0668296    0.0354098   -0.0732841    0.14334      0.2593       0.129173     0.247515    0.0198373   -0.145082     0.0281437   -0.107105     0.110356kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.42005331741797
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420072
[ Info: iteration 2, average log likelihood -1.420006
[ Info: iteration 3, average log likelihood -1.419958
[ Info: iteration 4, average log likelihood -1.419903
[ Info: iteration 5, average log likelihood -1.419837
[ Info: iteration 6, average log likelihood -1.419759
[ Info: iteration 7, average log likelihood -1.419672
[ Info: iteration 8, average log likelihood -1.419583
[ Info: iteration 9, average log likelihood -1.419500
[ Info: iteration 10, average log likelihood -1.419426
[ Info: iteration 11, average log likelihood -1.419360
[ Info: iteration 12, average log likelihood -1.419295
[ Info: iteration 13, average log likelihood -1.419214
[ Info: iteration 14, average log likelihood -1.419090
[ Info: iteration 15, average log likelihood -1.418879
[ Info: iteration 16, average log likelihood -1.418514
[ Info: iteration 17, average log likelihood -1.417930
[ Info: iteration 18, average log likelihood -1.417132
[ Info: iteration 19, average log likelihood -1.416280
[ Info: iteration 20, average log likelihood -1.415600
[ Info: iteration 21, average log likelihood -1.415184
[ Info: iteration 22, average log likelihood -1.414970
[ Info: iteration 23, average log likelihood -1.414869
[ Info: iteration 24, average log likelihood -1.414823
[ Info: iteration 25, average log likelihood -1.414802
[ Info: iteration 26, average log likelihood -1.414792
[ Info: iteration 27, average log likelihood -1.414788
[ Info: iteration 28, average log likelihood -1.414786
[ Info: iteration 29, average log likelihood -1.414785
[ Info: iteration 30, average log likelihood -1.414784
[ Info: iteration 31, average log likelihood -1.414784
[ Info: iteration 32, average log likelihood -1.414783
[ Info: iteration 33, average log likelihood -1.414783
[ Info: iteration 34, average log likelihood -1.414783
[ Info: iteration 35, average log likelihood -1.414783
[ Info: iteration 36, average log likelihood -1.414783
[ Info: iteration 37, average log likelihood -1.414783
[ Info: iteration 38, average log likelihood -1.414783
[ Info: iteration 39, average log likelihood -1.414783
[ Info: iteration 40, average log likelihood -1.414783
[ Info: iteration 41, average log likelihood -1.414783
[ Info: iteration 42, average log likelihood -1.414783
[ Info: iteration 43, average log likelihood -1.414782
[ Info: iteration 44, average log likelihood -1.414782
[ Info: iteration 45, average log likelihood -1.414782
[ Info: iteration 46, average log likelihood -1.414782
[ Info: iteration 47, average log likelihood -1.414782
[ Info: iteration 48, average log likelihood -1.414782
[ Info: iteration 49, average log likelihood -1.414782
[ Info: iteration 50, average log likelihood -1.414782
┌ Info: EM with 100000 data points 50 iterations avll -1.414782
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4200718163474033
│     -1.420006280674952
│      ⋮
└     -1.4147822303145916
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414797
[ Info: iteration 2, average log likelihood -1.414731
[ Info: iteration 3, average log likelihood -1.414676
[ Info: iteration 4, average log likelihood -1.414609
[ Info: iteration 5, average log likelihood -1.414525
[ Info: iteration 6, average log likelihood -1.414420
[ Info: iteration 7, average log likelihood -1.414300
[ Info: iteration 8, average log likelihood -1.414172
[ Info: iteration 9, average log likelihood -1.414053
[ Info: iteration 10, average log likelihood -1.413952
[ Info: iteration 11, average log likelihood -1.413875
[ Info: iteration 12, average log likelihood -1.413821
[ Info: iteration 13, average log likelihood -1.413786
[ Info: iteration 14, average log likelihood -1.413762
[ Info: iteration 15, average log likelihood -1.413746
[ Info: iteration 16, average log likelihood -1.413735
[ Info: iteration 17, average log likelihood -1.413727
[ Info: iteration 18, average log likelihood -1.413719
[ Info: iteration 19, average log likelihood -1.413713
[ Info: iteration 20, average log likelihood -1.413708
[ Info: iteration 21, average log likelihood -1.413703
[ Info: iteration 22, average log likelihood -1.413698
[ Info: iteration 23, average log likelihood -1.413694
[ Info: iteration 24, average log likelihood -1.413690
[ Info: iteration 25, average log likelihood -1.413686
[ Info: iteration 26, average log likelihood -1.413682
[ Info: iteration 27, average log likelihood -1.413678
[ Info: iteration 28, average log likelihood -1.413674
[ Info: iteration 29, average log likelihood -1.413671
[ Info: iteration 30, average log likelihood -1.413667
[ Info: iteration 31, average log likelihood -1.413664
[ Info: iteration 32, average log likelihood -1.413660
[ Info: iteration 33, average log likelihood -1.413657
[ Info: iteration 34, average log likelihood -1.413654
[ Info: iteration 35, average log likelihood -1.413650
[ Info: iteration 36, average log likelihood -1.413647
[ Info: iteration 37, average log likelihood -1.413644
[ Info: iteration 38, average log likelihood -1.413641
[ Info: iteration 39, average log likelihood -1.413638
[ Info: iteration 40, average log likelihood -1.413635
[ Info: iteration 41, average log likelihood -1.413632
[ Info: iteration 42, average log likelihood -1.413630
[ Info: iteration 43, average log likelihood -1.413627
[ Info: iteration 44, average log likelihood -1.413624
[ Info: iteration 45, average log likelihood -1.413621
[ Info: iteration 46, average log likelihood -1.413619
[ Info: iteration 47, average log likelihood -1.413616
[ Info: iteration 48, average log likelihood -1.413614
[ Info: iteration 49, average log likelihood -1.413611
[ Info: iteration 50, average log likelihood -1.413609
┌ Info: EM with 100000 data points 50 iterations avll -1.413609
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4147967220626523
│     -1.4147314590327398
│      ⋮
└     -1.4136089146685098
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413617
[ Info: iteration 2, average log likelihood -1.413557
[ Info: iteration 3, average log likelihood -1.413501
[ Info: iteration 4, average log likelihood -1.413435
[ Info: iteration 5, average log likelihood -1.413355
[ Info: iteration 6, average log likelihood -1.413258
[ Info: iteration 7, average log likelihood -1.413147
[ Info: iteration 8, average log likelihood -1.413027
[ Info: iteration 9, average log likelihood -1.412903
[ Info: iteration 10, average log likelihood -1.412782
[ Info: iteration 11, average log likelihood -1.412668
[ Info: iteration 12, average log likelihood -1.412567
[ Info: iteration 13, average log likelihood -1.412481
[ Info: iteration 14, average log likelihood -1.412411
[ Info: iteration 15, average log likelihood -1.412356
[ Info: iteration 16, average log likelihood -1.412314
[ Info: iteration 17, average log likelihood -1.412281
[ Info: iteration 18, average log likelihood -1.412255
[ Info: iteration 19, average log likelihood -1.412234
[ Info: iteration 20, average log likelihood -1.412218
[ Info: iteration 21, average log likelihood -1.412204
[ Info: iteration 22, average log likelihood -1.412192
[ Info: iteration 23, average log likelihood -1.412181
[ Info: iteration 24, average log likelihood -1.412172
[ Info: iteration 25, average log likelihood -1.412163
[ Info: iteration 26, average log likelihood -1.412156
[ Info: iteration 27, average log likelihood -1.412149
[ Info: iteration 28, average log likelihood -1.412142
[ Info: iteration 29, average log likelihood -1.412136
[ Info: iteration 30, average log likelihood -1.412131
[ Info: iteration 31, average log likelihood -1.412125
[ Info: iteration 32, average log likelihood -1.412121
[ Info: iteration 33, average log likelihood -1.412116
[ Info: iteration 34, average log likelihood -1.412112
[ Info: iteration 35, average log likelihood -1.412108
[ Info: iteration 36, average log likelihood -1.412104
[ Info: iteration 37, average log likelihood -1.412100
[ Info: iteration 38, average log likelihood -1.412096
[ Info: iteration 39, average log likelihood -1.412093
[ Info: iteration 40, average log likelihood -1.412089
[ Info: iteration 41, average log likelihood -1.412086
[ Info: iteration 42, average log likelihood -1.412083
[ Info: iteration 43, average log likelihood -1.412080
[ Info: iteration 44, average log likelihood -1.412077
[ Info: iteration 45, average log likelihood -1.412074
[ Info: iteration 46, average log likelihood -1.412070
[ Info: iteration 47, average log likelihood -1.412067
[ Info: iteration 48, average log likelihood -1.412064
[ Info: iteration 49, average log likelihood -1.412061
[ Info: iteration 50, average log likelihood -1.412058
┌ Info: EM with 100000 data points 50 iterations avll -1.412058
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4136166789860374
│     -1.413556704888081
│      ⋮
└     -1.4120582871486926
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412064
[ Info: iteration 2, average log likelihood -1.412010
[ Info: iteration 3, average log likelihood -1.411960
[ Info: iteration 4, average log likelihood -1.411901
[ Info: iteration 5, average log likelihood -1.411828
[ Info: iteration 6, average log likelihood -1.411736
[ Info: iteration 7, average log likelihood -1.411626
[ Info: iteration 8, average log likelihood -1.411502
[ Info: iteration 9, average log likelihood -1.411369
[ Info: iteration 10, average log likelihood -1.411236
[ Info: iteration 11, average log likelihood -1.411108
[ Info: iteration 12, average log likelihood -1.410986
[ Info: iteration 13, average log likelihood -1.410872
[ Info: iteration 14, average log likelihood -1.410767
[ Info: iteration 15, average log likelihood -1.410671
[ Info: iteration 16, average log likelihood -1.410584
[ Info: iteration 17, average log likelihood -1.410508
[ Info: iteration 18, average log likelihood -1.410442
[ Info: iteration 19, average log likelihood -1.410385
[ Info: iteration 20, average log likelihood -1.410336
[ Info: iteration 21, average log likelihood -1.410294
[ Info: iteration 22, average log likelihood -1.410257
[ Info: iteration 23, average log likelihood -1.410224
[ Info: iteration 24, average log likelihood -1.410195
[ Info: iteration 25, average log likelihood -1.410168
[ Info: iteration 26, average log likelihood -1.410143
[ Info: iteration 27, average log likelihood -1.410121
[ Info: iteration 28, average log likelihood -1.410100
[ Info: iteration 29, average log likelihood -1.410081
[ Info: iteration 30, average log likelihood -1.410062
[ Info: iteration 31, average log likelihood -1.410045
[ Info: iteration 32, average log likelihood -1.410029
[ Info: iteration 33, average log likelihood -1.410014
[ Info: iteration 34, average log likelihood -1.410000
[ Info: iteration 35, average log likelihood -1.409986
[ Info: iteration 36, average log likelihood -1.409973
[ Info: iteration 37, average log likelihood -1.409961
[ Info: iteration 38, average log likelihood -1.409950
[ Info: iteration 39, average log likelihood -1.409939
[ Info: iteration 40, average log likelihood -1.409928
[ Info: iteration 41, average log likelihood -1.409918
[ Info: iteration 42, average log likelihood -1.409909
[ Info: iteration 43, average log likelihood -1.409900
[ Info: iteration 44, average log likelihood -1.409891
[ Info: iteration 45, average log likelihood -1.409883
[ Info: iteration 46, average log likelihood -1.409875
[ Info: iteration 47, average log likelihood -1.409867
[ Info: iteration 48, average log likelihood -1.409860
[ Info: iteration 49, average log likelihood -1.409852
[ Info: iteration 50, average log likelihood -1.409845
┌ Info: EM with 100000 data points 50 iterations avll -1.409845
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4120637368473758
│     -1.4120095038327407
│      ⋮
└     -1.409845422705438
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409847
[ Info: iteration 2, average log likelihood -1.409784
[ Info: iteration 3, average log likelihood -1.409722
[ Info: iteration 4, average log likelihood -1.409647
[ Info: iteration 5, average log likelihood -1.409551
[ Info: iteration 6, average log likelihood -1.409430
[ Info: iteration 7, average log likelihood -1.409284
[ Info: iteration 8, average log likelihood -1.409118
[ Info: iteration 9, average log likelihood -1.408942
[ Info: iteration 10, average log likelihood -1.408767
[ Info: iteration 11, average log likelihood -1.408602
[ Info: iteration 12, average log likelihood -1.408451
[ Info: iteration 13, average log likelihood -1.408316
[ Info: iteration 14, average log likelihood -1.408197
[ Info: iteration 15, average log likelihood -1.408093
[ Info: iteration 16, average log likelihood -1.408003
[ Info: iteration 17, average log likelihood -1.407924
[ Info: iteration 18, average log likelihood -1.407856
[ Info: iteration 19, average log likelihood -1.407797
[ Info: iteration 20, average log likelihood -1.407745
[ Info: iteration 21, average log likelihood -1.407699
[ Info: iteration 22, average log likelihood -1.407658
[ Info: iteration 23, average log likelihood -1.407621
[ Info: iteration 24, average log likelihood -1.407588
[ Info: iteration 25, average log likelihood -1.407558
[ Info: iteration 26, average log likelihood -1.407531
[ Info: iteration 27, average log likelihood -1.407505
[ Info: iteration 28, average log likelihood -1.407482
[ Info: iteration 29, average log likelihood -1.407461
[ Info: iteration 30, average log likelihood -1.407440
[ Info: iteration 31, average log likelihood -1.407421
[ Info: iteration 32, average log likelihood -1.407404
[ Info: iteration 33, average log likelihood -1.407387
[ Info: iteration 34, average log likelihood -1.407371
[ Info: iteration 35, average log likelihood -1.407356
[ Info: iteration 36, average log likelihood -1.407341
[ Info: iteration 37, average log likelihood -1.407327
[ Info: iteration 38, average log likelihood -1.407314
[ Info: iteration 39, average log likelihood -1.407301
[ Info: iteration 40, average log likelihood -1.407288
[ Info: iteration 41, average log likelihood -1.407276
[ Info: iteration 42, average log likelihood -1.407264
[ Info: iteration 43, average log likelihood -1.407252
[ Info: iteration 44, average log likelihood -1.407241
[ Info: iteration 45, average log likelihood -1.407230
[ Info: iteration 46, average log likelihood -1.407219
[ Info: iteration 47, average log likelihood -1.407208
[ Info: iteration 48, average log likelihood -1.407198
[ Info: iteration 49, average log likelihood -1.407188
[ Info: iteration 50, average log likelihood -1.407178
┌ Info: EM with 100000 data points 50 iterations avll -1.407178
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4098474490887967
│     -1.4097840110368023
│      ⋮
└     -1.407177755621668
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.42005331741797
│     -1.4200718163474033
│     -1.420006280674952
│     -1.4199580547766337
│      ⋮
│     -1.407197671503087
│     -1.407187582898707
└     -1.407177755621668
32×26 Array{Float64,2}:
 -0.0566019   0.623375    -0.55526     -0.525724    -0.289506   -0.13938    -0.439003    -0.0606497  -0.103987    -0.160917     0.15126    -0.0215303  -0.274295   -0.174092     0.166835   -0.572807      0.241502    -0.0366837   -0.113067    0.0592322   -0.117912     0.185752     -0.00143025   0.0187248  -0.407071     0.616462
 -0.672012   -0.00689731  -0.542       -0.579428    -0.42466     0.0732921   0.634388     0.190348    0.0372658    0.204767    -0.224404    0.139852   -0.135065    0.0278923    0.0918495  -0.0111068     0.139771    -0.155459    -0.0915237   0.0936385   -0.367344     0.0324928    -0.459662     0.303708   -0.573112     0.707767
  0.0994327  -0.211786    -0.884268     0.127433    -0.247961    0.198487    0.0728691   -0.466567    0.0877262    0.870404     0.0979654   0.0964728   0.230443    0.110387     0.198421    0.000367159   0.741948    -0.24548     -0.0219325  -0.0716543   -0.437073    -0.5415       -0.23313     -0.402928    0.440158     0.269952
  0.457935   -0.254971    -0.472419     0.0104879   -0.317566   -0.0822769  -0.3928      -0.491106   -0.115663    -0.113315    -0.139067    0.542023   -0.23048    -0.487449     0.573026    0.236229      0.324531     0.407888    -0.465768    1.73643e-5  -0.721701    -0.500399     -0.161983     0.199905    0.104501     0.693843
  0.0121464  -0.108049     0.200402     0.209754    -0.118975   -0.0755297   0.0463246    0.153143   -0.00791214  -0.162568    -0.0395946   0.0969788   0.0458462  -0.00563542  -0.143248   -0.0208699     0.121056     0.0212124   -0.124225    0.255302    -0.0876679   -0.0450763    -0.198545    -0.131177   -0.369922     0.248832
  0.0993576   0.114674     0.107379     0.253931    -0.127217   -0.238603   -0.212258    -0.0364647  -0.250892    -0.0591543    0.0636528  -0.0153348  -0.052748    0.00194926  -0.0324966  -0.189145      0.0657077    0.0334995    0.223227   -0.0319646    0.414272    -0.000969082   0.323155    -0.0875809   0.431105    -0.13435
 -0.0339824   0.00189038  -0.321084    -0.306365     0.189345    0.246757   -0.046263    -0.158199    0.0408215    0.208072     0.139128    0.121407   -0.0251976  -0.117135     0.177985   -0.0229929    -0.217186     0.0662754   -0.124367   -0.0944474   -0.119752    -0.116808     -0.0913285    0.270567    0.0286019   -0.0949675
 -0.177836    0.224223     0.599192    -0.449772     0.37317    -0.0723679  -0.142998     0.340709   -0.088411    -0.239691     0.329992    0.231255   -0.380712    0.0615456   -0.277342    0.0487989    -0.143134    -0.172852    -0.155758    0.116835    -0.441345    -0.235607      0.329123     0.023637   -0.10849     -0.148615
  0.199707   -0.679082     0.229251     0.0704932   -0.0213725   0.292939   -0.10249     -0.521284    0.524338    -0.0838491    0.0324696  -0.224021    0.228032    0.18996     -0.208246    0.296852      0.155183     0.110551     0.0531269  -0.439713    -0.120408     0.213948      0.180561    -0.643638   -0.0730745    0.0983497
  0.288577   -0.900215     0.388545     0.47124      0.254758    0.302823    0.163528    -0.309349   -0.0370175    0.0998954   -0.433825    0.509402    0.516628    0.097867     0.0240684   0.0217395     0.0642587   -0.00109277   0.338411   -0.202752     0.475874    -0.264871      0.392584    -0.0637807   0.261214    -0.356477
  0.784689    0.0740043    0.274107    -0.0881159    0.154427   -0.0480041  -0.176266     0.0205803   0.23712     -0.0345388   -0.288571   -0.185157   -0.176369    0.327778    -0.0548667  -0.151135     -0.261389     0.128708    -0.0924953  -0.178705     0.260535     0.890926      0.0663309    0.0208845   0.186344    -0.569801
  0.160026    0.373179    -0.157801    -0.216979    -0.299413    0.133322   -0.163764    -0.267015    0.36577     -0.19405     -0.453194    0.368021    0.0823747   0.705016     0.529108    0.00851537   -0.710804    -0.183315     0.426553   -0.364458     0.189764     0.3652       -0.226529    -0.235082    0.172265    -0.159877
 -0.188191    0.158752     0.122349     0.0986275   -0.0970053  -0.103257    0.278158     0.118148   -0.835525    -0.282572    -0.280117   -0.263675    0.130001   -0.350907     0.156421    0.320354     -0.262738    -0.222558     0.0120686  -0.184053     0.574148     0.226276     -0.34769      0.503147    0.0445417   -0.193747
  0.0309472  -0.370857    -0.0799178    0.274186    -0.0609696   0.0944854   0.304991    -0.201589    0.293599     0.0960625   -0.400468   -0.216177    0.250134   -0.26845     -0.255449    0.239054     -0.145249     0.220969    -0.100772   -0.132712     0.190427    -0.00780361   -0.697512     0.559094   -0.0567262   -0.289878
 -0.485539    0.158876    -0.0879314    0.491472    -0.105592    0.0358379   0.301242     0.0887172  -0.119924    -0.48693     -0.37903    -0.13969     0.314376    0.506009    -0.173033    0.293629      0.274845    -0.549843     0.21282    -0.0552948   -0.128896    -0.0867768    -0.0751123   -0.342841    0.125349     0.0659522
 -0.416005    0.612876    -0.671338     0.376939     0.739638   -0.31068     0.373049     0.155796    0.0979394   -0.263523    -0.264552   -0.530349    0.365162    0.511214     0.281568   -0.049094     -0.136287    -0.175018     0.022765    0.0815816   -0.142334     0.341097     -0.307545    -0.224469   -0.175669    -0.592355
  0.584662   -0.229953     0.0694399   -0.251896    -0.0980911   0.0205032  -0.612183     0.552831    0.227043     0.464956    -0.34541    -0.153007    0.318682   -0.25291      0.0291826  -0.240016      0.333573    -0.366862    -0.909822    0.564271    -0.199362     0.6368       -0.134532     0.266204   -0.335534     0.129515
 -0.254625   -0.536229     0.460781    -0.652352     0.257536    0.305928   -0.0137127    0.317859    0.28587      0.488219     0.323436   -0.221149   -0.109192   -0.00416594  -0.197087    0.246406     -0.0375017   -0.156575    -0.25023    -0.189478    -1.0891      -0.0899751     0.0560208   -0.095275   -0.458879     0.0305067
 -0.332344    0.276829    -0.206165     0.194254     0.192216    0.478133   -0.168141     0.173608   -0.117525    -0.350233     0.4732      0.4224      0.327734   -0.150974    -0.20461    -0.314727     -0.00827647  -0.070092    -0.581743    0.345355    -0.415985    -0.52139      -0.277085    -0.184453   -0.544561     0.548309
 -0.0709703   0.597202     0.0364261    0.182219    -0.362458   -0.415541    0.110966     0.753582   -0.132812    -0.258448    -0.123328    0.0761088  -0.317918   -0.047646     0.0824867  -0.30561       0.205086     0.380751    -0.594867    0.505964    -0.455456    -0.210121      0.347998     0.309767   -0.902209    -0.297182
  0.296398    0.0320731   -0.142843    -0.421595     0.218494    0.22329    -0.207761    -0.146047   -0.208827     0.718161     0.343386    0.833881   -0.317209   -0.174039    -0.010795   -0.298815     -0.452053     0.148244    -0.0848109   0.463396     0.634157    -0.378174      0.308998     0.20707     0.383462     0.0701412
 -0.220238    0.961216    -0.726771    -0.623474     0.821647   -0.288737   -0.555833    -0.314924    0.767114     0.744486     0.507488   -0.353807    0.386211   -0.359338    -0.532274   -0.52135      -0.372459     0.161667     0.727692    0.3044      -0.0178761    0.256306      0.614806     0.0760961   0.592559     0.321558
 -0.164119    0.110198     0.101279    -0.0447597   -0.0203002  -0.411527   -0.392003     0.0543695  -0.376457     0.119936    -0.0801516  -0.626134   -0.467602   -0.595304     0.52707     0.0151759     0.446079     0.164314     0.138533   -0.174864     0.26212     -0.464216      0.378637     0.696025    0.616716    -0.378002
 -0.715926    0.194593    -0.151133    -0.407553     0.415157   -0.284275    0.291902    -0.258881    0.0537082   -0.0105542   -0.585515    0.279937   -0.279097   -0.0202339   -0.019619    0.162064      0.118207    -0.173733     0.572583   -0.0559237   -0.351351    -0.641739      0.0653867    0.43903     0.114865    -0.36793
  0.295271   -0.148884    -0.628375    -0.219964    -0.181515    0.24954     0.288781    -0.609418   -0.0356499   -0.02785     -0.449465   -0.0124465  -0.0615943   0.155573     0.15018     0.0910711    -0.139376    -0.227716    -0.165158   -0.436737    -0.194951     0.526898     -0.691964     0.220394    0.219193     0.279095
  0.0905826  -0.115547     0.297437     0.179959     0.138948   -0.202808    0.0343347    0.0670087  -0.0729131    0.00240209  -0.491134   -0.256177    0.062061    0.0482127    0.145593    0.275157     -0.10064      0.179117     0.217112   -0.241328     0.377583     0.188784      0.150128     0.297888    0.235636    -0.663887
  0.0265364   0.210963     0.565829     0.447986     0.167985   -0.317692   -0.199638    -0.3258     -0.172786    -0.55438      0.296696   -0.0276589   0.0182683   0.527789    -0.393129   -0.245731      0.195109    -0.774058     0.414223   -0.126146    -0.155783    -0.19604       0.451675    -0.990555    0.430284    -0.12028
 -0.470172   -0.122353    -0.0298375    0.122385     0.0177323   0.382451    0.110937    -0.60502     0.275323    -0.175771     0.0942802   0.414485   -0.194641    0.226384    -0.468379    0.263664     -0.392218     0.623154     0.725481   -0.390055     0.00183914  -0.59746      -0.261943    -0.529566   -0.0615626   -0.286789
  0.342386   -0.0202534    0.210348     0.313161    -0.478035    0.395148   -0.26045      0.421184   -0.40748     -0.387168     0.759726   -0.260406    0.421947   -0.190548     0.0423119  -0.216154     -0.573004    -0.0518659   -0.693745   -0.332158     0.426406     0.59457      -0.0953814   -0.417471   -0.00726726   0.103096
  0.677734   -0.18133     -0.00465778   0.949309    -0.559579   -0.496017    0.80001     -0.132545   -0.366962    -0.703129     0.164403    0.0667684  -0.802268   -0.0968105   -0.0518213   0.516803     -0.175042     0.148593    -0.602431    0.351146     0.476824     0.841557     -0.331758    -0.511771    0.264241    -0.202229
 -0.29442     0.096372     0.137696     0.204041    -1.06517    -0.498598    0.00395596   0.07088    -0.1584      -0.280402     0.305318    0.145907   -0.0947863  -0.0141931    0.318145   -0.0100607     0.189402     0.205356     0.760215    0.155009     0.55807     -0.417038      0.00874426  -0.391388    0.15465      0.794848
  0.130764    0.253134    -0.103126    -0.00616646   0.489388   -0.18749    -0.125802     0.650497   -0.914991    -0.314485     0.26378     0.180402    0.080402   -0.396726    -0.185112   -0.0983348     0.790341     0.144737     0.54447     0.129519     0.814221    -0.0132087     0.522772    -0.0550182  -0.755994     0.44307[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407168
[ Info: iteration 2, average log likelihood -1.407159
[ Info: iteration 3, average log likelihood -1.407150
[ Info: iteration 4, average log likelihood -1.407141
[ Info: iteration 5, average log likelihood -1.407132
[ Info: iteration 6, average log likelihood -1.407124
[ Info: iteration 7, average log likelihood -1.407116
[ Info: iteration 8, average log likelihood -1.407108
[ Info: iteration 9, average log likelihood -1.407101
[ Info: iteration 10, average log likelihood -1.407093
┌ Info: EM with 100000 data points 10 iterations avll -1.407093
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.249607e+05
      1       6.994489e+05      -2.255118e+05 |       32
      2       6.876897e+05      -1.175923e+04 |       32
      3       6.829995e+05      -4.690143e+03 |       32
      4       6.806001e+05      -2.399452e+03 |       32
      5       6.790666e+05      -1.533455e+03 |       32
      6       6.779669e+05      -1.099750e+03 |       32
      7       6.770007e+05      -9.661322e+02 |       32
      8       6.762631e+05      -7.375856e+02 |       32
      9       6.756280e+05      -6.351151e+02 |       32
     10       6.751025e+05      -5.254814e+02 |       32
     11       6.746198e+05      -4.827101e+02 |       32
     12       6.741934e+05      -4.263826e+02 |       32
     13       6.738591e+05      -3.343069e+02 |       32
     14       6.735766e+05      -2.825104e+02 |       32
     15       6.733051e+05      -2.715376e+02 |       32
     16       6.730477e+05      -2.573715e+02 |       32
     17       6.728000e+05      -2.477150e+02 |       32
     18       6.725533e+05      -2.467487e+02 |       32
     19       6.723405e+05      -2.127459e+02 |       32
     20       6.721451e+05      -1.954576e+02 |       32
     21       6.719489e+05      -1.961480e+02 |       32
     22       6.717757e+05      -1.732519e+02 |       32
     23       6.716200e+05      -1.556168e+02 |       32
     24       6.714818e+05      -1.382514e+02 |       32
     25       6.713501e+05      -1.316768e+02 |       32
     26       6.712323e+05      -1.178492e+02 |       32
     27       6.711246e+05      -1.076334e+02 |       32
     28       6.710169e+05      -1.077311e+02 |       32
     29       6.709026e+05      -1.143189e+02 |       32
     30       6.707871e+05      -1.155257e+02 |       32
     31       6.706811e+05      -1.059285e+02 |       32
     32       6.705723e+05      -1.088392e+02 |       32
     33       6.704664e+05      -1.058771e+02 |       32
     34       6.703693e+05      -9.715139e+01 |       32
     35       6.702776e+05      -9.169065e+01 |       32
     36       6.701882e+05      -8.936034e+01 |       32
     37       6.701068e+05      -8.137950e+01 |       32
     38       6.700241e+05      -8.276999e+01 |       32
     39       6.699458e+05      -7.827242e+01 |       32
     40       6.698723e+05      -7.348367e+01 |       32
     41       6.697999e+05      -7.239438e+01 |       32
     42       6.697242e+05      -7.570087e+01 |       32
     43       6.696583e+05      -6.585960e+01 |       32
     44       6.695842e+05      -7.412483e+01 |       32
     45       6.695137e+05      -7.049577e+01 |       32
     46       6.694428e+05      -7.089022e+01 |       32
     47       6.693744e+05      -6.840353e+01 |       32
     48       6.693035e+05      -7.091182e+01 |       32
     49       6.692313e+05      -7.226570e+01 |       32
     50       6.691611e+05      -7.011905e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 669161.1315819977)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418886
[ Info: iteration 2, average log likelihood -1.414032
[ Info: iteration 3, average log likelihood -1.412870
[ Info: iteration 4, average log likelihood -1.412145
[ Info: iteration 5, average log likelihood -1.411369
[ Info: iteration 6, average log likelihood -1.410451
[ Info: iteration 7, average log likelihood -1.409557
[ Info: iteration 8, average log likelihood -1.408905
[ Info: iteration 9, average log likelihood -1.408523
[ Info: iteration 10, average log likelihood -1.408305
[ Info: iteration 11, average log likelihood -1.408166
[ Info: iteration 12, average log likelihood -1.408063
[ Info: iteration 13, average log likelihood -1.407980
[ Info: iteration 14, average log likelihood -1.407910
[ Info: iteration 15, average log likelihood -1.407848
[ Info: iteration 16, average log likelihood -1.407792
[ Info: iteration 17, average log likelihood -1.407742
[ Info: iteration 18, average log likelihood -1.407697
[ Info: iteration 19, average log likelihood -1.407655
[ Info: iteration 20, average log likelihood -1.407616
[ Info: iteration 21, average log likelihood -1.407581
[ Info: iteration 22, average log likelihood -1.407548
[ Info: iteration 23, average log likelihood -1.407518
[ Info: iteration 24, average log likelihood -1.407489
[ Info: iteration 25, average log likelihood -1.407463
[ Info: iteration 26, average log likelihood -1.407438
[ Info: iteration 27, average log likelihood -1.407415
[ Info: iteration 28, average log likelihood -1.407393
[ Info: iteration 29, average log likelihood -1.407372
[ Info: iteration 30, average log likelihood -1.407353
[ Info: iteration 31, average log likelihood -1.407334
[ Info: iteration 32, average log likelihood -1.407317
[ Info: iteration 33, average log likelihood -1.407300
[ Info: iteration 34, average log likelihood -1.407284
[ Info: iteration 35, average log likelihood -1.407269
[ Info: iteration 36, average log likelihood -1.407254
[ Info: iteration 37, average log likelihood -1.407240
[ Info: iteration 38, average log likelihood -1.407227
[ Info: iteration 39, average log likelihood -1.407214
[ Info: iteration 40, average log likelihood -1.407201
[ Info: iteration 41, average log likelihood -1.407189
[ Info: iteration 42, average log likelihood -1.407177
[ Info: iteration 43, average log likelihood -1.407165
[ Info: iteration 44, average log likelihood -1.407154
[ Info: iteration 45, average log likelihood -1.407143
[ Info: iteration 46, average log likelihood -1.407132
[ Info: iteration 47, average log likelihood -1.407122
[ Info: iteration 48, average log likelihood -1.407111
[ Info: iteration 49, average log likelihood -1.407101
32×26 Array{Float64,2}:
[ Info: iteration 50, average log likelihood -1.407091
┌ Info: EM with 100000 data points 50 iterations avll -1.407091
└ 59.0 data points per parameter
  0.0256181    0.785932    -0.818152     -0.470169     0.618134   -0.147158    -0.201544   -0.283072    0.137098     0.860469    0.868585    0.124247    0.0800311  -0.431715    -0.117491    -0.446252    -0.496028    0.156555    0.180104    0.469521     0.221888   -0.0557738   0.344784   -0.0140987    0.651615    0.224703
  0.112299     0.328911    -0.172732     -0.0475065   -0.180669   -0.187933    -0.232101    0.416326   -0.49407     -0.10225     0.243611    0.101071   -0.250105   -0.400591     0.0708425   -0.21433      0.431531   -0.020088   -0.182822    0.248052     0.0665354  -0.0526165   0.137687    0.120995    -0.450913    0.410837
 -0.31134      0.411544    -0.155825     -0.277527     0.193993   -0.637751     0.117299    0.0817961   0.049361    -0.0996597  -0.713608   -0.224369   -0.354251   -0.107037     0.32298      0.0976307   -0.0794276  -0.0592946   0.0356656   0.00452856  -0.198081   -0.0344334  -0.0177436   0.675875     0.25268    -0.572358
  0.00389623  -0.0963714   -0.858847      0.0276354   -0.154932    0.138175     0.0331861  -0.538417    0.182316     0.688433    0.0296968   0.163814    0.101576    0.120085     0.308993    -0.0216565    0.604942   -0.113567   -0.0207622  -0.149388    -0.597494   -0.484609   -0.197294   -0.184591     0.487076    0.232927
 -0.212692    -0.411131     0.384887     -0.470248     0.201894    0.0495924   -0.130192    0.121773    0.44957      0.144679    0.276984   -0.385363   -0.14515     0.124894    -0.0231085    0.549163    -0.0598112  -0.232293   -0.300865   -0.352745    -1.16859     0.0321409   0.061433   -0.534133    -0.43295     0.251017
 -0.181389     0.263517     0.22302       0.464888    -0.192874    0.247411    -0.0487292   0.78551    -0.631694    -0.480528    0.316936   -0.327017    0.620532   -0.220599     0.0298738   -0.119831    -0.691684   -0.0683816  -0.725879   -0.193741     0.403587    0.34182    -0.2003     -0.0134122   -0.0897743  -0.329159
  0.101933    -0.530703     0.359812      0.124536    -0.0457656   0.095836    -0.0539991  -0.138685    0.29366      0.106963   -0.0339876   0.0563813   0.0799986   0.0795493   -0.266582     0.0795741    0.106277    0.0017925   0.119171    0.119154    -0.0789183  -0.115941    0.0079494  -0.323289    -0.0174952   0.0708716
 -0.145704     0.103257    -0.195697      0.0842061    0.0446532   0.0458606    0.109775   -0.059045    0.140625    -0.14458    -0.179314    0.0391036   0.122751    0.311767     0.11461      0.108959    -0.278062   -0.0206744  -0.0188026  -0.118107    -0.024747    0.0697211  -0.220547    0.0179811   -0.0281196  -0.161881
  0.105689    -0.253083    -0.0426163     0.183843    -0.0127151   0.00383004   0.071496   -0.427371    0.258101     0.0936947  -0.40014    -0.222817    0.192813    0.287051     0.0565605    0.224494    -0.280388    0.0749287   0.142011   -0.327485     0.1054      0.188037   -0.227773   -0.00649741   0.531692   -0.331133
  0.690101     0.213864     0.105999     -0.0836048   -0.25848     0.0483601   -0.595717   -0.0148222   0.370284    -0.237278   -0.129515   -0.358699   -0.0368213   0.40325      0.0868142   -0.232774    -0.145001    0.0364618  -0.0261985  -0.327354     0.25494     0.909685    0.0710396  -0.393114     0.102687   -0.164961
  0.0243241   -0.00223633   0.390003      0.439555    -0.400409   -0.268957     0.255199    0.65187    -0.0590344   -0.293126   -0.0332651  -0.146134   -0.0345458   0.0280768    0.189028    -0.485286     0.343987    0.437173   -0.348066    0.308435    -0.600444    0.11327     0.0697996  -0.122133    -1.16544    -0.130756
  0.118301     0.267161    -0.135189     -0.406152     0.012915   -0.0104659   -0.288233   -0.0317864  -0.203546     0.126888    0.295627    0.141096   -0.327432   -0.279028     0.09245     -0.397109    -0.0017895   0.280421   -0.0414226   0.063286     0.1136      0.0292503   0.107645    0.255034    -0.14368     0.0678358
 -0.0609072   -0.373204    -0.152594      0.236441     0.0845819   0.160064     0.260289   -0.266039   -0.00716173  -0.0427803  -0.428303   -0.626279    0.332819   -0.592752    -0.289794     0.0687102    0.0165679   0.0663065   0.060841   -0.594119     0.38566     0.170884   -0.734963    0.451952    -0.0613824   0.0316609
 -0.439615     0.124191    -0.000605046   0.0331961   -0.784889   -0.419585    -0.029998    0.0436039  -0.177454    -0.345866    0.366529    0.346176   -0.27862    -0.113465     0.288584     0.0221259    0.156533    0.287953    0.709136    0.0206356    0.416786   -0.661557    0.067097   -0.254948     0.10983     0.824584
 -0.0888178   -0.146179     0.623051     -0.39305     -0.504973    0.180269     0.246499    0.372054   -0.174986     0.276858    0.226797   -0.165013    0.265743   -0.387719    -0.0274447    1.30531     -0.360538   -0.661754    0.284958   -0.0895509    0.138854    0.383939   -0.87289    -0.0809348    0.120303   -0.161927
  0.241839    -0.200898    -0.0121496     0.0299082    0.163479    0.0598022   -0.167086   -0.416413   -0.00666325   0.257194   -0.141163    0.408978    0.1234      0.0612307    0.00687389  -0.0708118   -0.549858   -0.323564    0.319108    0.0273795    0.676324   -0.179662    0.195585    0.00740117   0.935446   -0.356239
  0.66006     -0.303046     0.143316      0.872191    -0.536681   -0.465694     0.82438    -0.170458   -0.2852      -0.678345    0.0330632  -0.0866796  -0.594625   -0.0481475   -0.101247     0.572834    -0.271242    0.219102   -0.552076    0.146198     0.530523    0.783132   -0.331671   -0.390489     0.201436   -0.291156
  0.101959     0.152181     0.208095      0.24795     -0.110925   -0.217812     0.0834165   0.367319   -0.53099     -0.320804   -0.0892517  -0.213397    0.0503706   0.00179008  -0.064467     0.0101123    0.184996   -0.295092   -0.0826099  -0.171906     0.343776    0.425265    0.335537    0.041508     0.219399   -0.0287028
 -0.0817989   -0.0524836    0.461576      0.250681    -0.0387618  -0.284078    -0.51193    -0.0666101  -0.444237     0.253231    0.0656745  -0.667663   -0.334487   -0.388917     0.373001     0.0163171    0.571931    0.178691    0.37456    -0.0979375    0.502281   -0.552526    0.380621    0.42427      0.920678   -0.507844
 -0.31911      0.204476    -0.0715966    -0.0216001    0.207953   -0.140027     0.056006    0.222141   -0.352158    -0.242676    0.121811    0.154032   -0.0503892  -0.443085    -0.124607     0.227715     0.344708   -0.123472   -0.174507    0.274161    -0.292219   -0.629516    0.0748431   0.194328    -0.150009    0.19507
 -0.558908    -0.291454     0.0303493     0.0138807    0.189978    0.326714     0.296953   -0.594301    0.292256    -0.202849   -0.271383    0.359988   -0.0693854   0.163608    -0.27396      0.296446    -0.174343    0.38809     0.77624    -0.602546    -0.0745645  -0.639936   -0.0364911  -0.252831    -0.161145   -0.473217
  0.0214822    0.331829     0.830089     -0.0114977    0.412883   -0.178699    -0.316722    0.129081   -0.0855131   -0.36742     0.620163    0.492312   -0.348868    0.224136    -0.423088    -0.148575    -0.345825   -0.104845    0.0117189   0.129377    -0.213124   -0.398252    0.500517   -0.325141     0.072543   -0.419399
 -0.156557     0.19156     -0.387855      0.204346     0.18111     0.557239    -0.286187   -0.0481107   0.523247    -0.401591    0.226137    0.736897    0.143082    0.218228    -0.557003    -0.368649    -0.0880798   0.0168505  -0.511967    0.334275    -0.353828   -0.0632738  -0.40691    -0.406638    -0.734862    0.643755
 -0.432859     0.116739     0.253287      0.690656    -0.0281266   0.101327     0.311431   -0.281778   -0.211238    -0.545047   -0.161461   -0.490563    0.417164    0.570227    -0.327975     0.0262489    0.580429   -0.896579    0.55532    -0.108792    -0.308443   -0.232948    0.105591   -0.804949     0.218019   -0.109034
 -0.0177543    0.300564     0.0416981     0.480282     0.431894   -0.388417     0.220948    0.414873   -0.458138    -0.282956   -0.573221    0.231414    0.282906    0.413441     0.0878986   -0.1092       0.23408     0.0850545   0.811917    0.218084     1.01979     0.164191    0.323794    0.0584818   -0.485392   -0.142558
  0.0435845    0.0476952   -0.447136      0.00789567  -0.21236     0.256618     0.0415314  -0.702083   -0.820723    -0.701437    0.0635284   0.420352   -0.11885    -0.138498     0.511751     0.00158715  -0.246541   -0.116601   -0.195184   -0.0863146    0.0225978  -0.0652416  -0.295184    0.0412827    0.0972686   0.59258
  0.679606    -0.0399829   -0.325784     -0.580471     0.397497    0.522671     0.468889   -0.78984     0.093769    -0.217635   -0.611641    0.968298   -0.202408    0.62471     -0.0308797   -0.0496191   -0.455817   -0.661866   -0.39953    -0.486444    -0.410231    0.773216   -0.476576    0.0792591    0.0527561  -0.238883
 -0.631884     0.455805    -0.705031     -0.554747    -0.433052   -0.252735     0.153063    0.253929    0.159782     0.061547   -0.206915   -0.0117334  -0.0134164   0.15818      0.0394662   -0.221379     0.154099   -0.313517   -0.175845    0.243253    -0.487192    0.0649892  -0.326959    0.0820034   -0.569907    0.668834
  0.781881    -0.64571     -0.110216     -0.159257    -0.141992    0.374917    -0.530971   [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
 0.286957    0.176573     0.494206   -0.171532    0.091979    0.243982   -0.501632     0.280284    -0.257666     0.0270339  -0.0501736  -1.08097     0.578605    -0.161899    0.094384   -0.0550459   0.276378    -0.166174    0.220588
  0.673572    -0.868297     0.0238156     0.086315     0.0334023   0.240774    -0.195421   -0.149812   -0.394057     0.229046    0.170179    0.725644    0.55525     0.0300337   -0.243381     0.0966975    0.625408    0.512072   -0.0332049  -0.459162     0.441242    0.20116     0.777101   -0.718346     0.120743    0.147681
 -0.303602    -0.213164     0.3538       -0.854647     0.60366     0.494061    -0.0395569   0.366505   -0.0134634    0.578997    0.0667206   0.0311847   0.0129638  -0.0465723   -0.386305    -0.232175    -0.0553842  -0.0545415  -0.0942836   0.0538661   -0.354679   -0.135441    0.0789525   0.603603    -0.550273   -0.223267
  0.255556    -0.37418     -0.119572      0.00626554  -0.587055    0.549578     0.707159   -0.217934   -0.128656     0.621417   -0.484868    0.191596   -0.113208   -0.127047     0.569842     0.587267     0.106795    0.398863   -0.0145879   0.0606831    0.17474    -0.170598   -0.35151     0.88213     -0.432631    0.186586[ Info: iteration 1, average log likelihood -1.407081
[ Info: iteration 2, average log likelihood -1.407071
[ Info: iteration 3, average log likelihood -1.407062
[ Info: iteration 4, average log likelihood -1.407052
[ Info: iteration 5, average log likelihood -1.407043
[ Info: iteration 6, average log likelihood -1.407033
[ Info: iteration 7, average log likelihood -1.407024
[ Info: iteration 8, average log likelihood -1.407015
[ Info: iteration 9, average log likelihood -1.407006
[ Info: iteration 10, average log likelihood -1.406997
┌ Info: EM with 100000 data points 10 iterations avll -1.406997
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3     ┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
  7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
