Julia Version 1.4.0-DEV.670
Commit 032dbe33e3 (2019-12-29 22:39 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed LegacyStrings ────── v0.4.1
 Installed FillArrays ───────── v0.8.2
 Installed JLD ──────────────── v0.9.1
 Installed FileIO ───────────── v1.2.0
 Installed StatsFuns ────────── v0.9.3
 Installed StatsBase ────────── v0.32.0
 Installed Distributions ────── v0.21.11
 Installed CMake ────────────── v1.1.2
 Installed Arpack ───────────── v0.4.0
 Installed Parameters ───────── v0.12.0
 Installed SpecialFunctions ─── v0.9.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed BinaryProvider ───── v0.5.8
 Installed Distances ────────── v0.8.2
 Installed Clustering ───────── v0.13.3
 Installed OpenBLAS_jll ─────── v0.3.7+1
 Installed URIParser ────────── v0.4.0
 Installed DataAPI ──────────── v1.1.0
 Installed StaticArrays ─────── v0.12.1
 Installed BinDeps ──────────── v1.0.0
 Installed Rmath ────────────── v0.6.0
 Installed QuadGK ───────────── v2.3.1
 Installed Missings ─────────── v0.4.3
 Installed SortingAlgorithms ── v0.3.1
 Installed OrderedCollections ─ v1.1.0
 Installed Blosc ────────────── v0.5.1
 Installed NearestNeighbors ─── v0.4.4
 Installed Arpack_jll ───────── v3.5.0+2
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed DataStructures ───── v0.17.6
 Installed HDF5 ─────────────── v0.12.5
 Installed PDMats ───────────── v0.9.10
 Installed CMakeWrapper ─────── v0.2.3
 Installed Compat ───────────── v2.2.0
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_NU85iZ/Project.toml`
 [no changes]
  Updating `/tmp/jl_NU85iZ/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_8buMHI/Project.toml`
 [no changes]
  Updating `/tmp/jl_8buMHI/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_tTsvWX/Project.toml`
 [no changes]
  Updating `/tmp/jl_tTsvWX/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_o1mevW/Project.toml`
 [no changes]
  Updating `/tmp/jl_o1mevW/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_l1RrJl/Project.toml`
 [no changes]
  Updating `/tmp/jl_l1RrJl/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_l1RrJl/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.0
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -5.003583385008605e6, [6354.594898373579, 93645.40510162643], [2189.7720772445055 7756.478353011949 -1566.107593992414; -1862.916118569694 -7391.414972646997 1444.0458212128808], [[4982.716787134082 327.13729374785515 -1617.454499149656; 327.1372937478551 10940.819486501867 -1760.0307871554405; -1617.4544991496562 -1760.030787155441 7592.604386773663], [94222.86061710902 -167.48056804222412 1163.34157913852; -167.48056804222406 88180.27768054426 1630.436727003504; 1163.34157913852 1630.436727003504 91855.66320265672]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.620106e+03
      1       1.054128e+03      -5.659782e+02 |        6
      2       9.900000e+02      -6.412778e+01 |        4
      3       8.730315e+02      -1.169685e+02 |        4
      4       8.222549e+02      -5.077662e+01 |        2
      5       8.172730e+02      -4.981853e+00 |        0
      6       8.172730e+02       0.000000e+00 |        0
K-means converged with 6 iterations (objv = 817.2730235600993)
┌ Info: K-means with 272 data points using 6 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.048466
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.750447
[ Info: iteration 2, lowerbound -3.633969
[ Info: iteration 3, lowerbound -3.520725
[ Info: iteration 4, lowerbound -3.408684
[ Info: iteration 5, lowerbound -3.310704
[ Info: iteration 6, lowerbound -3.232734
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -3.159100
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -3.081445
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.983516
[ Info: iteration 10, lowerbound -2.885075
[ Info: iteration 11, lowerbound -2.804924
[ Info: dropping number of Gaussions to 4
[ Info: iteration 12, lowerbound -2.745096
[ Info: iteration 13, lowerbound -2.699697
[ Info: dropping number of Gaussions to 3
[ Info: iteration 14, lowerbound -2.663324
[ Info: iteration 15, lowerbound -2.622455
[ Info: iteration 16, lowerbound -2.581137
[ Info: iteration 17, lowerbound -2.537674
[ Info: iteration 18, lowerbound -2.494612
[ Info: iteration 19, lowerbound -2.454097
[ Info: iteration 20, lowerbound -2.417084
[ Info: iteration 21, lowerbound -2.383321
[ Info: iteration 22, lowerbound -2.352553
[ Info: iteration 23, lowerbound -2.326680
[ Info: iteration 24, lowerbound -2.310565
[ Info: iteration 25, lowerbound -2.308089
[ Info: dropping number of Gaussions to 2
[ Info: iteration 26, lowerbound -2.302915
[ Info: iteration 27, lowerbound -2.299259
[ Info: iteration 28, lowerbound -2.299256
[ Info: iteration 29, lowerbound -2.299254
[ Info: iteration 30, lowerbound -2.299254
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Mon Dec 30 09:00:20 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Mon Dec 30 09:00:28 2019: K-means with 272 data points using 6 iterations
11.3 data points per parameter
, Mon Dec 30 09:00:30 2019: EM with 272 data points 0 iterations avll -2.048466
5.8 data points per parameter
, Mon Dec 30 09:00:32 2019: GMM converted to Variational GMM
, Mon Dec 30 09:00:41 2019: iteration 1, lowerbound -3.750447
, Mon Dec 30 09:00:41 2019: iteration 2, lowerbound -3.633969
, Mon Dec 30 09:00:41 2019: iteration 3, lowerbound -3.520725
, Mon Dec 30 09:00:41 2019: iteration 4, lowerbound -3.408684
, Mon Dec 30 09:00:41 2019: iteration 5, lowerbound -3.310704
, Mon Dec 30 09:00:41 2019: iteration 6, lowerbound -3.232734
, Mon Dec 30 09:00:42 2019: dropping number of Gaussions to 7
, Mon Dec 30 09:00:42 2019: iteration 7, lowerbound -3.159100
, Mon Dec 30 09:00:42 2019: dropping number of Gaussions to 6
, Mon Dec 30 09:00:42 2019: iteration 8, lowerbound -3.081445
, Mon Dec 30 09:00:42 2019: dropping number of Gaussions to 5
, Mon Dec 30 09:00:42 2019: iteration 9, lowerbound -2.983516
, Mon Dec 30 09:00:42 2019: iteration 10, lowerbound -2.885075
, Mon Dec 30 09:00:42 2019: iteration 11, lowerbound -2.804924
, Mon Dec 30 09:00:42 2019: dropping number of Gaussions to 4
, Mon Dec 30 09:00:42 2019: iteration 12, lowerbound -2.745096
, Mon Dec 30 09:00:42 2019: iteration 13, lowerbound -2.699697
, Mon Dec 30 09:00:42 2019: dropping number of Gaussions to 3
, Mon Dec 30 09:00:42 2019: iteration 14, lowerbound -2.663324
, Mon Dec 30 09:00:42 2019: iteration 15, lowerbound -2.622455
, Mon Dec 30 09:00:42 2019: iteration 16, lowerbound -2.581137
, Mon Dec 30 09:00:42 2019: iteration 17, lowerbound -2.537674
, Mon Dec 30 09:00:42 2019: iteration 18, lowerbound -2.494612
, Mon Dec 30 09:00:42 2019: iteration 19, lowerbound -2.454097
, Mon Dec 30 09:00:42 2019: iteration 20, lowerbound -2.417084
, Mon Dec 30 09:00:42 2019: iteration 21, lowerbound -2.383321
, Mon Dec 30 09:00:42 2019: iteration 22, lowerbound -2.352553
, Mon Dec 30 09:00:42 2019: iteration 23, lowerbound -2.326680
, Mon Dec 30 09:00:42 2019: iteration 24, lowerbound -2.310565
, Mon Dec 30 09:00:42 2019: iteration 25, lowerbound -2.308089
, Mon Dec 30 09:00:42 2019: dropping number of Gaussions to 2
, Mon Dec 30 09:00:42 2019: iteration 26, lowerbound -2.302915
, Mon Dec 30 09:00:42 2019: iteration 27, lowerbound -2.299259
, Mon Dec 30 09:00:42 2019: iteration 28, lowerbound -2.299256
, Mon Dec 30 09:00:42 2019: iteration 29, lowerbound -2.299254
, Mon Dec 30 09:00:42 2019: iteration 30, lowerbound -2.299254
, Mon Dec 30 09:00:42 2019: iteration 31, lowerbound -2.299253
, Mon Dec 30 09:00:42 2019: iteration 32, lowerbound -2.299253
, Mon Dec 30 09:00:42 2019: iteration 33, lowerbound -2.299253
, Mon Dec 30 09:00:42 2019: iteration 34, lowerbound -2.299253
, Mon Dec 30 09:00:42 2019: iteration 35, lowerbound -2.299253
, Mon Dec 30 09:00:42 2019: iteration 36, lowerbound -2.299253
, Mon Dec 30 09:00:42 2019: iteration 37, lowerbound -2.299253
, Mon Dec 30 09:00:42 2019: iteration 38, lowerbound -2.299253
, Mon Dec 30 09:00:42 2019: iteration 39, lowerbound -2.299253
, Mon Dec 30 09:00:42 2019: iteration 40, lowerbound -2.299253
, Mon Dec 30 09:00:42 2019: iteration 41, lowerbound -2.299253
, Mon Dec 30 09:00:42 2019: iteration 42, lowerbound -2.299253
, Mon Dec 30 09:00:42 2019: iteration 43, lowerbound -2.299253
, Mon Dec 30 09:00:42 2019: iteration 44, lowerbound -2.299253
, Mon Dec 30 09:00:42 2019: iteration 45, lowerbound -2.299253
, Mon Dec 30 09:00:42 2019: iteration 46, lowerbound -2.299253
, Mon Dec 30 09:00:42 2019: iteration 47, lowerbound -2.299253
, Mon Dec 30 09:00:42 2019: iteration 48, lowerbound -2.299253
, Mon Dec 30 09:00:42 2019: iteration 49, lowerbound -2.299253
, Mon Dec 30 09:00:42 2019: iteration 50, lowerbound -2.299253
, Mon Dec 30 09:00:42 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222607211, 95.95490777392801]
β = [178.04509222607211, 95.95490777392801]
m = [4.2503007332694365 79.28686694435486; 2.0002292577748815 53.85198717245872]
ν = [180.04509222607211, 97.95490777392801]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547478082 -0.007644049042333551; 0.0 0.008581705166324614], [0.3758763611956584 -0.00895312382735596; 0.0 0.012748664777411739]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9852278781244562
avll from llpg:  -0.9852278781244563
avll direct:     -0.9852278781244563
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9849571524379671
avll from llpg:  -0.9849571524379673
avll direct:     -0.9849571524379672
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.231587    -0.0153391    -0.150535     0.0714285   0.0487722   0.129402     0.0465957   -0.186447     -0.0950524    0.03982     -0.0461357    0.0551936   0.0920354    0.0885821    0.0503498   -0.0154663   -0.128412    -0.0910899    0.0971405  -0.0153589   -0.00500072  -0.0447811    0.105116     -0.0813882   -0.0442364    0.0318222
 -0.0875125    0.108364     -0.116412     0.0293888   0.0788621   0.0278741   -0.142887    -0.103994     -0.146523    -0.0173761   -0.210429     0.123973    0.0588973    0.0932054    0.114207    -0.1185       0.0465796   -0.216818     0.065075   -0.217508    -0.0368152   -0.0507586    0.0915239     0.0643116   -0.0141158   -0.108389
  0.0578791    0.0281836     0.0522393    0.0221138   0.0726508   0.073767     0.140246    -0.0181046    -0.0556658   -0.0425492    0.160986    -0.205926    0.262838    -0.163058    -0.0304296    0.0398862    0.0656024   -0.278805    -0.148793    0.00230883  -0.097282    -0.0447761   -0.0729598     0.174453    -0.117378    -0.025446
 -0.039259     0.0881114     0.148859    -0.0118955  -0.0639512  -0.00211751   0.0785405    0.00203739    0.0892822   -0.0522113    0.0716934    0.0405469   0.196488    -0.0533036   -0.0734965    0.0966724   -0.0913822   -0.0635061   -0.0966513   0.0476707    0.268297     0.0479566    0.114694      0.0188862    0.199777    -0.0808891
  0.142249    -0.071166      0.0651261   -0.0452896  -0.149034   -0.110245    -0.0569926   -0.116893     -0.150173    -0.0806432   -0.0500892   -0.0357811  -0.126905    -0.0746284    0.0694525   -0.0919732    0.124852    -0.00636087   0.0160629   0.102596     0.106876    -0.0247221   -0.0548683    -0.137938     0.0554379   -0.0628552
 -0.145454    -0.0121386    -0.0694601    0.07885    -0.0563944  -0.0843074   -0.0284407   -0.000208285   0.0284489    0.236157    -0.137572    -0.101545    0.0747772   -0.0257058    0.120143     0.0420902   -0.100425     0.136732    -0.187393   -0.030607     0.0151788   -0.0351032    0.133002     -0.065106     0.05099     -0.0294377
 -0.0257331    0.0532459    -0.0229286   -0.0638618  -0.0802256  -0.0888558    0.0890566    0.071014      0.0156499    0.0348368    0.182989    -0.0878387  -0.0638501   -0.130467    -0.083376     0.0594089    0.0803619    0.174235    -0.0559914   0.123808     0.0268427    0.00817705   0.0922651     0.0756251   -0.133261     0.159332
  0.101082    -0.100748      0.0508052    0.0507721   0.18698     0.0259685   -0.0643355   -0.00438114   -0.082137    -0.0855759    0.00330151  -0.0646422   0.0134973    0.112582     0.129099     0.00850566   0.0565766    0.0755587    0.0507793   0.0387456    0.0920355    0.122758     0.104243      0.166069    -0.117545    -0.0113333
  0.0797994    0.0440704     0.0141472   -0.0185182   0.0378198  -0.153816     0.0070083   -0.166832     -0.140784    -0.229651     0.0758853   -0.0149745   0.00782902  -0.0245833   -0.0310135    0.136001     0.0272826    0.00965955  -0.0377031   0.0956856   -0.258395    -0.0557261    0.00668045    0.133377    -0.157318    -0.0072735
 -0.213496     0.0352951     0.100714     0.0993729  -0.104738   -0.19864      0.153062    -0.154449      0.035044     0.107657    -0.166238     0.152858    0.139672    -0.100964    -0.0277483   -0.114521    -0.087447    -0.0454235    0.0501612  -0.0761508   -0.102104     0.240386     0.0459306     0.137909    -0.0404479   -0.0566969
 -0.160648    -0.216085      0.00605257   0.161857    0.0902933  -0.0671336   -0.0350614    0.0138833    -0.109423     0.0696515    0.00114825  -0.0973443  -0.112814     0.0242488    0.0421199    0.0532113    0.00111997  -0.0189454    0.0554648  -0.142512     0.0751725   -0.200518    -0.084378      0.0819801    0.15216     -0.0451047
  0.0870495   -0.0817771    -0.0143069    0.0353796  -0.0988772   0.0499673    0.00164952   0.0679602    -0.0026352   -0.0739419    0.0298605    0.0663811   0.14692     -0.0327323    0.0467875   -0.0796463    0.0278273    0.201623    -0.0314936   0.0903051    0.0706717    0.0829991   -0.155195     -0.102256     0.0939872   -0.0175246
  0.049609    -0.129806      0.0165332    0.0165903  -0.0913477   0.0238556    0.191954    -0.0192978    -0.0906289    0.0906776   -0.0328591   -0.0391882  -0.0405814    0.100893     0.278455     0.0715515   -0.0163429    0.0855784    0.119014    0.0709253    0.0217612   -0.0170572   -0.0320454    -0.135815    -0.106136     0.11894
 -0.114633     0.106685      0.00986775   0.113665   -0.0185237  -0.0371093    0.0937082    0.10756       0.0510139    0.0192012    0.134616     0.0657593  -0.00852818  -0.0806115    0.0514231    0.0348342   -0.053754    -0.107544    -0.0173525  -0.0828012    0.0141329    0.16888      0.000957188  -0.0973864   -0.0847032   -0.103837
 -0.0158877    0.104724     -0.0503431    0.167912   -0.0547541  -0.0453874    0.0189149   -0.055286     -0.0825472    0.13953      0.0616671    0.245364    0.0296645   -0.137398    -0.111326    -0.0545304   -0.0881995   -0.0407166   -0.0575002  -0.0166006    0.134364    -0.149053    -0.00626372    0.019766     0.0264935    0.00374724
 -0.0876727    0.0208167     0.20332      0.0441606  -0.0895122   0.0987871    0.0750894    0.00583841    0.0917102    0.0860916   -0.134725     0.0711564  -0.0513227    0.0454969   -0.0373228   -0.143783     0.196578    -0.035676     0.0211647  -0.122149    -0.134532    -0.118118    -0.0397167     0.00882262   0.0513809   -0.244837
 -0.0887152   -0.154745      0.106621    -0.0413141   0.0143241  -0.130999     0.0457497    0.0807664     0.0236326   -0.158113     0.232673    -0.0270531  -0.0568995    0.0332804    0.0779965    0.0113507   -0.091948     0.0506507    0.0435428  -0.0750959   -0.219222     0.0592918   -0.0832115    -0.0564328    0.100299    -0.0646115
 -0.0640143   -0.0726997     0.11859     -0.0485444   0.203545    0.157649     0.0195663    0.00228879   -0.121369    -0.0212502    0.044711     0.168193    0.0346684    0.0708613   -0.0104136    0.0018875    0.0094652   -0.0281992    0.0198764  -0.0337173    0.0326551   -0.115334    -0.061499      0.13924      0.128868     0.0723871
  0.0465416   -0.116507      0.176762    -0.0708225   0.0641342  -0.0358819   -0.0206158    0.190264      0.0747272    0.0601767    0.0929771   -0.0307242  -0.108501     0.175843    -0.205823    -0.0673342    0.0742169   -0.08808     -0.030445   -0.0640542    0.0666232   -0.0536149   -0.0660573    -0.110463     0.0211679    0.193575
  0.0205003    0.0342414     0.0422214    0.0646228  -0.284639    0.0149694   -0.123433     0.137256     -0.272407     0.0970045   -0.0938062    0.161798    0.0807505    0.156583     0.226239    -0.0618834   -0.0090579   -0.13577      0.0871748   0.0622019   -0.0557577    0.0804511   -0.000125832  -0.0935305    0.168873    -0.0875369
 -0.121247    -0.0588715     0.0469954   -0.0297991  -0.0634034  -0.10964     -0.0234404   -0.0385123    -0.108039     0.0432865    0.173156     0.0287705   0.100386     0.0599168   -0.00929143   0.0665313   -0.0835106   -0.0574893    0.06187    -0.207326     0.0908308   -0.0323351    0.00966322    0.0739201    0.0343677   -0.0772838
 -0.0313397    0.0946798     0.0508693    0.0571746   0.0747277  -0.0918769    0.103376     0.109039      0.0352068    0.0251936   -0.250417    -0.078227    0.157862    -0.102702     0.0807374    0.160595     0.0578904   -0.0688343   -0.0267645  -0.0109373    0.0277006   -0.0296398   -0.0184677     0.0249844    0.175114    -0.0178109
  0.0777806   -0.0391979     0.0171226   -0.116505    0.0785566   0.127155    -0.126702     0.0677244    -0.0561519    0.128714    -0.137274    -0.0573834   0.0294473   -0.0312604   -0.0815236    0.0441847   -0.0926132   -0.126947     0.0936206   0.0708146   -0.0165131   -0.0287496   -0.0842225    -0.214372    -0.036147     0.135382
  0.00286079   0.00674847   -0.19566     -0.0103655  -0.109719   -0.13528     -0.0623171   -0.0163005     0.104656     0.0160307   -0.0361712    0.0290808   0.151775     0.0153125   -0.155741    -0.0309433   -0.0353403   -0.0861213   -0.106468   -0.0681478   -0.0121177    0.00994691  -0.0837251     0.0303236    0.096835     0.0639686
  0.0525514   -0.0986294    -0.176749     0.0261089   0.023157    0.15435      0.0858804   -0.122411      0.0519014    0.237713    -0.0308399   -0.0720366  -0.00898442  -0.0445845   -0.0461856   -0.216483     0.0163647   -0.0385839   -0.0648934  -0.0675647    0.0671102    0.0942529   -0.022194     -0.0583243    0.0620116   -0.104464
  0.0829393   -0.000278523  -0.117308     0.0444761   0.168471    0.0349111    0.00963291  -0.00890308   -0.023264    -0.0347056    0.0360448   -0.135929    0.00755261  -0.0718337   -0.126262     0.0191416    0.0616697    0.0393913    0.0301719   0.241383    -0.0898055    0.0982012   -0.0230594     0.0690586   -0.0469834   -0.0754879
  0.0352649    0.125591      0.0845599   -0.0631398   0.128997    0.0139777    0.0550145   -0.0883111     0.0176194    0.0187975    0.057773    -0.113206   -0.181464     0.0591561    0.133058    -0.158951     0.0463949   -0.115082    -0.128569   -0.0126365   -0.0239751   -0.00879605   0.105732     -0.0380963   -0.100064    -0.010434
 -0.0283701   -0.030249      0.014062    -0.0517765   0.0408562   0.0346824   -0.130403     0.0679684    -0.067059    -0.236503    -0.0183189   -0.172981   -0.154933     0.0291224    0.129967    -0.135463     0.151577    -0.124013     0.0434265   0.0720909   -0.0566292   -0.0161716    0.014359      0.00819234   0.0769624    0.0186496
 -0.0533208    0.151981     -0.11714     -0.0733443  -0.0373533   0.101935     0.0987254    0.00709512   -0.0213828   -0.252657     0.0226659    0.0471445  -0.0355433    0.236714     0.0334433    0.057416    -0.020057     0.0743945    0.0839007  -0.0962062    0.217956    -0.0609361   -0.0117735    -0.0129633    0.00082306   0.15472
  0.174766    -0.0555188     0.0361212    0.0209184  -0.0478977  -0.125793     0.162787    -0.111371      0.0882342   -0.00902781   0.0318132   -0.0604062   0.0856523    0.00421515  -0.0908155    0.127658     0.0479247    0.0409005    0.0713847   0.144587     0.0576805   -0.0376253    0.0276693    -0.0107619    0.185823    -0.0541895
 -0.0351458   -0.0837392    -0.071579    -0.0111885   0.17528    -0.230516    -0.0234654    0.163714      0.0133653   -0.0415338   -0.067252    -0.173784    0.0167547    0.0164563    0.199418    -0.012976     0.0266393    0.107706     0.0909166  -0.0863157   -0.0549531    0.00129142  -0.0945996     0.0281324   -0.225345     0.0694009
  0.0199751    0.0850645     0.0624633   -0.0265316  -0.107634    0.102681     0.0602836   -0.0829006     0.00102437   0.072085     0.0194162   -0.0281164  -0.0868867    0.0582197   -0.0988326   -0.167133     0.018378    -0.00938627  -0.154165    0.0614171    0.0676337    0.153786    -0.0993073     0.400225    -0.10609     -0.178339kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4154540614610123
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415507
[ Info: iteration 2, average log likelihood -1.415459
[ Info: iteration 3, average log likelihood -1.415185
[ Info: iteration 4, average log likelihood -1.411309
[ Info: iteration 5, average log likelihood -1.395646
[ Info: iteration 6, average log likelihood -1.384324
[ Info: iteration 7, average log likelihood -1.381585
[ Info: iteration 8, average log likelihood -1.380133
[ Info: iteration 9, average log likelihood -1.379184
[ Info: iteration 10, average log likelihood -1.378544
[ Info: iteration 11, average log likelihood -1.378123
[ Info: iteration 12, average log likelihood -1.377843
[ Info: iteration 13, average log likelihood -1.377649
[ Info: iteration 14, average log likelihood -1.377508
[ Info: iteration 15, average log likelihood -1.377402
[ Info: iteration 16, average log likelihood -1.377317
[ Info: iteration 17, average log likelihood -1.377249
[ Info: iteration 18, average log likelihood -1.377194
[ Info: iteration 19, average log likelihood -1.377150
[ Info: iteration 20, average log likelihood -1.377116
[ Info: iteration 21, average log likelihood -1.377089
[ Info: iteration 22, average log likelihood -1.377069
[ Info: iteration 23, average log likelihood -1.377054
[ Info: iteration 24, average log likelihood -1.377042
[ Info: iteration 25, average log likelihood -1.377034
[ Info: iteration 26, average log likelihood -1.377028
[ Info: iteration 27, average log likelihood -1.377023
[ Info: iteration 28, average log likelihood -1.377020
[ Info: iteration 29, average log likelihood -1.377018
[ Info: iteration 30, average log likelihood -1.377016
[ Info: iteration 31, average log likelihood -1.377015
[ Info: iteration 32, average log likelihood -1.377014
[ Info: iteration 33, average log likelihood -1.377014
[ Info: iteration 34, average log likelihood -1.377014
[ Info: iteration 35, average log likelihood -1.377013
[ Info: iteration 36, average log likelihood -1.377013
[ Info: iteration 37, average log likelihood -1.377013
[ Info: iteration 38, average log likelihood -1.377013
[ Info: iteration 39, average log likelihood -1.377013
[ Info: iteration 40, average log likelihood -1.377013
[ Info: iteration 41, average log likelihood -1.377013
[ Info: iteration 42, average log likelihood -1.377012
[ Info: iteration 43, average log likelihood -1.377012
[ Info: iteration 44, average log likelihood -1.377012
[ Info: iteration 45, average log likelihood -1.377012
[ Info: iteration 46, average log likelihood -1.377012
[ Info: iteration 47, average log likelihood -1.377012
[ Info: iteration 48, average log likelihood -1.377012
[ Info: iteration 49, average log likelihood -1.377012
[ Info: iteration 50, average log likelihood -1.377012
┌ Info: EM with 100000 data points 50 iterations avll -1.377012
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4155065891995504
│     -1.4154593430887321
│      ⋮
└     -1.3770123353943569
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.377148
[ Info: iteration 2, average log likelihood -1.377029
[ Info: iteration 3, average log likelihood -1.376557
[ Info: iteration 4, average log likelihood -1.371852
[ Info: iteration 5, average log likelihood -1.357207
[ Info: iteration 6, average log likelihood -1.345279
[ Info: iteration 7, average log likelihood -1.340636
[ Info: iteration 8, average log likelihood -1.338498
[ Info: iteration 9, average log likelihood -1.337451
[ Info: iteration 10, average log likelihood -1.336953
[ Info: iteration 11, average log likelihood -1.336713
[ Info: iteration 12, average log likelihood -1.336586
[ Info: iteration 13, average log likelihood -1.336500
[ Info: iteration 14, average log likelihood -1.336421
[ Info: iteration 15, average log likelihood -1.336329
[ Info: iteration 16, average log likelihood -1.336208
[ Info: iteration 17, average log likelihood -1.336037
[ Info: iteration 18, average log likelihood -1.335800
[ Info: iteration 19, average log likelihood -1.335502
[ Info: iteration 20, average log likelihood -1.335183
[ Info: iteration 21, average log likelihood -1.334891
[ Info: iteration 22, average log likelihood -1.334659
[ Info: iteration 23, average log likelihood -1.334496
[ Info: iteration 24, average log likelihood -1.334386
[ Info: iteration 25, average log likelihood -1.334312
[ Info: iteration 26, average log likelihood -1.334260
[ Info: iteration 27, average log likelihood -1.334223
[ Info: iteration 28, average log likelihood -1.334196
[ Info: iteration 29, average log likelihood -1.334177
[ Info: iteration 30, average log likelihood -1.334164
[ Info: iteration 31, average log likelihood -1.334154
[ Info: iteration 32, average log likelihood -1.334147
[ Info: iteration 33, average log likelihood -1.334142
[ Info: iteration 34, average log likelihood -1.334139
[ Info: iteration 35, average log likelihood -1.334136
[ Info: iteration 36, average log likelihood -1.334134
[ Info: iteration 37, average log likelihood -1.334133
[ Info: iteration 38, average log likelihood -1.334131
[ Info: iteration 39, average log likelihood -1.334131
[ Info: iteration 40, average log likelihood -1.334130
[ Info: iteration 41, average log likelihood -1.334129
[ Info: iteration 42, average log likelihood -1.334129
[ Info: iteration 43, average log likelihood -1.334128
[ Info: iteration 44, average log likelihood -1.334128
[ Info: iteration 45, average log likelihood -1.334128
[ Info: iteration 46, average log likelihood -1.334127
[ Info: iteration 47, average log likelihood -1.334127
[ Info: iteration 48, average log likelihood -1.334127
[ Info: iteration 49, average log likelihood -1.334127
[ Info: iteration 50, average log likelihood -1.334126
┌ Info: EM with 100000 data points 50 iterations avll -1.334126
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.377147948109095
│     -1.3770286601962167
│      ⋮
└     -1.3341263993270993
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.334306
[ Info: iteration 2, average log likelihood -1.334140
[ Info: iteration 3, average log likelihood -1.333359
[ Info: iteration 4, average log likelihood -1.325806
[ Info: iteration 5, average log likelihood -1.307152
[ Info: iteration 6, average log likelihood -1.293908
[ Info: iteration 7, average log likelihood -1.287690
[ Info: iteration 8, average log likelihood -1.284400
[ Info: iteration 9, average log likelihood -1.282335
[ Info: iteration 10, average log likelihood -1.280708
[ Info: iteration 11, average log likelihood -1.279310
[ Info: iteration 12, average log likelihood -1.278242
[ Info: iteration 13, average log likelihood -1.277616
[ Info: iteration 14, average log likelihood -1.277235
[ Info: iteration 15, average log likelihood -1.276958
[ Info: iteration 16, average log likelihood -1.276715
[ Info: iteration 17, average log likelihood -1.276474
[ Info: iteration 18, average log likelihood -1.276232
[ Info: iteration 19, average log likelihood -1.275998
[ Info: iteration 20, average log likelihood -1.275785
[ Info: iteration 21, average log likelihood -1.275609
[ Info: iteration 22, average log likelihood -1.275489
[ Info: iteration 23, average log likelihood -1.275417
[ Info: iteration 24, average log likelihood -1.275376
[ Info: iteration 25, average log likelihood -1.275352
[ Info: iteration 26, average log likelihood -1.275339
[ Info: iteration 27, average log likelihood -1.275331
[ Info: iteration 28, average log likelihood -1.275326
[ Info: iteration 29, average log likelihood -1.275323
[ Info: iteration 30, average log likelihood -1.275321
[ Info: iteration 31, average log likelihood -1.275319
[ Info: iteration 32, average log likelihood -1.275318
[ Info: iteration 33, average log likelihood -1.275317
[ Info: iteration 34, average log likelihood -1.275316
[ Info: iteration 35, average log likelihood -1.275316
[ Info: iteration 36, average log likelihood -1.275315
[ Info: iteration 37, average log likelihood -1.275315
[ Info: iteration 38, average log likelihood -1.275315
[ Info: iteration 39, average log likelihood -1.275314
[ Info: iteration 40, average log likelihood -1.275314
[ Info: iteration 41, average log likelihood -1.275314
[ Info: iteration 42, average log likelihood -1.275314
[ Info: iteration 43, average log likelihood -1.275314
[ Info: iteration 44, average log likelihood -1.275313
[ Info: iteration 45, average log likelihood -1.275313
[ Info: iteration 46, average log likelihood -1.275313
[ Info: iteration 47, average log likelihood -1.275313
[ Info: iteration 48, average log likelihood -1.275313
[ Info: iteration 49, average log likelihood -1.275313
[ Info: iteration 50, average log likelihood -1.275313
┌ Info: EM with 100000 data points 50 iterations avll -1.275313
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3343062785183815
│     -1.334140104675363
│      ⋮
└     -1.2753128466573351
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.275556
[ Info: iteration 2, average log likelihood -1.275293
[ Info: iteration 3, average log likelihood -1.273853
[ Info: iteration 4, average log likelihood -1.261966
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.240809
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.224653
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.212538
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.210335
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.196847
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.204193
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.199973
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.198865
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.196041
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.194706
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.189553
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.198214
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.201581
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.199196
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.188357
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.189679
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.176424
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.199817
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.205649
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.189296
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.189834
[ Info: iteration 26, average log likelihood -1.191387
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.171415
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     10
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.192889
[ Info: iteration 29, average log likelihood -1.207363
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.181512
[ Info: iteration 31, average log likelihood -1.199156
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.182096
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.193719
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.198816
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.183840
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.180432
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.199274
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.190060
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.200660
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.186357
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.178547
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.180167
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.199831
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.196121
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.193984
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.190462
[ Info: iteration 47, average log likelihood -1.190359
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.170653
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     10
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.192283
[ Info: iteration 50, average log likelihood -1.207268
┌ Info: EM with 100000 data points 50 iterations avll -1.207268
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2755557098153743
│     -1.2752929084513622
│      ⋮
└     -1.2072683949707073
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.181732
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.176343
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     17
│     18
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.171191
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      5
│     14
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.159156
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│      ⋮
│     28
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.119720
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.110109
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.128311
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      5
│     13
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.098754
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      6
│     12
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.113006
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      5
│     13
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.119300
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.116554
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.090322
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.120596
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      5
│     13
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.100831
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      6
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.102691
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      5
│     13
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.095907
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│     14
│     17
│      ⋮
│     28
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.105375
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.101312
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.116479
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      5
│     13
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.094673
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      6
│     12
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.103275
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      5
│     13
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.108000
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│     14
│     17
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.104802
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.087843
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.115779
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      5
│     13
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.098707
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      6
│     12
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.100918
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      5
│     13
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.102153
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     14
│     18
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.104317
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.093320
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│     14
│     17
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.111171
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      5
│     13
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.088633
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      6
│      9
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.098585
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      5
│     13
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.113069
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.113541
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.092013
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│     14
│     18
│      ⋮
│     28
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.106570
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      5
│     13
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.109961
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      6
│     12
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.104153
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      5
│     13
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.104105
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│     14
│     17
│      ⋮
│     28
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.095729
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.101174
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.117073
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      5
│     13
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.094235
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      6
│     12
│      ⋮
│     28
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.092881
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      5
│     13
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.115085
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│     14
│     19
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.107553
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.088888
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│     14
│     18
│      ⋮
│     28
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.104728
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      5
│     13
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.107969
┌ Info: EM with 100000 data points 50 iterations avll -1.107969
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1817324390347947
│     -1.1763426304025417
│      ⋮
└     -1.1079688650574797
32×26 Array{Float64,┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4154540614610123
│     -1.4155065891995504
│     -1.4154593430887321
│     -1.4151846590318586
│      ⋮
│     -1.0888877591314465
│     -1.104728142168529
└     -1.1079688650574797
2}:
  0.157507     -0.184814     0.297852    -0.0170022    -0.0357755   0.0900957   -0.134956    -0.127948     -0.115546     0.123138    -0.131577    -0.0662614    0.0372161    -0.0312347   -0.0633184    0.0561185   -0.110017    -0.27239      0.133956     0.0769043    -0.0159029  -0.0321056   -0.0610762   -0.215703     0.221529    0.147555
 -0.0205193     0.100999    -0.248174    -0.188532      0.185957    0.135136    -0.123845     0.0977783    -0.0270886    0.131403    -0.132202    -0.061601     0.0723954    -0.0315724   -0.0699028    0.0197511   -0.138048     0.0385759    0.102946     0.0731689    -0.0105498  -0.0260359   -0.122766    -0.19254     -0.218826    0.159375
 -0.168583     -0.215199     0.0578555    0.123288      0.102687   -0.0765424   -0.050087    -0.066159     -0.0573998    0.246254    -1.22324     -0.0870111   -0.0389176     0.0194082   -0.00669467   0.0548847    0.0805455   -0.0204019    0.0594063   -0.175874      0.0921523  -0.256133    -0.116521     0.0132569    0.151694   -0.137921
 -0.143329     -0.215519    -0.0266214    0.141294      0.0809624  -0.0876349   -0.0430331    0.0761816    -0.134855    -0.0687031    1.3935      -0.131829    -0.111838      0.0257339    0.122041     0.0519278   -0.0652942   -0.0205779    0.0477639   -0.10088       0.0562396  -0.105507    -0.0269849    0.0851974    0.155643    0.0938828
 -0.000542471   0.0984631   -0.0504076    0.171619     -0.0515133  -0.0446879    0.0227992   -0.0372161    -0.166356     0.112044     0.0652174    0.245137     0.0437281    -0.137732    -0.135419    -0.0570038   -0.0794906   -0.0445601   -0.0535269   -0.0154323     0.13396    -0.128441    -0.00316772   0.0168918    0.0266367  -0.0156971
 -0.0460212    -0.084974    -0.0699711   -0.00931618    0.17461    -0.223506    -0.00375081   0.174088      0.0136154   -0.0248581   -0.0603333   -0.172662    -0.000917768   0.0142184    0.186065    -0.0213273    0.0267865    0.121864     0.098747    -0.070882     -0.0532784   0.0307046   -0.0990444    0.0264009   -0.225562    0.0843192
  0.0027892     0.0469903    0.0364331    0.053741     -0.298164    0.0117164   -0.123506     0.105838     -0.2738       0.100523    -0.117596     0.160837     0.0707652     0.150881     0.225776    -0.055574    -0.00360977  -0.144169     0.0795971    0.0635066    -0.0522388   0.103966     0.00721359  -0.0951987    0.184086   -0.0604755
 -0.0207637     0.00789643   0.103317     0.0266104     0.0239118  -0.0324391    0.0463979    0.152336      0.0592035    0.038139     0.139713     0.0214093   -0.046507      0.0354205   -0.0574803   -0.00456757   0.014925    -0.101868    -0.024867    -0.0826809     0.0394851   0.0702374   -0.0408301   -0.104081    -0.0486015   0.0321341
 -0.156344     -0.0701108   -0.0313514    0.0119456     0.0159617  -0.0265046    0.0401234   -0.0527944    -0.0362264   -0.0398816    0.112487     0.0162271    0.0141919     0.0300225    0.0564917   -0.00242102  -0.090736    -0.017513     0.0676291   -0.0452885    -0.0998205   0.00386262   0.013391    -0.0585271    0.0361777  -0.0273486
 -0.0279529     0.0086992    0.00485143   0.0106597    -0.0230371  -0.0272516    0.02505      0.0461141    -0.0264344   -0.0211678   -0.0364083    0.0242913    0.138516      0.0148714    0.0545835    0.0405707    0.0136634    0.0325781    0.00234783  -0.0717826     0.0828223   0.00542177  -0.0536455   -0.00491415   0.092783   -0.0146121
 -0.213124      0.0390289    0.10749      0.0951139    -0.108687   -0.216413     0.147852    -0.153006     -0.0430892    0.110088    -0.169837     0.17777      0.131782     -0.0911647   -0.0277616   -0.127907    -0.089133    -0.0931788    0.0484593   -0.0737802    -0.142263    0.240413     0.11436      0.136789    -0.0287285  -0.0558474
  0.0194414     0.0694116    0.0479536   -0.0268455    -0.106643    0.103482     0.0347371   -0.0799237     0.0364313    0.069257     0.0193061   -0.00654136  -0.081928      0.0508658   -0.0998228   -0.173608     0.0254444   -0.00364388  -0.150878     0.0775112     0.0620806   0.104848    -0.103508     0.397836    -0.125653   -0.175233
  0.0261051     0.126945     0.124063    -0.0747466     0.140857    0.0130525    0.0524401   -0.0817395     0.00206477  -0.00944607   0.0476046   -0.121003    -0.181034      0.0314596    0.147733    -0.151597     0.0834612   -0.108449    -0.114098    -0.050773     -0.0309803  -0.0155173    0.10747     -0.0379403   -0.0966322  -0.007006
  0.118501     -0.0817332    0.0462312   -0.0542337    -0.150373   -0.108435    -0.055546    -0.110511     -0.121125    -0.0893017   -0.0605756   -0.048603    -0.126994     -0.0719333    0.0673889   -0.111568     0.101993    -0.00414621   0.0139798    0.099727      0.0709919  -0.0702812   -0.0516272   -0.126372     0.0971246  -0.0943906
  0.059272     -0.0403147   -0.066693     0.0179116     0.0614988   0.091335     0.137237    -0.0669044    -0.00192951   0.0986682    0.0398725   -0.127069     0.125926     -0.0850105   -0.0584677   -0.0867197    0.0418026   -0.16775     -0.107348    -0.0309074    -0.0149152   0.0211556   -0.0555572    0.0120205   -0.0119154  -0.0780082
 -0.00176045    0.110914    -0.0593821   -0.00547134    0.0316909  -0.0130531   -0.0209137   -0.116179     -0.114493    -0.180601    -0.022792     0.0173478    0.0136714     0.0935144    0.00127654   0.0418357    0.00435494  -0.0511901    0.0148821   -0.0361245    -0.0935391  -0.0349165    0.0517058    0.0829718   -0.0995501   0.00180009
  0.161292      0.0590859   -0.106304    -0.0330065    -0.0401502  -0.117713    -0.0658055   -0.0071763     0.108494    -0.044097     0.00487055  -0.0819202    0.102632      0.0527505   -0.129552    -0.0361154   -0.0339828   -0.213793    -0.0912962   -0.0451918     0.160083   -0.0844122   -0.0750503    0.0127107    0.0875764   0.0695059
 -0.039125     -0.00742228  -0.198889    -0.00593655   -0.124828   -0.0827395   -0.0649486    0.011252      0.107376     0.0428881   -0.0329751    0.0516451    0.160451      0.027387    -0.122666    -0.0261195   -0.0196598   -0.0434909   -0.104077    -0.0730451    -0.0490514   0.0396303   -0.0901254    0.0274982    0.0943023   0.0635919
 -0.0420903     0.0724598    0.145767    -0.0305151    -0.0779192  -0.70826      0.077613    -0.0408859     0.0797815   -0.0467202    0.0674373    0.0357749    0.139839     -0.00836923   0.30412      0.0804236   -0.203704    -0.0338733   -0.23692      0.153902      0.316048    0.0484556    0.025973     0.0114601    0.197731   -0.349397
 -0.0391135     0.0743013    0.146519     0.00800665   -0.0435977   0.648054     0.090819     0.027942      0.0830833   -0.0399081    0.0918264    0.0370595    0.188218     -0.0946562   -0.463904     0.101822    -0.0144821   -0.0858679    0.0920604   -0.0991537     0.0752736   0.0485159    0.161304     0.0328028    0.194754    0.146175
 -0.208465      0.0133036    0.072289    -0.529942     -0.151788   -0.209566    -0.0134472   -0.0212964     0.0307289    0.36927     -0.1871      -0.0870882    0.0838357    -0.0408919    0.152764     0.124518    -0.0722539    0.0645329   -0.268193    -0.0536652     0.0163126  -0.069038     0.145336    -0.0988986   -0.010433   -0.0893466
 -0.199679     -0.0283307   -0.208103     0.631536     -0.0282863   0.0590883   -0.0424527    0.0156827     0.024794     0.165989    -0.103764    -0.0900539    0.0566697    -0.0195417    0.0774848   -0.0538487   -0.147        0.12134     -0.134605     0.000768508   0.030558    0.0246657    0.130997    -0.0343856    0.121907    0.0497543
 -0.132019      0.0236321    0.212687    -0.000402413  -0.0738121   0.058066     0.0845035   -0.000206082   0.0977008    0.080812    -0.139324     0.0929599   -0.0784043     0.00754091  -0.0528949   -0.122302     0.195806    -0.036809     0.0031788   -0.123456     -0.107433   -0.116235    -0.0403486    0.00457088   0.0362045  -0.266531
 -0.0133005     0.0517827   -0.0260511    0.0379749    -0.0880442  -0.0834919    0.0864008    0.0582239     0.0165686    0.0163625    0.179295    -0.0535249   -0.0522237    -0.1016      -0.0800795    0.0541085    0.0708185    0.173629    -0.0470043    0.157774      0.0108085   0.00846201   0.0940269    0.0515193   -0.129144    0.1583
 -0.589895     -0.072659     0.112334    -0.0292957     0.211452    0.228139     0.029569     0.174257     -0.086646    -0.016929     0.0908505    0.189832     0.0774384     0.0683397   -0.0213658    0.00178337  -0.0688671   -0.00447871   0.0170763   -0.170359      0.0433539  -0.163821    -0.0827678    0.134431     0.125204    0.127261
  0.295795     -0.0704886    0.12733     -0.0648458     0.183399    0.0292283    0.0151117   -0.101333     -0.136599    -0.0244064    0.00103      0.0978549   -0.040022      0.0725053    0.00662713   0.00196075   0.0335455   -0.0278571    0.0244045    0.0474288     0.0306942  -0.11055     -0.0396013    0.146069     0.132345    0.0177594
  0.0838701    -0.00228834  -0.117608     0.0813222     0.259664    0.165696     0.0606873   -0.452172     -0.0224553   -0.0271864    0.0373549   -0.138735     0.121518     -0.0900254   -0.0922209    0.189231     0.0918075   -0.0826774    0.0524698    0.156807     -0.0263513   0.083788    -0.00609414   0.101841    -0.05102    -0.0718166
  0.0752346     0.00210229  -0.117674    -0.0215494     0.119298   -0.103024     0.00527331   0.364407     -0.023456    -0.041623     0.080075    -0.14064     -0.0880127    -0.0634871   -0.137519    -0.23152      0.0443654    0.148789    -0.00514559   0.274731     -0.137612    0.107003    -0.0142218    0.00888456  -0.0131771  -0.0708028
  0.0970948    -0.138431     0.0130614    0.022064     -0.058233   -0.00838729   0.191356    -0.0265597    -0.111468     0.174618    -0.0311755   -0.0374583   -0.0284141     0.0880291    0.266688     0.0727527   -0.0807351    0.0721532    0.140618     0.0663965     0.0228266  -0.0316813   -0.012475    -0.13293     -0.0873563   0.124473
  0.146356     -0.0589593    0.0393961    0.0505814    -0.0420101  -0.151436     0.156286    -0.160935      0.104131    -0.0932137    0.0339554   -0.0765738    0.0996771     0.0205713   -0.105917     0.0650693    0.0722993    0.0426478    0.0724064    0.141944      0.075348   -0.0413248    0.0210733   -0.00449765   0.253214   -0.056092
  0.03183      -0.0306134    0.00112177  -0.0310623     0.0140049   0.0476655   -0.115081     0.0571438    -0.0790274   -0.205477    -0.0180126   -0.167042    -0.141989      0.0467309    0.146287    -0.130626     0.15609     -0.110583     0.0672837    0.0395362    -0.0437923  -0.0164618    0.0087335   -0.00544043   0.0560604   0.0296984
  0.100065     -0.0939808    0.0316641    0.00664396    0.186526    0.0249032   -0.0763972    0.0220672    -0.0927967   -0.0891394    0.0154567   -0.0588775    0.0106851     0.111756     0.134766     0.00235288   0.0835498    0.0757075    0.0537297    0.0344554     0.107925    0.0925395    0.0933469    0.147624    -0.119895   -0.0643476[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      6
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.102890
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.076894
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      6
│     12
│      ⋮
│     28
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.089234
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.092148
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      6
│     12
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.094576
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     28
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.079161
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      6
│     12
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.102478
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.076776
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      6
│     12
│      ⋮
│     28
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.089331
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     27
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
kind diag, method kmeans
[ Info: iteration 10, average log likelihood -1.092093
┌ Info: EM with 100000 data points 10 iterations avll -1.092093
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.479171e+05
      1       6.864190e+05      -2.614981e+05 |       32
      2       6.595622e+05      -2.685682e+04 |       32
      3       6.423926e+05      -1.716960e+04 |       32
      4       6.307738e+05      -1.161874e+04 |       32
      5       6.233151e+05      -7.458723e+03 |       32
      6       6.190331e+05      -4.281961e+03 |       32
      7       6.169692e+05      -2.063889e+03 |       32
      8       6.159421e+05      -1.027121e+03 |       32
      9       6.153902e+05      -5.519009e+02 |       32
     10       6.150515e+05      -3.387482e+02 |       32
     11       6.148013e+05      -2.502208e+02 |       32
     12       6.145975e+05      -2.037915e+02 |       32
     13       6.144334e+05      -1.640806e+02 |       32
     14       6.142524e+05      -1.810265e+02 |       32
     15       6.140060e+05      -2.463523e+02 |       32
     16       6.136349e+05      -3.711335e+02 |       32
     17       6.131779e+05      -4.569409e+02 |       32
     18       6.126306e+05      -5.473401e+02 |       32
     19       6.122337e+05      -3.969200e+02 |       32
     20       6.120344e+05      -1.992464e+02 |       32
     21       6.119220e+05      -1.124581e+02 |       32
     22       6.118139e+05      -1.080982e+02 |       32
     23       6.117356e+05      -7.821341e+01 |       32
     24       6.116971e+05      -3.856685e+01 |       32
     25       6.116711e+05      -2.600962e+01 |       31
     26       6.116541e+05      -1.700497e+01 |       31
     27       6.116413e+05      -1.274745e+01 |       30
     28       6.116291e+05      -1.221339e+01 |       28
     29       6.116130e+05      -1.612225e+01 |       32
     30       6.115904e+05      -2.256769e+01 |       31
     31       6.115585e+05      -3.193993e+01 |       29
     32       6.115148e+05      -4.369277e+01 |       32
     33       6.114576e+05      -5.722872e+01 |       32
     34       6.113871e+05      -7.040764e+01 |       32
     35       6.113016e+05      -8.553889e+01 |       32
     36       6.111759e+05      -1.256625e+02 |       32
     37       6.109789e+05      -1.970613e+02 |       32
     38       6.106612e+05      -3.177142e+02 |       32
     39       6.100624e+05      -5.988113e+02 |       32
     40       6.092918e+05      -7.705177e+02 |       32
     41       6.087154e+05      -5.763998e+02 |       32
     42       6.085628e+05      -1.526704e+02 |       31
     43       6.085326e+05      -3.014721e+01 |       29
     44       6.085246e+05      -8.056007e+00 |       27
     45       6.085190e+05      -5.602101e+00 |       23
     46       6.085163e+05      -2.661876e+00 |       24
     47       6.085139e+05      -2.422711e+00 |       21
     48       6.085111e+05      -2.790453e+00 |       21
     49       6.085088e+05      -2.278760e+00 |       17
     50       6.085079e+05      -9.388237e-01 |       18
K-means terminated without convergence after 50 iterations (objv = 608507.8742785163)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.328649
[ Info: iteration 2, average log likelihood -1.295375
[ Info: iteration 3, average log likelihood -1.265555
[ Info: iteration 4, average log likelihood -1.238448
[ Info: iteration 5, average log likelihood -1.197843
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.126906
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│     11
│     12
│     14
│     21
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.067758
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     15
│     18
│     20
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.129087
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.159286
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.106843
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│     11
│     12
│     14
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.063260
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     15
│     18
│     21
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.110652
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.134489
[ Info: iteration 14, average log likelihood -1.104788
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      3
│      4
│      5
│      ⋮
│     26
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.027216
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     18
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.163087
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.144617
[ Info: iteration 18, average log likelihood -1.112328
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      7
│      9
│     11
│     12
│     14
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.043037
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     15
│     18
│     21
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.118472
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.140393
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.109845
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      7
│      9
│     11
│     12
│     14
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.049392
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      4
│     15
│     21
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.120028
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.143181
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.107709
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      9
│     11
│      ⋮
│     18
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.051654
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     15
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.134107
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.121448
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.110676
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      7
│      9
│      ⋮
│     15
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.050488
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      4
│     21
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.143133
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     20
│     23
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.145505
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.124899
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      9
│     12
│      ⋮
│     18
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.051663
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      4
│      5
│     11
│     21
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.119667
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.169908
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.110681
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      9
│     12
│      ⋮
│     18
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.061308
[ Info: iteration 40, average log likelihood -1.144505
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      4
│     11
│     20
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.076703
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.098378
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      9
│     12
│      ⋮
│     16
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.078597
[ Info: iteration 44, average log likelihood -1.165882
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      4
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.096800
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     14
│     23
│     26
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.079184
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      5
│      7
│      9
│      ⋮
│     15
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.084022
[ Info: iteration 48, average log likelihood -1.160764
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      4
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.102355
32×26 Array{Float64,2}:
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     23
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.081755
┌ Info: EM with 100000 data points 50 iterations avll -1.081755
└ 59.0 data points per parameter
  0.0220607   0.135555      0.190239    -0.0917251    0.135793    0.000654035   0.0220972   -0.0753984   -0.00179915  -0.0615337   0.0664065   -0.117286    -0.138847    -0.0023125   0.155635    -0.137888     0.147122    -0.110196    -0.129097    -0.081635     -0.0526459   -0.0121209    0.0862396    -0.0370159   -0.0807153   -0.012549
 -0.156416   -0.215419      0.0168536    0.130546     0.0932897  -0.0806207    -0.0469732   -0.00274523  -0.0903559    0.101732   -0.0301645   -0.105091    -0.070949     0.022476    0.0516154    0.0533678    0.0122125   -0.0206851    0.0544795   -0.142475      0.0759741   -0.184321    -0.0754952     0.0455719    0.152611    -0.0310375
  0.0789535   0.000410287  -0.117292     0.033836     0.195062    0.0280683     0.0385225   -0.0455993   -0.0220153   -0.0345174   0.0655502   -0.139231     0.0181042   -0.0790684  -0.11533     -0.0296364    0.0762492    0.0509939    0.0205705    0.225671     -0.0870663    0.0975636   -0.0103099     0.0606291   -0.0377223   -0.0714635
  0.0933802  -0.0977183    -0.0126169   -0.00340383  -0.0498887  -0.000582848   0.169735    -0.0113519   -0.1171       0.159455   -0.0357215   -0.055025    -0.0529885    0.0893116   0.262938     0.0362743   -0.0718265    0.0458364    0.106508     0.0550877     0.027511    -0.0301985   -0.00529129   -0.112431    -0.0988223    0.111652
 -0.128115    0.0286159     0.3241       0.00866986  -0.0561239   0.0849382     0.0688735   -0.0322779    0.0794916    0.0670903  -0.120041     0.124205    -0.103287     0.0456661  -0.014686    -0.151646     0.232433    -0.0569528   -0.00239292  -0.137235     -0.23873     -0.107483    -0.0114155    -0.00475309   0.0178612   -0.211921
 -0.212782    0.0402064     0.106716     0.0960821   -0.108752   -0.217073      0.14867     -0.153064    -0.0411662    0.111097   -0.172701     0.177379     0.132803    -0.092333   -0.0277319   -0.128574    -0.0906022   -0.0952304    0.0473899   -0.073414     -0.143532     0.240607     0.11274       0.137991    -0.0291634   -0.0562974
  0.0690823  -0.0410107     0.00706807  -0.101231     0.0807073   0.116754     -0.128286    -0.015158    -0.0703847    0.117189   -0.130048    -0.0660062    0.048864    -0.0327403  -0.0668855    0.0375091   -0.124169    -0.113597     0.126718     0.0813881    -0.0154036   -0.0265242   -0.0951966    -0.203594    -0.00594381   0.149
 -0.0525165   0.163181     -0.110905    -0.0726795   -0.026301    0.099588      0.0768801    0.00548857  -0.0233264   -0.263168    0.0184166    0.0260015   -0.0314499    0.24246     0.0205129    0.055515    -0.0329339    0.0615832    0.0847402   -0.0958119     0.212538    -0.07369      0.0244576    -0.0224823   -0.0188179    0.164302
  0.0544682   0.034095      0.0387494    0.0305196    0.0799036   0.0127467     0.142511    -0.0185112   -0.0540918   -0.0251089   0.148562    -0.184892     0.260105    -0.154162   -0.0601698    0.0451373    0.0659697   -0.277387    -0.162293     0.000158529  -0.105262    -0.0553231   -0.109635      0.082562    -0.0674811   -0.0657904
  0.15254    -0.0634122     0.041382     0.05625     -0.0273974  -0.141124      0.158094    -0.15415      0.0986202   -0.0898469   0.0303962   -0.0726868    0.0911784    0.0240455  -0.087726     0.0654778    0.0583829    0.043419     0.0718639    0.146661      0.0703495   -0.035946     0.0221055    -0.0117026    0.241093    -0.0477436
 -0.219917   -0.00709073   -0.149459     0.0659788    0.0299608   0.0821269     0.0378787   -0.180277    -0.0993601    0.077629   -0.0307716    0.0454754    0.0730002    0.0524187   0.0382792   -0.020122    -0.12957     -0.0904912    0.0700846    0.0313015    -0.0151455   -0.0459252    0.0987093    -0.0734747   -0.00257357   0.0268923
 -0.102271    0.12907       0.0100184    0.107124    -0.019869   -0.0310512     0.0892352    0.119767     0.0627179    0.0228815   0.167374     0.0711614   -0.0164712   -0.0735892   0.0348087    0.0422189   -0.0271974   -0.108581    -0.0236995   -0.097693      0.0134094    0.163205    -0.0283746    -0.0935422   -0.0947038   -0.115677
 -0.0222826   0.019858     -0.0591963    0.0867184    0.0487192  -0.127829      0.00940622   0.0659672   -0.0805622    0.0500694   0.00630008   0.0529573    0.0224928   -0.0742138   0.0212337   -0.0417853   -0.0329878    0.0290156    0.0111007   -0.0386892     0.0479513   -0.0537758   -0.0452802     0.0220785   -0.0873893    0.0304948
 -0.0354329   0.11519      -0.0246678    0.0523286    0.0762595  -0.0703657     0.104342     0.110524     0.00855422   0.0249189  -0.263993    -0.0702157    0.143172    -0.098818    0.0980714    0.134261     0.0688737   -0.0640195   -0.0402309   -0.0287336     0.0418473   -0.0212362   -0.00898476    0.0533044    0.179199    -0.0184433
  0.0187502   0.0709776     0.0464483   -0.0313239   -0.106819    0.104129      0.0222692   -0.0881395    0.0396623    0.0727546   0.0201407   -0.00046133  -0.0834994    0.0558462  -0.0996698   -0.175289     0.0251055   -0.00651148  -0.153763     0.0784124     0.0660973    0.107975    -0.103315      0.393402    -0.13371     -0.177033
 -0.0408423   0.075457      0.148674    -0.0107066   -0.0617584  -0.0228445     0.0812052   -0.00163301   0.0904045   -0.04419     0.0790234    0.0374217    0.157613    -0.0633264  -0.0900907    0.0911902   -0.105988    -0.0628523   -0.0812977    0.0326146     0.195105     0.0486874    0.100766      0.0193586    0.194576    -0.0917341
 -0.197272   -0.00622676   -0.0681899    0.027784    -0.0925775  -0.0787269    -0.0278588   -0.00408424   0.0280997    0.268518   -0.146876    -0.0908376    0.0709106   -0.0340192   0.115301     0.0371797   -0.106314     0.0944489   -0.206278    -0.0265662     0.0240884   -0.0282581    0.136333     -0.0675661    0.048402    -0.01695
  0.0837557   0.0625468     0.00151536  -0.0226005    0.037281   -0.114175      0.0225749   -0.155225    -0.122033    -0.241205    0.077324    -0.0521476    0.00316598   0.0109802  -0.0676991    0.148174     0.0325831    0.0184083   -0.0388019    0.110759     -0.305697     0.01777      0.0068903     0.149019    -0.161505    -0.0148941
  0.0718558  -0.123347     -0.174599     0.0111662    0.0469941   0.162923      0.120764    -0.116862     0.0487579    0.231577   -0.05871     -0.0750723   -0.00439007  -0.0256699  -0.0556283   -0.216676     0.0163019   -0.0598523   -0.0613236   -0.0636107     0.0794628    0.0996336   -0.0198236    -0.0645284    0.0468016   -0.095318
  0.0197838   0.000912406  -0.220026    -0.0100221   -0.10588    -0.121054     -0.058646     0.00780547   0.0958273    0.0187729  -0.0211726    0.00661184   0.1386       0.0182683  -0.149417    -0.0303879   -0.0445052   -0.0835412   -0.1228      -0.0777351     0.00155281   0.0210849   -0.104165      0.0236292    0.062356     0.0503573
 -0.0867704   0.023709      0.0933936   -0.0169781   -0.0694507   0.0390104     0.0549959   -0.0185406    0.105782     0.0941287  -0.114224     0.0424288   -0.0213996   -0.0133681  -0.0381429   -0.104715     0.148543    -0.0343951   -0.0100336   -0.114531     -0.0571822   -0.101226    -0.0177828     0.00363398   0.0467688   -0.187598
  0.10152    -0.0928432     0.0416013    0.00915308   0.189194    0.0252259    -0.0765717    0.0227502   -0.0938422   -0.0820107   0.0196139   -0.0616527    0.00632919   0.111741    0.139362     0.00173081   0.0958694    0.0739491    0.0489395    0.0391413     0.108489     0.0967578    0.0957461     0.1498      -0.117994    -0.0675967
  0.0372068  -0.0302221     0.0216311   -0.0299662    0.0275608   0.0484896    -0.13512      0.0609852   -0.074995    -0.22756    -0.0220113   -0.18658     -0.151845     0.0236855   0.130064    -0.152965     0.162727    -0.106253     0.0608774    0.0700431    -0.0592424   -0.0187225    0.000780731   0.00821237   0.0744348    0.0253272
  0.0906405  -0.0598654     0.0198953    0.0463531   -0.0944541   0.0486937     0.01027      0.0626273    0.0213802   -0.0708185   0.0287552    0.0730678    0.170043    -0.0214543   0.0602721   -0.0541154    0.0311706    0.208953    -0.0301737    0.0189509     0.0637818    0.0938179   -0.179841     -0.104835     0.0634905   -0.0213605
  0.0048199   0.0489201     0.0398403    0.055678    -0.294448    0.00972179   -0.125276     0.108803    -0.273656     0.102813   -0.116055     0.162038     0.0719185    0.150277    0.226016    -0.053214    -0.00470797  -0.14571      0.0809707    0.0660948    -0.053811     0.101683     0.00856102   -0.0950754    0.184682    -0.056994
  0.123047   -0.0817451     0.0534143   -0.0506416   -0.150028   -0.110295     -0.0581958   -0.114681    -0.120886    -0.0864406  -0.0677701   -0.0515398   -0.127184    -0.075355    0.0700221   -0.119874     0.103683    -0.00523273   0.0103366    0.109288      0.0633784   -0.0668193   -0.0481759    -0.123654     0.096445    -0.102034
 -0.0964896  -0.131898      0.0937329   -0.0421153    0.0190509  -0.122606      0.0412315    0.0702441    0.0470356   -0.138365    0.239438    -0.0310049   -0.059394    -0.0139839   0.0973391    0.0100241   -0.0469707    0.0561085    0.0394504   -0.0799361    -0.190976     0.0670383   -0.0702415    -0.0470151    0.0847079   -0.0718687
 -0.0106951   0.0520798    -0.0120035    0.0297489   -0.0800079  -0.0953982     0.0915167    0.0616849    0.0181154    0.0166022   0.191645    -0.0658877   -0.0633791   -0.0986105  -0.0817287    0.0630365    0.072277     0.163007    -0.0551617    0.147995      0.0243513    0.00407738   0.0877225     0.0563316   -0.131956     0.134831
  0.0458661  -0.116801      0.152174    -0.0693052    0.0558032  -0.0590003    -0.0176985    0.173414     0.0622134    0.0576817   0.0831677   -0.0445927   -0.0692922    0.157862   -0.176431    -0.0597166    0.0531645   -0.0719074   -0.0348029   -0.0655616     0.0634397   -0.0398244   -0.075505     -0.0998842    0.00291202   0.190776
 -0.123675   -0.0610376     0.0467982   -0.0303235   -0.0563586  -0.11619      -0.0288486   -0.0441241   -0.114229     0.0355258   0.179049     0.0291249    0.158651     0.115328   -0.00912963   0.0515248   -0.0954032   -0.0569278    0.0536202   -0.216892      0.118123    -0.0338643    0.0216702     0.0510762    0.0422789   -0.0653783
 -0.0870124   0.101948     -0.0987493    0.0297664    0.0610595   0.0431951    -0.132241    -0.108701    -0.122528    -0.0368888  -0.188726     0.0908829    0.0494765    0.0858005   0.103417    -0.138511     0.0549307   -0.255684     0.0580312   -0.197845     -0.0371834   -0.0299656    0.135417      0.0555685   -0.0328989   -0.098186
 -0.126259   -0.068675      0.119982    -0.0412235    0.187648    0.117711      0.0246052    0.0315805   -0.106185    -0.0177711   0.0450804    0.144891     [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
0.016033     0.0686003  -0.00795981   0.00027484  -0.0161566   -0.016606     0.021234    -0.0609641     0.0352113   -0.13579     -0.0583691     0.134505     0.126741     0.0674613┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      7
│      9
│     12
│     15
│     16
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.074988
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      9
│     11
│      ⋮
│     16
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.027864
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      3
│      4
│      5
│      ⋮
│     26
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.996592
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      7
│      9
│     12
│     15
│     16
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.074391
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      9
│     11
│      ⋮
│     16
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.027968
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      3
│      4
│      5
│      ⋮
│     26
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.996347
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      7
│      9
│     12
│     15
│     16
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.074402
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      7
│      9
│     11
│      ⋮
│     16
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.027957
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      1
│      3
│      4
│      5
│      ⋮
│     26
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.996336
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      7
│      9
│     12
│     15
│     16
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.074410
┌ Info: EM with 100000 data points 10 iterations avll -1.074410
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0280633    0.0393834    -0.0633042   -0.0182787    0.22413      0.0958535     0.0899534   -0.0277804    0.253593    -0.0868818   0.153209     0.0366088  -0.0517871    -0.0679397    0.0326879   -0.114081     0.0798695     0.166176    0.116937     0.178916    0.0532998    0.0634232     0.188916     0.0287982     0.0231691   -0.119118
  0.137728     0.0781314    -0.0905652   -0.113215    -0.0502207    0.155646      0.0249636    0.187557    -0.0638502    0.045857   -0.0581125    0.100906    0.0867677    -0.0372549    0.0354086    0.111894     0.14003      -0.148553    0.0428764    0.0468855  -0.115298    -0.050275      0.0950265    0.0658822     0.123564     0.0204255
 -0.0389676   -0.0818757    -0.0214732    0.0617836    0.026702    -0.0122262    -0.0940711    0.0896241    0.128715    -0.0459185  -0.0591798    0.0303804   0.064656      0.0424549    0.166717    -0.0856954    0.0881622    -0.0965769  -0.0294453    0.0199089   0.0893306   -0.134374     -0.0468845    0.00946842    0.0660046    0.108395
  0.0530029   -0.209823      0.105042    -0.0677092    0.0599106   -0.0198386     0.0842269   -0.0183127   -0.0617497   -0.0654246   0.170389    -0.0849528  -0.0103319    -0.154022    -0.00826015   0.0554423    0.036072      0.173147    0.0567315    0.0300691   0.1892       0.0680989    -0.0284332   -0.101084      0.0326023    0.192516
  0.118331     0.000239782  -0.0117132    0.0595661   -0.0848453   -0.0404723    -0.155556    -0.00196523  -0.0933731   -0.0885538  -0.060837    -0.0600168  -0.101588      0.127022    -0.0666511    0.00190438   0.000728731  -0.0864328   0.0428383    0.0517195  -0.136187     0.0443303    -0.161209    -0.0249321    -0.0353935    0.0643601
 -0.235561     0.0944376    -0.0496021    0.113336    -0.11229      0.128633     -0.0335891   -0.0930373   -0.00587051   0.0813891  -0.134583    -0.168402    0.0357662    -0.01585      0.122562    -0.0816261    0.13931       0.143999    0.0414806   -0.114079   -0.0473381   -0.00180353    0.0589323    0.105043      0.109778     0.0536947
  0.0613209    0.0904027     0.129439     0.0331053    0.103467    -0.110071     -0.0483343    0.0608784   -0.0697786   -0.0708323  -0.038958     0.0109309  -0.068214     -0.121156     0.202006    -0.142305    -0.0709012     0.114638    0.141815    -0.0547147  -0.0504103    0.0487472     0.0507579    0.0569381     0.00847083   0.0818566
 -0.0769227    0.0622183     0.00220284   0.112647     0.077351     0.0176355    -0.104446     0.0545552    0.227978     0.152156   -0.185977    -0.084073   -0.0986733     0.0900551    0.0148119   -0.230393    -0.0444285     0.0464071  -0.174974     0.187923    0.0899313   -0.0997761     0.0881657   -0.0764681    -0.0771602   -0.149988
  0.0351451    0.0412701     0.0601236    0.0501523   -0.0773643   -0.0234731     0.166785    -0.0405053   -0.0832248    0.120221   -0.175705     0.0693943  -0.00790691    0.00294324   0.105726     0.00686732   0.00268183   -0.133137   -0.141966    -0.0477302  -0.0291063    0.0764256    -0.0882445    0.00475255    0.0360752   -0.029419
  0.118533    -0.219114      0.0315666    0.0992492    0.013908    -0.140581     -0.019009     0.112506     0.121332     0.166818    0.118264    -0.022844   -0.136894     -0.167566    -0.258615    -0.0351665   -0.0528584     0.0646621  -0.00839074  -0.0125885  -0.146064    -0.00239186    0.043196     0.0294002    -0.175321     0.125259
  0.119591     0.0227342     0.12581      0.0127332    0.005956    -0.229878      0.00918944   0.050387     0.11913     -0.0159937   0.0623969    0.0473143  -0.0202059     0.108289     0.110891     0.104537    -0.0670584    -0.0428631  -0.125998    -0.0409031   0.167951    -0.232592      0.0521917    0.202037     -0.00743628  -0.086489
  0.0295252    0.0587554    -0.0732864    0.0109434   -0.137088     0.0475762    -0.141455     0.050049    -0.0245917   -0.0535378  -0.0776979    0.131849   -0.00971721   -0.158238     0.00213711   0.0242034   -0.0970497     0.228832   -0.0642451   -0.105244   -0.0936474    0.0435869    -0.0286554   -0.0777797    -0.156907     0.0565304
 -0.0386862   -0.0512046    -0.0153882   -0.11458     -0.0248836    0.0201321    -0.148268     0.0838679   -0.115242     0.109401   -0.127136    -0.0461387  -0.0270683    -0.0332199   -0.108507     0.0454721    0.0483756    -0.129354    0.134149     0.166272   -0.0425799    0.000793746  -0.145176    -0.000332609   0.00430697   0.0215126
  0.0306492   -0.080952     -0.0533279    0.0396156    0.0760352   -0.0082339     0.00454837  -0.142326    -0.0162745    0.0350559  -0.022513    -0.136319   -0.164242      0.103523    -0.135614    -0.0146614   -0.0367584     0.119531    0.101823    -0.0861423  -0.0106056   -0.0733166     0.0183035    0.175918     -0.121227     0.0505543
  0.185114     0.0964172     0.0566237    0.184399     0.100505    -0.107417     -0.0333446    0.024679    -0.0500751    0.0558811   0.120857    -0.146488   -0.0606887     0.083068     0.15005      0.125989    -0.0273676     0.150916    0.183481    -0.0665574   0.109724    -0.0394691     0.0209549    0.0577269     0.00641759   0.0739281
 -0.152072     0.0250347    -0.116559     0.066745    -0.03079      0.0819016     0.0552672    0.0124534    0.0180644    0.0847927  -0.00833229   0.0337974  -0.0842014     0.0770438   -0.215067    -0.264168    -0.209381     -0.0130638  -0.154914    -0.0812443   0.0396539    0.0478802    -0.0279586   -0.0334492     0.174492     0.0286943
  0.125334    -0.146565     -0.120041    -0.0087935   -0.127483     0.0998853    -0.0766717   -0.024253     0.0705603    0.117831   -0.0163251    0.0717388  -0.01515      -0.0180045   -0.0484137   -0.0442146    0.0291659    -0.134201    0.0580053    0.0362954  -0.0396523   -0.193699      0.170732    -0.0599434     0.00058225   0.0640841
 -0.0562266    0.0791861    -0.0319265   -0.0178569   -0.0342354   -0.0913994     0.104212    -0.129616     0.185039    -0.221869    0.0174231   -0.166526   -0.113683     -0.206077     0.0309237    0.0107366    0.098        -0.110877   -0.0242263   -0.0114264  -0.0274783   -0.0725944    -0.0461059    0.0132564     0.00832013  -0.0445524
 -0.0951411   -0.215409     -0.0895258   -0.0562963   -0.0574867    0.101216      0.186023    -0.0804092    0.0682771    0.0350892   0.00818733  -0.162146    0.0496829     0.00440906   0.137882    -0.00739783   0.142628     -0.0539596   0.0020164    0.0190998  -0.128558    -0.0425783    -0.0334837    0.219085     -0.0843597    0.0445602
 -0.0904172    0.0307623    -0.112264     0.0747598   -0.0713748   -0.117304      0.0563196   -0.0755182   -0.198515    -0.0593724  -0.0379588   -0.0785402   0.190737      0.0285628   -0.0901176   -0.0971288    0.091714     -0.108793   -0.127531     0.0231408  -0.0644827   -0.0470898    -0.0586054   -0.116193     -0.242888    -0.0649252
  0.00953101   0.205748      0.0707882    0.00843906   0.103514     0.0993828     0.0797092    0.0977965   -0.107178    -0.120293    0.0601202   -0.023348   -0.0322061     0.0413471   -0.00431192   0.03475      0.00795243    0.162752    0.161988    -0.0349936   0.113983     0.106541      0.165099     0.0731524     0.00940104   0.190772
  0.0244613   -0.131487      0.0887402    0.0291116   -0.174988     0.0475344     0.126408     0.0861108   -0.0539038   -0.20185    -0.0737465   -0.0604362  -0.0337438     0.0798964   -0.187203    -0.0374974   -0.0623148    -0.243886   -0.126803    -0.0570928   0.0267448    0.027673     -0.0139553    0.204706      0.145764    -0.0902072
  0.162262     0.0740765     0.0396837   -0.0798605    0.0974336    0.0949324     0.0820256   -0.147148     0.0338307    0.112868   -0.148322     0.0606302   0.13276      -0.0423615    0.088429    -0.0962319    0.0336547     0.0359446   0.106033    -0.0149666  -0.0750977    0.0207934    -0.0626146    0.173576      0.139831     0.0115832
  0.109719     0.0288869     0.0299244   -0.119821     0.0154019    0.0694387    -0.0858483   -0.085479    -0.115682    -0.0600121   0.0493731    0.247334   -0.157761     -0.141616     0.100742    -0.00495132   0.00254723   -0.0442262   0.0706409   -0.0133843   0.018984     0.0993333    -0.0538814    0.00747737   -0.0638822   -0.0882649
  0.211062     0.0919117     0.178067     0.0193299    0.149559    -0.0943301     0.00992848  -0.00642437  -0.120672    -0.312342   -0.0385095   -0.0812053  -0.0602785     0.0897174   -0.0626905    0.0209789    0.0926184    -0.0517164   0.102293    -0.038155    0.0436495   -0.159252      0.0178645    0.0908916    -0.0165257    0.0314002
 -0.0888631   -0.140135      0.203079     0.0257472   -0.0607899   -0.000154036  -0.0349706   -0.0183708    0.0558491   -0.0912008   0.0726852    0.162477    0.0185962    -0.154445     0.161864    -0.165908    -0.118728     -0.0415273  -0.0416072    0.0773642  -0.161092    -0.0546352     0.0948298    0.135064      0.0846921   -0.0132643
 -0.21466     -0.0372933     0.0880658   -0.0277741   -0.142211    -0.0344669     0.135253     0.083145    -0.0130268   -0.0817932   0.0454307    0.083589   -0.0141797    -0.068427     0.0624969   -0.0628628   -0.0972183    -0.127605   -0.0761194    0.138847   -0.00226292  -0.00587395   -0.0680714    0.053931     -0.163781    -0.0132085
 -0.204732    -0.0483404     0.0167577   -0.119627    -0.0530006   -0.145986     -0.0406847    0.0166016    0.016954    -0.0672297   0.0824626   -0.184439   -0.158052      0.0449637    0.0283839   -0.0839002    0.0533168    -0.0791237   0.0204386    0.0757641  -0.0456409   -0.0200589    -0.0911612   -0.0434252    -0.0891194    0.0742123
 -0.103225     0.203678     -0.0303926   -0.0355413   -0.00734023   0.0222151    -0.135467    -0.053573     0.0504188    0.0943759   0.0578053    0.0209969  -0.0371788    -0.0589737    0.216214    -0.00910399  -0.076313      0.106429   -0.0249588   -0.126347    0.098213    -0.072522     -0.0216218   -0.0238846     0.182035    -0.112274
  0.0452813   -0.0577828     0.0811983    0.150564    -0.136846    -0.0381548    -0.0125128   -0.0762884    0.0635018    0.0680033   0.125734     0.0632668  -0.0496088     0.122504     0.0570553    0.0833259   -0.0104907    -0.0310139   0.0651007    0.133136    0.0848112    0.0348511     0.107511    -0.0356427     0.0958047    0.0136127
 -0.163244     0.0130111     0.0131694   -0.032469     0.126373    -0.0262606    -0.169419     0.077783    -0.0856211    0.0506732   0.0668947    0.0298347  -0.000409033  -0.00777294  -0.0857238   -0.130308     0.0778424     0.0199133   0.205127    -0.108586   -0.129575    -0.0679697    -0.116977     0.065819      0.102906     0.0508234
 -0.0041065    0.166445     -0.0846086    0.120976    -0.0898175    0.0303216     0.0110782    0.00324971   0.0129908    0.0856149   0.0382828   -0.132999   -0.0392454     0.0646      -0.10797      0.00613548  -0.0924458    -0.242576   -0.0615852    0.0888819  -0.0886515    0.0340996     0.00688824   0.0276873     0.0160108    0.00567566kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4263730517028763
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.426393
[ Info: iteration 2, average log likelihood -1.426321
[ Info: iteration 3, average log likelihood -1.426267
[ Info: iteration 4, average log likelihood -1.426203
[ Info: iteration 5, average log likelihood -1.426123
[ Info: iteration 6, average log likelihood -1.426012
[ Info: iteration 7, average log likelihood -1.425835
[ Info: iteration 8, average log likelihood -1.425504
[ Info: iteration 9, average log likelihood -1.424872
[ Info: iteration 10, average log likelihood -1.423839
[ Info: iteration 11, average log likelihood -1.422624
[ Info: iteration 12, average log likelihood -1.421691
[ Info: iteration 13, average log likelihood -1.421208
[ Info: iteration 14, average log likelihood -1.421011
[ Info: iteration 15, average log likelihood -1.420936
[ Info: iteration 16, average log likelihood -1.420907
[ Info: iteration 17, average log likelihood -1.420895
[ Info: iteration 18, average log likelihood -1.420890
[ Info: iteration 19, average log likelihood -1.420888
[ Info: iteration 20, average log likelihood -1.420887
[ Info: iteration 21, average log likelihood -1.420886
[ Info: iteration 22, average log likelihood -1.420885
[ Info: iteration 23, average log likelihood -1.420885
[ Info: iteration 24, average log likelihood -1.420884
[ Info: iteration 25, average log likelihood -1.420884
[ Info: iteration 26, average log likelihood -1.420883
[ Info: iteration 27, average log likelihood -1.420883
[ Info: iteration 28, average log likelihood -1.420883
[ Info: iteration 29, average log likelihood -1.420882
[ Info: iteration 30, average log likelihood -1.420882
[ Info: iteration 31, average log likelihood -1.420882
[ Info: iteration 32, average log likelihood -1.420882
[ Info: iteration 33, average log likelihood -1.420881
[ Info: iteration 34, average log likelihood -1.420881
[ Info: iteration 35, average log likelihood -1.420881
[ Info: iteration 36, average log likelihood -1.420881
[ Info: iteration 37, average log likelihood -1.420881
[ Info: iteration 38, average log likelihood -1.420881
[ Info: iteration 39, average log likelihood -1.420881
[ Info: iteration 40, average log likelihood -1.420881
[ Info: iteration 41, average log likelihood -1.420881
[ Info: iteration 42, average log likelihood -1.420881
[ Info: iteration 43, average log likelihood -1.420880
[ Info: iteration 44, average log likelihood -1.420880
[ Info: iteration 45, average log likelihood -1.420880
[ Info: iteration 46, average log likelihood -1.420880
[ Info: iteration 47, average log likelihood -1.420880
[ Info: iteration 48, average log likelihood -1.420880
[ Info: iteration 49, average log likelihood -1.420880
[ Info: iteration 50, average log likelihood -1.420880
┌ Info: EM with 100000 data points 50 iterations avll -1.420880
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4263932586965435
│     -1.4263209626278948
│      ⋮
└     -1.4208801731015555
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420900
[ Info: iteration 2, average log likelihood -1.420825
[ Info: iteration 3, average log likelihood -1.420769
[ Info: iteration 4, average log likelihood -1.420704
[ Info: iteration 5, average log likelihood -1.420629
[ Info: iteration 6, average log likelihood -1.420548
[ Info: iteration 7, average log likelihood -1.420468
[ Info: iteration 8, average log likelihood -1.420398
[ Info: iteration 9, average log likelihood -1.420341
[ Info: iteration 10, average log likelihood -1.420298
[ Info: iteration 11, average log likelihood -1.420264
[ Info: iteration 12, average log likelihood -1.420237
[ Info: iteration 13, average log likelihood -1.420212
[ Info: iteration 14, average log likelihood -1.420189
[ Info: iteration 15, average log likelihood -1.420166
[ Info: iteration 16, average log likelihood -1.420143
[ Info: iteration 17, average log likelihood -1.420118
[ Info: iteration 18, average log likelihood -1.420092
[ Info: iteration 19, average log likelihood -1.420064
[ Info: iteration 20, average log likelihood -1.420036
[ Info: iteration 21, average log likelihood -1.420007
[ Info: iteration 22, average log likelihood -1.419977
[ Info: iteration 23, average log likelihood -1.419947
[ Info: iteration 24, average log likelihood -1.419918
[ Info: iteration 25, average log likelihood -1.419891
[ Info: iteration 26, average log likelihood -1.419864
[ Info: iteration 27, average log likelihood -1.419839
[ Info: iteration 28, average log likelihood -1.419815
[ Info: iteration 29, average log likelihood -1.419793
[ Info: iteration 30, average log likelihood -1.419772
[ Info: iteration 31, average log likelihood -1.419753
[ Info: iteration 32, average log likelihood -1.419734
[ Info: iteration 33, average log likelihood -1.419716
[ Info: iteration 34, average log likelihood -1.419698
[ Info: iteration 35, average log likelihood -1.419682
[ Info: iteration 36, average log likelihood -1.419666
[ Info: iteration 37, average log likelihood -1.419651
[ Info: iteration 38, average log likelihood -1.419637
[ Info: iteration 39, average log likelihood -1.419623
[ Info: iteration 40, average log likelihood -1.419611
[ Info: iteration 41, average log likelihood -1.419600
[ Info: iteration 42, average log likelihood -1.419590
[ Info: iteration 43, average log likelihood -1.419580
[ Info: iteration 44, average log likelihood -1.419572
[ Info: iteration 45, average log likelihood -1.419565
[ Info: iteration 46, average log likelihood -1.419558
[ Info: iteration 47, average log likelihood -1.419552
[ Info: iteration 48, average log likelihood -1.419547
[ Info: iteration 49, average log likelihood -1.419543
[ Info: iteration 50, average log likelihood -1.419539
┌ Info: EM with 100000 data points 50 iterations avll -1.419539
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4209001815038038
│     -1.4208251940205234
│      ⋮
└     -1.4195389805734402
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419549
[ Info: iteration 2, average log likelihood -1.419479
[ Info: iteration 3, average log likelihood -1.419418
[ Info: iteration 4, average log likelihood -1.419346
[ Info: iteration 5, average log likelihood -1.419260
[ Info: iteration 6, average log likelihood -1.419160
[ Info: iteration 7, average log likelihood -1.419053
[ Info: iteration 8, average log likelihood -1.418950
[ Info: iteration 9, average log likelihood -1.418858
[ Info: iteration 10, average log likelihood -1.418782
[ Info: iteration 11, average log likelihood -1.418722
[ Info: iteration 12, average log likelihood -1.418676
[ Info: iteration 13, average log likelihood -1.418639
[ Info: iteration 14, average log likelihood -1.418610
[ Info: iteration 15, average log likelihood -1.418586
[ Info: iteration 16, average log likelihood -1.418565
[ Info: iteration 17, average log likelihood -1.418546
[ Info: iteration 18, average log likelihood -1.418528
[ Info: iteration 19, average log likelihood -1.418512
[ Info: iteration 20, average log likelihood -1.418496
[ Info: iteration 21, average log likelihood -1.418480
[ Info: iteration 22, average log likelihood -1.418464
[ Info: iteration 23, average log likelihood -1.418448
[ Info: iteration 24, average log likelihood -1.418432
[ Info: iteration 25, average log likelihood -1.418415
[ Info: iteration 26, average log likelihood -1.418399
[ Info: iteration 27, average log likelihood -1.418382
[ Info: iteration 28, average log likelihood -1.418365
[ Info: iteration 29, average log likelihood -1.418348
[ Info: iteration 30, average log likelihood -1.418332
[ Info: iteration 31, average log likelihood -1.418315
[ Info: iteration 32, average log likelihood -1.418299
[ Info: iteration 33, average log likelihood -1.418283
[ Info: iteration 34, average log likelihood -1.418267
[ Info: iteration 35, average log likelihood -1.418252
[ Info: iteration 36, average log likelihood -1.418237
[ Info: iteration 37, average log likelihood -1.418223
[ Info: iteration 38, average log likelihood -1.418209
[ Info: iteration 39, average log likelihood -1.418196
[ Info: iteration 40, average log likelihood -1.418184
[ Info: iteration 41, average log likelihood -1.418172
[ Info: iteration 42, average log likelihood -1.418160
[ Info: iteration 43, average log likelihood -1.418150
[ Info: iteration 44, average log likelihood -1.418139
[ Info: iteration 45, average log likelihood -1.418130
[ Info: iteration 46, average log likelihood -1.418120
[ Info: iteration 47, average log likelihood -1.418112
[ Info: iteration 48, average log likelihood -1.418103
[ Info: iteration 49, average log likelihood -1.418095
[ Info: iteration 50, average log likelihood -1.418088
┌ Info: EM with 100000 data points 50 iterations avll -1.418088
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4195492887217154
│     -1.4194793410831619
│      ⋮
└     -1.4180875273695588
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418089
[ Info: iteration 2, average log likelihood -1.418030
[ Info: iteration 3, average log likelihood -1.417977
[ Info: iteration 4, average log likelihood -1.417918
[ Info: iteration 5, average log likelihood -1.417847
[ Info: iteration 6, average log likelihood -1.417764
[ Info: iteration 7, average log likelihood -1.417670
[ Info: iteration 8, average log likelihood -1.417571
[ Info: iteration 9, average log likelihood -1.417472
[ Info: iteration 10, average log likelihood -1.417379
[ Info: iteration 11, average log likelihood -1.417293
[ Info: iteration 12, average log likelihood -1.417216
[ Info: iteration 13, average log likelihood -1.417147
[ Info: iteration 14, average log likelihood -1.417085
[ Info: iteration 15, average log likelihood -1.417029
[ Info: iteration 16, average log likelihood -1.416980
[ Info: iteration 17, average log likelihood -1.416935
[ Info: iteration 18, average log likelihood -1.416894
[ Info: iteration 19, average log likelihood -1.416857
[ Info: iteration 20, average log likelihood -1.416824
[ Info: iteration 21, average log likelihood -1.416793
[ Info: iteration 22, average log likelihood -1.416765
[ Info: iteration 23, average log likelihood -1.416740
[ Info: iteration 24, average log likelihood -1.416716
[ Info: iteration 25, average log likelihood -1.416694
[ Info: iteration 26, average log likelihood -1.416673
[ Info: iteration 27, average log likelihood -1.416653
[ Info: iteration 28, average log likelihood -1.416635
[ Info: iteration 29, average log likelihood -1.416617
[ Info: iteration 30, average log likelihood -1.416600
[ Info: iteration 31, average log likelihood -1.416583
[ Info: iteration 32, average log likelihood -1.416566
[ Info: iteration 33, average log likelihood -1.416550
[ Info: iteration 34, average log likelihood -1.416534
[ Info: iteration 35, average log likelihood -1.416519
[ Info: iteration 36, average log likelihood -1.416503
[ Info: iteration 37, average log likelihood -1.416488
[ Info: iteration 38, average log likelihood -1.416473
[ Info: iteration 39, average log likelihood -1.416457
[ Info: iteration 40, average log likelihood -1.416442
[ Info: iteration 41, average log likelihood -1.416427
[ Info: iteration 42, average log likelihood -1.416412
[ Info: iteration 43, average log likelihood -1.416397
[ Info: iteration 44, average log likelihood -1.416382
[ Info: iteration 45, average log likelihood -1.416366
[ Info: iteration 46, average log likelihood -1.416351
[ Info: iteration 47, average log likelihood -1.416336
[ Info: iteration 48, average log likelihood -1.416321
[ Info: iteration 49, average log likelihood -1.416305
[ Info: iteration 50, average log likelihood -1.416290
┌ Info: EM with 100000 data points 50 iterations avll -1.416290
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4180886915455138
│     -1.4180304736441034
│      ⋮
└     -1.4162901077920542
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416284
[ Info: iteration 2, average log likelihood -1.416211
[ Info: iteration 3, average log likelihood -1.416141
[ Info: iteration 4, average log likelihood -1.416058
[ Info: iteration 5, average log likelihood -1.415957
[ Info: iteration 6, average log likelihood -1.415832
[ Info: iteration 7, average log likelihood -1.415681
[ Info: iteration 8, average log likelihood -1.415507
[ Info: iteration 9, average log likelihood -1.415319
[ Info: iteration 10, average log likelihood -1.415125
[ Info: iteration 11, average log likelihood -1.414936
[ Info: iteration 12, average log likelihood -1.414760
[ Info: iteration 13, average log likelihood -1.414602
[ Info: iteration 14, average log likelihood -1.414463
[ Info: iteration 15, average log likelihood -1.414342
[ Info: iteration 16, average log likelihood -1.414237
[ Info: iteration 17, average log likelihood -1.414147
[ Info: iteration 18, average log likelihood -1.414068
[ Info: iteration 19, average log likelihood -1.413998
[ Info: iteration 20, average log likelihood -1.413936
[ Info: iteration 21, average log likelihood -1.413880
[ Info: iteration 22, average log likelihood -1.413829
[ Info: iteration 23, average log likelihood -1.413782
[ Info: iteration 24, average log likelihood -1.413739
[ Info: iteration 25, average log likelihood -1.413700
[ Info: iteration 26, average log likelihood -1.413663
[ Info: iteration 27, average log likelihood -1.413629
[ Info: iteration 28, average log likelihood -1.413597
[ Info: iteration 29, average log likelihood -1.413567
[ Info: iteration 30, average log likelihood -1.413538
[ Info: iteration 31, average log likelihood -1.413512
[ Info: iteration 32, average log likelihood -1.413486
[ Info: iteration 33, average log likelihood -1.413462
[ Info: iteration 34, average log likelihood -1.413440
[ Info: iteration 35, average log likelihood -1.413418
[ Info: iteration 36, average log likelihood -1.413397
[ Info: iteration 37, average log likelihood -1.413378
[ Info: iteration 38, average log likelihood -1.413359
[ Info: iteration 39, average log likelihood -1.413341
[ Info: iteration 40, average log likelihood -1.413324
[ Info: iteration 41, average log likelihood -1.413308
[ Info: iteration 42, average log likelihood -1.413292
[ Info: iteration 43, average log likelihood -1.413277
[ Info: iteration 44, average log likelihood -1.413263
[ Info: iteration 45, average log likelihood -1.413250
[ Info: iteration 46, average log likelihood -1.413237
[ Info: iteration 47, average log likelihood -1.413224
[ Info: iteration 48, average log likelihood -1.413212
[ Info: iteration 49, average log likelihood -1.413201
[ Info: iteration 50, average log likelihood -1.413190
┌ Info: EM with 100000 data points 50 iterations avll -1.413190
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4162843920282433
│     -1.4162113605560087
│      ⋮
└     -1.4131896193688445
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4263730517028763
│     -1.4263932586965435
│     -1.4263209626278948
│     -1.4262665546958668
│      ⋮
│     -1.4132121983073376
│     -1.413200688398567
└     -1.4131896193688445
32×26 Array{Float64,2}:
  0.0514137  -0.0501356    0.352091    -0.313817    0.41024     0.254902    -0.71226      -0.324684    -0.0404055    0.393358     -0.159069    -0.628636      0.0383269   -0.268371   -0.085986    0.0272244    0.308528   -0.431332     -0.365338     0.358009    -0.0511327   -0.447626   -0.146878   -0.00247431  -0.179099     0.320875
 -0.0333873  -0.265884     0.185154     0.0963811  -0.135369   -0.130192     0.25816       0.425249    -0.473385     0.385983      0.00912117  -0.652016      0.417048     0.137745    0.215725   -0.0534846   -0.260055   -0.511565     -0.15366      0.374614     0.352644    -0.398406   -0.587694    0.362977     0.122194     0.117038
 -0.0381409  -0.625614    -0.0118422    0.142235   -0.14367    -0.289779     0.0302892    -0.254499     0.121089     0.36843      -0.526853    -0.330062      0.0798003    0.0305484   0.50845    -0.00617894   0.474402   -0.551566     -0.475855     0.214065    -0.299457     0.0112757  -0.0197407  -0.468216    -0.410456    -0.212981
 -0.814581    0.149818    -0.531358     0.188257   -0.429943   -0.00184696  -0.0501652     0.0267201   -0.489494     0.210241      0.256589     0.00977891   -0.0988279   -0.669169   -0.126098    0.130289     0.272471    0.442178     -0.637885     0.390159    -0.399197    -0.190027   -0.0434682  -0.617162    -0.381236     0.0776167
 -0.0692875   0.231722    -0.159398     0.837747   -0.0659706  -0.460014    -0.0883721     0.193733    -0.0580777   -0.068858     -0.0794995   -0.332393     -0.0588125   -0.543565   -0.105904   -0.319112    -0.0389944  -0.160363     -0.421899    -0.104658    -0.384563    -0.473609    0.340256    0.688427     0.298788     0.462793
  0.159737    0.0561428   -0.156491     0.92212    -0.288878   -0.423171     0.354213     -0.177625     0.313206    -0.0089618     0.41397      0.358567     -0.0664724   -0.449865    0.555194    0.260507     0.0149644  -0.0870817     0.132289    -0.00670615  -0.465202     0.356938   -0.218451    0.227462    -0.076756     0.200681
  0.0860229   0.00616982   0.0203603    0.0204567   0.0475012  -0.061801    -0.426882     -0.407303    -0.314032     0.753714      0.164802    -0.0270544    -0.590623    -0.493892   -0.604609   -0.035041    -0.240716   -0.0148344     0.0433426   -0.278791     0.26184      0.57207     0.647966    0.409675    -0.414513    -0.00189904
 -0.177069    0.216387     0.0979166   -0.0333607   0.268101    0.261913    -0.480756     -0.136391     0.388472    -0.195759      0.0629081    0.649576      0.0192288   -0.532024   -0.437066    0.396477     0.342573    0.530563      0.307406     0.138822    -0.160665     0.200622    0.639896    0.427752     0.0408577    0.165337
  0.0544869   0.0309932   -0.150488     0.10749    -0.532936    0.0220579    0.174858     -0.236228     0.1623       0.0875826     0.0258874   -0.0213879     0.0323739    0.0249991  -0.143558   -0.044261     0.32765     0.122029      0.0690045    0.142956    -0.362102    -0.0958439  -0.0616597  -0.139523    -0.0023549    0.100527
  0.186623    0.289745     0.155054     0.0748108   0.143138   -0.05115     -0.0817702    -0.0313111    0.3016      -0.0533428     0.020169     0.0341711    -0.110474    -0.132349    0.306647    0.0424068   -0.263037   -0.100367      0.0806735   -0.0702525   -0.0964935   -0.161685   -0.176655    0.0141545    0.141675     0.18908
 -0.171795   -0.193403     0.0753763   -0.293496    0.188004    0.0884183   -0.172371      0.175785    -0.391674     0.000174504  -0.206114     0.0775617    -0.00542462  -0.109042   -0.0667579  -0.0587289   -0.26312     0.0484509    -0.00431406   0.0271862    0.343911    -0.291264    0.0220605  -0.00586221   0.0722141   -0.0492455
  0.0125719  -0.165953    -0.0437443    0.0864346   0.114003   -0.095113     0.0303679     0.074029    -0.146472    -0.113334      0.0451825   -0.0415011    -0.0732209    0.218671   -0.0258594  -0.0678294    0.032674   -0.0590331    -0.0244207   -0.189926     0.0633149    0.436287    0.180524    0.313246    -0.160093    -0.229468
 -0.0449779  -0.207686     0.171688     0.107858   -0.649351   -0.802579     0.225716     -0.135945     0.685225    -0.403861     -0.0528355    0.650601      0.0576356    0.680321    0.216682   -0.0241124   -0.240844    0.122308     -0.05479      0.0221004   -0.124398     0.372332    0.437753   -0.538075     0.75892     -0.738106
  0.0432047   0.419192     0.183408    -0.273339   -0.0637482   0.0306372   -0.000285561   0.107271     0.62338     -0.247089     -0.191971    -0.0952501    -0.191123     0.607004    0.539235   -0.478854     0.0654838   0.187405      0.0995918   -0.343343     0.508124     0.11419     0.32106     0.29554      0.13183     -0.405411
 -0.2191     -0.541839    -0.394133     0.19697     0.550897    0.0625268    0.40584       0.452363     0.201218    -0.640324      0.473       -0.167033      0.685281     0.430719    0.347633    0.0754712    0.469888   -0.0835351     0.595258     0.185052    -0.0437261   -0.183506    0.0425155   0.148913     0.602449     0.0126129
  0.486749    0.754983     0.656511     0.0508685   0.0347449   0.257856     0.348094     -0.121568     0.62804      0.155736      0.181398    -0.481769     -0.0788123    0.0567254  -0.295511    0.284003    -0.0887043   0.171056      0.611623     0.196946    -0.391998     0.112032   -0.221584    0.0577529    0.474001     0.134926
 -0.784882   -0.216817    -1.26326     -0.039216   -0.482374   -0.919274     0.235752      0.10411     -0.415285    -0.477955     -0.293156     0.544632     -0.340633     0.271236    0.232346   -0.358614    -0.136055   -0.0694224    -0.397321    -0.423076     0.307573     0.0379209  -0.137073   -0.182303    -0.0101751   -0.638653
 -0.242476    0.397535    -0.333377    -0.686811   -0.0512876  -0.321099    -0.0392621     0.333844     0.322314    -0.0732539     0.224825     0.251051      0.364033    -0.0742994  -0.215845   -0.0697957   -0.179203    0.0484456     0.331698    -0.282856    -1.05357e-5  -0.487804   -0.654853   -0.672658     0.373273     0.312063
  0.64695     0.24227     -0.592414     0.42641    -0.36721     0.0455953    0.32167       0.0910455    0.2449      -0.450204     -0.344698    -0.223502     -0.58862      0.204441    0.207696   -0.419723     0.385315    0.0245303     0.292664    -0.204835    -0.177509    -0.932579   -0.346752   -0.434023    -0.151778     0.354201
  0.322647    0.0804015    0.238521     0.148246   -0.487351    0.246911     0.328842      0.443526     0.171894    -0.417005     -0.285121     0.281921      0.517208     0.280846    0.287932   -0.625032     0.252169   -0.000115624  -0.26731      0.929972    -0.703587    -0.518476   -0.737445   -0.544597     0.266879     0.535424
  0.0314797   0.26595      0.0534658    0.6782     -0.605201   -0.0655115    0.789867     -0.157635    -0.188684    -0.00156277    0.634073     0.34634      -0.0289196    0.224001    0.139814   -0.604105    -0.549925    0.0801297     0.257715    -0.30998      0.157151     0.272591   -0.022882    0.316727     0.330298     0.277894
 -0.117072    0.0355891    0.0721812    0.50876    -0.429254    0.213552     0.151994     -0.273469     0.0113133    0.488914      0.249853    -0.210262     -0.0217498   -0.694138   -0.336598    0.313194     0.421327   -0.0635324    -0.18331      0.496638    -0.374771    -0.268523    0.0666428   0.221973    -0.195853     0.249381
  0.138273   -0.0134092   -0.0172896    0.442326    0.627155   -0.162941     0.101631      0.00101209   0.402005    -0.104136     -0.226565     0.0260285     0.0276036   -0.166347    1.11035     0.325125    -0.406993   -0.440863     -0.309288    -0.650928     0.148113    -0.317468    0.191204    0.65286     -0.377625    -0.071821
  0.254435    0.467223     0.101639     0.4885     -0.262479    0.22272      0.0760535     0.0918399    0.345618     0.087335     -0.0137105   -0.000612152  -0.514352     0.12998     1.01574    -0.166364    -0.158055    0.377612     -0.738698     0.952904     0.145049     0.324783    0.360275    0.108882    -0.342332    -0.0360809
 -0.231535   -0.183726     0.0365825   -0.719913    0.47302     0.0122085   -0.509002      0.194396     0.00597975   0.00994162   -0.268167    -0.19065      -0.00571131   0.253769   -0.172262    0.0141061    0.226217   -0.092704      0.0522609   -0.159605     0.188256     0.126795    0.0956785  -0.142222    -0.0288188   -0.233122
 -0.588489   -0.294043     0.65509     -0.437321    0.264036   -0.238092    -0.152499      0.0575015   -0.145583     0.310885      0.0561332    0.216005      0.65503     -0.0277655   0.110586    0.0718655   -0.320519   -0.00383667   -0.35365      0.139873     0.0507531    0.868051    0.110417    0.33389      0.292822    -0.170215
 -0.345861   -0.277432     0.00751978  -0.287204    0.0697891   0.416919     0.611223     -0.696453     0.243246    -0.0462715     0.352452     0.152134     -0.29371      0.345394   -0.294591    0.0462541    0.137066    0.0615773     0.721267    -0.535722     0.318826     0.368313   -0.0454218  -0.626192    -0.528187    -0.386124
 -0.0600744  -0.234804    -0.318846    -0.204474   -0.156179    0.305709     0.395875      0.324869    -0.456187    -0.0778457     0.0617663   -0.199807     -0.215063     0.158817   -0.733658   -0.0974467    0.600477    0.069196      0.564044    -0.114845     0.149721    -0.129597   -0.109285    0.0475257   -0.0129092   -0.0323241
  0.671843   -0.291206    -0.0874789   -0.300632    0.572674    0.19936     -0.335193      0.14277     -0.774635    -0.0506044    -0.0255961   -0.283473     -0.101705     0.226982    0.437868   -0.23913     -0.935749    0.266309      0.220277    -0.607436     0.805322     0.140038    0.0197404  -0.540648    -0.0422401    0.329068
  1.02175    -0.221174     0.451231    -0.170807    0.232282    0.316879    -0.189439      0.09116      0.0917046   -0.225444     -0.514881     0.427378      0.38082      0.831141   -0.360352   -0.192142    -0.559938   -0.210268      0.624805    -0.490271     0.102237     0.275915   -0.280246    0.827083    -0.00931132   0.188576
 -0.240027    0.159543     0.620575    -0.94262     0.198465    0.628947    -0.308868      0.173317    -0.860131    -0.41243      -0.0963755   -0.0804081    -0.275904     0.485265   -0.675576   -0.196227    -0.285718    0.424611     -0.0684547    0.187998     0.402724    -0.379001    0.0134117   0.319722     0.229932    -0.194322
  0.826016   -0.0207659   -0.0122288   -0.233485    0.213571    0.363173    -0.642052      0.0468148   -0.0391584   -0.7262       -0.394134     0.395834     -0.527629    -0.173389   -0.215316    0.455949    -0.110166    0.0424655    -0.0107337    0.269468    -0.445697    -0.314266    0.0516168  -0.272519    -0.0142531   -0.158217[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413179
[ Info: iteration 2, average log likelihood -1.413169
[ Info: iteration 3, average log likelihood -1.413159
[ Info: iteration 4, average log likelihood -1.413149
[ Info: iteration 5, average log likelihood -1.413140
[ Info: iteration 6, average log likelihood -1.413131
[ Info: iteration 7, average log likelihood -1.413122
[ Info: iteration 8, average log likelihood -1.413114
[ Info: iteration 9, average log likelihood -1.413106
[ Info: iteration 10, average log likelihood -1.413098
┌ Info: EM with 100000 data points 10 iterations avll -1.413098
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.005003e+06
      1       7.075154e+05      -2.974875e+05 |       32
      2       6.948596e+05      -1.265584e+04 |       32
      3       6.901561e+05      -4.703420e+03 |       32
      4       6.876641e+05      -2.492070e+03 |       32
      5       6.860529e+05      -1.611145e+03 |       32
      6       6.849647e+05      -1.088250e+03 |       32
      7       6.842121e+05      -7.525845e+02 |       32
      8       6.836361e+05      -5.759508e+02 |       32
      9       6.831376e+05      -4.985248e+02 |       32
     10       6.826943e+05      -4.432713e+02 |       32
     11       6.822840e+05      -4.103048e+02 |       32
     12       6.819186e+05      -3.654120e+02 |       32
     13       6.816007e+05      -3.179282e+02 |       32
     14       6.813268e+05      -2.739103e+02 |       32
     15       6.810708e+05      -2.559616e+02 |       32
     16       6.808442e+05      -2.266131e+02 |       32
     17       6.806368e+05      -2.073920e+02 |       32
     18       6.804609e+05      -1.759622e+02 |       32
     19       6.803113e+05      -1.495173e+02 |       32
     20       6.801751e+05      -1.362876e+02 |       32
     21       6.800407e+05      -1.343390e+02 |       32
     22       6.799107e+05      -1.299902e+02 |       32
     23       6.797811e+05      -1.295982e+02 |       32
     24       6.796633e+05      -1.178659e+02 |       32
     25       6.795578e+05      -1.054700e+02 |       32
     26       6.794620e+05      -9.577781e+01 |       32
     27       6.793700e+05      -9.199307e+01 |       32
     28       6.792884e+05      -8.164156e+01 |       32
     29       6.792129e+05      -7.546479e+01 |       32
     30       6.791388e+05      -7.407358e+01 |       32
     31       6.790768e+05      -6.208572e+01 |       32
     32       6.790257e+05      -5.105672e+01 |       32
     33       6.789753e+05      -5.042364e+01 |       32
     34       6.789298e+05      -4.549643e+01 |       32
     35       6.788822e+05      -4.757794e+01 |       32
     36       6.788343e+05      -4.786507e+01 |       32
     37       6.787905e+05      -4.378759e+01 |       32
     38       6.787530e+05      -3.753681e+01 |       32
     39       6.787149e+05      -3.813746e+01 |       32
     40       6.786798e+05      -3.504110e+01 |       32
     41       6.786505e+05      -2.927935e+01 |       32
     42       6.786210e+05      -2.955880e+01 |       32
     43       6.785941e+05      -2.686027e+01 |       32
     44       6.785666e+05      -2.750853e+01 |       32
     45       6.785384e+05      -2.820615e+01 |       32
     46       6.785108e+05      -2.765062e+01 |       32
     47       6.784797e+05      -3.102138e+01 |       32
     48       6.784480e+05      -3.172388e+01 |       32
     49       6.784197e+05      -2.833741e+01 |       32
     50       6.783952e+05      -2.451282e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 678395.1693493703)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425407
[ Info: iteration 2, average log likelihood -1.420348
[ Info: iteration 3, average log likelihood -1.418896
[ Info: iteration 4, average log likelihood -1.417751
[ Info: iteration 5, average log likelihood -1.416580
[ Info: iteration 6, average log likelihood -1.415603
[ Info: iteration 7, average log likelihood -1.415004
[ Info: iteration 8, average log likelihood -1.414694
[ Info: iteration 9, average log likelihood -1.414523
[ Info: iteration 10, average log likelihood -1.414411
[ Info: iteration 11, average log likelihood -1.414328
[ Info: iteration 12, average log likelihood -1.414259
[ Info: iteration 13, average log likelihood -1.414200
[ Info: iteration 14, average log likelihood -1.414148
[ Info: iteration 15, average log likelihood -1.414101
[ Info: iteration 16, average log likelihood -1.414057
[ Info: iteration 17, average log likelihood -1.414016
[ Info: iteration 18, average log likelihood -1.413978
[ Info: iteration 19, average log likelihood -1.413942
[ Info: iteration 20, average log likelihood -1.413908
[ Info: iteration 21, average log likelihood -1.413876
[ Info: iteration 22, average log likelihood -1.413844
[ Info: iteration 23, average log likelihood -1.413815
[ Info: iteration 24, average log likelihood -1.413786
[ Info: iteration 25, average log likelihood -1.413759
[ Info: iteration 26, average log likelihood -1.413733
[ Info: iteration 27, average log likelihood -1.413708
[ Info: iteration 28, average log likelihood -1.413684
[ Info: iteration 29, average log likelihood -1.413660
[ Info: iteration 30, average log likelihood -1.413638
[ Info: iteration 31, average log likelihood -1.413616
[ Info: iteration 32, average log likelihood -1.413596
[ Info: iteration 33, average log likelihood -1.413576
[ Info: iteration 34, average log likelihood -1.413557
[ Info: iteration 35, average log likelihood -1.413539
[ Info: iteration 36, average log likelihood -1.413521
[ Info: iteration 37, average log likelihood -1.413504
[ Info: iteration 38, average log likelihood -1.413487
[ Info: iteration 39, average log likelihood -1.413471
[ Info: iteration 40, average log likelihood -1.413456
[ Info: iteration 41, average log likelihood -1.413441
[ Info: iteration 42, average log likelihood -1.413426
[ Info: iteration 43, average log likelihood -1.413412
[ Info: iteration 44, average log likelihood -1.413398
[ Info: iteration 45, average log likelihood -1.413384
[ Info: iteration 46, average log likelihood -1.413371
[ Info: iteration 47, average log likelihood -1.413358
[ Info: iteration 48, average log likelihood -1.413345
[ Info: iteration 49, average log likelihood -1.413332
[ Info: iteration 50, average log likelihood -1.413320
┌ Info: EM with 100000 data points 50 iterations avll -1.413320
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0414963  -0.189268   -0.311181     0.188321    -0.235086    0.12919      0.221344   -0.174619   -0.150917    -0.118565   -0.086581    -0.00157745  -0.198039     0.123576    -0.126648   -0.0884805    0.390207    0.12826     0.0312604  -0.182736   -0.0783172    0.176494    0.301117     0.155106    -0.362129    -0.170902
  0.183837    0.694948    0.00991239   0.213356    -0.143779    0.0440999   -0.0088792   0.103521    0.956777    -0.187789   -0.175276    -0.0329657   -0.517414     0.730278     0.753715   -0.406273     0.171423    0.193995   -0.253969    0.0484232   0.299993     0.205839    0.304057     0.145176    -0.159291    -0.309853
  0.024795   -0.547455   -0.14129      0.184656     0.66122     0.284602     0.377887    0.39692    -0.0396175   -0.365782   -0.118651    -0.565082     0.300986     0.556009     0.124191    0.0412087    0.235261   -0.735277    0.43151    -0.254939    0.0562565   -0.0400988   0.226834     0.597713     0.408292    -0.186767
 -0.106534    0.0894699  -0.106574    -0.136419     0.291466   -0.28752     -0.953954   -0.295323   -0.121488     0.165382    0.373132     0.194413    -0.0931712    0.0596114   -0.19896     0.109998    -0.57        0.0744527  -0.307697   -0.369067    0.324271     0.934951    1.27943      0.641681    -0.255542     0.0833003
  0.763718    0.111056   -0.0958591    0.46575     -0.0552243   0.150736    -0.101103   -0.0692926  -0.0341986   -0.153457   -0.100323     0.344207    -0.777901    -0.523879     0.895853    0.0961757   -0.706448   -0.0551774  -0.0944754   0.275119    0.00870977  -0.363484    0.134962     0.0282819   -0.314926     0.133461
  0.513688   -0.0761658  -0.195618     0.521845    -0.78347     0.353912     0.54325     0.233322   -0.0991273   -0.0154044   0.0744666   -0.226863    -0.423111    -0.341697    -0.432562   -0.320993     0.322353   -0.169842    0.197653    0.227954   -0.01691     -1.12408    -0.298425     0.111364     0.0507696    0.295532
  0.645333    0.346831    0.311601    -0.191925    -0.479258    0.153387    -0.040904   -0.652375    0.13107      0.63391     0.206908     0.00935333  -0.560889    -0.0833848   -0.804655   -0.0850704   -0.107562    0.311722    0.563419    0.0586876  -0.217036     0.522377    0.100591    -0.181286     0.106227     0.124099
  0.437526    0.358697    0.324652     0.12582     -0.376143    0.413478     0.300671    0.135671    0.378592    -0.300749   -0.235752     0.0394452    0.340472     0.350045     0.336509   -0.254295     0.143214    0.0133933  -0.0822679   0.671838   -0.649818    -0.472517   -0.666464    -0.573699     0.229322     0.482077
 -0.178287    0.119809   -0.297405     0.179986    -0.153483   -0.0204389   -0.490134   -0.247241   -0.184969     0.125725   -0.0344627   -0.351781     0.0398489   -0.697114    -0.149537   -0.0516685    0.494467   -0.289895   -0.712857    0.35057    -0.677214    -0.591229   -0.183291    -0.160404    -0.1761       0.560007
 -0.211781   -0.331298    0.307687    -0.0348811   -0.557786   -0.502155     0.177323   -0.120617    0.480359    -0.161131   -0.211707     0.409213     0.422659     0.224197     0.109116   -0.400075     0.0539754   0.160431   -0.168719   -0.016818   -0.0675115    0.524173    0.458082    -0.00420396   0.529655    -0.242118
  0.102401    0.475067    0.0285037    0.976202    -0.0724549  -0.610441     0.175263    0.316922    0.00692364  -0.0844318   0.0357963   -0.329064    -0.0975635   -0.371516     0.045476   -0.348901    -0.316511   -0.107147   -0.311245   -0.0727205  -0.418495    -0.281472    0.249093     0.819527     0.342402     0.441719
 -0.300237   -0.39742    -0.0328967   -0.338703     0.0593088   0.258187     0.498105   -0.365172    0.202777    -0.215938    0.416482     0.182269    -0.257655     0.494341    -0.307186    0.055112     0.0510988  -0.18361     0.895214   -0.654913    0.426463     0.238904   -0.169365    -0.606531    -0.462204    -0.470423
 -0.124518    0.378201    0.334975     0.0163924    0.160656    0.290724    -0.142364   -0.0297912   0.642936    -0.354724    0.330377     0.464034     0.178166    -0.358766    -0.340064    0.706895     0.491897    0.39518     0.52837     0.186647   -0.43481      0.328722    0.231407     0.40984     -0.0523275    0.0427673
 -0.752166    0.0177465  -0.573689     0.268357    -0.644912   -0.147835     0.0945275   0.15949    -0.590682     0.0780862   0.368169     0.157889    -0.159015    -0.495558    -0.226473    0.173527     0.283694    0.554276   -0.441673    0.43885    -0.421546     0.0395192  -0.0890087   -0.623555    -0.272448    -0.0861366
 -0.0894906   0.0776929   0.768529    -0.332251     0.319822    0.156682    -0.341854    0.114045    0.121825     0.383143   -0.121624    -0.848948     0.167074     0.42235      0.0985117   0.0132591    0.139254   -0.574299   -0.235139    0.23441     0.276088     0.060947   -0.161795     0.520052    -0.179336    -0.198757
 -0.0383876  -0.112757   -0.122415    -0.717863     0.306738    0.0967677   -0.480675    0.060967   -0.0276778   -0.102382   -0.279451    -0.0427464   -0.0418694    0.142256    -0.254662    0.0349989    0.205528    0.0956381   0.0756033  -0.0859946  -0.0203772   -0.142054   -0.0121548   -0.59247      0.0455355   -0.0460811
 -0.170168   -0.640484    0.325556    -0.280468     0.2733     -0.0133279   -0.417557   -0.105933   -0.344925     0.112516   -0.365791    -0.297109     0.00575938   0.137793     0.107932   -0.109212     0.137997   -0.384453   -0.337684    0.274358    0.0265416   -0.177703    0.0491032   -0.0477222   -0.136119    -0.0983999
  0.947099   -0.283967    0.414573    -0.298105     0.216229    0.377274    -0.227175    0.179304   -0.133565    -0.416791   -0.562138     0.675985     0.31705      0.907314    -0.450224   -0.151649    -0.754324   -0.0259826   0.597938   -0.398666    0.169209     0.269915   -0.355812     0.494945     0.0424342    0.0543491
  0.526007    0.263795    0.252898    -0.0409346    0.489172    0.224903    -0.284219   -0.0496422   0.313784     0.0174868  -0.0488077   -0.144617    -0.0842158   -0.00164003   0.199703    0.0681287   -0.214985   -0.130991    0.286536   -0.324092    0.0834727   -0.138209   -0.10729      0.193977    -0.0226762    0.397762
 -0.3811     -0.330274    0.363859     0.524494     0.232261    0.644436     0.365606   -0.483758   -0.512838     1.04223     0.211275    -0.0257437   -0.0305868   -0.686048    -0.376551   -0.038135     0.100272    0.0233902  -0.194478    0.189585    0.0264518    0.471452    0.315762     0.587911    -0.529048     0.424889
  0.021738    0.0523493   0.00586843   0.074968    -0.124502   -0.132013     0.0609962   0.0939585   0.040437    -0.0730129   0.0460103    0.0375333    0.0110149   -0.0190767    0.027805    0.00133822  -0.0664823  -0.0498646   0.0793683   0.0263427  -0.12558     -0.0706831  -0.17679      0.012401     0.150427     0.0416128
 -0.286524   -0.796632   -0.534031     0.541572     0.282841   -0.461245     0.338085    0.3325      0.245115    -0.205197    0.0786428    0.176516     0.570796     0.0147792    1.12616     0.0705512    0.306006   -0.24859    -0.440689   -0.018622   -0.109316    -0.321034   -0.340732    -0.0570472   -0.231733     0.241892
  0.0559602  -0.288309    0.0832188    0.586575    -0.441876   -0.457657     0.0721315  -0.404343    0.569882     0.70555     0.00315281  -0.360585     0.00165101  -0.434295     0.317859    0.426372     0.396308   -0.771475   -0.0687526   0.0813672  -0.401643     0.0406515  -0.0520347   -0.0248171   -0.26271     -0.147888
  0.0198579   0.304088    0.0470451    0.685629    -0.33101    -0.313444     0.625579   -0.156881    0.147835    -0.139927    0.549294     0.412439     0.016274     0.0154972    0.613147   -0.0711015   -0.484812    0.114296    0.152748   -0.205343   -0.0664534    0.519556   -0.0330736    0.379155     0.184383     0.0245903
 -0.118724    0.0416673   0.177953    -0.632086    -0.054782    0.487947    -0.0669557   0.296638   -0.726909    -0.0626671  -0.0645968   -0.252507    -0.0742869    0.451401    -0.517974   -0.278497    -0.0534131   0.285579    0.196484    0.143801    0.571566    -0.268205   -0.19587      0.0592906   -0.00585368   0.000841052
 -0.427394    0.518125   -0.0423524   -0.270234    -0.13272     0.0981611   -0.160844   -0.34689     0.200592     0.610628   -0.00315769   0.143747     0.0827129   -0.520767     0.0860607  -0.0616183   -0.136863    0.328278   -0.302048    0.112358    0.165706    -0.159482    0.00481746  -0.193016    -0.0938302    0.209468
 -0.0211327  -0.345871    0.350026    -0.258761     0.284846   -0.197739     0.164347    0.203589   -0.874339     0.356226    0.0561072   -0.333426     0.413726     0.0870301    0.400668   -0.113638    -0.930569   -0.203453   -0.320875   -0.131615    0.434149     0.113962   -0.141505    -0.16247      0.223108     0.372593
 -0.308827    0.126266   -0.984239    -0.0856767   -0.412436   -0.744226     0.269452    0.222867   -0.211214    -0.55073    -0.379224     0.374947    -0.192787     0.482766     0.273601   -0.443176    -0.25295    -0.0988331  -0.190497   -0.455849    0.160164    -0.277135   -0.486985    -0.391645     0.0829993   -0.444875
 -0.276684    0.199389    0.388045    -0.336317     0.381119   -0.139084     0.0598315   0.202781    0.30074     -0.224648    0.0880654    0.0376816    0.027618     0.402796     0.346374    0.230878    -0.248361    0.163292   -0.0626793   0.144339    0.316641     0.273318   -0.114291     0.0071478    0.500773    -0.808194
  0.195395   -0.153831    0.25537     -0.336944     0.565238    0.171958    -0.536673    0.245626   -0.299074    -0.330647   -0.633589     0.207202     0.00611694  -0.82071     -0.316957    0.523485     0.143311    0.398152   -0.419576    0.621373    0.049392    -0.472607    0.272198     0.510483     0.419355     0.0214998
 -0.22318    -0.10224    -0.288414    -0.21628      0.497416   -0.200168    -0.373739    0.225274   -0.498243     0.129538    0.0812845    0.0315618   -0.429202    -0.721668    -0.625665    0.0403908   -0.218865   -0.0307652   0.30952    -0.625877    0.327029    -0.0377686   0.277646     0.249212    -0.13155     -0.243233
 -0.0562487   0.139805   -0.52871     -0.00482304  -0.0493873  -0.00038985   0.430008    0.249196    0.34763     -0.327424    0.510372    -0.0786552    0.272455     0.166191    -0.153656   -0.265202     0.418392    0.344928    0.84859     0.0686779  -0.174502    -0.304905   -0.164754    -0.194684     0.617849     0.454263[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413307
[ Info: iteration 2, average log likelihood -1.413295
[ Info: iteration 3, average log likelihood -1.413283
[ Info: iteration 4, average log likelihood -1.413272
[ Info: iteration 5, average log likelihood -1.413260
[ Info: iteration 6, average log likelihood -1.413248
[ Info: iteration 7, average log likelihood -1.413237
[ Info: iteration 8, average log likelihood -1.413226
[ Info: iteration 9, average log likelihood -1.413214
[ Info: iteration 10, average log likelihood -1.413203
┌ Info: EM with 100000 data points 10 iterations avll -1.413203
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
