Julia Version 1.4.0-DEV.666
Commit 2835347ff0 (2019-12-26 15:28 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed DataAPI ──────────── v1.1.0
 Installed URIParser ────────── v0.4.0
 Installed GaussianMixtures ─── v0.3.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed PDMats ───────────── v0.9.10
 Installed Missings ─────────── v0.4.3
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed OrderedCollections ─ v1.1.0
 Installed DataStructures ───── v0.17.6
 Installed Parameters ───────── v0.12.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed Rmath ────────────── v0.6.0
 Installed CMake ────────────── v1.1.2
 Installed BinaryProvider ───── v0.5.8
 Installed StatsFuns ────────── v0.9.3
 Installed Clustering ───────── v0.13.3
 Installed BinDeps ──────────── v1.0.0
 Installed OpenBLAS_jll ─────── v0.3.7+1
 Installed HDF5 ─────────────── v0.12.5
 Installed Distances ────────── v0.8.2
 Installed SpecialFunctions ─── v0.9.0
 Installed JLD ──────────────── v0.9.1
 Installed Distributions ────── v0.21.11
 Installed StaticArrays ─────── v0.12.1
 Installed Arpack_jll ───────── v3.5.0+2
 Installed Blosc ────────────── v0.5.1
 Installed StatsBase ────────── v0.32.0
 Installed LegacyStrings ────── v0.4.1
 Installed FileIO ───────────── v1.2.0
 Installed NearestNeighbors ─── v0.4.4
 Installed FillArrays ───────── v0.8.2
 Installed QuadGK ───────────── v2.3.1
 Installed SortingAlgorithms ── v0.3.1
 Installed Compat ───────────── v2.2.0
 Installed Arpack ───────────── v0.4.0
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_dFNNEp/Project.toml`
 [no changes]
  Updating `/tmp/jl_dFNNEp/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_srGMy0/Project.toml`
 [no changes]
  Updating `/tmp/jl_srGMy0/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_3Xpfu6/Project.toml`
 [no changes]
  Updating `/tmp/jl_3Xpfu6/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_CP5mzQ/Project.toml`
 [no changes]
  Updating `/tmp/jl_CP5mzQ/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_XNM6B0/Project.toml`
 [no changes]
  Updating `/tmp/jl_XNM6B0/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_XNM6B0/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.0
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -768928.8653183782, [78664.62050609599, 21335.37949390401], [1439.6921336372336 -9931.477672839179 15368.86219090258; -2099.2590590817435 9965.747505202053 -15658.322401363743], [[52930.952693078696 -7686.9538711498635 4985.259257641577; -7686.953871149863 74500.46800141256 9171.266925503183; 4985.259257641577 9171.266925503185 72129.04628697518], [47993.593814445034 7427.784660303112 -5161.499177025757; 7427.784660303112 25418.66036545109 -9203.309077103639; -5161.499177025757 -9203.30907710364 27501.900491373228]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.635033e+03
      1       1.004051e+03      -6.309822e+02 |        4
      2       9.385619e+02      -6.548880e+01 |        0
      3       9.385619e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 938.5619414951279)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.069418
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.714763
[ Info: iteration 2, lowerbound -3.522384
[ Info: iteration 3, lowerbound -3.329403
[ Info: iteration 4, lowerbound -3.139808
[ Info: iteration 5, lowerbound -2.976642
[ Info: dropping number of Gaussions to 7
[ Info: iteration 6, lowerbound -2.858263
[ Info: iteration 7, lowerbound -2.790588
[ Info: dropping number of Gaussions to 4
[ Info: iteration 8, lowerbound -2.744207
[ Info: dropping number of Gaussions to 3
[ Info: iteration 9, lowerbound -2.704122
[ Info: iteration 10, lowerbound -2.670426
[ Info: iteration 11, lowerbound -2.634732
[ Info: iteration 12, lowerbound -2.594200
[ Info: iteration 13, lowerbound -2.550788
[ Info: iteration 14, lowerbound -2.507053
[ Info: iteration 15, lowerbound -2.465403
[ Info: iteration 16, lowerbound -2.427211
[ Info: iteration 17, lowerbound -2.392502
[ Info: iteration 18, lowerbound -2.360804
[ Info: iteration 19, lowerbound -2.333170
[ Info: iteration 20, lowerbound -2.313775
[ Info: iteration 21, lowerbound -2.307428
[ Info: dropping number of Gaussions to 2
[ Info: iteration 22, lowerbound -2.302931
[ Info: iteration 23, lowerbound -2.299260
[ Info: iteration 24, lowerbound -2.299256
[ Info: iteration 25, lowerbound -2.299254
[ Info: iteration 26, lowerbound -2.299254
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Fri Dec 27 08:57:41 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Fri Dec 27 08:57:49 2019: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Fri Dec 27 08:57:51 2019: EM with 272 data points 0 iterations avll -2.069418
5.8 data points per parameter
, Fri Dec 27 08:57:53 2019: GMM converted to Variational GMM
, Fri Dec 27 08:58:01 2019: iteration 1, lowerbound -3.714763
, Fri Dec 27 08:58:01 2019: iteration 2, lowerbound -3.522384
, Fri Dec 27 08:58:01 2019: iteration 3, lowerbound -3.329403
, Fri Dec 27 08:58:01 2019: iteration 4, lowerbound -3.139808
, Fri Dec 27 08:58:01 2019: iteration 5, lowerbound -2.976642
, Fri Dec 27 08:58:01 2019: dropping number of Gaussions to 7
, Fri Dec 27 08:58:01 2019: iteration 6, lowerbound -2.858263
, Fri Dec 27 08:58:01 2019: iteration 7, lowerbound -2.790588
, Fri Dec 27 08:58:01 2019: dropping number of Gaussions to 4
, Fri Dec 27 08:58:01 2019: iteration 8, lowerbound -2.744207
, Fri Dec 27 08:58:01 2019: dropping number of Gaussions to 3
, Fri Dec 27 08:58:01 2019: iteration 9, lowerbound -2.704122
, Fri Dec 27 08:58:01 2019: iteration 10, lowerbound -2.670426
, Fri Dec 27 08:58:01 2019: iteration 11, lowerbound -2.634732
, Fri Dec 27 08:58:01 2019: iteration 12, lowerbound -2.594200
, Fri Dec 27 08:58:01 2019: iteration 13, lowerbound -2.550788
, Fri Dec 27 08:58:01 2019: iteration 14, lowerbound -2.507053
, Fri Dec 27 08:58:01 2019: iteration 15, lowerbound -2.465403
, Fri Dec 27 08:58:01 2019: iteration 16, lowerbound -2.427211
, Fri Dec 27 08:58:01 2019: iteration 17, lowerbound -2.392502
, Fri Dec 27 08:58:01 2019: iteration 18, lowerbound -2.360804
, Fri Dec 27 08:58:01 2019: iteration 19, lowerbound -2.333170
, Fri Dec 27 08:58:01 2019: iteration 20, lowerbound -2.313775
, Fri Dec 27 08:58:01 2019: iteration 21, lowerbound -2.307428
, Fri Dec 27 08:58:01 2019: dropping number of Gaussions to 2
, Fri Dec 27 08:58:01 2019: iteration 22, lowerbound -2.302931
, Fri Dec 27 08:58:01 2019: iteration 23, lowerbound -2.299260
, Fri Dec 27 08:58:01 2019: iteration 24, lowerbound -2.299256
, Fri Dec 27 08:58:01 2019: iteration 25, lowerbound -2.299254
, Fri Dec 27 08:58:01 2019: iteration 26, lowerbound -2.299254
, Fri Dec 27 08:58:01 2019: iteration 27, lowerbound -2.299253
, Fri Dec 27 08:58:01 2019: iteration 28, lowerbound -2.299253
, Fri Dec 27 08:58:01 2019: iteration 29, lowerbound -2.299253
, Fri Dec 27 08:58:01 2019: iteration 30, lowerbound -2.299253
, Fri Dec 27 08:58:01 2019: iteration 31, lowerbound -2.299253
, Fri Dec 27 08:58:01 2019: iteration 32, lowerbound -2.299253
, Fri Dec 27 08:58:01 2019: iteration 33, lowerbound -2.299253
, Fri Dec 27 08:58:01 2019: iteration 34, lowerbound -2.299253
, Fri Dec 27 08:58:01 2019: iteration 35, lowerbound -2.299253
, Fri Dec 27 08:58:01 2019: iteration 36, lowerbound -2.299253
, Fri Dec 27 08:58:01 2019: iteration 37, lowerbound -2.299253
, Fri Dec 27 08:58:01 2019: iteration 38, lowerbound -2.299253
, Fri Dec 27 08:58:01 2019: iteration 39, lowerbound -2.299253
, Fri Dec 27 08:58:02 2019: iteration 40, lowerbound -2.299253
, Fri Dec 27 08:58:02 2019: iteration 41, lowerbound -2.299253
, Fri Dec 27 08:58:02 2019: iteration 42, lowerbound -2.299253
, Fri Dec 27 08:58:02 2019: iteration 43, lowerbound -2.299253
, Fri Dec 27 08:58:02 2019: iteration 44, lowerbound -2.299253
, Fri Dec 27 08:58:02 2019: iteration 45, lowerbound -2.299253
, Fri Dec 27 08:58:02 2019: iteration 46, lowerbound -2.299253
, Fri Dec 27 08:58:02 2019: iteration 47, lowerbound -2.299253
, Fri Dec 27 08:58:02 2019: iteration 48, lowerbound -2.299253
, Fri Dec 27 08:58:02 2019: iteration 49, lowerbound -2.299253
, Fri Dec 27 08:58:02 2019: iteration 50, lowerbound -2.299253
, Fri Dec 27 08:58:02 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.0450922260165, 95.95490777398349]
β = [178.0450922260165, 95.95490777398349]
m = [4.2503007332698886 79.28686694436153; 2.000229257775348 53.85198717246118]
ν = [180.0450922260165, 97.95490777398349]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484444 -0.007644049042327794; 0.0 0.008581705166333187], [0.37587636119487766 -0.00895312382734649; 0.0 0.012748664777409532]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0199931739137889
avll from llpg:  -1.019993173913788
avll direct:     -1.019993173913788
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9778755416177481
avll from llpg:  -0.9778755416177481
avll direct:     -0.9778755416177483
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.0947406   -0.0608514   -0.0895421    0.00403177   0.0820524    0.116441    -0.0438834   -0.0247287  -0.0551997   0.180851    -0.00869268  -0.00778615  -0.165933    -0.323667    -0.0849339   -0.0643605    0.0561375    0.141829      0.0474368     0.246422    -0.0185292     0.0208212    0.01683      0.140276     0.181087    -0.0571053
 -0.0305659    0.062994     0.0927475    0.135509    -0.00527362  -0.0269561    0.136171    -0.0487371   0.144648   -0.0934322   -0.234083    -0.0182533   -0.0171735    0.0787152    0.0253652    0.0687817    0.14829     -0.0480898     0.14938      -0.00338773   0.0553875    -0.0458904   -0.0558951    0.0476447   -0.259484    -0.00909656
 -0.00782359   0.16151     -0.01134      0.0665199   -0.0433589   -0.0395164    0.118055    -0.0383211  -0.0546497   0.086186    -0.0434613   -0.0729324   -0.0780246    0.235482     0.0523611    0.15699      0.226458    -0.171748      0.203557      0.10106     -0.137754     -0.135993     0.0759988   -0.132016     0.00353271  -0.0258066
  0.0255937   -0.136985     0.0544803   -0.0197424   -0.061317     0.0526374    0.0524987    0.034293   -0.135203    0.00752034  -0.109506    -0.00312657   0.0825423   -0.00145197  -0.0367333   -0.0703458    0.0133491   -0.0624371     0.000665729  -0.0681162    0.122527      0.175613    -0.0556028   -0.204352    -0.101794     0.0744491
 -0.0678288   -0.0742391    0.00838785   0.057694    -0.0316014   -0.0837419    0.0805061    0.0574935  -0.0244195   0.145571    -0.041806     0.102176    -0.0188446   -0.206997    -0.0494979   -0.00944857  -0.112074     0.0164785     0.0783395    -0.11109      0.0971715    -0.104268     0.0693751   -0.124433    -0.203388    -0.110165
 -0.133889    -0.0768081   -0.15196      0.11065     -0.0532431   -0.0279944   -0.188412     0.106132   -0.0712516   0.0436215    0.0413721    0.0113018   -0.228411     0.0454875   -0.174169    -0.132807     0.0130657    0.0219174     0.0468886    -0.0295161   -0.116636     -0.0977542   -0.162489    -0.0474243   -0.101555    -0.0560214
  0.161643     0.127662     0.0223171   -0.0975446   -0.0555206   -0.121863     0.12787     -0.0244182   0.0216364   0.0885609   -0.079965     0.138451     0.040203     0.070579    -0.254887    -0.119198     0.196489     0.0175591     0.0539106    -0.0589499    0.161938      0.0684991   -0.020251    -0.0359797   -0.01206      0.108584
 -0.220085    -0.0248094   -0.0616336   -0.00310425  -0.0094139    0.0427832    0.0186045    0.0404311   0.03499     0.149945    -0.0379665   -0.0524426    0.142045     0.0112006    0.00133639   0.0633512   -0.0949043    0.118182     -0.132352     -0.101397    -0.013672      0.101566    -0.10017     -0.0963966   -0.0848609   -0.0631142
 -0.0609167   -0.0135628    0.124319    -0.230256    -0.173081     0.0376717    0.262878     0.178455    0.128627    0.0424936    0.0826562   -0.00430304  -0.0103278   -0.11209     -0.0579034    0.0301249   -0.0423298   -0.0151716     0.00227345    0.00409165   0.0345096     0.00367847  -0.0232405   -0.00280512   0.00181401   0.115148
 -0.0669569    0.0667345   -0.137266     0.111664    -0.0517152    0.0796034    0.0175757    0.127272    0.0577199  -0.0629599    0.115775     0.0519277    0.0869576    0.0302493    0.0295229   -0.053089     0.0106565    0.0131029    -0.064687     -0.0138259   -0.0052091    -0.0564697    0.0106614    0.0302765    0.102334    -0.00912828
 -0.04566     -0.037979    -0.145732     0.0333528    0.102149    -0.0683031    0.147758     0.0631462   0.0251793   0.0717248    0.280198    -0.0319754    0.00123043   0.0210446    0.0880033   -0.0675529   -0.142051     0.0334912     0.0327322     0.0677321   -0.127268      0.013442    -0.134398     0.156896     0.132304    -0.105522
 -0.0289813   -0.0398591   -0.0348461   -0.0246095   -0.00423806  -0.00212285   0.0128637    0.05695    -0.262637    0.0757379    0.0317502    0.107877     0.0389511   -0.0280966    0.127397     0.0462233    0.0337137   -0.0858769     0.0701765     0.0869348   -0.041779      0.072501    -0.0181122    0.00162342   0.103073     0.140483
 -0.037358     0.102603     0.0393468   -0.0757523    0.169386     0.239365    -0.167294     0.230231    0.0144859   0.187132     0.0991658   -0.0425883    0.0913087    0.0737156   -0.195823    -0.0712083   -0.0550853    0.110118     -0.172565      0.0941516    0.010838     -0.17671      0.0469183    0.0475344   -0.0620898   -0.076907
 -0.0191915    0.0556102    0.408235     0.0179493    0.0599095    0.197899     0.0279912    0.010655   -0.28103     0.103973    -0.0640445    0.0966858   -0.0128124   -0.144925     0.183271    -0.159057    -0.0648815    0.00350991   -0.0117433     0.022149    -0.00853587   -0.0794581    0.168868    -0.0383954    0.0529209    0.0362255
  0.137773     0.0473932    0.0974092    0.0887176    0.124483    -0.122215     0.168584     0.0844511   0.103363    0.121105    -0.240415    -0.0978917   -0.0688498   -0.101625     0.132014    -0.120287    -0.0398639   -0.0607069    -0.0754871     0.0511018    0.103335     -0.130603     0.0650069   -0.0401597    0.201193     0.20075
  0.0142446    0.240525     0.0163391   -0.360701     0.112487    -0.109581    -0.0160337   -0.0890871   0.0300311  -0.0347116   -0.102079     0.239913     0.0736583   -0.0203374   -0.027499    -0.0118718    0.173118     0.0943919    -0.0635283     0.00958039   0.000410144  -0.0013321    0.108089     0.058091     0.0631855    0.0788803
  0.165702     0.0976404   -0.188424    -0.0133136   -0.0106616   -0.0463887   -0.0303905   -0.0102846  -0.0227066   0.119188     0.0972683    0.0551582    0.0143225    0.0669318    0.147574    -0.00645038  -0.0240488    0.000283008   0.0853649    -0.0614677    0.114682     -0.0120764   -0.0545225    0.122089     0.130289     0.0304592
 -0.0609062    0.0395581   -0.0723655    0.00535502   0.01451      0.0113867   -0.167312    -0.112516   -0.157921    0.203038     0.134875    -0.105399    -0.0448377   -0.0297104   -0.0946195    0.00281398   0.157146     0.0319267     0.00268307    0.0776902   -0.0696075     0.077804     0.00501988  -0.0218055   -0.144203    -0.0891272
 -0.0346833   -0.0641986    0.201274     0.1737      -0.083926    -0.01013     -0.057449     0.098344   -0.139632   -0.095342     0.078946     0.00631084  -0.028911     0.0534006    0.0119855    0.27494     -0.0151656    0.0927786     0.0496766     0.00310609  -0.0552534     0.252146     0.128901    -0.0864367   -0.121858     0.0995599
  0.169193    -0.0215205    0.0228226    0.135201    -0.0567913   -0.00446517   0.0701707   -0.0635449  -0.0920332   0.0162494   -0.0914128   -0.087024    -0.0221814    0.0499409    0.071327    -0.0317251    0.145154     0.0868042     0.148401      0.056365     0.0241577    -0.0326483   -0.112282     0.0847371   -0.0955092    0.0228589
  0.0182882    0.00131608   0.052116     0.074543     0.103889    -0.256151    -0.0696638    0.129913    0.0232254   0.179209     0.0255772   -0.0585765   -0.14687      0.0785111    0.0554596    0.00396849  -0.0277602   -0.0695711    -0.161087      0.0199452    0.115885      0.156797     0.0762952    0.0681789   -0.0104403    0.0450461
  0.0434814   -0.203532     0.0427332   -0.0172924   -0.0311541   -0.0637901    0.0222259   -0.134722    0.0160871  -0.135485    -0.0307081   -0.0449028    0.0812183   -0.0370342   -0.115842     0.0363026    0.00811557  -0.0389647     0.0282984    -0.161235    -0.12983       0.040547     0.00576224  -0.181053    -0.0978895    0.0541516
 -0.193101    -0.0774734   -0.0831796    0.00499029  -0.167281     0.0570419    0.120404     0.0868151  -0.0365421  -0.0473648    0.0764959   -0.0170337    0.020582    -0.0490343    0.137087    -0.026375    -0.0693726   -0.0644713    -0.0868273    -0.00211368  -0.0829047     0.04752     -0.035307    -0.0108029   -0.0128052    0.221408
  0.0827875   -0.167425    -0.101982     0.0556624    0.0648251   -0.0666649    0.180825     0.135815   -0.0877113  -0.0666051   -0.10009     -0.0110979   -0.0786417   -0.0881794   -0.0686746    0.00206518   0.0180472   -0.0249079     0.0128748    -0.0317169    0.000781406   0.0971052    0.0619793   -0.126484     0.123756    -0.052045
  0.0486707    0.0930776    0.0201023    0.0642411   -0.0620829    0.188416     0.0660741    0.0135344  -0.0179374  -0.0292993   -0.128618    -0.177538     0.0906608    0.0713837   -0.0638987   -0.123256     0.0869601   -0.0565746     0.112019     -0.106955     0.089232     -0.00910757   0.0366134    0.158277     0.077994     0.166907
 -0.0301914    0.106658    -0.0503369    0.194101    -0.0821168    0.0722503    0.00235556   0.0627895  -0.0606211   0.0276035    0.0530761   -0.0816907    0.121724    -0.0602645   -0.269834    -0.0545366   -0.035994    -0.0398258    -0.140681      0.0617204   -0.013219      0.125093     0.0896488    0.211633     0.0921586    0.014299
  0.211546     0.145279     0.177979    -0.0665969   -0.0651079    0.0591318   -0.142352    -0.0825392   0.0306079  -0.227191     0.0461132    0.083191     0.0667723    0.055314     0.148338     0.0686856    0.0669731   -0.0669784    -0.228911     -0.065614    -0.0499071     0.0113202   -0.125919     0.0556607   -0.0352256   -0.00549241
  0.218603     0.0257596   -0.0132864   -0.141935     0.0289632    0.0281613    0.170436    -0.100186   -0.0541292   0.0324868    0.0429888    0.0236484    0.0415195    0.0724002   -0.271427     0.184774     0.133675     0.133204     -0.180102     -0.0457873    0.0385059     0.0702349    0.061192     0.0492602    0.101267    -0.0571384
  0.181511     0.113248     0.020147     0.00723884  -0.00534614  -0.042598    -0.144249     0.069828    0.12082    -0.169476     0.0484706   -0.180579     0.067448     0.026159    -0.0879547    0.178149     0.0654441    0.0369198    -0.0289667    -0.0636116   -0.00729717   -0.0315578    0.0157649   -0.185369     0.0891387    0.13734
  0.112859    -0.156834     0.0901704   -0.0114171   -0.0558337   -0.103151    -0.122417     0.0281948   0.0972885   0.00760965  -0.0240158   -0.0845745   -0.0221358   -0.0712564   -0.021945    -0.0255673   -0.0224869   -0.0631979     0.0559106    -0.031817     0.0469381    -0.0291446    0.108853     0.0232764    0.0474441    0.0656896
  0.117932    -0.127314     0.129556     0.00373742   0.139096    -0.0331464   -0.0580139   -0.092933   -0.176864    0.0819611    0.0515085    0.0174066    0.0495462    0.0228913    0.257077    -0.171193     0.109806    -0.0823306     0.080122      0.0960551    0.0798596    -0.0356836    0.101415     0.103731     0.0373875   -0.12106
  0.0220891   -0.0342637    0.20445     -0.045676     0.00876113  -0.0476544    0.0193565   -0.0734393   0.13207     0.0267319    0.032041    -0.030908    -0.118738     0.136187     0.144925    -0.00766407   0.0735027   -0.0643805     0.0126594    -0.0422091   -0.0653784    -0.0823314    0.0448884    0.0660925    0.0507432    0.0825787kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4213937957073601
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421488
[ Info: iteration 2, average log likelihood -1.421377
[ Info: iteration 3, average log likelihood -1.420374
[ Info: iteration 4, average log likelihood -1.410824
[ Info: iteration 5, average log likelihood -1.393015
[ Info: iteration 6, average log likelihood -1.387310
[ Info: iteration 7, average log likelihood -1.385734
[ Info: iteration 8, average log likelihood -1.384682
[ Info: iteration 9, average log likelihood -1.383312
[ Info: iteration 10, average log likelihood -1.381195
[ Info: iteration 11, average log likelihood -1.379313
[ Info: iteration 12, average log likelihood -1.378179
[ Info: iteration 13, average log likelihood -1.377586
[ Info: iteration 14, average log likelihood -1.377260
[ Info: iteration 15, average log likelihood -1.377071
[ Info: iteration 16, average log likelihood -1.376953
[ Info: iteration 17, average log likelihood -1.376876
[ Info: iteration 18, average log likelihood -1.376822
[ Info: iteration 19, average log likelihood -1.376782
[ Info: iteration 20, average log likelihood -1.376751
[ Info: iteration 21, average log likelihood -1.376726
[ Info: iteration 22, average log likelihood -1.376707
[ Info: iteration 23, average log likelihood -1.376692
[ Info: iteration 24, average log likelihood -1.376681
[ Info: iteration 25, average log likelihood -1.376673
[ Info: iteration 26, average log likelihood -1.376667
[ Info: iteration 27, average log likelihood -1.376663
[ Info: iteration 28, average log likelihood -1.376660
[ Info: iteration 29, average log likelihood -1.376657
[ Info: iteration 30, average log likelihood -1.376656
[ Info: iteration 31, average log likelihood -1.376654
[ Info: iteration 32, average log likelihood -1.376653
[ Info: iteration 33, average log likelihood -1.376653
[ Info: iteration 34, average log likelihood -1.376652
[ Info: iteration 35, average log likelihood -1.376652
[ Info: iteration 36, average log likelihood -1.376651
[ Info: iteration 37, average log likelihood -1.376651
[ Info: iteration 38, average log likelihood -1.376651
[ Info: iteration 39, average log likelihood -1.376651
[ Info: iteration 40, average log likelihood -1.376650
[ Info: iteration 41, average log likelihood -1.376650
[ Info: iteration 42, average log likelihood -1.376650
[ Info: iteration 43, average log likelihood -1.376650
[ Info: iteration 44, average log likelihood -1.376650
[ Info: iteration 45, average log likelihood -1.376650
[ Info: iteration 46, average log likelihood -1.376650
[ Info: iteration 47, average log likelihood -1.376650
[ Info: iteration 48, average log likelihood -1.376650
[ Info: iteration 49, average log likelihood -1.376650
[ Info: iteration 50, average log likelihood -1.376650
┌ Info: EM with 100000 data points 50 iterations avll -1.376650
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4214879147224846
│     -1.421377153744503
│      ⋮
└     -1.3766499472395137
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.376796
[ Info: iteration 2, average log likelihood -1.376659
[ Info: iteration 3, average log likelihood -1.375814
[ Info: iteration 4, average log likelihood -1.366870
[ Info: iteration 5, average log likelihood -1.346875
[ Info: iteration 6, average log likelihood -1.338618
[ Info: iteration 7, average log likelihood -1.336218
[ Info: iteration 8, average log likelihood -1.334634
[ Info: iteration 9, average log likelihood -1.333575
[ Info: iteration 10, average log likelihood -1.332817
[ Info: iteration 11, average log likelihood -1.332166
[ Info: iteration 12, average log likelihood -1.331537
[ Info: iteration 13, average log likelihood -1.330904
[ Info: iteration 14, average log likelihood -1.330317
[ Info: iteration 15, average log likelihood -1.329872
[ Info: iteration 16, average log likelihood -1.329564
[ Info: iteration 17, average log likelihood -1.329343
[ Info: iteration 18, average log likelihood -1.329176
[ Info: iteration 19, average log likelihood -1.329043
[ Info: iteration 20, average log likelihood -1.328935
[ Info: iteration 21, average log likelihood -1.328847
[ Info: iteration 22, average log likelihood -1.328774
[ Info: iteration 23, average log likelihood -1.328713
[ Info: iteration 24, average log likelihood -1.328661
[ Info: iteration 25, average log likelihood -1.328615
[ Info: iteration 26, average log likelihood -1.328574
[ Info: iteration 27, average log likelihood -1.328536
[ Info: iteration 28, average log likelihood -1.328498
[ Info: iteration 29, average log likelihood -1.328460
[ Info: iteration 30, average log likelihood -1.328421
[ Info: iteration 31, average log likelihood -1.328380
[ Info: iteration 32, average log likelihood -1.328337
[ Info: iteration 33, average log likelihood -1.328292
[ Info: iteration 34, average log likelihood -1.328244
[ Info: iteration 35, average log likelihood -1.328189
[ Info: iteration 36, average log likelihood -1.328128
[ Info: iteration 37, average log likelihood -1.328061
[ Info: iteration 38, average log likelihood -1.327992
[ Info: iteration 39, average log likelihood -1.327922
[ Info: iteration 40, average log likelihood -1.327852
[ Info: iteration 41, average log likelihood -1.327785
[ Info: iteration 42, average log likelihood -1.327721
[ Info: iteration 43, average log likelihood -1.327661
[ Info: iteration 44, average log likelihood -1.327603
[ Info: iteration 45, average log likelihood -1.327547
[ Info: iteration 46, average log likelihood -1.327491
[ Info: iteration 47, average log likelihood -1.327434
[ Info: iteration 48, average log likelihood -1.327379
[ Info: iteration 49, average log likelihood -1.327326
[ Info: iteration 50, average log likelihood -1.327272
┌ Info: EM with 100000 data points 50 iterations avll -1.327272
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.37679601856048
│     -1.3766587773556638
│      ⋮
└     -1.3272718665137793
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.327406
[ Info: iteration 2, average log likelihood -1.327125
[ Info: iteration 3, average log likelihood -1.325653
[ Info: iteration 4, average log likelihood -1.316191
[ Info: iteration 5, average log likelihood -1.297378
[ Info: iteration 6, average log likelihood -1.284171
[ Info: iteration 7, average log likelihood -1.277625
[ Info: iteration 8, average log likelihood -1.274483
[ Info: iteration 9, average log likelihood -1.272788
[ Info: iteration 10, average log likelihood -1.271503
[ Info: iteration 11, average log likelihood -1.270248
[ Info: iteration 12, average log likelihood -1.268946
[ Info: iteration 13, average log likelihood -1.267743
[ Info: iteration 14, average log likelihood -1.266853
[ Info: iteration 15, average log likelihood -1.266178
[ Info: iteration 16, average log likelihood -1.265542
[ Info: iteration 17, average log likelihood -1.264859
[ Info: iteration 18, average log likelihood -1.264105
[ Info: iteration 19, average log likelihood -1.263347
[ Info: iteration 20, average log likelihood -1.262718
[ Info: iteration 21, average log likelihood -1.262266
[ Info: iteration 22, average log likelihood -1.261893
[ Info: iteration 23, average log likelihood -1.261609
[ Info: iteration 24, average log likelihood -1.261407
[ Info: iteration 25, average log likelihood -1.261276
[ Info: iteration 26, average log likelihood -1.261200
[ Info: iteration 27, average log likelihood -1.261157
[ Info: iteration 28, average log likelihood -1.261132
[ Info: iteration 29, average log likelihood -1.261116
[ Info: iteration 30, average log likelihood -1.261105
[ Info: iteration 31, average log likelihood -1.261097
[ Info: iteration 32, average log likelihood -1.261092
[ Info: iteration 33, average log likelihood -1.261087
[ Info: iteration 34, average log likelihood -1.261084
[ Info: iteration 35, average log likelihood -1.261081
[ Info: iteration 36, average log likelihood -1.261079
[ Info: iteration 37, average log likelihood -1.261077
[ Info: iteration 38, average log likelihood -1.261075
[ Info: iteration 39, average log likelihood -1.261074
[ Info: iteration 40, average log likelihood -1.261072
[ Info: iteration 41, average log likelihood -1.261071
[ Info: iteration 42, average log likelihood -1.261070
[ Info: iteration 43, average log likelihood -1.261069
[ Info: iteration 44, average log likelihood -1.261069
[ Info: iteration 45, average log likelihood -1.261068
[ Info: iteration 46, average log likelihood -1.261067
[ Info: iteration 47, average log likelihood -1.261067
[ Info: iteration 48, average log likelihood -1.261066
[ Info: iteration 49, average log likelihood -1.261066
[ Info: iteration 50, average log likelihood -1.261065
┌ Info: EM with 100000 data points 50 iterations avll -1.261065
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3274063902830187
│     -1.3271248818162629
│      ⋮
└     -1.2610653472824196
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.261326
[ Info: iteration 2, average log likelihood -1.261048
[ Info: iteration 3, average log likelihood -1.260103
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.248549
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.213106
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.200753
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.179160
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     11
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.195836
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.194740
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.190409
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.185865
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.184704
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      7
│      8
│     11
│     12
│     13
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.164336
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.215827
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.190143
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.188964
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.170666
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     11
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.190484
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.188182
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.194986
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.189424
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.189903
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.177497
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.192634
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.184091
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      7
│      8
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.184227
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.198614
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.197772
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.175278
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     11
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.177702
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.190165
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.192535
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.171179
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.192023
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.170890
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.179033
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.172689
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.186041
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.165744
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.192701
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.174758
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.175258
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.158074
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     11
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.179393
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.179264
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.176943
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.176822
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.177829
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     11
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.167491
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.184645
┌ Info: EM with 100000 data points 50 iterations avll -1.184645
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.261326014112471
│     -1.2610479792849214
│      ⋮
└     -1.1846445147051472
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.160912
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│     13
│     14
│     15
│     16
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.155891
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.157620
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│     13
│     14
│     15
│     16
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.129134
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.098324
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      4
│     13
│     14
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.077318
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.091973
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│     13
│     14
│     15
│     16
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.074236
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     18
│     21
│     22
│     23
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.074865
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      4
│      5
│     13
│     14
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.073189
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.090715
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│     13
│     14
│     15
│     16
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.071330
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.078856
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      4
│      8
│     13
│     14
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.065694
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     18
│     21
│     22
│     23
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.087593
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│     13
│     14
│     15
│     16
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.077418
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.074872
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      4
│     13
│     14
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.065988
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.086028
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│     13
│     14
│     15
│     16
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.069378
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      8
│     18
│     21
│     22
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.071468
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      4
│     13
│     14
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.080355
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.081830
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      5
│     13
│     14
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.068695
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.088474
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      4
│     13
│     14
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.069212
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     18
│     21
│     22
│     23
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.079594
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│     13
│     14
│     15
│     16
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.074449
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      8
│     21
│     22
│     23
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.072433
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      4
│     13
│     14
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.073519
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.088150
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│     13
│     14
│     15
│     16
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.071156
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│     18
│     21
│     22
│     23
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.072999
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      4
│     13
│     14
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.072001
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.079826
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      8
│     13
│     14
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.067133
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.086954
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      4
│     13
│     14
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.069010
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│     18
│     21
│     22
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.079296
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│     13
│     14
│     15
│     16
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.084626
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│     21
│     22
│     23
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.075846
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│     13
│     14
│     15
│     16
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.074202
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.079994
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      8
│     13
│     14
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.067187
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│     18
│     21
│     22
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.079294
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│     13
│     14
│     15
│     16
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.082389
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.076289
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│     13
│     14
│     15
│     16
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.067454
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│     21
│     22
│     23
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.077754
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│     13
│     14
│     15
│     16
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.073838
┌ Info: EM with 100000 data points 50 iterations avll -1.073838
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.160912420948881
│     -1.155891093532289
│      ⋮
└     -1.0738380502334632
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4213937957073601
│     -1.4214879147224846
│     -1.421377153744503
│     -1.4203741882051628
│      ⋮
│     -1.067454177172344
│     -1.077754401580996
└     -1.0738380502334632
32×26 Array{Float64,2}:
 -0.0608506    0.00102912   0.142604    -0.277138    -0.165706      0.0241845     0.281805     0.186602    0.116469      0.0471915    0.0830853  -0.00656502  -0.00925137  -0.14726     -0.0569705    0.0155075    -0.0488403   -0.00147429   0.000437245   0.0175077    0.0334455    0.00463957  -0.0662869     0.00642876  -0.000184566   0.112848
 -0.0461197   -0.0375355   -0.143601     0.0522963    0.103637     -0.0692357     0.151481     0.0603018   0.0585013     0.0725462    0.286753   -0.00422996  -0.00153455   0.0182112    0.0859117   -0.0474363    -0.131706     0.0142279    0.0384186     0.0735643   -0.107377     0.0125731   -0.132064      0.150785     0.112547     -0.097144
 -0.069912     0.0384971   -0.105343     0.0803994   -0.0146012     0.0519886    -0.0736177   -0.0136138  -0.0515133     0.0510961    0.109692   -0.0857795    0.0225824   -0.00971522  -0.0351416   -0.0230363     0.0744015    0.0198485   -0.037217      0.047986    -0.0246491    0.00827609   0.000224909   0.029838    -0.0435587    -0.0575371
  0.163684     0.00648607   0.00927828  -0.110337    -0.000427028   0.0107142     0.152648    -0.0937815  -0.0623286     0.0870425    0.0158778   0.034383     0.0333453    0.0160925   -0.244801     0.152561      0.0892162    0.0993541   -0.112254     -0.0705895    0.0567495    0.0354363    0.00907167    0.0220645    0.0551169    -0.0609227
  0.00678774   0.232635     0.00448906  -0.332653     0.101657     -0.104143      0.0481571   -0.0790285   0.0225905    -0.0217975   -0.115473    0.225242     0.0796535   -0.0174532   -0.0264239    0.000636162   0.185162     0.0909148   -0.0514075     0.00611479   0.00468096  -0.00368959   0.109038      0.034817     0.0552802     0.0688284
  0.0626308   -0.0641768    0.0539807   -0.00730779   0.0472057     0.0390689    -0.0128769   -0.0441763   0.0244382     0.0980674    0.0135663  -0.0074273   -0.152015    -0.105902     0.0352551   -0.033957      0.0815883    0.0390885    0.0293303     0.0950382   -0.0151733   -0.0366176    0.0305436     0.103204     0.0832071     0.00193851
 -0.0494957   -0.13319      0.010809    -0.0153935   -0.0268955    -0.0203904     0.0359977   -0.0198115  -0.0277963     0.0208581   -0.0688941  -0.0200254    0.0925346   -0.013938    -0.0530435    0.00972612   -0.0285803   -0.00351286  -0.0285729    -0.109412    -0.0230602    0.109476    -0.044207     -0.16028     -0.0975761     0.0254536
 -0.0369065    0.0484153    0.385661     0.0259546    0.0514075     0.167105     -0.0212403    0.0145017  -0.262648      0.0913573   -0.0857025   0.0957712   -0.0160209   -0.175172     0.171842    -0.150436     -0.0639846    0.00855869  -0.00439868    0.0233713   -0.00505595  -0.0854359    0.158465     -0.0266865    0.0709266     0.0245664
 -0.0482852   -0.0521066   -0.0542644    0.0891197    0.0290225    -0.150673     -0.149986     0.117438   -0.0350736     0.107415     0.0338472  -0.0166955   -0.176565     0.061402    -0.0569183   -0.0875387    -0.00510575  -0.0175313   -0.0645358     0.0204585    0.00917788   0.0244643   -0.0436733    -0.0018444   -0.130278     -0.0215655
  0.0385875    0.100322     0.0309443   -0.0336058    0.0782545     0.11449      -0.112043     0.121942    0.0539268    -0.0118739    0.0715628  -0.113656     0.078374     0.0544474   -0.187347     0.0637275    -0.00484537   0.0861587   -0.106231      0.00922842  -0.015951    -0.0932577    0.022626     -0.0628335   -0.0132509     0.0474848
  0.184639     0.094695    -0.214052     0.0130415    0.028477     -0.0381108    -0.0209541   -0.0109857  -0.0289566     0.113002     0.0708623   0.0367449    0.0157567    0.0483371   -0.740769    -0.018728     -0.0665664    0.00312297   0.0907331     0.104355     0.1422      -0.0122927   -0.0739754     0.161565     0.117137      0.0807498
  0.217387     0.0986709   -0.218377    -0.0161128   -0.0786724    -0.0473989    -0.045461    -0.0176163   0.0128375     0.121647     0.184305    0.0582854    0.0315272    0.0763348    0.891084    -0.000221095   0.08553     -0.0119909    0.0719377    -0.180115     0.0721607   -0.0142162    0.00123737    0.0973687    0.145705     -0.0158168
  0.138836     0.04512     -0.0646304    0.113618     0.121387     -0.144978      0.225655    -0.122578    0.228987      0.084326    -0.268077   -0.120493    -0.654619    -0.103734     0.236023    -0.114088     -0.106339    -0.08632     -0.0693912     0.0492853    0.118978    -0.207059     0.0127513    -0.0534661    0.378797      0.220889
  0.14347      0.0457712    0.204681    -0.0044495    0.116805     -0.100155      0.151589     0.359929    0.0164923     0.172172    -0.213566   -0.148911     0.570617    -0.0981633    0.0489931   -0.112695      0.0175721   -0.0261143   -0.0871532     0.0509184    0.135211     0.00109884   0.0148041    -0.0332104    0.0572729     0.154186
  0.136001     0.127485    -0.0218163   -0.143606    -0.132397     -0.0405775    -0.292851    -0.0272985   0.000570797   0.0564497   -0.0783374   0.264572     0.0399805    0.0710165   -0.316166    -0.0752616     0.243137     0.0237156    0.0607809    -0.0938479    0.152858     0.0684411   -0.00405129   -0.0264359    0.00804585    0.176379
  0.238327     0.12553      0.0841405    0.0651939    0.103422     -0.266838      0.999784     0.0126381   0.076561      0.13113     -0.0768836   0.0193732    0.0399435    0.0699342   -0.224065    -0.164866      0.0961591    0.0329683    0.0230095    -0.0140304    0.16301      0.0686306   -0.110457     -0.0474021   -0.0313969    -0.0360332
  0.157025    -0.0308733    0.0200101    0.124772    -0.0593458    -0.00383645    0.0530251   -0.138516   -0.0751009     0.0199928   -0.091812   -0.0886093   -0.0253092    0.0159121    0.0698879   -0.0263276     0.152571     0.0728782    0.14433       0.0452319    0.0567397   -0.00895194  -0.109215      0.0535971   -0.0924298     0.00907971
  0.0383634    0.16783     -0.00961257   0.0676966   -0.0761639     0.00738128    0.159359    -0.0795639  -0.063668      0.0856826   -0.0516945  -0.0430867   -0.0804261    0.162905     0.0346513    0.159202      0.219903    -0.144232     0.13756       0.0460841   -0.162319    -0.135463     0.0583812    -0.130084     0.00365824   -0.0175309
 -0.0914815    0.0757021   -0.101717     0.16711     -0.124234      0.000427936  -0.0369892   -0.321374   -0.0701049     0.02773      0.0278103  -0.0947856    0.115648    -0.0710051   -0.276943     0.000551178  -0.0384922   -0.0423364   -0.196837      0.106247    -0.0622566    0.132563    -0.109639      0.164602     0.0649828    -0.0431916
  0.0236258    0.131379    -0.00600509   0.213568    -0.0429384     0.16694       0.0601255    0.473427   -0.0463843     0.0267822    0.0815995  -0.0606562    0.126358    -0.0410297   -0.253837    -0.080825     -0.0238807   -0.0372252   -0.0299263     0.0112613    0.0536919    0.141716     0.292488      0.244066     0.128463      0.0141352
 -0.0514463   -0.0777914   -0.0606351   -0.0189326   -0.0619827    -0.0382033     0.0374631   -0.0152947  -0.199467      0.00465382   0.222955   -0.0754416   -0.0705309   -0.0534717    0.0379315    0.0371544     0.0192854   -0.0548459    0.0387709     0.365607    -0.933124     0.0803627    0.0324646    -0.0457475    0.112767      0.070943
  0.109387    -0.115624    -0.0690647    0.0331559    0.143903     -0.0353107     0.159054     0.28435    -0.146914     -0.00526448  -0.358512    0.259328     0.0123819   -0.067525     0.015482     0.0115998     0.0219906   -0.0539693    0.0279784    -0.349849     0.969974    -0.0212445    0.024241     -0.0714506    0.11433       0.0536091
  0.102508    -0.228094     0.218473     0.0379481    0.183649     -0.0655573    -0.0700711   -0.0952054  -0.212447      0.0521081    0.0568356   0.0118871    0.0662222    0.550171     0.256083    -0.170524      0.10249     -0.0499036    0.0676344     0.104752     0.0863415    0.0189353    0.149938      0.102924     0.0389266    -0.112646
  0.113638    -0.17389      0.00548063   0.0485534    0.164962     -0.0122767    -0.0603788   -0.0909663  -0.141782      0.128598     0.0579185   0.00857783   0.0759626   -0.508627     0.256378    -0.123233      0.123153    -0.0859376    0.145356      0.0874083    0.0792362   -0.122093     0.130155      0.103247     0.0395569    -0.136735
  0.0471609    0.0893535    0.00277938   0.0258961   -0.0708867     0.183352      0.0704497    0.024188   -0.0180048     0.0747887   -0.110437   -0.148862    -0.149927     0.0469354   -0.0986939   -0.136856      0.086598    -0.0550168    0.00997777   -0.109877     0.198046     0.00246423  -0.0337006     0.451987     0.0661892     0.165944
  0.0466966    0.0850662    0.0505826    0.181113    -0.0641978     0.187018      0.0416107   -0.0938786  -0.0181232    -0.105482    -0.194284   -0.204175     0.323429     0.0644735    0.00997965  -0.125225      0.0864651   -0.0556245    0.246592     -0.106914     0.0175352   -0.00332558   0.129298     -0.0731372    0.0730977     0.191335
  0.00214646   0.136343     0.440126     0.0910156   -0.129695      0.342105      0.0970984   -0.0929016   0.133578     -0.0758122   -0.222272   -0.0171884   -0.0188231    0.0317905   -0.128687     0.0653559     0.148098    -0.177595     0.164052     -0.149196     0.0384974   -0.366301    -0.0583002     0.0559054    0.558595     -0.0665911
 -0.061351    -0.0276487   -0.247072     0.1332       0.0655313    -0.308706      0.171082    -0.0402238   0.15242      -0.092571    -0.220697   -0.0176206   -0.0168563    0.0488436    0.180853     0.0684321     0.148356     0.0613117    0.129373      0.176593     0.0416356    0.258856    -0.0537066     0.0403468   -0.984482      0.054363
  0.188347     0.149381     0.174886    -0.0759163   -0.0785563     0.056883     -0.147461    -0.0503746   0.0220279    -0.23206      0.0391855   0.082769     0.0682769    0.0513777    0.115451     0.057462      0.0803265   -0.0709687   -0.23252       0.00575152  -0.050663     0.0212622   -0.12538       0.066478    -0.0270068    -0.0154396
 -0.0465494   -0.111794     0.00462865   0.00506132  -0.135171     -0.0487208     0.00764929   0.0570558   0.02922       0.00744775   0.0205422  -0.0390787    0.00720061  -0.0716551    0.0482727    0.00417662   -0.0516101   -0.0568208   -0.0202239    -0.0142584   -0.00554275  -0.00189888   0.0393642    -0.0127253   -0.00539039    0.114082
 -0.0808751   -0.0635808    0.23022      0.17688     -0.493448     -0.0107144    -0.0413677    0.0935581  -0.187793     -0.165006     0.0804675   0.0351747   -0.030667     0.0533444    0.112044     0.28231      -0.0696315    0.0585922    0.0448755    -0.0244418   -0.0558632    0.216557     0.128048     -0.125061    -0.121845      0.0766055
  4.35612e-5  -0.0604896    0.190742     0.177323     0.397479     -0.00465184   -0.0846347    0.0991881  -0.100877     -0.0875294    0.0843901  -0.0213331   -0.0315589    0.0534463   -0.125504     0.248957      0.0310508    0.199854     0.0127884     0.0214707   -0.0576176    0.259018     0.127942     -0.037484    -0.121946      0.121768[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│     18
│     21
│     22
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.071959
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      5
│      8
│     13
│     14
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.065175
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│     18
│     21
│     22
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.070554
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      4
│      5
│      8
│     13
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.063409
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│     18
│     21
│     22
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.072058
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      5
│      8
│     13
│     14
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.064656
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      4
│      5
│     18
│     21
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.069560
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      5
│      8
│     13
│     14
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.065948
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│     18
│     21
│     22
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.070662
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      4
│      5
│      8
│     13
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.063331
┌ Info: EM with 100000 data points 10 iterations avll -1.063331
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.616544e+05
      1       7.015444e+05      -2.601101e+05 |       32
      2       6.672673e+05      -3.427709e+04 |       32
      3       6.485133e+05      -1.875394e+04 |       32
      4       6.393152e+05      -9.198096e+03 |       32
      5       6.346457e+05      -4.669534e+03 |       32
      6       6.318715e+05      -2.774178e+03 |       32
      7       6.299834e+05      -1.888088e+03 |       32
      8       6.287406e+05      -1.242848e+03 |       32
      9       6.278746e+05      -8.660109e+02 |       32
     10       6.271256e+05      -7.490227e+02 |       32
     11       6.263356e+05      -7.899274e+02 |       32
     12       6.254676e+05      -8.680314e+02 |       32
     13       6.247349e+05      -7.326799e+02 |       32
     14       6.241474e+05      -5.875279e+02 |       32
     15       6.236389e+05      -5.084606e+02 |       32
     16       6.229961e+05      -6.428766e+02 |       32
     17       6.221675e+05      -8.285909e+02 |       32
     18       6.214845e+05      -6.829931e+02 |       32
     19       6.211201e+05      -3.643480e+02 |       32
     20       6.209335e+05      -1.865889e+02 |       32
     21       6.208215e+05      -1.120195e+02 |       31
     22       6.207564e+05      -6.513301e+01 |       32
     23       6.206975e+05      -5.893569e+01 |       32
     24       6.206420e+05      -5.541135e+01 |       32
     25       6.205909e+05      -5.112205e+01 |       32
     26       6.205463e+05      -4.460821e+01 |       32
     27       6.205068e+05      -3.953967e+01 |       32
     28       6.204642e+05      -4.256073e+01 |       32
     29       6.204221e+05      -4.209871e+01 |       32
     30       6.203784e+05      -4.376025e+01 |       30
     31       6.203232e+05      -5.518834e+01 |       32
     32       6.202494e+05      -7.379539e+01 |       32
     33       6.201983e+05      -5.105105e+01 |       31
     34       6.201564e+05      -4.196078e+01 |       31
     35       6.201204e+05      -3.592573e+01 |       29
     36       6.200934e+05      -2.701350e+01 |       30
     37       6.200752e+05      -1.823999e+01 |       30
     38       6.200633e+05      -1.187607e+01 |       29
     39       6.200527e+05      -1.058174e+01 |       30
     40       6.200401e+05      -1.258496e+01 |       30
     41       6.200305e+05      -9.627645e+00 |       27
     42       6.200219e+05      -8.653619e+00 |       29
     43       6.200159e+05      -5.988335e+00 |       27
     44       6.200118e+05      -4.096916e+00 |       26
     45       6.200080e+05      -3.784918e+00 |       25
     46       6.200047e+05      -3.248432e+00 |       21
     47       6.200015e+05      -3.205593e+00 |       20
     48       6.199981e+05      -3.413683e+00 |       26
     49       6.199950e+05      -3.074048e+00 |       24
     50       6.199910e+05      -4.023980e+00 |       25
K-means terminated without convergence after 50 iterations (objv = 619991.0192059132)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.324017
[ Info: iteration 2, average log likelihood -1.288029
[ Info: iteration 3, average log likelihood -1.247376
[ Info: iteration 4, average log likelihood -1.201836
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.153979
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      9
│     17
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.112420
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.124773
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.082513
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      7
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.053627
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      5
│      9
│     17
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.059154
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.106334
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.050685
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      9
│     17
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.044761
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.079120
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      7
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.064581
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      9
│     14
│     17
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.043493
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.081567
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      3
│      5
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.045008
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      9
│     21
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.040642
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     14
│     17
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.049322
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      3
│     15
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.065451
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      5
│      7
│      9
│     21
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.067357
[ Info: iteration 23, average log likelihood -1.095936
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     14
│     17
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.035074
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      4
│      5
│      7
│      ⋮
│     21
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.022887
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.108287
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.082613
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│     14
│     17
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.035002
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     18
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.070035
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     15
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.044182
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      7
│     10
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.047025
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     14
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.048755
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      9
│     18
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.045957
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      5
│      7
│     15
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.048300
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.069758
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.060261
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      4
│      9
│     17
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.041668
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.073175
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     15
│     25
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.032134
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      9
│     14
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.064933
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      3
│     10
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.079448
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.076769
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      7
│      9
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.031900
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      3
│      5
│     15
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.041406
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     17
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.074688
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.079468
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.071784
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.047111
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│     14
│     15
│     17
│     18
│     21
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.017814
32×26 Array{Float64,2}:
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.094560
┌ Info: EM with 100000 data points 50 iterations avll -1.094560
└ 59.0 data points per parameter
 -0.0718457  -0.0812267    0.0166715    0.0312639     0.0213319   -0.0732125     0.061866     0.0717236  -0.0273541    0.185283     -0.0330981   0.117787    -0.0124482   -0.13311     -0.109354     -0.0159869    -0.106685     0.0243904     0.0470732    -0.140423      0.0718841   -0.104123      0.0633423   -0.07454     -0.283957     -0.112637
 -0.0356682   0.10272     -0.0548884    0.189911     -0.0841209    0.0815685     0.0113242    0.0635711  -0.0591418    0.0272392     0.0535595  -0.0784729    0.120835    -0.0557043   -0.265765     -0.0390326    -0.0312759   -0.0398178    -0.115443      0.0603033    -0.0064089    0.137327      0.0849465    0.203729     0.0959506    -0.0145275
  0.171924    0.125396     0.0133314   -0.0720833    -0.049129    -0.116499      0.160073    -0.0116176   0.0256218    0.083215     -0.077699    0.177496     0.0396793    0.0704852   -0.282866     -0.105203      0.189867     0.025114      0.0476089    -0.0631695     0.155384     0.0678201    -0.0381357   -0.0332216   -0.0060874     0.102568
  0.0668581  -0.168514    -0.0914842    0.0296839     0.0236729   -0.045758      0.160301     0.305521   -0.0726439   -0.0903393    -0.13005    -0.00687564  -0.0632005   -0.0965558   -0.0319031    -0.00642686    0.0198336   -0.0318536    -0.00145233   -0.0188205    -0.25472      0.178048      0.0422091   -0.115199     0.108322      0.0668965
  0.0103591   0.238298     0.0034907   -0.353144      0.107824    -0.104763      0.0530509   -0.0837807   0.0257536   -0.0286       -0.121908    0.23515      0.0829983   -0.0132251   -0.0278702     0.000295053   0.196177     0.0911039    -0.0564794     0.00813988    0.00166588  -0.000955202   0.108892     0.0453214    0.0616454     0.0750139
  0.021956   -0.130427     0.0535455   -0.014183     -0.0604061    0.0509835     0.0523134    0.0420698  -0.136245     0.000946947  -0.0992129   0.0203442    0.0796228    0.0131946   -0.0393464    -0.0784291     0.00446876  -0.0650827     0.0144699    -0.0624714     0.122304     0.201326     -0.0562105   -0.205045    -0.0972695     0.0843182
  0.130554    0.022361     0.402817    -0.427651     -0.331576     0.0104415    -0.250733     0.0908744  -0.111128     0.312384      0.23173    -0.122938    -0.0513643    0.104106     0.45932      -0.0719368     0.112988    -0.0792264    -0.164397     -0.222782     -0.297337    -0.332257     -0.00775216  -0.0117553   -0.157969      0.105906
  0.11066    -0.0715651   -0.0930243    0.0241845     0.089274     0.115276     -0.0576344   -0.0310765  -0.049464     0.173446      0.0163822  -0.00097066  -0.16369     -0.336882    -0.0946905    -0.0543977     0.0776277    0.142472      0.0496968     0.24494       0.00343077   0.0121686     0.01605      0.141274     0.169782     -0.0604094
 -0.0456197  -0.0615831    0.211563     0.177439     -0.0372322   -0.000877336  -0.0614752    0.095914   -0.15853     -0.127071      0.0845091   0.00354625  -0.0318723    0.0525662    0.000431558   0.269783     -0.0182928    0.134756      0.0212568    -0.000236557  -0.0561853    0.240783      0.126758    -0.0807254   -0.119452      0.098523
 -0.0605886   0.0936705    0.0393164   -0.074733      0.168065     0.247048     -0.127536     0.200278    0.0275392    0.159598      0.0967509  -0.0647333    0.0941568    0.0667136   -0.239917     -0.0422907    -0.0786432    0.109738     -0.173321      0.10376       0.00509466  -0.158679      0.0502069    0.045436    -0.104495     -0.0778015
  0.0506307  -0.214892     0.0371764   -0.0104712    -0.018463    -0.113993      0.0239818   -0.133934    0.018055    -0.130128     -0.0523756  -0.0421272    0.0778357   -0.0380308   -0.115733      0.0557875     0.00624315  -0.0404007     0.0284675    -0.157704     -0.16993      0.0379954     0.0131026   -0.164593    -0.0955523     0.054475
  0.198845    0.153938     0.178552    -0.0709573    -0.0799159    0.057726     -0.149757    -0.0565812   0.0226752   -0.233194      0.0383645   0.0788122    0.0684856    0.0570164    0.125206      0.0593949     0.087731    -0.0761249    -0.240339      0.00227816   -0.0575948    0.0230311    -0.125559     0.0722498   -0.0256756    -0.0135764
 -0.122364   -0.084471    -0.146406     0.102309     -0.054635    -0.0386309    -0.208699     0.0971209  -0.0815955    0.0413089     0.0448816  -0.00424268  -0.202134     0.0518593   -0.176612     -0.162731     -0.00496731   0.0355107     0.0365297    -0.0265589    -0.109121    -0.0982141    -0.157527    -0.050181    -0.123261     -0.0699243
  0.025589    0.136716     0.00573262   0.0624791    -0.0703224   -0.00579805    0.111907    -0.0871866  -0.0699241    0.0917014    -0.0332908  -0.0458196   -0.0601921    0.173329     0.0781331     0.133001      0.184618    -0.108373      0.184602      0.0752438    -0.16328     -0.138692      0.0908253   -0.0789248    0.0265153    -0.0261229
  0.0147437   0.065401     0.0197256    0.122851     -0.0770827    0.15512       0.073394    -0.036648   -0.0198801   -0.0288347    -0.245411   -0.166495     0.0737292    0.0258308   -0.0814368    -0.12843       0.0525098   -0.0450257     0.145607     -0.126364      0.206845    -0.012729      0.026247     0.37695      0.0495218     0.138237
  0.154467    0.111146     0.021132     0.00500349   -0.00528321  -0.0145243    -0.0968114    0.0479716   0.0972035   -0.172644      0.0473528  -0.161355     0.0632266    0.038223    -0.13984       0.171076      0.0677853    0.059485     -0.0437765    -0.0579759    -0.0320803   -0.0273641     0.00484772  -0.169895     0.0838897     0.164184
  0.239754    0.00476227   0.0315821   -0.122075      0.0217957    0.0379253     0.212604    -0.156651   -0.0761586    0.0351691     0.0323825   0.0153002    0.0457939    0.0768379   -0.202649      0.208527      0.125981     0.0834514    -0.230132     -0.0834166     0.0641237    0.0512711     0.0249006    0.0383814    0.101902     -0.0592568
 -0.0399949  -0.01471     -0.0299043   -0.0580288    -0.0182556   -0.00305969   -0.00607767   0.0703699  -0.296883     0.0754517     0.0640242   0.244628     0.0381267   -0.0342973    0.110449      0.0949542     0.0342053   -0.0844941     0.0659709     0.0962307    -0.0210757    0.0112168    -0.00716531   0.00390033   0.0915784     0.128974
  0.194645    0.0963569   -0.208216    -0.000660804  -0.029948    -0.0377631    -0.0343155   -0.0131846  -0.00635323   0.116613      0.125545    0.0397828    0.0304667    0.0656076    0.0853701    -0.0099846     0.0141544   -0.00668732    0.0818126    -0.0439311     0.10168     -0.0137214    -0.0330101    0.135068     0.131306      0.039373
 -0.112957    0.00165502   0.183484     0.00252001    0.0181158    0.105882     -0.00156971   0.0189174  -0.141236     0.131171     -0.0752946   0.038994     0.0551228   -0.10701      0.10303      -0.0579276    -0.0722799    0.0467263    -0.0620924    -0.0328845    -0.00868715  -0.00446932    0.0434474   -0.0781273    0.00224794   -0.0176325
  0.0930201  -0.292328     0.0552598    0.0525146     0.267033    -0.043671     -0.00789177  -0.110336   -0.239442     0.063355      0.03403     0.00513593   0.0685303   -0.0302675    0.157073     -0.257682      0.070038    -0.0660794     0.140382      0.0844446     0.210494    -0.0365983     0.129872     0.0340387    0.0663393    -0.161271
  0.0179169  -0.00557644   0.051937     0.076009      0.118874    -0.255675     -0.110373     0.128778    0.0149364    0.16855       0.0255204  -0.0459343   -0.139241     0.0775939    0.0562777    -0.0133765    -0.00183593  -0.0724523    -0.163158      0.0669312     0.118741     0.164498      0.0657703    0.0511159   -0.104225      0.0444812
 -0.0459793  -0.0373517   -0.143864     0.0517447     0.103433    -0.0690092     0.15177      0.0606659   0.0576862    0.0726429     0.286478   -0.00495995  -0.00186845   0.0175239    0.0875431    -0.0487325    -0.131534     0.0138939     0.037474      0.0739903    -0.108592     0.0131389    -0.131518     0.151606     0.114492     -0.0965872
 -0.185493   -0.0755508   -0.0852746    0.00444555   -0.22264      0.027169      0.125622     0.0798002  -0.0362713   -0.0355398     0.0720984  -0.0170616    0.0330389   -0.0512638    0.126659     -0.0139115    -0.06447     -0.0763372    -0.0934977     0.0317181    -0.0902877    0.0131248    -0.0508736   -0.0048951    0.0105479     0.220437
 -0.0199835   0.0455261    0.0734034    0.107077     -0.028901    -0.00157685    0.136548    -0.0641063   0.12287     -0.0794925    -0.219305   -0.0223673   -0.013054     0.0241654    0.00802435    0.0574298     0.13215     -0.0395435     0.145468      0.0152762     0.0466339   -0.0384584    -0.053788     0.0526185   -0.214606     -0.00624423
  0.131325    0.0390364    0.0405734    0.06578       0.119141    -0.104545      0.188583     0.127865    0.129286     0.128489     -0.234892   -0.167958    -0.0545289   -0.0963302    0.138912     -0.121408     -0.0359744   -0.069325     -0.0706936     0.0480246     0.167596    -0.120378      0.0102933   -0.0390015    0.218449      0.19271
  0.0152496  -0.0671055    0.184       -0.0400204     0.0061794   -0.0436011     0.0136441   -0.0478502   0.0859146    0.0144852     0.0257942  -0.0303016   -0.137049     0.128184     0.163617     -0.0250882     0.0918879   -0.0489235     0.00557289   -0.0476538    -0.0378805   -0.0869101     0.0451943    0.0621262    0.0303253     0.0735819
  0.0962961  -0.137169     0.102356    -0.00754337   -0.0534714   -0.104272     -0.112231     0.0299229   0.0881476    0.0124118    -0.0156734  -0.0696231   -0.0121617   -0.0497507   -0.00951611    0.0375688    -0.0169209   -0.042799      0.0369108    -0.031868      0.0372639    0.0223675     0.116871     0.0139477    0.0205323     0.0675909
 -0.0348974  -0.0508724    0.0195151    0.142239     -0.0342211   -0.0428114     0.0407051    0.0662838  -0.0401359    0.167382     -0.0195432   0.0812904   -0.00207376  -0.310531    -0.0613281    -0.0557551    -0.0504934    0.0109661     0.0690431    -0.137156      0.120613    -0.107481      0.0931666   -0.162524    -0.199052     -0.0586535
  0.162442   -0.0362455    0.01281      0.120038     -0.0599969   -0.00765683    0.0633691   -0.127221   -0.0726015    0.0145048    -0.0972671  -0.0902087   -0.0286884    0.0153045    0.0652683    -0.0236834     0.145621     0.0730272     0.141923      0.0425509     0.0355855    0.0028414    -0.0996414    0.0427956   -0.072877      0.00225305
 -0.0608151   0.00215828   0.14353     -0.282887     -0.166781     0.0250035     0.281497     0.187141    0.117985     0.0466826     0.0831601  -0.00852661  -0.00974684  -0.147721    -0.0559977     0.0167263    -0.04889     -0.000593463   0.000346337   0.0171088     0.0336809    0.00461427   -0.0685902    0.00755137  -0.000425973   0.113991
 -0.0536394   0.049902    -0.0903139    0.0769044    -0.0174203    0.0689292    -0.0736165   -0.0132608  -0.0482888    0.0523225     0.0930124  -0.0971829    0.0281669   -0.00399222  -0.0397804    -0.0383394     0.0826423    0.0131306    -0.0301462     0.0333083    -0.0176677    0.0114002     0.00430914   0.0525335   -0.0199823    -0.0351992[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      9
│     10
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.049398
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      4
│      9
│     10
│     21
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.999451
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      3
│      9
│     10
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.984804
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      4
│      5
│      9
│      ⋮
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.016735
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      9
│     10
│     17
│     18
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.012782
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      3
│      4
│      7
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.983837
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      9
│     10
│     18
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.023132
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      3
│      4
│      7
│      ⋮
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.983802
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      5
│      7
│      9
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.011522
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      4
│      9
│     10
│      ⋮
│     21
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.014610
┌ Info: EM with 100000 data points 10 iterations avll -1.014610
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.105935     0.000697247  -0.172996     0.147239   -0.192517    -0.0293254    0.05787      0.0286756   -0.0484565     0.0702108   -0.137611     0.0394838   -0.0957394    0.0763877    0.0631222   -0.160182     0.0729585    -0.0968942    0.094339    -0.0395164    0.0124423   -0.134446    -0.169621     -0.00778864  -0.084814    -0.13412
 -0.0800265    0.00274849    0.012499    -0.0865419  -0.123738     0.012438    -0.0337874    0.0332869   -0.0651086     0.0322101   -0.0403122    0.00213899   0.0640696   -0.0281459   -0.0674694   -0.19397     -0.140252      0.0705753    0.0540215    0.093584     0.0998616    0.0471124   -0.129994      0.101821     0.0927085    0.00559785
 -0.241456    -0.0494721     0.145629     0.0839601  -0.0455137    0.0417812   -0.079435     0.00940964  -0.0435398     0.0731877    0.183872    -0.0219787    0.0588393   -0.0105719    0.0261296    0.0701424   -0.0068954    -0.0876936   -0.038448     0.123569    -0.0155109    0.0608939    0.0864353    -0.0159373   -0.00165377  -0.0845501
 -0.0463088    0.0109342    -0.118395     0.0982442  -0.085165     0.09233      0.109605     0.0289147    0.0121319    -0.102555    -0.0489229    0.0487275   -0.0861598   -0.0159588   -0.0838402    0.0548925    0.221374     -0.0996543   -0.0375396   -0.159852     0.0377249    0.0367692    0.0743522    -0.0012856   -0.0180792   -0.0557903
  0.00405182  -0.0011313    -0.0176092    0.0287869   0.0453531    0.056413     0.0627081   -0.0104212   -0.192208      0.0140804   -0.0250768    0.0270923    0.113084     0.146123     0.180229    -0.118625    -0.0233748    -0.105104    -0.0398215   -0.0656562    0.257955    -0.134875    -0.0209055     0.083035     0.0820267    0.103615
 -0.233032     0.0622156     0.0739378   -0.140356    0.0111659   -0.114912     0.0847651    0.0913251    0.00509049    0.1231      -0.0901899    0.148133     0.0954084    0.0756407   -0.0512871   -0.131016    -0.0537396    -0.0693419   -0.0210849   -0.0826346   -0.0251413    0.00215398   0.0639034     0.0226507   -0.0598561   -0.0753994
  0.0780503   -0.0173972     0.0849717   -0.211698   -0.00413694   0.00518373  -0.0773665    0.0642487    0.0158696    -0.0111997   -0.0147604   -0.00432828   0.238796    -0.124762    -0.135097    -0.017503    -0.176613     -0.013729    -0.0351098   -0.0237789   -0.174355    -0.125992     0.000839173  -0.0941908    0.0481834    0.100191
  0.194125     0.00361958    0.0226334    0.0448347   0.0197182   -0.110655     0.0220687   -0.0361218   -0.0681046     0.0148704   -0.139668     0.0526401   -0.144108     0.0667516    0.161114     0.138535    -0.141449      0.20972     -0.0414222    0.0320755   -0.150649     0.044793    -0.141073     -0.173469    -0.0547587    0.212187
  0.0647927   -0.0722134     0.0986455   -0.0966665  -0.021886    -0.105817     0.0346825    0.181112     0.00190837   -0.261672    -0.0016287   -0.0727964   -0.119512     0.0229055   -0.0412827    0.096928     0.0958547    -0.00378429   0.0362633   -0.0602191    0.121633     0.00633804   0.0653696    -0.0427878    0.0627621   -0.115724
  0.0849525    0.108952      0.0921328    0.231549   -0.148015    -0.0487862    0.163791     0.0894609    0.0450957    -0.178843     0.0339637    0.117293     0.0478184   -0.0394366    0.182735    -0.0529403   -0.0197289     0.109507    -0.0286885    0.218012    -0.0700096   -0.0186655   -0.136674      0.0645595    0.104662     0.14436
  0.069691    -0.0351233    -0.0523763   -0.145921   -0.0651195   -0.0712256   -0.0142016   -0.0579394   -0.0422956     0.0290834   -0.00301753  -0.024721     0.14608      0.0257309    0.0582256   -0.0727317   -0.080147     -0.174849     0.117349     0.151007    -0.0659799   -0.0914755   -0.18087       0.0469586    0.10075     -0.00813635
 -0.115726    -0.0487837    -0.004987     0.0768901   0.0393714    0.0832967   -0.101838     0.126       -0.124349     -0.0049219   -0.119997     0.109671     0.0587571   -0.0542546   -0.00555887   0.0459167    0.104837     -0.0248064   -0.063527     0.101294     0.0138355    0.120298     0.0997998    -0.223559    -0.0427432   -0.0767063
  0.0948068   -0.0136642     0.115578    -0.0715262   0.0376585    0.00204169  -0.0434109   -0.0454952   -0.141295      0.070506     0.136443     0.0901978    0.105896     0.0452886   -0.0690517    0.178889     0.135003     -0.111411     0.193763     0.257197     0.161616     0.0422347    0.0328433    -0.0312669   -0.0934806   -0.106978
 -0.0416705    0.075882     -0.218154    -0.0706823  -0.179574     0.0215919    0.002593    -0.02099      0.0592915    -0.117259     0.208924    -0.154131    -0.119333    -0.0647762    0.00667765  -0.0674675    0.145724      0.183613    -0.236232     0.157136    -0.0538527   -0.0236761   -0.138452      0.0373489   -0.15403      0.0554563
 -0.00969196   0.0349866    -0.0913013    0.0298675   0.0393654    0.0613642   -0.0320976    0.147019     0.0819656     0.00839086   0.116467    -0.121953     0.00256823  -0.065887    -0.0526585   -0.148125    -0.0997955     0.0459929    0.0353651   -0.00922285   0.11103      0.00290606   0.156839     -0.0387444    0.0644774   -0.0356893
 -0.033389    -0.194657     -0.105428     0.147308   -0.0135373   -0.0418657   -0.114354    -0.0384202   -0.110252      0.195863     0.0288896   -0.0156112   -0.125723     0.0377495   -0.0137508   -0.0105851   -0.0312577    -0.0317439    0.0878183    0.014958    -0.0300501    0.135654     0.145507      0.0678813   -0.133744    -0.059223
  0.0469779    0.0228427     0.0248288    0.088226    0.22307      0.0134664   -0.13326      0.105841     0.0505334     0.07467     -0.124127    -0.00549838  -0.244457     0.104732    -0.0713494   -0.176012     0.1672        0.0123248    0.046325     0.110856    -0.00757193  -0.0415281   -0.0132074    -0.0240358   -0.204851    -0.00679654
 -0.150167    -0.187716      0.14026      0.146816    0.103963    -0.0770175    0.0662546   -0.225394    -0.102422     -0.12357      0.015614     0.0908937   -0.0311035    0.0696315    0.198364    -0.0886253    0.0444689    -0.0034461   -0.121678     0.0955      -0.0012201    0.14757      0.0361785     0.104315    -0.0841693   -0.0800812
  0.119784    -0.0271738    -0.0369384    0.0879126  -0.00514983   0.0154301    0.0484898    0.100992     0.00143601    0.0446698   -0.0228124   -0.0378678    0.0792972   -0.112762     0.038598    -0.0945752   -0.0518599     0.0758433    0.0103856    0.115979     0.0561762   -0.0372151   -0.0313307     0.0353654   -0.170829     0.0514349
  0.0105418    0.00359994   -0.00111382  -0.015237   -0.036274     0.02417     -0.137772    -0.0420897    0.0323436    -0.0522445   -0.0205238    0.0335368    0.00603158   0.158031     0.219271    -0.0333086   -0.0421549     0.0442472    0.0806099    0.0822995    0.0861904   -0.177963    -0.0485026     0.0743713    0.00904977  -0.0146051
 -0.0420935    0.0104768     0.0586687    0.0874441  -0.0590616   -0.177166    -0.00573777   0.0704062    0.0379849    -0.0218793   -0.0932864   -0.0833951    0.0246256    0.0112729    0.0063776    0.176082     0.173459     -0.0254648   -0.0382055    0.0618259   -0.020938    -0.0376042   -0.0657677    -0.0335691    0.0684232   -0.121069
  0.110224     0.0621179     0.172429    -0.0561576   0.0910925   -0.00370175   0.041571    -0.0486172   -0.142294      0.0544832   -0.159137    -0.071448     0.117948     0.17141      0.0150898   -0.0317247   -0.0136024    -0.080551     0.0285152    0.0184411   -0.0180236    0.0142142   -0.10333       0.0330808    0.245099     0.0648232
 -0.0724604    0.156365     -0.195632     0.0433412   0.0156701   -0.148428    -0.0148995   -0.149598    -0.0303662     0.0775898    0.00276226   0.0228671    0.244641     0.0897805    0.00542022  -0.205579     0.145295      0.0581777    0.0505202    0.0396321    0.0493101    0.0332974   -0.0780016     0.0445188    0.0763767    0.129613
 -0.00728133   0.0171246     0.0210087    0.0390832  -0.144263     0.0771143    0.12927      0.0358034   -0.0489136     0.0258794    0.0805306   -0.131024    -0.0629732    0.00176265   0.191667     0.00327842  -0.0333973    -0.0390833   -0.0892114   -0.150722    -0.157586     0.0341196   -0.0666815    -0.0653264   -0.110777     0.0823879
  0.106594     0.00939531    0.0955006   -0.0380088   0.0179011   -0.0513261   -0.0555522    0.0298419    0.20581       0.037263     3.21576e-5  -0.0117383   -0.0380484   -0.0842389    0.00483591  -0.0177376    0.0209632     0.122257    -0.0169898   -0.0112433    0.0421319    0.00496936  -0.0285793    -0.0721986   -0.0240326   -0.135351
 -0.0216094   -0.00424025    0.0440304   -0.0109348  -0.0200759   -0.18802     -0.0723023   -0.0903268    0.0521146     0.0561043    0.058061     0.02098     -0.00581048   0.0520777    0.100306    -0.0713645   -0.000860584   0.0589195    0.083409     0.198873     0.193682     0.178594     0.0110288    -0.143532     0.11268      0.0150005
 -0.174931    -0.0774587    -0.0939404   -0.10598     0.0626725   -0.0701399    0.0258503    0.0235325    0.000681586   0.0256692    0.0760665    0.0927816    0.217559    -0.0452623    0.133762     0.0367077   -0.124157      0.0381892   -0.0419897    0.0547981   -0.0628501    0.0133931    0.124205     -0.0249161   -0.077331    -0.0898299
 -0.0561341    0.0764129    -0.143706    -0.068067    0.0210582    0.209864    -0.318577     0.0802129   -0.0689006    -0.0710596    0.154363     0.0145725    0.112676     0.136456    -0.181104    -0.0357768   -0.0462571    -0.0296848   -0.00949302  -0.0629029   -0.104554     0.098944     0.0275369     0.0742659    0.0240841    0.111183
  0.0578718    0.0851114    -0.131763     0.141758    0.0153016   -0.206691    -0.0693799   -0.0491769    0.0057181     0.0826612    0.0216472   -0.0282394   -0.197236     0.0146084    0.0410284   -0.0337934    0.0780293     0.0994658   -0.0335127   -0.155493     0.153408     0.0703317   -0.131707     -0.0979148   -0.0463716    0.157162
  0.00926661  -0.09072      -0.103971     0.153647    0.0962186    0.0122882    0.0297926    0.10385      0.0722987    -0.0358519    0.0997505    0.114084     0.176015     0.0230254   -0.355494     0.148663    -0.0358946    -0.0281191   -0.0663726   -0.0818859    0.0163551    0.130778    -0.154958      0.0494578   -0.0203015    0.00556959
 -0.148915    -0.121939     -0.137571    -0.0409122  -0.127455    -0.145079     0.0380123   -0.0704651    0.0197959    -0.0949983    0.0593206    0.0487293   -0.0661447   -0.0104805    0.248643    -0.0176109    0.0563962     0.10624      0.00474247  -0.11782      0.277992    -0.145501    -0.0562304    -0.247338     0.107111    -0.0183376
  0.0108425   -0.0296986    -0.0399114    0.0082275   0.0516054   -0.159126    -0.142564     0.217911    -0.00658939   -0.0203647    0.0293879   -0.0774936    0.0727869    0.116218     0.0685763    0.0252353    0.110149      0.0237099    0.0831227   -0.0873427    0.0772273    0.0754402    0.0457584    -0.132492     0.0942449    0.20448kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4286293518252624
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.428650
[ Info: iteration 2, average log likelihood -1.428599
[ Info: iteration 3, average log likelihood -1.428564
[ Info: iteration 4, average log likelihood -1.428521
[ Info: iteration 5, average log likelihood -1.428466
[ Info: iteration 6, average log likelihood -1.428393
[ Info: iteration 7, average log likelihood -1.428293
[ Info: iteration 8, average log likelihood -1.428144
[ Info: iteration 9, average log likelihood -1.427892
[ Info: iteration 10, average log likelihood -1.427434
[ Info: iteration 11, average log likelihood -1.426639
[ Info: iteration 12, average log likelihood -1.425538
[ Info: iteration 13, average log likelihood -1.424477
[ Info: iteration 14, average log likelihood -1.423789
[ Info: iteration 15, average log likelihood -1.423455
[ Info: iteration 16, average log likelihood -1.423313
[ Info: iteration 17, average log likelihood -1.423254
[ Info: iteration 18, average log likelihood -1.423228
[ Info: iteration 19, average log likelihood -1.423217
[ Info: iteration 20, average log likelihood -1.423212
[ Info: iteration 21, average log likelihood -1.423210
[ Info: iteration 22, average log likelihood -1.423208
[ Info: iteration 23, average log likelihood -1.423208
[ Info: iteration 24, average log likelihood -1.423207
[ Info: iteration 25, average log likelihood -1.423207
[ Info: iteration 26, average log likelihood -1.423206
[ Info: iteration 27, average log likelihood -1.423206
[ Info: iteration 28, average log likelihood -1.423206
[ Info: iteration 29, average log likelihood -1.423205
[ Info: iteration 30, average log likelihood -1.423205
[ Info: iteration 31, average log likelihood -1.423205
[ Info: iteration 32, average log likelihood -1.423205
[ Info: iteration 33, average log likelihood -1.423205
[ Info: iteration 34, average log likelihood -1.423204
[ Info: iteration 35, average log likelihood -1.423204
[ Info: iteration 36, average log likelihood -1.423204
[ Info: iteration 37, average log likelihood -1.423204
[ Info: iteration 38, average log likelihood -1.423204
[ Info: iteration 39, average log likelihood -1.423204
[ Info: iteration 40, average log likelihood -1.423204
[ Info: iteration 41, average log likelihood -1.423204
[ Info: iteration 42, average log likelihood -1.423204
[ Info: iteration 43, average log likelihood -1.423204
[ Info: iteration 44, average log likelihood -1.423204
[ Info: iteration 45, average log likelihood -1.423204
[ Info: iteration 46, average log likelihood -1.423204
[ Info: iteration 47, average log likelihood -1.423203
[ Info: iteration 48, average log likelihood -1.423203
[ Info: iteration 49, average log likelihood -1.423203
[ Info: iteration 50, average log likelihood -1.423203
┌ Info: EM with 100000 data points 50 iterations avll -1.423203
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4286495608145349
│     -1.42859866533498
│      ⋮
└     -1.423203401824748
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423220
[ Info: iteration 2, average log likelihood -1.423165
[ Info: iteration 3, average log likelihood -1.423120
[ Info: iteration 4, average log likelihood -1.423064
[ Info: iteration 5, average log likelihood -1.422990
[ Info: iteration 6, average log likelihood -1.422895
[ Info: iteration 7, average log likelihood -1.422783
[ Info: iteration 8, average log likelihood -1.422662
[ Info: iteration 9, average log likelihood -1.422544
[ Info: iteration 10, average log likelihood -1.422440
[ Info: iteration 11, average log likelihood -1.422352
[ Info: iteration 12, average log likelihood -1.422283
[ Info: iteration 13, average log likelihood -1.422230
[ Info: iteration 14, average log likelihood -1.422189
[ Info: iteration 15, average log likelihood -1.422158
[ Info: iteration 16, average log likelihood -1.422133
[ Info: iteration 17, average log likelihood -1.422114
[ Info: iteration 18, average log likelihood -1.422098
[ Info: iteration 19, average log likelihood -1.422084
[ Info: iteration 20, average log likelihood -1.422072
[ Info: iteration 21, average log likelihood -1.422061
[ Info: iteration 22, average log likelihood -1.422052
[ Info: iteration 23, average log likelihood -1.422043
[ Info: iteration 24, average log likelihood -1.422036
[ Info: iteration 25, average log likelihood -1.422028
[ Info: iteration 26, average log likelihood -1.422022
[ Info: iteration 27, average log likelihood -1.422015
[ Info: iteration 28, average log likelihood -1.422009
[ Info: iteration 29, average log likelihood -1.422004
[ Info: iteration 30, average log likelihood -1.421998
[ Info: iteration 31, average log likelihood -1.421993
[ Info: iteration 32, average log likelihood -1.421988
[ Info: iteration 33, average log likelihood -1.421983
[ Info: iteration 34, average log likelihood -1.421978
[ Info: iteration 35, average log likelihood -1.421973
[ Info: iteration 36, average log likelihood -1.421968
[ Info: iteration 37, average log likelihood -1.421963
[ Info: iteration 38, average log likelihood -1.421958
[ Info: iteration 39, average log likelihood -1.421953
[ Info: iteration 40, average log likelihood -1.421948
[ Info: iteration 41, average log likelihood -1.421943
[ Info: iteration 42, average log likelihood -1.421937
[ Info: iteration 43, average log likelihood -1.421931
[ Info: iteration 44, average log likelihood -1.421925
[ Info: iteration 45, average log likelihood -1.421919
[ Info: iteration 46, average log likelihood -1.421913
[ Info: iteration 47, average log likelihood -1.421906
[ Info: iteration 48, average log likelihood -1.421899
[ Info: iteration 49, average log likelihood -1.421892
[ Info: iteration 50, average log likelihood -1.421884
┌ Info: EM with 100000 data points 50 iterations avll -1.421884
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4232196981116192
│     -1.42316536419179
│      ⋮
└     -1.4218841220372203
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421891
[ Info: iteration 2, average log likelihood -1.421839
[ Info: iteration 3, average log likelihood -1.421801
[ Info: iteration 4, average log likelihood -1.421759
[ Info: iteration 5, average log likelihood -1.421710
[ Info: iteration 6, average log likelihood -1.421653
[ Info: iteration 7, average log likelihood -1.421585
[ Info: iteration 8, average log likelihood -1.421508
[ Info: iteration 9, average log likelihood -1.421424
[ Info: iteration 10, average log likelihood -1.421336
[ Info: iteration 11, average log likelihood -1.421247
[ Info: iteration 12, average log likelihood -1.421162
[ Info: iteration 13, average log likelihood -1.421082
[ Info: iteration 14, average log likelihood -1.421008
[ Info: iteration 15, average log likelihood -1.420941
[ Info: iteration 16, average log likelihood -1.420879
[ Info: iteration 17, average log likelihood -1.420823
[ Info: iteration 18, average log likelihood -1.420770
[ Info: iteration 19, average log likelihood -1.420721
[ Info: iteration 20, average log likelihood -1.420675
[ Info: iteration 21, average log likelihood -1.420632
[ Info: iteration 22, average log likelihood -1.420592
[ Info: iteration 23, average log likelihood -1.420555
[ Info: iteration 24, average log likelihood -1.420521
[ Info: iteration 25, average log likelihood -1.420490
[ Info: iteration 26, average log likelihood -1.420462
[ Info: iteration 27, average log likelihood -1.420437
[ Info: iteration 28, average log likelihood -1.420414
[ Info: iteration 29, average log likelihood -1.420393
[ Info: iteration 30, average log likelihood -1.420373
[ Info: iteration 31, average log likelihood -1.420355
[ Info: iteration 32, average log likelihood -1.420338
[ Info: iteration 33, average log likelihood -1.420322
[ Info: iteration 34, average log likelihood -1.420306
[ Info: iteration 35, average log likelihood -1.420291
[ Info: iteration 36, average log likelihood -1.420277
[ Info: iteration 37, average log likelihood -1.420262
[ Info: iteration 38, average log likelihood -1.420249
[ Info: iteration 39, average log likelihood -1.420235
[ Info: iteration 40, average log likelihood -1.420222
[ Info: iteration 41, average log likelihood -1.420209
[ Info: iteration 42, average log likelihood -1.420197
[ Info: iteration 43, average log likelihood -1.420184
[ Info: iteration 44, average log likelihood -1.420172
[ Info: iteration 45, average log likelihood -1.420160
[ Info: iteration 46, average log likelihood -1.420148
[ Info: iteration 47, average log likelihood -1.420137
[ Info: iteration 48, average log likelihood -1.420125
[ Info: iteration 49, average log likelihood -1.420114
[ Info: iteration 50, average log likelihood -1.420103
┌ Info: EM with 100000 data points 50 iterations avll -1.420103
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4218914250441284
│     -1.4218390409980821
│      ⋮
└     -1.4201031993031266
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420102
[ Info: iteration 2, average log likelihood -1.420040
[ Info: iteration 3, average log likelihood -1.419984
[ Info: iteration 4, average log likelihood -1.419922
[ Info: iteration 5, average log likelihood -1.419848
[ Info: iteration 6, average log likelihood -1.419760
[ Info: iteration 7, average log likelihood -1.419658
[ Info: iteration 8, average log likelihood -1.419543
[ Info: iteration 9, average log likelihood -1.419421
[ Info: iteration 10, average log likelihood -1.419297
[ Info: iteration 11, average log likelihood -1.419177
[ Info: iteration 12, average log likelihood -1.419064
[ Info: iteration 13, average log likelihood -1.418961
[ Info: iteration 14, average log likelihood -1.418869
[ Info: iteration 15, average log likelihood -1.418788
[ Info: iteration 16, average log likelihood -1.418717
[ Info: iteration 17, average log likelihood -1.418656
[ Info: iteration 18, average log likelihood -1.418602
[ Info: iteration 19, average log likelihood -1.418555
[ Info: iteration 20, average log likelihood -1.418514
[ Info: iteration 21, average log likelihood -1.418477
[ Info: iteration 22, average log likelihood -1.418443
[ Info: iteration 23, average log likelihood -1.418412
[ Info: iteration 24, average log likelihood -1.418383
[ Info: iteration 25, average log likelihood -1.418356
[ Info: iteration 26, average log likelihood -1.418330
[ Info: iteration 27, average log likelihood -1.418305
[ Info: iteration 28, average log likelihood -1.418281
[ Info: iteration 29, average log likelihood -1.418258
[ Info: iteration 30, average log likelihood -1.418236
[ Info: iteration 31, average log likelihood -1.418215
[ Info: iteration 32, average log likelihood -1.418195
[ Info: iteration 33, average log likelihood -1.418176
[ Info: iteration 34, average log likelihood -1.418158
[ Info: iteration 35, average log likelihood -1.418141
[ Info: iteration 36, average log likelihood -1.418125
[ Info: iteration 37, average log likelihood -1.418110
[ Info: iteration 38, average log likelihood -1.418096
[ Info: iteration 39, average log likelihood -1.418083
[ Info: iteration 40, average log likelihood -1.418071
[ Info: iteration 41, average log likelihood -1.418060
[ Info: iteration 42, average log likelihood -1.418049
[ Info: iteration 43, average log likelihood -1.418039
[ Info: iteration 44, average log likelihood -1.418030
[ Info: iteration 45, average log likelihood -1.418021
[ Info: iteration 46, average log likelihood -1.418013
[ Info: iteration 47, average log likelihood -1.418006
[ Info: iteration 48, average log likelihood -1.417999
[ Info: iteration 49, average log likelihood -1.417993
[ Info: iteration 50, average log likelihood -1.417986
┌ Info: EM with 100000 data points 50 iterations avll -1.417986
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4201023076168764
│     -1.4200396198184941
│      ⋮
└     -1.4179863936100259
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417990
[ Info: iteration 2, average log likelihood -1.417923
[ Info: iteration 3, average log likelihood -1.417859
[ Info: iteration 4, average log likelihood -1.417785
[ Info: iteration 5, average log likelihood -1.417691
[ Info: iteration 6, average log likelihood -1.417574
[ Info: iteration 7, average log likelihood -1.417431
[ Info: iteration 8, average log likelihood -1.417268
[ Info: iteration 9, average log likelihood -1.417094
[ Info: iteration 10, average log likelihood -1.416921
[ Info: iteration 11, average log likelihood -1.416760
[ Info: iteration 12, average log likelihood -1.416618
[ Info: iteration 13, average log likelihood -1.416495
[ Info: iteration 14, average log likelihood -1.416390
[ Info: iteration 15, average log likelihood -1.416301
[ Info: iteration 16, average log likelihood -1.416225
[ Info: iteration 17, average log likelihood -1.416158
[ Info: iteration 18, average log likelihood -1.416099
[ Info: iteration 19, average log likelihood -1.416047
[ Info: iteration 20, average log likelihood -1.416000
[ Info: iteration 21, average log likelihood -1.415957
[ Info: iteration 22, average log likelihood -1.415919
[ Info: iteration 23, average log likelihood -1.415884
[ Info: iteration 24, average log likelihood -1.415851
[ Info: iteration 25, average log likelihood -1.415821
[ Info: iteration 26, average log likelihood -1.415794
[ Info: iteration 27, average log likelihood -1.415768
[ Info: iteration 28, average log likelihood -1.415744
[ Info: iteration 29, average log likelihood -1.415721
[ Info: iteration 30, average log likelihood -1.415700
[ Info: iteration 31, average log likelihood -1.415680
[ Info: iteration 32, average log likelihood -1.415661
[ Info: iteration 33, average log likelihood -1.415644
[ Info: iteration 34, average log likelihood -1.415627
[ Info: iteration 35, average log likelihood -1.415611
[ Info: iteration 36, average log likelihood -1.415595
[ Info: iteration 37, average log likelihood -1.415581
[ Info: iteration 38, average log likelihood -1.415567
[ Info: iteration 39, average log likelihood -1.415553
[ Info: iteration 40, average log likelihood -1.415541
[ Info: iteration 41, average log likelihood -1.415528
[ Info: iteration 42, average log likelihood -1.415517
[ Info: iteration 43, average log likelihood -1.415505
[ Info: iteration 44, average log likelihood -1.415495
[ Info: iteration 45, average log likelihood -1.415484
[ Info: iteration 46, average log likelihood -1.415474
[ Info: iteration 47, average log likelihood -1.415464
[ Info: iteration 48, average log likelihood -1.415455
[ Info: iteration 49, average log likelihood -1.415445
[ Info: iteration 50, average log likelihood -1.415436
┌ Info: EM with 100000 data points 50 iterations avll -1.415436
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4179902802459958
│     -1.417923130247665
│      ⋮
└     -1.4154362528426836
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4286293518252624
│     -1.4286495608145349
│     -1.42859866533498
│     -1.4285639944618131
│      ⋮
│     -1.4154545376353131
│     -1.4154452737308705
└     -1.4154362528426836
32×26 Array{Float64,2}:
  0.306056    0.492833   -0.300266    -0.140982    0.100337    0.267633    -0.0189561  -0.957836    -0.38043      0.0791697  -0.344963   -0.0669249   0.122815    -0.344929     0.353423    0.261819     0.173667     0.0114564   0.77545      0.0179043  -0.127168    0.450016    -0.414208    -0.567005     0.333238     0.350098
  0.71827     0.120727   -0.0526727   -0.620343    0.277152   -0.0306061    0.181587    0.450532    -0.225352     0.46088    -0.274332   -0.135003    0.0587071    0.187981     0.606156   -0.184887    -0.107587     0.145309    0.434617     0.412265    0.585892    0.211078     0.466449    -0.214462     0.00106366   0.0348018
  0.262997    0.441878   -0.335403     0.611855    0.552663   -0.00172243  -0.200832    0.124292    -0.67263      0.0717893  -0.288191   -0.267555   -0.133544    -0.330413    -0.46852     0.0461207    0.0894274   -1.01228     0.199768    -0.390329    0.0529384  -0.788619    -0.14423     -0.027811    -0.197435     0.0456555
 -0.313497    0.578175   -0.492771     0.106881    0.213514    0.33901      0.442403    0.212808     0.0355732   -0.0115176  -0.0593895   0.0247519  -0.759115    -0.0507742    0.409093   -0.021328     0.214808     0.449763   -0.0921013   -0.209837   -0.341342   -0.918386    -0.0837651   -0.186118    -0.272504    -0.0804231
 -0.296475    0.345737    0.330723    -0.337813    0.531521   -0.0659704   -0.683143   -0.114125    -0.374937    -0.31993    -0.354318    0.130636   -0.467656    -0.390153     0.0721935  -0.316322    -0.298409    -0.371842    0.197883     0.279482    0.147559   -0.587196     0.173804     0.38296      0.391325    -0.282263
  0.446058   -0.266297    0.255387    -0.103121   -0.281007   -0.86573     -0.241778   -0.54353      0.0785217   -0.416597    0.485646   -0.535778   -0.0342207    0.173015     0.0303102   0.693722    -0.188318    -0.578724    0.266667     0.327095    0.66782     0.421532     0.142571     0.229618     0.0508578   -0.515724
  0.0762972   0.0172133  -0.0348433    0.125599   -0.0905886   0.0619571   -0.0321881  -0.00433614  -0.384412     0.341329   -0.219296   -0.166736    0.00182464  -0.12658      0.0527052   0.154216    -0.062906     0.125005    0.293654     0.0359578  -0.0444412  -0.0373765   -0.183621     0.00700795   0.282006     0.168867
 -0.216118   -0.113956    0.0351181    0.11424     0.27835    -0.0158144   -0.220532    0.0503925    0.65562     -0.232842    0.311057    0.368281   -0.055443     0.313107     0.0439715  -0.103304     0.370252     0.0449071  [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
-0.35         0.214137   -0.0574297  -0.129649     0.22643     -0.00573657  -0.464527    -0.292699
 -0.71397     0.332945   -0.0281486   -0.138929   -0.103039   -1.20021      0.339703    0.147805    -0.331559     0.247965    0.477655   -0.234562   -0.334142     0.3153       0.914517   -0.25951     -0.00790985   0.407242   -0.314102     0.139391   -0.385669    0.328303     0.284315     0.298473    -0.128617     0.296176
 -0.624885    0.427966   -0.0874846   -0.130132   -0.110206    0.467592     0.0594131   0.391352     0.215305     0.254797    0.155486    0.157824    0.132438    -0.137292     0.682355   -0.270826    -0.32644      0.711734   -0.11901      0.484115   -0.15676    -0.0332281   -0.185639     0.212436    -0.091313     0.500291
  0.0907834  -0.146986    0.0506351    0.482408   -0.30183    -0.048422     0.211848    0.475487     0.148586     0.0229462   0.262969    0.586226    0.19744      0.636831    -0.0554638   0.230405    -1.09132      0.156916   -0.39693     -0.193681    0.173042   -0.0654101    0.222659    -0.199715    -0.17707      0.595226
 -0.405769    0.421779    0.28084      0.530721    0.233522   -0.260231     0.205691    0.172333     0.260561     0.131899   -0.214911    0.122906   -0.987873     0.552726    -0.42746     0.173771    -0.530795    -0.180233    0.390057    -0.104658   -0.109858    0.251572    -0.0464673    0.430609     0.559897     0.975901
 -0.137179    0.181841   -0.770836    -0.432813   -0.435251   -0.216814     0.297139    0.247552    -0.287985     0.0284721  -0.197062   -0.419282    0.984326    -0.0835342    0.320473    0.128013     0.174042    -0.234133   -0.454321    -0.272764    0.230284    0.0758355   -0.301468    -1.18982     -0.441734    -0.0451578
  0.212857    0.243129   -0.0596164   -0.575786   -0.680479   -0.0751211   -0.0316634   0.168332     0.765415     0.0514794   0.093005    0.0475915   0.521429    -0.221397     1.13875    -0.170803     0.723205    -0.10088    -0.674625    -0.500016   -0.0502997   0.258281    -0.0138537   -0.632926    -0.478963    -0.281794
  0.121193   -0.666559    0.129284     0.488188   -0.797209    0.00510412   0.416531   -0.166044     0.273255     0.0052705   0.0641956  -0.0803183   0.361964    -0.00469161  -0.304581   -0.918972     0.387612     0.130252   -0.434085    -0.0454599   0.0281747   0.599787    -0.392941    -0.156262    -0.144013     0.379708
  0.23731    -0.192325   -0.320062     0.156425   -0.431184    0.258729     0.804006   -0.0338921   -0.0336123    0.17772     0.268873   -0.058079    0.290935     0.577338    -0.246485    0.242763     0.648479     0.589067    0.0299006   -0.192356   -0.388784    0.602224    -0.139373     0.109336    -0.23881      0.0892876
  0.134531   -0.529956    0.00191728  -0.0296023   0.304336    0.0707024   -0.490136    0.318418     0.183725    -0.0365225  -0.114722    0.426647    0.332215     0.136597    -0.478666   -0.441103     0.247406    -0.645549    0.00967352   0.224053    0.2689      0.206266     0.395573    -0.00346573  -0.398854    -0.465086
  0.204649   -0.606134    0.153651     0.0753691  -0.326519    0.00818215  -0.83503    -0.17879     -0.162974     0.137055   -0.0314151   0.197907    0.104257     0.332817    -0.352506    0.479057    -0.24971     -0.424564    0.402836     0.208628    0.0970106   0.126891     0.0211048   -0.109781     0.375268    -0.211141
 -0.0263255  -0.0805155  -0.222232     0.272962    0.446389   -0.0092921    0.443594   -0.354568    -0.102073    -0.016989   -1.19362     0.348163   -0.272651     0.651503    -0.704083   -0.116355     0.109067    -0.249668    0.134476     0.0578376   0.685106    0.207463    -0.00775006  -0.392382     0.0411038   -0.317818
  0.264297   -0.522642    0.0275901    0.772113    0.188697   -0.18823      0.163377   -0.675859    -0.166235    -0.417121   -0.12529     0.43792     0.0455749    0.277908    -0.820192   -0.0317882    0.217585    -0.157456    0.455156    -0.392126   -0.160575    0.84985      0.341046     0.00967604   0.142093    -0.0303167
 -0.0481404   0.0627934   0.196803    -0.239245    0.178116    0.0384887    0.403845    0.375741    -0.573788    -0.570137    0.05496    -0.091292   -0.508157    -0.0328431   -0.625605    0.295715     0.245799    -0.169198   -0.206402    -0.725695    0.576132   -0.322561    -0.182508    -0.692524    -0.0361647   -0.474477
 -0.506348   -0.373435    0.326688     0.304286   -0.0621935  -0.326761    -0.0308734   0.517654     0.0970191   -0.244765    0.405304   -0.21796    -0.0292824    0.341108    -0.602483   -0.346349     0.0554002    0.101409   -0.852752    -0.153866    0.160498   -0.334116    -0.164026     0.53798     -0.193077    -0.17076
  0.0480389  -0.0612317   0.049664    -0.875642   -0.626416    0.389319    -0.152784   -0.333159     0.558915    -0.988184    0.187316    0.254516    0.271459     0.19102     -0.522378   -0.148979    -0.389608    -0.0137003   0.433488    -0.236091    0.570097    0.406173    -0.0923296   -0.244806    -0.330477     0.150263
  0.946486    0.227847    0.0590218    0.375714    0.493261    0.711861     0.232402    0.256975     0.477244    -0.555798    0.410442   -0.135999    0.577045    -0.327817    -0.383045   -0.00692819  -0.167318     0.250101   -0.215927     0.0324387   0.462267   -0.507377    -0.0862326   -0.109175     0.310981     0.365757
 -0.203596    0.27422    -0.185791     0.284398   -0.281506   -0.167115     0.124064   -0.229963    -0.401116    -0.35383     0.130221   -0.426983   -0.0933464    0.0577539   -0.362412    0.0283508   -0.211147     0.245457   -0.129719    -0.230753    0.0242955   0.161424    -0.338826     0.0567911    0.306332     0.339655
 -0.158984    0.182219   -0.0261792    0.0310352  -0.287893   -0.00424582   0.134213   -0.0287621    0.269149     0.134417    0.170161    0.226512    0.198587     0.0995267    0.223832    0.118779     0.0111588    0.142667   -0.0946625   -0.184408   -0.299865    0.172181    -0.0149738   -0.0324022   -0.156651     0.365446
  0.248048   -0.0265211  -0.166346    -0.100348    0.0811338   0.0940553    0.0771874   0.0201597   -0.103051    -0.112874   -0.0549056  -0.0778933   0.0581081    0.0551038   -0.040022    0.0158484    0.0170603   -0.0660443   0.0132154   -0.0246531   0.195574   -0.112467    -0.103385    -0.345285    -0.038172    -0.223568
 -0.195345   -0.0198296   0.294714     0.0267393   0.207044   -0.17834     -0.11337     0.0299218    0.100397     0.0926642  -0.0782142   0.093829   -0.235497    -0.0261003    0.0331554  -0.267472    -0.0207361    0.0159371   0.0481007    0.18738     0.161657    0.00482223   0.0834162    0.365556    -0.0185102   -0.0371399
 -0.463816   -0.376477    0.0985089   -0.0703102  -0.138433   -0.475017    -0.527657   -0.281552    -0.0321192    0.507015   -0.279929    0.087885   -0.597686     0.0379361    0.502755    0.0865472    0.380395     0.0126792   0.0391939    0.204354   -0.337411    0.0814037    0.152857     0.122568     0.0820007   -0.416421
 -0.162814   -0.351791   -0.171206     0.0196323   0.319046   -0.0845915   -0.305916   -0.14457      0.0249104    0.596526   -0.321022    0.238801    0.962689    -0.225564     0.532878    0.176057     0.209343     0.0118171  -0.266172     0.641053   -0.475566    0.0558069    0.056628     0.24558     -0.139695    -0.596131
  0.24207    -0.334437    0.187156    -0.24384    -0.766783   -0.102327    -0.135459    0.315933    -0.183133     0.0779817   0.458106   -0.420821    0.368303    -0.885319     0.548396   -0.458689    -0.117348    -0.0602845   0.227147     0.28572    -0.158777   -0.517106    -0.518088     0.331041     0.217186    -0.0289554
  0.301029    0.10817     0.119532    -0.132676    0.32963    -0.0543209   -0.162418    0.423856     0.00683835   0.239856    0.506404   -0.414149    0.153035    -0.557016     0.614249    0.0698395    0.452333     0.10985    -0.175901     0.151209   -0.334757   -0.248968     0.130495     0.19259      0.0942393   -0.0189449[ Info: iteration 1, average log likelihood -1.415427
[ Info: iteration 2, average log likelihood -1.415419
[ Info: iteration 3, average log likelihood -1.415410
[ Info: iteration 4, average log likelihood -1.415402
[ Info: iteration 5, average log likelihood -1.415394
[ Info: iteration 6, average log likelihood -1.415386
[ Info: iteration 7, average log likelihood -1.415378
[ Info: iteration 8, average log likelihood -1.415370
[ Info: iteration 9, average log likelihood -1.415363
[ Info: iteration 10, average log likelihood -1.415355
┌ Info: EM with 100000 data points 10 iterations avll -1.415355
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind full, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.261387e+05
      1       7.102917e+05      -2.158470e+05 |       32
      2       6.977846e+05      -1.250709e+04 |       32
      3       6.929115e+05      -4.873129e+03 |       32
      4       6.903770e+05      -2.534476e+03 |       32
      5       6.887731e+05      -1.603851e+03 |       32
      6       6.875708e+05      -1.202338e+03 |       32
      7       6.865824e+05      -9.884542e+02 |       32
      8       6.857717e+05      -8.106323e+02 |       32
      9       6.851264e+05      -6.452865e+02 |       32
     10       6.845496e+05      -5.767932e+02 |       32
     11       6.840540e+05      -4.956131e+02 |       32
     12       6.836339e+05      -4.201013e+02 |       32
     13       6.832765e+05      -3.574654e+02 |       32
     14       6.829415e+05      -3.349324e+02 |       32
     15       6.826286e+05      -3.129340e+02 |       32
     16       6.823343e+05      -2.943312e+02 |       32
     17       6.820649e+05      -2.693335e+02 |       32
     18       6.818174e+05      -2.475820e+02 |       32
     19       6.816100e+05      -2.073517e+02 |       32
     20       6.814225e+05      -1.875004e+02 |       32
     21       6.812439e+05      -1.786120e+02 |       32
     22       6.810723e+05      -1.715910e+02 |       32
     23       6.809286e+05      -1.436538e+02 |       32
     24       6.807922e+05      -1.364472e+02 |       32
     25       6.806673e+05      -1.249396e+02 |       32
     26       6.805579e+05      -1.093764e+02 |       32
     27       6.804488e+05      -1.090506e+02 |       32
     28       6.803514e+05      -9.745891e+01 |       32
     29       6.802622e+05      -8.914094e+01 |       32
     30       6.801842e+05      -7.805861e+01 |       32
     31       6.801102e+05      -7.397107e+01 |       32
     32       6.800407e+05      -6.950714e+01 |       32
     33       6.799703e+05      -7.043447e+01 |       32
     34       6.799070e+05      -6.330507e+01 |       32
     35       6.798520e+05      -5.490312e+01 |       32
     36       6.797985e+05      -5.355615e+01 |       32
     37       6.797520e+05      -4.644247e+01 |       32
     38       6.797108e+05      -4.120238e+01 |       32
     39       6.796749e+05      -3.599619e+01 |       32
     40       6.796410e+05      -3.384751e+01 |       32
     41       6.796088e+05      -3.215899e+01 |       32
     42       6.795821e+05      -2.679122e+01 |       32
     43       6.795594e+05      -2.268373e+01 |       32
     44       6.795385e+05      -2.090592e+01 |       32
     45       6.795221e+05      -1.635357e+01 |       32
     46       6.795054e+05      -1.667769e+01 |       32
     47       6.794913e+05      -1.414702e+01 |       32
     48       6.794780e+05      -1.324919e+01 |       32
     49       6.794645e+05      -1.351781e+01 |       32
     50       6.794515e+05      -1.305528e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 679451.463112715)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.427558
[ Info: iteration 2, average log likelihood -1.422536
[ Info: iteration 3, average log likelihood -1.421209
[ Info: iteration 4, average log likelihood -1.420260
[ Info: iteration 5, average log likelihood -1.419261
[ Info: iteration 6, average log likelihood -1.418279
[ Info: iteration 7, average log likelihood -1.417529
[ Info: iteration 8, average log likelihood -1.417072
[ Info: iteration 9, average log likelihood -1.416809
[ Info: iteration 10, average log likelihood -1.416644
[ Info: iteration 11, average log likelihood -1.416524
[ Info: iteration 12, average log likelihood -1.416428
[ Info: iteration 13, average log likelihood -1.416345
[ Info: iteration 14, average log likelihood -1.416271
[ Info: iteration 15, average log likelihood -1.416203
[ Info: iteration 16, average log likelihood -1.416141
[ Info: iteration 17, average log likelihood -1.416084
[ Info: iteration 18, average log likelihood -1.416031
[ Info: iteration 19, average log likelihood -1.415982
[ Info: iteration 20, average log likelihood -1.415936
[ Info: iteration 21, average log likelihood -1.415893
[ Info: iteration 22, average log likelihood -1.415853
[ Info: iteration 23, average log likelihood -1.415816
[ Info: iteration 24, average log likelihood -1.415781
[ Info: iteration 25, average log likelihood -1.415748
[ Info: iteration 26, average log likelihood -1.415717
[ Info: iteration 27, average log likelihood -1.415687
[ Info: iteration 28, average log likelihood -1.415660
[ Info: iteration 29, average log likelihood -1.415633
[ Info: iteration 30, average log likelihood -1.415608
[ Info: iteration 31, average log likelihood -1.415585
[ Info: iteration 32, average log likelihood -1.415562
[ Info: iteration 33, average log likelihood -1.415541
[ Info: iteration 34, average log likelihood -1.415521
[ Info: iteration 35, average log likelihood -1.415502
[ Info: iteration 36, average log likelihood -1.415484
[ Info: iteration 37, average log likelihood -1.415466
[ Info: iteration 38, average log likelihood -1.415450
[ Info: iteration 39, average log likelihood -1.415434
[ Info: iteration 40, average log likelihood -1.415419
[ Info: iteration 41, average log likelihood -1.415404
[ Info: iteration 42, average log likelihood -1.415390
[ Info: iteration 43, average log likelihood -1.415376
[ Info: iteration 44, average log likelihood -1.415363
[ Info: iteration 45, average log likelihood -1.415350
[ Info: iteration 46, average log likelihood -1.415338
[ Info: iteration 47, average log likelihood -1.415326
[ Info: iteration 48, average log likelihood -1.415315
[ Info: iteration 49, average log likelihood -1.415303
[ Info: iteration 50, average log likelihood -1.415293
┌ Info: EM with 100000 data points 50 iterations avll -1.415293
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.79608      0.824997     0.0263663   -0.469603    0.0119997  -0.625818     0.371263      0.392736   -0.249044     0.394077     0.177123   -0.106316   -0.591889    0.389082    0.474978    -0.282447    -0.204214    0.170786    -0.113454    -0.246329   -0.157056    0.235993    0.309036     0.261683   -0.0368674     0.439546
 -0.319966    -0.443494     0.0523251   -0.178812   -0.321748   -0.427076    -0.862851     -0.360947   -0.273696     0.466408    -0.218399    0.14654    -0.260991    0.123697    0.419196     0.399969     0.137547   -0.115452     0.399366     0.284419   -0.302296    0.331275    0.224006    -0.168468    0.425946     -0.239102
 -0.158447    -0.0827985   -0.307337     0.426659   -0.215745    0.189313     0.631917      0.0406762  -0.171639     0.216986     0.193684    0.0236188  -0.206293    0.135861    0.275134    -0.0915661    0.220117    1.26868     -0.326199     0.0937685  -0.486594    0.249101   -0.179122     0.0034158   0.189561      0.350056
 -0.386999     0.318525    -0.159558     0.365197   -0.14636    -0.00269216   0.00308962   -0.0904859  -0.317938    -0.803965    -0.0471768  -0.557143   -0.365121    0.155898   -0.822496    -0.222351    -0.363958    0.138757    -0.294313    -0.279824    0.287953   -0.463615   -0.492507     0.22119     0.0654038     0.102831
  0.312919     0.727798     0.0769723    0.373609    0.233427    0.354174     0.633706      0.0237554   1.17997     -0.0870035    0.739618    0.27157     0.583444    0.0132755  -0.129248     0.0828176    0.154009    0.277663    -0.0210864   -0.489205   -0.196965   -0.363231   -0.27369      0.164084   -0.284831      0.919652
  0.25278     -0.203841     0.158569    -0.0621065  -0.241832   -1.01625     -0.104234     -0.597774    0.0464971   -0.457905     0.599053   -0.525264   -0.193258    0.208872    0.228648     0.536286    -0.0193789  -0.497732     0.130303     0.229724    0.37704     0.456784    0.296563     0.26759    -0.0401976    -0.501385
 -0.0587833    0.239218    -0.09828     -0.539376    0.336063    0.242515     0.223729      0.327431   -0.108951    -0.374816    -0.312068    0.231674   -0.333144    0.174699   -0.182639     0.154462     0.164347   -0.337338    -0.129227    -0.182536    0.861057   -0.495231    0.0611835   -0.874315   -0.243518     -0.452091
  1.12694     -0.0035771   -0.110755    -0.486982    0.35137    -0.160706     0.0479789     0.372371    0.00402634   0.618603    -0.30563    -0.258095    0.123452    0.147939    0.661873    -0.129946     0.0678539   0.165985     0.589598     0.624249    0.433702    0.499714    0.449563    -0.189738    0.085228      0.0975941
 -0.318279    -0.722775     0.353652     0.370121   -0.174475   -0.30915      0.0986111     0.422895    0.146044    -0.134753     0.304391   -0.0996487   0.117564    0.28885    -0.698164    -0.370337     0.30474     0.00879625  -0.778526    -0.132679    0.221781    0.117255   -0.273022     0.271452   -0.108201     -0.10643
 -0.16158     -0.545697     0.039659    -0.146852   -0.0299038  -0.354154    -0.203171      0.17128    -1.07195      0.122476    -0.272395    0.112938    0.590581   -0.43175     0.595221    -0.398473    -0.360506   -0.168471    -0.353665     0.204635    0.261776   -0.245041   -0.190647    -0.0532602   0.061569     -1.09741
 -0.0799226    0.361976    -0.120098    -0.204095    0.041713    0.00864321  -0.285176      0.240057   -0.0139461   -0.0625438    0.30258    -0.100975    0.115433   -0.387784    0.459986     0.0509023   -0.20116     0.0522382   -0.00768653   0.162232   -0.100751   -0.391656    0.103616     0.0882346  -0.0657152     0.17066
 -0.130977     0.213565     0.12442      0.0451176   0.224041   -0.0545566   -0.281522      0.078266   -0.253529     0.174792    -0.117048   -0.0601988  -0.268194   -0.145255    0.163822     0.0244171   -0.146102   -0.0529106    0.119849     0.0509768  -0.0487797  -0.421116    0.00387944   0.148557    0.170118      0.0394133
  0.284473    -0.342188    -0.23983      0.116482   -0.0303309   0.187482    -0.000152687  -0.0575912   0.245112     0.0953069   -0.31919     0.234545    0.29926     0.257883   -0.178251    -0.141437     0.147002   -0.235144     0.128674     0.150071    0.167639    0.125951    0.15968     -0.261808   -0.269594     -0.31754
  0.295675     0.385252    -0.139602     0.35104     0.381175    0.0232109    0.000338836   0.291229   -0.755822     0.140978    -0.0195302  -0.374602   -0.191523   -0.341168   -0.265461     0.206421     0.305847   -0.699057     0.0449332   -0.889423   -0.0684405  -0.493012   -0.1278      -0.268601    0.0338437     0.0558404
 -0.304486     0.0137967    0.550683     0.0303276   0.496286    0.0457955   -0.250207      0.0169034   0.506456     0.0191964   -0.114945    0.310983   -0.566409   -0.089053    0.19405     -0.546826    -0.0654321   0.0928071    0.11563      0.180622    0.210124   -0.147566    0.207723     0.556806   -0.038517     -0.169717
  0.29051     -0.373779     0.178051    -0.188084   -0.70699    -0.165761    -0.0605513     0.481356   -0.0259238    0.230817     0.47635    -0.617167    0.152452   -0.763965    0.625621    -0.429895    -0.111037   -0.0238169    0.316652     0.249375   -0.136346   -0.456755   -0.449082     0.329523    0.307728      0.264012
 -1.1793      -0.147887    -0.46601      0.304753   -0.641236    0.523664     0.38763      -0.268739   -0.138183    -0.136386    -0.210256    0.855116   -0.327751    0.569739   -0.0467013    0.137517     0.218702   -0.221881     0.118827    -0.628661   -1.11269    -0.401267   -0.438543     0.295802   -0.314656     -0.00488033
 -0.572199    -0.0495599    0.0373801   -0.129214   -0.463373   -0.0415171   -0.0556229     0.201215    0.44394     -0.00412061   0.44401     0.284522    0.382278    0.13654     0.515932    -0.255636    -0.381244    0.623132    -0.250412     0.771218   -0.0633988   0.401913   -0.15592      0.289756   -0.16758       0.308725
  0.101893    -0.597255     0.103305     0.0262901   0.180997   -0.323589    -1.01456       0.19554    -0.208091     0.0561742   -0.204102    0.241664    0.0302402   0.173184   -0.521061    -0.00550917  -0.134804   -0.956904     0.154702     0.261833    0.31988    -0.181549    0.223275     0.162118   -0.128685     -0.303697
  0.118678    -0.0943606    0.0342027    0.442705   -0.270332    0.0160798    0.177016      0.549467    0.151626    -0.0496426    0.234207    0.558199    0.0884656   0.670026   -0.132621     0.186605    -1.05267     0.113786    -0.363268    -0.269766    0.201163   -0.133705    0.245107    -0.21662    -0.193486      0.559794
 -0.377572     0.296692    -0.201926     0.0449718   0.230493   -0.104588    -0.0549127     0.377559    0.373835     0.181422     0.123388   -0.315219   -0.0612929  -0.264464    0.654781    -0.153973     0.713181    0.290026    -0.63796      0.368602   -0.546066   -0.723126    0.0957541    0.0256077  -0.51417      -0.44134
  0.429167    -0.630958    -0.0722818    0.640833   -0.146194   -0.00585928   0.425541     -0.377844    0.0315559   -0.119964    -0.216554    0.221594    0.252208    0.346506   -0.718696    -0.110443     0.569363   -0.154599     0.239708    -0.372772   -0.0203558   0.809474    0.174137    -0.231756   -0.098208     -0.0545036
  0.00458797   0.486529    -0.00882124  -0.40312    -0.0724398   0.302913     0.344178     -0.189753   -0.00891804   0.0869408   -0.120266    0.125871   -0.31138    -0.0636633   0.463608     0.0867835    0.0773069   0.30547      0.326231    -0.225265    0.0554372   0.0116137  -0.285524    -0.436312    0.0346604     0.298223
  0.195508     0.264191    -0.083656    -0.269462    0.293255    0.421448    -0.647768     -0.773309   -0.176063    -0.156214    -0.228108    0.042794    0.360516   -0.582322    0.00105878  -0.0372268    0.500049   -0.190579     0.46929      0.495529   -0.504216   -0.0778048  -0.15803      0.187395    0.156675     -0.43875
  1.08429     -0.00864874   0.0495023    0.21311     0.405994    0.596524     0.0224177     0.390087    0.180815    -0.577361     0.334035   -0.347683    0.531116   -0.458551   -0.243691     0.0580516   -0.0905454   0.161741    -0.240302     0.241139    0.448441   -0.446177    0.105809    -0.242787    0.547955      0.0788634
  0.244559    -0.268657     0.323349    -0.357717   -0.20655     0.258556    -0.241342     -0.56875     0.186218    -0.662882    -0.0322674   0.334604    0.170151    0.21235    -0.815683     0.25001     -0.606012   -0.198798     0.648239    -0.236486    0.774774    0.490019   -0.0760045   -0.0631922   0.118801     -0.0659875
  0.211311     0.464427    -0.593448     0.0684153  -0.288969    0.104835     0.444832     -0.456122   -0.534729    -0.0227695   -0.305602   -0.368524    0.381406   -0.139668    0.0472877    0.116288    -0.0692414   0.132831     0.453642    -0.165908    0.164029    0.500976   -0.547058    -0.595942    0.149227      0.663064
  0.215734    -0.0392353   -0.238261    -0.60812    -0.861718    0.0434564    0.172881      0.103017    0.335723    -0.0663952    0.258036   -0.0720044   0.808674    0.0123592   0.515526    -0.133754     0.567712    0.00291768  -0.571335    -0.559849   -0.012507    0.525193   -0.0496025   -0.662272   -0.52219      -0.116414
 -0.273721     0.224549    -0.0222292    0.783055    0.569737   -0.228417     0.345422     -0.214584   -0.119855     0.034529    -0.49264     0.198415   -0.73699     0.376355   -0.459189     0.190965    -0.39976    -0.0604084    0.459869     0.209536   -0.0567111   0.252175    0.110042     0.26618     0.524924      0.642124
  0.0805191    0.0127249   -0.0963803   -0.0249454   0.49463    -0.196513     0.229782     -0.0218047  -0.387437    -0.00956542  -0.102064   -0.163346   -0.245862    0.067604   -0.0869579   -0.0373401    0.280705    0.00429893   0.0463777    0.124781    0.190687   -0.0853442  -0.100027    -0.0923551  -0.000237154  -0.510576
 -0.102449    -0.150962     0.167999    -0.0703598   0.0954521  -0.100815    -0.131339      0.141066    0.10133      0.776623    -0.0305783   0.174719    0.514367   -0.0173361   0.474387     0.212266     0.182564    0.0351075   -0.285925     0.369597   -0.373724    0.167536    0.0615839    0.350084   -0.0768805    -0.0254681
 -0.100673    -0.0198031    0.0481439    0.127056   -0.248437   -0.150073    -0.0151759    -0.0714934   0.00628481[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
  -0.161126     0.133991   -0.075085    0.0143796   0.130807   -0.198762    -0.0184258   -0.0794293   0.0276554   -0.125737    -0.164598   -0.0116364   0.186621   -0.104254     0.035653    0.0704006     0.210109[ Info: iteration 1, average log likelihood -1.415282
[ Info: iteration 2, average log likelihood -1.415272
[ Info: iteration 3, average log likelihood -1.415262
[ Info: iteration 4, average log likelihood -1.415253
[ Info: iteration 5, average log likelihood -1.415244
[ Info: iteration 6, average log likelihood -1.415236
[ Info: iteration 7, average log likelihood -1.415228
[ Info: iteration 8, average log likelihood -1.415220
[ Info: iteration 9, average log likelihood -1.415212
[ Info: iteration 10, average log likelihood -1.415205
┌ Info: EM with 100000 data points 10 iterations avll -1.415205
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
