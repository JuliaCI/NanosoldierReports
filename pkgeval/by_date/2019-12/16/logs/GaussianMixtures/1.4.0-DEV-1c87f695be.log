Julia Version 1.4.0-DEV.596
Commit 1c87f695be (2019-12-12 22:34 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed OpenBLAS_jll ─────── v0.3.7+1
 Installed Distances ────────── v0.8.2
 Installed FillArrays ───────── v0.8.2
 Installed Compat ───────────── v2.2.0
 Installed NearestNeighbors ─── v0.4.4
 Installed CMake ────────────── v1.1.2
 Installed ScikitLearnBase ──── v0.5.0
 Installed SortingAlgorithms ── v0.3.1
 Installed Rmath ────────────── v0.6.0
 Installed SpecialFunctions ─── v0.9.0
 Installed StatsBase ────────── v0.32.0
 Installed DataStructures ───── v0.17.6
 Installed Clustering ───────── v0.13.3
 Installed Missings ─────────── v0.4.3
 Installed PDMats ───────────── v0.9.10
 Installed URIParser ────────── v0.4.0
 Installed FileIO ───────────── v1.2.0
 Installed BinaryProvider ───── v0.5.8
 Installed StaticArrays ─────── v0.12.1
 Installed Distributions ────── v0.21.11
 Installed QuadGK ───────────── v2.3.1
 Installed LegacyStrings ────── v0.4.1
 Installed Parameters ───────── v0.12.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed DataAPI ──────────── v1.1.0
 Installed JLD ──────────────── v0.9.1
 Installed Blosc ────────────── v0.5.1
 Installed HDF5 ─────────────── v0.12.5
 Installed Arpack ───────────── v0.4.0
 Installed OrderedCollections ─ v1.1.0
 Installed BinDeps ──────────── v1.0.0
 Installed StatsFuns ────────── v0.9.2
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.2
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Testing GaussianMixtures
Status `/tmp/jl_kBOTLY/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.6
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.0
  [1a297f60] FillArrays v0.8.2
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+1
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.2
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
┌ Warning: Replacing docs for `FileIO.filename :: Tuple{Any}` in module `FileIO`
└ @ Base.Docs docs/Docs.jl:223
┌ Warning: Replacing docs for `FileIO.file_extension :: Tuple{Any}` in module `FileIO`
└ @ Base.Docs docs/Docs.jl:223
[ Info: Testing Data
(100000, -520438.27484462474, [47045.39775284904, 52954.60224715096], [-7271.184460715841 34617.20142053488 -13936.241432748884; 7645.2531559786585 -34335.16998170512 13981.86907265219], [[51351.434795320885 2036.8111120591825 4102.526359376037; 2036.8111120591825 49086.71270249744 -1383.9203706927055; 4102.526359376036 -1383.9203706927055 48480.502482503485], [49227.94302124556 -2010.753967055731 -4139.587806412965; -2010.753967055731 50890.439617534066 1112.484585858903; -4139.587806412966 1112.484585858903 51324.39760818387]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.573283e+03
      1       1.147436e+03      -4.258467e+02 |        7
      2       1.125066e+03      -2.237069e+01 |        2
      3       1.104823e+03      -2.024251e+01 |        2
      4       1.100492e+03      -4.330676e+00 |        2
      5       1.098604e+03      -1.888901e+00 |        0
      6       1.098604e+03       0.000000e+00 |        0
K-means converged with 6 iterations (objv = 1098.6035721627022)
┌ Info: K-means with 272 data points using 6 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.075261
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.725580
[ Info: iteration 2, lowerbound -3.582672
[ Info: iteration 3, lowerbound -3.443180
[ Info: iteration 4, lowerbound -3.292713
[ Info: dropping number of Gaussions to 7
[ Info: iteration 5, lowerbound -3.128780
[ Info: iteration 6, lowerbound -2.962610
[ Info: iteration 7, lowerbound -2.819447
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.682652
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.557960
[ Info: iteration 10, lowerbound -2.460216
[ Info: iteration 11, lowerbound -2.393602
[ Info: iteration 12, lowerbound -2.353625
[ Info: dropping number of Gaussions to 3
[ Info: iteration 13, lowerbound -2.324869
[ Info: iteration 14, lowerbound -2.308530
[ Info: dropping number of Gaussions to 2
[ Info: iteration 15, lowerbound -2.303134
[ Info: iteration 16, lowerbound -2.299265
[ Info: iteration 17, lowerbound -2.299258
[ Info: iteration 18, lowerbound -2.299255
[ Info: iteration 19, lowerbound -2.299254
[ Info: iteration 20, lowerbound -2.299254
[ Info: iteration 21, lowerbound -2.299253
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Mon Dec 16 15:13:23 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Mon Dec 16 15:13:31 2019: K-means with 272 data points using 6 iterations
11.3 data points per parameter
, Mon Dec 16 15:13:33 2019: EM with 272 data points 0 iterations avll -2.075261
5.8 data points per parameter
, Mon Dec 16 15:13:35 2019: GMM converted to Variational GMM
, Mon Dec 16 15:13:44 2019: iteration 1, lowerbound -3.725580
, Mon Dec 16 15:13:44 2019: iteration 2, lowerbound -3.582672
, Mon Dec 16 15:13:44 2019: iteration 3, lowerbound -3.443180
, Mon Dec 16 15:13:44 2019: iteration 4, lowerbound -3.292713
, Mon Dec 16 15:13:44 2019: dropping number of Gaussions to 7
, Mon Dec 16 15:13:44 2019: iteration 5, lowerbound -3.128780
, Mon Dec 16 15:13:44 2019: iteration 6, lowerbound -2.962610
, Mon Dec 16 15:13:44 2019: iteration 7, lowerbound -2.819447
, Mon Dec 16 15:13:44 2019: dropping number of Gaussions to 5
, Mon Dec 16 15:13:44 2019: iteration 8, lowerbound -2.682652
, Mon Dec 16 15:13:44 2019: dropping number of Gaussions to 4
, Mon Dec 16 15:13:44 2019: iteration 9, lowerbound -2.557960
, Mon Dec 16 15:13:44 2019: iteration 10, lowerbound -2.460216
, Mon Dec 16 15:13:44 2019: iteration 11, lowerbound -2.393602
, Mon Dec 16 15:13:44 2019: iteration 12, lowerbound -2.353625
, Mon Dec 16 15:13:44 2019: dropping number of Gaussions to 3
, Mon Dec 16 15:13:44 2019: iteration 13, lowerbound -2.324869
, Mon Dec 16 15:13:44 2019: iteration 14, lowerbound -2.308530
, Mon Dec 16 15:13:44 2019: dropping number of Gaussions to 2
, Mon Dec 16 15:13:44 2019: iteration 15, lowerbound -2.303134
, Mon Dec 16 15:13:44 2019: iteration 16, lowerbound -2.299265
, Mon Dec 16 15:13:44 2019: iteration 17, lowerbound -2.299258
, Mon Dec 16 15:13:44 2019: iteration 18, lowerbound -2.299255
, Mon Dec 16 15:13:44 2019: iteration 19, lowerbound -2.299254
, Mon Dec 16 15:13:44 2019: iteration 20, lowerbound -2.299254
, Mon Dec 16 15:13:44 2019: iteration 21, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 22, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 23, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 24, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 25, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 26, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 27, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 28, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 29, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 30, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 31, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 32, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 33, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 34, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 35, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 36, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 37, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 38, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 39, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 40, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 41, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 42, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 43, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 44, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 45, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 46, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 47, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 48, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 49, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: iteration 50, lowerbound -2.299253
, Mon Dec 16 15:13:44 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601382, 95.95490777398616]
β = [178.04509222601382, 95.95490777398616]
m = [4.25030073326991 79.28686694436185; 2.000229257775371 53.85198717246131]
ν = [180.04509222601382, 97.95490777398616]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484455 -0.007644049042327366; 0.0 0.008581705166333562], [0.3758763611948406 -0.008953123827346065; 0.0 0.012748664777409515]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0007603421609605
avll from llpg:  -1.0007603421609605
avll direct:     -1.0007603421609605
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0040854197104057
avll from llpg:  -1.0040854197104057
avll direct:     -1.0040854197104057
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.0684275  -0.170282    0.269884    -0.127558     0.00423214   0.0571007    0.000660304   0.0565951    0.0148249   -0.0914193    0.142584     0.0503147   -0.0421638   -0.121347     0.0772017   0.188171     0.0343784    0.0975617   -0.0601027     0.12702     -0.21001     0.0386491    0.0744199    0.0184436    -0.0517509    0.125962
  0.0575554   0.194916   -0.0455704    0.00390714   0.014902     0.0996355    0.13584      -0.026339    -0.0640521   -0.161024     0.0228119    0.125859     0.0863975   -0.074499    -0.0482377   0.0612788   -0.056694    -0.0532154   -0.235157      0.0610244    0.0133223  -0.276412     0.0949786    0.0101777     0.0529462    0.180173
  0.166802    0.0132938  -0.119003    -0.0473285   -0.0817196   -0.068553     0.213663      0.0441876    0.0492013   -0.108167     0.028824    -0.0701119   -0.0331513   -0.0683115    0.0710487   0.018041     0.123292     0.10247      0.100382      0.0867711   -0.0684338  -0.0663527    0.151233    -0.0152551    -0.102449    -0.0277887
 -0.0786056  -0.0105577  -0.17031      0.095055     0.112712     0.0594251   -0.0415022    -0.112713     0.132174    -0.0177786    0.127113    -0.107058    -0.0797508    0.129781    -0.0273454  -0.00217877   0.105557    -0.074846    -0.146064     -0.0108254    0.0757498  -0.0705444   -0.14849     -0.0734693    -0.0178941    0.0195311
  0.0332436   0.122308   -0.149777    -0.111        0.0629733    0.148196     0.00755491   -0.0943991   -0.108832     0.0487596   -0.167685    -0.0318925    0.172182    -0.0614213   -0.14433    -0.0365891   -0.088035    -0.0174483   -0.0193237     0.0656704    0.0754181   0.193177    -0.04915     -0.142807      0.0345331   -0.00813217
 -0.0427261   0.0774827  -0.141894     0.116124     0.0624901    0.0970325    0.013862     -0.0129349    0.184391    -0.0566028    0.0980629    0.0378227   -0.0702237   -0.173984     0.204091    0.0118668   -0.0203415   -0.150231    -0.044021     -0.0841835    0.128534    0.0627632    0.0828222    0.0508936    -0.0368944   -0.102019
 -0.0367416   0.0182893  -0.0474203   -0.0994034   -0.131018    -0.0776091   -0.0326935     0.0191653    0.0559669   -0.0116411    0.102131    -0.138823     0.078848     0.0613637   -0.0493012  -0.0957096   -0.125766     0.074906     0.139955     -0.130434    -0.108172    0.0376591   -0.141126     0.109846     -0.00812626  -0.0547432
  0.0650155  -0.0226804   0.113654    -0.0790396    0.0183201   -0.0840762   -0.097881      0.0144409    0.0578139    0.0707583    0.0438711   -0.058317     0.212919     0.225508    -0.26068    -0.0735912    0.138113    -0.187918     0.00707507   -0.136948    -0.0103504  -0.0320124   -0.0617713   -0.0822576     0.115113    -0.0244257
  0.0574245  -0.0153018   0.103642    -0.0889859    0.165208    -0.0405052   -0.101078     -0.0318062   -0.0325907   -0.0622617    0.0648221    0.239398    -0.113591     0.0335421    0.0283004   0.105978    -0.0333017    0.11227     -0.0364155    -0.155123     0.0952331  -0.2005      -0.0761176   -0.0383452    -0.0329082   -0.107616
  0.0183993  -0.0904096   0.16255     -0.0560314    0.0799525    0.243894    -0.0230658    -0.0312533    0.192377     0.273646     0.0406398   -0.00115797  -0.06705      0.0215827   -0.137266    0.0457317    0.07495     -0.118345     0.0656885    -0.148203     0.0459094  -0.0922752    0.0100159    0.0232081     0.115669     0.0863878
 -0.0282525   0.200977   -0.0247612   -0.0594464   -0.00783878   0.217344    -0.0354482    -0.0101261   -0.00623301   0.164986     0.0512361   -0.00371882  -0.129476     0.0619451   -0.04302    -0.225318    -0.108748     0.06905     -0.000788449  -0.0531842   -0.0200274   0.00902539   0.030969    -0.111708      0.00111816  -0.128027
  0.122857   -0.132279    0.0562565   -0.0175532   -0.0426772   -0.0797544   -0.113243     -0.161504    -0.15682      0.0655128    0.0822266    0.0256397    0.0805052    0.0248169   -0.125275    0.114689    -0.00620902   0.0700806   -0.0132712    -0.0621139   -0.0634225   0.0384941    0.18734      0.0243166    -0.012903    -0.032033
  0.172588    0.106495    0.0999088   -0.029464     0.00194359   0.031709    -0.208894      0.0249757    0.183801     0.0544244    0.0272136    0.0912181   -0.196734     0.00788889   0.103287   -0.0982921    0.0641839    0.0358792    0.0394154     0.106894    -0.0133602  -0.055074     0.0263469   -0.136779     -0.234848    -0.0742932
 -0.0367227   0.227179   -0.129474     0.0131638   -0.0313455   -0.0635018   -0.163796     -0.0325106   -0.263468    -0.00883243   0.00505731   0.0327362   -0.0366275    0.0409596   -0.0865986  -0.0650017    0.0363258    0.0718119    0.0471131    -0.0461888   -0.0885064  -0.0902589    0.0632222   -0.0766577    -0.0286837   -0.0963513
  0.0235568  -0.145722    0.147299     0.0410889   -0.0607737   -0.160128     0.114033      0.0496792   -0.0568913   -0.0880441    0.118284     0.185227    -0.0294015   -0.0759045    0.109549    0.187472     0.129518    -0.131589     0.190773     -0.00213992   0.0311644  -0.0659683   -0.0503526    0.163834      0.0888085    0.120031
  0.140596    0.217074    0.00334338   0.0694178   -0.0107857   -0.00882216  -0.163835      0.105428    -0.0813509   -0.153895    -0.065984     0.0676358   -0.0124901   -0.150425    -0.0526389   0.170753    -0.0309837    0.0281502    0.105027     -0.098803     0.0775183   0.164646    -0.01428     -0.0539617     0.0548888   -0.0525472
 -0.0948475  -0.128589    0.0717269   -0.0920561    0.0565152    0.0104041    0.115726     -0.173504    -0.025337     0.0568155   -0.0949526   -0.154062    -0.188695    -0.101309    -0.0464277  -0.0289852    0.214108     0.0538364    0.00673171    0.138895     0.0917921  -0.0537006    0.0889991   -0.0654542     0.0381981   -0.11735
 -0.0894925  -0.0864934  -0.0104219   -0.0117793    0.0651351    0.0121106   -0.154007      0.0731824    0.0327807   -0.0240067   -0.0733579   -0.0479526   -0.0196362   -0.0410817    0.118919    0.0753108    0.0586358   -0.0274999   -0.0238503    -0.00216413  -0.0802623   0.0437959    0.121537    -0.0642877     0.00832198   0.0149724
  0.0748251   0.133889    0.104218     0.05986     -0.0379661   -0.0871702   -0.0830199     0.0457041    0.0758263    0.141403     0.00227177   0.0680806    0.3122       0.197373     0.0403159  -0.0817887   -0.123152     0.00482212   0.0928301     0.137773     0.0688625  -0.00580322   0.0120258   -0.00667263   -0.0341213    0.0826309
  0.111175   -0.0839802  -0.156349     0.16428      0.0082418    0.0337872    0.212068     -0.21804      0.0330979   -0.166619    -0.0347714   -0.0775777   -0.191679    -0.00375307  -0.112128    0.0390269    0.168052     0.047783     0.0598334     0.0160259    0.121128   -0.0192577   -0.012157    -0.0627232     0.116678    -0.107588
 -0.0389813   0.0144567   0.0915498   -0.185983     0.0114652    0.114269     0.0276854     0.0350323   -0.159952     0.161997     0.0362876    0.0401438   -0.00192305   0.0572799   -0.0690651  -0.0514724   -0.0674255    0.0344577   -0.23876       0.0150363    0.0167295   0.0651947   -0.06162      0.0400137     0.0413972    0.0467338
 -0.0638092   0.115446    0.0449318    0.190188    -0.202496    -0.0634917   -0.0715101     0.164125    -0.0958702    0.04492     -0.0632691   -0.130299     0.108193     0.0859352    0.0610876   0.075057    -0.0208642    0.0321213    0.0567952    -0.0107106   -0.044863   -0.0674176   -0.00330232  -0.0693734    -0.085585    -0.0150118
 -0.0344859  -0.071341   -0.002084     0.181834     0.00426712   0.108331    -0.0933297    -0.00147637  -0.0130998    0.110868     0.126778    -0.118334     0.0537173   -0.0794539   -0.0454541   0.141501     0.061358    -0.0675799    0.0405019    -0.0865175   -0.0416176  -0.0812417   -0.0687107    0.0602312     0.0423047   -0.0903632
  0.0375524   0.084635   -0.177736     0.012555    -0.098122     0.197008     0.00429415   -0.114289    -0.0748629   -0.0849213    0.00997251   0.0142234   -0.0692139   -0.0832572    0.0392106  -0.0715735    0.0411396   -0.0189589   -0.236014     -0.0875441    0.105896    0.125514    -0.0496193   -0.132834     -0.102137     0.084129
  0.0288885  -0.0521405  -0.074641    -0.178621     0.106875     0.111639    -0.00522805   -0.0228821   -0.0583606   -0.119697     0.0467308    0.0697443    0.0106357    0.0412064    0.0111864  -0.0219575   -0.140622    -0.0551145   -0.0495014     0.0536835   -0.0354561  -0.15425      0.214984     0.0348465    -0.10273     -0.0449854
  0.0231421   0.14097     0.0756061    0.204452     0.0132516   -0.0564755    0.041386      0.0681297    0.122594     0.00729626   0.00790973   0.167731     0.0221823    0.00478341   0.0232269   0.0857935    0.07648     -0.0211504    0.0899435    -0.0506062    0.208436    0.0292823    0.00214584  -0.101939      0.0351857    0.135699
 -0.13599    -0.0672538  -0.0557501   -0.146637     0.0952686   -0.0677596   -0.122724     -0.0942667    0.0369353    0.186295    -0.0305711   -0.0816496    0.17895      0.153223     0.0422007   0.00180428   0.0614204    0.218308    -0.0917437     0.0524446   -0.14291    -0.117895     0.079195     0.000202492  -0.00828556  -0.0716574
  0.142161    0.124905    0.00690631   0.126398    -0.0877403   -0.0104808   -0.143206      0.0731105    0.0810034    0.0484891    0.0896816   -0.0530445   -0.130716    -0.196874    -0.160798    0.0246569    0.0280667    0.0168547    0.0719613    -0.00648589  -0.125968    0.0908287    0.166087    -0.0117087     0.0123798   -0.207618
 -0.128497    0.168796   -0.0831133   -0.0278985    0.148907     0.126657    -0.082253      0.104759    -0.128825    -0.0928996   -0.149604     0.127397    -0.102951    -0.198439     0.0190732  -0.104222     0.0610857   -0.0115466    0.0964536     0.0307423    0.018438   -0.0422525   -0.15978     -0.0254696     0.033442     0.0271438
  0.184786   -0.0839587   0.107753    -0.248013    -0.0561006   -0.166325    -0.194698      0.119639     0.0171829   -0.00715191  -0.0278408   -0.0493955    0.0251432    0.0323538   -0.0982607  -0.0877894    0.0639503    0.00929251  -0.0330401     0.0121718    0.0520989  -0.0888342   -0.0707605   -0.0635065     0.0288587   -0.173413
  0.0605085   0.13515     0.12414      0.0196455   -0.0237712    0.160723     0.0161432     0.0163408   -0.139372    -0.0881865    0.0655837    0.00604094   0.0445921   -0.160697    -0.0995987   0.0233451    0.0637199   -0.00955159   0.0266434     0.0268899   -0.0359213  -0.0226262   -0.0887721    0.0221063     0.145476     0.0573641
 -0.176985    0.138844    0.00907147   0.103039     0.0793608    0.33727      0.172894     -0.231844     0.0458637    0.18276      0.0117865    0.175723    -0.13311     -0.116176     0.0289721   0.0245074    0.0532081    0.0473088   -0.0158225    -0.0177803    0.0831871   0.0733813    0.00852127   0.0402209    -0.143877     0.00254432kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.389967010902839
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.390035
[ Info: iteration 2, average log likelihood -1.389990
[ Info: iteration 3, average log likelihood -1.389895
[ Info: iteration 4, average log likelihood -1.388504
[ Info: iteration 5, average log likelihood -1.378848
[ Info: iteration 6, average log likelihood -1.365441
[ Info: iteration 7, average log likelihood -1.361405
[ Info: iteration 8, average log likelihood -1.360418
[ Info: iteration 9, average log likelihood -1.359851
[ Info: iteration 10, average log likelihood -1.359364
[ Info: iteration 11, average log likelihood -1.358971
[ Info: iteration 12, average log likelihood -1.358659
[ Info: iteration 13, average log likelihood -1.358378
[ Info: iteration 14, average log likelihood -1.358096
[ Info: iteration 15, average log likelihood -1.357801
[ Info: iteration 16, average log likelihood -1.357457
[ Info: iteration 17, average log likelihood -1.356919
[ Info: iteration 18, average log likelihood -1.356216
[ Info: iteration 19, average log likelihood -1.355683
[ Info: iteration 20, average log likelihood -1.355351
[ Info: iteration 21, average log likelihood -1.355118
[ Info: iteration 22, average log likelihood -1.354925
[ Info: iteration 23, average log likelihood -1.354744
[ Info: iteration 24, average log likelihood -1.354554
[ Info: iteration 25, average log likelihood -1.354341
[ Info: iteration 26, average log likelihood -1.354089
[ Info: iteration 27, average log likelihood -1.353805
[ Info: iteration 28, average log likelihood -1.353502
[ Info: iteration 29, average log likelihood -1.353174
[ Info: iteration 30, average log likelihood -1.352828
[ Info: iteration 31, average log likelihood -1.352458
[ Info: iteration 32, average log likelihood -1.352068
[ Info: iteration 33, average log likelihood -1.351719
[ Info: iteration 34, average log likelihood -1.351440
[ Info: iteration 35, average log likelihood -1.351209
[ Info: iteration 36, average log likelihood -1.351013
[ Info: iteration 37, average log likelihood -1.350868
[ Info: iteration 38, average log likelihood -1.350778
[ Info: iteration 39, average log likelihood -1.350723
[ Info: iteration 40, average log likelihood -1.350689
[ Info: iteration 41, average log likelihood -1.350666
[ Info: iteration 42, average log likelihood -1.350650
[ Info: iteration 43, average log likelihood -1.350639
[ Info: iteration 44, average log likelihood -1.350632
[ Info: iteration 45, average log likelihood -1.350626
[ Info: iteration 46, average log likelihood -1.350622
[ Info: iteration 47, average log likelihood -1.350619
[ Info: iteration 48, average log likelihood -1.350617
[ Info: iteration 49, average log likelihood -1.350615
[ Info: iteration 50, average log likelihood -1.350614
┌ Info: EM with 100000 data points 50 iterations avll -1.350614
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3900351190290428
│     -1.389989608353421
│      ⋮
└     -1.350614037622934
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.350713
[ Info: iteration 2, average log likelihood -1.350607
[ Info: iteration 3, average log likelihood -1.350107
[ Info: iteration 4, average log likelihood -1.346274
[ Info: iteration 5, average log likelihood -1.334130
[ Info: iteration 6, average log likelihood -1.321940
[ Info: iteration 7, average log likelihood -1.316477
[ Info: iteration 8, average log likelihood -1.313188
[ Info: iteration 9, average log likelihood -1.310079
[ Info: iteration 10, average log likelihood -1.307556
[ Info: iteration 11, average log likelihood -1.305833
[ Info: iteration 12, average log likelihood -1.304872
[ Info: iteration 13, average log likelihood -1.304410
[ Info: iteration 14, average log likelihood -1.304163
[ Info: iteration 15, average log likelihood -1.304018
[ Info: iteration 16, average log likelihood -1.303926
[ Info: iteration 17, average log likelihood -1.303862
[ Info: iteration 18, average log likelihood -1.303814
[ Info: iteration 19, average log likelihood -1.303777
[ Info: iteration 20, average log likelihood -1.303747
[ Info: iteration 21, average log likelihood -1.303723
[ Info: iteration 22, average log likelihood -1.303703
[ Info: iteration 23, average log likelihood -1.303685
[ Info: iteration 24, average log likelihood -1.303670
[ Info: iteration 25, average log likelihood -1.303656
[ Info: iteration 26, average log likelihood -1.303643
[ Info: iteration 27, average log likelihood -1.303630
[ Info: iteration 28, average log likelihood -1.303618
[ Info: iteration 29, average log likelihood -1.303605
[ Info: iteration 30, average log likelihood -1.303592
[ Info: iteration 31, average log likelihood -1.303579
[ Info: iteration 32, average log likelihood -1.303564
[ Info: iteration 33, average log likelihood -1.303550
[ Info: iteration 34, average log likelihood -1.303535
[ Info: iteration 35, average log likelihood -1.303520
[ Info: iteration 36, average log likelihood -1.303507
[ Info: iteration 37, average log likelihood -1.303494
[ Info: iteration 38, average log likelihood -1.303483
[ Info: iteration 39, average log likelihood -1.303473
[ Info: iteration 40, average log likelihood -1.303464
[ Info: iteration 41, average log likelihood -1.303455
[ Info: iteration 42, average log likelihood -1.303446
[ Info: iteration 43, average log likelihood -1.303438
[ Info: iteration 44, average log likelihood -1.303430
[ Info: iteration 45, average log likelihood -1.303423
[ Info: iteration 46, average log likelihood -1.303416
[ Info: iteration 47, average log likelihood -1.303410
[ Info: iteration 48, average log likelihood -1.303404
[ Info: iteration 49, average log likelihood -1.303400
[ Info: iteration 50, average log likelihood -1.303396
┌ Info: EM with 100000 data points 50 iterations avll -1.303396
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3507128539108522
│     -1.3506068498353514
│      ⋮
└     -1.3033957940754581
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.303519
[ Info: iteration 2, average log likelihood -1.303356
[ Info: iteration 3, average log likelihood -1.302574
[ Info: iteration 4, average log likelihood -1.296713
[ Info: iteration 5, average log likelihood -1.282799
[ Info: iteration 6, average log likelihood -1.273558
[ Info: iteration 7, average log likelihood -1.269368
[ Info: iteration 8, average log likelihood -1.266491
[ Info: iteration 9, average log likelihood -1.264042
[ Info: iteration 10, average log likelihood -1.261909
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.259985
[ Info: iteration 12, average log likelihood -1.266325
[ Info: iteration 13, average log likelihood -1.261869
[ Info: iteration 14, average log likelihood -1.260168
[ Info: iteration 15, average log likelihood -1.258977
[ Info: iteration 16, average log likelihood -1.257934
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.256990
[ Info: iteration 18, average log likelihood -1.264131
[ Info: iteration 19, average log likelihood -1.260386
[ Info: iteration 20, average log likelihood -1.258956
[ Info: iteration 21, average log likelihood -1.257825
[ Info: iteration 22, average log likelihood -1.256790
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.255809
[ Info: iteration 24, average log likelihood -1.263039
[ Info: iteration 25, average log likelihood -1.259050
[ Info: iteration 26, average log likelihood -1.257307
[ Info: iteration 27, average log likelihood -1.255854
[ Info: iteration 28, average log likelihood -1.254522
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.253186
[ Info: iteration 30, average log likelihood -1.259889
[ Info: iteration 31, average log likelihood -1.255276
[ Info: iteration 32, average log likelihood -1.253323
[ Info: iteration 33, average log likelihood -1.252104
[ Info: iteration 34, average log likelihood -1.251170
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.250373
[ Info: iteration 36, average log likelihood -1.257803
[ Info: iteration 37, average log likelihood -1.254192
[ Info: iteration 38, average log likelihood -1.252936
[ Info: iteration 39, average log likelihood -1.251913
[ Info: iteration 40, average log likelihood -1.250995
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.250195
[ Info: iteration 42, average log likelihood -1.257624
[ Info: iteration 43, average log likelihood -1.254032
[ Info: iteration 44, average log likelihood -1.252795
[ Info: iteration 45, average log likelihood -1.251784
[ Info: iteration 46, average log likelihood -1.250870
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.250084
[ Info: iteration 48, average log likelihood -1.257544
[ Info: iteration 49, average log likelihood -1.253964
[ Info: iteration 50, average log likelihood -1.252730
┌ Info: EM with 100000 data points 50 iterations avll -1.252730
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3035192581967887
│     -1.3033555832778696
│      ⋮
└     -1.252730414634781
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.251894
[ Info: iteration 2, average log likelihood -1.250816
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.249254
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.242967
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.216057
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.192916
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.184061
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.188451
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      5
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.178320
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.192383
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     2
│     3
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.180314
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.188246
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.177712
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      5
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.174719
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.186814
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.177507
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.186678
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.179562
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     3
│     5
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.173060
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      3
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.178154
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.192688
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.182194
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.175461
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.170389
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      5
│      7
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.180155
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.191031
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.179508
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.173747
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.183844
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.174961
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      5
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.171682
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.182424
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.189688
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.178841
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.173361
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      3
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.159289
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.177031
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.175201
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.169140
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.160415
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.172504
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     5
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.169969
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.173537
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.163005
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.175056
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.164739
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.167985
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     1
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.167280
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.177994
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.167399
┌ Info: EM with 100000 data points 50 iterations avll -1.167399
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2518938979028964
│     -1.250816396822755
│      ⋮
└     -1.1673989145803516
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.162963
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     14
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.155243
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.160092
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     14
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.125805
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.090769
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     14
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.100556
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.076055
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.078670
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.084959
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.087728
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.071398
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.077094
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.083307
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.087097
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.071028
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.076876
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.083290
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.087067
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.071012
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.076863
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.083279
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.087059
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.071001
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.076857
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.083269
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.087053
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.070993
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.076853
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.083262
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.087049
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.070986
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.076848
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.083255
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.087045
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.070981
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.076845
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.083250
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.087042
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.070976
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.076841
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.083245
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.087038
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.070971
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.076837
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.083241
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.087035
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.070967
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.076834
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.083237
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.087031
┌ Info: EM with 100000 data points 50 iterations avll -1.087031
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.16296253010973
│     -1.1552431556130105
│      ⋮
└     -1.087031493542996
32×26 ┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.389967010902839
│     -1.3900351190290428
│     -1.389989608353421
│     -1.389895413819362
│      ⋮
│     -1.076834245859326
│     -1.0832374564052065
└     -1.087031493542996
Array{Float64,2}:
  0.0561495   -1.03386      0.115319    -0.0906087    0.123862    -0.0419089   -0.14583      -0.0524241   -0.0313179  -0.013268     0.151492     0.249703    -0.110349      0.0337309    0.0380663   0.098008    -0.0173319    0.103405    -0.027871    -0.156706    -0.0288441   -0.192771    -0.0783588   -0.0369166   -0.0752458   -0.105449
  0.0565662    1.16038      0.101017    -0.088567     0.233168    -0.0416229   -0.026928     -0.0535463   -0.0259316  -0.12164     -0.016779     0.196914    -0.108759      0.0341224    0.148171    0.0766396   -0.00274826   0.105361    -0.0386906   -0.15229      0.239343    -0.159667    -0.0770132   -0.0508432   -0.0181774   -0.105416
 -0.0951646   -0.127671     0.0768571   -0.085605     0.0534419    0.0118271    0.0942598    -0.151135    -0.0430827   0.0552438   -0.148091    -0.156823    -0.129856     -0.106589    -0.052931   -0.0286334    0.229235     0.0224696    0.00938984   0.129251     0.0842978   -0.0361698    0.0870997   -0.0657885    0.0309443   -0.115021
  0.0741631    0.0315212    0.109173     0.0616793   -0.0373742   -0.0931503   -0.0674019     0.0544162    0.0770901   0.145596     0.00468647   0.0657132    0.22881       0.198824     0.0178594  -0.0705709   -0.121052     0.00235137   0.0946075    0.139304     0.0564786    0.00940884   0.0212993   -0.00655628  -0.037926     0.0817164
 -0.0333894   -0.011358    -0.0830418   -0.148887    -0.151067    -0.110599    -0.0882604    -0.0192035    0.0503648   0.898143     0.104566    -0.138844     0.074372      0.0638328    0.0421796  -0.101054    -0.0210305    0.0850451    0.132796    -0.12182     -0.107498     0.0359731   -0.121087     0.144073    -0.0082074   -0.210974
 -0.0455407    0.0513222   -0.0221799    0.0162615   -0.142006    -0.0875869    0.0532839     0.0667278    0.0475553  -0.885749     0.105245    -0.13292      0.08725       0.0585328   -0.0940174  -0.0894542   -0.251792     0.070647     0.138348    -0.177454    -0.108339     0.0336129   -0.133693     0.0810685   -0.0458476    0.138598
  0.15772      0.0787922    0.00637103  -0.0559557   -0.0253147   -0.375907     0.230705     -0.0465241   -0.0038801  -0.0785942    0.0340136   -0.0748006   -0.0473972    -0.0747269    0.0661308  -0.0147871    0.0796778    0.0819066    0.0921255    0.0962866   -0.067301    -0.201183     0.150672     0.00750361  -0.0657284   -0.100073
  0.162793    -0.0326466   -0.264879    -0.0095568   -0.166909     0.314705     0.187826      0.112474     0.0937331  -0.132426     0.004937    -0.0566783   -0.0161182    -0.0487077    0.0921318   0.0599659    0.139161     0.112253     0.115844     0.0443987   -0.0685063    0.0134953    0.158437     0.0166402   -0.140555     0.0210772
  0.0351947    0.201567    -0.113959     0.0644519   -0.0453184   -0.0638003   -0.170298     -0.0337799   -0.345153   -0.24451      0.0724647   -0.0138562   -0.0133227     0.0508936   -0.659459   -0.0566613    0.0383336    0.0382228    0.0559504   -0.034845    -0.0972921   -0.0929271    0.0335188   -0.049372    -0.0318361   -0.0911238
 -0.0949431    0.262484    -0.149741    -0.0623124   -0.0158033   -0.0637225   -0.0953804    -0.0374437   -0.132027    0.396522    -0.204536     0.0589325   -0.0856522     0.0437272    0.639351   -0.0638858    0.0639477    0.112662     0.0545739   -0.092818    -0.101141    -0.068384     0.0942312   -0.0940243   -0.0217572   -0.103821
  0.0362929   -0.0936426    0.162748    -0.0607069    0.0958514    0.225559    -0.0395068     0.016773     0.18209     0.257898     0.0471082   -0.00579864  -0.0656116     0.0298057   -0.137917    0.0680829    0.0957587   -0.118926     0.0831952   -0.155703     0.0787735   -0.0936756    0.00865066   0.0162023    0.114263     0.0825882
  0.138504     0.243708     0.0159822    0.0697255   -0.0143485    0.00300592  -0.201505      0.070551    -0.0844167  -0.179273    -0.0636091    0.046617    -0.0183912    -0.184223    -0.0714269   0.184444    -0.0651539   -0.00949653   0.109136    -0.0815842    0.0683042    0.164647    -0.0139705   -0.0556875    0.0533174   -0.0556693
  0.0386454    0.00214574   0.269249    -0.127804     0.0317173    0.183503    -0.181904      0.0203614    0.0274313  -0.131812     0.17256      0.0416397   -0.135934     -0.143994     0.0833555   0.197897    -0.0136961   -0.0966735    0.0731294    0.0864829   -0.220694     0.0412201    0.090682    -0.233843    -0.0397815    0.12466
 -0.231183    -0.511171     0.268186    -0.128427    -0.051842    -0.181931     0.324535      0.151863    -0.0122364  -0.106957     0.10253      0.0593751    0.0407935    -0.065434     0.104408    0.164248     0.152417     0.248803    -0.327942     0.204113    -0.211376     0.0363245    0.0517041    0.625826    -0.042872     0.12675
 -0.0122342   -0.0892659   -0.140631     0.172485     0.0524109    0.107461     0.205917     -0.299379     0.0387467  -0.553471    -0.18393     -0.0805035   -0.277494      0.0386156   -0.174273    0.0394297    0.16565      0.0307457    0.0616056    0.0150449    0.146979    -0.0525683    0.070615     0.0660953    0.10455     -0.102819
  0.202382    -0.128493    -0.16578      0.167299    -0.0500588   -0.0695152    0.211532     -0.180946     0.0272231   0.147463     0.061045    -0.108846    -0.220594      0.0749459   -0.0705697  -0.0019916    0.169339     0.0736422    0.058037     0.00449935   0.0957946    0.0563253   -0.0887302   -0.110057     0.131506    -0.0730816
 -0.0656676    0.117421     0.0390318    0.178185    -0.187214    -0.0555723   -0.1144        0.163878    -0.0926964   0.0751996   -0.0497346   -0.120127     0.120686      0.0860378    0.0660907   0.0967064   -0.0297504    0.0343003    0.0423863   -0.0108587   -0.0434398   -0.066583     0.00588034  -0.0760899   -0.0826455   -0.0161514
  0.138552     0.0817567    0.0130381    0.153254    -0.086072     0.0074638   -0.141494      0.0711786    0.0912045   0.0458728    0.0829131   -0.0760122   -0.121136     -0.243142    -0.159845   -0.0190469    0.0373838    0.0378087    0.12494     -0.0582443   -0.125036     0.0834333    0.161251    -0.0128767    0.0291031   -0.205889
 -0.0756817   -0.00961064  -0.163156     0.0857539    0.102228     0.0602036   -0.0475964    -0.112875     0.127185   -0.100704     0.128347    -0.122556    -0.0620085     0.13082     -0.0266739   0.0174044    0.116495    -0.075485    -0.142509    -0.0382777    0.0702188   -0.0719597   -0.168038    -0.145175    -0.00904174   0.0251786
 -0.129869     0.160406    -0.114099    -0.0628592    0.153357     0.128755    -0.0813745     0.0982735   -0.11219    -0.0586701   -0.136002     0.125799    -0.1049       -0.191977    -0.037643   -0.0879397    0.0699871   -0.00804376   0.0911678    0.0592613    0.0153452   -0.0401241   -0.151099    -0.0154961   -0.0211495    0.0265962
 -0.120753    -0.133675    -0.116378    -0.186982     0.0960011   -0.0706231   -0.0957451     0.226034    -0.0236067   0.218591     0.0416925   -0.223448     0.160444      0.163696     0.019244    0.0995322    0.0677071    0.216811    -0.199206     0.00750056  -0.730032    -0.117052    -0.0301469   -0.0323939    0.036715    -0.0683927
 -0.148138    -0.00168338  -0.071816     0.00967343   0.0755365   -0.0645993   -0.197142     -0.397125     0.10203     0.144958    -0.0752343   -0.0433448    0.204692      0.123731     0.0654703  -0.270562     0.0590138    0.21495      0.0325618    0.121996     0.430207    -0.117107     0.235673     0.0450803   -0.0853865   -0.0680324
  0.0218116    0.122101    -0.165986    -0.086679     0.0648154    0.144112    -0.026904     -0.0991722   -0.115179    0.00452021  -0.157925    -0.0509416    0.169507     -0.0456466   -0.171789    0.00395477  -0.126333    -0.018338    -0.0370145    0.0762482    0.0728314    0.21145     -0.0534989   -0.127536     0.0265967   -0.016236
 -0.172709     0.125834     0.017605     0.106333     0.0717633    0.334497     0.163339     -0.231858     0.0656139   0.181297     0.0141759    0.160032    -0.127494     -0.117836     0.0273633   0.0200181    0.051281     0.0177445   -0.00748152  -0.0371146    0.0915692    0.0725582    0.00803567   0.040142    -0.13844      0.00464131
  0.180532    -0.0779528    0.120251    -0.239843    -0.0579842   -0.158702    -0.157432      0.110529     0.017029   -0.0130762   -0.00960044  -0.0452636    0.0242444     0.0336458   -0.0841061  -0.0808988    0.0646256    0.00381082  -0.0953097    0.0206862    0.0833338   -0.0871489   -0.0623454   -0.0776989    0.0163265   -0.221986
  0.117376    -0.139997     0.0719711   -0.0064615   -0.0332994   -0.079607    -0.110827     -0.147148    -0.136019    0.0765221    0.0534414    0.0241632    0.0568747     8.44159e-5  -0.158628    0.11734     -0.0150703    0.0702638    0.00731659  -0.0799529   -0.0527932    0.0518164    0.143883     0.0451184   -0.0115026   -0.0491726
  0.00673164   0.0403847   -0.0737279   -0.00713994  -0.00258636   0.121263    -0.000190567  -0.0218586   -0.0388563  -0.0922257   -0.00636537   0.0343869    0.000296928  -0.0715615    0.0351574   0.0128334    0.0098386   -0.0316847   -0.17023      0.00281996   0.0170985   -0.0311754    0.0500777   -0.049042    -0.0135812    0.0872225
  0.00653834   0.0104706    0.102816    -0.130634     0.0182302    0.00915933  -0.037301      0.0259059   -0.0429715   0.103286     0.0282831   -0.00588579   0.0994026     0.138911    -0.122884   -0.078751     0.0502971   -0.0829415   -0.100123    -0.0738748   -8.20216e-5   0.0218573   -0.061111    -0.0210442    0.0744569    0.0198971
  0.0405646    0.153935     0.0265856    0.0367104   -0.00846884   0.0665616   -0.0748104     0.00961651   0.0978832   0.0903129    0.0115372    0.0808621   -0.127686      0.0347156    0.0199932  -0.0888363    0.0130489    0.0192211    0.0393552    0.0279012    0.063043    -0.00327197   0.0162108   -0.121711    -0.0646555   -0.0102015
  0.0126531   -0.0972538    0.0476862   -0.0408227    0.0129057   -0.00689984   0.0562018     0.0283174   -0.0573749  -0.106434     0.0935302    0.123747    -0.0119812    -0.0169257    0.0394452   0.0904119    0.0318264   -0.082568     0.0766996    0.0258104    0.00215308  -0.108194     0.0769606    0.0891852   -0.00857043   0.0452001
  0.0275101    0.0409077    0.0422394    0.0981227   -0.0176043    0.159997    -0.0124233     0.0343486   -0.0726489   0.00103021   0.142166    -0.0203172    0.079619     -0.131304    -0.0812699   0.0892032    0.0654287   -0.0311078    0.0318617   -0.0121501   -0.0327769   -0.0527101   -0.0954792    0.0404091    0.0758359   -0.0437281
 -0.0607241    0.0666296   -0.132909     0.112697     0.0569043    0.0929811    0.00979728   -5.87083e-5   0.207001   -0.0570708    0.0975994    0.0780124   -0.0256353    -0.168944     0.200341    0.00718868  -0.0207722   -0.143449    -0.0571031   -0.101055     0.183828     0.0424976    0.0636509    0.0511425   -0.0809282   -0.098228[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.070964
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.056298
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.070928
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.056240
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.070927
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.056239
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.070926
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.056238
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.070925
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      4
│      5
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
kind diag, method kmeans
[ Info: iteration 10, average log likelihood -1.056237
┌ Info: EM with 100000 data points 10 iterations avll -1.056237
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.384667e+05
      1       6.587211e+05      -1.797456e+05 |       32
      2       6.295712e+05      -2.914994e+04 |       32
      3       6.153334e+05      -1.423779e+04 |       32
      4       6.074966e+05      -7.836829e+03 |       32
      5       6.028857e+05      -4.610863e+03 |       32
      6       6.001237e+05      -2.761982e+03 |       32
      7       5.977815e+05      -2.342189e+03 |       32
      8       5.958004e+05      -1.981173e+03 |       32
      9       5.943460e+05      -1.454352e+03 |       32
     10       5.932284e+05      -1.117589e+03 |       32
     11       5.923128e+05      -9.155792e+02 |       32
     12       5.912847e+05      -1.028116e+03 |       32
     13       5.896493e+05      -1.635398e+03 |       32
     14       5.877089e+05      -1.940457e+03 |       32
     15       5.867651e+05      -9.437934e+02 |       32
     16       5.864685e+05      -2.966297e+02 |       32
     17       5.863410e+05      -1.274269e+02 |       32
     18       5.862592e+05      -8.177809e+01 |       32
     19       5.862042e+05      -5.500137e+01 |       32
     20       5.861685e+05      -3.579361e+01 |       32
     21       5.861448e+05      -2.366810e+01 |       32
     22       5.861298e+05      -1.500484e+01 |       31
     23       5.861183e+05      -1.146332e+01 |       28
     24       5.861105e+05      -7.814120e+00 |       28
     25       5.861030e+05      -7.522102e+00 |       29
     26       5.860970e+05      -5.963663e+00 |       30
     27       5.860893e+05      -7.716964e+00 |       30
     28       5.860831e+05      -6.223267e+00 |       30
     29       5.860784e+05      -4.717700e+00 |       31
     30       5.860747e+05      -3.636947e+00 |       23
     31       5.860715e+05      -3.221741e+00 |       25
     32       5.860681e+05      -3.439277e+00 |       25
     33       5.860635e+05      -4.517428e+00 |       27
     34       5.860569e+05      -6.683860e+00 |       23
     35       5.860478e+05      -9.020202e+00 |       26
     36       5.860368e+05      -1.107402e+01 |       29
     37       5.860245e+05      -1.222428e+01 |       30
     38       5.860093e+05      -1.527132e+01 |       30
     39       5.859831e+05      -2.612838e+01 |       31
     40       5.859455e+05      -3.765880e+01 |       31
     41       5.858993e+05      -4.617196e+01 |       32
     42       5.858477e+05      -5.158261e+01 |       32
     43       5.857892e+05      -5.855147e+01 |       32
     44       5.857361e+05      -5.312240e+01 |       32
     45       5.856895e+05      -4.651364e+01 |       32
     46       5.856416e+05      -4.794095e+01 |       32
     47       5.855886e+05      -5.298172e+01 |       32
     48       5.855340e+05      -5.463956e+01 |       31
     49       5.854839e+05      -5.007953e+01 |       31
     50       5.854343e+05      -4.962666e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 585434.2708748351)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.308839
[ Info: iteration 2, average log likelihood -1.279987
[ Info: iteration 3, average log likelihood -1.254273
[ Info: iteration 4, average log likelihood -1.224083
[ Info: iteration 5, average log likelihood -1.180808
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     17
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.116421
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      4
│      6
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.110443
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     12
│     15
│     19
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.082804
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.109991
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     17
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.085754
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      4
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.103110
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     24
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.079308
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│      7
│      9
│     12
│      ⋮
│     22
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.024470
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      4
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.128301
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.123119
[ Info: iteration 16, average log likelihood -1.112639
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      9
│     15
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.036671
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      4
│      6
│      7
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.018449
[ Info: iteration 19, average log likelihood -1.167055
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.099914
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     15
│     17
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.031507
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│     12
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.037836
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.142816
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.116628
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     17
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.066044
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     15
│     22
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.049556
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      6
│     12
│     19
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.069494
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      7
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.107593
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.082029
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     18
│     22
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.051641
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│     12
│     15
│     19
│     20
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.066714
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.112477
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     2
│     4
│     7
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.080214
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     20
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.055096
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│     12
│     15
│     17
│      ⋮
│     26
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.054404
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.139426
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.071362
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     17
│     20
│     22
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.026361
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     15
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.091181
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      6
│      9
│     18
│     19
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.098096
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.120913
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.060989
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     12
│     15
│     17
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.043125
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      6
│      7
│      9
│     19
│     22
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.078630
[ Info: iteration 45, average log likelihood -1.120611
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     17
│     18
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.060135
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.082984
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│      7
│      9
│     12
│     19
│     25
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.039186
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      4
│     20
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.086429
32×26 Array{Float64,2}:
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     17
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.088296
┌ Info: EM with 100000 data points 50 iterations avll -1.088296
└ 59.0 data points per parameter
 -0.00333798  -0.149508     0.148355     0.0532953   -0.0692534    -0.107907     0.115909     0.0515025   -0.065676    -0.0883322    0.137564     0.186733    -0.0311633   -0.0754816    0.0761603    0.20198       0.144035   -0.113464      0.189685    -0.0150745    0.0358687  -0.0777572   -0.0465496    0.152835     0.0732011    0.120899
  0.0254831    0.150214     0.0549884    0.238077    -0.0111465    -0.13258      0.0428747    0.113556     0.136754     0.00429241   0.0232267    0.185938    -0.0589585   -0.0126848    0.0200978    0.0726326     0.0667052  -0.0158293     0.138445    -0.013425     0.333061    0.0438591    0.00384107  -0.125077     0.0224401    0.145174
  0.0292324   -0.0460509   -0.0665822   -0.143315     0.104487      0.0985418   -0.0039204   -0.00819496  -0.0441677   -0.128568     0.0408183    0.0611268    0.0193529    0.0505293    0.00504012  -0.0177023    -0.0751503  -0.0539831    -0.0460326    0.0621447   -0.0217034  -0.134977     0.204417     0.0343827   -0.0970263   -0.0303824
 -0.170109     0.238105    -0.17949     -0.0453912    0.0879646     0.0429141   -0.0990272    0.0356369   -0.208577    -0.0613306   -0.232997     0.0861123   -0.0733709   -0.128906    -0.0577155   -0.0814196     0.0671414  -0.00392692    0.0856299    0.0415883   -0.0220377  -0.0683674   -0.136271    -0.0199095   -0.0388525   -0.0274434
 -0.0754812   -0.0775205    0.00700017  -0.0273949    0.104999      0.0264249   -0.147707     0.0736837    0.0273959   -0.0161396   -0.0636676   -0.0398778   -0.0195397   -0.042884     0.0770895    0.0574389     0.0535639  -0.0201084    -0.0332011    0.0054246   -0.0601279   0.0426409    0.116245    -0.0608556    0.0125372    0.0213669
  0.160059    -0.0826135    0.144788    -0.219583    -0.0515393    -0.156859    -0.119309     0.107393     0.00760659  -0.0239991   -0.017505    -0.0285496    0.0128616    0.00608128  -0.0873678   -0.0525074     0.0550142   0.00409416   -0.10905      0.0292471    0.0674447  -0.0750007   -0.0419733   -0.0788016    0.0229307   -0.182063
 -0.0673444    0.137451     0.010782    -0.0477597    0.131097      0.139726    -0.0173166    0.0465739   -0.0204727   -0.110313    -0.120121     0.155734    -0.102868    -0.186855     0.0621202   -0.0779972     0.0298151  -0.00573844    0.0972901    0.128441     0.0573892  -0.00346942  -0.0545609   -0.0568597   -0.00907708   0.0226501
  0.117406    -0.139945     0.0649229   -0.00309972  -0.0337448    -0.0914923   -0.110863    -0.133376    -0.135068     0.0699675    0.0490248    0.0240712    0.0587975    0.00410486  -0.151616     0.115421     -0.0128134   0.0704823     0.0145761   -0.0816789   -0.0443703   0.0515655    0.144084     0.0459947   -0.0116644   -0.0464674
  0.0402905   -0.0700762    0.154885    -0.0553186    0.103093      0.219901    -0.0379814    0.0141533    0.179356     0.319409     0.0354854   -0.0307463   -0.0743004    0.0279677   -0.171071     0.0698079     0.0986893  -0.134462      0.101028    -0.16675      0.0384985  -0.0961417    0.0334464    0.00932854   0.112426     0.0474256
 -0.0537942    0.0719566   -0.0125831    0.0540429   -0.176595     -0.073564    -0.0718828    0.0914326   -0.0149168    0.0204445    0.0386097   -0.130536     0.106244     0.0731513    0.0158267   -0.007154     -0.088717    0.0561478     0.0983987   -0.0810015   -0.082857   -0.0109701   -0.0712344    0.0198682   -0.066291    -0.024475
 -0.0776689   -0.00736724  -0.162105     0.0827669    0.100918      0.0631772   -0.0460973   -0.106801     0.122933    -0.107028     0.122382    -0.118675    -0.0636195    0.12964     -0.0267354    0.0175118     0.121005   -0.0751791    -0.137165    -0.0360414    0.0695468  -0.0716163   -0.163255    -0.141209    -0.00885409   0.0242014
 -0.0633783   -0.16688      0.226608    -0.109164     8.90575e-5    0.0437829    0.00261936   0.0535504   -0.00252397  -0.118453     0.174501     0.0489731   -0.0788526   -0.0985352    0.101716     0.161463      0.056065    0.0465422    -0.0698747    0.122431    -0.22223     0.0328143    0.0745115    0.0762561   -0.042445     0.101468
  0.0919213   -0.10934     -0.152338     0.168386     0.00248542    0.0213872    0.210779    -0.239575     0.0330131   -0.205373    -0.0714085   -0.0939217   -0.245078     0.061025    -0.118814     0.0172929     0.163646    0.0528889     0.0599858    0.00918081   0.118832    0.00202214  -0.0103264   -0.0218853    0.116911    -0.0886724
  0.0904375    0.130303     0.10635      0.0211322   -0.0225893     0.177809     0.0526648    0.0385846   -0.139725    -0.0908371    0.158243     0.0325054    0.051889    -0.161806    -0.100236     0.038872      0.0627164  -0.00823471    0.0333406    0.031461    -0.0347496  -0.023187    -0.100731     0.0233859    0.149159     0.0322262
 -0.14261     -0.046155    -0.103853    -0.0666853    0.0890244    -0.0360555   -0.128093    -0.0711766    0.0172206    0.182895    -0.0329323   -0.1137       0.146838     0.113582     0.0379937   -0.080282      0.0613661   0.214565     -0.064644     0.0618172   -0.138224   -0.105964     0.0691329    0.00583171  -0.0272243   -0.056721
  0.126081     0.198512     0.0368736    0.0587638   -0.00897943    0.0317363   -0.169234     0.0830784   -0.0666122   -0.160122    -0.0564695    0.0463547   -0.0245443   -0.167914    -0.0682115    0.178009     -0.0480846  -0.019426      0.103686    -0.0851711    0.0583789   0.156359    -0.00742917  -0.0505366    0.0584198   -0.0364664
  0.0777517    0.0335838    0.109042     0.0636298   -0.0385092    -0.0923471   -0.0691567    0.0573699    0.0775154    0.145816     0.0091294    0.0665457    0.234156     0.200111     0.0220424   -0.0711642    -0.122097   -0.000878748   0.0951905    0.140724     0.0585064   0.0146193    0.0231866   -0.0065325   -0.04044      0.0825398
  0.160033     0.10863      0.0568068   -0.0295305    0.000576903   0.0477273   -0.191438     0.0153539    0.185553     0.0537262    0.0254364    0.0780821   -0.176601     0.0193818    0.0879809   -0.0948198     0.0698546   0.0201538     0.0439577    0.113155     0.0139661  -0.0508705   -0.0112025   -0.132211    -0.233541    -0.0253079
  0.1459       0.0833124    0.0153645    0.195098    -0.159718     -0.00786018  -0.134181     0.0623201    0.0826243    0.0479986    0.0789125   -0.0835474   -0.127239    -0.299364    -0.147892    -0.0197364     0.0280276   0.0500564     0.187094    -0.054842    -0.131676    0.0900997    0.154644    -0.0157217    0.0363984   -0.189415
  0.0451178    0.114297    -0.0123644    0.0368464    0.0181        0.149913     0.134864    -0.0300981   -0.00365588  -0.177297     0.033664     0.154758     0.0717111   -0.123549    -0.0247027    0.0619672    -0.0146116  -0.0325694    -0.313608     0.0605326    0.0442373  -0.235765     0.0587174   -0.0282855    0.0960081    0.239353
 -0.0595038    0.0781183   -0.119429     0.11366      0.0587141     0.100204     0.0170843   -0.00991241   0.202701    -0.056675     0.0931741    0.0782346   -0.0287481   -0.168539     0.193875     0.00328337   -0.0193309  -0.137599     -0.0448397   -0.104058     0.17079     0.0318097    0.0506819    0.0492702   -0.0705942   -0.0955939
  0.0283722    0.276679    -0.139505     0.0846032   -0.0242102    -0.10592     -0.103663    -0.0404956   -0.261299     0.0308693    0.0257582    0.0414972   -0.027653     0.0687738   -0.18731     -0.0379321     0.0449539   0.0422037     0.083669    -0.0932711   -0.0671551  -0.0681288    0.0637818   -0.0732293   -0.015564    -0.127363
 -0.073864     0.200497    -0.0104301   -0.0526472   -0.0132055     0.212972    -0.045445    -0.0207499   -0.00586453   0.198616    -0.0130023   -0.00241963  -0.129675     0.0842743   -0.045082    -0.224125     -0.0955175   0.0389703    -0.00516255  -0.0137045   -0.021606    0.00261916   0.0447024   -0.0974327    0.0108969   -0.0919788
 -0.0242863   -0.0583379   -0.03927      0.160349    -0.00295717    0.130644    -0.0740398    0.0144096   -0.0131205    0.074616     0.133482    -0.0563525    0.0777232   -0.0908805   -0.0586029    0.132995      0.0469766  -0.0703935     0.0247854   -0.06105     -0.033695   -0.112178    -0.0772198    0.0561477    0.0226068   -0.116035
 -0.0481083    0.0174558    0.0956591   -0.185898     0.0305637     0.157808     0.0330408    0.0302813   -0.151966     0.219541     0.0474961    0.0606889   -0.00345666   0.0513939   -0.0534405   -0.0671363    -0.0586001   0.0213049    -0.212927     0.018997     0.0256791   0.0598656   -0.0471721    0.0564007    0.0196007    0.0277317
 -0.194471     0.148012     0.0184472    0.114311     0.0879626     0.31605      0.150529    -0.205193     0.097879     0.194202     0.0145167    0.21563     -0.122757    -0.111115     0.0118667    0.0219327     0.049993    0.0327449    -0.0398692   -0.039946     0.138659    0.0666453    0.0323593    0.0629046   -0.16671     -0.0164303
  0.0343825    0.113189    -0.164112     0.0099354   -0.0947473     0.224067     0.00638035  -0.109029    -0.068169    -0.0904227    0.00187921   0.0207875   -0.0627765   -0.0845877    0.065928    -0.0798572     0.0500787  -0.0233767    -0.207272    -0.0678231    0.0924076   0.116416    -0.033882    -0.0869547   -0.125266     0.0814733
  0.0596992   -0.0116558    0.0840397   -0.0807827    0.141016     -0.0337428   -0.0974052   -0.0538338   -0.0352035   -0.0454675    0.0828098    0.213031    -0.10439      0.0364239    0.0735353    0.0694982    -0.0167785   0.111367     -0.0237255   -0.146418     0.0740834  -0.173753    -0.0586919   -0.0419557   -0.0444619   -0.0905934
  0.0647971    0.0101197    0.106013    -0.0838295    0.00894839   -0.0839085   -0.0971919    0.0151272    0.0433026    0.0271377    0.037629    -0.0583847    0.181096     0.225021    -0.240223    -0.0881297     0.137278   -0.169677     -0.00713607  -0.142855    -0.0147871  -0.0228792   -0.0624173   -0.0872069    0.12223      0.00167423
  0.00342215   0.118402    -0.149029    -0.071762     0.0629777     0.150045    -0.0174334   -0.102907    -0.108743     0.0197622   -0.145808    -0.0432038    0.150534    -0.0436279   -0.166349     0.000659221  -0.111787   -0.0168611    -0.0358706    0.0720744    0.066258    0.197583    -0.0504144   -0.126427     0.0211358   -0.0164099
  0.15375      0.0214212   -0.129243    -0.0339279   -0.093153     -0.0398225    0.206426     0.0321201    0.0444783   -0.104058     0.0205811   -0.0677674   -0.0300367   -0.0601731    0.0779869    0.0194268     0.107973    0.0982505     0.104577     0.0627849   -0.0688758  -0.0897101    0.15055      0.0194242   -0.100452    -0.0392702
 -0.0953911   -0.125986     0.0747514   -0.0842092    0.0534378     0.0115601    0.0922322   -0.150452    -0.0417856    0.0550572   -0.141423    -0.156011    -0.129497    -0.10457     -0.0495854   -0.0280987     0.224389    0.0287749     0.00950642   0.129238     0.0825142  -0.0368365    0.0845509   -0.0653455    0.0312257   -0.113923[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.083976
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     12
│     15
│     18
│      ⋮
│     26
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.021534
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      4
│      6
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.996213
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     12
│     15
│     18
│     19
│     22
│     25
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.062633
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     15
│     18
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.035156
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      6
│      7
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.982330
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     15
│     18
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.065667
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│      9
│     12
│     15
│      ⋮
│     26
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.023252
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      9
│     15
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.013875
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      6
│      7
│     12
│     15
│      ⋮
│     25
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.045160
┌ Info: EM with 100000 data points 10 iterations avll -1.045160
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0661271   -0.159874     0.00618199   0.105063    -0.104577     0.117132     -0.158413     0.0459461   -0.0536429    0.014824    -0.144856      0.162621     0.0421443    0.120415     0.0875596   -0.110727    -0.0179011   -0.0268121     0.087228     0.122875     -0.00139856   0.193492     0.00963547    0.000617923   0.078096    -0.078706
 -0.023645    -0.141182     0.0495214    0.0437883   -0.142406    -0.129985     -0.0248274    0.0367909    0.00137313  -0.0581052    0.0557365     0.0138204    0.131177    -0.040206    -0.0469358    0.0770081    0.00533707  -0.00134908   -0.0702944   -0.207238      0.0946984   -0.112806    -0.0800085    -0.0795246    -0.0855323    0.0373387
 -0.0648602   -0.125418    -0.265281     0.115235     0.0355829    0.0211941    -0.219375     0.0114311    0.173851    -0.0631454   -0.0274055     0.0014423   -0.0217618   -0.0545554   -0.0616253    0.0962074    0.110238    -0.0312932     0.092715    -0.149171      0.136671     0.0753996    0.00587518    0.136266      0.162003     0.218468
  0.058802     0.124831     0.016437     0.0664131    0.16828      0.00678742   -0.0805999    0.156378    -0.183256    -0.162608    -0.171848      0.0932793   -0.0642523   -0.0599069   -0.0113211   -0.13598     -0.110092    -0.115938     -0.0136514    0.0525045     0.0220879   -0.0110063    0.223779      0.00230258    0.0113498   -0.0478107
  0.0607906    0.0469748    0.0503718    0.00662511  -0.132195     0.0552313    -0.128129    -0.0855726    0.0611435    0.10706      0.0897664    -0.021454     0.00863043  -0.114802     0.100175     0.0167028    0.120401    -0.0853039    -0.048094    -0.0875165     0.0734407   -0.030022     0.00203083   -0.0726797    -0.0833589   -0.143159
 -0.131074     0.143875    -0.0261048    0.00886667  -0.0636739    0.112209     -0.0247657    0.00656786   0.0333513   -0.0220491   -0.101277      0.0396894   -0.00258403  -0.0275629    0.0218966   -0.10362     -0.257724     0.0290353     0.143464    -0.0548594     0.0428398    0.0325862   -0.122408     -0.13542       0.224333     0.0762544
 -0.112306     0.0553935    0.111286     0.0301273   -0.0918597    0.0667804    -0.0327739    0.0912858   -0.153964    -0.0415645   -0.00404207    0.0288865    0.0991624   -0.0412564    0.132221    -0.0267403   -0.097275     0.120623      0.0858763    0.093578     -0.140318    -0.0997873    0.0209681    -0.0827155    -0.0159373    0.0504163
 -0.0552158   -0.0119886    0.12857     -0.154846    -0.093143     0.0463907    -0.0696667    0.0808222   -0.0326418    0.0157534    0.0240092     0.17164      0.12976      0.0666325   -0.180348     0.0390285    0.133154     0.0579617     0.129487     0.0444501     0.119956    -0.0335829    0.053076      0.0203884     0.114161    -0.126577
  0.137552     0.114944     0.0105737    0.20432      0.130979    -0.0864358     0.112957    -0.0542587   -0.0864186   -0.085862     0.199581      0.0939805   -0.247863    -0.223646    -0.0491235   -0.0559584    0.0791293   -0.0135011     0.126763     0.0502192    -0.157334    -0.0316565   -0.087761      0.107567      0.124263    -0.016786
 -0.15454     -0.0609336   -0.10483     -0.0226282   -0.0682494   -0.174248     -0.0507634    0.24384      0.183472     0.0190807   -0.0946054    -0.100022     0.195649    -0.0309435    0.0452711   -0.168508     0.0327526   -0.0133593    -0.0480815   -0.0927688    -0.0652217    0.211051     0.0262163     0.0412943    -0.162718     0.162955
 -0.200366    -0.00340841  -0.0778955    0.0895822   -0.0654256    0.0172332    -0.0329183   -0.172125    -0.0183686   -0.124282     0.000778203   0.0184144   -0.0397416    0.0622006    0.122608     0.036721     0.0752      -0.0655885     0.0507408    0.0984266     0.0512553    0.0300545   -0.167491     -0.0691184    -0.0566481    0.0131845
 -0.0134077    0.0306506   -0.13468     -0.0224515    0.201656     0.0365735    -0.0500897    0.220151     0.0519561    0.0212049   -0.014625      0.119526    -0.0110139   -0.0417862   -0.00496106  -0.0972312   -0.096689    -0.209789      0.144536    -0.14927       0.0020605    0.0607847   -0.0441097     0.00610652    0.0503051    0.0210504
  0.0464473    0.0381455    0.08607     -0.0279811    0.077205     0.096463     -0.00254792  -0.080907    -0.0607006    0.096252     0.0212783    -0.122392    -0.00497526  -0.120392     0.00727307  -0.0484581    0.137292     0.110271      0.00262004   0.0247632    -0.0576935    0.0316116   -0.0746788     0.105295      0.194862     0.215964
  0.0429825    0.247184    -0.189876    -0.0676533   -0.0337192    0.00244711   -0.0972322    0.203484     0.0504985    0.0750354    0.151842      0.0869465    0.0115759   -0.0686826    0.0508961    0.17266     -0.0543967   -0.0683408    -0.115324    -0.0563025    -0.0408585   -0.0762709   -0.0425811    -0.075779      0.0543287    0.0860432
  0.126438    -0.0139134    0.130604    -0.108919    -0.0448073    0.0596845     0.0383197    0.0799478   -0.0932693   -0.0742796   -0.0581705     0.124147    -0.152231     0.108784    -0.0196669    0.229002     0.0903234   -0.0489677    -0.0374091    0.115984     -0.0155112    0.155473    -0.000623924  -0.0598699    -0.0341261   -0.0511274
 -0.0144941    0.158984    -0.00748675   0.0309461   -0.0788993   -0.0266516    -0.202491     0.0534056    0.0467866   -0.00914915  -0.0402905    -0.163498    -0.034599    -0.0696639    0.0690963    0.0134625   -0.0474033   -0.157459      0.0774578    0.143371     -0.042855     0.0146384    0.138357      0.19427       0.0448631   -0.196038
  0.0574813   -0.112991     0.133537    -0.00933376   0.178979    -0.0257124     0.0326144   -0.171492     0.0461035    0.138858    -0.120405      0.249837     0.0139639    0.2188      -0.0469049    0.0413077    0.0800197   -0.01772      -0.148283     0.0782139    -0.117865     0.0176912    0.0591403     0.00223686   -0.0047434   -0.0184699
  0.0844432    0.225705    -0.125803     0.0409834   -0.134611    -0.184939     -0.0495329    0.115991    -0.184209    -0.014452    -0.0647593     0.0265308   -0.056593    -0.0333437   -0.056561    -0.0894865   -0.0775115   -0.00408595   -0.0201828    0.0992012    -0.126859    -0.0440121   -0.000509964  -0.0104116    -0.00285965   0.116233
 -0.00811438  -0.00664505   0.0692292    0.0404858    0.017043    -0.134341      0.0296436    0.0913421   -0.0161109    0.0667978    0.126064     -0.216741    -0.0701828    0.0242255    0.0606387    0.0327558    0.18904     -0.0800678    -0.0353337    0.00787088   -0.00579405   0.162073     0.011278     -0.109833      0.234528    -0.181058
 -0.0166823   -0.15134     -0.0723003    0.00122677   0.008431    -0.0013949     0.00524544   0.144449    -0.0638588    0.0728259   -0.121291     -0.103538    -0.0735154    0.0960084   -0.194992    -0.0135301   -0.140032    -0.0366954    -0.103892    -0.041338     -0.0441755   -0.106677     0.0389439     0.0611348     0.01491      0.0618062
 -0.0373921    0.0523859   -0.0797274   -0.0301048    0.00189911  -0.000774283   0.147124     0.0662624    0.0644307    0.0750081   -0.00777164    0.23462      0.0097244   -0.05643     -0.0109566    0.076712    -0.157666    -0.0150205    -0.106153    -0.151807     -0.148504     0.140022     0.118565      0.063733     -0.057771     0.0905423
  0.0404719    0.124599     0.0749587    0.0879083   -0.240926     0.0369843     0.177312     0.113153     0.0617102    0.0832286    0.105948      0.0589571    0.100597    -0.0401876    0.165107     0.0195898    0.0322501   -0.050227      0.0120791   -0.0545049    -0.0706264    0.00284148  -0.0545383     0.000154426   0.184243    -0.187513
 -0.132787    -0.0969145   -0.0700115   -0.0439154    0.118455    -0.0682812    -0.188402     0.0223714    0.122351     0.0369639   -0.0564594     0.0538838    0.0748768    0.0173538    0.158796     0.19355      0.00940572   0.14042      -0.0149515   -0.0745255    -0.208883     0.0541723    0.151746     -0.0575299    -0.133959     0.0576165
 -0.0916901    0.0569929    0.0361978    0.12781      0.105352     0.149639      0.152192    -0.201251     0.00412082   0.0595523    0.0363201     0.048457    -0.0259803    0.0477045    0.187845    -0.192983     0.00592081   0.161765      0.0592546    0.164884     -0.0791295    0.143749    -0.110503     -0.0446034     0.106286     0.0159812
  0.00406557  -0.101264    -0.05645      0.0898791    0.0721972   -0.0115606    -0.187989    -0.0978732   -0.22616     -0.0131117    0.0247735    -0.148766    -0.00841281   0.0405066   -0.180018    -0.110691    -0.0723336   -0.0345085     0.0753137   -0.0723694     0.00606914  -0.181944     0.0934264    -0.0851936     0.150285     0.0612975
  0.0491259   -0.0439683   -0.0245773    0.0551288    0.126634     0.155986      0.0897121   -0.00349603   0.0396532   -0.0207639    0.0590817     0.00625637   0.248529    -0.014867    -0.172436    -0.0084759   -0.100955     0.0122509    -0.0499009    0.0297757    -0.126357     0.0873262    0.052489     -0.0180759     0.0965853    0.0604511
  0.0691689   -0.0620176    0.12242     -0.139193     0.0496245   -0.0285332    -0.017271    -0.0882999   -0.00757589  -0.0162405    0.0231188    -0.156185    -0.0320334   -0.147637     0.202911     0.0926606   -0.0439812   -0.12189       0.043278    -0.141565      0.0604611    0.083303     0.0497929     0.0938089    -0.0613079   -0.0313101
 -0.00997014  -0.0275941    0.0913983   -0.0278447    0.0800766    0.194975     -0.0660604    0.0643239    0.0906563    0.107173     0.200182     -0.142942     0.0516533   -0.00719597   0.208821     0.228783    -0.0293968   -0.00405763    0.0569433    0.000210523  -0.0884261    0.110207     0.00964099   -0.150549      0.0556917   -0.0356115
  0.0553346    0.0251617   -0.109876     0.134407    -0.0177952   -0.0564473     0.0772896    0.213232    -0.0204646   -0.0925788    0.0225471    -0.0629367    0.140521     0.013733    -0.0325955    0.00394426  -0.0294544    0.000362311   0.00734164  -0.122284     -0.0798966    0.134098     0.179684      0.134688      0.0804419    0.0349141
  0.0669212   -0.0402548   -0.106322    -0.00769271  -0.0804442   -0.0510165    -0.103802     0.0677121    0.134223    -0.0989871    0.118308      0.134598     0.0702927    0.0322645   -0.0351159    0.0652535    0.00147808   0.0995009     0.137064     0.124265     -0.116863     0.0268593    0.0768085     0.0461598     0.0386486    0.0134005
 -0.0349069    0.0310776   -0.0890312    0.113202    -0.0648135    0.131754      0.0484964    0.00821186  -0.123569    -0.0101969   -0.00459139   -0.090517     0.0353233    0.12729     -0.0358895   -0.048868     0.0906232   -0.104332     -0.0101616    0.000697943   0.151681    -0.133787    -0.0773346     0.0789332     0.057264     0.249155
  0.164572    -0.0432648   -0.00185212   0.155483    -0.00252945   0.000927568  -0.0884721    0.0195097    0.197919     0.130049     0.0610359    -0.0395418    0.0215983   -0.0268899    0.0939762    0.0242354   -0.0919901   -0.0997347    -0.066358     0.0212874     0.0305116   -0.0164026    0.0100881     0.20186      -0.00545013   0.161025kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4262615065911182
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.426283
[ Info: iteration 2, average log likelihood -1.426214
[ Info: iteration 3, average log likelihood -1.426147
[ Info: iteration 4, average log likelihood -1.426048
[ Info: iteration 5, average log likelihood -1.425910
[ Info: iteration 6, average log likelihood -1.425730
[ Info: iteration 7, average log likelihood -1.425519
[ Info: iteration 8, average log likelihood -1.425285
[ Info: iteration 9, average log likelihood -1.425006
[ Info: iteration 10, average log likelihood -1.424614
[ Info: iteration 11, average log likelihood -1.424018
[ Info: iteration 12, average log likelihood -1.423190
[ Info: iteration 13, average log likelihood -1.422273
[ Info: iteration 14, average log likelihood -1.421520
[ Info: iteration 15, average log likelihood -1.421054
[ Info: iteration 16, average log likelihood -1.420817
[ Info: iteration 17, average log likelihood -1.420707
[ Info: iteration 18, average log likelihood -1.420658
[ Info: iteration 19, average log likelihood -1.420636
[ Info: iteration 20, average log likelihood -1.420627
[ Info: iteration 21, average log likelihood -1.420622
[ Info: iteration 22, average log likelihood -1.420620
[ Info: iteration 23, average log likelihood -1.420619
[ Info: iteration 24, average log likelihood -1.420618
[ Info: iteration 25, average log likelihood -1.420618
[ Info: iteration 26, average log likelihood -1.420618
[ Info: iteration 27, average log likelihood -1.420617
[ Info: iteration 28, average log likelihood -1.420617
[ Info: iteration 29, average log likelihood -1.420617
[ Info: iteration 30, average log likelihood -1.420617
[ Info: iteration 31, average log likelihood -1.420617
[ Info: iteration 32, average log likelihood -1.420617
[ Info: iteration 33, average log likelihood -1.420617
[ Info: iteration 34, average log likelihood -1.420617
[ Info: iteration 35, average log likelihood -1.420617
[ Info: iteration 36, average log likelihood -1.420617
[ Info: iteration 37, average log likelihood -1.420616
[ Info: iteration 38, average log likelihood -1.420616
[ Info: iteration 39, average log likelihood -1.420616
[ Info: iteration 40, average log likelihood -1.420616
[ Info: iteration 41, average log likelihood -1.420616
[ Info: iteration 42, average log likelihood -1.420616
[ Info: iteration 43, average log likelihood -1.420616
[ Info: iteration 44, average log likelihood -1.420616
[ Info: iteration 45, average log likelihood -1.420616
[ Info: iteration 46, average log likelihood -1.420616
[ Info: iteration 47, average log likelihood -1.420616
[ Info: iteration 48, average log likelihood -1.420616
[ Info: iteration 49, average log likelihood -1.420616
[ Info: iteration 50, average log likelihood -1.420616
┌ Info: EM with 100000 data points 50 iterations avll -1.420616
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.426282692851172
│     -1.426214164653947
│      ⋮
└     -1.4206161205054386
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420637
[ Info: iteration 2, average log likelihood -1.420565
[ Info: iteration 3, average log likelihood -1.420492
[ Info: iteration 4, average log likelihood -1.420386
[ Info: iteration 5, average log likelihood -1.420239
[ Info: iteration 6, average log likelihood -1.420064
[ Info: iteration 7, average log likelihood -1.419891
[ Info: iteration 8, average log likelihood -1.419749
[ Info: iteration 9, average log likelihood -1.419651
[ Info: iteration 10, average log likelihood -1.419586
[ Info: iteration 11, average log likelihood -1.419542
[ Info: iteration 12, average log likelihood -1.419511
[ Info: iteration 13, average log likelihood -1.419487
[ Info: iteration 14, average log likelihood -1.419468
[ Info: iteration 15, average log likelihood -1.419453
[ Info: iteration 16, average log likelihood -1.419440
[ Info: iteration 17, average log likelihood -1.419429
[ Info: iteration 18, average log likelihood -1.419419
[ Info: iteration 19, average log likelihood -1.419410
[ Info: iteration 20, average log likelihood -1.419401
[ Info: iteration 21, average log likelihood -1.419393
[ Info: iteration 22, average log likelihood -1.419385
[ Info: iteration 23, average log likelihood -1.419376
[ Info: iteration 24, average log likelihood -1.419367
[ Info: iteration 25, average log likelihood -1.419359
[ Info: iteration 26, average log likelihood -1.419350
[ Info: iteration 27, average log likelihood -1.419341
[ Info: iteration 28, average log likelihood -1.419333
[ Info: iteration 29, average log likelihood -1.419324
[ Info: iteration 30, average log likelihood -1.419316
[ Info: iteration 31, average log likelihood -1.419308
[ Info: iteration 32, average log likelihood -1.419301
[ Info: iteration 33, average log likelihood -1.419294
[ Info: iteration 34, average log likelihood -1.419288
[ Info: iteration 35, average log likelihood -1.419282
[ Info: iteration 36, average log likelihood -1.419277
[ Info: iteration 37, average log likelihood -1.419272
[ Info: iteration 38, average log likelihood -1.419268
[ Info: iteration 39, average log likelihood -1.419264
[ Info: iteration 40, average log likelihood -1.419261
[ Info: iteration 41, average log likelihood -1.419258
[ Info: iteration 42, average log likelihood -1.419256
[ Info: iteration 43, average log likelihood -1.419253
[ Info: iteration 44, average log likelihood -1.419251
[ Info: iteration 45, average log likelihood -1.419250
[ Info: iteration 46, average log likelihood -1.419248
[ Info: iteration 47, average log likelihood -1.419247
[ Info: iteration 48, average log likelihood -1.419245
[ Info: iteration 49, average log likelihood -1.419244
[ Info: iteration 50, average log likelihood -1.419243
┌ Info: EM with 100000 data points 50 iterations avll -1.419243
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4206369698248926
│     -1.4205645523770634
│      ⋮
└     -1.4192433082512257
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419258
[ Info: iteration 2, average log likelihood -1.419213
[ Info: iteration 3, average log likelihood -1.419182
[ Info: iteration 4, average log likelihood -1.419144
[ Info: iteration 5, average log likelihood -1.419098
[ Info: iteration 6, average log likelihood -1.419039
[ Info: iteration 7, average log likelihood -1.418966
[ Info: iteration 8, average log likelihood -1.418881
[ Info: iteration 9, average log likelihood -1.418785
[ Info: iteration 10, average log likelihood -1.418682
[ Info: iteration 11, average log likelihood -1.418579
[ Info: iteration 12, average log likelihood -1.418478
[ Info: iteration 13, average log likelihood -1.418384
[ Info: iteration 14, average log likelihood -1.418297
[ Info: iteration 15, average log likelihood -1.418219
[ Info: iteration 16, average log likelihood -1.418149
[ Info: iteration 17, average log likelihood -1.418088
[ Info: iteration 18, average log likelihood -1.418035
[ Info: iteration 19, average log likelihood -1.417989
[ Info: iteration 20, average log likelihood -1.417950
[ Info: iteration 21, average log likelihood -1.417917
[ Info: iteration 22, average log likelihood -1.417888
[ Info: iteration 23, average log likelihood -1.417864
[ Info: iteration 24, average log likelihood -1.417843
[ Info: iteration 25, average log likelihood -1.417825
[ Info: iteration 26, average log likelihood -1.417810
[ Info: iteration 27, average log likelihood -1.417796
[ Info: iteration 28, average log likelihood -1.417785
[ Info: iteration 29, average log likelihood -1.417775
[ Info: iteration 30, average log likelihood -1.417766
[ Info: iteration 31, average log likelihood -1.417758
[ Info: iteration 32, average log likelihood -1.417751
[ Info: iteration 33, average log likelihood -1.417745
[ Info: iteration 34, average log likelihood -1.417740
[ Info: iteration 35, average log likelihood -1.417734
[ Info: iteration 36, average log likelihood -1.417730
[ Info: iteration 37, average log likelihood -1.417725
[ Info: iteration 38, average log likelihood -1.417721
[ Info: iteration 39, average log likelihood -1.417718
[ Info: iteration 40, average log likelihood -1.417714
[ Info: iteration 41, average log likelihood -1.417711
[ Info: iteration 42, average log likelihood -1.417707
[ Info: iteration 43, average log likelihood -1.417704
[ Info: iteration 44, average log likelihood -1.417702
[ Info: iteration 45, average log likelihood -1.417699
[ Info: iteration 46, average log likelihood -1.417696
[ Info: iteration 47, average log likelihood -1.417693
[ Info: iteration 48, average log likelihood -1.417691
[ Info: iteration 49, average log likelihood -1.417688
[ Info: iteration 50, average log likelihood -1.417686
┌ Info: EM with 100000 data points 50 iterations avll -1.417686
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.41925805835497
│     -1.4192134699137033
│      ⋮
└     -1.4176861328285124
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417694
[ Info: iteration 2, average log likelihood -1.417651
[ Info: iteration 3, average log likelihood -1.417613
[ Info: iteration 4, average log likelihood -1.417570
[ Info: iteration 5, average log likelihood -1.417517
[ Info: iteration 6, average log likelihood -1.417451
[ Info: iteration 7, average log likelihood -1.417371
[ Info: iteration 8, average log likelihood -1.417281
[ Info: iteration 9, average log likelihood -1.417186
[ Info: iteration 10, average log likelihood -1.417090
[ Info: iteration 11, average log likelihood -1.417000
[ Info: iteration 12, average log likelihood -1.416916
[ Info: iteration 13, average log likelihood -1.416839
[ Info: iteration 14, average log likelihood -1.416768
[ Info: iteration 15, average log likelihood -1.416702
[ Info: iteration 16, average log likelihood -1.416643
[ Info: iteration 17, average log likelihood -1.416588
[ Info: iteration 18, average log likelihood -1.416539
[ Info: iteration 19, average log likelihood -1.416495
[ Info: iteration 20, average log likelihood -1.416456
[ Info: iteration 21, average log likelihood -1.416420
[ Info: iteration 22, average log likelihood -1.416388
[ Info: iteration 23, average log likelihood -1.416358
[ Info: iteration 24, average log likelihood -1.416330
[ Info: iteration 25, average log likelihood -1.416304
[ Info: iteration 26, average log likelihood -1.416279
[ Info: iteration 27, average log likelihood -1.416256
[ Info: iteration 28, average log likelihood -1.416233
[ Info: iteration 29, average log likelihood -1.416211
[ Info: iteration 30, average log likelihood -1.416190
[ Info: iteration 31, average log likelihood -1.416169
[ Info: iteration 32, average log likelihood -1.416149
[ Info: iteration 33, average log likelihood -1.416130
[ Info: iteration 34, average log likelihood -1.416111
[ Info: iteration 35, average log likelihood -1.416093
[ Info: iteration 36, average log likelihood -1.416075
[ Info: iteration 37, average log likelihood -1.416058
[ Info: iteration 38, average log likelihood -1.416042
[ Info: iteration 39, average log likelihood -1.416027
[ Info: iteration 40, average log likelihood -1.416012
[ Info: iteration 41, average log likelihood -1.415998
[ Info: iteration 42, average log likelihood -1.415984
[ Info: iteration 43, average log likelihood -1.415971
[ Info: iteration 44, average log likelihood -1.415959
[ Info: iteration 45, average log likelihood -1.415947
[ Info: iteration 46, average log likelihood -1.415936
[ Info: iteration 47, average log likelihood -1.415925
[ Info: iteration 48, average log likelihood -1.415915
[ Info: iteration 49, average log likelihood -1.415905
[ Info: iteration 50, average log likelihood -1.415896
┌ Info: EM with 100000 data points 50 iterations avll -1.415896
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4176943838637959
│     -1.4176506330389376
│      ⋮
└     -1.4158958854470374
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415895
[ Info: iteration 2, average log likelihood -1.415831
[ Info: iteration 3, average log likelihood -1.415766
[ Info: iteration 4, average log likelihood -1.415686
[ Info: iteration 5, average log likelihood -1.415583
[ Info: iteration 6, average log likelihood -1.415455
[ Info: iteration 7, average log likelihood -1.415304
[ Info: iteration 8, average log likelihood -1.415138
[ Info: iteration 9, average log likelihood -1.414968
[ Info: iteration 10, average log likelihood -1.414802
[ Info: iteration 11, average log likelihood -1.414647
[ Info: iteration 12, average log likelihood -1.414505
[ Info: iteration 13, average log likelihood -1.414378
[ Info: iteration 14, average log likelihood -1.414265
[ Info: iteration 15, average log likelihood -1.414164
[ Info: iteration 16, average log likelihood -1.414075
[ Info: iteration 17, average log likelihood -1.413995
[ Info: iteration 18, average log likelihood -1.413924
[ Info: iteration 19, average log likelihood -1.413860
[ Info: iteration 20, average log likelihood -1.413802
[ Info: iteration 21, average log likelihood -1.413750
[ Info: iteration 22, average log likelihood -1.413703
[ Info: iteration 23, average log likelihood -1.413660
[ Info: iteration 24, average log likelihood -1.413620
[ Info: iteration 25, average log likelihood -1.413584
[ Info: iteration 26, average log likelihood -1.413550
[ Info: iteration 27, average log likelihood -1.413518
[ Info: iteration 28, average log likelihood -1.413488
[ Info: iteration 29, average log likelihood -1.413460
[ Info: iteration 30, average log likelihood -1.413433
[ Info: iteration 31, average log likelihood -1.413407
[ Info: iteration 32, average log likelihood -1.413383
[ Info: iteration 33, average log likelihood -1.413360
[ Info: iteration 34, average log likelihood -1.413338
[ Info: iteration 35, average log likelihood -1.413316
[ Info: iteration 36, average log likelihood -1.413296
[ Info: iteration 37, average log likelihood -1.413276
[ Info: iteration 38, average log likelihood -1.413257
[ Info: iteration 39, average log likelihood -1.413239
[ Info: iteration 40, average log likelihood -1.413222
[ Info: iteration 41, average log likelihood -1.413205
[ Info: iteration 42, average log likelihood -1.413188
[ Info: iteration 43, average log likelihood -1.413172
[ Info: iteration 44, average log likelihood -1.413156
[ Info: iteration 45, average log likelihood -1.413141
[ Info: iteration 46, average log likelihood -1.413126
[ Info: iteration 47, average log likelihood -1.413111
[ Info: iteration 48, average log likelihood -1.413097
[ Info: iteration 49, average log likelihood -1.413082
[ Info: iteration 50, average log likelihood -1.413068
┌ Info: EM with 100000 data points 50 iterations avll -1.413068
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4158954009350129
│     -1.4158307615554067
│      ⋮
└     -1.4130681388758772
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4262615065911182
│     -1.426282692851172
│     -1.426214164653947
│     -1.4261466902772628
│      ⋮
│     -1.41309669938323
│     -1.4130823280018807
└     -1.4130681388758772
32×26 Array{Float64,2}:
  0.0449654    0.118313    -0.102301    0.0168171  -0.00923749  -0.0740746   -0.0767886    0.158212    -0.0658268   0.0464603    0.108605    0.0778781   0.0533292   -0.279776   -0.0281533    0.169587     0.183777    -0.339711   -0.0902882   0.0116355   0.260622    0.0900817   0.0672544    0.152392    -0.0815091    0.133346
  0.00297996  -0.0715785   -0.0289818  -0.085346   -0.0922768    0.109095     0.0361099    0.0647662   -0.0646695  -0.0195899   -0.0723552   0.0288328   0.126621     0.143555    0.135434    -0.153099    -0.254041     0.114084    0.131341   -0.0810421  -0.176559    0.0285994  -0.00274461  -0.064997     0.237044     0.0291447
  0.42507      0.533825    -0.245553    0.470356   -0.545159    -0.119704     0.212647    -0.0586376   -0.44745    -0.270235    -0.127834   -0.456874    0.29092      0.207544    0.00308865   0.105073     0.206359    -0.229857   -0.0301334  -0.0702287   0.164908   -0.16664    -0.0569861   -0.122977     0.0759737   -0.00348008
 -0.0372138   -0.0899131   -0.271112    0.504916    0.59968     -0.112943     0.337163     0.0292104   -0.247347   -0.181909    -0.199711   -0.289416    0.155806     0.162543   -0.316128    -0.113943     0.404403    -0.0458209  -0.505227    0.128883   -0.107722   -0.168059   -0.0876229   -0.0588003    0.416716    -0.047507
 -0.115549     0.00945597  -0.134496   -0.314093   -0.348657    -0.133789     0.247998    -0.195511    -0.0295471  -0.167381     0.506291    0.105255    0.00643403  -0.478005   -0.388728     0.185836    -0.742088    -0.253251   -0.198535   -0.235552   -0.171873    0.0475148  -0.0655881   -0.0169292   -0.0997531    0.348247
 -0.278428    -0.496518    -0.504735   -0.31855     0.513405    -0.478103    -0.219543    -0.296759     0.241607    0.121978    -0.245026    0.219081    0.00430652  -0.0612889  -0.356646     0.0219346   -0.342377    -0.38548    -0.161612   -0.604059   -0.355696    0.220488   -0.317189     0.00921742  -0.0673601   -0.090521
 -0.680362     0.388083     0.154667   -0.286531    0.147834    -0.266859     0.611649    -0.349333    -0.467137    0.691497    -0.0452473   0.0979286  -0.0133484    0.339572    0.536785    -0.13128     -0.12068     -0.446332    0.0894949   0.357925   -0.55803     0.121487   -0.182006    -0.635189     0.263994    -0.420299
 -0.513222    -0.0849277    0.307869    0.254078   -0.0952985   -0.633665    -0.213298    -0.324866     0.141101    0.306299    -0.267371   -0.542786   -0.139198    -0.132842    0.547212    -0.551199    -0.634413    -0.291796    0.38122    -0.0739939  -0.516699    0.3828     -0.168146    -0.451859     0.626645    -0.0322653
  0.051349    -0.552162    -0.1702     -0.618962   -0.0556748    0.550832    -0.0548476    0.508651    -0.616243    0.107734    -0.238986   -0.0250133  -0.150139     0.396381    0.319637    -0.241598     0.227616     0.140227    0.0516638  -0.185858   -0.0336206   0.108799   -0.100438     0.340275    -0.00715277  -0.226128
 -0.0971307   -0.850097     0.213499   -0.518597    0.180932     0.171193    -0.297181     0.00343329   0.314718   -0.327193     0.222795   -0.208593   -0.64973      0.274099   -0.358147     0.0811592   -0.148477    -0.274347    0.308631    0.131531    0.277408   -0.0999015  -0.485912     0.493702     0.0897713   -0.0723069
 -0.0985142   -0.740967    -0.0301305   0.282184   -0.151565     0.00379015  -0.36103      0.515613     0.495374    0.0298565   -0.0746773  -0.741692   -0.466737    -0.0206524   0.329095     0.0682231   -0.0507879    0.24037     0.298597    0.253706    0.285676   -0.0310036   0.177924     0.201432     0.342278    -0.184455
 -0.173508    -0.262109     0.265702    0.0657986   0.00787356   0.0918412   -0.0829755    0.24432      0.324184    0.375291    -0.0412571   0.506187   -0.154537    -0.23792     0.0651469    0.184419     0.0778027    0.258453    0.198888    0.865686    0.189252   -0.303723    0.177103     0.0357392    0.38933     -0.122574
  0.0282946    0.192291    -0.174034   -0.445733   -0.489157     0.341367    -0.381903     0.385017     0.261086   -0.371966    -0.224771    0.242908   -0.220812    -0.270015    0.804944     0.308491    -0.589977     0.0781233   0.643479    0.0103477   0.459509    0.31854     0.34456     -0.0773168   -0.0488711    0.238115
  0.411742     0.615572     0.285171    0.150213   -0.145341     0.690564    -0.0488403    0.00657384   0.0754575   0.120368     0.408828    0.439584    0.204513    -0.253977    0.084524    -0.02159      0.324542     0.0937652   0.162344   -0.0812621   0.473263    0.596142    0.566532     0.178789    -0.402994     0.449061
  0.0280759    0.331068     0.212127    0.138589    0.285181     0.0278167   -0.107983    -0.137629     0.209945    0.0961418   -0.379224   -0.206807   -0.0852227    0.397797    0.075516    -0.0292214    0.237052     0.112681    0.176601   -0.0457978  -0.466835    0.096537    0.365019    -0.235178    -0.541759    -0.293697
 -0.140813     0.100746     0.388478    0.120854    0.0493046    0.234684    -0.398097    -0.372072     0.150877    0.0187756    0.396409    0.2067     -0.0798498    0.0374019  -0.00399379  -0.140238     0.0847008    0.447284    0.202149   -0.238568   -0.395042    0.0318788  -0.302231     0.154427    -0.106979     0.196985
  0.103038     0.489531    -0.653628   -0.0180846   0.0992818    0.054618     0.621461     0.469943    -0.490503   -0.0928      -0.373722   -0.252441   -0.474738    -0.335571   -0.161342     0.17568      0.188236     0.197101   -0.330462   -0.314196    0.425352   -0.230503    1.0304      -0.061902    -0.757488    -0.193402
  0.0853373   -0.140519    -0.101516   -0.0492789  -0.249611    -0.195064     0.328278     0.710005    -0.350519   -0.0600999   -0.203921   -0.129131    0.12173     -0.457157    0.050932     0.301441     0.339216    -0.66356    -0.423873   -0.0351655   0.68657    -0.048348    0.0856728    0.679952     0.0175779    0.251017
  0.0106188   -0.300602    -0.459948    0.290885   -0.110508    -0.0993829    0.243682     0.745652    -0.583979   -0.00911248  -0.486889   -0.493674    0.279675    -0.561924   -0.322245    -0.808084    -0.346919    -0.379843    0.282131   -0.909377   -0.112132    0.28299     0.374235    -0.155202     0.413258    -0.059596
  0.322745     0.699002    -0.355997    0.0583795  -0.0317138    0.0676756    0.248219     0.331809    -0.191189   -0.0425359   -0.445768    0.605706    0.70364      0.0737821   0.0276264   -0.406369    -0.326993    -0.0044486  -0.0723304  -0.109063   -0.204249    0.159626    0.346042    -0.52275      0.245241    -0.286907
  0.296531     0.0277745   -0.148882    0.794364    0.138313    -0.093699    -0.609977    -0.466681    -0.0624286  -0.0381225    0.824934   -0.333788   -0.354653    -0.146637   -0.783447    -0.177792    -0.302425     0.244851    0.3461     -0.179377   -0.059347    0.06645     0.15478     -0.424777     0.17822     -0.090937
  0.408715     0.616087    -0.129014    0.0224462  -0.178681    -0.10873      0.173031    -0.557658    -0.589769   -0.174053     0.317021    0.0866644   0.818726    -0.166321   -0.422526    -0.219423    -0.0578175   -0.265843   -0.455579   -0.448772   -0.34116     0.207207   -0.202528    -0.163847    -0.289564     0.403868
  0.586288    -0.0971394    0.239799    0.229444    0.403459    -0.773191     0.441182    -0.146272     0.966489   -0.567992    -0.0302345   0.417787    0.864215    -1.03255    -0.528861     0.0754741   -0.00616499   0.407773   -0.621596   -1.13735    -0.46768    -0.0453274   0.625079     0.647806    -0.613289     0.937692
 -0.11837      0.719207     0.482135    0.139651    0.0924613   -0.417784     0.016008    -0.439425     0.463522   -0.131936     0.574721    0.14046    -0.238788     0.0496403   0.0848597    0.738299     0.144158    -0.0130772  -0.488011    0.569661    0.11141    -0.141489   -0.0292518   -0.193266    -0.239516     0.367814
 -0.27819     -0.39551     -0.272891   -0.191651    0.320472    -0.184285     0.00895605  -0.185259     0.144102   -0.419882    -0.241412    0.0980265   0.249221     0.59575    -0.177249    -0.301439     0.114672    -0.216278   -0.308172   -0.12989    -0.45391    -0.430433   -1.17277     -0.134578     0.656272    -0.170256
 -0.0844666   -0.160513     0.0912802  -0.153258    0.228924     0.290337     0.498986    -0.0485666   -0.378115   -0.35931      0.0373053  -0.246632   -0.0713737    0.600501   -0.42571      0.0936471    0.184169     0.362399    0.0260668  -0.116181   -0.667936   -0.499815    0.394969     0.387947    -0.36399     -0.259659
 -0.0978273   -0.236611     0.259451   -0.122304   -0.177203     0.652152    -0.432343    -0.359228     0.34132     0.263425     0.225646    0.282665   -0.0639419    0.605786    0.0398214    0.171982     0.00575545   0.732964    0.0889585   0.356109   -0.87673    -0.388988   -0.400672     0.142673    -0.641446    -0.0178129
  0.379999    -0.267796     0.387445   -0.332847    0.804804    -0.274671    -0.070585    -0.0369291    0.629251    0.353748    -0.643697    0.476524    0.388924    -0.0575796   0.624753     0.399554     0.00288      0.275974    0.178889    0.212227   -0.492724   -0.0349436   0.0168028   -0.117312    -0.147165    -0.41054
  0.0200401    0.0510637    0.165914    0.15517    -0.00147298   0.0973623   -0.112263     0.255977     0.141992    0.0366676   -0.224329   -0.0327093  -0.328153     0.089174    0.266325     0.0400322    0.0269011    0.0210422   0.19051     0.339635    0.255863    0.130313    0.286445     0.0776644    0.144846    -0.226059
 -0.665776    -0.663464    -0.252659   -0.621937   -0.151046    -0.126416    -0.400665     0.0636028    0.610404    0.746778     0.498229    0.326148   -0.160356    -0.507158    0.380179     0.00199637  -0.187755    -0.273002    0.161872   -0.10192     0.0821119   0.275612   -0.274621    -0.0398174    0.0702068    0.198883
  0.388943    -0.233749     0.830701    0.165931   -0.447442     0.192078    -0.754788    -0.338434     0.273673    0.315138     0.585551    0.563225    0.398712     0.440951    0.158383    -0.268938     0.290942    -0.340198    0.512795    0.357806    0.224502    0.529027   -0.815919     0.120701     0.79053     -0.0628906
 -0.311906     0.228844    -0.163471    1.08286    -0.23132     -0.321485    -0.435024     0.283259    -0.0906635   0.0994822    0.0311445  -0.199062    0.317043    -0.163138    0.209926     0.0268517    0.464382     0.0248185  -0.307065    0.184143    0.449477    0.0417001  -0.257159    -0.0323821    0.741844     0.930285[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413054
[ Info: iteration 2, average log likelihood -1.413040
[ Info: iteration 3, average log likelihood -1.413027
[ Info: iteration 4, average log likelihood -1.413013
[ Info: iteration 5, average log likelihood -1.412999
[ Info: iteration 6, average log likelihood -1.412986
[ Info: iteration 7, average log likelihood -1.412973
[ Info: iteration 8, average log likelihood -1.412960
[ Info: iteration 9, average log likelihood -1.412947
[ Info: iteration 10, average log likelihood -1.412934
┌ Info: EM with 100000 data points 10 iterations avll -1.412934
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind full, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.834041e+05
      1       7.084017e+05      -2.750025e+05 |       32
      2       6.960274e+05      -1.237425e+04 |       32
      3       6.913182e+05      -4.709213e+03 |       32
      4       6.888655e+05      -2.452769e+03 |       32
      5       6.872454e+05      -1.620101e+03 |       32
      6       6.860590e+05      -1.186340e+03 |       32
      7       6.850937e+05      -9.653207e+02 |       32
      8       6.843401e+05      -7.535877e+02 |       32
      9       6.837549e+05      -5.852518e+02 |       32
     10       6.833061e+05      -4.487729e+02 |       32
     11       6.829587e+05      -3.473406e+02 |       32
     12       6.826485e+05      -3.102462e+02 |       32
     13       6.823764e+05      -2.720579e+02 |       32
     14       6.821273e+05      -2.491814e+02 |       32
     15       6.819085e+05      -2.187434e+02 |       32
     16       6.817062e+05      -2.022905e+02 |       32
     17       6.815407e+05      -1.655382e+02 |       32
     18       6.814128e+05      -1.279259e+02 |       32
     19       6.812951e+05      -1.176462e+02 |       32
     20       6.811826e+05      -1.124749e+02 |       32
     21       6.810831e+05      -9.948768e+01 |       32
     22       6.809841e+05      -9.906128e+01 |       32
     23       6.808841e+05      -9.993630e+01 |       32
     24       6.807795e+05      -1.046761e+02 |       32
     25       6.806821e+05      -9.735454e+01 |       32
     26       6.806042e+05      -7.794792e+01 |       32
     27       6.805339e+05      -7.024929e+01 |       32
     28       6.804574e+05      -7.649468e+01 |       32
     29       6.803775e+05      -7.996625e+01 |       32
     30       6.802974e+05      -8.006324e+01 |       32
     31       6.802216e+05      -7.581316e+01 |       32
     32       6.801554e+05      -6.614621e+01 |       32
     33       6.800947e+05      -6.074135e+01 |       32
     34       6.800373e+05      -5.739284e+01 |       32
     35       6.799758e+05      -6.153197e+01 |       32
     36       6.799130e+05      -6.281130e+01 |       32
     37       6.798536e+05      -5.938244e+01 |       32
     38       6.797963e+05      -5.726474e+01 |       32
     39       6.797345e+05      -6.180427e+01 |       32
     40       6.796814e+05      -5.310395e+01 |       32
     41       6.796292e+05      -5.222952e+01 |       32
     42       6.795755e+05      -5.369666e+01 |       32
     43       6.795231e+05      -5.241383e+01 |       32
     44       6.794741e+05      -4.892359e+01 |       32
     45       6.794315e+05      -4.263881e+01 |       32
     46       6.793908e+05      -4.072865e+01 |       32
     47       6.793466e+05      -4.416225e+01 |       32
     48       6.792966e+05      -5.003232e+01 |       32
     49       6.792481e+05      -4.847544e+01 |       32
     50       6.791986e+05      -4.954118e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 679198.5606068906)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425281
[ Info: iteration 2, average log likelihood -1.420202
[ Info: iteration 3, average log likelihood -1.418715
[ Info: iteration 4, average log likelihood -1.417488
[ Info: iteration 5, average log likelihood -1.416197
[ Info: iteration 6, average log likelihood -1.415144
[ Info: iteration 7, average log likelihood -1.414529
[ Info: iteration 8, average log likelihood -1.414211
[ Info: iteration 9, average log likelihood -1.414022
[ Info: iteration 10, average log likelihood -1.413887
[ Info: iteration 11, average log likelihood -1.413780
[ Info: iteration 12, average log likelihood -1.413688
[ Info: iteration 13, average log likelihood -1.413607
[ Info: iteration 14, average log likelihood -1.413535
[ Info: iteration 15, average log likelihood -1.413471
[ Info: iteration 16, average log likelihood -1.413413
[ Info: iteration 17, average log likelihood -1.413362
[ Info: iteration 18, average log likelihood -1.413315
[ Info: iteration 19, average log likelihood -1.413273
[ Info: iteration 20, average log likelihood -1.413235
[ Info: iteration 21, average log likelihood -1.413201
[ Info: iteration 22, average log likelihood -1.413169
[ Info: iteration 23, average log likelihood -1.413140
[ Info: iteration 24, average log likelihood -1.413113
[ Info: iteration 25, average log likelihood -1.413087
[ Info: iteration 26, average log likelihood -1.413063
[ Info: iteration 27, average log likelihood -1.413040
[ Info: iteration 28, average log likelihood -1.413019
[ Info: iteration 29, average log likelihood -1.412998
[ Info: iteration 30, average log likelihood -1.412978
[ Info: iteration 31, average log likelihood -1.412959
[ Info: iteration 32, average log likelihood -1.412940
[ Info: iteration 33, average log likelihood -1.412922
[ Info: iteration 34, average log likelihood -1.412905
[ Info: iteration 35, average log likelihood -1.412888
[ Info: iteration 36, average log likelihood -1.412871
[ Info: iteration 37, average log likelihood -1.412854
[ Info: iteration 38, average log likelihood -1.412838
[ Info: iteration 39, average log likelihood -1.412822
[ Info: iteration 40, average log likelihood -1.412806
[ Info: iteration 41, average log likelihood -1.412791
[ Info: iteration 42, average log likelihood -1.412775
[ Info: iteration 43, average log likelihood -1.412760
[ Info: iteration 44, average log likelihood -1.412745
[ Info: iteration 45, average log likelihood -1.412731
[ Info: iteration 46, average log likelihood -1.412717
[ Info: iteration 47, average log likelihood -1.412703
[ Info: iteration 48, average log likelihood -1.412689
[ Info: iteration 49, average log likelihood -1.412676
[ Info: iteration 50, average log likelihood -1.412664
┌ Info: EM with 100000 data points 50 iterations avll -1.412664
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0987684    0.401488   -0.0481889   0.521377    0.198637   -0.161496   -0.0342752   -0.19779       0.033903     0.0418062   -0.313895   -0.473483    -0.0472085   0.367283    0.0504703  -0.0440875   0.315859    0.0133488   0.0209492   -0.0364496  -0.346899    0.0615018     0.188081    -0.225296   -0.314176    -0.236732
  0.00999334  -0.0201159   0.052607    0.0204881   0.110954    0.0501269   0.51945      0.520124     -0.22566     -0.148997    -0.577056   -0.0780104   -0.69043    -0.130635    0.497943    0.371165    0.427805    0.0690099   0.00767949   0.297975    0.577779   -0.21227       0.649084     0.655125   -0.0648861   -0.411702
  0.585079     0.710141   -0.0585321   0.432331   -0.75652    -0.0287799   0.186652    -0.265839     -0.637373    -0.697098     0.0642012  -0.567946     0.189329    0.28735    -0.0915299   0.275424   -0.0566987  -0.117721   -0.0898315   -0.227791    0.178524   -0.573379     -0.244777    -0.136622    0.183711    -0.0378065
  0.416402     0.720584    0.316393    0.093483   -0.205488    0.67424    -0.10189     -0.0178969     0.137699    -0.0124744    0.406063    0.457691     0.0364664  -0.0519819   0.2666      0.186729    0.26848     0.121799    0.213563    -0.139383    0.314145    0.468396      0.500197     0.210207   -0.447859     0.338608
 -0.27757      0.721319    0.413925    0.111917    0.566175   -0.826388    0.751802    -0.741894      0.15986      0.0595206    0.138277    0.234374     0.303509   -0.0836972   0.0980054   0.143473   -0.0760487  -0.223355   -0.459748    -0.232629   -0.679883    0.0522072     0.0520941   -0.33102    -0.160214    -0.0675833
  0.244447     0.150477   -0.729514    0.148273   -0.245018   -0.0313067   0.430242     0.64629      -0.556021     0.0224434   -0.469577   -0.306274     0.290366   -0.319006   -0.111437   -0.658511   -0.121045   -0.322349    0.032357    -0.855202    0.0564875   0.326333      0.454483    -0.0743579   0.0416063   -0.219567
 -0.605372     0.0860956   0.322223   -0.209915   -0.0497724  -0.493696   -0.312489    -0.0852988    -0.293161     0.463514    -0.666475   -0.245678    -0.569858   -0.359204    1.09261    -0.307943   -0.540108   -0.439822    0.280631    -0.477319   -0.186558    0.61452      -0.238174    -0.626491    0.849434     0.449383
 -0.225638     0.0822816  -0.111497    0.934945   -0.479628   -0.480001   -0.446666     0.380333     -0.0536146   -0.00655131  -0.0112423  -0.313613     0.62603    -0.0102332   0.534547    0.228607    0.598572    0.132627   -0.0781442    0.308702    0.577026   -0.101711     -0.584232     0.445358    0.801782     0.68055
  0.0456955    0.140611    0.0905072   0.0964867  -0.0481123  -0.0226073  -0.0890831   -0.000213044   0.0665498    0.0587136    0.0151348   0.0670301    0.113641    0.0434189   0.0513034  -0.0349017  -0.0925693  -0.0510781  -0.0123105    0.0580965  -0.202578   -0.000566776   0.0589387   -0.110337    0.00375124   0.0412578
 -0.276401    -0.728996   -0.1272      0.194723    0.316713   -0.359515   -0.0774588    0.285472      0.0512777    0.0049922   -0.425426   -0.387788    -0.238242    0.208054   -0.131374   -0.0716838  -0.0685469  -0.0691312  -0.00484882   0.204668   -0.215301   -0.468134     -0.280212    -0.0190747   0.695879    -0.410311
  0.236769    -0.426627    0.237154   -0.649501    0.445533   -0.223115   -0.168617     0.0779943     0.378688     0.278128    -0.603639    0.209118     0.361168   -0.168655    0.694484    0.246794   -0.0564653  -0.193518    0.464621    -0.0496954  -0.392552    0.237388     -0.0968627    0.141106   -0.685298    -0.525055
  0.338611     0.509137    0.240588   -0.542579   -0.722301    0.190512   -0.00898407  -0.556313     -0.375727     0.207789     0.814719    0.382849     0.661181   -0.412279   -0.491547   -0.383609   -0.182825   -0.303714   -0.312726    -0.36282    -0.163391    0.477661     -0.367851    -0.107651   -0.577195     0.805188
  0.582765    -0.266829    0.0409396   0.22184     0.258823   -0.367949    0.0779354    0.153315      0.592953    -0.483491     0.0346805   0.392986     0.684736   -1.08044    -0.615922    0.217809   -0.107598    0.461437   -0.463398    -0.932141   -0.0686674  -0.0585015     0.562785     0.593288   -0.563163     0.973684
 -0.249968    -0.41892     0.0740952   0.200223   -0.390106    0.143681   -0.467417     0.240307      0.407719     0.198971     0.472405   -0.23597     -0.646833   -0.502138    0.202432    0.0427157  -0.249851    0.313877    0.536352     0.286685    0.37745     0.150207      0.425528     0.186582    0.0511698    0.0158722
 -0.0439429    0.526322   -0.113832    0.357166    0.136593   -0.700359   -0.271353     0.263402      0.312926     0.116264     0.0840207  -0.198706    -0.341882   -0.480665   -0.201982    0.373111    0.465252   -0.814223   -0.495992     0.0919922   0.861596    0.304408      0.259274     0.0635036  -0.147564     0.512966
 -0.0819338   -0.134509    0.0342799  -0.114422   -0.0436902   0.023539   -0.145391    -0.0414088     0.160354     0.0295761    0.0752521   0.00660833  -0.142053   -0.0304657   0.0757105   0.0853086  -0.135697   -0.0195351   0.0703862   -0.0186325  -0.0805011   0.0422068     0.00299386   0.0241889  -0.00516003   0.110251
 -0.0889684   -0.746958    0.409847   -0.718216   -0.025791    0.70873     0.0888043    0.0931578    -0.0534186   -0.328776    -0.0104075  -0.046212    -0.234921    0.586787   -0.154207   -0.120233   -0.23513     0.239244    0.458151     0.0343699  -0.340234   -0.0282353    -0.21855      0.610258   -0.114012    -0.274534
  0.00228536   0.300204   -0.251607   -0.783853    0.0448328   0.17065     0.318385     0.139666     -0.178686    -0.451337    -0.0939619   0.0683939   -0.470159   -0.0573878  -0.33668     0.317981   -0.495671   -0.0278773   0.121825    -0.270762   -0.227772   -0.197286      0.914943    -0.21657    -0.622136    -0.191171
 -0.172217    -0.0952457  -0.706844   -0.34723     0.381522    0.0225065   0.317905    -0.398418      0.29955     -0.480259    -0.412895    0.246962     0.625735    0.834182    0.237075   -0.307018    0.532967   -0.0853657  -0.454364    -0.353365   -0.205055   -0.128396     -1.13611     -0.0973862   0.321522     0.0794608
 -0.326361     0.0614204   0.385329    0.204935    0.236107    0.356814   -0.412202    -0.27377       0.156635    -0.11121      0.12665     0.205155    -0.247103    0.352413   -0.0988776  -0.31211     0.168773    0.633048    0.11532     -0.329423   -0.455038    0.00765314   -0.481551     0.287926   -0.118398     0.300953
 -0.0501825    0.239581   -0.0209867  -0.148736    0.210771    0.0647169   0.353994    -0.0241688    -0.445256     0.116526    -0.149111    0.298002     0.584641    0.246629   -0.0642368  -0.380131   -0.19811     0.0193765  -0.0448294   -0.220632   -0.661222    0.0654093    -0.038267    -0.333051    0.167667    -0.293491
 -0.190544     0.0667371   0.549872    0.0492808   0.186279    0.0806716  -0.161538    -0.466892      0.603095     0.222826     0.227237    0.45865     -0.317722    0.186343    0.191024    0.54667     0.249019    0.524835   -0.256985     1.04291    -0.275955   -0.407171     -0.27707     -0.156087    0.0203536    0.177305
 -0.324905    -1.16082    -0.306624   -0.816891    0.178319    0.233895   -0.429804     0.0527016     0.00819241   0.622214     0.289694   -0.251143    -0.261779    0.110434    0.0931033   0.335701    0.182444    0.170669   -0.217774    -0.421769   -0.191087   -0.170516     -0.256537     0.216799   -0.395369     0.303878
  0.195037    -0.017349   -0.0332091  -0.010092   -0.155747    0.525893   -0.313463     0.504376      0.417012     0.216317    -0.583911    0.485811     0.365774    0.114924    0.553512   -0.0617424  -0.167194    0.490167    0.358388     0.45657     0.329463    0.291414      0.242668    -0.224611    0.473344    -0.0792952
 -0.00269287   0.272877   -0.207101    0.033711   -0.331183   -0.492676    0.113634    -0.204654      0.237866    -0.0290403    0.191903    0.438933     0.527086   -0.529275    0.23434    -0.0040278  -0.555882   -0.116827    0.230674     0.34128    -0.056614    0.191013      0.250484    -0.446095    0.260091     0.0893601
  0.19463      0.163014   -0.175671    0.141039   -0.0420996   0.114289    0.175544     0.384799     -0.363417     0.03629     -0.0220302   0.0964711    0.31252    -0.148189   -0.0234351  -0.0292025   0.260686   -0.168707   -0.100978     0.0588606   0.398197    0.0185406     0.100122     0.137478    0.202732     0.106043
  0.130295    -0.431837    0.95621     0.0665424  -0.320386    0.058963   -0.894383    -0.455773      0.379852     0.286139     0.723988    0.399517     0.165544    0.347225    0.122057   -0.240756    0.21137    -0.538466    0.56549      0.383158    0.0688756   0.378005     -0.879593     0.108696    0.693358     0.0362806
 -0.29901     -0.0600712  -0.358679   -0.488193   -0.271956    0.456523   -0.364244     0.335019     -0.483374     0.244199     0.0905372  -0.00740127  -1.02946     0.803407    0.365613   -0.0876859  -0.113118   -0.691149   -0.0301415    0.56015     0.382674    0.569621     -0.392274    -0.16126     0.184298    -0.671072
 -0.313129    -0.392725   -0.296826   -0.310682   -0.134987   -0.291849    0.0253411    0.0867269     0.0151698   -0.122149     0.343772    0.16896      0.0371578  -0.562429   -0.353345    0.155279   -0.329721   -0.697156   -0.190606    -0.263832    0.0924266  -0.0018539    -0.6985       0.395295    0.237645     0.212102
  0.244269    -0.01082    -0.1249      0.601436    0.347667   -0.124423   -0.675889    -0.591677      0.0788431    0.00460292   0.683393   -0.13719     -0.0922974   0.0292349  -0.745943   -0.389829   -0.379281    0.204681    0.278497    -0.270308   -0.435812    0.102379     -0.187493    -0.582662    0.169765    -0.0952653
 -0.150478     0.158945   -0.190567    0.809363    0.0450851   0.208217    0.482683     0.0672441    -0.768926    -0.207224    -0.101275   -0.62374      0.262704   -0.219411   -0.39885    -0.115296    0.132395   -0.047678   -0.859276    -0.0607294   0.208701    0.0171599     0.555459    -0.137184    0.306373     0.866865
  0.475172    -0.0475924  -0.133729    0.363792    0.0216573   0.298517    0.503648     0.328767     -0.197197    -0.284102     0.450404    0.0588146    0.649057    0.45036    -1.03524     0.118976    0.651744    0.484773   -0.278613     0.529237   -0.127523   -0.720343      0.317293     0.514927   -0.495793    -0.367456[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412652
[ Info: iteration 2, average log likelihood -1.412640
[ Info: iteration 3, average log likelihood -1.412629
[ Info: iteration 4, average log likelihood -1.412618
[ Info: iteration 5, average log likelihood -1.412608
[ Info: iteration 6, average log likelihood -1.412598
[ Info: iteration 7, average log likelihood -1.412589
[ Info: iteration 8, average log likelihood -1.412580
[ Info: iteration 9, average log likelihood -1.412571
[ Info: iteration 10, average log likelihood -1.412562
┌ Info: EM with 100000 data points 10 iterations avll -1.412562
└ 59.0 data points per parameter
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
