Julia Version 1.4.0-DEV.661
Commit f6b5e8ad58 (2019-12-24 15:13 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed SortingAlgorithms ── v0.3.1
 Installed GaussianMixtures ─── v0.3.0
 Installed Missings ─────────── v0.4.3
 Installed Blosc ────────────── v0.5.1
 Installed Compat ───────────── v2.2.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed OrderedCollections ─ v1.1.0
 Installed FileIO ───────────── v1.2.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed CMake ────────────── v1.1.2
 Installed LegacyStrings ────── v0.4.1
 Installed PDMats ───────────── v0.9.10
 Installed QuadGK ───────────── v2.3.1
 Installed NearestNeighbors ─── v0.4.4
 Installed Rmath ────────────── v0.6.0
 Installed StaticArrays ─────── v0.12.1
 Installed StatsFuns ────────── v0.9.3
 Installed Parameters ───────── v0.12.0
 Installed JLD ──────────────── v0.9.1
 Installed OpenBLAS_jll ─────── v0.3.7+1
 Installed URIParser ────────── v0.4.0
 Installed BinaryProvider ───── v0.5.8
 Installed StatsBase ────────── v0.32.0
 Installed DataStructures ───── v0.17.6
 Installed FillArrays ───────── v0.8.2
 Installed BinDeps ──────────── v1.0.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed DataAPI ──────────── v1.1.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed SpecialFunctions ─── v0.9.0
 Installed Distances ────────── v0.8.2
 Installed Arpack ───────────── v0.4.0
 Installed Distributions ────── v0.21.11
 Installed Clustering ───────── v0.13.3
 Installed HDF5 ─────────────── v0.12.5
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_bVmqwq/Project.toml`
 [no changes]
  Updating `/tmp/jl_bVmqwq/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_ad4QmE/Project.toml`
 [no changes]
  Updating `/tmp/jl_ad4QmE/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_lBgAZX/Project.toml`
 [no changes]
  Updating `/tmp/jl_lBgAZX/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_qKCmPw/Project.toml`
 [no changes]
  Updating `/tmp/jl_qKCmPw/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_dXsZfy/Project.toml`
 [no changes]
  Updating `/tmp/jl_dXsZfy/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_dXsZfy/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.0
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.3222151974621508e6, [66.5186291154075, 99933.48137088459], [-147.73561177812826 45.84459888681137 174.62881986050306; 288.4737874445931 -492.69660809134 393.1571043849124], [[365.8075704985884 -93.86663804006338 -359.0382945791505; -93.86663804006338 89.73839411569728 112.57844175243032; -359.03829457915054 112.57844175243031 491.2005916925426], [98993.71039511231 216.90752028131834 724.6680162014973; 216.9075202813183 100141.92347241305 399.23372659968175; 724.6680162014973 399.23372659968186 99750.6199630149]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.357417e+03
      1       9.960463e+02      -3.613704e+02 |        6
      2       9.247229e+02      -7.132335e+01 |        2
      3       9.102711e+02      -1.445185e+01 |        0
      4       9.102711e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 910.2710618551064)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.081620
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.909429
[ Info: iteration 2, lowerbound -3.811465
[ Info: iteration 3, lowerbound -3.681765
[ Info: iteration 4, lowerbound -3.485799
[ Info: iteration 5, lowerbound -3.228775
[ Info: iteration 6, lowerbound -2.947809
[ Info: iteration 7, lowerbound -2.700470
[ Info: dropping number of Gaussions to 7
[ Info: iteration 8, lowerbound -2.526979
[ Info: dropping number of Gaussions to 6
[ Info: iteration 9, lowerbound -2.418323
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.354574
[ Info: iteration 11, lowerbound -2.319436
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.311421
[ Info: dropping number of Gaussions to 2
[ Info: iteration 13, lowerbound -2.302928
[ Info: iteration 14, lowerbound -2.299264
[ Info: iteration 15, lowerbound -2.299258
[ Info: iteration 16, lowerbound -2.299255
[ Info: iteration 17, lowerbound -2.299254
[ Info: iteration 18, lowerbound -2.299253
[ Info: iteration 19, lowerbound -2.299253
[ Info: iteration 20, lowerbound -2.299253
[ Info: iteration 21, lowerbound -2.299253
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Wed Dec 25 07:06:10 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Wed Dec 25 07:06:18 2019: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Wed Dec 25 07:06:20 2019: EM with 272 data points 0 iterations avll -2.081620
5.8 data points per parameter
, Wed Dec 25 07:06:22 2019: GMM converted to Variational GMM
, Wed Dec 25 07:06:31 2019: iteration 1, lowerbound -3.909429
, Wed Dec 25 07:06:31 2019: iteration 2, lowerbound -3.811465
, Wed Dec 25 07:06:31 2019: iteration 3, lowerbound -3.681765
, Wed Dec 25 07:06:31 2019: iteration 4, lowerbound -3.485799
, Wed Dec 25 07:06:31 2019: iteration 5, lowerbound -3.228775
, Wed Dec 25 07:06:31 2019: iteration 6, lowerbound -2.947809
, Wed Dec 25 07:06:31 2019: iteration 7, lowerbound -2.700470
, Wed Dec 25 07:06:31 2019: dropping number of Gaussions to 7
, Wed Dec 25 07:06:31 2019: iteration 8, lowerbound -2.526979
, Wed Dec 25 07:06:31 2019: dropping number of Gaussions to 6
, Wed Dec 25 07:06:31 2019: iteration 9, lowerbound -2.418323
, Wed Dec 25 07:06:31 2019: dropping number of Gaussions to 4
, Wed Dec 25 07:06:31 2019: iteration 10, lowerbound -2.354574
, Wed Dec 25 07:06:31 2019: iteration 11, lowerbound -2.319436
, Wed Dec 25 07:06:31 2019: dropping number of Gaussions to 3
, Wed Dec 25 07:06:31 2019: iteration 12, lowerbound -2.311421
, Wed Dec 25 07:06:31 2019: dropping number of Gaussions to 2
, Wed Dec 25 07:06:31 2019: iteration 13, lowerbound -2.302928
, Wed Dec 25 07:06:31 2019: iteration 14, lowerbound -2.299264
, Wed Dec 25 07:06:31 2019: iteration 15, lowerbound -2.299258
, Wed Dec 25 07:06:31 2019: iteration 16, lowerbound -2.299255
, Wed Dec 25 07:06:31 2019: iteration 17, lowerbound -2.299254
, Wed Dec 25 07:06:31 2019: iteration 18, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 19, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 20, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 21, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 22, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 23, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 24, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 25, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 26, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 27, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 28, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 29, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 30, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 31, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 32, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 33, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 34, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 35, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 36, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 37, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 38, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 39, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 40, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 41, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 42, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 43, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 44, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 45, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 46, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 47, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 48, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 49, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: iteration 50, lowerbound -2.299253
, Wed Dec 25 07:06:31 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601374, 95.95490777398626]
β = [178.04509222601374, 95.95490777398626]
m = [4.250300733269911 79.28686694436186; 2.0002292577753713 53.8519871724613]
ν = [180.04509222601374, 97.95490777398626]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484569 -0.007644049042327326; 0.0 0.00858170516633351], [0.375876361194839 -0.008953123827345944; 0.0 0.012748664777409335]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999993
avll from stats: -0.9932247299463398
avll from llpg:  -0.9932247299463406
avll direct:     -0.9932247299463406
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9952887272135825
avll from llpg:  -0.9952887272135825
avll direct:     -0.9952887272135826
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.161573     0.00804339    0.0889454    -0.0295883    0.10694     -0.0209338   -0.102535    -0.0244068    0.101605    -0.0968515   -0.155893    -0.0645861   -0.0489383   -0.0475075   -0.0218706    0.0688607    0.119774    -0.00924882   0.110279     0.0117135    0.000566418  -0.100264     0.0772363    -0.0766177   -0.0102022   -0.0360571
  0.0102404   -0.178743      0.0908056    -0.154086     0.128541    -0.171899     0.0394729    0.0173506    0.00145783  -0.0765305   -0.141652     0.0914656   -0.0502076   -0.015413     0.104014    -0.0514816   -0.152788     0.133194     0.0848919    0.102485     0.11844      -0.0189794   -0.0286476     0.147307    -0.105944     0.0881853
  0.102976    -0.105554     -0.00210537   -0.127508     0.0346837   -0.108105    -0.126998     0.0771705    0.0233921    0.0406572   -0.113524     0.134696    -0.106181    -0.17452      0.0546253   -0.0641638   -0.0474253    0.17302     -0.20098      0.0572533   -0.10228      -0.0412495    0.193061      0.0200658    0.138964     0.0885875
 -0.189223    -0.0640741     0.052205      0.010344     0.0404978   -0.0111242   -0.0503518    0.0804698    0.0424443    0.00228584  -0.0804486   -0.0120634   -0.0445728    0.131271    -0.188968     0.0337645    0.113763     0.00647607  -0.0400809    0.0140964   -0.112586     -0.0359319   -0.232697     -0.121909     0.132954    -0.0238856
 -0.0231272    0.0513446     0.0742384    -0.076795    -0.042856     0.0467699   -0.00849246   0.0687754    0.0151967   -0.0590503    0.0615258   -0.0717627    0.103171    -0.0275316   -0.0234177   -0.00243353  -0.0896384   -0.0586078    0.00165413   0.167271     0.125995      0.132499     0.0957651    -0.0479544    0.184673     0.0846696
 -0.0333478    0.140784      0.00014305   -0.103586    -0.0712684   -0.0587036   -0.0359164    0.00177166  -0.0860846    0.0661578    0.0156281    0.163772     0.0333846   -0.182957     0.070253     0.0352141   -0.0768301   -0.0980273    0.0662991   -0.138774    -0.13894       0.104681     0.0901126     0.0469436    0.0421869   -0.140914
  0.0531631   -0.0415498    -0.119197     -0.07102     -0.00497449  -0.0517399   -0.0298678   -0.0698542    0.110754     0.117369     0.0558059   -0.0140738   -0.0182497    0.154116    -0.187919    -0.102973    -0.115254     0.21706     -0.157309     0.0796156    0.0196714    -0.1172      -0.209978      0.111286    -0.0795598   -0.032987
 -0.0989981    0.175924     -0.0466865     0.0794933   -0.0409701    0.00082355   0.0130884    0.0661191   -0.0164899   -0.0488936   -0.0481611   -0.0617158    0.0165498    0.10007     -0.0165189   -0.0319011   -0.0175278    0.147156     0.0311011    0.063657    -0.181692     -0.220803    -0.0332922    -0.0296159   -0.0486772    0.117101
 -0.0705794    0.0890782    -0.000862542   0.150524     0.0361167    0.0981563    0.0133217   -0.0121978   -0.0360253    0.246063     0.143404     0.0161128    0.0649162   -0.05826      0.0655573    0.00176832  -0.0740177   -0.0271121   -0.265567    -0.116763     0.0416962     0.00759672   0.0784074     0.125547    -0.0264181    0.167217
 -0.0825289   -0.0933851     0.0431146    -0.157113    -0.185276     0.0123219    0.0135878    0.0914341   -0.0797204    0.0415937   -0.125284    -0.190676     0.0623503   -0.0828194    0.224897     0.0125042   -0.00217326   0.188008     0.0893047    0.0533536   -0.00137572    0.0337078   -0.0644531    -0.0952528   -0.0476295    0.108223
  0.00118099  -0.187743     -0.286918     -0.175888    -0.117625    -0.00165161  -0.100117    -0.118302     0.0822527   -0.114183     0.132595    -0.14202     -0.0483158   -0.106637     0.0277284    0.0729072    0.0377742    0.0726      -0.170052     0.0996089    0.100805      0.111333    -0.128012      0.118993     0.133651     0.00157991
 -0.0106773   -0.0794059     0.0188886     0.035263     0.00368157  -0.0623994   -0.0332509   -0.205772    -0.140571     0.04684     -0.002864     0.0676262    0.132746    -0.0862701   -0.00827918   0.00378268  -0.137552    -0.182352    -0.107117    -0.0505708   -0.00542641   -0.0251329    0.0537157     0.103751    -0.1011       0.040426
  0.0106361   -0.114778     -0.023853     -0.0307275    0.0435564    0.0760878    0.151136     0.0984734   -0.0968891   -0.0621324   -0.0113896   -0.149532     0.0450498    0.0878439   -0.149094    -0.112606    -0.0893799    0.0133874    0.0118169   -0.125942     0.0782847    -0.02842     -0.0305959    -0.0863515   -0.00127011   0.0838841
  0.075938     0.104413     -0.0273692     0.00782049   0.0220984   -0.00509221   0.192641     0.110669     0.0874032   -0.267669    -0.07961      0.108554     0.213035     0.173365     0.0527462   -0.0341687   -0.0231634   -0.201132    -0.0898945    0.0623347    0.121731      0.0170809    0.013464      0.0267107    0.00615137   0.0182889
 -0.0589826    0.000242784   0.111595     -0.119415    -0.010455    -0.048995     0.0895192    0.108286     0.00487311  -0.00347146   0.0262151   -0.0455859    0.0900288   -0.0778337    0.00538337   0.164433    -0.0966961    0.00359878  -0.0184061   -0.0546341   -0.0473297    -0.0554273    0.141877     -0.0613999    0.078819    -0.00672502
  0.00116391  -0.0421939     0.151321     -0.0327168    0.13489     -0.0256777   -0.036985    -0.0368744    0.0584412    0.0379785    0.183951    -0.0778242    0.146171    -0.0225036   -0.0277795   -0.0756045    0.0672137    0.0185084   -0.0693955    0.0855767    0.00398072   -0.0803186    0.000193824   0.022976     0.040813     0.12222
 -0.171        0.0176814    -0.125118     -0.0838994    0.0484824   -0.0329245   -0.0168778   -0.158525     0.0306541   -0.0248121   -0.130457     0.0794399    0.0393168   -0.0743802    0.17699     -0.0480594    0.0150344    0.138181     0.0906577   -0.00402217   0.128501      0.116631     0.13723       0.150455     0.0858564    0.0911195
 -0.131255     0.0746424    -0.064189     -0.0804516   -0.0485273   -0.0334602    0.00360547  -0.0827549   -0.0755533   -0.0898869    0.0867584   -0.0423896    0.104976     0.043365     0.160673     0.0860756    0.00173861  -0.0161707   -0.0418112   -0.0975412   -0.0138838    -0.0987059   -0.008152      0.0604336    0.216653    -0.0415444
  0.0885991    0.0295972    -0.0560588     0.247827     0.0526253   -0.0192473    0.088593     0.118235     0.105953     0.140768     0.0844559    0.0685755    0.0522415   -0.127566    -0.0245916    0.0379857    0.160884     0.0497476    0.179732     0.0236508   -0.0136279    -0.0542313    0.0620609    -0.147202     0.0118641   -0.176279
  0.0735538    0.019386      0.00964401   -0.0915528   -0.122609     0.121934    -0.0373032   -0.212017    -0.00303008  -0.0962405    0.132493     0.0395472   -0.0848911    0.0788913    0.0120873   -0.0393895   -0.0610788    0.0375164    0.133723    -0.0951802   -0.0951672    -0.0576682   -0.000294715   0.0312463   -0.0232164    0.00909782
 -0.126837     0.0144471     0.132154      0.028009     0.0291942   -0.00836685  -0.0794629    0.0120786    0.0989997   -0.0722986   -0.0509407   -0.0516148   -0.0517349   -0.116326     0.0394981   -0.00623316  -0.113294    -0.104122    -0.0310153   -0.0362675    0.0523408    -0.0558619    0.00635927    0.134878    -0.186389    -0.132033
  0.0932804    0.103101     -0.0427106     0.0863694    0.0880482   -0.00428345  -0.0473698    0.130801    -0.0428596   -0.0443159    0.0269875    0.181485    -0.00955626   0.111181    -0.0971694   -0.1911      -0.0891522    0.0217653    0.0227323    0.140314    -0.0844403    -0.135014    -0.0198616    -0.0787654    0.0618346   -0.0568529
 -0.1965      -0.00209003   -0.0751062     0.0193327   -0.0253123    0.0243854   -0.0028699    0.0590897   -0.119052    -0.0254546    0.0224606   -0.0943761   -0.0224408    0.0746908    0.0258737   -0.13486     -0.0647831    0.149485     0.0118177   -0.023589     0.0472336     0.0272233    0.0321996     0.169454     0.123325     0.104092
  0.122189    -0.0703798    -0.104408      0.126739    -0.0714367    0.249822    -0.0354579    0.0427848   -0.0472708   -0.184211    -0.29838      0.126375     0.129609    -0.00168234  -0.0105695    0.0514806   -0.0709022    0.0315388   -0.0928503   -0.047314     0.106892      0.155577     0.0721717     0.0962108   -0.0391369   -0.0136605
 -0.055676    -0.0427117    -0.0932117     0.0612181   -0.126005     0.019771     0.00301848   0.0509249    0.103871    -0.111738     0.0613406   -0.114009     0.0930184   -0.154125    -0.0968959    0.0548784   -0.0691548    0.0362337   -0.131242    -0.0010654   -0.0595801     0.103129     0.121841      0.00945607  -0.253212    -0.0496954
  0.0331814   -0.0396505    -0.0726602     0.0797523   -0.0780812   -0.0558589    0.0927194    0.0394324    0.0127795    0.151655     0.0969305   -0.0376929   -0.0387343   -0.0459082   -0.034814     0.114083    -0.0498265   -0.124958     0.172063     0.042598    -0.101375      0.0960973   -0.0693498     0.00692384  -0.0770449    0.0609602
  0.197683    -0.0184565     0.111942     -0.108638    -0.12022      0.0648527   -0.00831913   0.111625    -0.0307385    0.0319067    0.00931935  -0.0750694    0.152281     0.12446      0.107161    -0.0680477   -0.0827037   -0.0290187   -0.00335809   0.248501    -0.0898822     0.187667     0.0116631    -0.164965     0.0464933    0.123593
  0.0709949   -0.131268      0.104005     -0.0418165   -0.0634588    0.0819361    0.0854985    0.0757215   -0.173311     0.0837807   -0.0439248    0.0146161    0.0502032    0.114026     0.00534128  -0.0535793   -0.0278202   -0.0753783   -0.0575944   -0.0371059    0.0575432    -0.189374     0.0472789     0.055007    -0.0259086   -0.0297414
 -0.0308714   -0.0949759    -0.11255       0.0296405    0.0138055    0.0864793    0.0754134   -0.215551    -0.129717    -0.125535    -0.0236983    0.0392169    0.120857    -0.0937587    0.0215152    0.0074428   -0.103702     0.201804     0.0327964    0.093932    -0.0914694     0.0669562    0.087631     -0.0453847   -0.163119    -0.149347
 -0.0148202   -0.0240811     0.0310947    -0.0584162    0.0459623    0.135297     0.0547245   -0.0475674   -0.101667     0.119753     0.058542     0.0781098   -0.0358842    0.0511404   -0.0373568    0.157557     0.0265151   -0.0717754    0.0253322   -0.0171294    0.104951      0.0335285   -0.00980971    0.147849    -0.00512804   0.0316487
  0.0567704    0.174324      0.0865596    -0.0202345   -0.0778464    0.051306     0.0323851    0.15825     -0.0282778    0.0905997    0.0825529   -0.0384536   -0.135199     0.178228    -0.0229897   -0.0224152   -0.0724556   -0.0582481    0.0598723    0.11837     -0.0481941     0.143879     0.0592042     0.0482547   -0.0623337   -0.0896125
 -0.133916     0.256259      0.107151     -0.0871364   -0.0716064   -0.0837944   -0.0182242    0.0801744    0.11252     -0.109024     0.028582    -0.00652875   0.16539      0.107782     0.110083     0.130605     0.109731     0.0916743   -0.0811814   -0.260655    -0.0656377     0.0822731   -0.0831011     0.00596661   0.02471     -0.0988666kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4292228073569855
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.429291
[ Info: iteration 2, average log likelihood -1.429209
[ Info: iteration 3, average log likelihood -1.428611
[ Info: iteration 4, average log likelihood -1.423056
[ Info: iteration 5, average log likelihood -1.409071
[ Info: iteration 6, average log likelihood -1.401528
[ Info: iteration 7, average log likelihood -1.399878
[ Info: iteration 8, average log likelihood -1.399106
[ Info: iteration 9, average log likelihood -1.398379
[ Info: iteration 10, average log likelihood -1.397673
[ Info: iteration 11, average log likelihood -1.397139
[ Info: iteration 12, average log likelihood -1.396816
[ Info: iteration 13, average log likelihood -1.396602
[ Info: iteration 14, average log likelihood -1.396438
[ Info: iteration 15, average log likelihood -1.396297
[ Info: iteration 16, average log likelihood -1.396164
[ Info: iteration 17, average log likelihood -1.396038
[ Info: iteration 18, average log likelihood -1.395925
[ Info: iteration 19, average log likelihood -1.395829
[ Info: iteration 20, average log likelihood -1.395752
[ Info: iteration 21, average log likelihood -1.395690
[ Info: iteration 22, average log likelihood -1.395640
[ Info: iteration 23, average log likelihood -1.395596
[ Info: iteration 24, average log likelihood -1.395559
[ Info: iteration 25, average log likelihood -1.395527
[ Info: iteration 26, average log likelihood -1.395498
[ Info: iteration 27, average log likelihood -1.395474
[ Info: iteration 28, average log likelihood -1.395452
[ Info: iteration 29, average log likelihood -1.395432
[ Info: iteration 30, average log likelihood -1.395415
[ Info: iteration 31, average log likelihood -1.395399
[ Info: iteration 32, average log likelihood -1.395385
[ Info: iteration 33, average log likelihood -1.395373
[ Info: iteration 34, average log likelihood -1.395363
[ Info: iteration 35, average log likelihood -1.395354
[ Info: iteration 36, average log likelihood -1.395347
[ Info: iteration 37, average log likelihood -1.395341
[ Info: iteration 38, average log likelihood -1.395336
[ Info: iteration 39, average log likelihood -1.395332
[ Info: iteration 40, average log likelihood -1.395329
[ Info: iteration 41, average log likelihood -1.395326
[ Info: iteration 42, average log likelihood -1.395324
[ Info: iteration 43, average log likelihood -1.395322
[ Info: iteration 44, average log likelihood -1.395321
[ Info: iteration 45, average log likelihood -1.395319
[ Info: iteration 46, average log likelihood -1.395319
[ Info: iteration 47, average log likelihood -1.395318
[ Info: iteration 48, average log likelihood -1.395317
[ Info: iteration 49, average log likelihood -1.395316
[ Info: iteration 50, average log likelihood -1.395316
┌ Info: EM with 100000 data points 50 iterations avll -1.395316
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.429291242977574
│     -1.4292090088930407
│      ⋮
└     -1.3953158777526067
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.395426
[ Info: iteration 2, average log likelihood -1.395324
[ Info: iteration 3, average log likelihood -1.395067
[ Info: iteration 4, average log likelihood -1.392545
[ Info: iteration 5, average log likelihood -1.381781
[ Info: iteration 6, average log likelihood -1.368897
[ Info: iteration 7, average log likelihood -1.362854
[ Info: iteration 8, average log likelihood -1.359995
[ Info: iteration 9, average log likelihood -1.358107
[ Info: iteration 10, average log likelihood -1.356678
[ Info: iteration 11, average log likelihood -1.355550
[ Info: iteration 12, average log likelihood -1.354661
[ Info: iteration 13, average log likelihood -1.353953
[ Info: iteration 14, average log likelihood -1.353409
[ Info: iteration 15, average log likelihood -1.353012
[ Info: iteration 16, average log likelihood -1.352726
[ Info: iteration 17, average log likelihood -1.352522
[ Info: iteration 18, average log likelihood -1.352379
[ Info: iteration 19, average log likelihood -1.352278
[ Info: iteration 20, average log likelihood -1.352204
[ Info: iteration 21, average log likelihood -1.352148
[ Info: iteration 22, average log likelihood -1.352101
[ Info: iteration 23, average log likelihood -1.352061
[ Info: iteration 24, average log likelihood -1.352025
[ Info: iteration 25, average log likelihood -1.351993
[ Info: iteration 26, average log likelihood -1.351963
[ Info: iteration 27, average log likelihood -1.351934
[ Info: iteration 28, average log likelihood -1.351904
[ Info: iteration 29, average log likelihood -1.351872
[ Info: iteration 30, average log likelihood -1.351838
[ Info: iteration 31, average log likelihood -1.351802
[ Info: iteration 32, average log likelihood -1.351763
[ Info: iteration 33, average log likelihood -1.351720
[ Info: iteration 34, average log likelihood -1.351675
[ Info: iteration 35, average log likelihood -1.351625
[ Info: iteration 36, average log likelihood -1.351571
[ Info: iteration 37, average log likelihood -1.351514
[ Info: iteration 38, average log likelihood -1.351458
[ Info: iteration 39, average log likelihood -1.351406
[ Info: iteration 40, average log likelihood -1.351359
[ Info: iteration 41, average log likelihood -1.351319
[ Info: iteration 42, average log likelihood -1.351286
[ Info: iteration 43, average log likelihood -1.351259
[ Info: iteration 44, average log likelihood -1.351236
[ Info: iteration 45, average log likelihood -1.351218
[ Info: iteration 46, average log likelihood -1.351204
[ Info: iteration 47, average log likelihood -1.351192
[ Info: iteration 48, average log likelihood -1.351183
[ Info: iteration 49, average log likelihood -1.351175
[ Info: iteration 50, average log likelihood -1.351169
┌ Info: EM with 100000 data points 50 iterations avll -1.351169
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3954260133494891
│     -1.3953244418374409
│      ⋮
└     -1.3511691699645
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.351327
[ Info: iteration 2, average log likelihood -1.351168
[ Info: iteration 3, average log likelihood -1.350732
[ Info: iteration 4, average log likelihood -1.346948
[ Info: iteration 5, average log likelihood -1.333471
[ Info: iteration 6, average log likelihood -1.319014
[ Info: iteration 7, average log likelihood -1.310254
[ Info: iteration 8, average log likelihood -1.305064
[ Info: iteration 9, average log likelihood -1.302839
[ Info: iteration 10, average log likelihood -1.301545
[ Info: iteration 11, average log likelihood -1.300396
[ Info: iteration 12, average log likelihood -1.299355
[ Info: iteration 13, average log likelihood -1.298501
[ Info: iteration 14, average log likelihood -1.297765
[ Info: iteration 15, average log likelihood -1.297052
[ Info: iteration 16, average log likelihood -1.296301
[ Info: iteration 17, average log likelihood -1.295497
[ Info: iteration 18, average log likelihood -1.294725
[ Info: iteration 19, average log likelihood -1.294098
[ Info: iteration 20, average log likelihood -1.293655
[ Info: iteration 21, average log likelihood -1.293307
[ Info: iteration 22, average log likelihood -1.292987
[ Info: iteration 23, average log likelihood -1.292720
[ Info: iteration 24, average log likelihood -1.292514
[ Info: iteration 25, average log likelihood -1.292335
[ Info: iteration 26, average log likelihood -1.292121
[ Info: iteration 27, average log likelihood -1.291818
[ Info: iteration 28, average log likelihood -1.291419
[ Info: iteration 29, average log likelihood -1.291036
[ Info: iteration 30, average log likelihood -1.290869
[ Info: iteration 31, average log likelihood -1.290838
[ Info: iteration 32, average log likelihood -1.290831
[ Info: iteration 33, average log likelihood -1.290827
[ Info: iteration 34, average log likelihood -1.290825
[ Info: iteration 35, average log likelihood -1.290823
[ Info: iteration 36, average log likelihood -1.290822
[ Info: iteration 37, average log likelihood -1.290821
[ Info: iteration 38, average log likelihood -1.290820
[ Info: iteration 39, average log likelihood -1.290819
[ Info: iteration 40, average log likelihood -1.290818
[ Info: iteration 41, average log likelihood -1.290817
[ Info: iteration 42, average log likelihood -1.290817
[ Info: iteration 43, average log likelihood -1.290816
[ Info: iteration 44, average log likelihood -1.290815
[ Info: iteration 45, average log likelihood -1.290815
[ Info: iteration 46, average log likelihood -1.290815
[ Info: iteration 47, average log likelihood -1.290814
[ Info: iteration 48, average log likelihood -1.290814
[ Info: iteration 49, average log likelihood -1.290813
[ Info: iteration 50, average log likelihood -1.290813
┌ Info: EM with 100000 data points 50 iterations avll -1.290813
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.351326543819785
│     -1.3511678399819465
│      ⋮
└     -1.2908129192381392
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.291025
[ Info: iteration 2, average log likelihood -1.290800
[ Info: iteration 3, average log likelihood -1.290164
[ Info: iteration 4, average log likelihood -1.283680
[ Info: iteration 5, average log likelihood -1.259465
[ Info: iteration 6, average log likelihood -1.235017
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.221854
[ Info: iteration 8, average log likelihood -1.228302
[ Info: iteration 9, average log likelihood -1.217462
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.205768
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.208832
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.214916
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.220203
[ Info: iteration 14, average log likelihood -1.219318
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.206588
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.211518
[ Info: iteration 17, average log likelihood -1.215045
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.203438
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.208222
[ Info: iteration 20, average log likelihood -1.224493
[ Info: iteration 21, average log likelihood -1.212533
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.202464
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.206455
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.210996
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.216135
[ Info: iteration 26, average log likelihood -1.216711
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.204431
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.210282
[ Info: iteration 29, average log likelihood -1.214673
[ Info: iteration 30, average log likelihood -1.203309
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      8
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.191732
[ Info: iteration 32, average log likelihood -1.230489
[ Info: iteration 33, average log likelihood -1.214655
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.203639
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.208003
[ Info: iteration 36, average log likelihood -1.212564
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.198823
[ Info: iteration 38, average log likelihood -1.213342
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.194257
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.198713
[ Info: iteration 41, average log likelihood -1.203269
[ Info: iteration 42, average log likelihood -1.191754
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      8
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.179841
[ Info: iteration 44, average log likelihood -1.218172
[ Info: iteration 45, average log likelihood -1.201970
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.190728
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.195078
[ Info: iteration 48, average log likelihood -1.200111
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.188799
[ Info: iteration 50, average log likelihood -1.210084
┌ Info: EM with 100000 data points 50 iterations avll -1.210084
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2910253935439313
│     -1.290799907355012
│      ⋮
└     -1.2100842670752308
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.193963
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.185985
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.187192
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     15
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.162982
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.147273
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│      9
│     10
│     15
│     16
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.126058
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     15
│     16
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.147664
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      9
│     10
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.135426
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     15
│     16
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.128333
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      9
│     10
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.131991
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     15
│     16
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.127907
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      4
│      9
│     10
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.121741
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     14
│     15
│     16
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.130892
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      9
│     10
│     15
│     16
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.119366
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     15
│     16
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.137828
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      9
│     10
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.137558
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.135008
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      9
│     10
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.118023
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│     14
│     15
│     16
│      ⋮
│     24
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.108116
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      4
│      9
│     10
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.136198
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.136639
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      4
│      9
│     10
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.120496
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.124998
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      4
│      9
│     10
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.114746
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     15
│     16
│     19
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.120480
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      9
│     10
│     14
│     15
│     16
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.126770
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.138172
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      4
│      9
│     10
│     15
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.123424
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.137702
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      9
│     10
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.131594
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     16
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.122254
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      4
│      9
│     10
│      ⋮
│     16
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.096062
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│     15
│     16
│     19
│     20
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.133309
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      9
│     10
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.145272
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     15
│     16
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.128229
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      9
│     10
│     15
│     16
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.115009
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     15
│     16
│     19
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.120155
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      4
│      9
│     10
│      ⋮
│     16
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.123046
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.139241
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      9
│     10
│     15
│     16
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.117714
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     15
│     16
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.126911
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      9
│     10
│     15
│     16
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.122734
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     16
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.146240
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      9
│     10
│     14
│     15
│     16
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.116830
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     15
│     16
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.127293
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      4
│      9
│     10
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.127334
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     15
│     16
│     19
│     20
│     24
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.123605
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│      9
│     10
│     15
│     16
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.124052
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     15
│     16
│     19
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.139157
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      4
│      9
│     10
│     14
│     15
│     16
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.112331
┌ Info: EM with 100000 data points 50 iterations avll -1.112331
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1939633668351421
│     -1.185985060957677
│      ⋮
└     -1.1123305625145423
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4292228073569855
│     -1.429291242977574
│     -1.4292090088930407
│     -1.4286107968846715
│      ⋮
│     -1.1240517773594287
│     -1.1391572052873908
└     -1.1123305625145423
32×26 Array{Float64,2}:
 -0.00645575   -0.205376    -0.276014    -0.178592     -0.126636    0.0157147   -0.102093     -0.185077     0.107509    -0.112415     0.126811    -0.144155    -0.0532472  -0.0820517    0.0382966    0.0776522    0.0226439    0.0698451   -0.164886     0.0974313     0.0802487    0.112939     -0.128918     0.12887      0.132585    -0.017569
  0.148521     -0.111048     0.00309701  -0.119545      0.03706    -0.106512    -0.129963      0.0809609    0.023906     0.0356609   -0.11558      0.14504     -0.102472   -0.176266     0.0548668   -0.0641775   -0.0384875    0.172011    -0.201982     0.0701869    -0.0987615   -0.0510717     0.21403      0.0736801    0.138152     0.085246
 -0.0420395    -0.0994086   -0.0903513    0.0151162     0.0225293   0.0977782    0.0789295    -0.208497    -0.139541    -0.0877193   -0.0246161    0.0470676    0.122543   -0.092481     0.0157561    0.00802382  -0.0924658    0.201386     0.0279807    0.0374101    -0.0983425    0.0753457     0.0895868   -0.0637491   -0.145314    -0.151712
  0.0518592     0.185857     0.060808    -0.0390073    -0.0955217   0.0522784    0.0348186     0.15872      0.0110696    0.0901249    0.0861831   -0.041945    -0.121099    0.178167    -0.0250416   -0.0197039   -0.0723935   -0.0585051    0.049174     0.120813     -0.0367956    0.149759      0.053955     0.0520171   -0.0724291   -0.089561
 -0.0714366    -0.0111849   -0.0243412    0.0673415    -0.140416   -0.600468     0.0340304     0.0629602    0.129884    -0.0952947    0.0459439   -0.125012     0.113183   -0.019958    -0.0115439    0.104314     0.0158813    0.00888522  -0.105975     0.0137002    -0.150963     0.101482      0.0436946    0.00864362  -0.178336    -0.0491906
 -0.0653264    -0.055911    -0.148084     0.0441202    -0.142665    0.681906    -0.0320899     0.0452141    0.0515872   -0.106618     0.0712125   -0.0625622    0.0401426  -0.303971    -0.191647     0.0521061   -0.0834007    0.0582683   -0.147048    -0.0356757    -0.00501533   0.102086      0.134548     0.00910101  -0.314616    -0.0487621
 -0.0538546     0.015292     0.149647     0.047602      0.105554   -0.383893     0.0963462    -0.0844492   -0.113819    -0.175584     0.0228848   -0.0911308    0.0851374  -0.0692135   -0.00817226   0.195881    -0.136714    -0.0277742   -0.0325374    0.118424     -0.0854212   -0.142262      0.130406    -0.140266     0.118736    -0.0201385
 -0.0825917    -0.0196752    0.0594711   -0.234072     -0.0573133   0.188116     0.0865601     0.362068     0.0591171   -0.053345     0.029136     0.00151071   0.0941401  -0.124631     0.0267603    0.146922    -0.0568434   -0.0556731    0.00726292  -0.186055     -0.00085695  -0.0262176     0.151641     0.013929    -0.0395353    0.010165
 -0.213303      0.0185862   -0.125551    -0.764361      0.0837269   0.076966    -0.0170609    -0.15185      0.0397989   -0.00795416  -0.252157     0.0706634    0.0329892  -0.0771614    0.177361    -0.19374     -0.0860358    0.186876    -0.0220375    0.000330334   0.194777    -0.138121      0.137002     0.131392     0.0870553    0.0954154
 -0.110047      0.0185335   -0.125098     0.83882       0.0857789  -0.203399    -0.0172053    -0.175522    -0.0566904   -0.0321403   -0.00603047   0.0865505    0.0690817  -0.0745478    0.173484     0.136172     0.126999     0.0552688    0.229179    -0.0122318     0.00772567   0.457618      0.137107     0.162973     0.0635675    0.063192
  0.0342056    -0.21073      0.091014    -0.162573      0.211968   -0.12214      0.04852       0.00435278   0.155736    -0.0695884   -0.167977     0.14907      0.0226583   0.0222665    0.102081    -0.0854464   -0.869031     0.130389     0.104828     0.044976      0.1893      -0.0732543    -0.0256468    0.145575    -0.0755809    0.0668522
 -0.014688     -0.132932     0.0887474   -0.140591      0.0938906  -0.225665     0.0391153     0.023595    -0.165465    -0.0850565   -0.0963423    0.0370344   -0.0913521  -0.0641626    0.0877412    0.0347857    0.478702     0.158312     0.0459476    0.156525      0.0370214    0.0762853    -0.0209475    0.147003    -0.132006     0.103173
  0.0995156     0.0112898    0.00132719   0.000898787   0.017874   -0.0391563   -0.0109034     0.0377451    0.0674396    0.0148068   -0.03701     -0.0388549   -0.0556075  -0.0154127   -0.0136462    0.0999332    0.0364826   -0.0696785    0.134889     0.0251455    -0.0491639   -0.0296822     0.00373124  -0.0506498   -0.0400132    0.0230057
 -0.102852      0.166153    -0.0470543    0.0842446    -0.0367906  -0.0415067    0.0165288     0.061324    -0.0335444   -0.0523673   -0.0430824   -0.070696     0.0258613   0.0898431   -0.0172153   -0.0364803   -0.0287286    0.132877     0.0455461    0.0673616    -0.185371    -0.264558     -0.010359    -0.014051    -0.0463749    0.110454
 -0.0119458    -0.0241447    0.0312013   -0.996371      0.0523673   0.134901     0.0522681    -0.0419522   -0.155267     0.181682     0.0516298    0.0539345   -0.0372436  -0.00874593  -0.0367575    0.160509     0.0531368    0.0276646    0.0265367   -0.0154225     0.0860373    0.111373     -0.0100615    0.086582     0.00333687  -0.00723146
 -0.0118421    -0.0230244    0.0311766    0.716926      0.0467154   0.143145     0.0010389    -0.0436481   -0.0959393    0.0332508    0.00508979   0.0800819   -0.0330162   0.087252    -0.0432988    0.147899     0.0204182   -0.120513     0.0257617   -0.0132258     0.100799    -0.130611     -0.0092174    0.194333     0.0173747    0.099747
  0.0775762     0.0876504   -0.0359188    0.115332      0.0349991  -0.00726488  -0.114487      0.141145    -0.0418832   -0.0414258   -0.0837509    0.189601    -0.050336    0.134167    -0.0878524    0.10886     -0.0870623    0.0206494   -0.0368886    0.133093     -0.0948917   -0.12687      -0.768114    -0.0992161    0.0480253   -0.0722104
  0.178564      0.150463    -0.0454636    0.0383739     0.141073   -0.0020208    0.00365656    0.126111    -0.048675    -0.0507159    0.170314     0.158053     0.0710572   0.0849552   -0.105588    -0.37627     -0.0913343    0.0235643    0.0356509    0.138477     -0.074804    -0.136027      0.66499     -0.172633     0.0804058   -0.0460353
  0.10104      -0.105556    -0.138616     0.11747      -0.073855    0.255502    -0.0424653     0.0382759   -0.0464321   -0.21847     -0.330136     0.143537     0.111597    0.0134265   -0.0146366    0.0506268   -0.105752     0.0209509   -0.185147    -0.0476532     0.101441     0.165454      0.010077     0.105102    -0.0650525   -0.0257127
  0.0651167     0.18008     -0.020901     0.0197178     0.047496   -0.0500285    0.173865      0.110981     0.0829596   -0.267544    -0.0499561    0.126004     0.255562    0.184024     0.0606788   -0.0120224   -0.0292392   -0.207397    -0.0374691    0.0652582     0.118704    -0.000589895   0.00288383   0.019068     0.0143823    0.019801
 -0.0905309     0.231743    -0.407343     0.142476      0.0359416   0.100518     0.129432      0.0689443    0.0437997    0.249178     0.0709253    0.0488876    0.0730997  -0.0978876    0.0619679    0.0321769   -0.138026    -0.0232912   -0.244236    -0.0982494     0.0321269    0.00556485    0.0677688    0.147515    -0.0656309    0.165912
 -0.0576467    -0.088852     0.502628     0.157832      0.0298203   0.0816764    0.00149874   -0.0533634   -0.0989619    0.241593     0.297755    -0.00628701   0.0620099  -0.0741573    0.0593845   -0.0113744   -0.0400086   -0.025764    -0.239254    -0.1233        0.0695653    0.0138465     0.0839883    0.108495     0.0179487    0.168792
  0.146543     -0.229042     0.122834    -0.10465      -0.0986261   0.00370762  -0.0434502     0.219516     0.0990317   -0.0288747    0.00942632  -0.0734916    0.178489    0.111249     0.248899    -0.0620193   -0.0963659    0.0389421   -0.029272     0.0592445     0.00568189   0.186376     -0.0542135   -0.175127     0.0755651    0.124067
  0.189156      0.171495     0.196637    -0.0952453    -0.134382    0.129556     0.0430467     0.00206219  -0.0596168    0.08488     -0.00628587  -0.0790643    0.131047    0.125776    -0.0447532   -0.0753004   -0.11533     -0.0904141    0.0121749    0.406998     -0.16941      0.188401      0.0275992   -0.15591      0.0351756    0.124624
  0.0329325    -0.110199     0.035806    -0.0160986    -0.0230776   0.0649547    0.10158       0.049673    -0.12792      0.0154859   -0.00963343  -0.0472415    0.0584747   0.0679662   -0.0631034   -0.0695472   -0.104157    -0.0490771   -0.019076    -0.0813727     0.0406462   -0.11693      -0.00857735   0.00200742  -0.0331657   -0.00479797
 -0.0284122     0.0304085   -0.0221532   -0.0429357    -0.010347   -0.0770385   -0.029603     -0.00524066   0.0340936    0.039537     0.0114248    0.00597484  -0.0254158  -0.0440418   -0.0162322   -0.0262552   -0.0964425   -0.00882278  -0.0365485   -0.0498871    -0.0217102   -0.0243904    -0.052188     0.113173    -0.0817998   -0.0972617
 -0.14877       0.109414    -0.0072176   -0.0435425    -0.0218619  -0.0204012   -0.000741044   0.0206865   -0.00933538  -0.0759533    0.035975    -0.0453814    0.114094    0.0710844    0.109387     0.0436655   -0.00208417   0.0691621   -0.0210773   -0.136801     -0.00432594   0.00340534   -0.00524945   0.0756156    0.12373     -0.0468472
  0.0461511     0.00354023  -0.0296115   -0.0532195    -0.0238223   0.0576503   -0.0428179    -0.197683    -0.0340371   -0.0535482    0.0853212    0.0448434   -0.014834    0.0427502    0.0190269    0.00785537  -0.0787074   -0.0267788    0.0512722   -0.0932437    -0.0615956   -0.0677621     0.02124      0.0381162   -0.0283861    0.0294283
 -0.00928244   -0.0523057    0.136602    -0.0570345     0.0650274   0.0380105   -0.0259973    -0.0150666   -0.0213159    0.0380703    0.150061    -0.0869896    0.128376   -0.0173134    0.0160526   -0.0756548    0.0711353    0.0441251   -0.0437679    0.0948295     0.010548    -0.0860964    -0.0119174    0.00363019   0.0111638    0.11223
  0.000316095  -0.0137904   -0.0168595    0.0581016    -0.0365447  -0.0170937   -0.00728539    0.128138     0.0409657    0.0972141    0.00935629  -0.00669291   0.0538016  -0.125893     0.0847723    0.0243967    0.0971623    0.100975     0.152137     0.0185973    -0.0122197   -0.0092372     0.0051122   -0.128259     0.00755367  -0.0523007
 -0.0109289     0.0653663    0.0539333   -0.0718353    -0.0430217   0.0501363    0.01953       0.0428238    0.0172914   -0.0510922    0.066116    -0.0678283    0.0903702   0.013569    -0.108263    -0.00310112  -0.101993    -0.0507772    0.00359733   0.16869       0.122833     0.129841      0.104459    -0.049372     0.230842     0.107585
 -0.187171     -0.0639312    0.0283981    0.0248371     0.0455382  -0.00546807  -0.0659655     0.0806347    0.0572155   -0.0251568   -0.0266686   -0.0264814   -0.0531783   0.114672    -0.149063     0.0342134    0.115585     0.00421516  -0.0497798    0.00503455   -0.10852     -0.00572228   -0.24407     -0.118273     0.148483    -0.0464667[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     15
│     16
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.136627
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      4
│      9
│     10
│      ⋮
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.107001
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     15
│     16
│     19
│     20
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.110766
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      4
│      9
│      ⋮
│     19
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.096354
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│     15
│     16
│     19
│     20
│     28
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.113209
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      4
│      9
│     10
│      ⋮
│     20
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.102109
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│     15
│     16
│     19
│     20
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.111658
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      4
│      9
│      ⋮
│     20
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.103592
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     15
│     16
│     19
│     20
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.126798
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      4
│      9
│     10
│      ⋮
│     20
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
kind diag, method kmeans
[ Info: iteration 10, average log likelihood -1.103280
┌ Info: EM with 100000 data points 10 iterations avll -1.103280
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.205231e+05
      1       7.172464e+05      -2.032767e+05 |       32
      2       6.823440e+05      -3.490243e+04 |       32
      3       6.645728e+05      -1.777117e+04 |       32
      4       6.549489e+05      -9.623864e+03 |       32
      5       6.485308e+05      -6.418168e+03 |       32
      6       6.438825e+05      -4.648249e+03 |       32
      7       6.402580e+05      -3.624505e+03 |       32
      8       6.378582e+05      -2.399857e+03 |       32
      9       6.364296e+05      -1.428552e+03 |       32
     10       6.356609e+05      -7.687548e+02 |       32
     11       6.351159e+05      -5.450038e+02 |       32
     12       6.346898e+05      -4.260584e+02 |       32
     13       6.343879e+05      -3.019033e+02 |       32
     14       6.341395e+05      -2.484010e+02 |       32
     15       6.339551e+05      -1.844144e+02 |       32
     16       6.338124e+05      -1.426877e+02 |       32
     17       6.336893e+05      -1.230560e+02 |       32
     18       6.335785e+05      -1.108579e+02 |       32
     19       6.334657e+05      -1.127710e+02 |       32
     20       6.333297e+05      -1.360355e+02 |       31
     21       6.331120e+05      -2.176352e+02 |       32
     22       6.325936e+05      -5.184655e+02 |       32
     23       6.317838e+05      -8.097766e+02 |       32
     24       6.310223e+05      -7.614707e+02 |       32
     25       6.303861e+05      -6.361912e+02 |       32
     26       6.298222e+05      -5.639459e+02 |       32
     27       6.294756e+05      -3.466005e+02 |       32
     28       6.293661e+05      -1.095037e+02 |       32
     29       6.293413e+05      -2.476378e+01 |       31
     30       6.293327e+05      -8.628393e+00 |       28
     31       6.293299e+05      -2.834121e+00 |       21
     32       6.293283e+05      -1.524791e+00 |       14
     33       6.293276e+05      -7.012748e-01 |       13
     34       6.293269e+05      -7.662151e-01 |        7
     35       6.293264e+05      -4.867981e-01 |       10
     36       6.293259e+05      -4.709872e-01 |        9
     37       6.293257e+05      -1.745412e-01 |       10
     38       6.293255e+05      -2.526568e-01 |       10
     39       6.293252e+05      -2.380524e-01 |        8
     40       6.293250e+05      -2.017735e-01 |        4
     41       6.293249e+05      -1.071843e-01 |        2
     42       6.293249e+05      -4.819504e-02 |        3
     43       6.293248e+05      -5.811541e-02 |        2
     44       6.293248e+05      -3.783193e-02 |        0
     45       6.293248e+05       0.000000e+00 |        0
K-means converged with 45 iterations (objv = 629324.7878661513)
┌ Info: K-means with 32000 data points using 45 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.349154
[ Info: iteration 2, average log likelihood -1.320722
[ Info: iteration 3, average log likelihood -1.288349
[ Info: iteration 4, average log likelihood -1.255543
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.221705
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.181181
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     10
│     15
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.147781
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     12
│     17
│     19
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.138715
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.164292
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.141878
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     21
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.120973
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      5
│      9
│     11
│     12
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.115681
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.150626
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.144426
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     10
│     15
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.121791
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.135486
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      3
│      5
│     11
│     19
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.101862
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      6
│     10
│     15
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.130846
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.152737
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     18
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.132686
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      3
│      5
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.124353
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     15
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.132996
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.144851
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.133603
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      3
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.117690
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     15
│     18
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.123057
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     10
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.138748
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     12
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.133197
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     11
│     15
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.090183
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.120750
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.159514
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.130537
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      5
│     11
│     12
│     17
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.080217
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.121465
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     21
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.148778
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     18
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.135011
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.119320
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      9
│     10
│     11
│     17
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.096773
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     19
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.135108
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      4
│      6
│     15
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.119718
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.147542
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      9
│     10
│     17
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.107494
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.137557
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      4
│     12
│     15
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.107152
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.130840
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      6
│     17
│     21
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.125789
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     15
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.126077
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      4
│      9
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.115892
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     10
│     18
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.141426
[ Info: iteration 50, average log likelihood -1.132604
┌ Info: EM with 100000 data points 50 iterations avll -1.132604
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.180627     0.0136173    -0.106225    -0.187264     0.0770097    -0.0140543   -0.0183909   -0.154947      0.013337    -0.0172488  -0.158753     0.0759804   0.0427822   -0.0788132    0.154812    -0.0584974   -0.00510122   0.141147     0.0749331   -0.00775406   0.127213     0.0905938     0.1194       0.142508     0.0828447     0.0880322
  0.0216186   -0.108822     -0.0257754   -0.0313177    0.026437      0.105224     0.147238     0.0985423    -0.0842015   -0.0607492   0.0321851   -0.137812    0.0521312    0.096105    -0.142116    -0.120445    -0.118384     0.0111286    0.0132252   -0.128735     0.0773926   -0.0619301    -0.0489494   -0.0875834    0.00815412    0.0574939
 -0.0031233   -0.0406065     0.157769    -0.0266909    0.129154      0.0196835   -0.0371866   -0.0389308     0.00926793   0.0373691   0.222281    -0.0654728   0.138268    -0.0227285   -0.032065    -0.077233     0.0688001    0.00378686  -0.0639781    0.0905071    0.0107962   -0.0739408    -0.0050298    0.0242742    0.0228183     0.112104
 -0.0129108   -0.0221214     0.0191382   -0.0858408    0.044681      0.142002     0.0321458   -0.0481241    -0.192919     0.141569    0.0880401    0.062188   -0.0338693    0.0723091   -0.0280414    0.206843     0.0456733   -0.0696051    0.0261814   -0.0222724    0.09758     -0.000554439  -0.00102954   0.158411     0.0219693     0.0425483
 -0.0907673    0.0719569    -0.0652776   -0.0206393   -0.0299392     0.0226579   -0.00927988  -0.0642117    -0.0346769   -0.0833422  -0.0114289   -0.0843037   0.148858     0.0264722    0.0786467    0.0792528   -0.00935509   0.0195379   -0.0202038   -0.0595095    0.0287802   -0.0757428     0.0607101    0.082242     0.164519     -0.0886883
  0.00024683  -0.204522     -0.276363    -0.178838    -0.126272      0.0118639   -0.102066    -0.181439      0.105678    -0.112399    0.123647    -0.143506   -0.0564926   -0.0818246    0.038149     0.0768288    0.0230137    0.0687494   -0.166154     0.0964362    0.0784235    0.111066     -0.128499     0.125212     0.132567     -0.018482
  0.131869     0.116457     -0.0407964    0.0777389    0.0910388    -0.00412914  -0.0570618    0.133782     -0.0450244   -0.0463199   0.0384716    0.176409    0.00885244   0.109904    -0.0945456   -0.129548    -0.0899577    0.0223485   -0.00281819   0.133557    -0.0847342   -0.131962     -0.0642416   -0.141205     0.0655473    -0.0606966
  0.055449    -0.00237856   -0.0720226    0.0467442   -0.0609364    -0.069996     0.0913654    0.0647671     0.0149693    0.115016    0.0660739   -0.0347757  -0.0485028   -0.0302191   -0.0335811    0.138164    -0.0483345   -0.131067     0.182107     0.0432394   -0.106226    -0.00196466   -0.050482    -0.0211165   -0.0742138     0.0693571
  0.00534157   0.0657632     0.0564992   -0.0643282   -0.0453242     0.0536821    0.0256509    0.0653474     0.0175092   -0.0544685   0.0652794   -0.0689374   0.0951036    0.0124839   -0.0956058   -0.00329077  -0.107578    -0.0521897    0.00960241   0.164212     0.118583     0.139363      0.11425     -0.0539782    0.233071      0.106159
  0.19172     -0.177457      0.0176658   -0.106935     0.0376705    -0.106326    -0.130368     0.0899107     0.0342679    0.0244272  -0.103879     0.250824   -0.212037    -0.203597     0.0692852   -0.0659099   -0.0553873    0.133365    -0.258223     0.0640018   -0.0859      -0.0490378     0.30621      0.115833     0.139766      0.167862
 -0.0319141   -0.0598396    -0.00258235   0.0352995    0.00761878   -0.0616002   -0.0398755   -0.178226     -0.112032     0.0371701  -0.0114557    0.0521078   0.152635    -0.0687911    0.0183765    0.00106137  -0.143218    -0.158397    -0.083701    -0.0817919   -0.0144554   -0.0792156     0.0408196    0.0985344   -0.080648      0.0427127
 -0.126318     0.0963251    -0.0731701   -0.075479    -0.0226384    -0.0244754   -0.05532     -0.109106     -0.0932432   -0.0734145   0.0117146   -0.0260476   0.104413     0.0112276    0.103557     0.107256    -0.03261      0.00198896  -0.0616094   -0.0691687   -0.0222883   -0.149243      0.0371721    0.0484791    0.182116     -0.0448514
  0.167954     0.0217913     0.085879    -0.0481636    0.0973686    -0.0207224   -0.138264     0.00722614    0.111056    -0.0836354  -0.153935    -0.0384666  -0.0867744   -0.0215515    0.00494732   0.0691852    0.128555    -0.00461617   0.0969283   -0.0135779   -0.0101647   -0.100179      0.0679214   -0.107082     0.000223936  -0.013661
 -0.07141     -0.00843952   -0.0253794    0.0693994   -0.145414     -1.13987      0.044598     0.0662892     0.145004    -0.107314    0.0444571   -0.130051    0.130349     0.0384444    0.0245924    0.143981     0.0115282   -0.0261103   -0.102005     0.00601113  -0.163916     0.10177       0.0152703    0.00434207  -0.239039     -0.0490186
  0.0553472    0.185737      0.0621536   -0.0410123   -0.0932662     0.0514212    0.0344735    0.158535      0.0102546    0.0910183   0.083836    -0.0424567  -0.117925     0.177716    -0.0248952   -0.0212097   -0.0722224   -0.0575246    0.0472863    0.120097    -0.0354481    0.150588      0.0534524    0.0516168   -0.071357     -0.0886216
 -0.065831    -0.0467719    -0.117213     0.0521153   -0.141639      0.609003    -0.0203569    0.0483599     0.064076    -0.0992027   0.0656034   -0.0777512   0.0507323   -0.26326     -0.163531     0.0471506   -0.056656     0.0590999   -0.137974    -0.0203533   -0.0357365    0.101984      0.127686     0.0108354   -0.257096     -0.0480293
  0.0679846    0.180143     -0.0254809    0.00643865   0.0393608    -0.0311392    0.153145     0.108379      0.0826346   -0.255531   -0.0643713    0.117008    0.226849     0.161556     0.0532453   -0.0117581   -0.0366828   -0.187094    -0.064017     0.0616884    0.113067     0.0154488    -0.00146423   0.0290258    0.00924203    0.0169903
 -0.0945074    2.72098e-6    0.136923     0.0669025    0.0223119     0.0108115   -0.136626     0.000858009   0.0635721   -0.0928516  -0.100169    -0.0805719  -0.0559604   -0.123115     0.0442108   -0.015868    -0.123989    -0.0729962   -0.0132117   -0.0507359    0.0682005   -0.0259072    -0.0771249    0.167063    -0.236812     -0.130716
  0.0706713    0.0256895    -0.0396494   -0.100539    -0.0504789     0.121333    -0.0359282   -0.212611     -0.00392081  -0.0967934   0.126884     0.040183   -0.0898784    0.0838236    0.0188452    0.0119836   -0.0569489    0.0396405    0.134517    -0.100753    -0.0958714   -0.0574279    -0.0019154    0.00685159  -0.0209118     0.0071752
 -0.0417215   -0.0993602    -0.0917121    0.0157478    0.0220516     0.0992352    0.0793497   -0.208406     -0.13996     -0.0876011  -0.0238423    0.0521043   0.122402    -0.0926249    0.0153858    0.00800736  -0.0911286    0.20269      0.0276439    0.0374877   -0.0985456    0.0766163     0.0894027   -0.0682696   -0.14459      -0.151676
 -0.106255     0.169296     -0.0465647    0.0844528   -0.034257     -0.0428113    0.00524215   0.0549987    -0.0380855   -0.058894   -0.0462006   -0.0677204   0.025419     0.0903118   -0.0163936   -0.0441613   -0.0250969    0.142415     0.0386117    0.0715228   -0.19444     -0.266759     -0.00769822  -0.0183504   -0.0474596     0.107312
 -0.0219925    0.117652     -0.0436975   -0.0882705   -0.0522304    -0.102234     0.0144879    0.00340873   -0.0806093    0.0634111   0.0361073    0.155161   -0.0137915   -0.177894     0.0611089    0.0598691   -0.0743822   -0.0921861    0.0736325   -0.155018    -0.132437     0.106367      0.0748236    0.0403786    0.0431501    -0.10515
 -0.180232     0.0243325    -0.0658779    0.0100423    0.0129939     0.0229965    0.00544239   0.0596034    -0.0728579   -0.0368646   0.00983848  -0.0857735   0.0456983    0.0739904    0.0391829   -0.0812214   -0.0696296    0.13196      0.00648848  -0.0496171    0.0515867    0.0174096     0.0451278    0.163136     0.125721      0.0997242
 -0.183883    -0.0610594     0.028316     0.030423     0.0469834    -0.0010162   -0.0710361    0.0961418     0.0538594   -0.0283572  -0.0316029   -0.0283595  -0.058989     0.122335    -0.155231     0.035044     0.117378     0.00732875  -0.0442231    0.00459702  -0.109634    -0.0126141    -0.264322    -0.140352     0.1583       -0.0610428
 -0.0692904   -0.000872397   0.105334    -0.093174     0.0232358    -0.100613     0.0922662    0.140315     -0.0304359   -0.115591    0.0261523   -0.0458558   0.0895444   -0.0980808    0.00876872   0.172091    -0.0967946   -0.0388293   -0.0128315   -0.0304855   -0.0435952   -0.0847637     0.142838    -0.0669524    0.0392255    -0.00539093
  0.0513551    0.0306813     0.11202      0.0312578   -0.040989      0.0875858    0.041472     0.0519124    -0.0120603    0.138602    0.0887535   -0.0282478   0.110772     0.0187924    0.0729306   -0.0313105   -0.101888    -0.0291016   -0.132257     0.0655845   -0.017212     0.0980219     0.0376087   -0.0171062    0.0135776     0.146795
  0.102562    -0.215822     -0.220014     0.100468    -0.0569444     0.225167    -0.00295878   0.0327289    -0.0315839   -0.212821   -0.350766     0.155579    0.136424     0.00650192   0.00428433   0.0605132   -0.125734     0.0317081   -0.266786    -0.0499619    0.0814884    0.168365     -0.019403     0.123156    -0.0834844    -0.0397677
 -0.010971    -0.0276822     0.00232553   0.0118001   -0.0506128     0.0167627   -0.00194476   0.104562      0.00353555   0.0859471  -0.0200463   -0.0236812   0.0470158   -0.0934468    0.091442     0.0295142    0.0862601    0.0861185    0.12351      0.0190157   -0.00270636  -0.0218691    -0.00536592  -0.0961527   -0.0021106    -0.0229626
  0.0494471   -0.0366697    -0.116093    -0.0789631   -0.000685587  -0.0790967   -0.0331924   -0.0132103     0.126311     0.107757    0.0627627   -0.0498842  -0.0193139    0.1536      -0.165499    -0.102637    -0.0916512    0.204227    -0.149638     0.0809026    0.0107868   -0.123612     -0.207294     0.119375    -0.0718876    -0.0369917
 -0.129032     0.292193      0.110643    -0.0830415   -0.0790316    -0.0785851    0.0069064    0.0734255     0.198633    -0.124359    0.059182    -0.0103273   0.161923     0.108215     0.149792     0.0956313    0.11092      0.0990779   -0.0154843   -0.241387    -0.074992     0.109786     -0.0884427   -0.00932234   0.0374538    -0.269029
  0.0540125   -0.106494      0.0995578   -0.0251768   -0.0563674     0.0787304    0.0943745    0.099505     -0.172479     0.0712105  -0.0559782    0.0187243   0.0490235    0.0950648    0.00728269  -0.0380239   -0.0400708   -0.0705468   -0.0351954   -0.0390494    0.0294473   -0.181932      0.0274455    0.0736942   -0.0450565    -0.0614279
  0.0115087   -0.16196       0.0787699   -0.154428     0.148241     -0.17257      0.0410555    0.00861958   -0.0013944   -0.0734396  -0.129969     0.092224   -0.0275847   -0.022264     0.101347    -0.0282881   -0.200663     0.136598     0.0714559    0.0965339    0.10987      0.00204833   -0.0148103    0.146474    -0.0970918     0.0839687[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      ⋮
│     19
│     21
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.060035
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      ⋮
│     24
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.031814
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      ⋮
│     19
│     21
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.051410
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      ⋮
│     24
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.036856
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      ⋮
│     19
│     21
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.047733
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      ⋮
│     24
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.032486
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      ⋮
│     19
│     21
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.052936
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      ⋮
│     24
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.029986
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      ⋮
│     19
│     21
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.038762
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      3
│      4
│      6
│      ⋮
│     24
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.029751
┌ Info: EM with 100000 data points 10 iterations avll -1.029751
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.179279   -0.0262485    -0.219477      0.0595765    0.0233135   -0.107411     0.0133043     0.0262109   0.00910671  -0.111087   -0.0784038    0.0494443    0.042257     0.0895511    0.104897     -0.0116387     0.0929047  -0.00842199   0.0455903     0.104895    -0.105381     -0.0376877   -0.177939     0.0758224    0.189453    -0.0473497
  0.0541377   0.0262258     0.051838     -0.104979     0.0341908    0.0625507    0.0896393    -0.0393531  -0.0527515    0.137901   -0.155359    -0.0236924   -0.010701     0.00634814   0.00646224   -0.0376754     0.0933108   0.0804784    0.0373499     0.0987631    0.000257337   0.00505735  -0.163986     0.0463821   -0.0905763   -0.135534
 -0.140391    0.0347335    -0.0851893     0.0431561    0.0264866   -0.119271     0.0348325    -0.118173   -0.0184464   -0.0694775   0.0529826   -0.0683516   -0.0569141   -0.116219     0.0286271    -0.00522392   -0.0203422  -0.302855     0.112615      0.0685104   -0.190995     -0.00196141   0.0694024    0.0851288   -0.0276125   -0.179245
  0.0698261  -0.00615265   -0.0977937    -0.0310348   -0.0475319    0.00487515  -0.0158797    -0.170799    0.0962322   -0.201491    0.101937    -0.115578    -0.165318    -0.0769427   -0.104808      0.0623279     0.0562796  -0.023728    -0.000108835  -0.133117     0.174188     -0.00748346  -0.00619265   0.125348     0.0682954    0.0224879
 -0.0516683  -0.0439188     0.0405653    -0.117707    -0.00489402  -0.0437024    0.0208509     0.18135     0.0384881   -0.018462    0.114555     0.051589    -0.00178685   0.0133252    0.139237      0.17182      -0.121779    0.0965349    0.190699     -0.00236766   0.100599     -0.12879     -0.100551     0.0498491    0.0338619   -0.00125312
  0.0728904  -0.0364098    -0.000222111   0.00270085  -0.0583531   -0.0792984   -0.0853377    -0.0651777   0.0783132   -0.110854   -0.109163     0.0379083    0.00694212  -0.0960783    0.0348818    -0.0454202    -0.11005     0.0972014    0.0889506    -0.0158239   -0.26846       0.09675      0.130911     0.0972769    0.109753     0.026844
  0.0197387  -0.108067      0.129335      0.0366368    0.132499    -0.022185    -0.100449      0.124992    0.12587      0.0114355   0.161426     0.0878685   -0.142905     0.057514     0.017065     -0.0310471    -0.066829   -0.0630627   -0.18207      -0.0734193    0.0468815    -0.158568    -0.0713358    0.142695    -0.0342826    0.302857
 -0.0638603   0.0544684    -0.0691127    -0.0319572   -0.0178957   -0.0165044   -0.0206017     0.0914383  -0.0783513   -0.03321     0.025977    -0.0679017    0.257989     0.00756074  -0.0636478    -0.252329     -0.162163   -0.0327777    0.0771022    -0.0202051   -0.0399326    -0.19151     -0.0599762   -0.173675    -0.158305    -0.00492161
  0.0532775  -0.00120479    0.0830904    -0.0101183    0.0478058    0.0453812    0.018069      0.141477    0.0183029    0.0379167  -0.19562     -0.0276776    0.0971682   -0.191632    -0.00468071   -0.0194367     0.0288172  -0.0746624   -0.0873623    -0.0117734    0.146213     -0.0169133    0.0942675   -0.0366208    0.0533405   -0.0685123
  0.0599477   0.0527729    -0.0876738    -0.137572     0.0490438   -0.0740328    0.0656132    -0.0109116  -0.0270316    0.0293136   0.0568699   -0.204563     0.069448     0.142959    -0.000381326   0.0133066    -0.0148475   0.0125139    0.0208127    -0.100849     0.00596543    0.129153    -0.142302    -0.0202893    0.0371222    0.0518332
 -0.193717    0.103595      0.0168349     0.00114092   0.0274708    0.132508     0.106857      0.151296    0.0360055   -0.0211518  -0.116281    -0.0561826   -0.239898    -0.0295513    0.0559562    -0.03536      -0.0892725  -0.112336    -0.0600063     0.0492582   -0.0898536     0.0386226   -0.0755201   -0.122844     0.0213836   -0.0335543
 -0.013292   -0.00608951   -0.081133      0.0640675    0.0592198   -0.0500435    0.095917      0.0860365  -0.0213378    0.0540734  -0.0208792   -0.058095     0.0839422    0.0545517    0.088191     -0.00192817   -0.0674982  -0.106339     0.0586608     0.0682122   -0.129585     -0.0208366   -0.0529103    0.17217      0.0597128    0.168156
  0.0208729  -0.0848738     0.0246405    -0.032355     0.0387487   -0.0184589    0.000790589  -0.0582427  -0.00771839  -0.132801   -0.10242     -0.0324077   -0.121223     0.0374369    0.188295     -0.0207648    -0.0152461   0.0726485   -0.0471664    -0.0136891   -0.100255     -0.00385043   0.099654    -0.0188924   -0.0372278    0.0196071
  0.0199614  -0.0720945    -0.0425394    -0.0441993    0.130674    -0.0456      -0.107537      0.0225283   0.0292804   -0.0493934   0.0671508    0.0239957    0.159836    -0.0792424   -0.146102     -0.0806415     0.0476675   0.0360637    0.0270764     0.0217499   -0.119215      0.0515132   -0.00184367   0.137797     0.365404     0.0996906
 -0.0701561  -0.0134188     0.139829     -0.0626986   -0.155774     0.00900739  -0.0286921    -0.0662058  -0.0782156   -0.0294772  -0.0809798    0.0271262   -0.0692848   -0.0165393   -0.208364      0.102922      0.162532   -0.050213    -0.0680732     0.087654    -0.146886     -0.0312065    0.0616302   -0.0331503   -0.0688892    0.197397
 -0.0961204  -0.00755781    0.0116203     0.0809855    0.0552459   -0.0214081    0.00211575   -0.0434616  -0.139446     0.0133466   0.183923    -0.00908631  -0.0281138    0.0184453   -0.167716     -0.0297237     0.021113   -0.062804    -0.0114213    -0.0922917    0.0922974    -0.00539342   0.00831777   0.0317493    0.0111444   -0.0793718
  0.0442973   0.0210536     0.0267174    -0.128068    -0.00353617   0.010028     0.0805906    -0.161016    0.0369537    0.0830371   0.20358     -0.017174     0.171093     0.0148773    0.176987     -0.0806447     0.0108116  -0.11013     -0.0887242    -0.107093    -0.0339407    -0.103126     0.109413    -0.0798356   -0.00464509  -0.129564
 -0.0923772   0.149645     -0.114832      0.00842616  -0.0469503   -0.012237    -0.127159     -0.0102998  -0.0404783    0.0192064  -0.0530771    0.113495     0.117605     0.258174     0.028744      0.0960912    -0.0948147   0.0519583   -0.119918     -0.203356    -0.0172232    -0.00329349  -0.0266467    0.0719101   -0.128573    -0.0908176
  0.169109   -0.173697     -0.0160073     0.0829952   -0.0129812   -0.0678377   -0.157894     -0.114884   -0.0768787   -0.152045   -0.0301499   -0.0302233   -0.105381    -0.111147     0.0149829     0.0433091     0.0517297  -0.0588688    0.00744574    0.0635763   -0.0410919    -0.0366872   -0.060067     0.0907931   -0.0917611   -0.11411
  0.0161147  -0.0606203     0.0807743    -0.0203493   -0.170855     0.298147    -0.125274      0.0977141   0.0252628    0.138865   -0.0274912    0.00822845  -0.0284771    0.144892    -0.192004      0.051194     -0.0597603  -0.00587253  -0.0116932    -0.0574268   -0.0277269    -0.170921     0.0515565    0.18188     -0.0932565   -0.0719256
 -0.0990962   0.180154     -0.0520252    -0.088063    -0.110736    -0.174392    -0.0921043    -0.0057567   0.152072    -0.0494891  -0.065253    -0.0069173   -0.0352197    0.103948    -0.114501      0.0642743    -0.0344354  -0.0374513   -0.00680374   -0.151173     0.172604      0.0344133    0.0220108   -0.109397     0.0856583   -0.0932539
  0.0308039   0.0119002     0.0592354     0.16148     -0.0334706   -0.108156    -0.0804791    -0.0081232   0.00344741   0.012354    0.108607     0.0226434    0.0123667   -0.127856     0.0870217     0.0341421     0.0415782  -0.00398301  -0.0710456    -0.00762275   0.101555      0.151346     0.0394556   -0.0315714    0.205793     0.077051
 -0.0287736  -0.210169     -0.0817544     0.0128936   -0.0285734    0.0444041    0.02981       0.115823    0.00521457  -0.180905   -0.0149827    0.0403665    0.0560497    0.00554541  -0.0421777     0.0644003     0.0484348  -0.0471476   -0.0169165    -0.0170186   -0.0948652     0.00428969  -0.0888012   -0.0272725    0.0405769   -0.0442374
 -0.0732852   0.0675692    -0.0130061    -0.0448595    0.0348704   -0.0721448    0.00960794    0.0933475  -0.147644    -0.091463   -0.123567     0.012277     0.0169398    0.0134327   -0.0632507     0.102833      0.0844789  -0.0499587   -0.0392441     0.00411394   0.0805234    -0.00559025   0.062333     0.0454383   -0.197684     0.00427806
  0.0617968   0.0297712    -0.0405773    -0.166983    -0.008252    -0.0334284    0.0206974     0.334121   -0.130186     0.112703    0.0563887    0.0594576   -0.0809161    0.0433099   -0.0756586     0.112797     -0.226039   -0.137141     0.128731      0.0501239   -0.0399694     0.129896     0.255498     0.217158    -0.0400731    0.186471
 -0.0864758  -0.0267136     0.0614173    -0.0139464   -0.102307    -0.156994     0.0706405    -0.0413181  -0.222302    -0.109267    0.0593021    0.150655    -0.141821    -0.0302521   -0.0027795    -0.0568178    -0.1797      0.0679415    0.0506241    -0.0716784    0.103474     -0.0596265    0.436533     0.0769577    0.0990765    0.101735
 -0.0953173  -0.129002      0.144189      0.181583     0.037227     0.00112865   0.051582      0.0779074   0.0534734    0.261276    0.0644735   -0.00972387  -0.089233    -0.10824      0.142545     -0.0321113    -0.0363933  -0.0369574    0.0684487    -0.173224    -0.0264934    -0.150445    -0.050511     0.00947897   0.0170143    0.0339726
  0.0384035   0.000656179   0.123635     -0.0732049    0.0449422   -0.059622     0.0738074     0.12675     0.197667    -0.171527   -0.0175483   -0.0365601   -0.175508    -0.181673    -0.0175984    -0.000653575  -0.0453121  -0.0769116   -0.0832083     0.180902     0.0135904    -0.0833898   -0.0770649   -0.192619    -0.0602454    0.149747
  0.0556318  -0.0665509     0.0985455    -0.0361108   -0.0611229   -0.138962     0.0470653     0.0639353   0.0460185    0.105901   -0.0320748    0.0398915   -0.0113157    0.0981919    0.12345       0.0539021     0.226524    0.133511    -0.179506      0.064865     0.0109384    -0.223288     0.0823339   -0.0793029   -0.172813     0.124969
  0.156984    0.0140953    -0.0287156    -0.0373797    0.0338885    0.0570716    0.055666     -0.0266714  -0.00236833   0.0155421   0.0331306    0.0761134    0.180131     0.106843     0.0565556     0.245107      0.176641    0.00192281   0.136778     -0.129211    -0.0979682     0.0159238   -0.0639577    0.114051    -0.0468877    0.119206
  0.0191702  -0.00374221    0.0454465     0.0383126    0.084788     0.162975    -0.0310407    -0.0862546  -0.0908155    0.0737476   0.107569    -0.0323843   -0.129957    -0.0823902    0.0472479     0.0176184    -0.0723493   0.0997658   -0.0912007    -0.098711     0.0140126    -0.0164209   -0.0025664   -0.0148632    0.116874    -0.152875
  0.106892   -0.0668585    -0.118717      0.110477    -0.00101971   0.176627     0.0458632    -0.0292166   0.0895434   -0.112464   -0.00715868  -0.208498     0.0776891    0.154034    -0.144688     -0.0934058     0.032206   -0.00192812  -0.0840998     0.128185     0.131167     -0.0420238   -0.132175    -0.0692953   -0.0452138   -0.0329548kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4285186459028998
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.428539
[ Info: iteration 2, average log likelihood -1.428480
[ Info: iteration 3, average log likelihood -1.428439
[ Info: iteration 4, average log likelihood -1.428393
[ Info: iteration 5, average log likelihood -1.428335
[ Info: iteration 6, average log likelihood -1.428250
[ Info: iteration 7, average log likelihood -1.428098
[ Info: iteration 8, average log likelihood -1.427776
[ Info: iteration 9, average log likelihood -1.427097
[ Info: iteration 10, average log likelihood -1.425934
[ Info: iteration 11, average log likelihood -1.424592
[ Info: iteration 12, average log likelihood -1.423643
[ Info: iteration 13, average log likelihood -1.423203
[ Info: iteration 14, average log likelihood -1.423040
[ Info: iteration 15, average log likelihood -1.422982
[ Info: iteration 16, average log likelihood -1.422961
[ Info: iteration 17, average log likelihood -1.422954
[ Info: iteration 18, average log likelihood -1.422950
[ Info: iteration 19, average log likelihood -1.422949
[ Info: iteration 20, average log likelihood -1.422948
[ Info: iteration 21, average log likelihood -1.422948
[ Info: iteration 22, average log likelihood -1.422948
[ Info: iteration 23, average log likelihood -1.422948
[ Info: iteration 24, average log likelihood -1.422947
[ Info: iteration 25, average log likelihood -1.422947
[ Info: iteration 26, average log likelihood -1.422947
[ Info: iteration 27, average log likelihood -1.422947
[ Info: iteration 28, average log likelihood -1.422947
[ Info: iteration 29, average log likelihood -1.422947
[ Info: iteration 30, average log likelihood -1.422947
[ Info: iteration 31, average log likelihood -1.422947
[ Info: iteration 32, average log likelihood -1.422947
[ Info: iteration 33, average log likelihood -1.422947
[ Info: iteration 34, average log likelihood -1.422946
[ Info: iteration 35, average log likelihood -1.422946
[ Info: iteration 36, average log likelihood -1.422946
[ Info: iteration 37, average log likelihood -1.422946
[ Info: iteration 38, average log likelihood -1.422946
[ Info: iteration 39, average log likelihood -1.422946
[ Info: iteration 40, average log likelihood -1.422946
[ Info: iteration 41, average log likelihood -1.422946
[ Info: iteration 42, average log likelihood -1.422946
[ Info: iteration 43, average log likelihood -1.422946
[ Info: iteration 44, average log likelihood -1.422946
[ Info: iteration 45, average log likelihood -1.422946
[ Info: iteration 46, average log likelihood -1.422946
[ Info: iteration 47, average log likelihood -1.422946
[ Info: iteration 48, average log likelihood -1.422946
[ Info: iteration 49, average log likelihood -1.422946
[ Info: iteration 50, average log likelihood -1.422946
┌ Info: EM with 100000 data points 50 iterations avll -1.422946
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4285391849325233
│     -1.428479565841455
│      ⋮
└     -1.4229460674590217
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422963
[ Info: iteration 2, average log likelihood -1.422905
[ Info: iteration 3, average log likelihood -1.422863
[ Info: iteration 4, average log likelihood -1.422817
[ Info: iteration 5, average log likelihood -1.422763
[ Info: iteration 6, average log likelihood -1.422699
[ Info: iteration 7, average log likelihood -1.422627
[ Info: iteration 8, average log likelihood -1.422550
[ Info: iteration 9, average log likelihood -1.422474
[ Info: iteration 10, average log likelihood -1.422402
[ Info: iteration 11, average log likelihood -1.422339
[ Info: iteration 12, average log likelihood -1.422287
[ Info: iteration 13, average log likelihood -1.422246
[ Info: iteration 14, average log likelihood -1.422214
[ Info: iteration 15, average log likelihood -1.422189
[ Info: iteration 16, average log likelihood -1.422170
[ Info: iteration 17, average log likelihood -1.422155
[ Info: iteration 18, average log likelihood -1.422143
[ Info: iteration 19, average log likelihood -1.422131
[ Info: iteration 20, average log likelihood -1.422121
[ Info: iteration 21, average log likelihood -1.422112
[ Info: iteration 22, average log likelihood -1.422103
[ Info: iteration 23, average log likelihood -1.422094
[ Info: iteration 24, average log likelihood -1.422086
[ Info: iteration 25, average log likelihood -1.422078
[ Info: iteration 26, average log likelihood -1.422071
[ Info: iteration 27, average log likelihood -1.422064
[ Info: iteration 28, average log likelihood -1.422057
[ Info: iteration 29, average log likelihood -1.422051
[ Info: iteration 30, average log likelihood -1.422045
[ Info: iteration 31, average log likelihood -1.422039
[ Info: iteration 32, average log likelihood -1.422034
[ Info: iteration 33, average log likelihood -1.422030
[ Info: iteration 34, average log likelihood -1.422025
[ Info: iteration 35, average log likelihood -1.422021
[ Info: iteration 36, average log likelihood -1.422017
[ Info: iteration 37, average log likelihood -1.422014
[ Info: iteration 38, average log likelihood -1.422011
[ Info: iteration 39, average log likelihood -1.422008
[ Info: iteration 40, average log likelihood -1.422005
[ Info: iteration 41, average log likelihood -1.422002
[ Info: iteration 42, average log likelihood -1.422000
[ Info: iteration 43, average log likelihood -1.421998
[ Info: iteration 44, average log likelihood -1.421995
[ Info: iteration 45, average log likelihood -1.421994
[ Info: iteration 46, average log likelihood -1.421992
[ Info: iteration 47, average log likelihood -1.421990
[ Info: iteration 48, average log likelihood -1.421988
[ Info: iteration 49, average log likelihood -1.421987
[ Info: iteration 50, average log likelihood -1.421986
┌ Info: EM with 100000 data points 50 iterations avll -1.421986
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4229628212859353
│     -1.4229051006119393
│      ⋮
└     -1.4219856375702458
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421995
[ Info: iteration 2, average log likelihood -1.421937
[ Info: iteration 3, average log likelihood -1.421886
[ Info: iteration 4, average log likelihood -1.421828
[ Info: iteration 5, average log likelihood -1.421760
[ Info: iteration 6, average log likelihood -1.421681
[ Info: iteration 7, average log likelihood -1.421596
[ Info: iteration 8, average log likelihood -1.421510
[ Info: iteration 9, average log likelihood -1.421428
[ Info: iteration 10, average log likelihood -1.421353
[ Info: iteration 11, average log likelihood -1.421287
[ Info: iteration 12, average log likelihood -1.421227
[ Info: iteration 13, average log likelihood -1.421175
[ Info: iteration 14, average log likelihood -1.421130
[ Info: iteration 15, average log likelihood -1.421090
[ Info: iteration 16, average log likelihood -1.421056
[ Info: iteration 17, average log likelihood -1.421027
[ Info: iteration 18, average log likelihood -1.421002
[ Info: iteration 19, average log likelihood -1.420980
[ Info: iteration 20, average log likelihood -1.420961
[ Info: iteration 21, average log likelihood -1.420944
[ Info: iteration 22, average log likelihood -1.420929
[ Info: iteration 23, average log likelihood -1.420915
[ Info: iteration 24, average log likelihood -1.420902
[ Info: iteration 25, average log likelihood -1.420889
[ Info: iteration 26, average log likelihood -1.420877
[ Info: iteration 27, average log likelihood -1.420865
[ Info: iteration 28, average log likelihood -1.420853
[ Info: iteration 29, average log likelihood -1.420841
[ Info: iteration 30, average log likelihood -1.420830
[ Info: iteration 31, average log likelihood -1.420818
[ Info: iteration 32, average log likelihood -1.420807
[ Info: iteration 33, average log likelihood -1.420795
[ Info: iteration 34, average log likelihood -1.420784
[ Info: iteration 35, average log likelihood -1.420773
[ Info: iteration 36, average log likelihood -1.420762
[ Info: iteration 37, average log likelihood -1.420751
[ Info: iteration 38, average log likelihood -1.420740
[ Info: iteration 39, average log likelihood -1.420730
[ Info: iteration 40, average log likelihood -1.420719
[ Info: iteration 41, average log likelihood -1.420709
[ Info: iteration 42, average log likelihood -1.420699
[ Info: iteration 43, average log likelihood -1.420690
[ Info: iteration 44, average log likelihood -1.420680
[ Info: iteration 45, average log likelihood -1.420671
[ Info: iteration 46, average log likelihood -1.420662
[ Info: iteration 47, average log likelihood -1.420654
[ Info: iteration 48, average log likelihood -1.420645
[ Info: iteration 49, average log likelihood -1.420637
[ Info: iteration 50, average log likelihood -1.420628
┌ Info: EM with 100000 data points 50 iterations avll -1.420628
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4219950671018897
│     -1.4219366256741282
│      ⋮
└     -1.4206282888243758
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420631
[ Info: iteration 2, average log likelihood -1.420568
[ Info: iteration 3, average log likelihood -1.420511
[ Info: iteration 4, average log likelihood -1.420444
[ Info: iteration 5, average log likelihood -1.420364
[ Info: iteration 6, average log likelihood -1.420267
[ Info: iteration 7, average log likelihood -1.420156
[ Info: iteration 8, average log likelihood -1.420038
[ Info: iteration 9, average log likelihood -1.419918
[ Info: iteration 10, average log likelihood -1.419803
[ Info: iteration 11, average log likelihood -1.419696
[ Info: iteration 12, average log likelihood -1.419598
[ Info: iteration 13, average log likelihood -1.419510
[ Info: iteration 14, average log likelihood -1.419432
[ Info: iteration 15, average log likelihood -1.419363
[ Info: iteration 16, average log likelihood -1.419302
[ Info: iteration 17, average log likelihood -1.419248
[ Info: iteration 18, average log likelihood -1.419200
[ Info: iteration 19, average log likelihood -1.419158
[ Info: iteration 20, average log likelihood -1.419120
[ Info: iteration 21, average log likelihood -1.419086
[ Info: iteration 22, average log likelihood -1.419055
[ Info: iteration 23, average log likelihood -1.419027
[ Info: iteration 24, average log likelihood -1.419001
[ Info: iteration 25, average log likelihood -1.418976
[ Info: iteration 26, average log likelihood -1.418953
[ Info: iteration 27, average log likelihood -1.418931
[ Info: iteration 28, average log likelihood -1.418910
[ Info: iteration 29, average log likelihood -1.418890
[ Info: iteration 30, average log likelihood -1.418870
[ Info: iteration 31, average log likelihood -1.418852
[ Info: iteration 32, average log likelihood -1.418834
[ Info: iteration 33, average log likelihood -1.418816
[ Info: iteration 34, average log likelihood -1.418799
[ Info: iteration 35, average log likelihood -1.418783
[ Info: iteration 36, average log likelihood -1.418767
[ Info: iteration 37, average log likelihood -1.418752
[ Info: iteration 38, average log likelihood -1.418737
[ Info: iteration 39, average log likelihood -1.418722
[ Info: iteration 40, average log likelihood -1.418707
[ Info: iteration 41, average log likelihood -1.418693
[ Info: iteration 42, average log likelihood -1.418680
[ Info: iteration 43, average log likelihood -1.418666
[ Info: iteration 44, average log likelihood -1.418653
[ Info: iteration 45, average log likelihood -1.418640
[ Info: iteration 46, average log likelihood -1.418628
[ Info: iteration 47, average log likelihood -1.418615
[ Info: iteration 48, average log likelihood -1.418603
[ Info: iteration 49, average log likelihood -1.418590
[ Info: iteration 50, average log likelihood -1.418578
┌ Info: EM with 100000 data points 50 iterations avll -1.418578
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4206309509499628
│     -1.4205677971703716
│      ⋮
└     -1.418578409359613
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418576
[ Info: iteration 2, average log likelihood -1.418508
[ Info: iteration 3, average log likelihood -1.418445
[ Info: iteration 4, average log likelihood -1.418373
[ Info: iteration 5, average log likelihood -1.418284
[ Info: iteration 6, average log likelihood -1.418173
[ Info: iteration 7, average log likelihood -1.418039
[ Info: iteration 8, average log likelihood -1.417886
[ Info: iteration 9, average log likelihood -1.417723
[ Info: iteration 10, average log likelihood -1.417558
[ Info: iteration 11, average log likelihood -1.417401
[ Info: iteration 12, average log likelihood -1.417256
[ Info: iteration 13, average log likelihood -1.417128
[ Info: iteration 14, average log likelihood -1.417015
[ Info: iteration 15, average log likelihood -1.416917
[ Info: iteration 16, average log likelihood -1.416832
[ Info: iteration 17, average log likelihood -1.416758
[ Info: iteration 18, average log likelihood -1.416694
[ Info: iteration 19, average log likelihood -1.416638
[ Info: iteration 20, average log likelihood -1.416589
[ Info: iteration 21, average log likelihood -1.416545
[ Info: iteration 22, average log likelihood -1.416505
[ Info: iteration 23, average log likelihood -1.416470
[ Info: iteration 24, average log likelihood -1.416437
[ Info: iteration 25, average log likelihood -1.416407
[ Info: iteration 26, average log likelihood -1.416379
[ Info: iteration 27, average log likelihood -1.416354
[ Info: iteration 28, average log likelihood -1.416329
[ Info: iteration 29, average log likelihood -1.416306
[ Info: iteration 30, average log likelihood -1.416284
[ Info: iteration 31, average log likelihood -1.416263
[ Info: iteration 32, average log likelihood -1.416243
[ Info: iteration 33, average log likelihood -1.416224
[ Info: iteration 34, average log likelihood -1.416205
[ Info: iteration 35, average log likelihood -1.416187
[ Info: iteration 36, average log likelihood -1.416169
[ Info: iteration 37, average log likelihood -1.416152
[ Info: iteration 38, average log likelihood -1.416135
[ Info: iteration 39, average log likelihood -1.416118
[ Info: iteration 40, average log likelihood -1.416102
[ Info: iteration 41, average log likelihood -1.416086
[ Info: iteration 42, average log likelihood -1.416071
[ Info: iteration 43, average log likelihood -1.416056
[ Info: iteration 44, average log likelihood -1.416041
[ Info: iteration 45, average log likelihood -1.416026
[ Info: iteration 46, average log likelihood -1.416012
[ Info: iteration 47, average log likelihood -1.415998
[ Info: iteration 48, average log likelihood -1.415984
[ Info: iteration 49, average log likelihood -1.415970
[ Info: iteration 50, average log likelihood -1.415957
┌ Info: EM with 100000 data points 50 iterations avll -1.415957
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4185756368084186
│     -1.4185080840291118
│      ⋮
└     -1.4159568946922703
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4285186459028998
│     -1.4285391849325233
│     -1.428479565841455
│     -1.4284392185312549
│      ⋮
│     -1.4159839830559895
│     -1.4159703359029034
└     -1.4159568946922703
32×26 Array{Float64,2}:
  0.0133255    0.0910002   0.117092    -0.38806     -0.0179772  -0.52046     0.169961     0.205669    -0.0183226   -0.87725     0.0732936    0.54871     0.154377    -0.256302     0.045122     0.15461      -0.160195    0.219251   -0.105664    -0.311086     -0.28322     -0.205578     0.170924   -0.364897   -0.212891     0.323362
  0.0323062    0.0882757   0.00235996  -0.268572     0.246477    0.354925   -0.233338     0.572465    -0.0147433   -1.03863     0.032613     0.16174    -0.0375197   -0.390723    -0.104984    -0.0256655     0.534856    0.363438    0.0899343   -0.100191      0.00148793  -0.0689472   -0.488199    0.359151   -0.0255506   -0.321281
  0.834577     0.290119    0.00433387   0.272112    -0.123307   -0.359085    0.0944223    0.107313     1.02656     -0.161806    0.155235     0.616283   -0.156104    -0.00834646  -0.250683    -0.3484       -0.521724   -0.249638    0.232609    -0.0464183    -0.532487     0.201225     0.189003   -0.102688    0.388171    -0.440136
  0.0562248    0.511747   -0.632155    -0.378878    -0.04431     0.71781     0.0903328    0.39526      0.192837    -0.412535    0.286059     0.445942   -0.350214     0.0489928    0.178211    -0.386551     -0.557676    0.412157    0.376306    -0.0530792    -0.323897     0.217535     0.486      -0.618652    0.054461    -0.303286
 -0.133994    -0.0287505   0.0654625    0.115825    -0.112713   -0.333926    0.0393667   -0.0442269   -0.0912327   -0.0695389   0.0557087   -0.0776152  -0.218877    -0.133818    -0.0158812    0.166307      0.0812383  -0.164525    0.0555643   -0.227892     -0.0833772    0.0243115    0.0495345  -0.0483103   0.123122     0.180452
  0.14665      0.0854005  -0.083656    -0.0882265    0.0227129   0.224335    0.0384383   -0.037278    -0.00693193   0.126037    0.0469077    0.0919811   0.102311     0.135669    -0.00854524  -0.0843143    -0.0754992  -0.0112345  -0.0190564    0.207232     -0.0293374    0.00603353   0.163413    0.0571921  -0.13787     -0.10641
 -0.219716    -0.164232    0.159703    -0.0821425    0.197084    0.0323336   0.1459       0.275521    -0.3474       0.018409   -0.314255    -0.031046    0.389839     0.270198    -0.307971    -0.0812379     0.204369    0.337111   -0.309854    -0.508996      0.289168    -0.317203    -0.137609   -0.0251812   0.0292366   -0.136365
 -0.43481      0.876805    0.361204    -0.0759967   -0.27744     0.25105     0.201196     0.449964    -0.0169209    0.363058   -0.176763    -0.14928     0.166892     0.182894     0.0783548    0.0196733    -0.0647467   0.0287341   0.0192889   -0.380788     -0.0993502   -0.0928369   -0.0502929   0.321201    0.267295     0.104743
 -0.177931     0.129389    0.434699    -0.510083     0.0666282  -0.423744    0.037736    -0.0825258    0.361042     0.233643    0.341346    -0.191902   -0.540053     0.159209     0.336618     0.139526     -0.1479      0.0731238   0.173293     0.289664      0.222084     0.242135    -0.190654    0.27563     0.0786524    0.437507
 -0.0396117   -0.291838    0.404066    -0.761153    -0.109287   -0.177145   -0.41627      0.0483178    0.200845     0.503872    0.304052    -0.13794     0.668613     0.257433     0.368636    -0.356251     -0.264255    0.351789   -0.00598381   0.210876      0.282601     0.0437589    0.323083    0.277044    0.216398    -0.275771
 -0.0746838    0.563877    0.341092    -0.191963     0.736096    0.620718    0.11572      0.00398668  -0.0551774    0.900466   -0.403928    -0.457602   -0.123746     0.276728    -0.0114742    0.302588      0.569594   -0.166573   -0.195054     0.423136      0.416024    -0.194726    -0.615099    0.0162484   0.146537    -0.543123
  0.302609     0.267095    0.197379    -0.305677     0.733182    0.517099    0.239652     0.184859     0.0557167    0.151019    0.15085      0.424011    0.415222    -0.00185431  -0.084771    -0.0614254     0.0203086   0.483125   -0.219837     0.728152      0.175763    -0.627369    -0.0407814  -0.116914   -0.351312    -0.67088
  0.0544634   -0.325525   -0.356184     0.0932376    0.0477267   0.233053   -0.379576    -0.334023     0.0465062   -0.0334513   0.116176    -0.224635    0.136665    -0.332202    -0.108837    -0.212617     -0.225875    0.0299863   0.414031     0.568624      0.251251    -0.246625    -0.260472    0.242314   -0.113611     0.0836364
  0.303981    -0.875199   -0.220301     0.0109453    0.374341    0.128628   -0.383454     0.205267     0.258196    -0.070469    0.118308    -0.0856857  -0.22447      0.078661     0.0862299    0.309848     -0.188688    0.112876   -0.188928     0.138547      0.228764    -0.092169    -0.341587   -0.0219705   0.413794    -0.107715
  0.00425378  -0.0117512  -0.558397     0.263312    -0.893502    0.1869      0.228845    -0.375266     0.250257     0.286144   -0.447024     0.0985076   0.389238     0.143804     0.0800886   -0.119722     -0.321112    0.1149     -0.171026     0.121677      0.0591194    0.0571483   -0.0719242   0.259714   -0.679276     0.0335179
  0.397604     0.186193    0.256084     0.550359    -0.219601   -0.247327   -0.0904031    0.0759412   -0.0494635   -0.391048   -0.422865    -0.0143204   0.597582     0.112461    -0.420663    -0.571822      0.310118    0.300261   -0.846861     0.993237      0.241959     0.653024     0.243809    0.970312   -0.120155    -0.135582
 -1.21603     -0.537155   -0.258177     0.00379863   0.0900042  -0.395016    0.00582517  -0.208076    -0.0391461   -0.230119    0.212917     0.0722007  -0.553609     0.0499815    0.0582344    0.39761      -0.664597    0.714045    1.09081     -0.804338     -0.183898    -0.549151    -0.475346   -0.587257   -0.0713782   -0.181488
 -0.21873     -0.53548    -0.192406    -0.305395     0.0371771   0.823689   -0.164216    -0.157516    -0.0735481    0.529729    0.66672     -0.0763727  -0.304507    -0.164393     0.25727      0.37303      -0.544471   -0.616232    0.578901    -0.642271      0.107652    -0.805341    -0.192877   -0.606783    0.0997961   -0.186648
 -0.148457    -0.854232   -0.648363     0.454718    -0.001878   -0.209465   -0.09922     -0.670061    -0.346923     0.445142    0.616988    -0.0272717   0.296103    -0.220437    -0.408019     0.22393      -0.716946    0.106155   -0.425965     0.256253     -0.383427    -0.280352     0.406887   -0.367848    0.129591     0.310249
  0.809242    -1.09494    -0.268533     0.00111148   0.624199   -0.013584   -0.171116    -0.165764    -0.322978    -0.122009    0.0431503    0.0866343  -0.454372     0.212758    -0.0475901   -0.312587     -0.0933582   0.28145    -0.176987     0.420311      0.327457    -0.30464      0.329292   -0.523677   -0.31982      0.0399211
  0.0875863   -0.576969   -0.113476     0.0150722   -0.0249884  -0.0662014  -0.227662    -0.0364868   -0.0276651   -0.184243    0.0136805   -0.0356874   0.00209931  -0.0669215    0.0327192   -0.0161091    -0.129988    0.0574074   0.0599475   -0.0032142     0.126167    -0.100465    -0.145768    0.0904462  -0.0961375    0.103307
 -0.324443     0.967504    0.179138    -0.240585    -0.161053    0.151693    0.456725     0.367734     0.0380594   -0.119957   -0.113079    -0.0853193  -0.00897169   0.0955966   -0.104553    -0.000983963   0.0852816   0.0456848  -0.125894    -0.421244     -0.230009    -0.0622392   -0.175871    0.0349382   0.153798    -0.0242475
 -0.0799724    0.119455   -0.467046     1.14839     -0.0054059  -0.256315   -0.239391     0.65231      0.336902    -0.805559   -0.00128589  -0.333741   -0.0870337   -0.971359    -0.472321    -0.316138     -0.234634   -0.469894   -0.0233243    0.000144003  -0.179126     0.0772701   -0.371826   -0.417859    0.412875    -0.0720694
 -0.258852    -0.21489    -0.463835     0.503696     0.153303    0.468945   -0.0503538    0.312814     0.0924138    0.766423   -0.196932    -0.736379   -0.352794     0.281731    -0.478477    -0.9375       -0.326328    0.149231    0.11721     -0.0629957     0.0720869    0.364244    -0.0417727   0.349818    0.357602    -0.16657
  0.0437261   -0.0529598   0.419227     0.43814     -0.275622   -0.529968   -0.627872    -0.519872    -0.152905     0.057099   -0.534229    -0.666975   -0.200494     0.250483     0.155108    -0.0181533     0.362722   -0.673823    0.293527    -0.349325     -0.487843     0.119654    -0.14432     0.0664927  -0.00927994  -0.0691495
 -0.606595    -0.0339246  -0.555526    -0.0690775   -0.417513   -0.205754    0.162791    -0.213396    -0.303767    -0.635821   -0.265224    -0.378248   -0.0423107   -0.228939    -0.258246    -0.195227      0.235696   -0.231431    0.0831511   -0.519305     -0.343309     0.273986    -0.138111    0.219416   -0.161849     0.57177
 -0.517193     0.336763   -0.0968542    0.297122     0.0540277   0.128992   -0.306751    -0.327215     0.0556303   -0.0522586   0.215236     0.147473    0.0773977   -0.263071     0.447827     0.99695       0.149439   -0.177968   -0.340385     0.283636     -0.519119     0.121897    -0.145737    0.392292    0.265304    -0.176069
  0.616948    -0.553038   -0.23073     -0.0128372   -0.0125934  -0.251598   -0.298372    -0.585089    -0.167062    -0.0899966   0.0846603    0.273217   -0.0135541   -0.200716     0.399188     0.455611      0.705609   -0.690898   -0.126089     0.453402      0.0629215    0.407791     0.253628    0.288321   -0.10581      0.0139347
  0.363046     0.435975    0.185457     0.0835705    0.0535444  -0.0912987   0.369918     0.285742    -0.204101    -0.0322035  -0.157328     0.258459   -0.656372     0.167491    -0.0135495    0.0915812     0.57771    -0.86175    -0.2658      -0.126348     -0.162145     0.344866     0.418178   -0.183988   -0.0704799    0.175875
 -0.0407587    0.494364    0.668128     0.163285    -0.0299745  -0.399106    0.721754     0.702269    -0.0456154    0.233109    0.252998     0.0793     -0.446613    -0.282836    -0.589256    -0.227009     -0.0386309  -0.384468    0.736073    -0.191011      0.542618    -0.216968     0.187494   -0.5073     -0.394183     0.572279
 -0.0188928   -0.0569319   0.332599    -0.212599    -0.285056   -0.232428    0.656528    -0.595725    -0.280457     0.870253    0.0272572    0.403607   -0.0612406    0.753626     0.543345     0.578042     -0.178118   -0.157556    0.0552518   -0.638517      0.256959     0.0875483    0.579804   -0.0635501   0.164459     0.527107
  0.567652    -0.150005    0.390714     0.844635     0.175275   -0.030062    0.377594    [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
 0.0852537   -0.491322     0.617457   -0.539712    -0.115947    0.503715     0.359243     0.133283     0.124059      0.226152   -0.236407   -0.523653     0.0561985    -0.258085    -0.442177     0.805162   -0.297602    0.269674     0.208872[ Info: iteration 1, average log likelihood -1.415944
[ Info: iteration 2, average log likelihood -1.415931
[ Info: iteration 3, average log likelihood -1.415918
[ Info: iteration 4, average log likelihood -1.415905
[ Info: iteration 5, average log likelihood -1.415892
[ Info: iteration 6, average log likelihood -1.415880
[ Info: iteration 7, average log likelihood -1.415867
[ Info: iteration 8, average log likelihood -1.415855
[ Info: iteration 9, average log likelihood -1.415843
[ Info: iteration 10, average log likelihood -1.415831
┌ Info: EM with 100000 data points 10 iterations avll -1.415831
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.847388e+05
      1       7.100452e+05      -2.746936e+05 |       32
      2       6.969393e+05      -1.310591e+04 |       32
      3       6.919074e+05      -5.031893e+03 |       32
      4       6.892449e+05      -2.662536e+03 |       32
      5       6.874385e+05      -1.806366e+03 |       32
      6       6.860746e+05      -1.363880e+03 |       32
      7       6.850637e+05      -1.010954e+03 |       32
      8       6.843274e+05      -7.362769e+02 |       32
      9       6.836969e+05      -6.304767e+02 |       32
     10       6.831644e+05      -5.325554e+02 |       32
     11       6.826903e+05      -4.740405e+02 |       32
     12       6.822294e+05      -4.609512e+02 |       32
     13       6.818238e+05      -4.056043e+02 |       32
     14       6.814283e+05      -3.954767e+02 |       32
     15       6.810804e+05      -3.479099e+02 |       32
     16       6.807988e+05      -2.815484e+02 |       32
     17       6.805315e+05      -2.673658e+02 |       32
     18       6.802824e+05      -2.490540e+02 |       32
     19       6.800580e+05      -2.244352e+02 |       32
     20       6.798624e+05      -1.955972e+02 |       32
     21       6.796755e+05      -1.869075e+02 |       32
     22       6.795244e+05      -1.510957e+02 |       32
     23       6.793893e+05      -1.350454e+02 |       32
     24       6.792620e+05      -1.273575e+02 |       32
     25       6.791347e+05      -1.273050e+02 |       32
     26       6.790053e+05      -1.293555e+02 |       32
     27       6.788755e+05      -1.298528e+02 |       32
     28       6.787622e+05      -1.132140e+02 |       32
     29       6.786496e+05      -1.126022e+02 |       32
     30       6.785600e+05      -8.968083e+01 |       32
     31       6.784793e+05      -8.063066e+01 |       32
     32       6.783940e+05      -8.537481e+01 |       32
     33       6.783146e+05      -7.938981e+01 |       32
     34       6.782407e+05      -7.386125e+01 |       32
     35       6.781721e+05      -6.860448e+01 |       32
     36       6.781151e+05      -5.701965e+01 |       32
     37       6.780619e+05      -5.318388e+01 |       32
     38       6.780124e+05      -4.945022e+01 |       32
     39       6.779687e+05      -4.377147e+01 |       32
     40       6.779310e+05      -3.769632e+01 |       32
     41       6.778954e+05      -3.555624e+01 |       32
     42       6.778597e+05      -3.573434e+01 |       32
     43       6.778209e+05      -3.876940e+01 |       32
     44       6.777886e+05      -3.234001e+01 |       32
     45       6.777576e+05      -3.093510e+01 |       32
     46       6.777258e+05      -3.179789e+01 |       32
     47       6.776950e+05      -3.080480e+01 |       32
     48       6.776635e+05      -3.157978e+01 |       32
     49       6.776314e+05      -3.203510e+01 |       32
     50       6.776004e+05      -3.099567e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 677600.4300053403)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.428272
[ Info: iteration 2, average log likelihood -1.423123
[ Info: iteration 3, average log likelihood -1.421863
[ Info: iteration 4, average log likelihood -1.421022
[ Info: iteration 5, average log likelihood -1.420098
[ Info: iteration 6, average log likelihood -1.419061
[ Info: iteration 7, average log likelihood -1.418133
[ Info: iteration 8, average log likelihood -1.417506
[ Info: iteration 9, average log likelihood -1.417141
[ Info: iteration 10, average log likelihood -1.416919
[ Info: iteration 11, average log likelihood -1.416765
[ Info: iteration 12, average log likelihood -1.416644
[ Info: iteration 13, average log likelihood -1.416543
[ Info: iteration 14, average log likelihood -1.416455
[ Info: iteration 15, average log likelihood -1.416376
[ Info: iteration 16, average log likelihood -1.416306
[ Info: iteration 17, average log likelihood -1.416242
[ Info: iteration 18, average log likelihood -1.416183
[ Info: iteration 19, average log likelihood -1.416129
[ Info: iteration 20, average log likelihood -1.416080
[ Info: iteration 21, average log likelihood -1.416034
[ Info: iteration 22, average log likelihood -1.415992
[ Info: iteration 23, average log likelihood -1.415952
[ Info: iteration 24, average log likelihood -1.415916
[ Info: iteration 25, average log likelihood -1.415881
[ Info: iteration 26, average log likelihood -1.415849
[ Info: iteration 27, average log likelihood -1.415819
[ Info: iteration 28, average log likelihood -1.415790
[ Info: iteration 29, average log likelihood -1.415763
[ Info: iteration 30, average log likelihood -1.415737
[ Info: iteration 31, average log likelihood -1.415713
[ Info: iteration 32, average log likelihood -1.415690
[ Info: iteration 33, average log likelihood -1.415668
[ Info: iteration 34, average log likelihood -1.415647
[ Info: iteration 35, average log likelihood -1.415626
[ Info: iteration 36, average log likelihood -1.415607
[ Info: iteration 37, average log likelihood -1.415589
[ Info: iteration 38, average log likelihood -1.415571
[ Info: iteration 39, average log likelihood -1.415554
[ Info: iteration 40, average log likelihood -1.415538
[ Info: iteration 41, average log likelihood -1.415523
[ Info: iteration 42, average log likelihood -1.415508
[ Info: iteration 43, average log likelihood -1.415493
[ Info: iteration 44, average log likelihood -1.415479
[ Info: iteration 45, average log likelihood -1.415466
[ Info: iteration 46, average log likelihood -1.415453
[ Info: iteration 47, average log likelihood -1.415440
[ Info: iteration 48, average log likelihood -1.415428
[ Info: iteration 49, average log likelihood -1.415416
32×26 Array{Float64,2}:
[ Info: iteration 50, average log likelihood -1.415404
┌ Info: EM with 100000 data points 50 iterations avll -1.415404
└ 59.0 data points per parameter
 -0.113566    0.4907       0.0376115  -0.350709    0.217772     0.10208      0.262437    0.732288   -0.01404    -0.428217   -0.0518463    0.217949     0.351224    -0.0238655  -0.236476   -0.21989    -0.114683     0.482441    -0.0591447    -0.510019   -0.28768      -0.449707    0.146066   -0.440879    0.346114    -0.277284
  0.164206    0.432822     0.465431   -0.254246    0.782517     0.672615     0.136594    0.374244    0.10461     0.197363   -0.224651     0.137611     0.0115715    0.226553   -0.139293    0.0763014   0.364036     0.223274    -0.139604      0.325742    0.391897     -0.300457   -0.525266    0.0252132  -0.251734    -0.80584
 -0.349358   -0.186631    -0.0524927   0.0327417  -0.823335    -0.446382    -0.357439    0.0442036   0.444385   -0.0785162  -0.955933    -0.221288     0.565909     0.389559    0.0544956  -0.428398   -0.180753     0.198024     0.389307     -0.686207    0.0548338    -0.44917    -0.175816    0.116035   -0.527847    -0.189265
  0.635369   -0.613783     0.192963    0.444403    0.752747     0.508316    -0.463001    0.201992   -0.0857007   0.300386   -0.298       -0.0603344   -0.0873578    0.148822    0.323147    0.551172    0.0228276   -0.262626    -0.457898      0.299352   -0.306021     -0.375       0.407456   -0.0220366   0.21701     -0.224175
 -0.856823    0.725352    -0.277299    0.207729   -0.320007     0.388623     0.354532   -0.277569   -0.336322   -0.127762   -0.233339     0.0303961    0.567975    -0.499041    0.141406    0.551784    0.406757    -0.225015    -0.0793046     0.233395   -0.381435     -0.240708   -0.214194    0.616565   -0.233073     0.100031
  0.199333    0.722411     0.205514    0.146469   -0.504557     0.0992274   -0.101732    0.0303115   1.23121    -0.210468    0.457501     0.316719    -0.119761    -0.43493    -0.121895   -0.194526   -0.528442    -0.349088     0.162162     -0.0614858  -0.971949      0.422417    0.0800637   0.154894    0.592387    -0.724626
 -0.179932    0.0277764   -0.446497   -0.234374    0.0112185    0.338336    -0.810826    0.376614    0.239151   -1.17214     0.23545     -0.120596     0.0786969   -0.736196    0.0208201  -0.0946784   0.610466     0.30411      0.134341     -0.045012   -0.0285901     0.0609792  -0.894698    0.621828   -0.160456    -0.380811
  0.115181   -0.332252    -0.158577    0.392225   -0.470126    -0.173843    -0.328365   -0.533774    0.159099    0.246509    0.0292138   -0.237123    -0.291266    -0.0754869   0.239029    0.331954   -0.133285    -0.414594     0.0577148     0.323126    0.00797837    0.385005   -0.0756843   0.237973   -0.119361     0.309683
  0.369855    0.109859     0.0675001   0.599312   -0.253877    -0.134234     0.0735043   0.0426351  -0.0985048  -0.236957   -0.488521    -0.00559589   0.741623     0.105928   -0.389269   -0.434647    0.262672     0.260452    -0.873922      0.73392     0.156188      0.393335    0.188284    0.752682   -0.239826    -0.126051
  0.117632   -0.0900801   -0.0550317  -0.159855    0.139747    -0.011458    -0.0691232   0.132703    0.234136   -0.157002    0.0788529    0.118623    -0.054192     0.0399877  -0.149592   -0.109146    0.006153     0.144798     0.013739      0.230169    0.125926      0.0736898  -0.0263021   0.239893    0.0372448    0.00551947
  0.380631   -0.902271     0.0216087   0.156784    0.501736    -0.193504    -0.607457    0.175131    0.0454193  -0.231155    0.0767222   -0.3827      -0.373519     0.238561   -0.50332    -0.567109   -0.339545     0.0210757    0.525309     -0.155541    0.164838      0.102953   -0.394331   -0.190432    0.595491    -0.241373
 -0.723028    0.635781     0.128914   -0.445098   -0.34087     -0.47656      0.23637     0.677708    0.89055    -0.0632989   0.294648     0.154503    -0.532751    -0.449225    0.233274    0.222547   -0.406421     0.226546    -0.112746      0.282789    0.138553      0.30939    -0.482722    0.233513    0.134585     0.68639
  0.0754555  -0.0763921    0.2187      0.0378767  -0.146137    -0.229045     0.725909   -0.615257   -0.345809    1.00245    -0.127072     0.23945      0.18776      0.85797     0.353102    0.437861   -0.250086    -0.25222     -0.110425     -0.473434   -0.000305952  -0.0563186   0.751213   -0.346942    0.126034     0.457574
  0.0134386   0.114641     0.0753206  -0.124243    0.135611     0.129546     0.0906521   0.0645648  -0.0258069   0.138081   -0.0170642   -0.135117    -0.0347245    0.102327    0.0339232   0.0128758   0.038585    -0.00729948  -0.0634179     0.0715447   0.110106     -0.0944207  -0.0919717   0.022134   -0.00371625  -0.0988296
  0.384421   -0.548701     0.403686   -0.124259   -0.045111     0.228991    -0.0370301   0.62615    -0.586188   -1.10085    -0.39705      0.537572    -0.655799    -0.228238   -0.54378    -0.227856    0.111612     0.12026      0.0446105    -0.0180973  -0.38201      -0.474035    0.150816   -0.719032   -1.27336      0.561359
 -0.650107   -0.187759     0.0223861  -0.320649    0.269667    -0.056178    -0.0488769  -0.276848   -0.0452191  -0.125451    0.450272     0.117768    -0.964806    -0.0544868   0.310595    0.342006   -0.293831    -0.0239165    1.0309       -0.567975   -0.159333     -0.283739   -0.195327   -0.59483     0.051876     0.129339
  0.340117    0.00585297  -0.741283   -0.226945   -0.278561     0.264423     0.363064    0.213679    0.517433   -0.404065    0.151596     0.528892    -0.135609    -0.119654    0.0730142  -0.602435   -0.676752     0.494671     0.0569631     0.226342    0.0334992     0.116017    0.525075   -0.355262   -0.291968     0.114515
 -0.468713   -0.395428     0.222925   -0.282864    0.442282     5.35671e-5  -0.206978   -0.279654   -0.351361    0.295867   -0.161185    -0.69411     -0.146974     0.274804    0.0830237   0.186746    0.41363      0.177252    -0.134588      0.0756361   0.218484     -0.0837522  -0.325256    0.225127    0.0267866    0.14753
 -0.124909    0.148568    -0.169852    0.0181701  -0.0892494    0.589292     0.093235   -0.0374609   0.0358173   0.882539   -0.247575    -0.650505     0.180425     0.227613   -0.0284439  -0.542993   -0.35228      0.156162     0.162158      0.188254    0.0255665     0.0548369   0.055505    0.301483    0.0541024   -0.179502
 -0.25512     0.873714     0.844712   -0.106118   -0.283126    -0.0744473    0.382227    0.35212    -0.121578    0.164615   -0.238533     0.131733    -0.335799     0.514342    0.0842927   0.140347    0.318137    -0.140118     0.000546916  -0.446037   -0.0419418     0.158349   -0.146146    0.383275    0.291795     0.194634
 -0.134152    0.212854    -0.612612    0.70835     0.294256     0.0590562    0.236018    0.4412      0.0331139  -0.0156436   0.0355244   -0.243751    -0.741074    -0.220008   -0.716916   -0.29132     0.273315    -0.613695    -0.0446245    -0.296144   -0.0448445     0.0887772  -0.0863765  -0.264423   -0.0419454    0.288761
  0.46213    -0.494435    -0.783371   -0.064709    0.421939     0.0790372   -0.326053   -0.663997   -0.164552   -0.392913    0.0559645    0.28113      0.351994    -0.29417     0.13057     0.0782563   0.339088    -0.190971     0.202555      0.754825    0.0533182    -0.272948    0.0643526  -0.248794   -0.302498    -0.429984
 -0.092446   -0.151246    -0.289812    1.13336    -0.339719    -0.441712    -0.16902    -0.181656    0.0245559  -0.302163   -0.355425    -0.145365    -0.236281    -0.283078   -0.317949    0.0187686   0.00161814  -0.397781     0.0939119    -0.283793   -0.563799      0.330939   -0.0593159  -0.0328544   0.301843     0.314319
  0.209665   -0.0430516    0.094706   -0.143478    0.00994361  -0.660222     0.081479    0.0522993  -0.119296   -0.944256   -0.0460204    0.290161     0.091604    -0.158208    0.232389    0.592916    0.466797    -0.244603    -0.383568     -0.519829   -0.214802      0.121099    0.161994   -0.0884829  -0.0745381    0.183072
 -0.0787797   0.014591     0.0205698   0.0449036  -0.138069    -0.0429977    0.0599965  -0.0564728  -0.212749   -0.0110891   0.00183284   0.0114112    0.0945787   -0.054283    0.0610665   0.137854   -0.0527575   -0.0811975   -0.00903987   -0.223252   -0.100877     -0.131851    0.0614887  -0.137394   -0.00162714   0.0267748
 -0.0972554  -0.732645    -0.438989   -0.240507   -0.224041     0.936738    -0.254074   -0.267278    0.0711511   0.536475    0.604989    -0.0385486    0.00705584  -0.291987    0.14109     0.234141   -0.768705    -0.765358     0.35708      -0.419759    0.238961     -0.88403    -0.185475   -0.295104   -0.0378229   -0.240148
  0.558477    0.447084     0.61185     0.20021    -0.0318685   -0.392995     0.67797     0.365238   -0.147175    0.321538   -0.00444174   0.261923    -0.139161    -0.0501114  -0.0528493  -0.0055413   0.169974    -0.614597     0.312106      0.0270786   0.271905     -0.343182    0.387422   -0.488033   -0.336306     0.2457
  0.448542    0.464309    -0.388735    0.0547342   0.841509     0.198912    -0.0268875  -0.668454   -0.610575    0.0916827   0.543979     0.42244     -0.548836     0.327854    0.162738    0.520713   -0.0173518    0.085689    -0.782409      0.423437   -0.515738      0.531016   -0.127338   -0.430576    0.203639     0.302696
  0.0727243  -0.277804     0.628494   -0.875485    0.0898013   -0.242507    -0.250145   -0.176808    0.216618    0.369894    0.489533     0.26212      0.255289     0.286755    0.654338   -0.167661   -0.0655198    0.348399     0.225736      0.542041    0.234143      0.14093     0.46304     0.394133    0.00796666  -0.241677
 -0.0620026  -0.636932    -0.240438   -0.0211048   0.20128     -0.172085    -0.0794625  -0.0107616  -0.0705921   0.0832585   0.698422     0.202066     0.551996    -0.219647   -0.24162     0.249517   -0.912371     0.887816    -0.341552      0.143399    0.275887     -0.504525   -0.29719    -0.0709325   0.23725      0.110002
 -0.654919   -0.303864    -0.244755   -0.734224   -0.757303    -0.333338     0.278313   -0.184342   -0.649846   -0.768351   -0.0310802   -0.185713     0.156838     0.113945   -0.178784   -0.533601   -0.365728     0.0768832    0.27219      -0.709154   -0.26273       0.341315   -0.116387    0.234256   -0.547601     0.522943
  0.274683   -0.102855     0.13062    -0.168729   -0.371397    -0.442808    -0.449746    0.0990467  -0.148438    0.34573     0.100828    -0.282916     0.0796572   -0.0655407   0.221157   -0.351855    0.704562    -0.696491    -0.434697     -0.0920855   0.15082       0.289041    0.856569    0.317607    0.67422      0.138953[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415393
[ Info: iteration 2, average log likelihood -1.415382
[ Info: iteration 3, average log likelihood -1.415371
[ Info: iteration 4, average log likelihood -1.415361
[ Info: iteration 5, average log likelihood -1.415351
[ Info: iteration 6, average log likelihood -1.415341
[ Info: iteration 7, average log likelihood -1.415332
[ Info: iteration 8, average log likelihood -1.415323
[ Info: iteration 9, average log likelihood -1.415314
[ Info: iteration 10, average log likelihood -1.415306
┌ Info: EM with 100000 data points 10 iterations avll -1.415306
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
