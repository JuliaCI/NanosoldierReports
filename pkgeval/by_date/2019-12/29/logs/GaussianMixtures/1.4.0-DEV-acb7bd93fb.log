Julia Version 1.4.0-DEV.667
Commit acb7bd93fb (2019-12-27 21:20 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed PDMats ───────────── v0.9.10
 Installed GaussianMixtures ─── v0.3.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed Blosc ────────────── v0.5.1
 Installed NearestNeighbors ─── v0.4.4
 Installed Arpack ───────────── v0.4.0
 Installed StaticArrays ─────── v0.12.1
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Distances ────────── v0.8.2
 Installed Clustering ───────── v0.13.3
 Installed OrderedCollections ─ v1.1.0
 Installed DataAPI ──────────── v1.1.0
 Installed SpecialFunctions ─── v0.9.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed CMake ────────────── v1.1.2
 Installed Rmath ────────────── v0.6.0
 Installed Parameters ───────── v0.12.0
 Installed StatsFuns ────────── v0.9.3
 Installed JLD ──────────────── v0.9.1
 Installed BinDeps ──────────── v1.0.0
 Installed StatsBase ────────── v0.32.0
 Installed Missings ─────────── v0.4.3
 Installed QuadGK ───────────── v2.3.1
 Installed BinaryProvider ───── v0.5.8
 Installed OpenBLAS_jll ─────── v0.3.7+1
 Installed DataStructures ───── v0.17.6
 Installed Distributions ────── v0.21.11
 Installed SortingAlgorithms ── v0.3.1
 Installed Compat ───────────── v2.2.0
 Installed LegacyStrings ────── v0.4.1
 Installed FillArrays ───────── v0.8.2
 Installed URIParser ────────── v0.4.0
 Installed HDF5 ─────────────── v0.12.5
 Installed Arpack_jll ───────── v3.5.0+2
 Installed FileIO ───────────── v1.2.0
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_IC5BBm/Project.toml`
 [no changes]
  Updating `/tmp/jl_IC5BBm/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_fvNc9k/Project.toml`
 [no changes]
  Updating `/tmp/jl_fvNc9k/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_KiOYtp/Project.toml`
 [no changes]
  Updating `/tmp/jl_KiOYtp/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_96CaqJ/Project.toml`
 [no changes]
  Updating `/tmp/jl_96CaqJ/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_y41nbw/Project.toml`
 [no changes]
  Updating `/tmp/jl_y41nbw/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_y41nbw/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.0
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -5.409329555422091e6, [90365.78158495735, 9634.218415042642], [-112.99889181985765 -50.18717555881861 -164.55789290548321; -263.8858879291013 -15.886426353324577 347.4391117156469], [[87765.40559642774 -1820.1656682968578 7853.144488372851; -1820.1656682968578 91567.87465700487 -3284.708724014779; 7853.144488372851 -3284.7087240147785 91390.42787211644], [11983.304964973322 1821.1420784611391 -7992.032346006721; 1821.1420784611391 7692.458071386785 3530.5938592400676; -7992.032346006721 3530.5938592400676 8630.294013996423]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.368439e+03
      1       1.144644e+03      -2.237952e+02 |        8
      2       1.115292e+03      -2.935188e+01 |        4
      3       1.095160e+03      -2.013239e+01 |        3
      4       1.067061e+03      -2.809834e+01 |        2
      5       1.063207e+03      -3.854456e+00 |        3
      6       1.012920e+03      -5.028686e+01 |        4
      7       9.783957e+02      -3.452442e+01 |        2
      8       9.772697e+02      -1.126050e+00 |        2
      9       9.745521e+02      -2.717628e+00 |        2
     10       9.718484e+02      -2.703657e+00 |        2
     11       9.617631e+02      -1.008536e+01 |        2
     12       9.557364e+02      -6.026671e+00 |        0
     13       9.557364e+02       0.000000e+00 |        0
K-means converged with 13 iterations (objv = 955.7363811737728)
┌ Info: K-means with 272 data points using 13 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.076102
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.697355
[ Info: iteration 2, lowerbound -3.534916
[ Info: iteration 3, lowerbound -3.374323
[ Info: iteration 4, lowerbound -3.208647
[ Info: iteration 5, lowerbound -3.056899
[ Info: dropping number of Gaussions to 7
[ Info: iteration 6, lowerbound -2.932267
[ Info: iteration 7, lowerbound -2.854718
[ Info: dropping number of Gaussions to 4
[ Info: iteration 8, lowerbound -2.809287
[ Info: iteration 9, lowerbound -2.781910
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.773171
[ Info: iteration 11, lowerbound -2.762168
[ Info: iteration 12, lowerbound -2.750330
[ Info: iteration 13, lowerbound -2.731368
[ Info: iteration 14, lowerbound -2.701994
[ Info: iteration 15, lowerbound -2.658997
[ Info: iteration 16, lowerbound -2.601499
[ Info: iteration 17, lowerbound -2.534110
[ Info: iteration 18, lowerbound -2.467170
[ Info: iteration 19, lowerbound -2.410550
[ Info: iteration 20, lowerbound -2.367265
[ Info: iteration 21, lowerbound -2.335461
[ Info: iteration 22, lowerbound -2.314707
[ Info: iteration 23, lowerbound -2.307397
[ Info: dropping number of Gaussions to 2
[ Info: iteration 24, lowerbound -2.302946
[ Info: iteration 25, lowerbound -2.299261
[ Info: iteration 26, lowerbound -2.299257
[ Info: iteration 27, lowerbound -2.299255
[ Info: iteration 28, lowerbound -2.299254
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sun Dec 29 14:11:38 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sun Dec 29 14:11:47 2019: K-means with 272 data points using 13 iterations
11.3 data points per parameter
, Sun Dec 29 14:11:49 2019: EM with 272 data points 0 iterations avll -2.076102
5.8 data points per parameter
, Sun Dec 29 14:11:52 2019: GMM converted to Variational GMM
, Sun Dec 29 14:12:03 2019: iteration 1, lowerbound -3.697355
, Sun Dec 29 14:12:03 2019: iteration 2, lowerbound -3.534916
, Sun Dec 29 14:12:03 2019: iteration 3, lowerbound -3.374323
, Sun Dec 29 14:12:03 2019: iteration 4, lowerbound -3.208647
, Sun Dec 29 14:12:03 2019: iteration 5, lowerbound -3.056899
, Sun Dec 29 14:12:03 2019: dropping number of Gaussions to 7
, Sun Dec 29 14:12:03 2019: iteration 6, lowerbound -2.932267
, Sun Dec 29 14:12:03 2019: iteration 7, lowerbound -2.854718
, Sun Dec 29 14:12:03 2019: dropping number of Gaussions to 4
, Sun Dec 29 14:12:03 2019: iteration 8, lowerbound -2.809287
, Sun Dec 29 14:12:03 2019: iteration 9, lowerbound -2.781910
, Sun Dec 29 14:12:03 2019: dropping number of Gaussions to 3
, Sun Dec 29 14:12:03 2019: iteration 10, lowerbound -2.773171
, Sun Dec 29 14:12:04 2019: iteration 11, lowerbound -2.762168
, Sun Dec 29 14:12:04 2019: iteration 12, lowerbound -2.750330
, Sun Dec 29 14:12:04 2019: iteration 13, lowerbound -2.731368
, Sun Dec 29 14:12:04 2019: iteration 14, lowerbound -2.701994
, Sun Dec 29 14:12:04 2019: iteration 15, lowerbound -2.658997
, Sun Dec 29 14:12:04 2019: iteration 16, lowerbound -2.601499
, Sun Dec 29 14:12:04 2019: iteration 17, lowerbound -2.534110
, Sun Dec 29 14:12:04 2019: iteration 18, lowerbound -2.467170
, Sun Dec 29 14:12:04 2019: iteration 19, lowerbound -2.410550
, Sun Dec 29 14:12:04 2019: iteration 20, lowerbound -2.367265
, Sun Dec 29 14:12:04 2019: iteration 21, lowerbound -2.335461
, Sun Dec 29 14:12:04 2019: iteration 22, lowerbound -2.314707
, Sun Dec 29 14:12:04 2019: iteration 23, lowerbound -2.307397
, Sun Dec 29 14:12:04 2019: dropping number of Gaussions to 2
, Sun Dec 29 14:12:04 2019: iteration 24, lowerbound -2.302946
, Sun Dec 29 14:12:04 2019: iteration 25, lowerbound -2.299261
, Sun Dec 29 14:12:04 2019: iteration 26, lowerbound -2.299257
, Sun Dec 29 14:12:04 2019: iteration 27, lowerbound -2.299255
, Sun Dec 29 14:12:04 2019: iteration 28, lowerbound -2.299254
, Sun Dec 29 14:12:04 2019: iteration 29, lowerbound -2.299253
, Sun Dec 29 14:12:04 2019: iteration 30, lowerbound -2.299253
, Sun Dec 29 14:12:04 2019: iteration 31, lowerbound -2.299253
, Sun Dec 29 14:12:04 2019: iteration 32, lowerbound -2.299253
, Sun Dec 29 14:12:04 2019: iteration 33, lowerbound -2.299253
, Sun Dec 29 14:12:04 2019: iteration 34, lowerbound -2.299253
, Sun Dec 29 14:12:04 2019: iteration 35, lowerbound -2.299253
, Sun Dec 29 14:12:04 2019: iteration 36, lowerbound -2.299253
, Sun Dec 29 14:12:04 2019: iteration 37, lowerbound -2.299253
, Sun Dec 29 14:12:04 2019: iteration 38, lowerbound -2.299253
, Sun Dec 29 14:12:04 2019: iteration 39, lowerbound -2.299253
, Sun Dec 29 14:12:04 2019: iteration 40, lowerbound -2.299253
, Sun Dec 29 14:12:04 2019: iteration 41, lowerbound -2.299253
, Sun Dec 29 14:12:04 2019: iteration 42, lowerbound -2.299253
, Sun Dec 29 14:12:04 2019: iteration 43, lowerbound -2.299253
, Sun Dec 29 14:12:04 2019: iteration 44, lowerbound -2.299253
, Sun Dec 29 14:12:04 2019: iteration 45, lowerbound -2.299253
, Sun Dec 29 14:12:04 2019: iteration 46, lowerbound -2.299253
, Sun Dec 29 14:12:04 2019: iteration 47, lowerbound -2.299253
, Sun Dec 29 14:12:04 2019: iteration 48, lowerbound -2.299253
, Sun Dec 29 14:12:04 2019: iteration 49, lowerbound -2.299253
, Sun Dec 29 14:12:04 2019: iteration 50, lowerbound -2.299253
, Sun Dec 29 14:12:04 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777396948, 178.04509222603048]
β = [95.95490777396948, 178.04509222603048]
m = [2.0002292577752314 53.85198717246057; 4.250300733269776 79.28686694435989]
ν = [97.95490777396948, 180.04509222603048]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.37587636119507073 -0.008953123827348256; 0.0 0.012748664777409957], [0.18404155547482595 -0.007644049042328796; 0.0 0.008581705166331105]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000003
avll from stats: -0.9865762676899207
avll from llpg:  -0.986576267689913
avll direct:     -0.986576267689913
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0144603506563181
avll from llpg:  -1.0144603506563181
avll direct:     -1.0144603506563181
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.214913     0.0218574   0.0120217     0.114847     -0.0115614   -0.0653164   -0.109892    -0.124339     0.172262    -0.00800536   0.0184403   -0.157339    -0.0214077   -0.0475413   -0.0564972    0.0943613    0.194705     -0.0065928   -0.226549     0.0836391     0.0184543   -0.125119      0.00345936   0.0132969    0.0712753   -0.0144456
  0.0687491   -0.030688   -0.0795197     0.0562642     0.0270179   -0.0102867    0.056383    -0.0375267   -0.0860984    0.0989512    0.0225973   -0.0454136    0.00611957   0.0491076    0.0594278   -0.0206522   -0.0881987     0.0301804   -0.0487938    0.181917      0.0574161   -0.0352498     0.0483026    0.141966    -0.00183482  -0.026765
  0.0589132   -0.0705996  -0.0381369    -0.0110754    -0.114795    -0.137605    -0.0528839   -0.0855064    0.0824189   -0.126484    -0.0884119    0.0862782    0.118222     0.0672575    0.0824477    0.122951     0.286549     -0.155391    -0.151196    -0.000995708  -0.0876211    0.0965148     0.121184    -0.00713979  -0.0803737    0.160342
 -0.0688455    0.033747    0.0491994     0.104004      0.0791071    0.119265    -0.041043    -0.0880302   -0.0781052   -0.0667161   -0.107763    -0.00633421  -0.031581    -0.107255     0.0553493   -0.0140101    0.0546407     0.196094    -0.0266124    0.168519     -0.0225931    0.119268     -0.118196     0.0894203    0.201892    -0.0573757
  0.155407    -0.0564854  -0.121663     -0.267114     -0.164142    -0.00322901  -0.0482736    0.0534936    0.119546    -0.0260112    0.111632    -0.144006     0.0312939    0.00578728   0.0676567   -0.160805    -0.0659182    -0.122422     0.0357308   -0.191799      0.0928835   -0.113121      0.0643139    0.00839422  -0.0910773   -0.0543867
  0.0836773   -0.163288   -0.0168833     0.120262     -0.0545014    0.0687946    0.00133074  -0.0293786    0.0625851    0.0093132   -0.118713     0.216164    -0.0943477   -0.0476951    0.00118673   0.0174633    0.0724125     0.161129    -0.0132864   -0.108681      0.136016     0.0367637     0.00322257  -0.117077    -0.0358092   -0.0578727
 -0.157123    -0.116274    0.0103975     0.00342154   -0.0172237    0.0761733    0.198835     0.0398544    0.0985447   -0.0116865    0.0468449   -0.0704329   -0.0309933   -0.0317734   -0.0161071   -0.073739    -0.0896008     0.012096    -0.1584       0.0964366     0.109513    -0.132528      0.128875    -0.106806    -0.196548     0.057281
 -0.00881419  -0.0987485   0.0504143     0.0806927     0.0557812    0.19996      0.156872     0.199062    -0.138734     0.0935446    0.102831    -0.108414    -0.130428     0.00689634   0.300012     0.131456     0.101358      0.136904     0.147367    -0.0229218    -0.196805    -0.134682      0.238627    -0.0303418   -0.0729737    0.211046
 -0.106018    -0.122903    0.0349618     0.144803      0.0411837    0.0159402   -0.0578736   -0.18174      0.0820452   -0.116826    -0.0542796   -0.113336    -0.10012     -0.0349349   -0.0400689    0.0252791    0.00836786    0.159093     0.0510941    0.0418847     0.049118    -0.119667     -0.0502021   -0.152809     0.0752451   -0.189257
  0.0668876   -0.0523676   0.00565018   -0.173865     -0.0543601   -0.185845    -0.11893      0.0877007    0.0375063   -0.0303943   -0.00249812   0.15471     -0.00237565  -0.00424062  -0.184056     0.136463     0.0655562     0.13839      0.136251     0.057253      0.0252849    0.0066536    -0.0897692    0.0548709   -0.11213      0.240263
  0.057922     0.0792463   0.218596      0.000710157   0.0236215   -0.0947253    0.155382     0.0119853    0.0615891   -0.00414119   0.152504     0.162349     0.052305    -0.111065     0.140095     0.0925721    0.0360783     0.160243     0.123223     0.0235635    -0.0391104    0.094628      0.145217     0.0222082    0.0650431    0.108863
  0.041939    -0.164298   -0.0422112     0.0409089    -0.0216192    0.0548242   -0.0899471    0.0189911   -0.00849873   0.0745518   -0.154661    -0.00943583   0.210566     0.194557    -0.114252     0.0835341   -0.049509      0.170594    -0.105361    -0.0054971    -0.0557803    0.0387677     0.187149    -0.0699276    0.181731     0.0165963
  0.222412     0.166114   -0.0889306    -0.0381345     0.0314549   -0.0861757    0.128822     0.0775284   -0.157802     0.227833     0.155012    -0.114176     0.0372711    0.0216824    0.00148995   0.0750407    0.119633      0.167074     0.0771703    0.00758141    0.069824    -0.0999057    -0.120941    -0.058379    -0.167458    -0.114068
 -0.0947499    0.0681905  -0.0962687    -0.0772825    -0.0270023   -0.0990989    0.0246681   -0.0125654    0.0463392   -0.13571     -0.0612502   -0.229317     0.0138557    0.116251     0.171811     0.0075725   -0.0704857    -0.0813066    0.0182633    0.0694857    -0.0164185    0.000915354   0.186629    -0.105981     0.156149    -0.0143081
 -0.106969    -0.0280997   0.0605339     0.140257      0.00304576  -0.0353106   -0.0741007   -0.0661694    0.0666453   -0.097829    -0.114653     0.0413339   -0.0915805   -0.0255684   -0.0535677    0.0342486   -0.00470691   -0.0736714    0.0617932    0.0887683    -0.101982    -0.0335009     0.00487995  -0.15736      0.0655677   -0.0787855
 -0.168889     0.0668503   0.10486      -0.00274792   -0.1013       0.114316    -0.113641     0.248863    -0.214094     0.111191     0.176452    -0.0337493    0.115461     0.0807929   -0.0372649    0.0562486    0.0155923    -0.068392    -0.0434243   -0.0725411    -0.0205054   -0.0139704     0.0685032    0.0480897   -0.174756    -0.0430057
 -0.00726833  -0.210011   -0.0424935    -0.0392075    -0.121542    -0.145987     0.0711245   -0.12669      0.0790367    0.0332199   -0.0187101   -0.0681138    0.0309027   -0.0466899   -0.0106229   -0.114773     0.0269327    -0.17983      0.0878977   -0.0658637    -0.319012     0.04634       0.0293636    0.0826437   -0.147594    -0.177613
  0.0413896   -0.125441    0.000686379   0.0714004    -0.086867    -0.0450208    0.0100092    0.108993    -0.0231007   -0.125506    -0.0548358    0.143561     0.0282996    0.021833    -0.0823173   -0.0290796   -0.110231      0.0688116    0.109505    -0.0348773    -0.132248     0.016555      0.136701    -0.178958    -0.0362042    0.0593121
 -0.0105826    0.0669548  -0.0402718    -0.0677199    -0.0984721    0.200168    -0.041561    -0.00994013  -0.07231      0.0175569    0.0121382    0.136345     0.150357     0.0389107   -0.0678014   -0.125599     0.0111309    -0.114685    -0.00366296   0.130664     -0.0110566   -0.127019     -0.0872034    0.00345506  -0.117442     0.0117996
  0.0106105    0.202264   -0.171059     -0.176787     -0.0850639   -0.0700265   -0.00185339   0.0228176   -0.0817146   -0.0306293    0.0718745   -0.0501522    0.17718     -0.0858377   -0.264184    -0.096163    -0.0684853    -0.0459848    0.327276     0.0519562    -0.0378603    0.116347      0.119772    -0.0970128    0.0781602    0.0479003
  0.0936136    0.116405   -0.0181791    -0.0335904    -0.0332987    0.0493776   -0.0501247   -0.0228283    0.0942505   -0.0240437    0.140478    -0.011814     0.0503791   -0.0278111    0.0348059    0.0129036   -0.0737448    -0.00990138   0.168491     0.0858485     0.130286    -0.211858      0.0739478    0.0147477   -0.0719564   -0.0460777
 -0.157751     0.0783081  -0.0523154     0.0451355     0.0373083    0.229568    -0.0848068    0.0219022    0.137344    -0.0452614    0.0263274   -0.0597725   -0.0544294    0.167746    -0.0140359    0.0763545   -0.0806523    -0.00276851  -0.145575     0.108106     -0.0762337   -0.063924      0.0992958    0.0721907    0.00509356   0.0030658
 -0.020766    -0.0958726   0.0656976    -0.109075     -0.100463    -0.045401     0.119779    -0.0618078    0.126087     0.0236845    0.127891     0.0192435   -0.0505789    0.0570349   -0.0237521   -0.10388     -0.000679363   0.0110282    0.201501     0.0930162    -0.0841695    0.0862852     0.00887157   0.0529722    0.112306     0.0255136
  0.144983     0.171249    0.0283674     0.178605     -0.0661691    0.0508487    0.146126     0.0622983   -0.099719    -0.0704809   -0.0675514   -0.0495115   -0.0689742    0.0577222    0.032938     0.0161779   -0.196104      0.0246869    0.00204938   0.00244529    0.00824157  -0.0539285    -0.149728     0.0157079    0.139571    -0.0137214
 -0.141842     0.022018    0.0333227     0.0948705     0.0779087   -0.0724027    0.0761389   -0.0496811    0.0317144    0.0378652   -0.00543885  -0.0128388   -0.172086    -0.00495284   0.100249    -0.0567518   -0.0184167    -0.0657578   -0.114445    -0.121592      0.0251668    0.0167634    -0.0718476    0.072998     0.0157033    0.214102
 -0.00457611   0.0153167  -0.112914      0.106535     -0.0937085   -0.179291    -0.105807     0.105553     0.135607     0.0944106   -0.103679     0.0191931   -0.102056     0.0200286    0.152381     0.0509695   -0.00730844   -0.0722914    0.0225327    0.147022      0.0171827    0.0553248    -0.0980486   -0.121378    -0.264002     0.0651577
  0.152443    -0.173258   -0.11639      -0.0368845     0.100394     0.073276     0.0236452    0.0394651   -0.130518     0.0401217    0.0190622    0.0625427    0.104369    -0.265382    -0.0768996    0.0621963    0.20676      -0.10577     -0.00934979  -0.10045      -0.0761397   -0.0175037     0.0900677   -0.190509     0.0267913    0.0547528
  0.0493409   -0.151371    0.0488189    -0.23105       0.126399    -0.0777942   -0.102123     0.110167     0.0328824   -0.0352857    0.0632791   -0.0375212    0.252661     0.133374    -0.00151788   0.0120381    0.00948487    0.143725    -0.096748     0.0231474     0.0569599   -0.0938614    -0.0702308    0.185726     0.0472543    0.0643426
  0.0404575   -0.0401407  -0.167837     -0.185716      0.0461743    0.0563367   -0.0953992    0.294457    -0.0044925    0.111927     0.141078     0.00688243   0.134144     0.0191755    0.168817     0.104974    -0.0715176     0.0522565    0.238903    -0.00506766    0.0664648   -0.066175      0.168375    -0.0481991    0.170074     0.0742587
 -0.058937    -0.0846429  -0.0981937     0.0211457     0.032933    -0.086301     0.103056     0.0638345    0.287289    -0.0789286   -0.0828366   -0.0703433    0.066197     0.0859513   -0.179576    -0.00332214  -0.0524176     0.181498    -0.0543928   -0.0467775    -0.194821    -0.163756      0.037934    -0.21232      0.0720331   -0.200999
  0.0324377   -0.162714    0.0635229    -0.125076      0.181858     0.00399091  -0.00866704   0.132678     0.0400013   -0.0935883    0.0542508    0.13385     -0.0485222    0.0517033    0.114842    -0.128961    -0.103216     -0.0156223    0.029665    -0.060669      0.0609787   -0.0690059     0.158148     0.0437992    0.0227851    0.0889415
  0.0106903    0.0163344  -0.12097      -0.0186685     0.0151532    0.0582325    0.0880124   -0.0153114   -0.00424327  -0.0670189    0.113899     0.0596892    0.0257405    0.0490519    0.0650606    0.0417598   -0.0224428     0.0385468    0.16433     -0.0712069     0.051817    -0.0526988     0.0721508    0.218202     0.120734    -0.0406817kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3992040418494736
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.399277
[ Info: iteration 2, average log likelihood -1.399203
[ Info: iteration 3, average log likelihood -1.398810
[ Info: iteration 4, average log likelihood -1.395042
[ Info: iteration 5, average log likelihood -1.382965
[ Info: iteration 6, average log likelihood -1.374080
[ Info: iteration 7, average log likelihood -1.371987
[ Info: iteration 8, average log likelihood -1.371292
[ Info: iteration 9, average log likelihood -1.370883
[ Info: iteration 10, average log likelihood -1.370530
[ Info: iteration 11, average log likelihood -1.370132
[ Info: iteration 12, average log likelihood -1.369609
[ Info: iteration 13, average log likelihood -1.368990
[ Info: iteration 14, average log likelihood -1.368393
[ Info: iteration 15, average log likelihood -1.367907
[ Info: iteration 16, average log likelihood -1.367558
[ Info: iteration 17, average log likelihood -1.367312
[ Info: iteration 18, average log likelihood -1.367135
[ Info: iteration 19, average log likelihood -1.366999
[ Info: iteration 20, average log likelihood -1.366890
[ Info: iteration 21, average log likelihood -1.366795
[ Info: iteration 22, average log likelihood -1.366707
[ Info: iteration 23, average log likelihood -1.366617
[ Info: iteration 24, average log likelihood -1.366515
[ Info: iteration 25, average log likelihood -1.366387
[ Info: iteration 26, average log likelihood -1.366212
[ Info: iteration 27, average log likelihood -1.365958
[ Info: iteration 28, average log likelihood -1.365619
[ Info: iteration 29, average log likelihood -1.365283
[ Info: iteration 30, average log likelihood -1.365026
[ Info: iteration 31, average log likelihood -1.364827
[ Info: iteration 32, average log likelihood -1.364665
[ Info: iteration 33, average log likelihood -1.364529
[ Info: iteration 34, average log likelihood -1.364414
[ Info: iteration 35, average log likelihood -1.364314
[ Info: iteration 36, average log likelihood -1.364226
[ Info: iteration 37, average log likelihood -1.364146
[ Info: iteration 38, average log likelihood -1.364067
[ Info: iteration 39, average log likelihood -1.363972
[ Info: iteration 40, average log likelihood -1.363831
[ Info: iteration 41, average log likelihood -1.363618
[ Info: iteration 42, average log likelihood -1.363354
[ Info: iteration 43, average log likelihood -1.363122
[ Info: iteration 44, average log likelihood -1.362951
[ Info: iteration 45, average log likelihood -1.362830
[ Info: iteration 46, average log likelihood -1.362750
[ Info: iteration 47, average log likelihood -1.362697
[ Info: iteration 48, average log likelihood -1.362658
[ Info: iteration 49, average log likelihood -1.362629
[ Info: iteration 50, average log likelihood -1.362607
┌ Info: EM with 100000 data points 50 iterations avll -1.362607
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3992774590976398
│     -1.3992028138997723
│      ⋮
└     -1.3626072743089763
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.362692
[ Info: iteration 2, average log likelihood -1.362585
[ Info: iteration 3, average log likelihood -1.362080
[ Info: iteration 4, average log likelihood -1.356375
[ Info: iteration 5, average log likelihood -1.339367
[ Info: iteration 6, average log likelihood -1.327269
[ Info: iteration 7, average log likelihood -1.323325
[ Info: iteration 8, average log likelihood -1.321977
[ Info: iteration 9, average log likelihood -1.321210
[ Info: iteration 10, average log likelihood -1.320641
[ Info: iteration 11, average log likelihood -1.320162
[ Info: iteration 12, average log likelihood -1.319729
[ Info: iteration 13, average log likelihood -1.319431
[ Info: iteration 14, average log likelihood -1.319259
[ Info: iteration 15, average log likelihood -1.319148
[ Info: iteration 16, average log likelihood -1.319070
[ Info: iteration 17, average log likelihood -1.319011
[ Info: iteration 18, average log likelihood -1.318963
[ Info: iteration 19, average log likelihood -1.318923
[ Info: iteration 20, average log likelihood -1.318888
[ Info: iteration 21, average log likelihood -1.318856
[ Info: iteration 22, average log likelihood -1.318826
[ Info: iteration 23, average log likelihood -1.318798
[ Info: iteration 24, average log likelihood -1.318771
[ Info: iteration 25, average log likelihood -1.318745
[ Info: iteration 26, average log likelihood -1.318721
[ Info: iteration 27, average log likelihood -1.318698
[ Info: iteration 28, average log likelihood -1.318677
[ Info: iteration 29, average log likelihood -1.318657
[ Info: iteration 30, average log likelihood -1.318639
[ Info: iteration 31, average log likelihood -1.318622
[ Info: iteration 32, average log likelihood -1.318605
[ Info: iteration 33, average log likelihood -1.318590
[ Info: iteration 34, average log likelihood -1.318575
[ Info: iteration 35, average log likelihood -1.318562
[ Info: iteration 36, average log likelihood -1.318549
[ Info: iteration 37, average log likelihood -1.318536
[ Info: iteration 38, average log likelihood -1.318524
[ Info: iteration 39, average log likelihood -1.318513
[ Info: iteration 40, average log likelihood -1.318502
[ Info: iteration 41, average log likelihood -1.318491
[ Info: iteration 42, average log likelihood -1.318481
[ Info: iteration 43, average log likelihood -1.318471
[ Info: iteration 44, average log likelihood -1.318462
[ Info: iteration 45, average log likelihood -1.318453
[ Info: iteration 46, average log likelihood -1.318445
[ Info: iteration 47, average log likelihood -1.318438
[ Info: iteration 48, average log likelihood -1.318431
[ Info: iteration 49, average log likelihood -1.318425
[ Info: iteration 50, average log likelihood -1.318419
┌ Info: EM with 100000 data points 50 iterations avll -1.318419
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3626915144981449
│     -1.3625851078813132
│      ⋮
└     -1.3184187354523496
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.318544
[ Info: iteration 2, average log likelihood -1.318398
[ Info: iteration 3, average log likelihood -1.317860
[ Info: iteration 4, average log likelihood -1.313035
[ Info: iteration 5, average log likelihood -1.296025
[ Info: iteration 6, average log likelihood -1.281897
[ Info: iteration 7, average log likelihood -1.276132
[ Info: iteration 8, average log likelihood -1.272999
[ Info: iteration 9, average log likelihood -1.270806
[ Info: iteration 10, average log likelihood -1.269068
[ Info: iteration 11, average log likelihood -1.267460
[ Info: iteration 12, average log likelihood -1.265771
[ Info: iteration 13, average log likelihood -1.264156
[ Info: iteration 14, average log likelihood -1.263080
[ Info: iteration 15, average log likelihood -1.262533
[ Info: iteration 16, average log likelihood -1.262045
[ Info: iteration 17, average log likelihood -1.261533
[ Info: iteration 18, average log likelihood -1.261019
[ Info: iteration 19, average log likelihood -1.260540
[ Info: iteration 20, average log likelihood -1.260112
[ Info: iteration 21, average log likelihood -1.259708
[ Info: iteration 22, average log likelihood -1.259321
[ Info: iteration 23, average log likelihood -1.258954
[ Info: iteration 24, average log likelihood -1.258587
[ Info: iteration 25, average log likelihood -1.258189
[ Info: iteration 26, average log likelihood -1.257736
[ Info: iteration 27, average log likelihood -1.257257
[ Info: iteration 28, average log likelihood -1.256759
[ Info: iteration 29, average log likelihood -1.256255
[ Info: iteration 30, average log likelihood -1.255820
[ Info: iteration 31, average log likelihood -1.255514
[ Info: iteration 32, average log likelihood -1.255340
[ Info: iteration 33, average log likelihood -1.255267
[ Info: iteration 34, average log likelihood -1.255245
[ Info: iteration 35, average log likelihood -1.255238
[ Info: iteration 36, average log likelihood -1.255236
[ Info: iteration 37, average log likelihood -1.255236
[ Info: iteration 38, average log likelihood -1.255235
[ Info: iteration 39, average log likelihood -1.255235
[ Info: iteration 40, average log likelihood -1.255235
[ Info: iteration 41, average log likelihood -1.255235
[ Info: iteration 42, average log likelihood -1.255235
[ Info: iteration 43, average log likelihood -1.255235
[ Info: iteration 44, average log likelihood -1.255234
[ Info: iteration 45, average log likelihood -1.255234
[ Info: iteration 46, average log likelihood -1.255234
[ Info: iteration 47, average log likelihood -1.255234
[ Info: iteration 48, average log likelihood -1.255234
[ Info: iteration 49, average log likelihood -1.255234
[ Info: iteration 50, average log likelihood -1.255234
┌ Info: EM with 100000 data points 50 iterations avll -1.255234
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3185444112136895
│     -1.3183981926644834
│      ⋮
└     -1.255234344734457
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.255433
[ Info: iteration 2, average log likelihood -1.255197
[ Info: iteration 3, average log likelihood -1.254372
[ Info: iteration 4, average log likelihood -1.245830
[ Info: iteration 5, average log likelihood -1.219618
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.190774
[ Info: iteration 7, average log likelihood -1.181676
[ Info: iteration 8, average log likelihood -1.167663
[ Info: iteration 9, average log likelihood -1.159904
[ Info: iteration 10, average log likelihood -1.153837
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.151071
[ Info: iteration 12, average log likelihood -1.160986
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.153978
[ Info: iteration 14, average log likelihood -1.160898
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.154015
[ Info: iteration 16, average log likelihood -1.160869
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.153998
[ Info: iteration 18, average log likelihood -1.160847
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.153977
[ Info: iteration 20, average log likelihood -1.160822
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.153947
[ Info: iteration 22, average log likelihood -1.160786
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.153905
[ Info: iteration 24, average log likelihood -1.160732
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.153840
[ Info: iteration 26, average log likelihood -1.160654
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.153757
[ Info: iteration 28, average log likelihood -1.160563
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.153662
[ Info: iteration 30, average log likelihood -1.160462
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.153570
[ Info: iteration 32, average log likelihood -1.160386
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.153523
[ Info: iteration 34, average log likelihood -1.160357
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.153511
[ Info: iteration 36, average log likelihood -1.160350
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.153508
[ Info: iteration 38, average log likelihood -1.160348
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.153508
[ Info: iteration 40, average log likelihood -1.160348
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.153507
[ Info: iteration 42, average log likelihood -1.160347
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.153507
[ Info: iteration 44, average log likelihood -1.160347
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.153506
[ Info: iteration 46, average log likelihood -1.160346
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.153506
[ Info: iteration 48, average log likelihood -1.160346
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.153506
[ Info: iteration 50, average log likelihood -1.160346
┌ Info: EM with 100000 data points 50 iterations avll -1.160346
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.255433251829481
│     -1.255197215650919
│      ⋮
└     -1.1603461875616476
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.153773
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.151163
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.151234
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.125740
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      9
│     20
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.076556
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│     10
│     14
│     15
│     19
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.066768
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     20
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.075862
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     10
│     14
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.052885
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      9
│     19
│     20
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.055294
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     14
│     15
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.063496
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      9
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.065911
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│     10
│     14
│     20
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.050067
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     19
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.064375
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     10
│     14
│     15
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.048155
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      9
│     20
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.060583
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     14
│     19
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.059002
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      9
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.056484
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│     10
│     14
│     15
│     20
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.043748
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     19
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.071314
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     10
│     14
│     20
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.051022
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      9
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.061388
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     10
│     14
│     15
│     19
│     20
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.045199
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      9
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.065636
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     10
│     14
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.053382
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     15
│     20
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.050545
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      5
│     10
│     14
│     19
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.048331
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     20
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.067528
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│     10
│     14
│     15
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.045078
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      9
│     19
│     20
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.054936
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     10
│     14
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.060829
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     15
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.060481
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      5
│     10
│     14
│     20
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.042253
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     19
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.065966
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│     10
│     14
│     15
│     20
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.045072
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      9
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.064195
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│     10
│     14
│     19
│     20
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.046336
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     15
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.065023
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      5
│     10
│     14
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.052315
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     20
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.059462
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│     10
│     14
│     15
│     19
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.042744
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      9
│     20
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.063635
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     10
│     14
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.054989
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     15
│     19
│     20
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.049698
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      5
│     10
│     14
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.056443
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.069577
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│     10
│     14
│     15
│     20
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.036648
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      9
│     19
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.062200
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│     10
│     14
│     20
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.055115
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     15
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.058921
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      5
│     10
│     14
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.041913
┌ Info: EM with 100000 data points 50 iterations avll -1.041913
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.153773292230022
│     -1.151163168771337
│      ⋮
└     -1.0419129325964267
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3992040418494736
│     -1.3992774590976398
│     -1.3992028138997723
│     -1.3988096232478915
│      ⋮
│     -1.0551153764196457
│     -1.0589211533082634
└     -1.0419129325964267
32×26 Array{Float64,2}:
 -0.203329    0.00314243   0.0336155   0.0705624    0.00287403  -0.0663515   -0.125684    -0.120373    0.171273    -0.0246079    0.0183475   -0.140448    -0.026447   -0.0564455   -0.0627377    0.0828747    0.188354     0.0141858   -0.178685     0.0821165    0.0144665   -0.112499     0.0140394     0.0179619    0.0842186    0.00772619
 -0.0513095  -0.0934113    0.0814621  -0.0149913    0.147372    -0.0291       0.0348424    0.0605198   0.0363843   -0.0135418    0.0270894    0.069061    -0.122647    0.0183121    0.103104    -0.0779276   -0.0639661   -0.04908     -0.0439253   -0.104929     0.0433208    0.0159841    0.0493938     0.0594767    0.0183177    0.156002
  0.0492521   0.0388768    0.20726    -0.0198688    0.0759226   -0.0993914    0.131503     0.0138735   0.0620286   -0.0872257    0.13633      0.159804     0.0864981  -0.0990055    0.113238     0.102885     0.0291196    0.159992     0.124405     0.0269149   -0.0418989    0.0984247    0.13021       0.0256553    0.059373     0.131582
 -0.0674045   0.0354936    0.0533048   0.0964212    0.0846057    0.12945     -0.0554216   -0.106989   -0.0754102   -0.0525945   -0.107447    -0.0130678   -0.0341016  -0.101859     0.0647757   -0.00681319   0.0621215    0.195463     0.00376882   0.158914    -0.0205996    0.1151      -0.115826      0.14212      0.211399    -0.0717525
 -0.164569   -0.137315     0.0688855  -0.0206108   -0.0159445    0.071583     0.189268     0.0391555   0.0993289   -0.0206965    0.0454937   -0.0541832   -0.0252948  -0.0440833   -0.0161036   -0.0720538   -0.0887221   -0.016252    -0.142256     0.0765483    0.109991    -0.11209      0.126887     -0.119599    -0.193028     0.0598908
  0.0503705  -0.180931    -0.0377307   0.0564099   -0.0237136    0.063722    -0.0981025   -0.0465077  -0.00261267   0.08469     -0.150508    -0.00351724   0.216495    0.217222    -0.132414     0.0905104   -0.0413667    0.104345    -0.15932     -0.00998028  -0.061876     0.0473254    0.20986      -0.0518144    0.17031      0.0143255
 -0.186158    0.0703827    0.0986903   0.0103628   -0.106914     0.115337    -0.110238     0.245645   -0.202897     0.0724119    0.168669    -0.0377151    0.141367    0.0829538   -0.0369964    0.0629725    0.0118276   -0.0676081   -0.0652485   -0.0656485   -0.0442028   -0.0119009    0.0575757     0.0422324   -0.172374    -0.0427551
 -0.0264563   0.00194297  -0.0820613  -0.0376553   -0.0548529   -0.0668157    0.0182049   -0.0325664   0.0417755   -0.118409    -0.0233431   -0.0372375    0.0543982   0.0817932    0.110836     0.0553635    0.0644173   -0.0662215    0.0190755    0.00201753  -0.02167      0.0239267    0.141366      0.0248886    0.0490128    0.0399842
  0.148165   -0.0398215   -0.117575   -0.22508     -0.163472    -0.00441821  -0.0364497    0.0625416   0.117093    -0.0169353    0.106755    -0.163484     0.0286244  -0.0240399    0.0647702   -0.126254    -0.0712697   -0.101343     0.0416825   -0.22112      0.0840466   -0.115282     0.0635123     0.013964    -0.0773637   -0.0266659
 -0.0106848   0.0736446   -0.0919865  -0.0730581   -0.0961933    0.199873    -0.0588285   -0.0042324  -0.0774794    0.0267883    0.00236418   0.14466      0.152627    0.0584381   -0.0631956   -0.115599     0.0110789   -0.11376     -0.0110997    0.12421     -0.00485324  -0.125573    -0.103336      0.00144397  -0.122334    -0.0127018
  0.142473    0.170363     0.0326368   0.208577    -0.0648174    0.0488977    0.139765     0.0746476  -0.118137    -0.031564    -0.0748969   -0.0483968   -0.0694068   0.0572971    0.0287228    0.00719963  -0.180598     0.0181842    0.0100986   -0.0109491   -0.055013    -0.059899    -0.147075      0.0129613    0.115312    -0.0292841
  0.0440452  -0.129914    -0.10546    -0.00648109   0.0663283   -0.00234473   0.0645194    0.0704259   0.102278    -0.035807    -0.0340592   -0.00394267   0.0806821  -0.0819946   -0.128374     0.0399157    0.0956912    0.0235464   -0.0186668   -0.0783578   -0.128389    -0.0877603    0.0509288    -0.194212     0.0438786   -0.0440073
  0.0477695  -0.0280743   -0.159867   -0.187963     0.0476945    0.053952    -0.0725205    0.295333    0.0140657    0.117856     0.126838     0.00844627   0.140632    0.0205134    0.14731      0.090432    -0.0734594    0.0567271    0.244754    -0.0118182    0.0638662   -0.0679513    0.113713     -0.0405818    0.195742     0.0733579
 -0.0986631  -0.0329262    0.0678109   0.140219     0.00224995  -0.0327944   -0.0674628   -0.0558717   0.0377076   -0.0966464   -0.111122     0.0346347   -0.129625   -0.0251124   -0.0618656    0.0311393   -0.00621651  -0.0534954    0.0617217    0.0868054   -0.108671    -0.0318738   -0.00106008   -0.156836     0.0730632   -0.0129062
  0.0254719  -0.0912526    0.0594706   0.0702156    0.0458782    0.1949       0.158411     0.224703   -0.152894     0.0666574    0.103229    -0.0906768   -0.157787    0.00108469   0.309711     0.136721     0.0870894    0.139263     0.158188    -0.0215225   -0.195918    -0.13535      0.217098     -0.0293877   -0.0648503    0.207343
  0.0344485  -0.15723      0.0484796  -0.250613     0.12335     -0.0858268   -0.082997     0.107869    0.0515278   -0.0354974    0.0574962   -0.0422214    0.242935    0.134262    -0.00337088   0.029492    -0.0242274    0.144809    -0.113538     0.0213834    0.0521789   -0.0937455   -0.0693409     0.176801     0.0461108    0.0373809
  0.192242    0.153784    -0.0592852  -0.0652197    0.0449184   -0.0875976    0.12984      0.0970218  -0.161639     0.207344     0.152741    -0.112359     0.0771863   0.00821149   0.00113033   0.0684751    0.10392      0.18036      0.0760561    0.00801239   0.0902413   -0.0597777   -0.128948     -0.0455328   -0.143966    -0.102065
  0.0203187   0.060269    -0.0801565  -0.0808257   -0.0794713   -0.139359    -0.0813173    0.078845    0.023815     0.00985023  -0.0104833    0.0313628    0.0418252  -0.0203896   -0.0822812    0.0287511   -0.00147653  -0.00138604   0.16032      0.0836785    0.00802277   0.0627834   -0.0103132    -0.0583649   -0.117465     0.101822
  0.0744799  -0.162125    -0.0104795   0.124335    -0.062829     0.0765258   -0.0186206   -0.0286658   0.0629281   -0.0187152   -0.179609     0.222938    -0.097314   -0.0517679   -0.00270945   0.0322511    0.0491628    0.179657    -0.0106315   -0.126525     0.180424     0.041025    -0.0589851    -0.116803    -0.0362617   -0.0896326
  0.106418    0.124988     0.0047538  -0.0311016   -0.0333745    0.051438    -0.0505765   -0.0214997   0.10351     -0.0342478    0.127103     0.00128424   0.0852331  -0.0260728    0.0321646    0.0213964   -0.0891554   -0.010998     0.15342      0.104936     0.107463    -0.21196      0.092526      0.00917842  -0.0576899   -0.0416694
 -0.721704   -0.175825     0.0231346   0.146592     0.17484      0.0283542   -0.0543098   -0.0988831   0.0420741   -0.142494    -0.078428    -0.112723    -0.14125    -0.0281878   -0.0427938    0.00554028   0.00812453   0.1055       0.0338944    0.0918841   -0.0729      -0.028559     0.000342501  -0.150093     0.0743153   -0.189262
  0.377176   -0.0540551    0.0442118   0.144033    -0.0779703    0.00750877  -0.0610442   -0.228876    0.0770805   -0.088412    -0.03526     -0.106117    -0.0812069  -0.0362242   -0.03853      0.0177712    0.00738161   0.202592     0.0660581   -0.0318773    0.191291    -0.191341    -0.16069      -0.151316     0.075943    -0.193147
 -0.736669    0.105042    -0.0926492   0.00499953   0.0417283    0.244625    -0.0800703    0.138365    0.143601    -0.00258723   0.062233    -0.0499817   -0.0676008   0.156684    -0.0275113    0.0915928    0.0567418    0.104469    -0.153888     0.105094    -0.12802     -0.106982    -0.0895276     0.0756334    0.160065     0.00182025
  0.379429    0.054847    -0.0324595   0.0593717   -0.0115669    0.233098    -0.0870868   -0.167781    0.127655    -0.0758742    0.00508242  -0.0545762   -0.047116    0.180257     0.0666406    0.0706238   -0.119933    -0.040836    -0.143673     0.129563    -0.0407826   -0.0273733    0.149082      0.0632565   -0.132458     0.00958213
  0.0810779  -0.183397     0.227658   -0.19105     -0.203312    -0.146324     0.00736165  -0.207481    0.0826933   -0.0217237    0.176744    -0.0777018   -0.0737822  -0.0743202   -0.0192636   -0.117546     0.0686104   -0.170258     0.0946584   -0.0664823   -0.170154     0.0749865    0.00830791    0.098855    -0.173173    -0.971877
  0.0869942  -0.219872     0.361084    0.663726     0.0330919   -0.133465     0.0251334    0.0904829   0.0961707    0.0869046   -0.0248537   -0.00103808   0.152464   -0.0239574   -0.0151252   -0.124829     0.113909    -0.214716     0.00124399  -0.0645962   -0.276617     0.0416233    0.022658      0.0704293   -0.172086     0.0776951
 -0.0849206  -0.214137    -0.58829    -0.157023    -0.24258     -0.145336     0.170389    -0.0484766   0.0568889    0.109522    -0.314366    -0.115259    -0.028498   -0.0578469   -0.0110356   -0.109481     0.0691712   -0.124559     0.109502    -0.0917547   -0.584717    -0.0290903    0.0564506     0.0759487   -0.242957    -0.704932
 -0.105481   -0.223702    -0.0921345  -0.321837    -0.0720476   -0.156665     0.0582021   -0.454797    0.0897859   -0.0465011   -0.229208    -0.0935843    0.0343932  -0.0339683    0.00221651  -0.107825    -0.0148596   -0.250743     0.217202    -0.0570727   -0.33067      0.0852351    0.0494375     0.0797857   -0.0669929    0.692784
  0.0462137  -0.125981     0.020056    0.0539839   -0.031467    -0.039916     0.0573074    0.117376   -0.0245506   -0.127024    -0.0397943    0.149126     0.0403621   0.0297481   -0.084652    -0.028766    -0.143374     0.0690182    0.125528    -0.0348336   -0.135564    -0.00747429   0.158778     -0.17745     -0.035301     0.0566542
 -0.0771424  -0.0959318    0.062287   -0.108601    -0.106677    -0.0646216    0.114223    -0.056211    0.121501     0.0221759    0.126257     0.0182833   -0.0288521   0.0327818   -0.0227518   -0.103194    -0.00316272   0.0185424    0.180556     0.0967682   -0.0837273    0.103312     0.0220213     0.0545379    0.0982973    0.00971417
 -0.430589   -0.0386896    0.249674   -0.106172     0.00680574   0.0749066    0.0554668   -0.0413011  -0.335149     0.0977672    0.0356307   -0.102896    -0.537241    0.0477325    0.0258081   -0.0207035   -0.0910125    0.0658088    0.0711001    0.180534     0.415516     0.182245     0.49428       0.0772421    0.00334079   0.0514957
  0.149707   -0.0298064   -0.208632    0.154067     0.0195255   -0.0339416    0.0500001   -0.0388629   0.0192332    0.0981719    0.0130088   -0.0206912    0.19791     0.0491877    0.0803701   -0.0213199   -0.0880423    0.0282553   -0.021595     0.18063     -0.0524091   -0.0955328   -0.156188      0.169132    -0.00388046   0.00943375[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.074018
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      9
│     10
│     14
│     15
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.039500
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      9
│     20
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.048613
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      9
│     10
│     14
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.042561
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     20
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.060022
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      5
│      9
│     10
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.034241
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     19
│     20
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.058408
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      9
│     10
│     14
│     15
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.043677
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      9
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.058679
kind diag, method kmeans
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      9
│     10
│     14
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.036390
┌ Info: EM with 100000 data points 10 iterations avll -1.036390
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.743279e+05
      1       6.743737e+05      -1.999542e+05 |       32
      2       6.403226e+05      -3.405114e+04 |       32
      3       6.234890e+05      -1.683353e+04 |       32
      4       6.153641e+05      -8.124883e+03 |       32
      5       6.107310e+05      -4.633128e+03 |       32
      6       6.069688e+05      -3.762260e+03 |       32
      7       6.037475e+05      -3.221233e+03 |       32
      8       6.017038e+05      -2.043695e+03 |       32
      9       6.005980e+05      -1.105832e+03 |       32
     10       5.999922e+05      -6.058378e+02 |       32
     11       5.996088e+05      -3.833249e+02 |       32
     12       5.992908e+05      -3.180011e+02 |       32
     13       5.989760e+05      -3.148417e+02 |       32
     14       5.986731e+05      -3.028578e+02 |       32
     15       5.983529e+05      -3.202686e+02 |       32
     16       5.980459e+05      -3.069193e+02 |       32
     17       5.978346e+05      -2.113420e+02 |       32
     18       5.976834e+05      -1.511813e+02 |       32
     19       5.975433e+05      -1.401251e+02 |       32
     20       5.973909e+05      -1.524302e+02 |       32
     21       5.972010e+05      -1.898597e+02 |       32
     22       5.969648e+05      -2.362179e+02 |       32
     23       5.966986e+05      -2.661980e+02 |       32
     24       5.964413e+05      -2.573025e+02 |       32
     25       5.961943e+05      -2.469470e+02 |       32
     26       5.959835e+05      -2.108525e+02 |       32
     27       5.958327e+05      -1.507543e+02 |       31
     28       5.956855e+05      -1.472268e+02 |       32
     29       5.955363e+05      -1.491965e+02 |       32
     30       5.954095e+05      -1.268507e+02 |       32
     31       5.952849e+05      -1.245318e+02 |       32
     32       5.951654e+05      -1.195093e+02 |       32
     33       5.950259e+05      -1.395499e+02 |       32
     34       5.948270e+05      -1.988991e+02 |       32
     35       5.946031e+05      -2.238310e+02 |       32
     36       5.943558e+05      -2.473141e+02 |       32
     37       5.941271e+05      -2.287188e+02 |       32
     38       5.939133e+05      -2.138136e+02 |       32
     39       5.936930e+05      -2.202580e+02 |       32
     40       5.934235e+05      -2.695145e+02 |       32
     41       5.931002e+05      -3.233444e+02 |       32
     42       5.927733e+05      -3.268636e+02 |       32
     43       5.925126e+05      -2.607165e+02 |       31
     44       5.923947e+05      -1.178749e+02 |       32
     45       5.923513e+05      -4.339869e+01 |       29
     46       5.923338e+05      -1.750726e+01 |       30
     47       5.923229e+05      -1.091948e+01 |       30
     48       5.923158e+05      -7.059848e+00 |       27
     49       5.923099e+05      -5.953857e+00 |       26
     50       5.923042e+05      -5.698775e+00 |       26
K-means terminated without convergence after 50 iterations (objv = 592304.1833643795)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.313392
[ Info: iteration 2, average log likelihood -1.282559
[ Info: iteration 3, average log likelihood -1.249101
[ Info: iteration 4, average log likelihood -1.211312
[ Info: iteration 5, average log likelihood -1.161996
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.110561
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      8
│      9
│     24
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.074848
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.124452
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.092183
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.058620
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      8
│      9
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.040090
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     12
│     15
│     17
│     21
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.060738
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.086769
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│      4
│      7
│      9
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.044720
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.086269
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     12
│     17
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.058769
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     15
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.051013
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      7
│      8
│      9
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.051474
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.087418
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     12
│     15
│     17
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.038545
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     16
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.080255
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      7
│      9
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.067578
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.073072
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│      8
│     12
│     15
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.022839
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     16
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.064762
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      9
│     21
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.059512
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.090778
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      8
│     12
│     15
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.032728
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.079457
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      7
│      9
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.061759
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.067734
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      6
│      8
│     12
│     15
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.003698
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.089335
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      7
│      9
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.071863
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.071216
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      6
│      8
│      ⋮
│     20
│     21
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.006704
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.102888
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      7
│      9
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.057467
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.056679
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      6
│      8
│     12
│     15
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.015850
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.086534
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      7
│      9
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.043967
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     24
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.037390
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      6
│      8
│     12
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.019598
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.075014
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      7
│      9
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.042028
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.056047
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      6
│      8
│     12
│     15
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.012198
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.070347
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      7
│      9
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.039272
┌ Info: EM with 100000 data points 50 iterations avll -1.039272
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0681695   -0.170205    -0.0851624    0.0171125    0.0234321   -0.0779274    0.113502     0.0572037     0.388588    -0.12617     -0.107985     -0.104073     0.0255957    0.0921454   -0.215253     0.0179961   -0.0781534    0.194035    -0.0803487   -0.0306458   -0.201969     -0.185462     0.0723053   -0.370556      0.0651256   -0.190886
 -0.307373    -0.153332     0.16205      0.0221532   -0.0503563    0.0805728    0.335778     0.0324311     0.10091     -0.0325356    0.0517384    -0.0459468   -0.0219642   -0.0674151    0.00387551   0.0327962   -0.100285     3.28118e-5  -0.132626     0.149138     0.106874     -0.124982     0.123283    -0.130701     -0.228471     0.0525026
  0.0663057   -0.0549008    0.00521884  -0.155262    -0.0612376   -0.174961    -0.108839     0.10013       0.0427241   -0.0399848    0.000701728   0.134922     0.00956371   0.0075127   -0.185705     0.138913     0.0743393    0.154432     0.135434     0.0541385    0.0382596    -0.0109835   -0.0769064    0.0398101    -0.115154     0.227784
 -0.0993413   -0.0324485    0.0698266    0.141936     0.0013347   -0.0294139   -0.0694897   -0.0551623     0.0311114   -0.0962466   -0.114151      0.038581    -0.126608    -0.0253042   -0.0638257    0.0315133   -0.00535374  -0.0543999    0.0607905    0.0885746   -0.107514     -0.0340023   -0.00350682  -0.156708      0.0740318   -0.0107962
  0.0225017   -0.181902    -0.0247197    0.0456735   -0.0225573    0.0568248   -0.100442    -0.0458753     0.00771836   0.0883755   -0.13347      -0.00780934   0.203026     0.196558    -0.123569     0.0689446   -0.0554247    0.100043    -0.171137    -0.00344029  -0.0456815     0.0420416    0.20808     -0.0511572     0.135862     0.0115786
  0.094686     0.147855     0.0243299   -0.00325562  -0.0214079    0.0827449   -0.0766182   -0.0288655     0.129058    -0.010684     0.117633     -0.0157018    0.105202    -0.0220879    0.036918     0.0565672   -0.058582     0.0219518    0.157604     0.0959002    0.0664645    -0.195631     0.134019    -0.00426971   -0.045262     0.0218083
 -0.0032829    0.00701853  -0.123918     0.00039555   0.0128086    0.0566361    0.0742334    0.000631073  -0.00936044  -0.0672845    0.12584       0.0514788    0.0248473    0.0508152    0.0760919    0.0330533   -0.0391258    0.0399438    0.178658    -0.0467335    0.0384973    -0.0522959    0.0660612    0.217013      0.107423    -0.0376957
  0.189667    -0.0102866   -0.155043    -0.215708    -0.110759     0.0151572   -0.0813199    0.0579436     0.109492    -0.0163052    0.105592     -0.152572     0.0130442   -0.0420262    0.0397617   -0.17353     -0.0729677   -0.103035     0.0313277   -0.194175     0.0853885    -0.124314     0.0805675   -0.000311046  -0.0896284   -0.00688236
 -0.00426353   0.0168345   -0.0615837    0.0636976   -0.0947621   -0.181614    -0.127546     0.108175      0.145716     0.0935752   -0.100495      0.0203117   -0.0730081    0.0318772    0.151395     0.0512938   -0.00287831  -0.0787053    0.0236245    0.138297    -0.000799404   0.0717313   -0.0970104   -0.115493     -0.30321      0.0410466
 -0.00826083  -0.209525    -0.0292648   -0.0265235   -0.125343    -0.146146     0.0656325   -0.168356      0.0810574    0.0282606   -0.102183     -0.0735287    0.0173708   -0.0476605   -0.0101959   -0.114519     0.0571777   -0.190602     0.113537    -0.0698982   -0.339666      0.0452857    0.0343978    0.0816409    -0.160495    -0.21461
  0.197257     0.152179    -0.0518169   -0.068162     0.0540764   -0.0863608    0.129699     0.10152      -0.164364     0.206155     0.159121     -0.114838     0.0709142    0.0114667    0.00220246   0.0674956    0.0974286    0.184469     0.0764636    0.00588717   0.0884631    -0.0509727   -0.131712    -0.0380258    -0.145884    -0.110179
  0.0734104   -0.157382    -0.0102423    0.11946     -0.0610328    0.0695209   -0.013775    -0.0233174     0.0699424   -0.00717675  -0.165073      0.218714    -0.0921769   -0.0462233   -0.008027     0.0327808    0.0620588    0.180028    -0.00790955  -0.114198     0.17051       0.0364664   -0.0751796   -0.112232     -0.030465    -0.0805517
 -0.166703     0.071683     0.0951733    0.0147574   -0.103808     0.114751    -0.0985493    0.246811     -0.202784     0.0694772    0.170732     -0.0376564    0.148084     0.082777    -0.0415648    0.0625037    0.0291159   -0.0637482   -0.0665731   -0.0701374   -0.0523823    -0.0124325    0.061434     0.0476343    -0.171775    -0.0472535
 -0.144663    -0.0142792    0.0601287    0.103581     0.0923129   -0.072914     0.0792607   -0.0305697     0.0315767    0.046975    -0.00336907   -0.00614941  -0.198735    -0.0159664    0.0972668   -0.0350303   -0.0197739   -0.0673475   -0.115068    -0.143644     0.00475981    0.0921804   -0.0695476    0.0727171     0.0176404    0.214392
  0.00108626  -0.0390269   -0.0446145    0.0216261   -0.0417494    0.0290102    0.0534721    0.0269419     0.181163    -0.120226     0.0551628     0.00372829   0.188396     0.0097358   -0.0857254   -0.00278334  -0.121887     0.0818638    0.0266768   -0.0434061   -0.137716     -0.149526    -0.0632006   -0.108377     -0.0101498   -0.348008
 -0.011196     0.0795835   -0.118933    -0.0618393   -0.0811376    0.16742     -0.0498371   -0.0162891    -0.0806035    0.0166159   -0.0106082     0.18813      0.143815     0.0576283   -0.0706456   -0.136605     0.0137619   -0.0805666   -0.00570838   0.117007    -0.0219495    -0.131768    -0.110259     0.0150687    -0.0956799    0.0173974
  0.0310641   -0.158084     0.0468152   -0.2409       0.120899    -0.081777    -0.0799946    0.10778       0.0604127   -0.0360147    0.0572644    -0.0461602    0.236763     0.133467    -0.00421246   0.0264739   -0.0220868    0.143761    -0.113607     0.0196373    0.0458243    -0.0946152   -0.0701588    0.169495      0.0435862    0.0321067
  0.0477742   -0.0274763   -0.159618    -0.184575     0.046629     0.0541798   -0.07537      0.294775      0.0163866    0.118377     0.125255      0.0061559    0.141266     0.0208239    0.146266     0.0872059   -0.0732747    0.0555594    0.24334     -0.00907918   0.0635695    -0.0675079    0.114444    -0.0406669     0.194672     0.0729545
 -0.0166684    0.0423001    0.131062     0.0491304    0.0819059    0.0206832    0.0520969   -0.0549391    -0.00901032  -0.0735096    0.0124435     0.0714256    0.0318949   -0.106014     0.106895     0.0407594    0.0459588    0.177334     0.0650448    0.0959468   -0.0301686     0.112424     0.00644669   0.0838278     0.143944     0.0168135
  0.00788434  -0.0305145   -0.102482     0.103627     0.0120378   -0.00654838   0.0501485   -0.0353374    -0.0804904    0.097663     0.0197593    -0.0438682    0.00269096   0.0494732    0.0634953   -0.0176921   -0.0844521    0.0254816   -0.00697879   0.177161     0.0700044    -0.0352402    0.0222182    0.147694      0.00223489   0.0303541
  0.025997    -0.164917     0.0584172    0.0749707    0.0551511    0.189489     0.236992     0.322455     -0.237657     0.0685619    0.1013       -0.105065    -0.247281     0.00778046   0.389372     0.140318     0.127101     0.139762     0.15117     -0.0313014   -0.197166     -0.14589      0.24708     -0.0361248    -0.054416     0.187778
  0.128535     0.170716     0.0313604    0.186564    -0.0672584    0.0669467    0.13051      0.0730852    -0.11522     -0.0214047   -0.0748434    -0.0569741   -0.0539088    0.0700718    0.0240529    0.00859234  -0.174383     0.0039309    0.00951011  -0.00958364  -0.0525684    -0.0681214   -0.148954     0.0109124     0.103327    -0.062499
 -0.16141      0.0793422   -0.0621127    0.0329316    0.015367     0.240894    -0.0835481   -0.017669      0.136155    -0.0416142    0.032149     -0.0545773   -0.0571899    0.168788     0.0190664    0.0803135   -0.0315024    0.0298591   -0.148988     0.11782     -0.0857366    -0.0646015    0.0331968    0.0699158     0.00977585   0.00345293
 -0.209096    -0.00712745   0.0337029    0.0762639    0.00298077  -0.061943    -0.114861    -0.120263      0.176253    -0.0156205    0.0175368    -0.152054    -0.0198956   -0.0491741   -0.0644434    0.0846102    0.195148     0.0237727   -0.194204     0.0835647    0.00818009   -0.12018      0.0146217    0.0149146     0.0842796    0.00597352
  0.00913692   0.184324    -0.169291    -0.18041     -0.0734066   -0.0662767   -0.00857685   0.0277554    -0.104411    -0.0162463    0.0762674    -0.0480216    0.177405    -0.0749919   -0.26715     -0.0855504   -0.0601223   -0.0328448    0.328613     0.0534583   -0.0393893     0.109604     0.120186    -0.0969133     0.0824554    0.0513133
  0.0409635   -0.0820473   -0.0357058   -0.0210754   -0.113213    -0.138186    -0.0707326   -0.109654      0.0910097   -0.164137    -0.124603      0.0730395    0.135156     0.0734932    0.0924892    0.119776     0.285368    -0.15808     -0.151416    -0.00239349  -0.0816918     0.102003     0.136595    -0.0147005    -0.129193     0.156803
  0.0323149   -0.153935     0.0878943   -0.123488     0.183997     0.0115092   -0.00584236   0.139924      0.0471789   -0.0719505    0.0542815     0.132327    -0.0436731    0.0512973    0.102989    -0.121302    -0.10263     -0.0375976    0.0293175   -0.0580357    0.0764966    -0.0645766    0.163334     0.0439796     0.0225633    0.0933676
 -0.164973    -0.114182     0.033849     0.145299     0.0469278    0.0180595   -0.0577066   -0.164554      0.0597407   -0.115099    -0.0567103    -0.109363    -0.110671    -0.0322415   -0.0405889    0.0118182    0.007721     0.154772     0.0506322    0.0293365    0.0603251    -0.110985    -0.0815841   -0.150851      0.0751446   -0.191441
  0.138222    -0.121794    -0.114512    -0.0297266    0.097796     0.0810076    0.0341482    0.0786621    -0.0972631    0.0100862    0.0111324     0.0563523    0.111842    -0.234369    -0.0652441    0.0625025    0.208534    -0.125999    -0.00286162  -0.112423    -0.0662584    -0.018273     0.0879019   -0.169437      0.0216493    0.0787163
  0.0458585   -0.125577     0.0225353    0.0530393   -0.0370995   -0.0394118    0.0552226    0.116177     -0.0231284   -0.125874    -0.0385827     0.145368     0.0405261    0.028119    -0.0838805   -0.0297301   -0.141334     0.0681683    0.125403    -0.0340069   -0.135247     -0.00453411   0.157016    -0.175002     -0.0360605    0.0547019
 -0.0842313   -0.0944843    0.0690855   -0.112646    -0.105852    -0.0589279    0.112279    -0.057951      0.120722     0.0270309    0.126327      0.0164505   -0.0252442    0.0389305   -0.0220264   -0.098269    -0.00566307   0.0138161    0.178382     0.0986628   -0.0817082     0.100297     0.0133578    0.0527783     0.089656     0.0035279
 -0.132647     0.0666531   -0.0793562   -0.0768506   -0.0424763   -0.101775     0.0465719   -0.00871485    0.0515408   -0.13047     -0.0694912    -0.219636     0.0155057    0.114642     0.170909     0.0111674   -0.0873202   -0.0774675    0.0268618    0.0598315   -0.0126784    -0.00232802   0.201444    -0.0940563     0.168163    -0.0123244[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.051357
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      6
│      8
│      ⋮
│     21
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.977453
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      7
│      8
│      9
│      ⋮
│     25
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.985924
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      6
│      8
│     12
│     16
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.018706
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     20
│     21
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.009572
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      4
│      6
│      ⋮
│     25
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.954576
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.049321
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      6
│      8
│      ⋮
│     21
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.977717
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      7
│      8
│      9
│      ⋮
│     25
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.990185
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      6
│      8
│     12
│     16
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.018882
┌ Info: EM with 100000 data points 10 iterations avll -1.018882
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.050428     0.0327769    0.112831     0.0338738    -0.00723427  -0.068726    -0.0978638    -0.0756539    0.272308     -0.0585458   -0.119627      0.0722516    0.0638988     0.109577     -0.00835269  -0.103059     -0.00327391  -0.0656883  -0.0487288    0.12627     0.0392873    0.0595655     0.0383207    0.056986     0.0541185   0.0250368
  0.110897     0.0399504    0.07355      0.0174358    -0.00177716  -0.0872628    0.0991239    -0.00200462   0.0244609    -0.104841    -0.0542597    -0.158831    -0.171961      0.0759833    -0.0382412    0.0260157    -0.0941002    0.158132   -0.0766935    0.120428   -0.0863726   -0.0458352    -0.0457629    0.0985125   -0.131202    0.0645799
 -0.0336514    0.0341721   -0.0657021    0.0744727     0.1467       0.113074    -0.0220542     0.0412428    0.00891874   -0.00496395  -0.0967354    -0.148284     0.0920614    -0.0962322    -0.0646981   -0.0068376    -0.118619     0.154228    0.0483371   -0.0037704  -0.0740883   -0.0349537     0.0158483   -0.0538413    0.0185002   0.0595114
 -0.0711684   -0.112215    -0.156103     0.111332     -0.0945041   -0.0248407   -0.0757963     0.0828081   -0.000435271   0.0265898   -0.00514305   -0.144972     0.0810822    -0.0687946     0.00197821   0.0442866     0.172108    -0.0217108  -0.132554     0.0136102   0.0217081    0.151969      0.0221418   -0.0181543   -0.0242283  -0.173032
 -0.0772555   -0.0785284   -0.0285476    0.106619      0.142845    -0.0200937   -0.0696688    -0.107378    -0.163867     -0.120741    -0.0871987    -0.124834     0.0448243     0.0310675     0.0640131   -0.0978768    -0.0488458    0.0281112  -0.016872    -0.0442883  -0.0488837   -0.00538624    0.0549378    0.0225177    0.0465071  -0.120348
  0.179807     0.185836    -0.269547    -0.046449     -0.0379997    0.0134363   -0.0151486     0.100658    -0.161724     -0.0901488    0.15018       0.0728428   -0.0760097    -0.028279      0.138655     0.0674093    -0.103342     0.0467827   0.00587317   0.14521    -0.154726     0.0132394    -0.055811    -0.0573053   -0.0945146  -0.244125
  0.0859962   -0.227951    -0.0692381    0.131577     -0.16459      0.148538     0.139388     -0.0216403    0.270138      0.102895    -0.158256     -0.0171852    0.0534997     0.00710274    0.0408926    0.0156401    -0.238388     0.0959049   0.0306996   -0.14171     0.0309479    0.157189     -0.0828501   -0.0157609    0.170496   -0.19567
 -0.233766     0.0786809    0.043756    -0.00794949    0.0711993    4.12153e-5   0.000910143   0.017557    -0.0190969    -0.0880491   -0.00440344   -0.0313291   -0.120717     -0.0879823     0.148491    -0.0595135    -0.148751     0.189603    0.0088435    0.214128   -0.0820864    0.105877     -0.118553    -0.11339     -0.222674   -0.00268477
 -0.0488715   -0.0878479    0.0873717    0.127683      0.0673997   -0.154996    -0.0782362     0.0809888    0.0555483     0.107209     0.0301645     0.0186484   -0.135555      0.0560809     0.137239    -0.192677      0.00338076   0.0964135  -0.0937592   -0.143945    0.0645552    0.130027      0.193659    -0.0699358   -0.0224205  -0.035188
 -0.0745172   -0.121943     0.0704609   -0.0418153     0.0794263   -0.173022    -0.115651     -0.0519429    0.0555469     0.172831     0.041587     -0.163973    -0.00852732   -0.0331453    -0.139587     0.051162     -0.128665    -0.0109626  -0.0629684    0.0569056  -0.142779     0.010513     -0.0174694   -0.0182381    0.0677374  -0.00963971
 -0.0788782    0.0286504   -0.0449108    0.000641093  -0.0166027    0.0367605   -0.0395209     0.341485    -0.0558828     0.062526     0.0711647    -0.0574103   -0.0586858    -0.180071     -0.043473    -0.156692     -0.0346276   -0.005859    0.163285     0.0836708   0.03238     -0.093803     -0.0230767   -0.0156745    0.10215    -0.104557
 -0.197704     0.0949971   -0.106627    -0.0665932    -0.0251791    0.0215871   -0.0723702    -0.12963     -0.00388921   -0.216457     0.121425     -0.00972929  -0.0460085    -0.210566     -0.106302     0.120536      0.223315     0.0746254  -0.108929    -0.0284093  -0.0161948   -0.0622779    -0.032982    -0.0622935   -0.126811    0.0481756
 -0.0350679    0.00728778   0.0770985    0.103849     -0.14038      0.0791152   -0.0359332     0.0959969    0.182043     -0.0207618   -0.000473642  -0.117936     0.0705616    -0.0574079    -0.123719    -0.0982391    -0.16025      0.0542457   0.157483    -0.141338    0.0964719   -0.047324      0.0743781   -0.060482     0.0439867   0.0683673
 -0.0295866    0.0457936    0.0421318   -0.00256161    0.0126989   -0.100826    -0.0301063     0.0835506   -0.0914953    -0.0525642   -0.00902155    0.0455418    0.0577374    -0.0342283    -0.261412     0.05568       0.123427     0.135576   -0.00127788  -0.0334241   0.0512389   -0.177241     -0.0891298    0.0972456   -0.0481935  -0.140574
  0.00988966   0.028059     0.170935    -0.190692      0.0176043    0.11314     -0.179537     -0.066835    -0.108151      0.0567437    0.0259314     0.049926    -0.076749     -0.0287253    -0.0256699    0.0384185    -0.0980338    0.0204212   0.118413     0.0350142   0.0241763   -0.130685     -0.0908368    0.0733791    0.191933    0.142537
 -0.0753224    0.0272713    0.047753     0.23152       0.105089     0.150562    -0.0347659    -0.0227387    0.0632402    -0.0497113   -0.0691841    -0.00168813   0.0216112     0.00789775   -0.212048     0.00953058    0.101026    -0.221002   -0.0938557   -0.165089    0.0356999   -0.0103974     0.0876409    0.00449272   0.0658902  -0.024127
 -0.119293     0.010565    -0.147179     0.00584096   -0.10395      0.272138     0.156468     -0.0914864    0.0801889     0.0204492    0.0696859    -0.129569     0.16493      -0.0248633     0.157008     0.12195      -0.0901652   -0.0620195  -0.0874312    0.135159    0.0297218    0.076554     -0.00318994  -0.0706642    0.0697692   0.00501967
  0.0101102    0.0866409    0.0289102   -0.0616109    -0.0221627   -0.0802278   -0.0577899     0.0596417    0.0252048     0.0676098   -0.246409      0.183824    -0.051017     -0.206676      0.0734945    0.0756694     0.060227     0.0960317   0.0876642    0.0396529  -0.0869468    0.0171885     0.129572     0.10154      0.100319   -0.0294638
 -0.00623503   0.0349925    0.12886     -0.0565053     0.00840009  -0.0551778   -0.0794429     0.0379217    0.208072      0.0743982    0.0176665    -0.0420864   -0.0445466    -0.26939       0.0608495    0.0274381    -0.0739751    0.0621437   0.0704201    0.180532   -0.0308212    0.146064      0.0646661   -0.00890172   0.119117    0.0416022
 -0.114453    -0.0399311    0.0217319   -0.133823     -0.0247146    0.0550629   -0.000513093  -0.0447285   -0.0563303    -0.152767    -0.00545469   -0.116416    -0.0883136     0.0748175     0.0686187    0.113631     -0.0344114    0.0164318  -0.0415789    0.109744   -0.00537208  -0.023789      0.108822     0.145969    -0.041588    0.105541
 -0.0940401    0.065018    -0.263072     0.220634      0.0107741   -0.107159    -0.187512      0.0211358    0.0133037     0.121191    -0.0165086     0.0718584   -0.176792     -0.0554065    -0.0797958    0.0214738    -0.118752     0.0747527   0.0160338   -0.0569191   0.166857     0.146783     -0.0866842   -0.0112951    0.0559378  -0.124083
 -0.116312     0.0113755   -0.023729    -0.109246     -0.0458447   -0.0428453   -0.00221194   -0.104557    -0.0946464    -0.0307247   -0.0096672     0.0649516   -0.191769     -0.0689883    -0.00785212   0.0307469    -0.012233     0.282959   -0.0553955    0.106098   -0.0951045   -0.177882     -0.0445043   -0.0426874   -0.0396162   0.0962572
 -0.0878561    0.119252    -0.103928    -0.252906      0.0810087   -0.115998    -0.0328929     0.21824      0.06242       0.106524    -0.0336215     0.127974    -0.0394488     0.101841      0.185518     0.0446684     0.00951924  -0.129395   -0.0587348    0.106644   -0.143256     0.0775079    -0.0658097    0.0736926   -0.0395736   0.0327613
  0.0215564   -0.0652084    0.0491107    0.100386     -0.0932061    0.0771487   -0.040685      0.120445    -0.0882273    -0.0800037   -0.0724329     0.112537    -0.000609305  -0.000923172   0.182974    -0.11938       0.0144813   -0.0986499   0.00410375   0.0717371  -0.0904218   -0.000350663  -0.0607253    0.0513535   -0.0479311   0.0788088
  0.11201      0.0817866   -0.0178486   -0.0506004     0.107377     0.0428983    0.208087      0.0779851    0.0660787     0.0885253   -0.023182     -0.219179    -0.205976     -0.0572667    -0.0833317    0.0706208    -0.0238983   -0.0620498   0.0454431    0.0345453  -0.0692418   -0.0394992    -0.0216154    0.0849686   -0.0671393   0.0552822
  0.0848281   -0.19182      0.0622442    0.0749766    -0.0313861    0.03436     -0.0962821     0.0302307   -0.0847399     0.0319561   -0.00325942    0.0109618   -0.0590991    -0.0722743    -0.0483278    0.170019      0.114089     0.094124   -0.0411296   -0.0262452   0.0287285    0.0413059     0.180555     0.0316053   -0.0459007  -0.137083
  0.181634    -0.0504274    0.0354167    0.0978007    -0.0729911   -0.133848     0.103796     -0.100217    -0.0525866    -0.131676    -0.238406      0.0678763   -0.108969      0.0649924    -0.0163117    0.0825292    -0.0547621   -0.0607523  -0.0557516    0.0423355  -0.00809849   0.0390582    -0.0121598   -0.0926641    0.0525741   0.0902401
  0.082289    -0.159688     0.0476033   -0.0362469    -0.0892651   -0.0573151    0.140698      0.0426984    0.0366882    -0.0373485   -0.0103595    -0.0534314   -0.183306     -0.0406131    -0.00577225  -0.0268147    -0.0285455   -0.131335   -0.00871197  -0.079505    0.0964681   -0.0697226    -0.115441    -0.070986     0.0102704   0.0942532
  0.0298258    0.0942145    0.00291421   0.0279171    -0.0802341   -0.0046492   -0.123203     -0.0141898   -0.0757755    -0.089447    -0.00565073   -0.220879    -0.0819398    -0.0353981    -0.0535511   -0.000734211   0.0988337   -0.196345    0.0097685    0.156212    0.137986    -0.0228947    -0.100615     0.00851988  -0.0416765   0.130801
 -0.0699095   -0.0109558    0.0476235    0.0587695    -0.264175    -0.084312    -0.22249      -0.112882    -0.158873      0.102133     0.0869015    -0.0654061   -0.00273925   -0.0845665    -0.0816389    0.0451384    -0.0242622    0.0817689   0.0267608    0.151468   -0.0335942   -0.160764      0.0565096   -0.00981352   0.0684867   0.0960102
  0.0972741    0.212883     0.208493    -0.0509379     0.0969192   -0.0195008    0.138504     -0.0482739   -0.0572066    -0.0114748    0.110656     -0.160137     0.0762496     0.000216367   0.0681069   -0.0881963    -0.167472     0.0523128   0.0981745    0.0654402   0.0263125   -0.0178687    -0.00313637  -0.0385893   -0.0550972   0.286728
 -0.103371     0.127087     0.223643     0.17659      -0.00532966  -0.117861    -0.026584     -0.0881052    0.103952     -0.25189     -0.0877421    -0.157679     0.174884     -0.167        -0.0237747    0.139649      0.169968    -0.0325676  -0.132461     0.0963972  -0.0586176   -0.192305     -0.0644187   -0.0541492   -0.0691577   0.0826061kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.419589414586705
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419609
[ Info: iteration 2, average log likelihood -1.419566
[ Info: iteration 3, average log likelihood -1.419545
[ Info: iteration 4, average log likelihood -1.419523
[ Info: iteration 5, average log likelihood -1.419498
[ Info: iteration 6, average log likelihood -1.419468
[ Info: iteration 7, average log likelihood -1.419433
[ Info: iteration 8, average log likelihood -1.419392
[ Info: iteration 9, average log likelihood -1.419342
[ Info: iteration 10, average log likelihood -1.419277
[ Info: iteration 11, average log likelihood -1.419178
[ Info: iteration 12, average log likelihood -1.418998
[ Info: iteration 13, average log likelihood -1.418633
[ Info: iteration 14, average log likelihood -1.417923
[ Info: iteration 15, average log likelihood -1.416811
[ Info: iteration 16, average log likelihood -1.415615
[ Info: iteration 17, average log likelihood -1.414792
[ Info: iteration 18, average log likelihood -1.414401
[ Info: iteration 19, average log likelihood -1.414247
[ Info: iteration 20, average log likelihood -1.414188
[ Info: iteration 21, average log likelihood -1.414166
[ Info: iteration 22, average log likelihood -1.414157
[ Info: iteration 23, average log likelihood -1.414153
[ Info: iteration 24, average log likelihood -1.414151
[ Info: iteration 25, average log likelihood -1.414150
[ Info: iteration 26, average log likelihood -1.414150
[ Info: iteration 27, average log likelihood -1.414150
[ Info: iteration 28, average log likelihood -1.414149
[ Info: iteration 29, average log likelihood -1.414149
[ Info: iteration 30, average log likelihood -1.414149
[ Info: iteration 31, average log likelihood -1.414149
[ Info: iteration 32, average log likelihood -1.414149
[ Info: iteration 33, average log likelihood -1.414148
[ Info: iteration 34, average log likelihood -1.414148
[ Info: iteration 35, average log likelihood -1.414148
[ Info: iteration 36, average log likelihood -1.414148
[ Info: iteration 37, average log likelihood -1.414148
[ Info: iteration 38, average log likelihood -1.414148
[ Info: iteration 39, average log likelihood -1.414148
[ Info: iteration 40, average log likelihood -1.414148
[ Info: iteration 41, average log likelihood -1.414148
[ Info: iteration 42, average log likelihood -1.414148
[ Info: iteration 43, average log likelihood -1.414148
[ Info: iteration 44, average log likelihood -1.414148
[ Info: iteration 45, average log likelihood -1.414148
[ Info: iteration 46, average log likelihood -1.414148
[ Info: iteration 47, average log likelihood -1.414147
[ Info: iteration 48, average log likelihood -1.414147
[ Info: iteration 49, average log likelihood -1.414147
[ Info: iteration 50, average log likelihood -1.414147
┌ Info: EM with 100000 data points 50 iterations avll -1.414147
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4196085572542545
│     -1.419566247739983
│      ⋮
└     -1.41414742587269
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414163
[ Info: iteration 2, average log likelihood -1.414119
[ Info: iteration 3, average log likelihood -1.414089
[ Info: iteration 4, average log likelihood -1.414056
[ Info: iteration 5, average log likelihood -1.414015
[ Info: iteration 6, average log likelihood -1.413964
[ Info: iteration 7, average log likelihood -1.413899
[ Info: iteration 8, average log likelihood -1.413822
[ Info: iteration 9, average log likelihood -1.413733
[ Info: iteration 10, average log likelihood -1.413638
[ Info: iteration 11, average log likelihood -1.413542
[ Info: iteration 12, average log likelihood -1.413454
[ Info: iteration 13, average log likelihood -1.413377
[ Info: iteration 14, average log likelihood -1.413313
[ Info: iteration 15, average log likelihood -1.413261
[ Info: iteration 16, average log likelihood -1.413219
[ Info: iteration 17, average log likelihood -1.413184
[ Info: iteration 18, average log likelihood -1.413154
[ Info: iteration 19, average log likelihood -1.413129
[ Info: iteration 20, average log likelihood -1.413108
[ Info: iteration 21, average log likelihood -1.413088
[ Info: iteration 22, average log likelihood -1.413071
[ Info: iteration 23, average log likelihood -1.413055
[ Info: iteration 24, average log likelihood -1.413041
[ Info: iteration 25, average log likelihood -1.413028
[ Info: iteration 26, average log likelihood -1.413016
[ Info: iteration 27, average log likelihood -1.413004
[ Info: iteration 28, average log likelihood -1.412994
[ Info: iteration 29, average log likelihood -1.412985
[ Info: iteration 30, average log likelihood -1.412976
[ Info: iteration 31, average log likelihood -1.412968
[ Info: iteration 32, average log likelihood -1.412961
[ Info: iteration 33, average log likelihood -1.412955
[ Info: iteration 34, average log likelihood -1.412949
[ Info: iteration 35, average log likelihood -1.412944
[ Info: iteration 36, average log likelihood -1.412940
[ Info: iteration 37, average log likelihood -1.412936
[ Info: iteration 38, average log likelihood -1.412933
[ Info: iteration 39, average log likelihood -1.412930
[ Info: iteration 40, average log likelihood -1.412927
[ Info: iteration 41, average log likelihood -1.412925
[ Info: iteration 42, average log likelihood -1.412923
[ Info: iteration 43, average log likelihood -1.412921
[ Info: iteration 44, average log likelihood -1.412919
[ Info: iteration 45, average log likelihood -1.412918
[ Info: iteration 46, average log likelihood -1.412917
[ Info: iteration 47, average log likelihood -1.412916
[ Info: iteration 48, average log likelihood -1.412915
[ Info: iteration 49, average log likelihood -1.412914
[ Info: iteration 50, average log likelihood -1.412913
┌ Info: EM with 100000 data points 50 iterations avll -1.412913
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4141626606202584
│     -1.414118548015298
│      ⋮
└     -1.4129133944638201
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412926
[ Info: iteration 2, average log likelihood -1.412885
[ Info: iteration 3, average log likelihood -1.412856
[ Info: iteration 4, average log likelihood -1.412825
[ Info: iteration 5, average log likelihood -1.412788
[ Info: iteration 6, average log likelihood -1.412743
[ Info: iteration 7, average log likelihood -1.412690
[ Info: iteration 8, average log likelihood -1.412627
[ Info: iteration 9, average log likelihood -1.412555
[ Info: iteration 10, average log likelihood -1.412477
[ Info: iteration 11, average log likelihood -1.412392
[ Info: iteration 12, average log likelihood -1.412304
[ Info: iteration 13, average log likelihood -1.412214
[ Info: iteration 14, average log likelihood -1.412125
[ Info: iteration 15, average log likelihood -1.412040
[ Info: iteration 16, average log likelihood -1.411962
[ Info: iteration 17, average log likelihood -1.411893
[ Info: iteration 18, average log likelihood -1.411832
[ Info: iteration 19, average log likelihood -1.411780
[ Info: iteration 20, average log likelihood -1.411736
[ Info: iteration 21, average log likelihood -1.411696
[ Info: iteration 22, average log likelihood -1.411661
[ Info: iteration 23, average log likelihood -1.411630
[ Info: iteration 24, average log likelihood -1.411602
[ Info: iteration 25, average log likelihood -1.411576
[ Info: iteration 26, average log likelihood -1.411552
[ Info: iteration 27, average log likelihood -1.411530
[ Info: iteration 28, average log likelihood -1.411510
[ Info: iteration 29, average log likelihood -1.411492
[ Info: iteration 30, average log likelihood -1.411475
[ Info: iteration 31, average log likelihood -1.411459
[ Info: iteration 32, average log likelihood -1.411445
[ Info: iteration 33, average log likelihood -1.411432
[ Info: iteration 34, average log likelihood -1.411419
[ Info: iteration 35, average log likelihood -1.411408
[ Info: iteration 36, average log likelihood -1.411398
[ Info: iteration 37, average log likelihood -1.411388
[ Info: iteration 38, average log likelihood -1.411379
[ Info: iteration 39, average log likelihood -1.411370
[ Info: iteration 40, average log likelihood -1.411362
[ Info: iteration 41, average log likelihood -1.411355
[ Info: iteration 42, average log likelihood -1.411348
[ Info: iteration 43, average log likelihood -1.411341
[ Info: iteration 44, average log likelihood -1.411335
[ Info: iteration 45, average log likelihood -1.411329
[ Info: iteration 46, average log likelihood -1.411324
[ Info: iteration 47, average log likelihood -1.411319
[ Info: iteration 48, average log likelihood -1.411314
[ Info: iteration 49, average log likelihood -1.411310
[ Info: iteration 50, average log likelihood -1.411305
┌ Info: EM with 100000 data points 50 iterations avll -1.411305
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4129262318593154
│     -1.41288458151215
│      ⋮
└     -1.411305224498288
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411313
[ Info: iteration 2, average log likelihood -1.411259
[ Info: iteration 3, average log likelihood -1.411216
[ Info: iteration 4, average log likelihood -1.411167
[ Info: iteration 5, average log likelihood -1.411109
[ Info: iteration 6, average log likelihood -1.411039
[ Info: iteration 7, average log likelihood -1.410955
[ Info: iteration 8, average log likelihood -1.410858
[ Info: iteration 9, average log likelihood -1.410751
[ Info: iteration 10, average log likelihood -1.410638
[ Info: iteration 11, average log likelihood -1.410525
[ Info: iteration 12, average log likelihood -1.410414
[ Info: iteration 13, average log likelihood -1.410311
[ Info: iteration 14, average log likelihood -1.410216
[ Info: iteration 15, average log likelihood -1.410130
[ Info: iteration 16, average log likelihood -1.410053
[ Info: iteration 17, average log likelihood -1.409985
[ Info: iteration 18, average log likelihood -1.409925
[ Info: iteration 19, average log likelihood -1.409871
[ Info: iteration 20, average log likelihood -1.409824
[ Info: iteration 21, average log likelihood -1.409781
[ Info: iteration 22, average log likelihood -1.409742
[ Info: iteration 23, average log likelihood -1.409707
[ Info: iteration 24, average log likelihood -1.409675
[ Info: iteration 25, average log likelihood -1.409646
[ Info: iteration 26, average log likelihood -1.409618
[ Info: iteration 27, average log likelihood -1.409593
[ Info: iteration 28, average log likelihood -1.409569
[ Info: iteration 29, average log likelihood -1.409546
[ Info: iteration 30, average log likelihood -1.409525
[ Info: iteration 31, average log likelihood -1.409505
[ Info: iteration 32, average log likelihood -1.409485
[ Info: iteration 33, average log likelihood -1.409467
[ Info: iteration 34, average log likelihood -1.409449
[ Info: iteration 35, average log likelihood -1.409433
[ Info: iteration 36, average log likelihood -1.409417
[ Info: iteration 37, average log likelihood -1.409402
[ Info: iteration 38, average log likelihood -1.409388
[ Info: iteration 39, average log likelihood -1.409374
[ Info: iteration 40, average log likelihood -1.409361
[ Info: iteration 41, average log likelihood -1.409349
[ Info: iteration 42, average log likelihood -1.409338
[ Info: iteration 43, average log likelihood -1.409327
[ Info: iteration 44, average log likelihood -1.409316
[ Info: iteration 45, average log likelihood -1.409306
[ Info: iteration 46, average log likelihood -1.409296
[ Info: iteration 47, average log likelihood -1.409287
[ Info: iteration 48, average log likelihood -1.409278
[ Info: iteration 49, average log likelihood -1.409269
[ Info: iteration 50, average log likelihood -1.409261
┌ Info: EM with 100000 data points 50 iterations avll -1.409261
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4113132260991323
│     -1.4112594745415747
│      ⋮
└     -1.40926112431901
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409262
[ Info: iteration 2, average log likelihood -1.409193
[ Info: iteration 3, average log likelihood -1.409126
[ Info: iteration 4, average log likelihood -1.409048
[ Info: iteration 5, average log likelihood -1.408949
[ Info: iteration 6, average log likelihood -1.408828
[ Info: iteration 7, average log likelihood -1.408687
[ Info: iteration 8, average log likelihood -1.408532
[ Info: iteration 9, average log likelihood -1.408373
[ Info: iteration 10, average log likelihood -1.408216
[ Info: iteration 11, average log likelihood -1.408068
[ Info: iteration 12, average log likelihood -1.407932
[ Info: iteration 13, average log likelihood -1.407808
[ Info: iteration 14, average log likelihood -1.407698
[ Info: iteration 15, average log likelihood -1.407600
[ Info: iteration 16, average log likelihood -1.407514
[ Info: iteration 17, average log likelihood -1.407439
[ Info: iteration 18, average log likelihood -1.407372
[ Info: iteration 19, average log likelihood -1.407314
[ Info: iteration 20, average log likelihood -1.407263
[ Info: iteration 21, average log likelihood -1.407217
[ Info: iteration 22, average log likelihood -1.407177
[ Info: iteration 23, average log likelihood -1.407140
[ Info: iteration 24, average log likelihood -1.407106
[ Info: iteration 25, average log likelihood -1.407075
[ Info: iteration 26, average log likelihood -1.407047
[ Info: iteration 27, average log likelihood -1.407019
[ Info: iteration 28, average log likelihood -1.406993
[ Info: iteration 29, average log likelihood -1.406969
[ Info: iteration 30, average log likelihood -1.406944
[ Info: iteration 31, average log likelihood -1.406921
[ Info: iteration 32, average log likelihood -1.406899
[ Info: iteration 33, average log likelihood -1.406876
[ Info: iteration 34, average log likelihood -1.406855
[ Info: iteration 35, average log likelihood -1.406834
[ Info: iteration 36, average log likelihood -1.406813
[ Info: iteration 37, average log likelihood -1.406793
[ Info: iteration 38, average log likelihood -1.406773
[ Info: iteration 39, average log likelihood -1.406753
[ Info: iteration 40, average log likelihood -1.406734
[ Info: iteration 41, average log likelihood -1.406715
[ Info: iteration 42, average log likelihood -1.406697
[ Info: iteration 43, average log likelihood -1.406679
[ Info: iteration 44, average log likelihood -1.406662
[ Info: iteration 45, average log likelihood -1.406645
[ Info: iteration 46, average log likelihood -1.406628
[ Info: iteration 47, average log likelihood -1.406612
[ Info: iteration 48, average log likelihood -1.406596
[ Info: iteration 49, average log likelihood -1.406581
[ Info: iteration 50, average log likelihood -1.406566
┌ Info: EM with 100000 data points 50 iterations avll -1.406566
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4092616021708546
│     -1.4091926671527408
│      ⋮
└     -1.4065658407893662
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.419589414586705
│     -1.4196085572542545
│     -1.419566247739983
│     -1.4195446641287066
│      ⋮
│     -1.4065961544289831
│     -1.4065807943528683
└     -1.4065658407893662
32×26 Array{Float64,2}:
 -0.0292154    0.510236   -0.286353   -0.232696   -0.0999255   0.256329    -0.0545025   -0.168437   -0.185046      0.839796    -0.135426     0.182416    -0.209696   -0.251987   -0.274388    -0.28415     -0.432304   -0.521458   -0.265491    0.442144    -0.181468    -0.164495    0.0254684   -0.109539      0.323147     0.654199
 -0.317843     0.285284    0.188841   -0.10444     0.0892303   0.31685     -0.18829     -0.225313   -0.313054      0.00241919  -0.369574     0.325914     0.252567   -0.268095   -0.414795     0.0475522   -0.678326    0.72311     0.0917304   0.561129    -0.133217     0.11757    -0.0736808    0.571192     -0.03599      0.0226572
 -0.0117129   -0.460175    0.0235424  -0.23277    -0.497432   -0.00972155  -0.473925    -0.482311   -0.31794       0.180459    -0.178051    -0.184535     0.162371   -0.503143    0.652594    -0.0454422    0.55673     0.2214     -0.33231     0.120582     0.0280803   -0.214955   -0.174043    -0.203642      0.0851068    0.0264383
  0.124277     0.298544   -0.32223    -0.262507   -0.510373    0.69372      0.253974    -0.247708   -0.158624      0.0783539   -0.10044     -0.213073    -0.125424   -0.549979   -0.210257     0.410662     0.638271    0.171371   -0.617073    0.0455656   -0.113353    -0.530309    0.0300613    0.0290231    -0.348222    -0.288136
  0.087752    -0.176102   -0.10265     0.0220543  -0.0803166  -0.172002     0.0620752   -0.301425   -0.000880391  -0.00507956  -0.129483     0.00560226  -0.232026   -0.109475    0.0986486   -0.0342241    0.0469685   0.0368138   0.171075    0.0462318    0.184805    -0.0208605  -0.0937583    0.00857037    0.190539     0.0851362
 -0.102166     0.0378604   0.0538711   0.0478745   0.0569813   0.0633807   -0.10188      0.199649    0.0705002     0.0405813   -0.169523    -0.237045     0.188257    0.100272   -0.0949427    0.0916247   -0.0906796   0.0459131  -0.311649   -0.216766    -0.0611313    0.118389   -0.149832     0.000900143   0.0986826   -0.120836
 -0.0560862   -0.191435    0.340961    0.327813    0.669109   -0.560195    -0.327416     0.179163   -0.108353     -0.254848     0.00940971  -0.058627     0.194626    0.289788   -0.0173864   -0.435433    -0.594315   -0.156416    0.681341   -0.162548     0.189787     0.429594    0.112179    -0.0518454     0.348012     0.248285
 -0.180951    -0.0422401   0.568082    0.163619    0.174981    0.074306     0.00448325   0.0938285  -0.571148     -0.10811      0.0015781    0.432629     0.808026   -0.0702395   0.062931     0.232779     0.547439    0.0870171   0.209168   -0.405942     0.253396     0.403982    0.126072     0.33269       0.0430173    0.200903
  0.109161    -0.375001    0.0649112  -0.717486    0.114148   -0.477393    -0.0248487   -0.540361   -0.681752     -0.0854288   -0.272323     0.00646454  -0.521463   -0.0318339  -0.145374     0.268968    -0.276224    0.128215   -0.557931    0.3065       0.220032     0.347242    0.398819    -1.17084      -0.179978    -0.248189
 -0.606485    -0.784564   -0.25969    -0.488777    0.0879134  -0.373482     0.224857    -0.0959141  -0.113533     -0.00873758  -0.418452    -0.785926    -0.190143   -0.0439903  -0.1923      -0.0970779   -0.10091    -0.0300956  -0.0942547   0.293835     0.278816    -0.0817134  -0.238084     0.269763      0.0895337   -0.704377
  0.0919848   -0.0973133   0.266892   -0.543657    0.411986    0.0965745   -0.341885     0.44152     0.603829     -0.525432     0.218951     0.104381    -0.16573     0.165328   -0.390066    -0.506698    -0.351823   -0.116725   -0.265412    0.279887    -0.544921     0.0723522  -0.548267    -0.142268     -0.0976087    0.0842482
 -0.129665     0.07383    -0.0255301  -0.0855015  -0.120114   -0.0559912    0.0805989    0.101573    0.210561     -0.231812     0.0341451   -0.197918    -0.164139    0.677721    0.00657981  -0.63376     -0.128104   -0.186224    0.0315959   0.186727    -0.411792    -0.603357    0.529953    -0.377491      0.0273762    0.210136
 -0.00344175  -0.666903    0.340007    0.195955   -0.0431877  -0.722985    -0.017958     0.138958    0.447022     -0.503043     0.131792     0.454366    -0.071252   -0.134409    0.0777161    0.325435     0.484866    0.1541      0.521871    0.20971     -0.199537    -0.12424     0.0881857   -0.00371112   -0.385692     0.145247
  0.122417     0.538384    0.231924    0.276598   -0.173462    0.0531219   -0.327946     0.214809   -0.0327899    -0.0727592    0.25047      0.353224    -0.207884   -0.165525    0.262965     0.266518    -0.0715937   0.0422938   0.139591    0.264915    -0.497218     0.023327    0.196072    -0.054462     -0.427723    -0.0100605
 -0.0426361   -0.0533513  -0.425576   -0.338806    0.180538    0.163719    -0.0517522    0.232051    0.120547     -0.0978667    0.550931    -0.279311    -0.199366   -0.387685   -0.117091    -0.0615968    0.289522   -0.052674    0.126667    0.251215     0.430623    -0.104171    0.259615    -0.0328236    -0.273585    -0.17059
  0.250234     0.323381   -0.0978701   0.156682    0.566243    0.0298366    0.742675     0.214571    0.0122753     0.0124744    0.0814544   -0.136236    -0.509813   -0.0655006  -0.0866877    0.128769     0.0873754  -0.219728    0.801059    0.0325706    0.0631865    0.184948    0.172836     0.110177     -0.36136     -0.319492
 -0.619177    -0.307031    0.401982   -0.0131237   0.148481   -0.596175    -0.831169    -0.218566   -0.0803931     0.455066    -0.427367     0.573536    -0.258191    0.251973    0.30997     -0.461683    -0.225117    0.205357   -0.101476    0.358075    -0.898425     0.132512   -0.0134519   -0.241491      0.561679     0.207391
 -0.243719    -0.167334    0.169633    0.309925    0.363182   -0.606068    -0.0403125    0.218677    0.370243     -0.333396     0.0280187   -0.0576008   -0.283722    0.302374   -0.0416109   -0.0485357   -0.434396   -0.216102    0.533349    0.134214    -0.310395    -0.0541532   0.0672951   -0.0359336    -0.0847395   -0.0506678
 -0.292664    -0.770365    0.711703   -0.17552     0.554321    0.640299     0.245356    -0.227199   -0.389267     -0.636937     0.292405    -0.171159    -0.0340912  -0.818118    0.287857    -0.340263     0.263702    0.2266      0.69002     0.724147    -0.433015     0.274831    0.537281    -0.0471715    -0.0894327    0.31465
 -0.127611     0.678899    0.0200688  -0.251235    0.0473955   0.581031    -0.140262     0.214165   -0.442534     -0.118947     0.156444     0.337827    -0.193117    0.181173   -0.225961    -0.00297479  -0.362063    0.137739    0.171361    0.657924    -0.637622    -0.363399    0.455395     0.16377      -0.654565    -0.0100276
  0.10856      0.217379   -0.163217    0.539607   -0.0410866   0.370764    -0.369424    -0.319596   -0.040502      0.38507     -0.415475    -0.0544054    0.297577   -0.341245    0.00656903  -0.0915438   -0.218425    0.261789   -0.550626   -0.589453     0.00206061   0.408124   -0.787661     0.103163      0.533084     0.240162
  0.304262     0.401107    0.447935    0.0461215   0.264229    0.235639     0.0849578    0.715665   -0.120857      0.702542    -0.191784    -0.213434     0.155702    0.0714713   0.0798249    0.258692    -0.364572   -0.0346557  -0.681034   -0.615963    -0.518489     0.639498   -0.186855    -0.0151935     0.0389006   -0.242915
  0.18829      0.682927    0.390324    0.478206   -0.512709   -0.13187      0.145856    -0.0581537   0.534955     -0.0101032   -0.256079     0.154893    -0.135248    0.331058   -0.186483     0.628429    -0.660255   -0.525759   -0.124594   -0.12043     -0.169315    -0.0426767  -0.324222     0.212471      0.290109     0.677843
 -0.0642051    0.0966812   0.062833    0.344369   -0.522572    0.216394     0.493326     0.337508    0.388965     -0.034219    -0.16081      0.182106     0.400261    0.862095   -0.1522       0.354021    -0.354431    0.492327   -0.661482   -0.502818     0.305215    -0.21047    -0.0897237    0.0909164     0.226167     0.0897032
  0.43693      0.671378   -0.8189      0.120358   -0.302717   -0.679089    -0.174921     0.235599    0.805968      0.385068    -0.284964     0.109921    -0.692608    0.167691    0.0390066    0.275824    -0.0810106   0.202056   -0.472729   -0.00420355   0.0854805   -0.194074   -1.15402     -0.301588     -0.894778    -0.835156
  0.0920444    0.0932849  -0.351259    0.100836   -0.432011    0.400245    -0.332216    -0.0213469   0.816952     -0.184823     0.848691    -0.190418    -0.2064     -0.212961    0.61973     -0.0531923    0.447061   -0.0117296  -0.175772   -0.0812479   -0.168628    -0.463093   -0.301826    -0.112446     -0.173429     0.444969
  0.306538    -0.143865   -0.1563      0.0577382  -0.0647834  -0.311451     0.0773489    0.028627    0.491671     -0.161417     0.0664085   -0.767859     0.169366   -0.0373709   0.159611    -0.139336     0.603881   -1.05367    -0.192082   -0.675658     0.405091    -0.39275    -0.00955301  -0.541184     -0.00274896  -0.189965
 -0.151709    -0.711867    0.0792842   0.155584    0.214764   -0.00626005  -0.0293786    0.384472   -0.534834     -0.877463    -0.151534    -0.470853     0.476995    0.248145    0.691625    -0.321502     0.593081    0.746648    0.262298   -0.405754     0.0698554   -0.249888    0.140831    -0.177176     -0.179822    -0.78046
 -0.119844     0.0300845  -0.417156   -0.271198    0.420642    0.430309     0.12335     -0.129678    0.0209536     0.0769784    0.184169    -0.23656      0.075463    0.0836054  -0.934578    -0.700319    -0.203304    0.117714    0.12291    -0.102235     0.742232     0.678576   -0.00282794   0.11161       0.525178     0.0967453
  0.152045    -0.113233   -0.218755   -0.219751   -0.25532     0.0192239    0.140876    -0.350248   -0.0886282     0.042252    -0.0317557    0.0967467    0.0867632  -0.452662    0.0555298    0.130026     0.52523     0.193466   -0.071074    0.0986683    0.67741      0.136348   -0.0337435    0.108145      0.11861      0.105179
  0.113248     0.044574   -0.0809297   0.535634   -0.437652   -0.772956    -0.0115677   -0.303856   -0.250432     -0.271803    -0.356581     0.00478047  -0.115414   -0.433944    0.123422     0.724595    -0.285713   -0.291583    0.236024    0.114313     0.378861     0.166665    0.482037     0.451646      0.269227    -1.05531
 -0.0375614   -0.29961    -0.342749    0.56572    -0.433675   -0.210613     0.162069    -0.132447   -0.335737      0.680721     0.373862    -0.289951    -0.167861   -0.432543    0.209584     0.621241     0.0262406   0.222119    0.158979   -0.00665933   0.811121     0.0213249   0.210821     0.471042      0.169574     0.489985[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406551
[ Info: iteration 2, average log likelihood -1.406537
[ Info: iteration 3, average log likelihood -1.406523
[ Info: iteration 4, average log likelihood -1.406510
[ Info: iteration 5, average log likelihood -1.406497
[ Info: iteration 6, average log likelihood -1.406484
[ Info: iteration 7, average log likelihood -1.406472
[ Info: iteration 8, average log likelihood -1.406460
[ Info: iteration 9, average log likelihood -1.406448
[ Info: iteration 10, average log likelihood -1.406436
┌ Info: EM with 100000 data points 10 iterations avll -1.406436
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind full, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.367556e+05
      1       7.028675e+05      -2.338881e+05 |       32
      2       6.869831e+05      -1.588440e+04 |       32
      3       6.813312e+05      -5.651952e+03 |       32
      4       6.786101e+05      -2.721122e+03 |       32
      5       6.769633e+05      -1.646817e+03 |       32
      6       6.757514e+05      -1.211868e+03 |       32
      7       6.748265e+05      -9.248979e+02 |       32
      8       6.740728e+05      -7.537249e+02 |       32
      9       6.734772e+05      -5.955785e+02 |       32
     10       6.729671e+05      -5.100931e+02 |       32
     11       6.725158e+05      -4.513337e+02 |       32
     12       6.721398e+05      -3.759136e+02 |       32
     13       6.718150e+05      -3.248483e+02 |       32
     14       6.715483e+05      -2.667069e+02 |       32
     15       6.713417e+05      -2.065966e+02 |       32
     16       6.711706e+05      -1.710722e+02 |       32
     17       6.710110e+05      -1.596207e+02 |       32
     18       6.708632e+05      -1.477895e+02 |       32
     19       6.707251e+05      -1.380935e+02 |       32
     20       6.705872e+05      -1.379603e+02 |       32
     21       6.704580e+05      -1.291675e+02 |       32
     22       6.703485e+05      -1.095252e+02 |       32
     23       6.702349e+05      -1.135591e+02 |       32
     24       6.701051e+05      -1.298044e+02 |       32
     25       6.699818e+05      -1.232857e+02 |       32
     26       6.698623e+05      -1.195272e+02 |       32
     27       6.697541e+05      -1.081637e+02 |       32
     28       6.696563e+05      -9.785995e+01 |       32
     29       6.695638e+05      -9.247547e+01 |       32
     30       6.694656e+05      -9.823739e+01 |       32
     31       6.693740e+05      -9.150495e+01 |       32
     32       6.692908e+05      -8.320664e+01 |       32
     33       6.692187e+05      -7.209480e+01 |       32
     34       6.691508e+05      -6.795820e+01 |       32
     35       6.690845e+05      -6.626521e+01 |       32
     36       6.690313e+05      -5.321666e+01 |       32
     37       6.689888e+05      -4.250047e+01 |       32
     38       6.689452e+05      -4.364638e+01 |       32
     39       6.689013e+05      -4.388247e+01 |       32
     40       6.688574e+05      -4.391056e+01 |       32
     41       6.688186e+05      -3.873631e+01 |       32
     42       6.687825e+05      -3.612477e+01 |       32
     43       6.687448e+05      -3.771502e+01 |       32
     44       6.687099e+05      -3.487378e+01 |       32
     45       6.686820e+05      -2.789351e+01 |       32
     46       6.686582e+05      -2.380766e+01 |       32
     47       6.686356e+05      -2.258027e+01 |       32
     48       6.686133e+05      -2.236847e+01 |       32
     49       6.685913e+05      -2.192898e+01 |       31
     50       6.685691e+05      -2.224178e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 668569.0944156987)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417898
[ Info: iteration 2, average log likelihood -1.413082
[ Info: iteration 3, average log likelihood -1.411807
[ Info: iteration 4, average log likelihood -1.410855
[ Info: iteration 5, average log likelihood -1.409793
[ Info: iteration 6, average log likelihood -1.408747
[ Info: iteration 7, average log likelihood -1.408010
[ Info: iteration 8, average log likelihood -1.407615
[ Info: iteration 9, average log likelihood -1.407410
[ Info: iteration 10, average log likelihood -1.407286
[ Info: iteration 11, average log likelihood -1.407198
[ Info: iteration 12, average log likelihood -1.407128
[ Info: iteration 13, average log likelihood -1.407068
[ Info: iteration 14, average log likelihood -1.407016
[ Info: iteration 15, average log likelihood -1.406969
[ Info: iteration 16, average log likelihood -1.406925
[ Info: iteration 17, average log likelihood -1.406885
[ Info: iteration 18, average log likelihood -1.406846
[ Info: iteration 19, average log likelihood -1.406810
[ Info: iteration 20, average log likelihood -1.406776
[ Info: iteration 21, average log likelihood -1.406744
[ Info: iteration 22, average log likelihood -1.406713
[ Info: iteration 23, average log likelihood -1.406684
[ Info: iteration 24, average log likelihood -1.406656
[ Info: iteration 25, average log likelihood -1.406630
[ Info: iteration 26, average log likelihood -1.406606
[ Info: iteration 27, average log likelihood -1.406582
[ Info: iteration 28, average log likelihood -1.406560
[ Info: iteration 29, average log likelihood -1.406540
[ Info: iteration 30, average log likelihood -1.406520
[ Info: iteration 31, average log likelihood -1.406501
[ Info: iteration 32, average log likelihood -1.406484
[ Info: iteration 33, average log likelihood -1.406467
[ Info: iteration 34, average log likelihood -1.406451
[ Info: iteration 35, average log likelihood -1.406436
[ Info: iteration 36, average log likelihood -1.406421
[ Info: iteration 37, average log likelihood -1.406408
[ Info: iteration 38, average log likelihood -1.406394
[ Info: iteration 39, average log likelihood -1.406382
[ Info: iteration 40, average log likelihood -1.406370
[ Info: iteration 41, average log likelihood -1.406358
[ Info: iteration 42, average log likelihood -1.406347
[ Info: iteration 43, average log likelihood -1.406336
[ Info: iteration 44, average log likelihood -1.406325
[ Info: iteration 45, average log likelihood -1.406315
[ Info: iteration 46, average log likelihood -1.406306
[ Info: iteration 47, average log likelihood -1.406296
[ Info: iteration 48, average log likelihood -1.406287
[ Info: iteration 49, average log likelihood -1.406278
[ Info: iteration 50, average log likelihood -1.406270
┌ Info: EM with 100000 data points 50 iterations avll -1.406270
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.354396      0.656059   -0.0670065   0.552652   -0.412623   -0.326736    -0.616406     0.0108914  -0.145922   -0.105671    0.343426    0.688675    0.100526    -0.00590514   0.596717      0.667917    0.180049    0.452787     0.235638     0.187502    -0.479337   -0.210506     0.134018   -0.0477523   -0.610094     0.437563
 -0.108264      0.0137336   0.0446422   0.0359196  -0.0304826  -0.0184311   -0.136972    -0.0343444  -0.0869741   0.102974   -0.243978   -0.0903811  -0.0242837   -0.101846    -0.0055478     0.0627718  -0.166404    0.00456483  -0.133815     0.00955965  -0.118963    0.0788014   -0.127139    0.0448144    0.160834    -0.100355
  0.338675      0.491797    0.143407    0.821835   -0.0920179   0.466255    -0.62825     -0.0296548   0.320768    0.39637     0.0446406   0.107561   -0.0331131   -0.581644    -0.000286984   0.126709   -0.228038   -0.0668111   -0.332902    -0.481578    -0.294071    0.600565    -0.540621    0.257074     0.379971     0.387527
  0.226102     -0.949599   -0.235888    0.10125    -0.30673    -0.219819     0.01376     -0.37159     0.143948    0.0944081   0.125383   -0.728765   -0.243667    -0.507249     0.242209     -0.0149305   0.530465   -0.238538    -0.471705    -0.139667     0.21415    -0.532059    -0.561135   -0.610081     0.395515     0.064028
 -0.16892       0.152956    0.0579621   0.477103    0.459289   -0.465143     0.122642     0.265691    0.211945   -0.46626    -0.419005   -0.629656   -0.108284     0.215853    -0.0510781    -0.252249   -0.429149   -0.291719     0.92771      0.0341542   -0.241346   -0.203372     0.221101   -0.0741132   -0.292347    -0.564926
 -0.0696062     0.0766223   0.184769   -0.152406    0.131705    0.151542    -0.0125       0.139643    0.0655586  -0.115035   -0.0717536   0.179637    0.0406839    0.15866     -0.0945625    -0.123029   -0.187494    0.0794029   -0.0589349    0.0546614   -0.250557    0.0559086    0.0241584  -0.022585    -0.0208748    0.116714
 -0.0656198    -0.172183    0.0825369   0.0796474  -0.473495   -0.435962     0.00233241  -0.0731863   0.626804   -0.250595   -0.441455   -0.200546    0.285192     0.211369    -0.503707      0.458704   -0.226208   -0.0369456   -0.927177    -0.432318     0.167395    0.115733    -0.414324    0.170042     0.0782236   -0.151452
  0.000840865  -0.091447   -0.0960636   0.419165    0.142562    0.0673178    0.449031    -0.13406    -0.877194    0.411489    0.221896   -0.0954226   0.00448132  -0.683996     0.10014       0.313647    0.102701   -0.223534     0.917436    -0.115968     0.429655    0.510918     0.167391    0.418159     0.0735351   -0.170575
 -0.538758      0.309343    0.326814    0.0399564  -0.0106642   0.383838    -0.332029    -0.132005   -0.637641    0.0686987  -0.422733    0.218349    0.310088    -0.205439    -0.400525      0.0561777  -0.668092    0.721276     0.0615771    0.598052    -0.483769   -0.00675115   0.175522    0.590044    -0.0464636   -0.104179
 -0.256111     -0.849447    0.304891    0.114092    0.152627    0.0235535   -0.0684927    0.338881   -0.453801   -0.83007    -0.044982   -0.245718    0.688378     0.184035     0.522413     -0.221019    0.734868    0.560247     0.0699801   -0.430842     0.0090416  -0.077862     0.106732    0.00860669  -0.126532    -0.536767
  0.232523     -0.0914044  -0.356198    0.0344481  -0.132628   -0.00451386  -0.0344874   -0.0320247   0.220596    0.0678334   0.311661   -0.203304   -0.0699557   -0.268953     0.129621      0.135925    0.33192     0.149541    -0.00269944  -0.0520456    0.528364   -0.0973968   -0.0573349  -0.0172497    0.0197349    0.0165201
 -0.348523     -0.534863   -0.307852   -0.661868    0.344758    0.139361     0.105975    -0.157244    0.0534297   0.0566354  -0.299615   -0.794377   -0.173119    -0.252607    -0.4561       -0.460113   -0.148681   -0.0214836   -0.206965     0.181803     0.276898    0.377518    -0.274932    0.16365      0.2604      -0.625443
  0.0871883     0.0593589   0.213765    0.11699     0.259014    0.00711471   0.0836003    0.28367     0.0634599  -0.284265    0.158285    0.186845    0.0302411    0.153109    -0.119782     -0.125283    0.0104537  -0.0929175    0.37386     -0.0309083   -0.231043    0.120589     0.345187   -0.0663936   -0.274659     0.0449123
 -0.478981     -0.220861   -0.0504514  -0.490665    0.244376    0.0970726   -0.0755655    0.530911    0.327263   -0.625633    0.715892    0.167641   -0.38169      0.0957247   -0.612987     -0.0526439  -0.209838    0.0457307    0.357961     0.644649     0.0230591  -0.247607     0.22919     0.419298    -0.318121     0.0153926
  0.126498     -0.704285    0.687771    0.212282   -0.278445   -0.940019    -0.199684     0.0176869   0.250183   -0.283997   -0.16028     0.315979   -0.179165    -0.525116     0.481108      0.443288    0.449504   -0.267118     0.743744     0.233795    -0.193004    0.128454     0.207145    0.188447    -0.00422753  -0.203421
  0.476872      0.124484   -0.407893   -0.168786    0.196939   -0.0173001    0.204431     0.399622    0.84164    -0.170748    0.668009   -0.44856    -0.203033    -0.0118245    0.37865      -0.180115    0.714661   -0.706081     0.171149    -0.64462      0.346489   -0.0581155    0.137212   -0.306361    -0.370318    -0.102796
  0.155162     -0.449545   -0.484648   -0.168463   -0.204229   -0.431779    -0.236242    -0.655111    0.400345   -0.198192    0.0926764   0.466734    0.179511    -0.299168     0.121415     -0.705077    0.204454    0.343432     1.00697      0.66554      0.683088   -0.160491     0.02118     0.246223     0.713344     0.273781
  0.277966      0.274318    0.0412374  -0.414857    0.55355    -0.397763    -0.388341     0.146757   -0.0504449   0.0524418   0.054124    0.372325   -0.736573     0.0684136   -0.360456     -0.241107   -0.156055   -0.213471     0.144488     0.523212    -0.793591    0.202007    -0.318955   -0.440531    -0.773076    -0.333265
 -0.0836006     0.790462   -0.422153    0.0546871  -0.270235    0.874834     0.306437     0.119072   -0.207362    0.350863    0.284905   -0.198626    0.358935     0.610713    -0.435108     -0.217527   -0.440787    0.495431    -0.941751    -0.401401     0.207148   -0.14617     -0.0772868  -0.119872    -0.0227017    0.125117
  0.175007      0.347946   -0.414351   -0.218795   -0.372784    0.794528     0.162351    -0.117502   -0.0563053  -0.054166    0.0515067  -0.075177   -0.251969    -0.881651     0.0181416     0.234532    0.702058    0.0122351   -0.206213     0.286944    -0.290878   -0.571983     0.191568    0.00482053  -0.697396    -0.321855
 -0.708959     -0.188372   -0.148649    0.0574041  -0.0901257   0.316118    -0.120236    -0.295906   -0.0549149   0.148091    0.0794457  -0.307447   -0.0863173    0.0751927    0.0508426    -0.33904     0.456297   -0.291853     0.057436    -0.0296941   -0.0100969  -0.56683     -0.183374   -0.0459422    0.226177     0.601695
 -0.529902     -0.401578    0.226115   -0.190226   -0.0305034  -0.376115    -0.435133    -0.0278214  -0.0890952   0.287022   -0.228271    0.290437   -0.222984     0.478293     0.435988     -0.7917     -0.268941   -0.0682355   -0.226339     0.129896    -0.827191   -0.0230808    0.250632   -0.418276     0.646507     0.198468
  0.178609      0.825738   -0.142418   -0.0971005   0.0478785   0.070932     0.374959     0.0674072   0.184373    0.62384    -0.133552    0.232811   -0.321217    -0.0945223   -0.620725      0.0173107  -0.846393   -0.74586      0.065623     0.512768     0.0303859  -0.0599775    0.167119    0.0389279    0.137562     0.552199
 -0.0531606    -0.190389    0.416244    0.21462     0.726724   -0.483247    -0.410819     0.220123   -0.0745594  -0.115387    0.167091   -0.0507115   0.264424     0.499308    -0.114663     -0.302682   -0.572656    0.00535823   0.372495    -0.37574      0.408564    0.631346    -0.0811487  -0.0958322    0.636069     0.460378
  0.441398      0.0878954   0.295584   -0.164561    0.0726488  -0.033371     0.232178    -0.419446    0.0602653  -0.257034   -0.420596    0.526077    0.0692717   -0.0585016    0.0244044     0.0258652  -0.131027    0.665266     0.125219     0.19763      0.168007    0.241069    -0.485151    0.208522    -0.0968298    0.192208
  0.124213      0.365401    0.329568    0.996812   -0.412665   -0.0784278    0.636856     0.316855    0.309873   -0.049429   -0.192117    0.263264    0.20463      0.763099     0.0348799     0.559165   -0.130303   -0.14358      0.082096    -0.485305    -0.0626977  -0.326701    -0.0631664   0.21175      0.320334     0.455236
  0.198543      0.35109     0.0486619  -0.211351   -0.295569    0.309059    -0.281551     0.127131    0.532685   -0.154876    0.190655   -0.200262   -0.271597     0.342246     0.149089     -0.239185   -0.287418   -0.0172536   -0.593378     0.330486    -0.66356    -0.492462     0.0024745  -0.390012    -0.188756     0.224001
 -0.14935      -0.330448   -0.288872   -0.433079   -0.035217   -0.508204     0.233245    -0.0899388  -0.553238   -0.127991   -0.229122   -0.301511   -0.241032     0.12841      0.149861      0.188862    0.0903071   0.0834313   -0.0671572    0.381234     0.498429   -0.198068     0.545009   -0.417582    -0.264796    -0.470389
 -0.0582369    -0.0622721  -0.527735    0.521359   -0.592741   -0.556152     0.191348    -0.333903   -0.119706    0.123918    0.0261453  -0.367971   -0.318533    -0.330517     0.117441      0.775032   -0.134027    0.120099     0.0259261    0.166668     0.891486   -0.0760371    0.294979    0.504653     0.0317374   -0.280551
  0.083969     -0.0029771   0.220417   -0.644112   -0.0201209   0.50752     -0.169654    -0.172619   -0.650658    0.429486    0.138517    0.509179    0.175415    -0.510021    -0.133558      0.466195    0.370938    0.216654    -0.773241     0.00715356   0.376233    0.345471    -0.210302    0.0349192    0.179314     0.518216
 -0.357407     -0.788554    0.864317   -0.109721    0.722315    0.831935     0.307169    -0.264114   -0.361778   -0.778439    0.432538   -0.270188    0.0418666   -0.919541     0.397167     -0.284575    0.300115    0.300777     0.678856     0.805508    -0.434483    0.325946     0.742512   -0.138143    -0.105646     0.486854
  0.218068      0.443822    0.0234275   0.148498   -0.084318   -0.0950946    0.0680149    0.0888067  -0.283889    0.707653   -0.711111   -0.394877    0.339388    -0.0554928    0.567508      0.15383     0.0154799  -0.0600053   -0.601063    -0.683328     0.0524946   0.239932    -0.353666   -0.116449     0.24034     -0.436725[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406261
[ Info: iteration 2, average log likelihood -1.406253
[ Info: iteration 3, average log likelihood -1.406246
[ Info: iteration 4, average log likelihood -1.406238
[ Info: iteration 5, average log likelihood -1.406231
[ Info: iteration 6, average log likelihood -1.406224
[ Info: iteration 7, average log likelihood -1.406217
[ Info: iteration 8, average log likelihood -1.406210
[ Info: iteration 9, average log likelihood -1.406204
[ Info: iteration 10, average log likelihood -1.406198
┌ Info: EM with 100000 data points 10 iterations avll -1.406198
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
