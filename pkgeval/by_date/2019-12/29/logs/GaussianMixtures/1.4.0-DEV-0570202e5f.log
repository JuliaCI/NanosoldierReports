Julia Version 1.4.0-DEV.668
Commit 0570202e5f (2019-12-28 22:20 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed OpenBLAS_jll ─────── v0.3.7+1
 Installed CMakeWrapper ─────── v0.2.3
 Installed FillArrays ───────── v0.8.2
 Installed ScikitLearnBase ──── v0.5.0
 Installed NearestNeighbors ─── v0.4.4
 Installed QuadGK ───────────── v2.3.1
 Installed DataStructures ───── v0.17.6
 Installed CMake ────────────── v1.1.2
 Installed StatsBase ────────── v0.32.0
 Installed Parameters ───────── v0.12.0
 Installed Blosc ────────────── v0.5.1
 Installed BinaryProvider ───── v0.5.8
 Installed URIParser ────────── v0.4.0
 Installed Arpack ───────────── v0.4.0
 Installed JLD ──────────────── v0.9.1
 Installed Missings ─────────── v0.4.3
 Installed Distances ────────── v0.8.2
 Installed PDMats ───────────── v0.9.10
 Installed SortingAlgorithms ── v0.3.1
 Installed StaticArrays ─────── v0.12.1
 Installed Compat ───────────── v2.2.0
 Installed Clustering ───────── v0.13.3
 Installed OrderedCollections ─ v1.1.0
 Installed LegacyStrings ────── v0.4.1
 Installed Arpack_jll ───────── v3.5.0+2
 Installed DataAPI ──────────── v1.1.0
 Installed SpecialFunctions ─── v0.9.0
 Installed Rmath ────────────── v0.6.0
 Installed Distributions ────── v0.21.11
 Installed FileIO ───────────── v1.2.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed HDF5 ─────────────── v0.12.5
 Installed StatsFuns ────────── v0.9.3
 Installed BinDeps ──────────── v1.0.0
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_hWBVME/Project.toml`
 [no changes]
  Updating `/tmp/jl_hWBVME/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_8eJM1t/Project.toml`
 [no changes]
  Updating `/tmp/jl_8eJM1t/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_nrS4Im/Project.toml`
 [no changes]
  Updating `/tmp/jl_nrS4Im/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_M2RgVu/Project.toml`
 [no changes]
  Updating `/tmp/jl_M2RgVu/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_3jQh15/Project.toml`
 [no changes]
  Updating `/tmp/jl_3jQh15/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_3jQh15/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.0
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.06912887816911e6, [99868.52391860448, 131.47608139552673], [-416.49759629054495 316.7397516680131 137.49279857886037; -160.57399829033824 -321.16157424257 -203.79044018742238], [[99600.47823101543 -581.8071445256898 -425.0999242806713; -581.80714452569 100345.51153200389 -139.2152104474283; -425.0999242806713 -139.2152104474283 100108.38507524246], [293.51939685682953 388.40725500753956 184.57156347447324; 388.40725500753956 815.5976654446981 479.5149956460365; 184.57156347447324 479.51499564603654 383.18971952551294]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.547643e+03
      1       9.062342e+02      -6.414093e+02 |        5
      2       8.795964e+02      -2.663776e+01 |        2
      3       8.743948e+02      -5.201614e+00 |        0
      4       8.743948e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 874.3948069378794)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.069638
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.796991
[ Info: iteration 2, lowerbound -3.652118
[ Info: iteration 3, lowerbound -3.493617
[ Info: iteration 4, lowerbound -3.322312
[ Info: iteration 5, lowerbound -3.162208
[ Info: dropping number of Gaussions to 7
[ Info: iteration 6, lowerbound -3.024355
[ Info: iteration 7, lowerbound -2.909268
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.818416
[ Info: iteration 9, lowerbound -2.743432
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.683350
[ Info: iteration 11, lowerbound -2.636709
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.591615
[ Info: iteration 13, lowerbound -2.544357
[ Info: iteration 14, lowerbound -2.500858
[ Info: iteration 15, lowerbound -2.459732
[ Info: iteration 16, lowerbound -2.422123
[ Info: iteration 17, lowerbound -2.387893
[ Info: iteration 18, lowerbound -2.356648
[ Info: iteration 19, lowerbound -2.329846
[ Info: iteration 20, lowerbound -2.312038
[ Info: iteration 21, lowerbound -2.307649
[ Info: dropping number of Gaussions to 2
[ Info: iteration 22, lowerbound -2.302919
[ Info: iteration 23, lowerbound -2.299259
[ Info: iteration 24, lowerbound -2.299256
[ Info: iteration 25, lowerbound -2.299254
[ Info: iteration 26, lowerbound -2.299254
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sun Dec 29 09:23:15 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sun Dec 29 09:23:23 2019: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Sun Dec 29 09:23:25 2019: EM with 272 data points 0 iterations avll -2.069638
5.8 data points per parameter
, Sun Dec 29 09:23:27 2019: GMM converted to Variational GMM
, Sun Dec 29 09:23:36 2019: iteration 1, lowerbound -3.796991
, Sun Dec 29 09:23:36 2019: iteration 2, lowerbound -3.652118
, Sun Dec 29 09:23:36 2019: iteration 3, lowerbound -3.493617
, Sun Dec 29 09:23:36 2019: iteration 4, lowerbound -3.322312
, Sun Dec 29 09:23:36 2019: iteration 5, lowerbound -3.162208
, Sun Dec 29 09:23:36 2019: dropping number of Gaussions to 7
, Sun Dec 29 09:23:36 2019: iteration 6, lowerbound -3.024355
, Sun Dec 29 09:23:36 2019: iteration 7, lowerbound -2.909268
, Sun Dec 29 09:23:36 2019: dropping number of Gaussions to 5
, Sun Dec 29 09:23:36 2019: iteration 8, lowerbound -2.818416
, Sun Dec 29 09:23:36 2019: iteration 9, lowerbound -2.743432
, Sun Dec 29 09:23:36 2019: dropping number of Gaussions to 4
, Sun Dec 29 09:23:36 2019: iteration 10, lowerbound -2.683350
, Sun Dec 29 09:23:36 2019: iteration 11, lowerbound -2.636709
, Sun Dec 29 09:23:36 2019: dropping number of Gaussions to 3
, Sun Dec 29 09:23:36 2019: iteration 12, lowerbound -2.591615
, Sun Dec 29 09:23:36 2019: iteration 13, lowerbound -2.544357
, Sun Dec 29 09:23:36 2019: iteration 14, lowerbound -2.500858
, Sun Dec 29 09:23:36 2019: iteration 15, lowerbound -2.459732
, Sun Dec 29 09:23:36 2019: iteration 16, lowerbound -2.422123
, Sun Dec 29 09:23:36 2019: iteration 17, lowerbound -2.387893
, Sun Dec 29 09:23:36 2019: iteration 18, lowerbound -2.356648
, Sun Dec 29 09:23:36 2019: iteration 19, lowerbound -2.329846
, Sun Dec 29 09:23:36 2019: iteration 20, lowerbound -2.312038
, Sun Dec 29 09:23:36 2019: iteration 21, lowerbound -2.307649
, Sun Dec 29 09:23:36 2019: dropping number of Gaussions to 2
, Sun Dec 29 09:23:37 2019: iteration 22, lowerbound -2.302919
, Sun Dec 29 09:23:37 2019: iteration 23, lowerbound -2.299259
, Sun Dec 29 09:23:37 2019: iteration 24, lowerbound -2.299256
, Sun Dec 29 09:23:37 2019: iteration 25, lowerbound -2.299254
, Sun Dec 29 09:23:37 2019: iteration 26, lowerbound -2.299254
, Sun Dec 29 09:23:37 2019: iteration 27, lowerbound -2.299253
, Sun Dec 29 09:23:37 2019: iteration 28, lowerbound -2.299253
, Sun Dec 29 09:23:37 2019: iteration 29, lowerbound -2.299253
, Sun Dec 29 09:23:37 2019: iteration 30, lowerbound -2.299253
, Sun Dec 29 09:23:37 2019: iteration 31, lowerbound -2.299253
, Sun Dec 29 09:23:37 2019: iteration 32, lowerbound -2.299253
, Sun Dec 29 09:23:37 2019: iteration 33, lowerbound -2.299253
, Sun Dec 29 09:23:37 2019: iteration 34, lowerbound -2.299253
, Sun Dec 29 09:23:37 2019: iteration 35, lowerbound -2.299253
, Sun Dec 29 09:23:37 2019: iteration 36, lowerbound -2.299253
, Sun Dec 29 09:23:37 2019: iteration 37, lowerbound -2.299253
, Sun Dec 29 09:23:37 2019: iteration 38, lowerbound -2.299253
, Sun Dec 29 09:23:37 2019: iteration 39, lowerbound -2.299253
, Sun Dec 29 09:23:37 2019: iteration 40, lowerbound -2.299253
, Sun Dec 29 09:23:37 2019: iteration 41, lowerbound -2.299253
, Sun Dec 29 09:23:37 2019: iteration 42, lowerbound -2.299253
, Sun Dec 29 09:23:37 2019: iteration 43, lowerbound -2.299253
, Sun Dec 29 09:23:37 2019: iteration 44, lowerbound -2.299253
, Sun Dec 29 09:23:37 2019: iteration 45, lowerbound -2.299253
, Sun Dec 29 09:23:37 2019: iteration 46, lowerbound -2.299253
, Sun Dec 29 09:23:37 2019: iteration 47, lowerbound -2.299253
, Sun Dec 29 09:23:37 2019: iteration 48, lowerbound -2.299253
, Sun Dec 29 09:23:37 2019: iteration 49, lowerbound -2.299253
, Sun Dec 29 09:23:37 2019: iteration 50, lowerbound -2.299253
, Sun Dec 29 09:23:37 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601615, 95.95490777398388]
β = [178.04509222601615, 95.95490777398388]
m = [4.25030073326989 79.28686694436156; 2.000229257775351 53.85198717246118]
ν = [180.04509222601615, 97.95490777398388]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484252 -0.007644049042327716; 0.0 0.00858170516633319], [0.3758763611948714 -0.008953123827346546; 0.0 0.01274866477740943]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999994
avll from stats: -1.006516111935961
avll from llpg:  -1.0065161119359523
avll direct:     -1.0065161119359523
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000003
avll from stats: -0.976200913473943
avll from llpg:  -0.976200913473943
avll direct:     -0.9762009134739429
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.134733     0.0281474    0.0801532   0.0053863    0.0244956     0.0150239    0.077879    -0.20722     -0.0275973     0.0517696   -0.0789823    0.114392     0.0502849    0.11545    -0.118641     -0.074813     0.0844455    0.0879679     0.0886408   -0.156537     0.126972     0.00810068   0.0868917   -0.0772783   -0.0497245    0.0499126
  0.0170937   -0.00161498  -0.0524194  -0.118758     0.124747     -0.0720442    0.0676267   -0.0892535    0.0779582    -0.0895394   -0.035232    -0.0411406   -0.0622347    0.214171   -0.0819646    -0.122136     0.00125529  -0.144211      0.0405946    0.15171     -0.060544    -0.0400717    0.104301    -0.0480394    0.188041     0.0828247
 -0.00361423   0.0233933   -0.147942   -0.0438539   -0.134471      3.83672e-7   0.194195     0.0440815    0.125645      0.0096045    0.0424472    0.00105438   0.260947    -0.0130835   0.0306627    -0.0464077   -0.0210874   -0.0710582    -0.0359034    0.12892     -0.106343     0.120363    -0.154898    -0.106477    -0.191798     0.0655524
  0.0116984   -0.124382    -0.186836   -0.0203799   -0.129651     -0.0453315    0.0586107   -0.158344     0.0418967    -0.00685727   0.0361434    0.103492     0.130365     0.146381    0.0298601     0.0659445    0.0444561   -0.1047       -0.137988     0.0854842    0.134604     0.0883105    0.108064     0.0253055    0.0604782   -0.123029
  0.0489744   -0.0898868   -0.147452   -0.0983012    0.16129      -0.124572     0.0456647    0.0594172   -0.11024      -0.0535937    0.131717     0.00283296  -0.130697    -0.0157289  -0.0527193    -0.0222503    0.065687    -0.141476      0.0209818    0.0180861    0.0807166   -0.0360944    0.0458009   -0.0383081   -0.0897309   -0.0315939
 -0.0158329    0.10172     -0.0640751   0.0123575   -0.047821     -0.233335    -0.0798899   -0.0065005   -0.126535     -0.0485196   -0.0923337    0.0230038   -0.0629761    0.341026   -0.00760995   -0.204574     0.115926    -0.0301803     0.0855174    0.0335219    0.13405     -0.0348653    0.0470145   -0.0315358    0.0841096   -0.168141
 -0.120655    -0.0906387   -0.24726     0.0955743    0.0829112    -0.0909066   -0.0383606   -0.132683     0.0974174    -0.0680412   -0.0138993   -0.0365246    0.109291    -0.0887384  -0.21352       0.0329524   -0.0339506   -0.119824      0.133301    -0.0375499    0.0235754    0.0717156   -0.0543808    0.179894     0.0575628   -0.140223
 -0.0453657   -0.0166188    0.0376486   0.0914756   -0.0986676    -0.0925504    0.0560217    0.0640824   -0.00177614    0.219289     0.062919    -0.0361037    0.280253     0.0134668  -0.109054     -0.0442001   -0.209809     0.197792      0.0855326    0.0595666    0.0444625   -0.0995245   -0.0511677    0.0119863    0.145161     0.0229805
  0.0537995   -0.127626     0.123558    0.190908     0.0113366     0.0382214    0.0271861   -0.121964     0.0329145    -0.180642     0.0329422    0.133791     0.0631628    0.116538    0.154016     -0.0802485    0.0170078    0.0302824    -0.112299     0.0570639   -0.063086    -0.0585973   -0.171996     0.0580145   -0.0600474    0.0761391
 -0.142126    -0.0615442   -0.211959    0.076782    -0.0811457    -0.0565119    0.117449     0.0227396    0.0455994    -0.0918159    0.00708495   0.13074     -0.00873312   0.0286694   0.0631998    -0.105331    -0.0673571    0.0497039     0.0210195   -0.149602    -0.0467052    0.153205    -0.206181     0.102683    -0.00431154   0.150086
  0.157584    -0.0561197    0.171935   -0.023734     0.0576418    -0.102371     0.0153455   -0.0229851   -0.000415405  -0.12027     -0.0708415    0.305091    -0.015737     0.145173    0.0387667    -0.14868     -0.130193     0.0233413    -0.0211399    0.266344     0.022352     0.16517      0.0917432   -0.0809479    0.0374521   -0.0272168
  0.00563741  -0.0696925    0.172314    0.00288861   0.00636274   -0.0204458    0.00879554  -0.0678128   -0.052456     -0.0366403    0.0686474   -0.140752    -0.101463    -0.044244   -0.000339234  -0.00552648  -0.00261032   0.186195      0.0304649    0.00733526   0.140104     0.0497675    0.121851    -0.136716    -0.0801623    0.221589
 -0.0611136   -0.0279437   -0.0296406  -0.112284    -0.0954967     0.244383    -0.100028    -0.123298    -0.00460498    0.146247     0.16604     -0.126549    -0.0999817    0.127569    0.0143433     0.23464     -0.0487497   -0.0466104    -0.148536    -0.0342488   -0.189715    -0.0509622   -0.0883244   -0.173776    -0.0715852    0.0158188
 -0.087714    -0.04691     -0.125452   -0.102893     0.0960491    -0.0298826    0.122739     0.0902546   -0.0254932    -0.201853     0.122394     0.0789128   -0.121599     0.107092    0.143502     -0.0111674    0.092481     0.0881244     0.0664547    0.0319404   -0.15145      0.162905     0.238961     0.122824    -0.203724     0.194386
  0.0500146    0.110986     0.235316    0.00501775  -0.104092     -0.0440917    0.039854    -0.141789     0.0491186    -0.187729     0.0359508    0.0207323    0.0937374    0.0128263  -0.141537      0.0358631    0.0932208    0.0114799    -0.0163518   -0.0433789    0.00392182  -0.0245532    0.00864893   0.0440754   -0.0419945    0.0883968
  0.0255623   -0.0579469    0.0339019   0.0742162    0.0134961     0.0532778    0.053854    -0.16044      0.0723922     0.00236725  -0.175292    -0.0521836    0.0451336    0.0479532   0.0356138     0.140641    -0.0214891   -0.123006      0.0212417    0.0861099   -0.100423     0.0723753    0.0445214    0.100871     0.0151011    0.187555
 -0.0860955   -0.123599     0.0477445  -0.114804    -0.18264       0.0252821   -0.118788     0.193853     0.140063      0.0861735    0.0291943    0.0519383    0.00783721  -0.129399   -0.133152      0.059539    -0.141111    -0.144125      0.0859634   -0.0331277    0.0067275   -0.25831     -0.00513524  -0.128829     0.057864     0.11274
 -0.0614109   -0.0466541    0.0645438  -0.00142036   0.240395     -0.0260766   -0.035279    -0.0510023   -0.127884      0.182196     0.0595633    0.111042     0.0679746    0.0061607  -0.0498239    -0.123372     0.160436    -0.018765     -0.0580968   -0.0623266    0.0392805    0.0305074   -0.214786     0.0105484   -0.113577     0.088169
 -0.057238    -0.11434     -0.0425666  -0.097524    -0.0286384    -0.189449     0.0922609    0.152757     0.0607206    -0.0356541    0.0149169    0.0179907    0.243473    -0.0401884   0.0386857    -0.121965    -0.0234778    0.0540868     0.18868      0.0246305   -0.0101338    0.121595    -0.0772306    0.0771495    0.00279208   0.220242
 -0.142651     0.0395601    0.0863664   0.0386831    0.070175     -0.0410442   -0.0438585    0.00109426  -0.142344      0.0119076   -0.0193113    0.119792    -0.20105     -0.0702264  -0.112255     -0.0377599    0.049553    -0.0702044     0.0105849    0.0236026    0.121316    -0.0836775   -0.0541566   -0.0166148   -0.0595186    0.0906907
  0.0310354   -0.0515386    0.0488685  -0.0263944   -0.000807919   0.0932546   -0.197497    -0.0200312    0.0192191     0.0358812    0.0183899   -0.15221     -0.101508     0.0202654  -0.062197     -0.0925961   -0.126237    -0.000505832  -0.0893804   -0.0589097    3.41604e-5  -0.0469637    0.00479634  -0.00597055  -0.140169    -0.0232231
  0.084212    -0.201876    -0.0572803  -0.0456056   -0.0194678    -0.0903566   -0.10245      0.021741    -0.0581864     0.0971947   -0.133309    -0.0279062   -0.159775    -0.057063   -0.142732     -0.154354    -0.0194545    0.00481302    0.198691     0.0288562    0.282278     0.109561     0.202039     0.0024561   -0.206725    -0.0427193
  0.0639006    0.0681081    0.0138346  -0.062303    -0.0348256     0.0567392   -0.0877751    0.0928647   -0.160067     -0.0359166    0.118814     0.153453    -0.0525445    0.0857802  -0.174307     -0.0903345   -0.104472    -0.0773183    -0.0389922   -0.0544927   -0.285087    -0.00392385  -0.0819017   -0.0031684    0.00202978   0.0169052
  0.0274986    0.185374     0.0337401  -0.123401    -0.0565879     0.0505556    0.0415017   -0.0958577   -0.0406012     0.0536103   -0.0636652   -0.172212     0.0600562   -0.0593708  -0.00582862    0.0555486    0.0343789    0.00624635   -0.00737792   0.0319154    0.0334546   -0.100306     0.184642    -0.0232658   -0.0415238   -0.155146
 -0.290367     0.047989     0.159556   -0.126667     0.0531944     0.0314809    0.154644     0.0285271    0.104024     -0.0203525   -0.0863315    0.0206749   -0.11339     -0.0985451  -0.006106     -0.0788709   -0.222829    -0.16806      -0.0912042   -0.118839    -0.00943916  -0.0724239    0.0353226   -0.010153     0.126409     0.0189854
 -0.13603     -0.0514304    0.0708127   0.0402336    0.065851      0.21259      0.0564254   -0.115874    -0.129624     -0.0756906    0.188313    -0.0675669   -0.0474789    0.208393    0.0834228     0.0271638   -0.159201     0.0781876    -0.167942     0.0564373   -0.0605368   -0.0281186   -0.116869     0.0905657   -0.0796894   -0.0137784
 -0.004192     0.00485958   0.1059      0.114707     0.093847     -0.0912314    0.0385645    0.157623     0.00120634   -0.0699861    0.0512079   -0.208338    -0.0862732    0.100663    0.139898      0.068231    -0.0405717    0.0622739    -0.132642    -0.0110467    0.0462222    0.00373265  -0.0366636   -0.215087     0.0134985   -0.0496433
  0.00832319  -0.0502383    0.0210873   0.0603037   -0.0880306    -0.040014     0.0377821   -0.183091    -0.101833     -0.0192744    0.0921667   -0.112815     0.0302476   -0.0537983  -0.13864      -0.0287123   -0.080059     0.0499612    -0.0757741    0.00103616   0.197964     0.00103655  -0.142688     0.035504    -0.0585258   -0.129894
  0.0210851   -0.0304145   -0.0452927  -0.0768942   -0.0998262    -0.00164235  -0.11189      0.0369052    0.0394106    -0.0151378    0.0334362   -0.0312652   -0.14269     -0.122508    0.0409014     0.0253675   -0.145054     0.102015     -0.0944486    0.114828    -0.0757062    0.134611     0.149423     0.0272219    0.0349145   -0.0161816
  0.133577    -0.00522623  -0.0380615   0.0779173    0.0922775     0.0787301   -0.133927     0.0353821    0.0522799     0.0713067   -0.106134    -0.0124166   -0.0374124    0.0673115  -0.0180711     0.068307    -0.0167393   -0.0249021    -0.0183319   -0.064178    -0.0271315    0.110163     0.0352832    0.105787     0.0914716   -0.108932
  0.0520261    0.0120935   -0.056633    0.164427     0.13252      -0.195257    -0.079919    -0.0391449   -0.0229712    -0.03063      0.0884967   -0.0940923    0.0355618    0.079071   -0.0571406     0.208453    -0.0657064    0.00476597    0.0129352    0.0310706   -0.0224681   -0.0586531    0.162694    -0.0807021    0.0976002    0.0638165
  0.116648    -0.0436878   -0.111466   -0.0176819   -0.164437      0.06001     -0.0835166    0.0111057    0.0841509    -0.035389     0.245039     0.0589722    0.109513     0.125627   -0.0562116     0.185164    -0.0631976   -0.124173     -0.124237    -0.0515609    0.262178     0.0858565    0.13988     -0.0337198   -0.00569796  -0.00489569kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4290628543236503
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.429154
[ Info: iteration 2, average log likelihood -1.429073
[ Info: iteration 3, average log likelihood -1.428595
[ Info: iteration 4, average log likelihood -1.423116
[ Info: iteration 5, average log likelihood -1.407491
[ Info: iteration 6, average log likelihood -1.397876
[ Info: iteration 7, average log likelihood -1.394879
[ Info: iteration 8, average log likelihood -1.393234
[ Info: iteration 9, average log likelihood -1.392188
[ Info: iteration 10, average log likelihood -1.391581
[ Info: iteration 11, average log likelihood -1.391197
[ Info: iteration 12, average log likelihood -1.390936
[ Info: iteration 13, average log likelihood -1.390733
[ Info: iteration 14, average log likelihood -1.390543
[ Info: iteration 15, average log likelihood -1.390351
[ Info: iteration 16, average log likelihood -1.390191
[ Info: iteration 17, average log likelihood -1.390078
[ Info: iteration 18, average log likelihood -1.390006
[ Info: iteration 19, average log likelihood -1.389960
[ Info: iteration 20, average log likelihood -1.389931
[ Info: iteration 21, average log likelihood -1.389913
[ Info: iteration 22, average log likelihood -1.389901
[ Info: iteration 23, average log likelihood -1.389893
[ Info: iteration 24, average log likelihood -1.389887
[ Info: iteration 25, average log likelihood -1.389883
[ Info: iteration 26, average log likelihood -1.389880
[ Info: iteration 27, average log likelihood -1.389877
[ Info: iteration 28, average log likelihood -1.389875
[ Info: iteration 29, average log likelihood -1.389874
[ Info: iteration 30, average log likelihood -1.389873
[ Info: iteration 31, average log likelihood -1.389871
[ Info: iteration 32, average log likelihood -1.389870
[ Info: iteration 33, average log likelihood -1.389870
[ Info: iteration 34, average log likelihood -1.389869
[ Info: iteration 35, average log likelihood -1.389868
[ Info: iteration 36, average log likelihood -1.389868
[ Info: iteration 37, average log likelihood -1.389867
[ Info: iteration 38, average log likelihood -1.389866
[ Info: iteration 39, average log likelihood -1.389866
[ Info: iteration 40, average log likelihood -1.389866
[ Info: iteration 41, average log likelihood -1.389865
[ Info: iteration 42, average log likelihood -1.389865
[ Info: iteration 43, average log likelihood -1.389864
[ Info: iteration 44, average log likelihood -1.389864
[ Info: iteration 45, average log likelihood -1.389864
[ Info: iteration 46, average log likelihood -1.389864
[ Info: iteration 47, average log likelihood -1.389863
[ Info: iteration 48, average log likelihood -1.389863
[ Info: iteration 49, average log likelihood -1.389863
[ Info: iteration 50, average log likelihood -1.389863
┌ Info: EM with 100000 data points 50 iterations avll -1.389863
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4291535388811347
│     -1.4290734730364998
│      ⋮
└     -1.3898628807558921
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.390024
[ Info: iteration 2, average log likelihood -1.389843
[ Info: iteration 3, average log likelihood -1.388853
[ Info: iteration 4, average log likelihood -1.380695
[ Info: iteration 5, average log likelihood -1.364254
[ Info: iteration 6, average log likelihood -1.356399
[ Info: iteration 7, average log likelihood -1.353576
[ Info: iteration 8, average log likelihood -1.351725
[ Info: iteration 9, average log likelihood -1.349812
[ Info: iteration 10, average log likelihood -1.348103
[ Info: iteration 11, average log likelihood -1.346918
[ Info: iteration 12, average log likelihood -1.346138
[ Info: iteration 13, average log likelihood -1.345620
[ Info: iteration 14, average log likelihood -1.345253
[ Info: iteration 15, average log likelihood -1.344983
[ Info: iteration 16, average log likelihood -1.344770
[ Info: iteration 17, average log likelihood -1.344574
[ Info: iteration 18, average log likelihood -1.344361
[ Info: iteration 19, average log likelihood -1.344124
[ Info: iteration 20, average log likelihood -1.343871
[ Info: iteration 21, average log likelihood -1.343593
[ Info: iteration 22, average log likelihood -1.343291
[ Info: iteration 23, average log likelihood -1.343014
[ Info: iteration 24, average log likelihood -1.342794
[ Info: iteration 25, average log likelihood -1.342651
[ Info: iteration 26, average log likelihood -1.342567
[ Info: iteration 27, average log likelihood -1.342515
[ Info: iteration 28, average log likelihood -1.342481
[ Info: iteration 29, average log likelihood -1.342457
[ Info: iteration 30, average log likelihood -1.342439
[ Info: iteration 31, average log likelihood -1.342421
[ Info: iteration 32, average log likelihood -1.342403
[ Info: iteration 33, average log likelihood -1.342384
[ Info: iteration 34, average log likelihood -1.342367
[ Info: iteration 35, average log likelihood -1.342350
[ Info: iteration 36, average log likelihood -1.342334
[ Info: iteration 37, average log likelihood -1.342317
[ Info: iteration 38, average log likelihood -1.342301
[ Info: iteration 39, average log likelihood -1.342285
[ Info: iteration 40, average log likelihood -1.342269
[ Info: iteration 41, average log likelihood -1.342253
[ Info: iteration 42, average log likelihood -1.342236
[ Info: iteration 43, average log likelihood -1.342218
[ Info: iteration 44, average log likelihood -1.342200
[ Info: iteration 45, average log likelihood -1.342183
[ Info: iteration 46, average log likelihood -1.342166
[ Info: iteration 47, average log likelihood -1.342150
[ Info: iteration 48, average log likelihood -1.342135
[ Info: iteration 49, average log likelihood -1.342120
[ Info: iteration 50, average log likelihood -1.342106
┌ Info: EM with 100000 data points 50 iterations avll -1.342106
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3900242480694378
│     -1.389842671060948
│      ⋮
└     -1.3421058192227606
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.342249
[ Info: iteration 2, average log likelihood -1.342053
[ Info: iteration 3, average log likelihood -1.340895
[ Info: iteration 4, average log likelihood -1.330692
[ Info: iteration 5, average log likelihood -1.311157
[ Info: iteration 6, average log likelihood -1.302391
[ Info: iteration 7, average log likelihood -1.299332
[ Info: iteration 8, average log likelihood -1.297726
[ Info: iteration 9, average log likelihood -1.296545
[ Info: iteration 10, average log likelihood -1.295582
[ Info: iteration 11, average log likelihood -1.294788
[ Info: iteration 12, average log likelihood -1.294132
[ Info: iteration 13, average log likelihood -1.293560
[ Info: iteration 14, average log likelihood -1.293012
[ Info: iteration 15, average log likelihood -1.292448
[ Info: iteration 16, average log likelihood -1.291902
[ Info: iteration 17, average log likelihood -1.291455
[ Info: iteration 18, average log likelihood -1.291097
[ Info: iteration 19, average log likelihood -1.290769
[ Info: iteration 20, average log likelihood -1.290370
[ Info: iteration 21, average log likelihood -1.289766
[ Info: iteration 22, average log likelihood -1.288813
[ Info: iteration 23, average log likelihood -1.287477
[ Info: iteration 24, average log likelihood -1.286295
[ Info: iteration 25, average log likelihood -1.285736
[ Info: iteration 26, average log likelihood -1.285457
[ Info: iteration 27, average log likelihood -1.285232
[ Info: iteration 28, average log likelihood -1.284993
[ Info: iteration 29, average log likelihood -1.284709
[ Info: iteration 30, average log likelihood -1.284350
[ Info: iteration 31, average log likelihood -1.283853
[ Info: iteration 32, average log likelihood -1.283056
[ Info: iteration 33, average log likelihood -1.281809
[ Info: iteration 34, average log likelihood -1.280603
[ Info: iteration 35, average log likelihood -1.279963
[ Info: iteration 36, average log likelihood -1.279701
[ Info: iteration 37, average log likelihood -1.279578
[ Info: iteration 38, average log likelihood -1.279506
[ Info: iteration 39, average log likelihood -1.279451
[ Info: iteration 40, average log likelihood -1.279394
[ Info: iteration 41, average log likelihood -1.279323
[ Info: iteration 42, average log likelihood -1.279231
[ Info: iteration 43, average log likelihood -1.279112
[ Info: iteration 44, average log likelihood -1.278954
[ Info: iteration 45, average log likelihood -1.278762
[ Info: iteration 46, average log likelihood -1.278559
[ Info: iteration 47, average log likelihood -1.278378
[ Info: iteration 48, average log likelihood -1.278229
[ Info: iteration 49, average log likelihood -1.278096
[ Info: iteration 50, average log likelihood -1.277933
┌ Info: EM with 100000 data points 50 iterations avll -1.277933
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3422487921330362
│     -1.342052776303166
│      ⋮
└     -1.2779333392103958
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.277908
[ Info: iteration 2, average log likelihood -1.277405
[ Info: iteration 3, average log likelihood -1.276248
[ Info: iteration 4, average log likelihood -1.265534
[ Info: iteration 5, average log likelihood -1.227970
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.194826
[ Info: iteration 7, average log likelihood -1.190151
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.177247
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.189796
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.182978
[ Info: iteration 11, average log likelihood -1.179514
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.168103
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.173320
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.175544
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.174910
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.175611
[ Info: iteration 17, average log likelihood -1.176602
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.167398
[ Info: iteration 19, average log likelihood -1.183619
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.168557
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.172211
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.174724
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.176502
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.177851
[ Info: iteration 25, average log likelihood -1.176677
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.165824
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.171361
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.174635
[ Info: iteration 29, average log likelihood -1.186975
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.170964
[ Info: iteration 31, average log likelihood -1.174015
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.165008
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.171287
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.185108
[ Info: iteration 35, average log likelihood -1.180071
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.168240
[ Info: iteration 37, average log likelihood -1.173192
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.164937
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.181773
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.178210
[ Info: iteration 41, average log likelihood -1.177422
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.167453
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.173129
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.175425
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.174852
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.175530
[ Info: iteration 47, average log likelihood -1.176571
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.167355
[ Info: iteration 49, average log likelihood -1.183594
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.168512
┌ Info: EM with 100000 data points 50 iterations avll -1.168512
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2779079694105
│     -1.277404715016222
│      ⋮
└     -1.1685115506666621
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.172487
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     18
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.164101
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.169379
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     17
│     18
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.139886
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     10
│     17
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.104441
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.081086
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│     10
│     12
│     17
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.069782
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     17
│     18
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.092266
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      7
│     10
│     17
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.070723
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      8
│     12
│     17
│     18
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.075949
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      7
│     10
│     17
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.079373
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     17
│     18
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.079296
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│     10
│     12
│     17
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.064544
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     17
│     18
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.081778
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     10
│     17
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.070928
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      8
│     12
│     17
│     18
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.073593
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      7
│     10
│     17
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.074492
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     17
│     18
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.074216
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      7
│      8
│      ⋮
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.058733
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     18
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.087896
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      8
│     10
│     17
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.062518
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│      8
│     12
│      ⋮
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.069568
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     10
│     17
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.075867
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     17
│     18
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.073908
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      7
│      8
│      ⋮
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.057613
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     18
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.087683
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      8
│     10
│     17
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.062543
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│      8
│     12
│      ⋮
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.069413
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     10
│     17
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.075911
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     17
│     18
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.073827
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      7
│      8
│      ⋮
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.057629
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     18
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.087628
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      8
│     10
│     17
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.062572
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│      8
│     12
│      ⋮
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.069352
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     10
│     17
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.075948
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     17
│     18
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.073780
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      7
│      8
│      ⋮
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.057658
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     18
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.087587
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      8
│     10
│     17
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.062603
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│      8
│     12
│      ⋮
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.069310
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     10
│     17
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.075979
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     17
│     18
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.073742
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      7
│      8
│      ⋮
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.057688
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     18
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.087552
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      8
│     10
│     17
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.062631
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│      8
│     12
│      ⋮
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.069276
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     10
│     17
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.076007
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     17
│     18
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.073710
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      7
│      8
│      ⋮
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.057714
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     17
│     18
│     23
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.087522
┌ Info: EM with 100000 data points 50 iterations avll -1.087522
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.172487246146946
│     -1.1641013840438352
│      ⋮
└     -1.0875221524095262
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4290628543236503
│     -1.4291535388811347
│     -1.4290734730364998
│     -1.4285953982886372
│      ⋮
│     -1.0737098920468828
│     -1.0577140851243327
└     -1.0875221524095262
32×26 Array{Float64,2}:
 -0.137959   -0.0301039   -0.213442     0.0762853    -0.07181     -0.0719909    0.119501     0.0216892    0.0362194   -0.0971649   -0.0173393   0.128513    -0.00879162   0.0279848    0.0655269   -0.101875    -0.0353541    0.0491825    0.0051046    -0.208794    -0.0698872    0.154672     -0.238661     0.125466    -0.0131401    0.152221
 -0.312362    0.0719651    0.169295    -0.125864      0.0599206    0.0347111    0.150473     0.0508699    0.094391    -0.0230352   -0.0510371   0.0197294   -0.117552    -0.090344    -0.0140216   -0.0517192   -0.199058    -0.107091    -0.0878112    -0.103721     0.00416302  -0.0712191     0.0362429   -0.0140622    0.108493     0.0104704
  0.0190166  -0.049177     0.167528     0.00129083    0.0180284   -0.0143799   -0.0657478   -0.0830083   -0.0335497   -0.0398747    0.0731264  -0.134455    -0.0908775   -0.0151621    0.00140361  -0.0469531    0.0130706    0.167427     0.039984      0.00578936   0.129846     0.0502755     0.109172    -0.133245    -0.0523768    0.20435
  0.0196927   0.0165402   -0.150826    -0.0484796    -0.161028     0.00612812   0.173752     0.0204215    0.159668     0.0112803    0.0596663   0.00477769   0.261009    -0.0136568    0.0399568    0.0140255   -0.00334691  -0.0369637   -0.0383619     0.108925    -0.109482     0.145099     -0.169224    -0.108049    -0.193828     0.0711354
 -0.0943145  -0.0896683   -0.241394     0.0926407     0.0687844   -0.0929632    0.0101266   -0.149024     0.097893    -0.0881903   -0.023194   -0.0445739    0.105089    -0.0871863   -0.215323     0.0228921   -0.0350356   -0.11377      0.157824     -0.0381919    0.0391885    0.0801529    -0.0788665    0.173312     0.101745    -0.132912
 -0.0868515  -0.128498     0.0737013   -0.107192     -0.179068     0.0541022   -0.114691     0.227219     0.142225     0.0879381    0.0212804   0.0511434    0.00313462  -0.141019    -0.131788     0.0655155   -0.140535    -0.142926     0.118603     -0.0442525    0.00059041  -0.266838      0.0364602   -0.133913     0.0556575    0.114173
  0.119231   -0.0515114   -0.130207    -0.0363123    -0.0892594    0.0599924   -0.105653    -0.00326436   0.0869984   -0.0637975    0.227749    0.0477208    0.104        0.126519    -0.0554295    0.169987    -0.0767938   -0.125402    -0.0976318    -0.059053     0.246943     0.103481      0.177624    -0.0179113   -0.0185574   -0.0232204
  0.0358284  -0.0637105    0.0395821    0.071043      0.0114776    0.0513811    0.0706873   -0.146373     0.0707243    0.0294613   -0.166096    0.00146665   0.0354366    0.0167994    0.0348348    0.10496     -0.0218814   -0.111109     0.0499321     0.075364    -0.0979789    0.00421106    0.0428907    0.114261    -0.00210934   0.188326
  0.0093571  -0.0769148    0.0223433    0.0515372    -0.0899767   -0.0501447    0.0370423   -0.200012    -0.102532    -0.0246785    0.0615991  -0.0706587    0.0424088   -0.0622704   -0.132649    -0.037673    -0.0672884    0.0523397   -0.0734474    -0.0127988    0.196703     0.000917314  -0.155887     0.0372554   -0.0671279   -0.149816
  0.0547041   0.0192876   -0.0561155    0.165194      0.133036    -0.219051    -0.0461513   -0.0281926   -0.0290922   -0.0292105    0.101296   -0.0878812    0.0252645    0.073829    -0.0767787    0.186596    -0.0608764    0.0128768    0.0219793     0.037841    -0.00966164  -0.0564308     0.18509     -0.0798722    0.0884096    0.0394049
  0.0191634  -0.0462892    0.069947     0.0836823    -0.102241    -0.108815     0.0484292    0.0608589   -0.00134393   0.210089     0.0621917  -0.0298134    0.26231      0.0116604   -0.114866    -0.0381481   -0.240066     0.199548     0.0850886     0.0623059    0.0240424   -0.10799      -0.0266517    0.0110408    0.14472      0.0751228
 -0.0914784  -0.0472294   -0.112748    -0.0688855     0.0730227   -0.0327389    0.121209     0.102322    -0.0224375   -0.207019     0.120655    0.0791197   -0.159339     0.095176     0.137394     0.00207141   0.0796421    0.0874134    0.0868745     0.0357974   -0.082872     0.163764      0.232657     0.12118     -0.196995     0.221052
 -0.0473805   0.0252311    0.0378425   -0.0098617     0.00474098   0.00430737  -0.0331685    0.0665065   -0.154395    -0.00619539   0.0219791   0.129986    -0.131025    -0.00173704  -0.157766    -0.0665515   -0.0194032   -0.0668335    0.0118882    -0.00533412  -0.0453428   -0.0252988    -0.0664176   -0.00488543  -0.0331865    0.0408654
  0.0544158   0.0931945    0.23101      0.00939771   -0.103359    -0.0224945    0.0386264   -0.130598     0.040169    -0.197176     0.0353105   0.0240763    0.0913227    0.012905    -0.122095     0.0283552    0.103832    -0.0164926   -0.031853     -0.0469426   -0.0139512   -0.0326347    -0.026918     0.0425284   -0.0399543    0.0484246
  0.181106   -0.0337884    0.0445932    0.000734119   0.0324293   -0.0134358    0.120058    -0.250734    -0.242722     0.210059    -0.0781079  -0.417341     0.0674949    0.0888907   -0.11547     -0.110121     0.114787     0.0954105    0.101867     -0.216205     0.140199     0.0819287    -0.0382852   -0.083559    -0.0496278    0.0557426
  0.101628    0.0475761    0.0881083   -0.00512341    0.0157257    0.0463855    0.0362025   -0.159208     0.221494    -0.0729856   -0.0870866   0.538494    -0.0240977    0.16505     -0.109976    -0.0698725    0.226503     0.119482     0.0747626    -0.166371     0.126629     0.0786111     0.196057    -0.0601369   -0.0494289    0.0386714
  0.0164719  -0.154198    -0.793592     0.0805037     0.160842    -0.138986    -0.0798569   -0.0795876   -0.116075    -0.116049     0.145851    0.0428445   -0.173129    -0.0170659   -0.0888418   -0.0210693    0.0684132   -0.565073     0.0288116     0.0814977    0.0920031   -0.0377357     0.0426961   -0.0314432   -0.0534011   -0.021774
  0.106707   -0.025831     0.497612    -0.249957      0.161288    -0.097787     0.21487      0.0397301   -0.0995376    0.0183237    0.103528    0.0026671   -0.0971359   -0.0295457    0.00437565   0.0566893    0.0610486    0.272768     0.0447156    -0.0327269    0.0746795   -0.0154064     0.0575341   -0.0546069   -0.147682    -0.0466134
  0.0355424  -0.109412    -0.100003    -0.0120449    -0.0252935    0.0516146   -0.0615904   -0.0589428    0.00632869   0.0818744    0.0141614  -0.0228257   -0.0345676    0.0779671   -0.0261064    0.0820423   -0.00208757  -0.0379175   -0.0400895    -0.0121272    0.0457277    0.0681403     0.0417471   -0.00863593  -0.0175367   -0.0808125
 -0.0618027  -0.0871671   -0.046577    -0.0940152    -0.0107806   -0.19788      0.0993424    0.143893     0.0616786   -0.0181864    0.0295241   0.0195797    0.245906    -0.0419497    0.0370902   -0.123548    -0.0188095    0.0522247    0.186367      0.0143857    0.00401559   0.123207     -0.0782518    0.0782529   -0.0129007    0.226843
  0.0502464  -0.188377     0.146657     0.195907     -0.00553029   0.0144137    0.0240192   -0.118087     0.0331643   -0.157142     0.0389612   0.150726     0.121661     0.12679      0.120919    -0.194391     0.0164449    0.0313273   -0.115779      0.0378325   -0.00450271  -0.0534184    -0.0845437    0.0705293   -0.909919     0.0439704
  0.0752529  -0.0552079    0.0382262    0.177151      0.0233312    0.0803291    0.0262743   -0.126293     0.0322928   -0.179754     0.0247711   0.119799     0.0590868    0.117852     0.178855    -0.00340332   0.0403306   -0.00385468  -0.111264      0.101703    -0.0580576   -0.0704642    -0.322672     0.0418753    0.89202      0.0453366
  0.0278801   0.251519     0.0109797   -0.1245       -0.057923     0.0489011   -1.52575     -0.0707833   -0.0389267    0.0615181   -0.0614424  -0.122343     0.107249    -0.0720287   -0.00586741   0.0372151    0.0350266   -0.00436636   0.00328185    0.0425644    0.0382287   -0.194917      0.182737    -0.0230723   -0.0856821   -0.148331
  0.0234742   0.206675     0.0333924   -0.123141     -0.0579049    0.0501196    1.31523     -0.0913708   -0.0405973    0.0786882   -0.0727005  -0.202767     0.066629    -0.0410585   -0.00572884   0.0452682    0.0360943    0.0147279   -0.0105288     0.0206162    0.0541726   -0.0649132     0.183533    -0.0231235    0.0231438   -0.149357
  0.0586414  -0.0588007    0.123759    -0.0259552    -0.0083904    0.0920976   -0.209046    -0.0162788    0.0165578    0.0405829    0.015299   -0.14826     -0.102216     0.0817857   -0.070899    -0.0979518   -0.124221     0.0131719   -0.0859121    -0.0268021    0.0087329   -0.024001     -0.00853993   0.0603756   -0.159385    -0.0102559
 -0.0129957   0.00562961   0.158745     0.0623684     0.0910452   -0.06763      0.0261084    0.153113     0.00103921  -0.0807417    0.0521568  -0.150043    -0.0939525    0.0746555    0.136804     0.0623361   -0.0368051    0.0639493   -0.126471     -0.014077     0.0631016    2.62229e-5   -0.0384405   -0.22342      0.0544772   -0.0353244
  0.0940662  -0.06166      0.0760436   -0.0394746    -0.033205    -0.027705    -0.0488951   -0.0131136    0.038313    -0.065518    -0.0051244   0.151202    -0.0820014    0.0458043    0.0507958   -0.0570701   -0.135786     0.0665261   -0.0547192     0.175863    -0.0348277    0.153615      0.111356    -0.0250611    0.0304496   -0.0386623
 -0.0272559  -0.0131523   -0.00597509  -0.0591014     0.162965    -0.0563285    0.00894448  -0.0748188   -0.0158462    0.0383402    0.0103691   0.0271505    0.00504921   0.106589    -0.0712472   -0.111246     0.0711262   -0.0757746   -0.000404076   0.0440607   -0.0154415   -0.00252136   -0.0373142   -0.0108947    0.0454133    0.104029
 -0.073591   -0.0433732    0.0642366    0.25252       0.147198     0.606198    -0.0252442   -0.179497    -0.130377    -0.0779045    0.153638   -0.0819833   -0.0918379   -0.106227     0.135778     0.00906213  -0.138426     0.0521447   -0.169769      0.0782166   -0.0720358   -0.0142973    -0.0848443    0.112921    -0.0483534   -0.0239114
 -0.257265   -0.0071637    0.0754103   -0.18204       0.113124    -0.132754     0.0776006   -0.0610066   -0.126695    -0.071429     0.189743   -0.0053706   -0.0672268    0.683394     0.0576243    0.0806401   -0.201014     0.0665168   -0.165386      0.0441356   -0.076382    -0.0392858    -0.125577     0.0572469   -0.114333    -0.00798967
 -0.0147397   0.102703    -0.0632984   -0.0063378    -0.0242244   -0.191843    -0.0758358   -0.00705994  -0.130641    -0.0387999   -0.087917   -0.0166917   -0.0635526    0.344717    -0.0142716   -0.207857     0.110267    -0.0370137    0.0889834     0.0352048    0.107405    -0.0436817     0.0476561   -0.0193502    0.110788    -0.176675
  0.0473294   0.0892019   -0.059678    -0.0359382     0.0198765   -0.574093    -0.0851339   -0.0198023   -0.145894    -0.0484238    0.0291132   0.321671    -0.0146345    0.345085     0.0205478   -0.752944     0.13899      0.726064     0.0901683     0.0318501    0.222578     0.0461845     0.0544569   -0.00777819  -0.0835293   -0.15191[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      8
│     10
│     17
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.062654
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      7
│      8
│      ⋮
│     24
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.045909
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      8
│     10
│     17
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.062499
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      7
│      8
│      ⋮
│     24
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.045959
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      8
│     10
│     17
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.062431
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      7
│      8
│      ⋮
│     24
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.045992
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      8
│     10
│     17
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.062351
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      7
│      8
│      ⋮
│     24
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.046035
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      8
│     10
│     17
│     18
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.062258
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      7
│      8
│      ⋮
│     24
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.046088
┌ Info: EM with 100000 data points 10 iterations avll -1.046088
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind diag, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.358123e+05
      1       7.017726e+05      -2.340397e+05 |       32
      2       6.691740e+05      -3.259856e+04 |       32
      3       6.535315e+05      -1.564253e+04 |       32
      4       6.465638e+05      -6.967672e+03 |       32
      5       6.427780e+05      -3.785874e+03 |       32
      6       6.404280e+05      -2.349965e+03 |       32
      7       6.389203e+05      -1.507684e+03 |       32
      8       6.379646e+05      -9.557601e+02 |       32
      9       6.371889e+05      -7.756263e+02 |       32
     10       6.363217e+05      -8.672535e+02 |       32
     11       6.353993e+05      -9.223755e+02 |       32
     12       6.345272e+05      -8.721107e+02 |       32
     13       6.338095e+05      -7.177056e+02 |       32
     14       6.330971e+05      -7.123685e+02 |       32
     15       6.322997e+05      -7.973879e+02 |       32
     16       6.314430e+05      -8.567289e+02 |       32
     17       6.305244e+05      -9.186008e+02 |       32
     18       6.293548e+05      -1.169571e+03 |       32
     19       6.278169e+05      -1.537979e+03 |       32
     20       6.257613e+05      -2.055503e+03 |       32
     21       6.239241e+05      -1.837225e+03 |       32
     22       6.228690e+05      -1.055091e+03 |       32
     23       6.221976e+05      -6.714623e+02 |       32
     24       6.217410e+05      -4.565841e+02 |       32
     25       6.214565e+05      -2.845195e+02 |       32
     26       6.212545e+05      -2.019371e+02 |       32
     27       6.210824e+05      -1.721253e+02 |       32
     28       6.209103e+05      -1.721249e+02 |       32
     29       6.206956e+05      -2.146546e+02 |       32
     30       6.204197e+05      -2.759403e+02 |       32
     31       6.200632e+05      -3.565200e+02 |       32
     32       6.197842e+05      -2.790072e+02 |       32
     33       6.195590e+05      -2.251648e+02 |       32
     34       6.193612e+05      -1.978412e+02 |       32
     35       6.191611e+05      -2.000597e+02 |       32
     36       6.189837e+05      -1.774224e+02 |       32
     37       6.188214e+05      -1.622422e+02 |       32
     38       6.187157e+05      -1.057673e+02 |       32
     39       6.186798e+05      -3.586641e+01 |       30
     40       6.186620e+05      -1.781399e+01 |       30
     41       6.186507e+05      -1.124183e+01 |       28
     42       6.186381e+05      -1.267628e+01 |       30
     43       6.186285e+05      -9.587521e+00 |       31
     44       6.186210e+05      -7.483041e+00 |       29
     45       6.186167e+05      -4.329745e+00 |       26
     46       6.186138e+05      -2.815443e+00 |       24
     47       6.186105e+05      -3.376887e+00 |       21
     48       6.186073e+05      -3.178598e+00 |       25
     49       6.186038e+05      -3.529882e+00 |       26
     50       6.185973e+05      -6.425719e+00 |       27
K-means terminated without convergence after 50 iterations (objv = 618597.3347272496)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.342438
[ Info: iteration 2, average log likelihood -1.308678
[ Info: iteration 3, average log likelihood -1.269593
[ Info: iteration 4, average log likelihood -1.226253
[ Info: iteration 5, average log likelihood -1.174442
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.110579
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      9
│     14
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.075834
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.105973
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.074307
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.070424
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      9
│     14
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.026612
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│     10
│     13
│     21
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.067959
[ Info: iteration 13, average log likelihood -1.112647
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.057365
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      7
│      9
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.031428
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     10
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.049709
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     14
│     21
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.074380
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.090619
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.058367
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     13
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.030702
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      4
│     14
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.053432
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│      9
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.079664
[ Info: iteration 23, average log likelihood -1.093719
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.048261
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      9
│     10
│     13
│     14
│     25
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.010157
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.115839
[ Info: iteration 27, average log likelihood -1.095777
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.053632
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      9
│     10
│     13
│     14
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.029173
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     21
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.087431
[ Info: iteration 31, average log likelihood -1.108530
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.064318
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      7
│      9
│     10
│     14
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.012118
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.100111
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.086733
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.058329
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      9
│     10
│     13
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.040212
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.087798
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.056139
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.052393
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      9
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.052909
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     13
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.064948
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.072354
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     14
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.025517
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      7
│     10
│     13
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.057866
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.093345
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.051707
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.080533
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     10
│     21
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.043492
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     13
│     14
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
32×26 Array{Float64,2}:
[ Info: iteration 50, average log likelihood -1.041191
┌ Info: EM with 100000 data points 50 iterations avll -1.041191
└ 59.0 data points per parameter
  0.108168     -0.101539    -0.110527     -0.0872865   -0.278863     0.0141357  -0.132009     0.00757974   0.0565844   -0.0538182    0.170925     0.0450039    0.0226438    0.059139    -0.0515984    0.107822   -0.1137      -0.113184    -0.0665834   -0.0356337     0.269121     0.0974743    0.32777    -0.0709807   -0.0847296   -0.00993271
 -0.174582      0.0336807    0.0864131     0.0370589    0.0414777   -0.047375   -0.00734652   0.0355024   -0.173499     0.0041352   -0.0218973    0.12891     -0.184017    -0.0634629   -0.141464    -0.0321012   0.0580249   -0.0643122    0.030322     0.0348223     0.117539    -0.0826951   -0.0523305  -0.00504741  -0.0583987    0.0884687
  0.0179919    -0.0453226    0.0686807     0.0833342   -0.102584    -0.106382    0.0499189    0.0612825   -0.00136547   0.206935     0.0623823   -0.0274213    0.261111     0.0101166   -0.114396    -0.0379285  -0.231754     0.199025     0.0851985    0.0629223     0.0229222   -0.104971    -0.0240558   0.0120122    0.142423     0.0743634
  0.0531394     0.015259    -0.0570853     0.170084     0.133718    -0.209508   -0.0390821   -0.0292503   -0.0280982   -0.0298131    0.0951194   -0.0976421    0.0309302    0.0694676   -0.0714242    0.191579   -0.0588912    0.0112353    0.024429     0.0423633    -0.00805932  -0.0627413    0.181386   -0.0818022    0.0890266    0.0504814
  0.171265     -0.0528478    0.172279     -0.0226532    0.0482383   -0.099974    0.0252536   -0.0287308   -0.0072419   -0.122265    -0.052353     0.313248    -0.0120708    0.194201     0.0819888   -0.175362   -0.124186     0.0464864   -0.0109432    0.217247      0.0207564    0.155607     0.0916924  -0.0725669    0.026385    -0.0544084
 -0.220243      0.0214238   -0.0243652    -0.0237799   -0.00286903  -0.0220838   0.135491     0.0378558    0.0596145   -0.0573629   -0.0408015    0.0752737   -0.0683648   -0.03166      0.0272364   -0.0794588  -0.124949    -0.0295122   -0.0404326   -0.16159      -0.0308361    0.0401387   -0.0966085   0.0546227    0.0437158    0.0801174
 -0.00851542    0.102469    -0.0631438    -0.00776089  -0.0212657   -0.236138   -0.0769603   -0.00795106  -0.135397    -0.0398668   -0.075841     0.0231896   -0.0581868    0.345562    -0.0105602   -0.272467    0.113562     0.0497101    0.0889347    0.0350728     0.118691    -0.0342988    0.0468721  -0.0166898    0.0915222   -0.175202
  0.011935     -0.152727    -0.179386     -0.0067233   -0.100363    -0.0241839   0.0519618   -0.139708     0.0225141   -0.00331202   0.0671931    0.0665504    0.120235     0.139417     0.0413183    0.101637    0.0632276   -0.0648404   -0.127518     0.0591475     0.147504     0.0864422    0.101341    0.0252209    0.0727207   -0.109616
  0.0147179    -0.0496155    0.170384      0.00364613   0.0167557   -0.0185762  -0.059064    -0.0842548   -0.0283405   -0.0372569    0.0688422   -0.137875    -0.0904907   -0.0185207   -0.00296185  -0.0465672   0.0135351    0.174974     0.0285789    0.00205914    0.137013     0.0493768    0.106678   -0.1334      -0.0564546    0.199728
  0.100868     -0.152392    -0.065752     -0.0145568    0.0564188   -0.0462616  -0.105008     0.0151452   -0.0411194    0.0963823   -0.0693505   -0.0479001   -0.0841186    0.0022995   -0.154359    -0.0994143  -0.0489039   -0.00926775   0.181939     0.000873933   0.279997     0.123544     0.304375   -0.0804009   -0.181606    -0.0644498
  0.0608271     0.0502585    0.00861353   -0.0404373   -0.0454991    0.0462861  -0.0610001    0.0933115   -0.157282    -0.0181458    0.0855849    0.153781    -0.0732378    0.0749586   -0.166853    -0.0904715  -0.102622    -0.0764505   -0.0346769   -0.0612557    -0.239388     0.00818507  -0.120235    0.00399056   0.0030184    0.00758162
  0.000569323   0.0137578   -0.0707062    -0.113481     0.12515     -0.0763722   0.0606634   -0.0938512    0.0991929   -0.0891711   -0.0339187   -0.050269    -0.0588901    0.210225    -0.0791719   -0.103198    0.00568518  -0.162642     0.0436812    0.1492       -0.0638826   -0.0514905    0.114526   -0.0441846    0.190938     0.0971991
  0.0350158    -0.0583684    0.0317065     0.0681978    0.0184824    0.053155    0.0742608   -0.157917     0.0729104    0.0167411   -0.151772    -0.00413919   0.0522346    0.0310452    0.0342708    0.135973   -0.0142506   -0.11666      0.0253457    0.0683361    -0.0863574    0.0122489    0.0520651   0.133978     0.00249683   0.18556
  0.0254929     0.227243     0.0260879    -0.125196    -0.0583287    0.0496607   0.0854101   -0.0846225   -0.0397703    0.069741    -0.0671308   -0.168735     0.0847501   -0.0542961   -0.00617894   0.0420953   0.0355954    0.00625361  -0.00466554   0.0305706     0.048434    -0.121784     0.184169   -0.0233769   -0.0230879   -0.14976
  0.0527327    -0.0605646    0.116423     -0.0150543   -0.00265583   0.089888   -0.209151    -0.0169998    0.023092     0.0382727    0.0164386   -0.146853    -0.0926137    0.0840433   -0.0697824   -0.0955883  -0.114518     0.00376309  -0.0832237   -0.0303794     0.0136118   -0.0261338   -0.0104596   0.0631242   -0.164618    -0.00772604
  0.022908     -0.0823499   -0.0199844    -0.054729    -0.0991511    0.0178714  -0.110706     0.0215201    0.0915046   -0.0149873    0.0308593    0.0142923   -0.143131    -0.126353    -0.00878365   0.0248838  -0.149657     0.0954878   -0.0887503    0.12305      -0.0769199    0.160337     0.144632    0.0254834    0.0423927   -0.0245495
  0.0348008    -0.0378345    0.00424024    0.0443148    0.158828     0.0215203  -0.0955094   -0.0180625   -0.0358092    0.131382    -0.0222533    0.0477447    0.0146078    0.0239311   -0.0382803   -0.0184375   0.0668412   -0.0121614   -0.0405921   -0.064487      0.00390319   0.0772644   -0.09726     0.063493    -0.0128811    0.000693183
  0.0543036     0.0924123    0.23001       0.00837616  -0.108042    -0.0241397   0.0383855   -0.129198     0.0385838   -0.196852     0.0362562    0.0234764    0.0881333    0.0131783   -0.122246     0.0261125   0.103386    -0.0148778   -0.0294818   -0.0451207    -0.0105139   -0.0327292   -0.0243218   0.0428201   -0.0418266    0.0471615
  0.137804      0.00192736   0.0605566    -0.00445014   0.0219758    0.0158427   0.0816614   -0.20396     -0.00115841   0.0663705   -0.0788253    0.0812397    0.0219946    0.124908    -0.11597     -0.0897176   0.170464     0.105775     0.08852     -0.188007      0.13961      0.0881593    0.0955204  -0.0725183   -0.0497485    0.0505172
 -0.163329     -0.0247648    0.0704486     0.0446911    0.135875     0.244232    0.0242298   -0.121144    -0.127197    -0.0746887    0.173665    -0.0466658   -0.0778542    0.281585     0.0945146    0.0451822  -0.170844     0.056646    -0.167606     0.0618172    -0.076545    -0.0266539   -0.10686     0.0861376   -0.0808686   -0.0168018
 -0.0258961    -0.0245676   -0.000870726   0.0010612   -0.0219752   -0.171597   -0.135654    -0.0312355    0.0114679   -0.0577605   -0.0608343    0.0546904    0.0418757    0.0859177   -0.0991116   -0.270862    0.119045     0.0842758    0.00753399   0.00612934    0.130324    -0.0490922    0.0246068   0.0271824    0.136208    -0.167674
 -0.0773408    -0.0402544   -0.029893     -0.112964    -0.0890602    0.243935   -0.0956181   -0.124123     0.00878476   0.155308     0.188112    -0.127767    -0.0995024    0.123445     0.00314411   0.239999   -0.0395786   -0.0807617   -0.147469    -0.0530656    -0.189671    -0.0358579   -0.0939163  -0.154317    -0.0773334    0.00676887
  0.0098221    -0.0759095    0.0204565     0.0559404   -0.0789286   -0.0563424   0.0355591   -0.197196    -0.10059     -0.0233503    0.0634466   -0.0681052    0.041974    -0.0568768   -0.135156    -0.0342086  -0.0688772    0.0515592   -0.07074     -0.0151019     0.19445      0.00102665  -0.151175    0.0361923   -0.0629087   -0.14793
 -0.0865592    -0.127484     0.0564974    -0.0957665   -0.18059      0.0477726  -0.112623     0.209214     0.139898     0.0778788    0.011845     0.0507367    0.00998928  -0.140128    -0.134373     0.0578429  -0.13571     -0.140662     0.127952    -0.0464598     0.00121267  -0.248442     0.0242754  -0.112287     0.074857     0.103053
 -0.0628911    -0.0996131   -0.279013      0.0774811    0.186312    -0.0631197   0.0172816   -0.0995145    0.0699878   -0.0761529   -0.00465526  -0.0442173    0.058378    -0.0600509   -0.202302     0.0492557  -0.0345998   -0.115781     0.183513    -0.034825      0.0682455    0.118738    -0.237013    0.182843     0.0656976   -0.131664
  0.0746954     0.527459    -0.130932     -0.0398234   -0.0989388    0.0544204   0.127916     0.0393982    0.157303     0.00557296   0.025433    -0.0233592    0.236704    -0.0152978    0.0141271    0.226934    0.0286533    0.0301993   -0.0187243    0.098296     -0.126488     0.19074     -0.140218   -0.128624    -0.183318     0.0596805
 -0.0458371    -0.71838     -0.16333      -0.049941    -0.265683    -0.0734789   0.239465    -0.0115291    0.160672     0.0147254    0.125573     0.0451362    0.293959    -0.00969879   0.0635307   -0.280664   -0.0524129   -0.117745    -0.025284     0.120729     -0.0600963    0.0843571   -0.207655   -0.0682524   -0.208921     0.0791208
 -0.0619847    -0.0865708   -0.04711      -0.0937835   -0.0100246   -0.199676    0.101326     0.14487      0.0624391   -0.0202375    0.0319155    0.0203866    0.24621     -0.0445226    0.0382428   -0.123538   -0.0188302    0.0540706    0.186897     0.015789      0.00243175   0.125226    -0.0780898   0.0782338   -0.00948713   0.230644
 -0.00678786    0.00884414   0.171468      0.0701763    0.0936027   -0.069875    0.0358055    0.160654     0.0018255   -0.0865836    0.0529525   -0.162395    -0.101642     0.0767002    0.138948     0.0709329  -0.0403946    0.0703906   -0.130217    -0.0120848     0.0642057   -0.0100156   -0.0408757  -0.239691     0.0661295   -0.0283089
  0.058371     -0.0915832   -0.167805     -0.0778804    0.161062    -0.122599    0.0639047   -0.021016    -0.106201    -0.0522431    0.125552     0.0228531   -0.135982    -0.023631    -0.0457348    0.01476     0.0651449   -0.1634       0.0364869    0.0280064     0.0867736   -0.0308421    0.0499085  -0.0415226   -0.099545    -0.0339166
 -0.0900549    -0.0480853   -0.115163     -0.0758259    0.0809365   -0.0185808   0.12365      0.0945845   -0.0238318   -0.207664     0.121292     0.0747864   -0.150393     0.0922473    0.1236       0.0028628   0.082898     0.0865727    0.0832467    0.0350864    -0.0567816    0.16344      0.238205    0.117938    -0.195103     0.203775
  0.0624805    -0.125041     0.0932713     0.187312     0.0086675    0.0445855   0.0254803   -0.121819     0.0326477   -0.168161     0.0325305    0.136918     0.091847     0.122379     0.14856     -0.104937    0.0283779    0.0163106   -0.113817     0.0680011    -0.0305278   -0.0615743   -0.198852    0.0562015   -0.0335253    0.0451121[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.098061
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.051443
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      9
│     10
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.017541
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      4
│      9
│     13
│     25
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.015935
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      9
│     10
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.048498
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      9
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.044628
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      4
│      9
│     10
│     13
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.025011
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      9
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.036776
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      7
│      9
│     14
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.042186
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      4
│      9
│     10
│     13
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.028167
┌ Info: EM with 100000 data points 10 iterations avll -1.028167
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0297282  -0.160653    -0.07462      0.0867342   -0.0104133   0.034975    -0.186009    -0.108553     0.0520776    0.0379704  -0.033324   -0.00192046   -0.0856688    0.000537578   0.0436145   -0.0505739   0.00752162    0.120195    -0.150993     -0.059902    -0.18898      0.00887939   0.024431      0.300083    -0.0311934    0.0890608
  0.0283644  -0.0972002   -0.042392    -0.10415      0.0776949   0.00722908  -0.0183884    0.0424268    0.0402269   -0.156501   -0.0513619  -0.0247353     0.127838    -0.01929       0.0783106   -0.0160352  -0.187899     -0.0508818   -0.0579523    -0.125281    -0.0768359    0.146626    -0.0251069    -0.0274959    0.090825     0.0163451
 -0.0737887   0.116231    -0.0153446   -0.0102073   -0.13142     0.125511     0.125295    -0.131845    -0.17072      0.159164    0.156436   -0.0192929     0.112115    -0.0972572     0.0681733    0.129919    0.000251776  -0.111177     0.0270147    -0.105305    -0.0912693    0.0255286   -0.0345219     0.226224    -0.134479    -0.0359772
 -0.0434889  -0.0613715    0.0610228    0.0121643   -0.0656899  -0.0868498    0.152223    -0.00865395  -0.169498     0.0533875  -0.143415    0.142254      0.0170379   -0.123416     -0.0897704    0.0770755  -0.0779491    -0.00956084  -0.0970223    -0.0482448   -0.0343204    0.220203     0.111695     -0.00696679  -0.022734     0.120261
  0.0371459   0.0593924   -0.0597681    0.274037     0.247988    0.0312498   -0.103065    -0.0845839    0.135556     0.146012   -0.102787   -0.176823      0.0197848    0.0789429     0.238485    -0.0389601  -0.0801172     0.1264       0.135949      0.169101     0.11556      0.0211388    0.0636688     0.00324765  -0.0197331    0.00283904
 -0.0755175  -0.0229712    0.0167846    0.174733    -0.123508    0.135367     0.0214388   -0.0504723   -0.0411847   -0.0300294   0.0787938   0.0609931    -0.0241966    0.103344     -0.0892286    0.0158958   0.0290047     0.0716113    0.0321223     0.0944415   -0.0708464    0.0342692    0.0212879    -0.116593    -0.0160846   -0.129192
 -0.199039   -0.0364257   -0.0016446   -0.00875245   0.0522767   0.136886     0.00456808  -0.147511    -0.0914974   -0.285561    0.106456   -0.0568293    -0.0492418    0.0312333    -0.0841475    0.0617425   0.0976481    -0.00452154  -0.0819811     0.209431     0.0601734    0.0161559   -0.0979714     0.0147676   -0.0735339   -0.203545
 -0.0457942  -0.189097    -0.0329122   -0.0497663   -0.078337   -0.0708071    0.201448    -0.0524548   -0.0292665   -0.0199351   0.0277815  -0.138257      0.183076     0.157646     -0.00725765   0.150608    0.144301     -0.073171    -0.100734      8.68251e-5  -0.0269675   -0.0303691    0.0202512     0.0156699    0.0630348    0.238304
  0.0742645  -0.0254243    0.0736241    0.0277233    0.0681705   0.0884796    0.0994753    0.00406745  -0.0202912    0.0714966  -0.0175704  -0.186888      0.0684083    0.0167834    -0.0502687   -0.22766    -0.0425495     0.0352358    0.0417459    -0.0501014   -0.210352     0.14341      0.139682      0.14737     -0.163414    -0.0204724
  0.1079      0.0566658    0.163425    -0.0595925    0.0165658   0.0982478   -0.0383504    0.0162414   -0.0116843    0.0771648   0.0741996  -0.0314308    -0.159028    -0.0466482     0.120927     0.106882    0.001216      0.00731959  -0.0826767    -0.00619949  -0.0555139    0.011677    -0.183352     -0.00622649  -0.0236204    0.0794193
  0.192862    0.136777     0.295787    -0.0113411   -0.0930808   0.113376     0.00645317   0.179507    -0.192046    -0.0837532   0.0475563  -0.214597      0.0657189    0.0326071    -0.102574    -0.0157214  -0.155397     -0.013118    -0.144579     -0.0166777    0.0436112    0.151399    -0.0280749     0.296845    -0.0397727    0.122858
  0.200816    0.0273751    0.0777184    0.0680694    0.0594132  -0.04348     -0.111101    -0.0964802    0.146556     0.0745781   0.101553    0.0242742    -0.211635    -0.0970237     0.117534     0.119516   -0.00891896   -0.0790012   -0.119478     -0.0315005    0.0372557   -0.177068    -0.101937     -0.215548    -0.148405     0.161038
 -0.122094    0.148284     0.15709     -0.0279729   -0.0120816   0.148814    -0.0542274   -0.0675698   -0.127531    -0.0951067  -0.0992835  -0.0138009    -0.082804     0.0693404    -0.019831     0.163076    0.216356     -0.00739838   0.0825568     0.083556     0.166887     0.0802757    0.070689      0.115738     0.0532332   -0.00270814
 -0.138945    0.0722982    0.116688     0.102526    -0.171597    0.00719508  -0.00537098  -0.145594     0.105584    -0.040819    0.0666787  -0.0693574     0.0702966   -0.0713177     0.0917019    0.0189743   0.154108     -0.0816959    0.0203335     0.0744901    0.188674     0.0700997    0.165694      0.0306594    0.0667285    0.125835
  0.0998981   0.0820465   -0.141678     0.175368     0.0887164   0.0326044    0.0884611   -0.0735497    0.155359    -0.164254    0.0975346   0.00861157   -0.0170165    0.0550982    -0.271938     0.0806404   0.0146903    -0.0480739    0.156407      0.0160289    0.123583     0.0660884   -0.022112      0.0159816    0.220165    -0.0200025
 -0.166806    0.0253371   -0.25666      0.0482877    0.0418355   0.246833     0.0837092   -0.0274359   -0.099606     0.0408671  -0.0228903  -0.0476316     0.136564    -0.0686471    -0.0464407   -0.137478    0.0667723     0.0121454   -0.0746149    -0.110873    -0.0843722    0.0910852   -0.0678086    -0.136779    -0.0356535    0.122099
  0.0352765   0.0129382    0.030323    -0.0227428    0.0268029  -0.0871076   -0.010191    -0.0392456   -0.0159052   -0.0972414  -0.0844122  -0.0374168     0.0855693   -0.117308     -0.108353    -0.0566559   0.012543     -0.0175211   -0.110782      0.0404728    0.110005     0.113528     0.0205954    -0.0398129   -0.0579866   -0.147297
 -0.122338    0.00985756  -0.0645516    0.0717959    0.119289    0.0367411    0.0526745    0.0154808   -0.182371     0.0441022   0.154392   -0.00151095    0.0247836    0.126219      0.0777181   -0.15155    -0.122438     -0.00815109  -0.0368072     0.134681     0.0363997   -0.0207142   -0.098522      0.188603    -0.0454952   -0.135874
 -0.0552803  -0.176442     0.0477221    0.140108     0.0413853   0.0317274    0.118085     0.17332     -0.0687619   -0.25238     0.0180079  -0.000464035   0.0669184    0.0457233     0.0381227   -0.0349793  -0.177551      0.150176    -0.0404662     0.150518     0.00499496  -0.0650005   -0.0792328     0.00828518   0.0564355    0.0567341
 -0.115086    0.0661136   -0.123877     0.127307     0.166226    0.0862357    0.0131399   -0.0546051   -0.10293      0.109253    0.0187313   0.0895223     0.0498419   -0.220129     -0.1811      -0.072397    0.0535856     0.0138596    0.0215555     0.0353661   -0.022532     0.0415237   -0.117541      0.0900781   -0.00638792  -0.0343414
  0.0969214  -0.0892298   -0.16252     -0.178971     0.184344    0.0594551   -0.125258    -0.0744602    0.00417945  -0.014224   -0.0234994  -0.0635031    -0.082825     0.101158      0.0356105   -0.13904    -0.179119     -0.241152    -0.0311372     0.0963878   -0.0150644    0.0077815    0.000593546   0.100975    -0.163886     0.118863
  0.0645202   0.0937009    0.112395     0.00728515  -0.17512     0.0714767    0.0710556    0.0993383   -0.154337     0.0217572  -0.0689658   0.0625492    -0.00321541  -0.0597028     0.12684     -0.191427   -0.0561745    -0.064735    -0.0632426     0.0294903    0.0801205   -0.115164    -0.0943274     0.11214      0.0543677   -0.0743212
 -0.045521   -0.0808544    0.0399446    0.00895489  -0.0305223  -0.0628972   -0.159912     0.024955     0.0167131    0.16437    -0.0224824   0.0369345    -0.134489     0.0186524     0.042493     0.0708751   0.0792681    -0.127463    -0.0372405     0.125476     0.0196294    0.0969302   -0.0894949    -0.0110007   -0.0471652    0.0448474
 -0.178873   -0.105013     0.0332934    0.00184829  -0.0385689   0.0188699   -0.0402109    0.0582291   -0.0530847   -0.023088    0.115105    0.0628841     0.166942     0.0850489    -0.0480049   -0.0819768   0.0509769     0.020616     0.0456868     0.121762    -0.120793    -0.0898425   -0.120582      0.0477613   -0.0584219    0.06124
  0.0303394  -0.068254     0.0768655   -0.105237    -0.135465   -0.0318896   -0.0693915   -0.0570051   -0.15644      0.0478449   0.0344208   0.13506      -0.152697     0.190929      0.115446    -0.0661919  -0.0116733    -0.0788669    0.000511472  -0.101291     0.00272808  -0.060238    -0.0909337    -0.0767749   -0.0766598   -0.0804025
  0.0334323  -0.214623    -0.160183     0.00713543  -0.116964   -0.0685692   -0.0736049    0.1013       0.024922     0.0497912   0.0166011  -0.00801689   -0.106079     0.229719      0.0103874    0.0885228  -0.0948128     0.245214    -0.102685      0.0388612    0.0612521    0.0202406   -0.0576738     0.0660366    0.0844409   -0.0767199
  0.14163     0.127507    -0.0421268   -0.00680803   0.051736   -0.0265617   -0.0677304    0.0923084    0.0304995    0.0502105   0.0667892   0.0852801     0.19318      0.010324     -0.0300467   -0.110537   -0.031251      0.034617     0.080631      0.0349838    0.140564    -0.150587     0.039546     -0.0144842    0.0272244   -0.0153502
 -0.0197436  -0.0581524   -0.0225008    0.0117507    0.0600066   0.0632743    0.0339519    0.12542      0.0130232   -0.0152275  -0.0106121   0.139672      0.0239102    0.102245      0.0194872    0.0825083  -0.0455092     0.0713208   -0.0323312     0.0581329   -0.0663526   -0.0163547    0.0580424     0.0512065   -0.156129    -0.0771524
  0.0398058  -0.202298     0.00940906  -0.131564     0.0563919   0.100603    -0.0198902    0.15077     -0.0179689    0.0427595   0.157346    0.0279665    -0.173731    -0.247358      0.085789    -0.174399   -0.134597      0.192406    -0.00308334    0.14252      0.0713921   -0.158676     0.0686622     0.0221843    0.0920144    0.00227545
 -0.026217    0.156828    -0.153696     0.0563237    0.218321   -0.106082    -0.0370529   -0.0919613    0.120762    -0.017027   -0.0542247  -0.288473     -0.00911883  -0.113044     -0.159294     0.0373054  -0.155808      0.129693    -0.0647564    -0.0285892   -0.106598     0.141612     0.114024      0.0927105    0.0221499    0.222963
 -0.126881    0.122843     0.0410437    0.00489043  -0.0713676  -0.0154891    0.0280479   -0.283777    -0.0992403    0.245213   -0.0749968  -0.00906554    0.169176    -0.0664463     0.0177031   -0.143636    0.0482937     0.15729     -0.0849353    -0.0813428    0.00921769  -0.0624527    0.0168162    -0.0545088    0.104456     0.136909
  0.249916    0.100075    -0.0237333   -0.124473     0.0270994  -0.00994446  -0.0605508    0.147566     0.0858294   -0.0738448   0.130684   -0.134977      0.0253068    0.00924914    0.198079     0.253541   -0.0859658     0.0432142   -0.0907846    -0.173951     0.0422506   -0.0868191    0.0501028    -0.00803213  -0.085722     0.00594323kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.429375039700027
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.429394
[ Info: iteration 2, average log likelihood -1.429337
[ Info: iteration 3, average log likelihood -1.429298
[ Info: iteration 4, average log likelihood -1.429255
[ Info: iteration 5, average log likelihood -1.429203
[ Info: iteration 6, average log likelihood -1.429139
[ Info: iteration 7, average log likelihood -1.429053
[ Info: iteration 8, average log likelihood -1.428916
[ Info: iteration 9, average log likelihood -1.428654
[ Info: iteration 10, average log likelihood -1.428120
[ Info: iteration 11, average log likelihood -1.427157
[ Info: iteration 12, average log likelihood -1.425882
[ Info: iteration 13, average log likelihood -1.424802
[ Info: iteration 14, average log likelihood -1.424218
[ Info: iteration 15, average log likelihood -1.423984
[ Info: iteration 16, average log likelihood -1.423899
[ Info: iteration 17, average log likelihood -1.423869
[ Info: iteration 18, average log likelihood -1.423857
[ Info: iteration 19, average log likelihood -1.423853
[ Info: iteration 20, average log likelihood -1.423851
[ Info: iteration 21, average log likelihood -1.423850
[ Info: iteration 22, average log likelihood -1.423850
[ Info: iteration 23, average log likelihood -1.423849
[ Info: iteration 24, average log likelihood -1.423849
[ Info: iteration 25, average log likelihood -1.423849
[ Info: iteration 26, average log likelihood -1.423849
[ Info: iteration 27, average log likelihood -1.423849
[ Info: iteration 28, average log likelihood -1.423849
[ Info: iteration 29, average log likelihood -1.423849
[ Info: iteration 30, average log likelihood -1.423849
[ Info: iteration 31, average log likelihood -1.423849
[ Info: iteration 32, average log likelihood -1.423848
[ Info: iteration 33, average log likelihood -1.423848
[ Info: iteration 34, average log likelihood -1.423848
[ Info: iteration 35, average log likelihood -1.423848
[ Info: iteration 36, average log likelihood -1.423848
[ Info: iteration 37, average log likelihood -1.423848
[ Info: iteration 38, average log likelihood -1.423848
[ Info: iteration 39, average log likelihood -1.423848
[ Info: iteration 40, average log likelihood -1.423848
[ Info: iteration 41, average log likelihood -1.423848
[ Info: iteration 42, average log likelihood -1.423848
[ Info: iteration 43, average log likelihood -1.423848
[ Info: iteration 44, average log likelihood -1.423848
[ Info: iteration 45, average log likelihood -1.423848
[ Info: iteration 46, average log likelihood -1.423848
[ Info: iteration 47, average log likelihood -1.423848
[ Info: iteration 48, average log likelihood -1.423848
[ Info: iteration 49, average log likelihood -1.423848
[ Info: iteration 50, average log likelihood -1.423848
┌ Info: EM with 100000 data points 50 iterations avll -1.423848
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4293936387128174
│     -1.4293368600900975
│      ⋮
└     -1.423848029123485
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423866
[ Info: iteration 2, average log likelihood -1.423808
[ Info: iteration 3, average log likelihood -1.423767
[ Info: iteration 4, average log likelihood -1.423722
[ Info: iteration 5, average log likelihood -1.423668
[ Info: iteration 6, average log likelihood -1.423607
[ Info: iteration 7, average log likelihood -1.423542
[ Info: iteration 8, average log likelihood -1.423477
[ Info: iteration 9, average log likelihood -1.423419
[ Info: iteration 10, average log likelihood -1.423369
[ Info: iteration 11, average log likelihood -1.423327
[ Info: iteration 12, average log likelihood -1.423292
[ Info: iteration 13, average log likelihood -1.423260
[ Info: iteration 14, average log likelihood -1.423229
[ Info: iteration 15, average log likelihood -1.423198
[ Info: iteration 16, average log likelihood -1.423164
[ Info: iteration 17, average log likelihood -1.423128
[ Info: iteration 18, average log likelihood -1.423090
[ Info: iteration 19, average log likelihood -1.423051
[ Info: iteration 20, average log likelihood -1.423011
[ Info: iteration 21, average log likelihood -1.422972
[ Info: iteration 22, average log likelihood -1.422935
[ Info: iteration 23, average log likelihood -1.422902
[ Info: iteration 24, average log likelihood -1.422872
[ Info: iteration 25, average log likelihood -1.422846
[ Info: iteration 26, average log likelihood -1.422824
[ Info: iteration 27, average log likelihood -1.422805
[ Info: iteration 28, average log likelihood -1.422789
[ Info: iteration 29, average log likelihood -1.422775
[ Info: iteration 30, average log likelihood -1.422763
[ Info: iteration 31, average log likelihood -1.422753
[ Info: iteration 32, average log likelihood -1.422744
[ Info: iteration 33, average log likelihood -1.422736
[ Info: iteration 34, average log likelihood -1.422728
[ Info: iteration 35, average log likelihood -1.422722
[ Info: iteration 36, average log likelihood -1.422716
[ Info: iteration 37, average log likelihood -1.422711
[ Info: iteration 38, average log likelihood -1.422706
[ Info: iteration 39, average log likelihood -1.422701
[ Info: iteration 40, average log likelihood -1.422697
[ Info: iteration 41, average log likelihood -1.422693
[ Info: iteration 42, average log likelihood -1.422689
[ Info: iteration 43, average log likelihood -1.422685
[ Info: iteration 44, average log likelihood -1.422682
[ Info: iteration 45, average log likelihood -1.422679
[ Info: iteration 46, average log likelihood -1.422676
[ Info: iteration 47, average log likelihood -1.422673
[ Info: iteration 48, average log likelihood -1.422671
[ Info: iteration 49, average log likelihood -1.422668
[ Info: iteration 50, average log likelihood -1.422666
┌ Info: EM with 100000 data points 50 iterations avll -1.422666
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4238663704788075
│     -1.423807557571704
│      ⋮
└     -1.4226660782562828
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422675
[ Info: iteration 2, average log likelihood -1.422624
[ Info: iteration 3, average log likelihood -1.422583
[ Info: iteration 4, average log likelihood -1.422538
[ Info: iteration 5, average log likelihood -1.422484
[ Info: iteration 6, average log likelihood -1.422419
[ Info: iteration 7, average log likelihood -1.422341
[ Info: iteration 8, average log likelihood -1.422250
[ Info: iteration 9, average log likelihood -1.422151
[ Info: iteration 10, average log likelihood -1.422048
[ Info: iteration 11, average log likelihood -1.421950
[ Info: iteration 12, average log likelihood -1.421862
[ Info: iteration 13, average log likelihood -1.421788
[ Info: iteration 14, average log likelihood -1.421727
[ Info: iteration 15, average log likelihood -1.421677
[ Info: iteration 16, average log likelihood -1.421636
[ Info: iteration 17, average log likelihood -1.421600
[ Info: iteration 18, average log likelihood -1.421568
[ Info: iteration 19, average log likelihood -1.421537
[ Info: iteration 20, average log likelihood -1.421508
[ Info: iteration 21, average log likelihood -1.421479
[ Info: iteration 22, average log likelihood -1.421449
[ Info: iteration 23, average log likelihood -1.421418
[ Info: iteration 24, average log likelihood -1.421387
[ Info: iteration 25, average log likelihood -1.421355
[ Info: iteration 26, average log likelihood -1.421322
[ Info: iteration 27, average log likelihood -1.421290
[ Info: iteration 28, average log likelihood -1.421259
[ Info: iteration 29, average log likelihood -1.421229
[ Info: iteration 30, average log likelihood -1.421201
[ Info: iteration 31, average log likelihood -1.421175
[ Info: iteration 32, average log likelihood -1.421150
[ Info: iteration 33, average log likelihood -1.421128
[ Info: iteration 34, average log likelihood -1.421108
[ Info: iteration 35, average log likelihood -1.421090
[ Info: iteration 36, average log likelihood -1.421073
[ Info: iteration 37, average log likelihood -1.421058
[ Info: iteration 38, average log likelihood -1.421045
[ Info: iteration 39, average log likelihood -1.421032
[ Info: iteration 40, average log likelihood -1.421020
[ Info: iteration 41, average log likelihood -1.421009
[ Info: iteration 42, average log likelihood -1.420999
[ Info: iteration 43, average log likelihood -1.420990
[ Info: iteration 44, average log likelihood -1.420981
[ Info: iteration 45, average log likelihood -1.420972
[ Info: iteration 46, average log likelihood -1.420964
[ Info: iteration 47, average log likelihood -1.420957
[ Info: iteration 48, average log likelihood -1.420950
[ Info: iteration 49, average log likelihood -1.420943
[ Info: iteration 50, average log likelihood -1.420936
┌ Info: EM with 100000 data points 50 iterations avll -1.420936
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4226748376998617
│     -1.4226240218243462
│      ⋮
└     -1.420936082958345
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420938
[ Info: iteration 2, average log likelihood -1.420873
[ Info: iteration 3, average log likelihood -1.420812
[ Info: iteration 4, average log likelihood -1.420742
[ Info: iteration 5, average log likelihood -1.420658
[ Info: iteration 6, average log likelihood -1.420556
[ Info: iteration 7, average log likelihood -1.420438
[ Info: iteration 8, average log likelihood -1.420310
[ Info: iteration 9, average log likelihood -1.420178
[ Info: iteration 10, average log likelihood -1.420048
[ Info: iteration 11, average log likelihood -1.419926
[ Info: iteration 12, average log likelihood -1.419813
[ Info: iteration 13, average log likelihood -1.419710
[ Info: iteration 14, average log likelihood -1.419619
[ Info: iteration 15, average log likelihood -1.419539
[ Info: iteration 16, average log likelihood -1.419469
[ Info: iteration 17, average log likelihood -1.419408
[ Info: iteration 18, average log likelihood -1.419357
[ Info: iteration 19, average log likelihood -1.419312
[ Info: iteration 20, average log likelihood -1.419274
[ Info: iteration 21, average log likelihood -1.419241
[ Info: iteration 22, average log likelihood -1.419212
[ Info: iteration 23, average log likelihood -1.419186
[ Info: iteration 24, average log likelihood -1.419162
[ Info: iteration 25, average log likelihood -1.419141
[ Info: iteration 26, average log likelihood -1.419122
[ Info: iteration 27, average log likelihood -1.419104
[ Info: iteration 28, average log likelihood -1.419087
[ Info: iteration 29, average log likelihood -1.419071
[ Info: iteration 30, average log likelihood -1.419056
[ Info: iteration 31, average log likelihood -1.419042
[ Info: iteration 32, average log likelihood -1.419029
[ Info: iteration 33, average log likelihood -1.419017
[ Info: iteration 34, average log likelihood -1.419005
[ Info: iteration 35, average log likelihood -1.418994
[ Info: iteration 36, average log likelihood -1.418983
[ Info: iteration 37, average log likelihood -1.418973
[ Info: iteration 38, average log likelihood -1.418964
[ Info: iteration 39, average log likelihood -1.418955
[ Info: iteration 40, average log likelihood -1.418946
[ Info: iteration 41, average log likelihood -1.418937
[ Info: iteration 42, average log likelihood -1.418929
[ Info: iteration 43, average log likelihood -1.418922
[ Info: iteration 44, average log likelihood -1.418914
[ Info: iteration 45, average log likelihood -1.418907
[ Info: iteration 46, average log likelihood -1.418900
[ Info: iteration 47, average log likelihood -1.418893
[ Info: iteration 48, average log likelihood -1.418886
[ Info: iteration 49, average log likelihood -1.418880
[ Info: iteration 50, average log likelihood -1.418874
┌ Info: EM with 100000 data points 50 iterations avll -1.418874
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.420938417492831
│     -1.4208733983283377
│      ⋮
└     -1.4188736401749782
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418876
[ Info: iteration 2, average log likelihood -1.418799
[ Info: iteration 3, average log likelihood -1.418721
[ Info: iteration 4, average log likelihood -1.418625
[ Info: iteration 5, average log likelihood -1.418503
[ Info: iteration 6, average log likelihood -1.418350
[ Info: iteration 7, average log likelihood -1.418171
[ Info: iteration 8, average log likelihood -1.417978
[ Info: iteration 9, average log likelihood -1.417783
[ Info: iteration 10, average log likelihood -1.417598
[ Info: iteration 11, average log likelihood -1.417432
[ Info: iteration 12, average log likelihood -1.417288
[ Info: iteration 13, average log likelihood -1.417166
[ Info: iteration 14, average log likelihood -1.417065
[ Info: iteration 15, average log likelihood -1.416981
[ Info: iteration 16, average log likelihood -1.416910
[ Info: iteration 17, average log likelihood -1.416850
[ Info: iteration 18, average log likelihood -1.416798
[ Info: iteration 19, average log likelihood -1.416752
[ Info: iteration 20, average log likelihood -1.416711
[ Info: iteration 21, average log likelihood -1.416673
[ Info: iteration 22, average log likelihood -1.416638
[ Info: iteration 23, average log likelihood -1.416606
[ Info: iteration 24, average log likelihood -1.416575
[ Info: iteration 25, average log likelihood -1.416546
[ Info: iteration 26, average log likelihood -1.416519
[ Info: iteration 27, average log likelihood -1.416492
[ Info: iteration 28, average log likelihood -1.416467
[ Info: iteration 29, average log likelihood -1.416443
[ Info: iteration 30, average log likelihood -1.416420
[ Info: iteration 31, average log likelihood -1.416398
[ Info: iteration 32, average log likelihood -1.416377
[ Info: iteration 33, average log likelihood -1.416356
[ Info: iteration 34, average log likelihood -1.416336
[ Info: iteration 35, average log likelihood -1.416317
[ Info: iteration 36, average log likelihood -1.416299
[ Info: iteration 37, average log likelihood -1.416281
[ Info: iteration 38, average log likelihood -1.416264
[ Info: iteration 39, average log likelihood -1.416248
[ Info: iteration 40, average log likelihood -1.416232
[ Info: iteration 41, average log likelihood -1.416216
[ Info: iteration 42, average log likelihood -1.416201
[ Info: iteration 43, average log likelihood -1.416186
[ Info: iteration 44, average log likelihood -1.416172
[ Info: iteration 45, average log likelihood -1.416158
[ Info: iteration 46, average log likelihood -1.416144
[ Info: iteration 47, average log likelihood -1.416131
[ Info: iteration 48, average log likelihood -1.416118
[ Info: iteration 49, average log likelihood -1.416105
[ Info: iteration 50, average log likelihood -1.416092
┌ Info: EM with 100000 data points 50 iterations avll -1.416092
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4188764105255744
│     -1.4187993457188872
│      ⋮
└     -1.4160921119608056
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.429375039700027
│     -1.4293936387128174
│     -1.4293368600900975
│     -1.4292981243746534
│      ⋮
│     -1.416117553252448
│     -1.4161047031148124
└     -1.4160921119608056
32×26 Array{Float64,2}:
 -0.00566506   0.0520454   0.442853   -0.26266    -0.464434    -0.0405806  -0.14721     0.211588    -0.17029     0.0115924   0.0610302  -0.266505    -1.07533     -0.546061   -0.292049     0.498766     0.0660333  -0.183825   -0.0764367  -0.192248    0.211881     0.321195    -0.649943     0.348962     0.00836044  -1.17075
 -0.0353501   -0.388746    0.466885    0.169427    0.213188    -0.258903    0.308159    0.468843    -0.0543766   0.445447    0.134304   -0.328647     0.307104    -0.151156    0.108079     0.194397     0.162709   -0.154905   -0.633231   -0.20482    -0.377957     0.460468    -0.527529     0.0810592   -0.0975244   -0.866215
  0.452939    -0.0821284   0.239007    0.0695025  -0.493867    -0.255622    0.382155    0.443665    -0.463008    0.174621    0.235168    0.655034    -0.43381     -0.308621    0.537335    -0.0798784    0.0488987  -0.5668      0.0563143   0.931811   -0.153841     0.282257    -0.626859    -0.0272706    0.00849114   0.245904
  0.512436    -0.132089    0.398394   -0.276532    0.856581    -0.494286   -0.0235101   0.557769    -0.116154   -0.304089    0.0536209   0.0900177   -0.518411    -0.391156    0.344275     0.173818    -0.094459   -0.30503    -0.106629   -0.361091    0.132507     0.312331    -0.158295     0.130262    -0.805559     0.649227
  0.23552      0.0365128  -0.112578    0.0780311   0.175385    -0.467179   -0.156989   -0.00553731   0.615874    0.0510321  -0.070946   -0.313796    -0.0327147    0.247824    0.0231267   -0.830359    -0.198835   -0.0131659  -0.660975   -1.04204     0.294       -0.124795    -0.0623108   -0.082719     0.6067      -0.373796
  1.17795     -0.0146882  -0.751769    0.083993    0.0172168   -0.710089   -0.561427    0.521751    -0.592505    1.0699      0.337082    0.647379    -0.0957937    0.0345921  -0.451464    -0.349651    -0.119246    0.0829213   0.209298   -0.355939   -0.511201    -0.430598    -0.115672    -0.205384     0.933759     0.0449805
  0.595588     0.773699   -0.0838571   0.194682    0.00809071   0.6679     -0.103847   -0.27748     -0.301394    0.19152     0.102913    0.384066     0.46734     -0.489039   -0.603786    -0.499971    -0.34374     0.0116236  -0.634422    0.548558   -0.369527     0.862359     0.144066     0.31859      0.0971699   -0.216452
  0.460262     0.483962    0.0280557  -0.0927678  -0.0887663    0.335665   -0.129003    0.178613     0.270412   -0.238404   -0.135169   -0.280039    -0.0903486   -0.447263    0.103327    -0.176644    -0.727827    0.0188668   0.32119     0.0753783   0.0689863   -0.0296221   -0.0377266    0.0568137    0.21815      0.16779
 -0.280478    -0.538005   -0.207294   -0.146368   -0.490083    -0.557228    0.0265941  -0.162406    -0.0944669   0.325235   -0.113219    0.0501732    0.0857245   -0.520086   -0.206664     0.179435    -0.337281    0.383774    0.0116464  -0.219309   -0.548559    -0.216381     0.10909      0.824017     0.152694    -0.0700318
 -0.457766    -1.06593    -0.65572    -0.305636   -0.222088     0.542136    0.100953   -0.0168218    0.0670638   0.460599    0.0233138  -0.107705     0.159293    -0.168493   -0.436224    -0.00870374   0.395019   -0.0101631  -0.203171    0.07911    -0.621287    -0.188002     0.228904    -0.419126    -0.356623    -0.000896953
 -0.0792942   -0.220608   -1.0035      0.465505    0.355045    -0.0570266   0.353481    0.195381     0.319883    0.467567   -0.297296   -0.595946    -0.258659     0.498389    0.0748026    0.151172    -0.622033   -0.145854   -0.330358   -0.320672   -0.203628     0.238481     0.32961      0.540441    -0.150902     0.510231
 -0.337291    -0.207728   -0.471163    0.488735    0.651855     0.372247    0.080417   -0.28764      0.0703617   0.0409953   0.149598   -0.288573     1.22499      0.741179    0.154477    -0.393097    -0.445564    0.406275   -0.0806407  -0.0195516  -0.236891    -0.1837       0.834869    -0.208397    -0.369373     0.51936
 -1.02734     -0.361316    0.0909047  -0.0777424  -0.188873     0.553353    0.177628   -0.103261     0.234177   -0.49151    -0.366742   -0.962844     0.0809712   -0.0911112   0.359599     0.65259     -0.142393   -0.159064    0.0497654   0.376512    0.763062     0.228829     0.583466    -0.143732    -0.410937     0.0323526
 -0.452939     0.615317   -0.0606355   0.0341103   0.370293    -0.0103604   0.596205   -0.511242     0.539207   -0.158766    0.182967   -0.95221     -0.0938968   -0.0166741   0.265316     0.220367     0.422176    0.369577    0.399031   -0.516345    0.844101    -0.00416106   0.0397463   -0.241881     0.387032    -0.0906392
 -0.357787    -0.247952    0.594445    0.0600599   0.211923     0.0623104  -0.305014   -0.19074     -0.494281    0.25346    -0.064247   -0.080526     0.384671     0.201574   -0.0872884   -0.150547     0.630448   -0.0278673  -0.0210535   0.323725   -0.0656753   -0.153408    -0.026149    -0.327129     0.185044    -0.805014
 -0.519587    -0.0764905  -0.195925    0.129678    0.0630802   -0.0521071   0.327807   -0.476796     0.0767672  -0.328489    0.438919    0.58942      0.0789546    0.228011    0.0810757    0.344538     0.417412    0.29214    -0.113935   -0.140557    0.0229143    0.00190723  -0.00669018   0.340438    -0.446207     0.323607
  0.0654302   -0.438515   -0.146522   -0.314552   -0.0393831   -0.129474   -0.10527    -0.419035    -0.472634    0.193974   -0.901604    0.164545     0.0125946    0.669748   -0.723055     0.650333     0.477472    0.457183   -0.847052    0.530206    0.163923     0.319722    -0.522313     0.141261    -0.018174     0.503195
 -0.312943    -0.217313   -0.154921    0.171721   -0.236226    -0.370191    0.125118    0.144723    -0.153296    0.261879    0.0933031   0.190339    -0.224996     1.03031    -0.409178     0.192396     0.75395    -0.104252    0.293459    0.156415    0.415165     0.0313901   -0.360077    -0.212276    -0.244245     0.295949
  0.340095     0.0613552   0.483102   -0.316609   -0.29164      0.29586     0.253718    0.0507355   -0.145978   -0.100797   -0.24268     0.240017    -0.576336     0.116925    0.210632    -0.00125602   0.682926    0.28508    -0.333131    0.0403157   0.611018    -0.546654    -0.284047     0.127358    -0.0304215    0.0346702
  0.0716254    0.319316    0.633261    0.0163783   0.252881    -0.0888575  -0.0162984  -0.273316    -0.415581   -0.41544     0.296756    0.350978     0.607527     0.272489    0.166496     0.0507894    0.734778    0.0699377   0.204899    0.420904    0.0434183   -0.219373     0.142944    -0.0349561    0.261415     0.107732
  0.155291    -0.0165087   0.0654911  -0.0815016  -0.0490149   -0.0647257  -0.0659196   0.11139     -0.0968118   0.115666   -0.0491599  -0.0121352   -0.0616693    0.0176541  -0.149        0.0120741   -0.0446501  -0.0582933   0.0764621   0.0447396   0.0198921   -0.017085    -0.0739413    0.0199707    0.0632072   -0.0239756
 -0.208741    -0.0233486  -0.103608    0.227565   -0.00319578   0.262026    0.328875    0.0329566    0.0141036  -0.106593    0.243386   -0.0812906    0.141848    -0.0667116   0.211405     0.219627     0.166996    0.0194823  -0.163451    0.242549   -0.00700155   0.252598    -0.323882     0.131478    -0.133881     0.076081
 -0.217018    -0.28697    -0.199706    0.343579    0.0491943   -0.726344    0.170437   -0.426607     0.0777744   0.0848016  -0.184983    0.405146     0.00507363   0.240291    0.00648944  -0.173969     0.226991    0.243667   -0.478787   -0.433946   -0.196158    -0.156254     0.277375     0.0842198    0.0713326    0.00048268
 -0.297124    -0.164067   -0.0872416   0.0881251   0.501711     0.403073   -0.471806   -0.434789     0.24688     0.0467919  -0.180798   -0.52738      0.244555     0.0250884  -0.138632     0.0703317   -0.193687    0.519761   -0.0263471  -0.371905   -0.0689192   -0.24538      0.298643     0.129832    -0.00605475  -0.230927
  0.557174     0.23888     0.156054   -0.497923   -0.593458     0.256801   -0.0102754  -0.0419296    0.279526   -0.0516667   0.218428   -0.354543     0.107088     0.027581   -0.435623     0.407106    -0.304937    0.0524891   0.697699    0.523611    0.252138    -0.113435    -0.570275    -0.0505286    0.319385     0.357566
 -0.0647188    0.401352   -0.569059    0.273569   -0.0319461    0.439009   -0.157893   -0.591709    -0.106018   -0.494197   -0.125029    0.165075    -0.291294     0.220985   -0.221598     0.129147     0.012644   -0.323729    0.507081    0.399159    0.202902    -0.26467      0.548386    -0.155287     0.169736     0.396034
  0.473866    -0.122364   -0.0205748  -0.15035    -0.205841     0.118133   -0.921414    0.512314    -0.310696    0.463592   -1.021       0.00316771  -0.241259    -0.342104   -0.110628    -0.279876    -0.188794    0.026609   -0.130899   -0.0873478   0.106021    -0.393946     0.400385    -0.508718     0.389501     0.102974
  0.171703    -0.164789    0.0834595  -0.202053   -0.139682     0.0679446  -0.57002     0.349533    -0.0769809   0.184558    0.211855   -0.225783     0.129642     0.0567839  -0.0448464   -0.445575    -0.588991   -0.217294    0.432238    0.237422   -0.114601    -0.048213     0.237137    -0.469996    -0.0458965    0.0391062
  0.0619463   -0.035056    0.273382   -0.350783    0.282509     0.180347    0.217661   -0.0592908    0.299248   -0.630474    0.031669   -0.0097004    0.0787637   -0.669862    0.439107     0.0409685   -0.635269   -0.476858   -0.05678    -0.291965   -0.248795    -0.0615102    0.274442     0.414164     0.0826896   -0.224218
  0.0951772    0.76822    -0.221111   -0.110608    0.0975879   -0.168106   -0.198636   -0.420137    -0.117307   -0.0579876   0.0927388   0.0498115   -0.0325758    0.0289695  -0.124876    -0.108555    -0.721982   -0.405688   -0.0793665  -0.203692   -0.213938     0.673664    -0.0576804    0.576863    -0.287442     0.425925
 -0.50701      0.165446    0.225843    0.494522    0.419918     0.458632    0.22751     0.249266    -0.195369   -0.43381     0.443081    0.100717    -0.0435968    0.0726353   0.697226    -0.430009     0.309254   -0.0941161  -0.334058   -0.0836321   0.154296     0.0457691   -0.00615257  -0.156298    -0.45661     -0.292196
  0.143422     0.675557    0.107158    0.139166   -0.125786     0.0720177   0.0994738   0.227331     0.163664   -0.0929052   0.390347    0.200175    -0.0322495   -0.298917    0.411192    -0.790111    -0.421246    0.7869      0.205111   -0.204992    0.257127    -0.0949365   -0.181729    -0.00506251   0.137149     0.0541603[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416080
[ Info: iteration 2, average log likelihood -1.416068
[ Info: iteration 3, average log likelihood -1.416056
[ Info: iteration 4, average log likelihood -1.416044
[ Info: iteration 5, average log likelihood -1.416033
[ Info: iteration 6, average log likelihood -1.416022
[ Info: iteration 7, average log likelihood -1.416011
[ Info: iteration 8, average log likelihood -1.416000
[ Info: iteration 9, average log likelihood -1.415989
kind full, method kmeans
[ Info: iteration 10, average log likelihood -1.415979
┌ Info: EM with 100000 data points 10 iterations avll -1.415979
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.007481e+05
      1       7.178689e+05      -1.828793e+05 |       32
      2       7.015473e+05      -1.632161e+04 |       32
      3       6.950345e+05      -6.512790e+03 |       32
      4       6.917727e+05      -3.261760e+03 |       32
      5       6.897805e+05      -1.992251e+03 |       32
      6       6.883566e+05      -1.423817e+03 |       32
      7       6.872174e+05      -1.139256e+03 |       32
      8       6.863093e+05      -9.080840e+02 |       32
      9       6.855894e+05      -7.198965e+02 |       32
     10       6.849916e+05      -5.978202e+02 |       32
     11       6.844807e+05      -5.108713e+02 |       32
     12       6.840466e+05      -4.341208e+02 |       32
     13       6.836415e+05      -4.051073e+02 |       32
     14       6.832534e+05      -3.881249e+02 |       32
     15       6.828920e+05      -3.613502e+02 |       32
     16       6.825526e+05      -3.394084e+02 |       32
     17       6.822497e+05      -3.029346e+02 |       32
     18       6.819817e+05      -2.679513e+02 |       32
     19       6.817701e+05      -2.115732e+02 |       32
     20       6.815873e+05      -1.828411e+02 |       32
     21       6.814151e+05      -1.721823e+02 |       32
     22       6.812630e+05      -1.521385e+02 |       32
     23       6.811306e+05      -1.324298e+02 |       32
     24       6.810113e+05      -1.192162e+02 |       32
     25       6.809040e+05      -1.073418e+02 |       32
     26       6.808089e+05      -9.513141e+01 |       32
     27       6.807272e+05      -8.164314e+01 |       32
     28       6.806502e+05      -7.699124e+01 |       32
     29       6.805760e+05      -7.418478e+01 |       32
     30       6.805112e+05      -6.483647e+01 |       32
     31       6.804562e+05      -5.498033e+01 |       32
     32       6.804012e+05      -5.498126e+01 |       32
     33       6.803417e+05      -5.952599e+01 |       32
     34       6.802809e+05      -6.079366e+01 |       32
     35       6.802218e+05      -5.913708e+01 |       32
     36       6.801697e+05      -5.209342e+01 |       32
     37       6.801237e+05      -4.598518e+01 |       32
     38       6.800829e+05      -4.083929e+01 |       32
     39       6.800469e+05      -3.599133e+01 |       32
     40       6.800148e+05      -3.205479e+01 |       32
     41       6.799846e+05      -3.026800e+01 |       32
     42       6.799571e+05      -2.741426e+01 |       32
     43       6.799314e+05      -2.573338e+01 |       32
     44       6.799102e+05      -2.118212e+01 |       32
     45       6.798917e+05      -1.856096e+01 |       32
     46       6.798747e+05      -1.696882e+01 |       32
     47       6.798577e+05      -1.696446e+01 |       32
     48       6.798408e+05      -1.692516e+01 |       32
     49       6.798257e+05      -1.510255e+01 |       32
     50       6.798110e+05      -1.473868e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 679810.9700785198)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.427934
[ Info: iteration 2, average log likelihood -1.422946
[ Info: iteration 3, average log likelihood -1.421602
[ Info: iteration 4, average log likelihood -1.420596
[ Info: iteration 5, average log likelihood -1.419525
[ Info: iteration 6, average log likelihood -1.418525
[ Info: iteration 7, average log likelihood -1.417834
[ Info: iteration 8, average log likelihood -1.417448
[ Info: iteration 9, average log likelihood -1.417235
[ Info: iteration 10, average log likelihood -1.417100
[ Info: iteration 11, average log likelihood -1.417003
[ Info: iteration 12, average log likelihood -1.416925
[ Info: iteration 13, average log likelihood -1.416860
[ Info: iteration 14, average log likelihood -1.416803
[ Info: iteration 15, average log likelihood -1.416752
[ Info: iteration 16, average log likelihood -1.416706
[ Info: iteration 17, average log likelihood -1.416663
[ Info: iteration 18, average log likelihood -1.416624
[ Info: iteration 19, average log likelihood -1.416587
[ Info: iteration 20, average log likelihood -1.416554
[ Info: iteration 21, average log likelihood -1.416523
[ Info: iteration 22, average log likelihood -1.416494
[ Info: iteration 23, average log likelihood -1.416468
[ Info: iteration 24, average log likelihood -1.416443
[ Info: iteration 25, average log likelihood -1.416420
[ Info: iteration 26, average log likelihood -1.416399
[ Info: iteration 27, average log likelihood -1.416379
[ Info: iteration 28, average log likelihood -1.416360
[ Info: iteration 29, average log likelihood -1.416343
[ Info: iteration 30, average log likelihood -1.416326
[ Info: iteration 31, average log likelihood -1.416310
[ Info: iteration 32, average log likelihood -1.416295
[ Info: iteration 33, average log likelihood -1.416280
[ Info: iteration 34, average log likelihood -1.416266
[ Info: iteration 35, average log likelihood -1.416253
[ Info: iteration 36, average log likelihood -1.416240
[ Info: iteration 37, average log likelihood -1.416228
[ Info: iteration 38, average log likelihood -1.416216
[ Info: iteration 39, average log likelihood -1.416204
[ Info: iteration 40, average log likelihood -1.416193
[ Info: iteration 41, average log likelihood -1.416182
[ Info: iteration 42, average log likelihood -1.416171
[ Info: iteration 43, average log likelihood -1.416161
[ Info: iteration 44, average log likelihood -1.416151
[ Info: iteration 45, average log likelihood -1.416141
[ Info: iteration 46, average log likelihood -1.416131
[ Info: iteration 47, average log likelihood -1.416122
[ Info: iteration 48, average log likelihood -1.416113
[ Info: iteration 49, average log likelihood -1.416104
32×26 Array{Float64,2}:
[ Info: iteration 50, average log likelihood -1.416095
┌ Info: EM with 100000 data points 50 iterations avll -1.416095
└ 59.0 data points per parameter
 -0.0889564   -0.30424     0.0503957  -0.235805     -0.36636    -0.172402    0.0211376   0.192314    0.139195     0.191039    -0.453533    -0.234146   -0.469837    -0.529154   -0.154697     0.347657   -0.259379    0.253563     -0.00107912  -0.669739   -0.166286    -0.172266   -0.134011    0.911045    0.146456   -0.450596
 -0.35231     -0.46176    -0.0495087   0.342445      0.391373   -0.442569   -0.166526   -0.443325    0.569908     0.147265    -0.107679    -0.53125     0.387982     0.552315   -0.229151    -0.315747   -0.133536    0.446702     -0.709122    -0.625317   -0.170824    -0.0744436   0.116597    0.0193362   0.208673   -0.331903
  0.104165    -0.173357   -0.163362   -0.250948     -0.0737144   0.084102    0.11247    -0.391509   -0.300528     0.137361    -0.772161     0.191265   -0.0444907    0.495024   -0.48891      0.540417    0.580515    0.565486     -0.816948     0.5795      0.345862     0.325468   -0.558925    0.243095    0.131899    0.465507
 -0.132438     0.169529    0.16763     0.37691      -0.0102963   0.110049   -0.184669    0.166832   -0.513179     0.0950031    0.315595     0.0531778   0.187965     0.0548057   0.104287    -0.373992   -0.103783   -0.189882     -0.236252     0.569936   -0.386587     0.516938   -0.509134    0.0677999  -0.22552    -0.00466658
 -0.694823     0.132645    0.0684705   0.589485      0.188711   -0.254964    0.334182   -0.666728    0.0262952   -0.453072     0.375851     0.852738    0.0904362    0.319223    0.251791     0.22458     0.652268    0.584502     -0.305208    -0.549761    0.0480542   -0.188078   -0.0287761   0.452484   -0.574878   -0.107978
 -0.0279758   -0.341017   -0.122835    0.278713     -0.44205    -0.637494    0.33838    -0.486539   -0.138164     0.194944    -0.0279743    0.556834   -0.0113212   -0.0078648   0.171387     0.0773569   0.361368    0.111396     -0.458161    -0.0252351  -0.105054    -0.358754    0.0671694   0.238958    0.357791    0.139802
 -0.825778    -0.778766   -0.538875    0.0288604     0.104688    0.590895   -0.013745   -0.417271    0.112165     0.292005     0.0163433   -0.379369    0.501588     0.236465   -0.182692    -0.0460959   0.250367    0.296938     -0.0867334    0.0683914  -0.300934    -0.365466    0.664532   -0.354674   -0.232299    0.0639285
 -0.202111    -0.347914   -0.445117    0.137641     -0.0794565   0.245375   -0.185713   -0.22096     0.038691    -0.0602151   -0.412593     0.0791648  -0.070599     0.0830219  -0.257475     0.0454744   0.129006   -0.179233      0.0400991    0.272985   -0.0747016   -0.24683     0.589435   -0.35172     0.0570435   0.130411
  0.552209     0.183442    0.378801   -0.337908      0.686497   -0.671055   -0.0416308   0.225937   -0.0510105   -0.63383     -0.00494134   0.225176   -0.710054    -0.389305    0.3403       0.140063   -0.336036   -0.708909      0.158069    -0.154939    0.123474     0.230968   -0.059528    0.314389   -0.400206    0.529025
  0.103295     0.95784    -0.379981    0.293331      0.383142    0.407726   -0.144265   -0.510734    0.129172    -0.0926243   -0.0718827   -0.357825    0.0933655    0.0493377   0.102853    -0.326039   -0.817586   -0.0562589     0.102096    -0.281142    0.11865      0.256331    0.500207    0.319395    0.163517    0.198769
 -0.0720873    0.32626     0.890689   -0.180613      0.3227     -0.0445202   0.174106   -0.297382   -0.571272    -0.468723    -0.0114856    0.254791    0.623225     0.198616    0.158419    -0.0471787   1.13831    -0.0205527     0.190041     0.309539    0.263268    -0.387323    0.314626    0.0383885   0.868296   -0.439165
  0.70224     -0.15176    -0.0511872  -0.267362     -0.441135   -0.0630783   0.0582069   0.469596   -0.120308     0.685011    -0.0832426   -0.339476   -0.23462     -0.070886   -0.411132    -0.042414   -0.29195    -0.415841      0.0861111    0.337872   -0.129431    -0.139227   -0.350468   -0.208032    0.327805   -0.00900465
 -0.636944     0.217884   -0.193818    0.27694      -0.329044    0.392381    0.0290537   0.132195   -0.242139    -0.379966     0.181779    -0.4644     -0.762758    -0.0269944   0.154734     0.713566    0.309732   -0.629738      0.108193     0.280997    0.981751     0.325985   -0.160293   -0.181231   -0.235698   -0.553568
  0.0387338    0.169414    0.14089    -0.0427561    -0.0424865   0.0685027   0.117226    0.0343459  -0.0311883   -0.129788     0.161625     0.0843921  -0.0545099    0.246643    0.0123337    0.0907103   0.236763   -0.0294251     0.105021     0.114478    0.292957    -0.0124445  -0.235239   -0.0466762  -0.0507559   0.110988
  0.352518     0.39301     0.187843   -0.357172     -0.623811    0.315977   -0.20586    -0.425178    0.1778      -0.330005     0.258558    -0.21108     0.00517968   0.0527623  -0.324521     0.392844   -0.373568    0.144468      0.997653     0.56125     0.170021    -0.215192   -0.333567    0.0430084   0.267367    0.355659
 -0.150358    -0.227226   -0.5529     -0.453077     -0.313853   -0.249008   -0.0149016  -0.349267   -0.324846     0.506402     0.208318     0.50795     0.00081666   0.0280784  -0.571502    -0.124752   -0.289067   -0.275458     -0.417938    -0.311363   -0.605659     0.398963   -0.0307905   0.437984   -0.610054    0.419929
  0.47145      0.242536    0.13455    -0.0599255    -0.143553    0.31988    -0.257168   -0.0117605  -0.169949    -0.180775    -0.0871169    0.294428    0.192171    -1.25253    -0.0410386   -0.142684   -0.538003   -0.0281322    -0.414667     0.402989   -0.547608     0.337269    0.0170669   0.308241    0.407608   -0.265321
 -0.50795      0.109133    0.429392   -0.253754      0.10638     0.604507    0.565846   -0.294314    0.489142    -1.02391      0.0455528   -0.276118    0.424435    -0.507772    0.539959     0.272383   -0.239236   -0.226294     -0.0405424    0.361454    0.112557     0.19942     0.124166    0.458788   -0.439092    0.158027
  0.0234314   -0.331651   -0.165745   -0.422703     -0.165587   -0.0208782  -0.679909    0.482704    0.116729     0.112755    -0.137357    -0.331413    0.176254     0.058462   -0.160534    -0.416496   -0.781334   -0.187494      0.578459     0.119206   -0.107814     0.124349    0.469029   -0.401565   -0.0689452   0.140594
  0.0689814    0.0350946   0.0428628   0.176394      0.39865     0.360496   -0.109107   -0.165814   -0.294774    -0.286302     0.458482     0.33158     0.677967     0.149108    0.280091    -0.114743    0.0258636   0.307954      0.45365      0.545809   -0.0780808   -0.183114    0.50952    -0.227945   -0.390094    0.519655
 -0.501768    -0.379216    0.179918    0.0597251     0.542091   -0.185095    0.162487   -0.344518   -0.586452     0.505184    -0.16875     -0.701655   -0.0197431    0.669165   -0.0241724    0.632141    0.209311   -0.499554      0.104186     0.0629069  -0.192719     0.24418    -0.178719    0.457611   -0.250445   -0.575058
 -0.103576    -0.268236   -1.08433     0.508283      0.385261   -0.0953799   0.468577    0.256485    0.326403     0.235929    -0.0997787   -0.442551   -0.0492172    0.50541     0.197339     0.137388   -0.65224    -0.0174613    -0.394575    -0.212969   -0.173776     0.248939    0.441659    0.446714   -0.283938    0.952844
  0.510388     0.0229402   0.297033   -0.190289     -0.0513625   0.182651   -1.13951     0.292223   -0.135676     0.282241    -0.490769    -0.396434    0.0331155   -0.122867    0.00572963  -0.293559   -0.118959    0.277217     -0.0515864   -0.14732     0.424497    -0.564501    0.211583   -0.914642    0.245636   -0.117899
  0.288325     0.097835    0.140302    0.0482121    -0.0590281  -0.0952755   0.04029     0.181993   -0.15253      0.113166     0.0878984    0.133753   -0.20436     -0.158204    0.0888776   -0.0131788  -0.0293279  -0.120543      0.0200905    0.142795    0.048053     0.109278   -0.301734    0.0319627   0.0437116  -0.00380046
  0.0113071   -0.293135    0.235645    0.266569      0.66744    -0.0255969   0.338413    0.842458   -0.0562659    0.0377889    0.119522     0.0493183   0.147927    -0.1817      0.566305    -0.506135    0.157884   -0.182352     -0.648631    -0.562351   -0.0419719    0.123247    0.253522   -0.28835    -0.251768   -0.509928
  0.00464047   0.805261    0.188125    0.161134     -0.226167    0.0128167   0.634348    0.275699    0.474146    -0.231732     0.529976    -0.28604    -0.046405    -0.179334    0.711069    -0.337867   -0.164022    0.513063      0.17161     -0.167925    0.500639     0.396345   -0.547127    0.0255817   0.494421   -0.321129
 -0.211372    -0.142726   -0.0255771   0.139858     -0.391389   -0.440454   -0.0140614   0.106424   -0.341567     0.218647    -0.00703556   0.56665    -0.215832     1.10947    -0.281666     0.061131    0.903992    0.000890777   0.330454     0.406661    0.33888     -0.0618916  -0.351349   -0.295307   -0.120428    0.474459
 -0.389751     0.208729   -0.318848   -0.000715107   0.545936    0.0461338   0.535534   -0.500287    0.476022    -0.160213     0.0371913   -0.679739   -0.166443     0.312249   -0.115123     0.161646    0.50621     0.133841      0.444622    -0.557183    0.752614    -0.386299    0.327052   -0.389586   -0.0723293   0.264196
  0.355243     0.282927    0.734658   -0.474174     -0.112363    0.885138    0.295057    0.358304   -0.177981    -0.205641    -0.22296     -0.123091   -0.989327    -0.104703    0.339331    -0.569014    0.572329    0.272789     -0.599187     0.120985    0.750767    -0.301958   -0.429164    0.223437   -0.408601   -0.309505
  0.623064     0.464591   -0.0195339   0.0833093    -0.120055   -0.335122   -0.324767    0.121345   -0.00331456   0.0855503    0.303688     0.803975   -0.0905776   -0.035308   -0.189129    -0.817421   -0.211904    0.427009      0.0908034   -0.411203   -0.00124922  -0.464305   -0.164232   -0.0496241   0.558902    0.159232
 -0.0590713   -0.59218     0.156872   -0.0847398    -0.090968    0.0879542   0.357411    0.605702    0.0275128    0.193761     0.44643      0.0822462   0.106926    -0.298451    0.0607187    0.622304    0.668701    0.15431      -0.365564     0.0456873  -0.309095     0.314477   -0.80739    -0.196258   -0.534316   -0.196896
 -0.054654    -0.0585227  -0.0076944  -0.00200025    0.145673    0.0333479  -0.0695388  -0.0540798   0.0765324    0.00393496   0.0156091   -0.140598    0.0979894   -0.235002    0.053384    -0.0561551  -0.296293    0.0981306    -0.0609717   -0.223984   -0.189        0.0349076   0.0891168   0.212616    0.0417952  -0.153788[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416086
[ Info: iteration 2, average log likelihood -1.416078
[ Info: iteration 3, average log likelihood -1.416070
[ Info: iteration 4, average log likelihood -1.416061
[ Info: iteration 5, average log likelihood -1.416053
[ Info: iteration 6, average log likelihood -1.416046
[ Info: iteration 7, average log likelihood -1.416038
[ Info: iteration 8, average log likelihood -1.416030
[ Info: iteration 9, average log likelihood -1.416023
[ Info: iteration 10, average log likelihood -1.416016
┌ Info: EM with 100000 data points 10 iterations avll -1.416016
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
