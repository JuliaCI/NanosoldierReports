Julia Version 1.4.0-DEV.667
Commit acb7bd93fb (2019-12-27 21:20 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed PDMats ───────────── v0.9.10
 Installed GaussianMixtures ─── v0.3.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed Blosc ────────────── v0.5.1
 Installed NearestNeighbors ─── v0.4.4
 Installed Arpack ───────────── v0.4.0
 Installed StaticArrays ─────── v0.12.1
 Installed Clustering ───────── v0.13.3
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed DataAPI ──────────── v1.1.0
 Installed Distances ────────── v0.8.2
 Installed Rmath ────────────── v0.6.0
 Installed OrderedCollections ─ v1.1.0
 Installed Parameters ───────── v0.12.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed SpecialFunctions ─── v0.9.0
 Installed CMake ────────────── v1.1.2
 Installed JLD ──────────────── v0.9.1
 Installed StatsFuns ────────── v0.9.3
 Installed BinDeps ──────────── v1.0.0
 Installed Missings ─────────── v0.4.3
 Installed StatsBase ────────── v0.32.0
 Installed QuadGK ───────────── v2.3.1
 Installed BinaryProvider ───── v0.5.8
 Installed Compat ───────────── v2.2.0
 Installed Distributions ────── v0.21.11
 Installed SortingAlgorithms ── v0.3.1
 Installed DataStructures ───── v0.17.6
 Installed FillArrays ───────── v0.8.2
 Installed OpenBLAS_jll ─────── v0.3.7+1
 Installed Arpack_jll ───────── v3.5.0+2
 Installed URIParser ────────── v0.4.0
 Installed LegacyStrings ────── v0.4.1
 Installed FileIO ───────────── v1.2.0
 Installed HDF5 ─────────────── v0.12.5
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_0oEssW/Project.toml`
 [no changes]
  Updating `/tmp/jl_0oEssW/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_9wcxwt/Project.toml`
 [no changes]
  Updating `/tmp/jl_9wcxwt/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_06Lbc0/Project.toml`
 [no changes]
  Updating `/tmp/jl_06Lbc0/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_Xu6RxL/Project.toml`
 [no changes]
  Updating `/tmp/jl_Xu6RxL/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_eNno0W/Project.toml`
 [no changes]
  Updating `/tmp/jl_eNno0W/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_eNno0W/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.0
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.187248584645236e6, [80769.40482411579, 19230.59517588423], [11687.018156585917 -6385.836369839869 18914.368050223085; -11652.178635231105 6235.768288009659 -18552.619036735552], [[79881.38790557509 -4079.497351099253 -10193.55835626855; -4079.497351099253 85636.9791892704 4461.328891047566; -10193.55835626855 4461.328891047566 76157.08351728716], [20807.451401023747 3749.6157414010645 9998.579863241082; 3749.6157414010645 14122.287253534027 -4664.4488427121905; 9998.579863241082 -4664.4488427121905 23875.70119144643]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.129374e+03
      1       9.449760e+02      -1.843984e+02 |        7
      2       9.001001e+02      -4.487596e+01 |        4
      3       8.785743e+02      -2.152579e+01 |        2
      4       8.717144e+02      -6.859887e+00 |        0
      5       8.717144e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 871.7144103553819)
┌ Info: K-means with 272 data points using 5 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.081664
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.846343
[ Info: iteration 2, lowerbound -3.702214
[ Info: iteration 3, lowerbound -3.533398
[ Info: iteration 4, lowerbound -3.329774
[ Info: iteration 5, lowerbound -3.115735
[ Info: iteration 6, lowerbound -2.923446
[ Info: iteration 7, lowerbound -2.782614
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.695362
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.631924
[ Info: dropping number of Gaussions to 3
[ Info: iteration 10, lowerbound -2.571785
[ Info: iteration 11, lowerbound -2.515530
[ Info: iteration 12, lowerbound -2.469518
[ Info: iteration 13, lowerbound -2.428349
[ Info: iteration 14, lowerbound -2.392082
[ Info: iteration 15, lowerbound -2.359890
[ Info: iteration 16, lowerbound -2.332349
[ Info: iteration 17, lowerbound -2.313333
[ Info: iteration 18, lowerbound -2.307459
[ Info: dropping number of Gaussions to 2
[ Info: iteration 19, lowerbound -2.302927
[ Info: iteration 20, lowerbound -2.299260
[ Info: iteration 21, lowerbound -2.299256
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299254
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: 49 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sat Dec 28 05:11:14 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sat Dec 28 05:11:23 2019: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Sat Dec 28 05:11:26 2019: EM with 272 data points 0 iterations avll -2.081664
5.8 data points per parameter
, Sat Dec 28 05:11:28 2019: GMM converted to Variational GMM
, Sat Dec 28 05:11:37 2019: iteration 1, lowerbound -3.846343
, Sat Dec 28 05:11:37 2019: iteration 2, lowerbound -3.702214
, Sat Dec 28 05:11:37 2019: iteration 3, lowerbound -3.533398
, Sat Dec 28 05:11:37 2019: iteration 4, lowerbound -3.329774
, Sat Dec 28 05:11:37 2019: iteration 5, lowerbound -3.115735
, Sat Dec 28 05:11:37 2019: iteration 6, lowerbound -2.923446
, Sat Dec 28 05:11:37 2019: iteration 7, lowerbound -2.782614
, Sat Dec 28 05:11:37 2019: dropping number of Gaussions to 6
, Sat Dec 28 05:11:37 2019: iteration 8, lowerbound -2.695362
, Sat Dec 28 05:11:37 2019: dropping number of Gaussions to 5
, Sat Dec 28 05:11:37 2019: iteration 9, lowerbound -2.631924
, Sat Dec 28 05:11:37 2019: dropping number of Gaussions to 3
, Sat Dec 28 05:11:37 2019: iteration 10, lowerbound -2.571785
, Sat Dec 28 05:11:37 2019: iteration 11, lowerbound -2.515530
, Sat Dec 28 05:11:37 2019: iteration 12, lowerbound -2.469518
, Sat Dec 28 05:11:37 2019: iteration 13, lowerbound -2.428349
, Sat Dec 28 05:11:37 2019: iteration 14, lowerbound -2.392082
, Sat Dec 28 05:11:37 2019: iteration 15, lowerbound -2.359890
, Sat Dec 28 05:11:37 2019: iteration 16, lowerbound -2.332349
, Sat Dec 28 05:11:37 2019: iteration 17, lowerbound -2.313333
, Sat Dec 28 05:11:37 2019: iteration 18, lowerbound -2.307459
, Sat Dec 28 05:11:37 2019: dropping number of Gaussions to 2
, Sat Dec 28 05:11:37 2019: iteration 19, lowerbound -2.302927
, Sat Dec 28 05:11:37 2019: iteration 20, lowerbound -2.299260
, Sat Dec 28 05:11:37 2019: iteration 21, lowerbound -2.299256
, Sat Dec 28 05:11:37 2019: iteration 22, lowerbound -2.299254
, Sat Dec 28 05:11:37 2019: iteration 23, lowerbound -2.299254
, Sat Dec 28 05:11:37 2019: iteration 24, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: iteration 25, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: iteration 26, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: iteration 27, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: iteration 28, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: iteration 29, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: iteration 30, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: iteration 31, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: iteration 32, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: iteration 33, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: iteration 34, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: iteration 35, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: iteration 36, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: iteration 37, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: iteration 38, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: iteration 39, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: iteration 40, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: iteration 41, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: iteration 42, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: iteration 43, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: iteration 44, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: iteration 45, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: iteration 46, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: iteration 47, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: iteration 48, lowerbound -2.299253
, Sat Dec 28 05:11:37 2019: 49 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.0450922260143, 95.95490777398567]
β = [178.0450922260143, 95.95490777398567]
m = [4.250300733269905 79.28686694436179; 2.000229257775367 53.85198717246128]
ν = [180.0450922260143, 97.95490777398567]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484816 -0.007644049042327786; 0.0 0.008581705166333404], [0.3758763611948473 -0.008953123827346057; 0.0 0.012748664777409357]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000003
avll from stats: -0.9785922533396935
avll from llpg:  -0.9785922533396932
avll direct:     -0.9785922533396932
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -1.0130727329810283
avll from llpg:  -1.0130727329810283
avll direct:     -1.0130727329810283
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.110704    -0.0398323  -0.0467112   -0.0573012   -0.0703376    -0.0515316    -0.0663767    0.199619    -0.0176322   -0.0216433   -0.0975548    -0.0178514   -0.0344139   0.0988931   -0.0409985     0.215421    -0.0286882    0.192631     0.0823087   -0.229924    -0.0022005    -0.0188473    -0.231803    -0.0283323    0.052445   -0.036443
 -0.23192     -0.040573    0.0467443    0.0342259   -0.0811615     0.0283279    -0.0265981    0.06417      0.00247924   0.0708488   -0.0744393    -0.0254148    0.208203    0.0826971    0.0389441     0.0209141    0.0455598   -0.190103    -0.00142947   0.158192    -0.00643022    0.0676078     0.109508    -0.113258     0.156542   -0.00178517
  0.0226276   -0.0671166   0.115565    -0.0886754   -0.192032     -0.0589906     0.062793    -0.00990834  -0.129574    -0.0140662    0.0441612     0.0464992   -0.0219896  -0.00517149   0.000406268  -0.0622478    0.0394175   -0.215553    -0.0315442   -0.110643    -0.0666705     0.0357028     0.167767    -0.167791     0.049418   -0.0201474
  0.0477115   -0.138962    0.0704442    0.267378     0.000319294  -0.127042     -0.0280127   -0.152099     0.0540249    0.0790721   -0.0726121     0.0335323   -0.134425   -0.182181     0.032983     -0.0551956   -0.031547    -0.0162388    0.108217    -0.109125    -0.0235577    -0.0361061     0.0849544   -0.0310403   -0.0113411   0.193764
 -0.00568974  -0.120077   -0.0548801   -0.160364     0.00834251    0.0242635    -0.0206172   -0.190132    -0.0291063    0.00540576  -0.107896     -0.0756791    0.268896    0.00792574   0.0649903    -0.116705    -0.0178359    0.043438    -0.0410958   -0.00903794   0.0036904    -0.0510815     0.0710628    0.0424041   -0.0509616  -0.0301056
  0.129822    -0.0185213   0.0975905    0.0509539    0.0949313    -0.0808035    -0.0376277   -0.120448     0.0635402    0.0615438   -0.113028      0.0520141    0.0239009   0.0861883   -0.0576912    -0.167748    -0.134961     0.0146145    0.0715685   -0.0785417   -0.00358223   -0.0544277    -0.00865059   0.0580474   -0.0708683  -0.0380243
 -0.145855     0.0700785   0.0277129    0.205928     0.12796      -0.0204256     0.0902891   -0.048219     0.00596781   0.0708182   -0.000874425  -0.0222116    0.111189   -0.0221525   -0.0209843     0.0431142   -0.116592    -0.0290827   -0.0123593    0.024626     0.0382078    -0.200993     -0.00176136  -0.209703     0.0244569   0.127673
 -0.0994534    0.0944583  -0.335845    -0.038342    -0.0369161    -0.0378167     0.0363508   -0.136405    -0.0502343   -0.157637     0.0723816    -0.0316083   -0.120847    0.0822875   -0.0353372    -0.0555294    0.116353    -0.0397301    0.116364    -0.0388699   -0.195111     -0.199448      0.206995     0.0273445   -0.0532022  -0.0697495
 -0.137232     0.0224325   0.045887     0.103026    -0.055485      0.0582359     0.0611322   -0.101594    -0.0270224   -0.116784     0.155762      0.0285432   -0.023057   -0.171997     0.0215779    -0.106765     0.0138623    0.11248     -0.184829    -0.0605285   -0.00192036    0.00700939    0.131643     0.133114    -0.100465    0.00243277
 -0.0376368   -0.080433   -0.0135629    0.0165976    0.04387       0.0378075    -0.151988    -0.0444329   -0.00755774  -0.0703303    0.0471706     0.0331987   -0.0850985   0.00217387  -0.0483326     0.00852205   0.129996    -0.035908    -0.0126562   -0.133078    -0.152099      0.0073631    -0.137489    -0.0817287   -0.056656    0.0960533
  0.13247      0.0384773   0.0366412   -0.0142881    0.0363897     0.0631233    -0.0500037   -0.0507848    0.00258795   0.03347      0.036646     -0.0990611    0.103525    0.127952     0.0625918    -0.0338731   -0.0825425    0.24434      0.060199    -0.0124356    0.100551      0.0264024    -0.0972611    0.0338656   -0.113143   -0.15373
  0.132002    -0.022207   -0.186444    -0.115511    -0.0866543     0.325012      0.0448092   -0.162429     0.145568     0.0657561    0.0256549     0.0175763    0.114973   -0.0169738   -0.071048     -0.144906     0.0417682    0.11974      0.0482733   -0.157019     0.0369702    -0.0219806    -0.023403    -0.0720536   -0.0851772  -0.0378
 -0.138234    -0.15566     0.0138663    0.0611795    0.0139383    -0.0773823     0.210659    -0.00900535  -0.0306383    0.147884    -0.112026     -0.0800561    0.0093971  -0.161553    -0.0567229     0.0294762    0.0168041    0.255498    -0.160634    -0.256407     0.0499814     0.091365      0.0116047    0.0519602   -0.0125853  -0.00982717
 -0.0554562    0.0375311  -0.106147     0.114358     0.112616     -0.0179463     0.00794626  -0.0432735    0.0162484    0.074627    -0.0202439     0.0376715    0.0278857   0.0633527    0.0897377     0.268718     0.172778     0.0836864   -0.152108    -0.107684     0.00487423   -0.0342524    -0.174582    -0.0946143    0.115472   -0.0906508
 -0.0249897    0.0394689   0.118672    -0.00627242  -0.0929386     0.0760283    -0.00386095  -0.0309618   -0.16003     -0.0393167    0.0134335    -0.0749621   -0.157211   -0.0460542   -0.00949151   -0.0190925    0.0975089    0.0468871   -0.0426576    0.0223687   -0.110767      0.0671621    -0.0132544    0.0454728    0.131528    0.0302021
 -0.0840604   -0.0251008  -0.126049     0.121308     0.0573279    -0.0731897     0.054452    -0.127086    -0.0360986    0.00300451   0.055413     -0.00708202  -0.0700377  -0.0333306   -0.0800381     0.0998806    0.258493     0.0899287    0.0103421    0.0685762   -0.0763761    -0.00810974    0.0388201   -0.00340725  -0.0354875  -0.0902059
 -0.120694    -0.0952171  -0.0602815   -0.117221    -0.143771     -0.0413528     0.168076    -0.0942101    0.0678606    0.00588985  -0.0527705     0.014753    -0.0427789  -0.0243716   -0.0288085    -0.0272437    0.0406893    0.0565995   -0.193428    -0.0348624   -0.0534307     0.00526508   -0.0922463   -0.0360307   -0.0787438   0.0932487
  0.109499     0.120207   -0.0128967   -0.210827     0.0969779     0.118385      0.182207    -0.0723197   -0.0551065   -0.0273707   -0.12654      -0.214825    -0.0836696   0.145607    -0.0720795    -0.135083     0.0754901   -0.0776429    0.0127518   -0.0498571    0.000116571   0.0919792    -0.00772634   0.131474    -0.0895219  -0.134391
  0.0129884   -0.212601    0.0370291   -0.0994891    0.101967      0.12129      -0.0347272    0.124517    -0.0707822    0.0253585   -0.063094     -0.00921623  -0.0179758  -0.140965    -0.00704113   -0.0930997   -0.0831517   -0.163012     0.0670574   -0.017493    -0.0955757     0.0275313    -0.00960143   0.0734454   -0.023601   -0.028497
  0.134416    -0.0365686  -0.124385     0.0580562   -0.043673      0.126862      0.0785674    0.0271376   -0.0441323   -0.110978     0.0221803    -0.058753     0.0780952  -0.00946728   0.0517299    -0.0277999    0.100028     0.0601083    0.222546    -0.0114937    0.0511989    -0.133143     -0.0115786    0.0263631    0.130346   -0.032701
 -0.0812936    0.129027   -0.028963     0.0294454    0.0855828     0.0817758    -0.0392341    0.0835917    0.00974162  -0.0736433   -0.0304305     0.00304333   0.0838997  -0.0654522   -0.0449385     0.139331     0.125594     0.107547     0.230078    -0.10202     -0.0909166    -0.008293      0.0216764   -0.110083     0.0758455   0.0625182
 -0.0154773   -0.0262923  -0.0441878    0.123256     0.143403      0.0561248    -0.0791866    0.104309     0.0784355   -0.0722105   -0.0813928    -0.0266667   -0.0928844  -0.00726578  -0.0189951     0.0172337   -0.0976603    0.0519227    0.00806074  -0.0971742    0.243911     -0.0536487    -0.0335083    0.16174      0.053373    0.104439
  0.111112     0.042868    0.139802     0.0284766    0.0806759    -0.00829981   -0.0659334    0.14503     -0.0340749    0.0365679   -0.0376608    -0.0479009   -0.0307333  -0.00748576  -0.0258362    -0.0310435   -0.0257956   -0.0139765   -0.0543778    0.0781215    0.0749294     0.0632452     0.254389    -0.0372793    0.0172102   0.0512735
  0.163816    -0.15242     0.0844457   -0.13702     -0.0378524    -0.149588     -0.0837558   -0.0470014   -0.0420805    0.0233342    0.183138      0.0374476   -0.030688   -0.108699    -0.101417     -0.101642    -0.0439358    0.069983    -0.142889    -0.0513667   -0.105331      0.0922065    -0.139344    -0.0100744   -0.0410867   0.169547
 -0.0765902   -0.0670025   0.0679239    0.0611242   -0.119743      0.031374      0.065913     0.0178979    0.114979     0.058269     0.138139      0.0762529   -0.0874457  -0.0525432   -0.134285     -0.0375217    0.00802703   0.179663     0.126324     0.0436226    0.131603      0.000406557   0.0489022   -0.0832491   -0.0704849   0.0200422
  0.0799039   -0.0353366   0.0469735    0.0875647    0.0415238     0.100471     -0.011305     0.0736429    0.0257606    0.080227     0.0647824    -0.0403999   -0.108226    0.0958566    0.154511     -0.103735     0.0769511    0.0254691   -0.0613818    0.174846    -0.228496     -0.107296      0.0665985   -0.0215734    0.0206881   0.0532916
  0.0255227    0.200083    0.0150274   -0.0577361   -0.18602      -0.0551247    -0.0860715    0.0929467   -0.00920773   0.170331    -0.00606976    0.16209      0.0123541  -0.175977     0.0264001    -0.090515    -0.128475     0.11424     -0.0882835    0.0746758    0.107111     -0.144342      0.0151982    0.0841455   -0.098725   -0.160744
 -0.0642145   -0.158071    0.168514     0.0200165   -0.14281       0.0303045     0.0513228    0.217097    -0.1265       0.033259    -0.0416108    -0.0325261   -0.103241   -0.0803399    0.00369025    0.0690743    0.0623511   -0.0966812    0.146425    -0.0286747   -0.159122     -0.108496     -0.0907749   -0.0761998    0.0535501  -0.295139
  0.0878609    0.0585247   0.156345     0.0632062    0.0565852     0.000953463  -0.0124331   -0.108535    -0.0497665   -0.21688     -0.0730303     0.0526262    0.142872    0.0156952    0.225483     -0.0428872   -0.138779     0.203585     0.166059    -0.0437264    0.0679109    -0.0182752    -0.0979327   -0.0101259   -0.0198387   0.0819177
 -0.0213403   -0.0522114  -0.0794437   -0.0745216    0.0726923    -0.0149609    -0.143369    -0.106834    -0.0383781   -0.0375539    0.0812328    -0.127093     0.0516256   0.00822926  -0.199224     -0.218374     0.1705       0.130821    -0.083984    -0.0964477    0.0242162    -0.142001     -0.15598     -0.0583947   -0.0333986  -0.0155852
 -0.0160582   -0.100665    0.00779847   0.0239767    0.202999      0.0630222    -0.163519    -0.0280154   -0.112908    -0.0298024    0.217065     -0.0426029   -0.0132435  -0.0712598    0.0280219    -0.00272035  -0.0306762   -0.0331087    0.0637194   -0.00875852  -0.100392      0.0162707     0.0679451   -0.0289245   -0.0782277  -0.060199
  0.20568     -0.0187477   0.0167621    0.0156906   -0.000607927   0.0850913     0.00946097  -0.055497     0.122996    -0.00520528  -0.144266     -0.0166245   -0.100999    0.0383249    0.034448      0.0774624   -0.107566    -0.00735276  -0.0908602    0.0114589    0.0321699    -0.0731329     0.0232622    0.151871     0.0338653   0.0819126kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4031694937632486
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.403262
[ Info: iteration 2, average log likelihood -1.403196
[ Info: iteration 3, average log likelihood -1.402891
[ Info: iteration 4, average log likelihood -1.398488
[ Info: iteration 5, average log likelihood -1.380993
[ Info: iteration 6, average log likelihood -1.371476
[ Info: iteration 7, average log likelihood -1.369923
[ Info: iteration 8, average log likelihood -1.368837
[ Info: iteration 9, average log likelihood -1.368134
[ Info: iteration 10, average log likelihood -1.367714
[ Info: iteration 11, average log likelihood -1.367413
[ Info: iteration 12, average log likelihood -1.367160
[ Info: iteration 13, average log likelihood -1.366946
[ Info: iteration 14, average log likelihood -1.366774
[ Info: iteration 15, average log likelihood -1.366642
[ Info: iteration 16, average log likelihood -1.366547
[ Info: iteration 17, average log likelihood -1.366478
[ Info: iteration 18, average log likelihood -1.366427
[ Info: iteration 19, average log likelihood -1.366389
[ Info: iteration 20, average log likelihood -1.366362
[ Info: iteration 21, average log likelihood -1.366342
[ Info: iteration 22, average log likelihood -1.366327
[ Info: iteration 23, average log likelihood -1.366316
[ Info: iteration 24, average log likelihood -1.366308
[ Info: iteration 25, average log likelihood -1.366302
[ Info: iteration 26, average log likelihood -1.366298
[ Info: iteration 27, average log likelihood -1.366294
[ Info: iteration 28, average log likelihood -1.366292
[ Info: iteration 29, average log likelihood -1.366289
[ Info: iteration 30, average log likelihood -1.366288
[ Info: iteration 31, average log likelihood -1.366286
[ Info: iteration 32, average log likelihood -1.366285
[ Info: iteration 33, average log likelihood -1.366284
[ Info: iteration 34, average log likelihood -1.366284
[ Info: iteration 35, average log likelihood -1.366283
[ Info: iteration 36, average log likelihood -1.366282
[ Info: iteration 37, average log likelihood -1.366282
[ Info: iteration 38, average log likelihood -1.366282
[ Info: iteration 39, average log likelihood -1.366281
[ Info: iteration 40, average log likelihood -1.366281
[ Info: iteration 41, average log likelihood -1.366281
[ Info: iteration 42, average log likelihood -1.366281
[ Info: iteration 43, average log likelihood -1.366281
[ Info: iteration 44, average log likelihood -1.366281
[ Info: iteration 45, average log likelihood -1.366281
[ Info: iteration 46, average log likelihood -1.366281
[ Info: iteration 47, average log likelihood -1.366280
[ Info: iteration 48, average log likelihood -1.366280
[ Info: iteration 49, average log likelihood -1.366280
[ Info: iteration 50, average log likelihood -1.366280
┌ Info: EM with 100000 data points 50 iterations avll -1.366280
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4032623942625124
│     -1.4031962016896242
│      ⋮
└     -1.3662803880374201
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.366411
[ Info: iteration 2, average log likelihood -1.366288
[ Info: iteration 3, average log likelihood -1.365816
[ Info: iteration 4, average log likelihood -1.361398
[ Info: iteration 5, average log likelihood -1.346420
[ Info: iteration 6, average log likelihood -1.335119
[ Info: iteration 7, average log likelihood -1.331639
[ Info: iteration 8, average log likelihood -1.330264
[ Info: iteration 9, average log likelihood -1.329480
[ Info: iteration 10, average log likelihood -1.328984
[ Info: iteration 11, average log likelihood -1.328684
[ Info: iteration 12, average log likelihood -1.328501
[ Info: iteration 13, average log likelihood -1.328387
[ Info: iteration 14, average log likelihood -1.328313
[ Info: iteration 15, average log likelihood -1.328262
[ Info: iteration 16, average log likelihood -1.328226
[ Info: iteration 17, average log likelihood -1.328200
[ Info: iteration 18, average log likelihood -1.328180
[ Info: iteration 19, average log likelihood -1.328164
[ Info: iteration 20, average log likelihood -1.328150
[ Info: iteration 21, average log likelihood -1.328138
[ Info: iteration 22, average log likelihood -1.328126
[ Info: iteration 23, average log likelihood -1.328115
[ Info: iteration 24, average log likelihood -1.328104
[ Info: iteration 25, average log likelihood -1.328093
[ Info: iteration 26, average log likelihood -1.328083
[ Info: iteration 27, average log likelihood -1.328072
[ Info: iteration 28, average log likelihood -1.328061
[ Info: iteration 29, average log likelihood -1.328049
[ Info: iteration 30, average log likelihood -1.328037
[ Info: iteration 31, average log likelihood -1.328023
[ Info: iteration 32, average log likelihood -1.328009
[ Info: iteration 33, average log likelihood -1.327992
[ Info: iteration 34, average log likelihood -1.327973
[ Info: iteration 35, average log likelihood -1.327951
[ Info: iteration 36, average log likelihood -1.327924
[ Info: iteration 37, average log likelihood -1.327892
[ Info: iteration 38, average log likelihood -1.327853
[ Info: iteration 39, average log likelihood -1.327805
[ Info: iteration 40, average log likelihood -1.327745
[ Info: iteration 41, average log likelihood -1.327668
[ Info: iteration 42, average log likelihood -1.327563
[ Info: iteration 43, average log likelihood -1.327431
[ Info: iteration 44, average log likelihood -1.327289
[ Info: iteration 45, average log likelihood -1.327170
[ Info: iteration 46, average log likelihood -1.327087
[ Info: iteration 47, average log likelihood -1.327029
[ Info: iteration 48, average log likelihood -1.326986
[ Info: iteration 49, average log likelihood -1.326950
[ Info: iteration 50, average log likelihood -1.326916
┌ Info: EM with 100000 data points 50 iterations avll -1.326916
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.366411150964418
│     -1.366287519328907
│      ⋮
└     -1.3269161665036888
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.327052
[ Info: iteration 2, average log likelihood -1.326848
[ Info: iteration 3, average log likelihood -1.326088
[ Info: iteration 4, average log likelihood -1.319034
[ Info: iteration 5, average log likelihood -1.298355
[ Info: iteration 6, average log likelihood -1.283328
[ Info: iteration 7, average log likelihood -1.276971
[ Info: iteration 8, average log likelihood -1.274013
[ Info: iteration 9, average log likelihood -1.271959
[ Info: iteration 10, average log likelihood -1.270365
[ Info: iteration 11, average log likelihood -1.268850
[ Info: iteration 12, average log likelihood -1.267282
[ Info: iteration 13, average log likelihood -1.265963
[ Info: iteration 14, average log likelihood -1.265190
[ Info: iteration 15, average log likelihood -1.264783
[ Info: iteration 16, average log likelihood -1.264508
[ Info: iteration 17, average log likelihood -1.264250
[ Info: iteration 18, average log likelihood -1.263944
[ Info: iteration 19, average log likelihood -1.263534
[ Info: iteration 20, average log likelihood -1.262999
[ Info: iteration 21, average log likelihood -1.262367
[ Info: iteration 22, average log likelihood -1.261678
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.261019
[ Info: iteration 24, average log likelihood -1.270292
[ Info: iteration 25, average log likelihood -1.265039
[ Info: iteration 26, average log likelihood -1.263232
[ Info: iteration 27, average log likelihood -1.262118
[ Info: iteration 28, average log likelihood -1.261257
[ Info: iteration 29, average log likelihood -1.260639
[ Info: iteration 30, average log likelihood -1.260251
[ Info: iteration 31, average log likelihood -1.260026
[ Info: iteration 32, average log likelihood -1.259901
[ Info: iteration 33, average log likelihood -1.259825
[ Info: iteration 34, average log likelihood -1.259771
[ Info: iteration 35, average log likelihood -1.259725
[ Info: iteration 36, average log likelihood -1.259683
[ Info: iteration 37, average log likelihood -1.259644
[ Info: iteration 38, average log likelihood -1.259607
[ Info: iteration 39, average log likelihood -1.259576
[ Info: iteration 40, average log likelihood -1.259552
[ Info: iteration 41, average log likelihood -1.259533
[ Info: iteration 42, average log likelihood -1.259520
[ Info: iteration 43, average log likelihood -1.259510
[ Info: iteration 44, average log likelihood -1.259501
[ Info: iteration 45, average log likelihood -1.259495
[ Info: iteration 46, average log likelihood -1.259489
[ Info: iteration 47, average log likelihood -1.259483
[ Info: iteration 48, average log likelihood -1.259478
[ Info: iteration 49, average log likelihood -1.259473
[ Info: iteration 50, average log likelihood -1.259468
┌ Info: EM with 100000 data points 50 iterations avll -1.259468
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3270519542517738
│     -1.3268478464766171
│      ⋮
└     -1.2594682301781923
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.259659
[ Info: iteration 2, average log likelihood -1.259421
[ Info: iteration 3, average log likelihood -1.257996
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.244985
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.224033
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.206327
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.203673
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.204374
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.192769
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.192973
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.197255
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.188572
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.190584
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.195685
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.187584
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.189901
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.195134
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.187030
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.189312
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.194388
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.185936
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.187499
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.191360
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.189962
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.188828
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.193890
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.185978
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.188385
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.193760
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.185894
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.188279
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.193590
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.185631
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.182182
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.195406
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.190859
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.181761
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.186461
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.196936
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.193181
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.185418
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.182466
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.196512
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.193018
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.185287
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.182291
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.196197
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.192481
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.184297
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.180343
┌ Info: EM with 100000 data points 50 iterations avll -1.180343
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2596588350324085
│     -1.2594213642766108
│      ⋮
└     -1.1803430400429102
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.193082
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.189192
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.179674
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│     21
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.158760
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│     12
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.127023
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.112147
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│     12
│     15
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.085304
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      7
│     11
│     12
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.105593
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│     12
│     15
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.098547
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.090766
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     15
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.069201
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.112031
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│     12
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.093178
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     15
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.079948
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      8
│     10
│     11
│     12
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.100086
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.093435
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     15
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.064257
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      8
│     10
│     11
│     12
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.089408
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│     12
│     15
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.082202
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│     11
│     12
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.069557
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      8
│     10
│     11
│     12
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.080980
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│     12
│     15
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.086578
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│     11
│     12
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.090452
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│     12
│     15
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.079238
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.076304
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│      ⋮
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.072638
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│     12
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.102468
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.084253
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     15
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.059984
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│     12
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.105423
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│     12
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.090186
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     15
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.073520
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      8
│     10
│     11
│     12
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.093443
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│     12
│     15
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.080489
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      7
│     11
│     12
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.084501
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│     12
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.085034
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      8
│     10
│     11
│     12
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.071374
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│     11
│     12
│     15
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.063385
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│      ⋮
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.074919
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.090904
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│     10
│     11
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.064875
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│     12
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.085123
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.082097
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.071173
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     11
│     12
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.090062
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      8
│     10
│     11
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.072236
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.086393
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│     12
│     15
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.066129
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     12
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.073228
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.092507
┌ Info: EM with 100000 data points 50 iterations avll -1.092507
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1930816177177022
│     -1.1891923329240117
│      ⋮
└     -1.0925074376871762
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4031694937632486
│     -1.4032623942625124
│     -1.4031962016896242
│     -1.402890682713252
│      ⋮
│     -1.0661287012124159
│     -1.0732277534943804
└     -1.0925074376871762
32×26 Array{Float64,2}:
 -0.133366     -0.182767    0.0205375    0.0645155     1.58182     -0.0447332    0.21008     -0.00853866  -0.0701577    0.142328    -0.123483    -0.0721449   -0.000402795  -0.148278     -0.0582995    0.0729882     0.0209229    0.251763    -0.158262    -0.342158     0.0502426     0.0744191    0.00905197   0.0832867   -0.0435333   -0.0294494
 -0.135666     -0.123019    0.0152877    0.0598548    -1.82604     -0.108466     0.212967    -0.00864597   0.0429207    0.158064    -0.0263857   -0.0782917   -0.0756429    -0.166734     -0.0682823    0.00515016   -0.00391993   0.249945    -0.150413    -0.218795     0.0549936     0.0946663    0.0091397    0.0393885   -0.00656423  -0.00372388
  0.0694249     0.0431134   0.0280689   -0.0311009     0.022656     0.0951657   -0.126419    -0.0498378   -0.256648     0.0336988    0.108523    -0.0934344    0.110332      0.130958     -0.032492    -0.0339099    -0.0356935    0.278568     0.109885    -0.226184     0.0866921     0.0849376   -0.140889     0.0162943   -0.0680247   -0.148779
  0.189306      0.0542378   0.0493718    0.0148568     0.0563234   -0.0277881   -0.00317927  -0.0512688    0.349017     0.0298899   -0.0398337   -0.0952335    0.0371537     0.124802      0.190233    -0.0345772    -0.115994     0.159309    -0.0277342    0.277217     0.100782     -0.0729818   -0.0927019    0.0402959   -0.137983    -0.16396
 -0.0763933    -0.0253807  -0.123364     0.111401      0.0696969   -0.0826999    0.0358736   -0.110845    -0.0710199    0.0167547    0.0543945    0.00559745  -0.0659373    -0.0456552    -0.0633294    0.102882      0.25924      0.103002     0.0139142    0.0567031   -0.0701849    -0.0127198    0.0513252   -0.00455498  -0.121466    -0.0676946
  0.000383159   0.100184   -0.0136345    0.0233334     0.00517612   0.0195821   -0.0519274    0.0847482    0.0340822    0.0119796   -0.0563942    0.0720838   -0.00273311   -0.0690372     0.00851892   0.021226     -0.0371619    0.114325     0.0408094   -0.0445061    0.0856583    -0.0707327   -0.0110765    0.0620121    0.0159891    0.014702
  0.145829     -0.153432    0.0753355   -0.151163     -0.0173821   -0.124098    -0.118333    -0.0846326   -0.0560221    0.00995181   0.299152     0.022954    -0.0117321    -0.0997117    -0.143307    -0.117972     -0.0790378    0.0688006   -0.109975    -0.090625    -0.108583      0.0617441   -0.0726557    0.0646036   -0.0172399    0.151346
  0.0965811    -0.0592851   0.043312     0.105248      0.0383251    0.0980219    0.0217798    0.10733      0.0654912    0.0430843   -0.0172669   -0.0558533   -0.119518      0.120444      0.192368    -0.116166      0.0990623   -0.0541424   -0.069639     0.175784    -0.22142      -0.135981     0.0690889   -0.0740867    0.00934243   0.0510829
 -0.14726       0.0677416  -0.00847247   0.204588      0.129077    -0.0207952    0.0905944   -0.0507998   -0.023476     0.0717047    0.00290713  -0.0296129    0.124324     -0.02988      -0.0448357    0.0466044    -0.11864     -0.0361798   -0.0078459    0.0357128    0.0371703    -0.19987     -0.00661472  -0.202141     0.0342006    0.13112
  0.0516104    -0.134276    0.07346      0.250535     -0.0188147   -0.12822     -0.0616583   -0.142018     0.047547     0.0661814   -0.0875056    0.0173825   -0.122962     -0.182031      0.0325984   -0.0687186    -0.0219416   -0.0350829    0.112555    -0.118183    -0.031698     -0.0315982    0.097571    -0.0232377   -0.015589     0.191481
 -0.00517586   -0.155167   -0.0485833   -0.160016     -0.0366613   -0.02752      0.0514231   -0.161457    -0.0281647   -0.0298641   -0.138057    -0.0726778    0.366581      0.0095647     0.0836776   -0.0285882    -0.542183     0.0417903   -0.0130012   -0.196035     0.0163877     0.125403     0.108419     0.0455644   -0.00847872  -0.0220924
 -0.0050747    -0.0992894  -0.0576228   -0.160014      0.0819739    0.0975663   -0.116605    -0.238407     0.0161237   -0.0188117   -0.0789353   -0.0717001    0.184469      0.00433339   -0.061272    -0.221289      0.46609      0.0334272   -0.0443242    0.126901    -0.0185765    -0.218571     0.0294931    0.0477419   -0.0944309   -0.0281674
  0.0231707     0.0932941  -0.0710414   -0.039352      0.100063     0.0424869    0.10012     -0.0575334   -0.00957854   0.0228268   -0.075175    -0.0761311   -0.0230332     0.101326      0.0141522    0.0764746     0.123608     0.00715336  -0.0258388   -0.0806468   -0.0011007     0.0235864   -0.0873899   -0.0151982    0.0219593   -0.111109
  0.0292584     0.0450645   0.133366     0.00905626   -0.0484326    0.0311995    0.00345172  -0.0669018   -0.142842    -0.123812    -0.00831173  -0.0298306   -0.0284389    -0.0323718     0.0817161   -0.0379399     0.00103027   0.098925     0.0504101    0.00223506  -0.0125797     0.0373865   -0.0350988    0.0191697    0.0615209    0.0445233
 -0.0939671     0.0868442  -0.324564    -0.040676     -0.028603    -0.0301791    0.0307481   -0.124302    -0.0512128   -0.152894     0.0827149   -0.0226687   -0.115011      0.0828474    -0.0379287   -0.0633644     0.0929061   -0.0324344    0.109624    -0.0523931   -0.248546     -0.19105      0.183148     0.012268    -0.0248566   -0.0751342
 -0.041213     -0.0742171  -0.113443    -0.0754463     0.112361    -0.0167461   -0.146849    -0.105047    -0.0380412   -0.0400217    0.0789449   -0.120731     0.0436887     0.00818113   -0.237469    -0.219435      0.227496     0.141258    -0.0842929   -0.0674442   -0.000230632  -0.128169    -0.159467    -0.0582959   -0.0350781   -0.00885362
  0.110763     -0.010442   -0.192478    -0.0878756    -0.115914     0.31183      0.079553    -0.153512     0.143238     0.0731559    0.0392781    0.0203372    0.110027     -0.0358036    -0.0578086   -0.157522      0.0450939    0.124598     0.0611062   -0.184526     0.0183229    -0.0218193   -0.0360637   -0.0756857   -0.105579    -0.0385499
  0.0901826    -0.130113   -0.00088414  -0.0929586     0.0189412    0.0350794   -0.046265     0.154569    -0.0456202    0.00723826  -0.0823467   -0.0146711   -0.0191868    -0.0209339    -0.0268423    0.0769931    -0.0671852   -0.00253266   0.0701762   -0.122283    -0.0496656     0.00248115  -0.131306     0.023892     0.00955278  -0.0299902
 -0.122807     -0.0410803   0.0680596    0.163897     -0.0725463    0.113287     0.0104202   -0.0732124   -0.0300668   -0.139396     0.137326     0.0247795   -0.0633244    -0.159655      0.0139523   -0.11465       0.0810777    0.110618    -0.185999    -0.516909    -0.104771     -0.00566371   0.142247     0.245906    -0.0251965   -0.00225652
 -0.134615      0.0678409   0.0274191    0.0542206    -0.0594159    0.0549623    0.120719    -0.147353    -0.00369252  -0.0992683    0.164208     0.0287592   -0.0212934    -0.133712      0.00618162  -0.0957293    -0.0444151    0.107181    -0.18622      0.303469     0.124766      0.0229097    0.121872     0.0353828   -0.0956508   -0.0239915
  0.120849      0.0806667   0.155372    -0.000463102   0.0908284   -0.00470033   0.0120248    0.191799    -0.030969    -0.0046546   -0.0356801   -0.0388008   -0.0415869     0.000692042   0.0236526    0.000994794   0.0460731   -0.019749     0.0361271    0.0654399    0.0925262     0.0920258    0.244424    -0.0146013    0.0175399    0.0583275
  0.111228      0.0590284   0.148209    -0.000296531   0.0795738   -0.0041556   -0.033477     0.134848    -0.0111302    0.0246559   -0.0552748   -0.0504198   -0.031516      0.00209689    0.0166846   -0.0339033    -0.0626184   -0.00154036  -0.0423815    0.0653133    0.0839929     0.0787421    0.254491    -0.035832     0.00139087   0.037168
  0.212067     -0.0206635   0.0218756    0.0157018    -0.00825475   0.120448     0.0193375   -0.0667525    0.13505     -0.017853    -0.139507    -0.015786    -0.103329      0.0352805     0.0392139    0.0850251    -0.105452    -0.00417418  -0.0871327    0.00662512   0.0725746    -0.0752997    0.0253733    0.147763     0.0369262    0.0532838
 -0.133699     -0.117734    0.251673     0.078461     -0.192445     0.0319768    0.0492493    0.216675    -0.131527    -0.0076321   -0.0502941   -0.0250486   -0.0850133    -0.102698     -0.0302531    0.0712829     0.0677605   -0.0963047    0.157141    -0.0305498   -0.212123     -0.145254    -0.0944253   -0.102762     0.0531925   -0.291214
 -0.0860435    -0.0713091   0.0589396    0.0567719    -0.1286       0.0320944    0.0672392    0.0124128    0.10339      0.0435811    0.139432     0.0774147   -0.122848     -0.0590898    -0.132646    -0.0378953     0.00722301   0.176291     0.10282      0.0528184    0.132431      0.00303101   0.0361929   -0.0915627   -0.0873645    0.0288546
  0.0611878    -0.124529    0.103181    -0.0848305    -0.202642    -0.0642806    0.0628158   -0.01078     -0.150666    -0.0102769    0.0390554    0.0422355   -0.0201852    -0.0107976     0.0262845   -0.0645778     0.037754    -0.21754      0.00626587  -0.0922432   -0.0661154     0.0386815    0.171569    -0.171979    -0.00532325  -0.0218012
 -0.0359429    -0.0884002  -0.00779008   0.00228277    0.0412498    0.0349883   -0.148256    -0.0418842    0.0159968   -0.088536     0.0435502    0.0323757   -0.0825498     0.0021588    -0.022126    -0.00236539    0.153044    -0.0487563   -0.0124661   -0.141173    -0.17706      -0.0353597   -0.124993    -0.0624236   -0.0716818    0.10163
  0.146488     -0.0121342  -0.129093     0.0639038    -0.0839635    0.169894     0.0794188    0.0254091   -0.0664205   -0.110207     0.0185592   -0.0589232    0.0805337    -0.00941514    0.0831528   -0.0460907     0.108561     0.0485963    0.21052     -0.0150233    0.0589165    -0.125993     0.0220531    0.0489869    0.116561    -0.0519966
 -0.0906346    -0.0901535  -0.0539265   -0.107321     -0.110152    -0.0708377    0.153319    -0.105674     0.0492713   -0.0114868   -0.0391122    0.00629235  -0.0690791    -0.019747      0.00746613  -0.0190155     0.0342862    0.0637843   -0.175009    -0.0293579   -0.0483803     0.0143345   -0.0870948   -0.0323185   -0.0739121    0.091352
  0.0715775    -0.0666923   0.0729708    0.0449618     0.131265    -0.011157    -0.0776274   -0.0701964   -0.0145036    0.0223703    0.0410474    0.0169905    0.0131479     0.011321     -0.00397877  -0.100256     -0.0840655   -0.0139636    0.0760699   -0.0402386   -0.0588461    -0.0344719    0.027356     0.0207456   -0.0740116   -0.0635362
 -0.320921     -0.0359898  -0.0975004    0.00795855   -0.080514     0.0219402   -0.00946589   0.183412     0.0139761    0.076504    -0.0801442   -0.0354712   -0.788255     -0.0643979     0.0378459    0.0470423     0.0479626   -0.174532     0.0103078    0.173418    -0.0550076     0.104458     0.11456     -0.183277     0.166489     0.0247073
 -0.115078     -0.0508889   0.215773     0.0639027    -0.0725495    0.0276334   -0.0639237    0.036401    -0.0447855    0.0677164   -0.0646566   -0.00955574   1.07526       0.268965      0.0338145    0.00701921    0.0477545   -0.197015    -0.00863061   0.13417      0.0515533     0.0538392    0.100657    -0.015893     0.150255    -0.00794764[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│     12
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.077165
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.056933
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      8
│     10
│      ⋮
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.064963
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.062006
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│     12
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.068490
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.048831
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     10
│     11
│     12
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.074029
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.050018
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      8
│     10
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.060286
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│     10
│      ⋮
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.053136
┌ Info: EM with 100000 data points 10 iterations avll -1.053136
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind diag, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.970106e+05
      1       6.646646e+05      -2.323460e+05 |       32
      2       6.392439e+05      -2.542062e+04 |       32
      3       6.268939e+05      -1.235008e+04 |       32
      4       6.186734e+05      -8.220468e+03 |       32
      5       6.125035e+05      -6.169863e+03 |       32
      6       6.090712e+05      -3.432314e+03 |       32
      7       6.074899e+05      -1.581278e+03 |       32
      8       6.067147e+05      -7.752752e+02 |       32
      9       6.063364e+05      -3.782685e+02 |       32
     10       6.061338e+05      -2.025619e+02 |       32
     11       6.059367e+05      -1.971160e+02 |       32
     12       6.057059e+05      -2.308347e+02 |       32
     13       6.053948e+05      -3.110689e+02 |       32
     14       6.050172e+05      -3.776456e+02 |       32
     15       6.043974e+05      -6.197883e+02 |       32
     16       6.036928e+05      -7.045404e+02 |       32
     17       6.031246e+05      -5.682530e+02 |       32
     18       6.027490e+05      -3.755768e+02 |       31
     19       6.025098e+05      -2.392087e+02 |       31
     20       6.023497e+05      -1.600589e+02 |       32
     21       6.022375e+05      -1.122393e+02 |       31
     22       6.021713e+05      -6.615390e+01 |       31
     23       6.021235e+05      -4.781955e+01 |       31
     24       6.020909e+05      -3.259582e+01 |       31
     25       6.020595e+05      -3.142595e+01 |       31
     26       6.020211e+05      -3.837211e+01 |       31
     27       6.019879e+05      -3.324398e+01 |       32
     28       6.019424e+05      -4.549961e+01 |       31
     29       6.018846e+05      -5.775274e+01 |       32
     30       6.018167e+05      -6.790337e+01 |       31
     31       6.017376e+05      -7.918107e+01 |       31
     32       6.016479e+05      -8.961533e+01 |       31
     33       6.015629e+05      -8.505409e+01 |       31
     34       6.014807e+05      -8.214214e+01 |       31
     35       6.014114e+05      -6.935272e+01 |       30
     36       6.013470e+05      -6.440590e+01 |       32
     37       6.012890e+05      -5.801437e+01 |       32
     38       6.012418e+05      -4.713883e+01 |       31
     39       6.011891e+05      -5.275573e+01 |       32
     40       6.011304e+05      -5.868590e+01 |       32
     41       6.010847e+05      -4.566050e+01 |       32
     42       6.010456e+05      -3.908047e+01 |       32
     43       6.010096e+05      -3.609377e+01 |       31
     44       6.009810e+05      -2.850181e+01 |       31
     45       6.009602e+05      -2.083889e+01 |       32
     46       6.009471e+05      -1.308855e+01 |       29
     47       6.009410e+05      -6.150066e+00 |       29
     48       6.009385e+05      -2.438749e+00 |       24
     49       6.009368e+05      -1.712357e+00 |       20
     50       6.009358e+05      -1.036969e+00 |       14
K-means terminated without convergence after 50 iterations (objv = 600935.7840337448)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.319682
[ Info: iteration 2, average log likelihood -1.284625
[ Info: iteration 3, average log likelihood -1.254035
[ Info: iteration 4, average log likelihood -1.224000
[ Info: iteration 5, average log likelihood -1.186019
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.132982
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.093779
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     12
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.061025
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.085674
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.081250
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      5
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.049362
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.061386
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     12
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.067730
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.078959
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      3
│      5
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.024947
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.088560
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.081999
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.067749
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      9
│     16
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.026172
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      5
│     10
│     24
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.055511
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.113285
[ Info: iteration 22, average log likelihood -1.071535
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      9
│     16
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.016352
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      5
│     10
│     12
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.072782
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.101877
[ Info: iteration 26, average log likelihood -1.061292
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      3
│      9
│     16
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.008639
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│     10
│     12
│     24
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.055934
[ Info: iteration 29, average log likelihood -1.136828
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.068257
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      5
│      9
│     12
│     16
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.018871
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.098089
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.070907
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     22
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.044540
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      5
│     10
│     12
│     16
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.033018
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.095266
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.084568
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      3
│      9
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.028639
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│     10
│     12
│     16
│     24
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.043242
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.115645
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.059107
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      9
│     16
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.024170
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     10
│     12
│     24
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.055279
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.103507
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.067904
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      3
│      9
│     10
│     16
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.013625
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     12
│     22
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.083053
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.099106
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      2
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.055231
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      9
│     10
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.034348
┌ Info: EM with 100000 data points 50 iterations avll -1.034348
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.164043    -0.159248    0.0780245   -0.0979393   -0.0263495   -0.142396   -0.110801    -0.101581    -0.0389031    0.0241442    0.235578     0.0274309   -0.0334481  -0.118963    -0.128049    -0.136284    -0.0847187    0.0710578   -0.113965     -0.0778926    -0.0930017     0.0863808   -0.107769     0.0410455   -0.0351262    0.170141
  0.0514624   -0.121318    0.071788     0.263986    -0.00995219  -0.115235   -0.0980057   -0.236964     0.041726     0.14293     -0.108449     0.0134278   -0.128274   -0.186907     0.0583203   -0.0597862   -0.0245289   -0.044932     0.132309     -0.169642     -0.0374615    -0.047964     0.160151    -0.0307662   -0.0193609    0.179029
 -0.137238    -0.160766    0.0160826    0.0610822   -0.0644568   -0.0784696   0.212299    -0.00833508  -0.00932928   0.15114     -0.0827965   -0.0727853   -0.0395667  -0.160032    -0.0644222    0.0422171    0.00737255   0.253854    -0.163361     -0.290963      0.0535287     0.0854946    0.011565     0.0668771   -0.0264668   -0.01828
  0.0495315    0.197763    0.0167611   -0.0844192   -0.17404     -0.0601052  -0.0525412    0.0883246   -4.01088e-5   0.178619     0.00246957   0.195167     0.0167994  -0.175725     0.0418235   -0.0838601   -0.116997     0.15545     -0.0824225     0.0841556     0.106605     -0.14349      0.00935079   0.0836583   -0.100102    -0.132916
 -0.0921307    0.079792   -0.334388    -0.0408947   -0.0292404   -0.0305625   0.0308609   -0.121035    -0.050559    -0.15153      0.0797488   -0.019278    -0.117009    0.0821107   -0.0369227   -0.0611644    0.0919739   -0.031099     0.109666     -0.052493     -0.2449       -0.192668     0.182305     0.0137568   -0.0220819   -0.0709856
 -0.129236     0.0129835   0.0480395    0.109104    -0.0678131    0.0845153   0.0658347   -0.109383    -0.0188097   -0.11923      0.150749     0.027392    -0.0423706  -0.149249     0.00984402  -0.106193     0.0195362    0.108979    -0.186267     -0.10518       0.0105722     0.00872082   0.133347     0.139084    -0.06363     -0.0127496
 -0.0660312    0.0444477  -0.135026     0.115568     0.100142    -0.0229011   0.0316622   -0.0419624    0.0261726    0.077327    -0.023301     0.0449037    0.019397    0.0686241    0.0893395    0.266202     0.175721     0.0727087   -0.11518      -0.0966205     0.00143876   -0.0352133   -0.156517    -0.145522     0.116285    -0.100645
  0.0604918   -0.12655     0.102977    -0.0860338   -0.207784    -0.0637065   0.0604874   -0.0102268   -0.152609    -0.0109805    0.0459738    0.0472128   -0.0192111  -0.0106518    0.0263394   -0.0653283    0.0356411   -0.217196     0.00724858   -0.0887061    -0.0691104     0.0381397    0.173755    -0.177033    -0.00328016  -0.0188331
  0.0833014   -0.0592411   0.0434237    0.0826684    0.0421542    0.103684    0.00598872   0.0738578    0.052685     0.0374456    0.0349776   -0.0400643   -0.113059    0.112876     0.155889    -0.122352     0.075698    -0.0439302   -0.0658221     0.149972     -0.227304     -0.152242     0.0847604   -0.0469733    0.0182716    0.0403911
 -0.110894    -0.0982532  -0.0772828   -0.119273    -0.144019    -0.0708774   0.1669      -0.102956     0.0642832    0.0099055   -0.0444481    0.0183125   -0.0980337  -0.0191022   -0.00972283  -0.0123301    0.03956      0.05819     -0.190926     -0.0258458    -0.0559719     0.00860104  -0.0882786   -0.0355543   -0.0748154    0.0936434
 -0.21366     -0.0426043   0.0645106    0.038544    -0.0766927    0.0246255  -0.041184     0.102971    -0.0169586    0.0714689   -0.0724869   -0.0219034    0.191529    0.112213     0.0362256    0.0260398    0.0471893   -0.185319     0.000707097   0.153276     -0.000692483   0.0764523    0.107898    -0.0975555    0.157112     0.00423958
  0.122377     0.130758   -0.014318    -0.218974     0.0971797    0.104541    0.171763    -0.0717055   -0.0605823   -0.0297792   -0.120172    -0.223409    -0.0700846   0.139557    -0.071366    -0.133255     0.0681398   -0.0791543    0.0418674    -0.0513154     0.000270856   0.090131    -0.0101232    0.131344    -0.0838544   -0.131784
  0.00673349   0.0242127   0.116049     0.0113391   -0.107179     0.0538811   0.0359558   -0.0599315   -0.175332    -0.0307057    0.0190706   -0.0831546   -0.130402   -0.0569662   -0.0184792   -0.0398191    0.0897063   -0.00771641  -0.0103455     0.0207415    -0.0572185     0.0554833    0.00385104   0.0451188    0.098495     0.0335817
 -0.0361998   -0.0885118  -0.00685558   0.00314499   0.0390973    0.0300354  -0.148821    -0.0440994    0.0136351   -0.0902363    0.0441093    0.0339683   -0.0831743   0.0017509   -0.0219691   -0.00214514   0.152041    -0.046792    -0.0130116    -0.142701     -0.18135      -0.0316983   -0.124814    -0.0634099   -0.0752157    0.103112
  0.119245     0.0466256   0.0388428   -0.00965261   0.0376133    0.0390996  -0.0676313   -0.0503636    0.0203445    0.0326669    0.0417017   -0.0938869    0.0763977   0.126255     0.0680274   -0.0340126   -0.0701976    0.227491     0.0458203    -0.000687288   0.0932539     0.0143175   -0.117242     0.0266426   -0.0999168   -0.153366
  0.0316216   -0.0581597   0.118938     0.0412234   -0.0500646   -0.02295     0.037405     0.417562    -0.0607241   -0.0427694   -0.025407    -0.0191951   -0.0486924  -0.0507908    0.0158484    0.0673106    0.0857488   -0.0304422    0.152151     -0.0360208    -0.121457     -0.0690948    0.0387388   -0.0760424    0.0197225   -0.082098
  0.110096    -0.0124678  -0.193503    -0.0906444   -0.117277     0.312736    0.0825841   -0.155143     0.138316     0.073018     0.0344889    0.0205648    0.109789   -0.0296647   -0.0587725   -0.154926     0.0443726    0.124353     0.0623136    -0.183511      0.0156683    -0.0222835   -0.0385481   -0.0773106   -0.106192    -0.0370243
 -0.147068     0.0669132  -0.00925591   0.203402     0.128852    -0.0212576   0.0883334   -0.0545343   -0.0231763    0.0712737    0.00306917  -0.031501     0.123039   -0.0301087   -0.0442632    0.0486194   -0.118609    -0.0365996   -0.00550344    0.0337448     0.037045     -0.198197    -0.00586837  -0.201656     0.0322514    0.131671
  0.0843841    0.0523222   0.137017     0.071757     0.0552655   -0.0364592  -0.0130225   -0.105486    -0.0563236   -0.216483    -0.0739632    0.0706387    0.122363    0.0027774    0.235375    -0.0452607   -0.14914      0.194108     0.147187     -0.0510297     0.0718708    -0.0191433   -0.0950566   -0.0108395   -0.0280294    0.0912189
 -0.0755346   -0.0310443  -0.118733     0.116408     0.0563117   -0.0903356   0.0457586   -0.117585    -0.0693446    0.0229905    0.0513663   -0.00113998  -0.0676634  -0.0459444   -0.0702658    0.105899     0.269707     0.102067     0.0136349     0.0579664    -0.0748956    -0.0181646    0.055121    -0.00535076  -0.125065    -0.0693512
 -0.0361944   -0.0799703  -0.105182    -0.0540782    0.102903    -0.0236557  -0.133663    -0.105132    -0.03469     -0.0414174    0.0709417   -0.111546     0.0330906   0.00561106  -0.223179    -0.213265     0.210561     0.133137    -0.0745841    -0.0736322    -0.000533299  -0.12487     -0.148191    -0.0578673   -0.0335606    0.00237754
  0.154628    -0.0464738  -0.0426561   -0.0689685   -0.0720122   -0.0385675  -0.0565116    0.188819    -0.0168922   -0.0174718   -0.0971229   -0.0185807   -0.0159254   0.0970622   -0.0412551    0.244542    -0.0465304    0.203155     0.0697221    -0.231344     -0.00604902   -0.0195477   -0.229347    -0.0413193    0.0439333   -0.0390004
  0.0487529   -0.0222415   0.0925127    0.0533555    0.134476     0.0180947  -0.0979541    0.0635977   -0.0466779    0.00255027   0.0714933   -0.0323485   -0.0227444  -0.0474493    0.0285037   -0.0250196   -0.0300795   -0.017506     0.0127676     0.0353239    -0.0101506     0.0403144    0.175052    -0.0303758   -0.0333089    0.00143533
  0.199875    -0.0293196   0.016843     0.0127489   -0.00194655   0.11525     0.00596545  -0.0559687    0.129193    -0.0116552   -0.126052    -0.0171244   -0.0983924   0.0342646    0.0387413    0.0699323   -0.104743    -0.00366965  -0.0858689     0.00515537    0.0635047    -0.0676871    0.0289296    0.149114     0.0280437    0.0509561
  0.143768    -0.0284805   0.0992242    0.0325189    0.0632931   -0.0797492  -0.0118366   -0.116813     0.0660637    0.0673905   -0.117766     0.0482262    0.02008     0.0845587   -0.0556396   -0.183888    -0.134477     0.00754573   0.0818104    -0.0769983    -0.00483217   -0.0542079   -0.0119673    0.0381088   -0.070842    -0.0575396
 -0.0947782   -0.0954846   0.249609     0.0654751   -0.156184     0.0318901   0.0490148    0.216428    -0.120178    -0.00404553  -0.0550194   -0.0268838   -0.0855538  -0.0918588   -0.0262245    0.0676465    0.0620943   -0.0937264    0.146099     -0.0179481    -0.172004     -0.113047    -0.0486327   -0.0824499    0.0526528   -0.262011
 -0.0069548   -0.0242756  -0.0410397    0.111824     0.092781     0.0569517  -0.0786968    0.10646      0.0671026   -0.0730395   -0.105425    -0.013282    -0.0954812   0.0129389    0.00286409   0.0377557   -0.0724935    0.039144     0.00403758   -0.094322      0.228967     -0.0519949   -0.0467691    0.168115     0.0847685    0.117099
 -0.0870956   -0.0709171   0.0588742    0.0568949   -0.127691     0.0320209   0.0672779    0.0127867    0.103226     0.0430569    0.139472     0.0773657   -0.121919   -0.0596393   -0.132579    -0.0380302    0.00718146   0.176343     0.102991      0.0525911     0.133496      0.00280424   0.0355808   -0.0917776   -0.087787     0.0278361
 -0.0867139    0.1267     -0.0291789    0.061037     0.122559     0.0682637  -0.0206786    0.0713288    0.0420889   -0.0741684   -0.0550218    0.00511609   0.0724664  -0.0599286   -0.0305726    0.142628     0.125713     0.129387     0.214776     -0.111829     -0.0902751    -0.00928147   0.0343159   -0.097456     0.0972648    0.0632825
  0.147896    [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
-0.0115313  -0.128399     0.0624647   -0.0848833    0.171521    0.0796125    0.025799    -0.066218    -0.110336     0.0184362   -0.0597968    0.0808477  -0.00942309   0.0835475   -0.0468965    0.109184     0.0487634    0.212091     -0.0151507     0.061449     -0.12662      0.0245121    0.0496162    0.117479    -0.0516061
  0.0120543   -0.213757    0.0725001   -0.129632     0.133637     0.117047   -0.038978     0.119711    -0.0686597    0.0406549   -0.0587713   -0.0113302   -0.017212   -0.165926    -0.00859006  -0.086337    -0.0830702   -0.221767     0.0716089    -0.0165537    -0.107631      0.0291483   -0.0167907    0.0831153   -0.0259067   -0.0182621
 -0.0013908   -0.12868    -0.0441093   -0.136066     0.0223186    0.0234216  -0.0439279   -0.190557     0.00165138  -0.0236619   -0.104342    -0.0701898    0.242686   -0.00213086   0.0118034   -0.125661    -0.0081141    0.0401072   -0.0199969    -0.0412569    -0.00619829   -0.0492073    0.0689359    0.0461704   -0.0511295   -0.00743858┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     12
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.064517
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      5
│     12
│     22
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.011435
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      3
│      5
│      9
│      ⋮
│     24
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.999771
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      5
│     12
│     22
│     24
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.036086
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│     12
│     22
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.020443
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      3
│      5
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.992333
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     12
│     22
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.046838
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│      5
│     12
│     22
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.012740
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      3
│      5
│      9
│      ⋮
│     24
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.999916
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      5
│     12
│     22
│     24
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.038235
┌ Info: EM with 100000 data points 10 iterations avll -1.038235
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.017104     0.0322028   -0.225201    -0.120829     0.168733     0.125585     0.0158517   0.191066     0.101638    -0.138017     0.0743136   -0.126015    -0.0139887    0.0340938   -0.262949     -0.0161299    -0.015004     -0.221631    0.0444638   -0.0114855   -0.0363348   0.0450693    0.188798      0.126326    -0.0392829    0.0116992
  0.0318918   -0.0333964    0.0404135    0.0108694    0.0420157    0.12902     -0.057164   -0.0789502   -0.0949647   -0.0528689   -0.0297719    0.0150027   -0.158372     0.0559708   -0.0431916    -0.0354495    -0.037192      0.115562   -0.0543479   -0.0749391   -0.098084   -0.163732    -0.0981148    -0.0674138    0.0114891    0.164451
 -0.0461683   -0.125375     0.0323782    0.0883805   -0.0563077   -0.034873    -0.0303774   0.0951427    0.0871076   -0.134378     0.0876045    0.109191    -0.174472     0.0436604   -0.0351468    -0.0787831    -0.110416      0.0374017   0.0107547    0.0834467    0.0765737   0.0439889   -0.140354      0.0146567   -0.0653395    0.0893685
 -0.0815984    0.0094337   -0.0286742   -0.10893     -0.240963     0.0207518   -0.0778327  -0.132337     0.224438     0.0938879   -0.103821     0.0502459    0.076899     0.0542615    0.132064      0.0726184     0.0344692     0.168322   -0.0578671   -0.0217145   -0.103549    0.0577584    0.0542794    -0.0217831    0.0332728    0.0222348
 -0.0116393   -0.0798444   -0.103299     0.082791    -0.0614057   -0.0415698   -0.0516678   0.00612495   0.0530661    0.102664    -0.102202     0.0613202    0.0999794    0.0673192    0.106056     -0.146237      0.118824     -0.0431137   0.106943     0.231996    -0.160668    0.0626883   -0.010315     -0.00134006   0.0358138   -0.118645
  0.0673471    0.089498     0.0262414    0.181297     0.059417     0.0231877   -0.0545937  -0.00591113   0.0867891   -0.0711441   -0.0489019    0.110008    -0.0189137   -0.153611     0.0899006     0.000905948  -0.0846097    -0.0924676  -0.0337941   -0.131978     0.0936028   0.010314    -0.0972479     0.162612     0.0255536    0.0122111
 -0.0328909    0.0384911    0.0163686    0.196573    -0.0843974   -0.177731    -0.0331357   0.0338476    0.061702     0.122965     0.0728671   -0.145667     0.18154     -0.0587115   -0.0485412    -0.0188434     0.0334338    -0.145289   -0.0801822   -0.0544564   -0.0958762  -0.0166538   -0.0608213    -0.0270886    0.117825     0.0665483
 -0.146902     0.0890212   -0.111374    -0.042959    -0.0779351   -0.0815196   -0.177783   -0.0367735    0.0299008    0.0822954    0.121572     0.0182968   -0.071999     0.0428319   -0.0910906    -0.0880809     0.0384741    -0.0979366   0.159606    -0.221221    -0.0312738  -0.0692923    0.297162      0.130685     0.0229874   -0.117009
 -0.17168      0.0665233    0.0771452   -0.091356    -0.0986458   -0.0256465   -0.0635322  -0.247282     0.0877141    0.193809    -0.00863921  -0.00745363  -0.0982856    0.1258      -0.0267692     0.143142      0.0455058     0.012748    0.00290921   0.0994093   -0.0401666  -0.0889415    0.0670018    -0.0285999    0.0723051    0.0249252
 -0.0583364   -0.202044     0.0190032   -0.00184083   0.112164     0.00547215   0.0239662  -0.150531     0.0379551    0.109743     0.0738338    0.00265391  -0.152336     0.114314     0.0309199     0.0204932    -0.00668199    0.0854443  -0.0598921   -0.0637837   -0.156343    0.0319812   -0.0702625    -0.0261206   -0.00198191   0.142274
 -0.0203469   -0.162932     0.00135236   0.00632696   0.0654795   -0.0430675    0.0111496  -0.0639458    0.0412872   -0.109101    -0.0442374    0.0922958   -0.0461771   -0.0216209   -0.0743093    -0.0300848    -0.150034      0.0869796  -0.0288462    0.0371306    0.0993965  -0.00967566  -0.0540126     0.108282    -0.0236244   -0.121521
  0.0342869   -0.0771257   -0.027443     0.0428547    0.0326013   -0.00543385   0.174269   -0.173482    -0.0230611   -0.0570214    0.0654246   -0.018186     0.0114491    0.175263    -0.190623     -0.146222     -0.192418     -0.0312265  -0.0627355    0.0411675    0.221722   -0.0535461   -0.0171918     0.127703     0.0955803   -0.123959
  0.0774876    0.137281     0.0712086   -0.0155069    0.0337265   -0.073766     0.146268    0.221702    -0.0711741    0.00587816   0.280143    -0.0516025   -0.129065    -0.0241041   -0.0441443     0.0302447     0.0595788     0.0403016  -0.29856      0.0135799   -0.0876199   0.0315024   -0.138493      0.0892663    0.133239    -0.0193471
 -0.119412    -0.0921364   -0.035828    -0.0378032    0.0598896    0.0781644   -0.271606    0.0139975    0.0538844    0.0211035   -0.118867    -0.0526431   -0.100836     0.17851     -0.0532191    -0.0420595    -0.0384592     0.030619    0.0457045    0.0432103    0.0121133   0.0329233    0.00372595    0.110996    -0.018663    -0.0761105
 -0.0623132   -0.125167    -0.0348425    0.0170928    0.00716316   0.132989    -0.0405667  -0.216878     0.0624006    0.0438245    0.12677      0.0192417    0.0971062    0.0468617    0.0364381    -0.0307084     0.0659163    -0.139715    0.156214    -0.0642924    0.0210284  -0.0127234   -0.0435107    -0.196601    -0.00109493  -0.104711
  0.0729438    0.0364574    0.0449041   -0.138906    -0.16564      0.0703566    0.122713    0.0832747    0.0525375   -0.159282     0.179412    -0.0628771   -0.0669058   -0.00910792   0.149526     -0.0557091    -0.0933737    -0.137633   -0.0404995   -0.0892006   -0.129112   -0.0267378    0.00824833    0.0499347   -0.151694     0.0211392
  0.119377    -0.00689377  -0.0193634   -0.030182     0.0900907    0.0773606   -0.0484125   0.156461     0.00712989   0.0879438    0.0492351   -0.0885571    0.0953161    0.10974     -0.0128103     0.0463978     0.0015106     0.0881741   0.065721    -0.0216109   -0.107055   -0.0150876    0.0552517    -0.143741     0.0958064   -0.160464
 -0.0877374   -0.043045    -0.0222586    0.0760733   -0.013974    -0.0562455   -0.0727153  -0.0391604   -0.0937636   -0.169117     0.141877     0.0698615    0.157278    -0.0336215    0.0987146    -0.139553     -0.117926     -0.0803278   0.0947892   -0.108764    -0.0473968   0.0125263   -0.241891     -0.0479111   -0.0888521   -0.0261459
  0.0732442    0.0916992   -0.0868577   -0.276053    -0.0054858   -0.127795    -0.0220741  -0.0502885   -0.0195775   -0.046423    -0.10328     -0.0620106   -0.0240916    0.155271    -0.041342      0.0143817     0.171344      0.0948658   0.105601    -0.04836     -0.188427    0.0453342   -0.0204317     0.189529    -0.023331     0.0622999
  0.158934     0.0719284    0.10637     -0.0352996   -0.024449    -0.0030866    0.20384     0.089628    -0.0226978   -0.0669346   -0.0866905   -0.0122793    0.158073     0.0522639   -0.0936692     0.0215252     0.150116     -0.0384058  -0.167327    -0.0189952   -0.12275    -0.0994887    0.000564244  -0.102154    -0.039953    -0.019176
  0.113262    -0.0327027   -0.0454255   -0.0165822   -0.0407194   -0.0087529   -0.196015    0.0306307    0.0519849    0.220585     0.167596    -0.00487692  -0.0923248   -0.228762    -0.12018       0.0286483     0.000677612  -0.0532755  -0.0272551    0.077975    -0.0935227   0.116151    -0.123223      0.119733     0.0755016   -0.00997774
 -0.0167651   -0.0158681    0.0388569    0.0830327   -0.0176528   -0.00791585   0.0437586  -0.0158181   -0.106736    -0.0623798    0.0685492    0.0835266    0.0287271   -0.0102463   -0.0323661    -0.0273201     0.0851976     0.103776    0.0146244   -0.068789     0.0936401   0.142893    -0.152952      0.166142     0.0498629   -0.101858
 -0.0183289    0.029206     0.138215    -0.110713    -0.154941    -0.047477     0.217948    0.0363606    0.0765793    0.0868884    0.194506    -0.107764    -0.00348403  -0.0740679    0.0831444    -0.0591823     0.103157     -0.0299555  -0.0658742    0.203831    -0.100105    0.0978016    0.0904159     0.0472232   -0.112016     0.0265878
 -0.0523558    0.0930171    0.185151    -0.0216931    0.061666     0.084452    -0.0379063  -0.0944443    0.0583306    0.0532489    0.108036     0.193896    -0.0218014    0.0339249   -0.0812823    -0.0996477    -0.0751796    -0.141928    0.177161     0.00473259   0.0848091  -0.0650084    0.140495      0.162065     0.160432    -0.0046307
  0.0727026   -0.189427     0.152119    -0.105315    -0.0745351   -0.092164    -0.0791443   0.106379    -0.00971619   0.158036     0.139224     0.0894122    0.110102    -0.150706     0.0725931     0.0140656    -0.0936946    -0.0962134  -0.266807     0.139493    -0.19171     0.00674024   0.00283792    0.0464415    0.0602488   -0.0544513
  0.040524     0.0153709   -0.0884543    0.0685245    0.0770669    0.0803189   -0.0618045   0.0872779   -0.234958    -0.0992954   -0.0746985    0.200763    -0.079903     0.0999231    0.0784546    -0.0898232     0.045736     -0.100716   -0.0869569   -0.133976     0.133591   -0.0647786   -0.0746314    -0.123376    -0.0681439   -0.0314851
  0.182003     0.0747231    0.158607     0.0872225    0.0411024   -0.0433047    0.164871   -0.0480366    0.0326764    0.23068      0.0731277   -0.145031     0.0558692    0.0579983   -0.0750129    -0.0460882    -0.100748     -0.128454   -0.187644     0.114237     0.109534   -0.030802    -0.0741574     0.0408335    0.196879    -0.0518074
  0.031935     0.0324187    0.0285516   -0.146704     0.048759     0.0326394    0.0555671   0.188604    -0.263327     0.00721877  -0.0924178    0.00653264  -0.196838    -0.0590138   -0.000922889  -0.0765801    -0.0498379    -0.0238094  -0.109422     0.0379251    0.101293    0.108043     0.0813464    -0.00918866   0.00110487   0.0266127
  0.0215857   -0.106232    -0.0352987   -0.0267345   -0.0856719    0.111694     0.0179226   0.0891337   -0.134238     0.163714     0.207702    -0.0345019    0.0177986    0.103021     0.0883054    -0.123773      0.169542      0.0329475   0.00458236  -0.180783     0.128237    0.128252    -0.165213     -0.209639    -0.102057    -0.231097
 -0.104767    -0.0126747    0.0861805   -0.0537118    0.0742428    0.107824    -0.0890099  -0.106051     0.065511    -0.00517462   0.0114417   -0.0767053    0.0387871    0.0457788    0.0324591     0.0610371    -0.00380077   -0.0485703   0.0827809   -0.0608192   -0.036743   -0.0849278   -0.224095      0.159822    -0.00592302   0.0482404
 -0.0697763    0.141557     0.0222304    0.120474    -0.0552618   -0.0276301    0.0065229   0.0720392   -0.0383074   -0.0550396   -0.0101185    0.141218     0.0939188    0.144901     0.0460798     0.173753      0.0255289     0.0813165  -0.0713727    0.0104042   -0.121105    0.106172    -0.0979873     0.0446004   -0.104379    -0.0277687
  0.00520887  -0.014304    -0.07927      0.0662193    0.0166005   -0.225568     0.046228   -0.0497532   -0.110304     0.132765    -0.186104     0.00808981  -0.0537363   -0.0409342   -0.069835     -0.0563504     0.0568981     0.17305     0.219094     0.0157263    0.16139     0.0680556    0.0253038    -0.120222    -0.036525     0.0168713kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4242507126866037
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.424270
[ Info: iteration 2, average log likelihood -1.424202
[ Info: iteration 3, average log likelihood -1.424148
[ Info: iteration 4, average log likelihood -1.424084
[ Info: iteration 5, average log likelihood -1.424008
[ Info: iteration 6, average log likelihood -1.423922
[ Info: iteration 7, average log likelihood -1.423835
[ Info: iteration 8, average log likelihood -1.423755
[ Info: iteration 9, average log likelihood -1.423692
[ Info: iteration 10, average log likelihood -1.423646
[ Info: iteration 11, average log likelihood -1.423617
[ Info: iteration 12, average log likelihood -1.423598
[ Info: iteration 13, average log likelihood -1.423586
[ Info: iteration 14, average log likelihood -1.423578
[ Info: iteration 15, average log likelihood -1.423572
[ Info: iteration 16, average log likelihood -1.423567
[ Info: iteration 17, average log likelihood -1.423563
[ Info: iteration 18, average log likelihood -1.423557
[ Info: iteration 19, average log likelihood -1.423550
[ Info: iteration 20, average log likelihood -1.423538
[ Info: iteration 21, average log likelihood -1.423515
[ Info: iteration 22, average log likelihood -1.423469
[ Info: iteration 23, average log likelihood -1.423374
[ Info: iteration 24, average log likelihood -1.423181
[ Info: iteration 25, average log likelihood -1.422810
[ Info: iteration 26, average log likelihood -1.422170
[ Info: iteration 27, average log likelihood -1.421263
[ Info: iteration 28, average log likelihood -1.420298
[ Info: iteration 29, average log likelihood -1.419570
[ Info: iteration 30, average log likelihood -1.419165
[ Info: iteration 31, average log likelihood -1.418979
[ Info: iteration 32, average log likelihood -1.418901
[ Info: iteration 33, average log likelihood -1.418869
[ Info: iteration 34, average log likelihood -1.418856
[ Info: iteration 35, average log likelihood -1.418850
[ Info: iteration 36, average log likelihood -1.418848
[ Info: iteration 37, average log likelihood -1.418847
[ Info: iteration 38, average log likelihood -1.418846
[ Info: iteration 39, average log likelihood -1.418845
[ Info: iteration 40, average log likelihood -1.418845
[ Info: iteration 41, average log likelihood -1.418845
[ Info: iteration 42, average log likelihood -1.418844
[ Info: iteration 43, average log likelihood -1.418844
[ Info: iteration 44, average log likelihood -1.418844
[ Info: iteration 45, average log likelihood -1.418844
[ Info: iteration 46, average log likelihood -1.418843
[ Info: iteration 47, average log likelihood -1.418843
[ Info: iteration 48, average log likelihood -1.418843
[ Info: iteration 49, average log likelihood -1.418843
[ Info: iteration 50, average log likelihood -1.418843
┌ Info: EM with 100000 data points 50 iterations avll -1.418843
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4242696229380638
│     -1.4242021774903155
│      ⋮
└     -1.4188429156054563
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418862
[ Info: iteration 2, average log likelihood -1.418791
[ Info: iteration 3, average log likelihood -1.418733
[ Info: iteration 4, average log likelihood -1.418664
[ Info: iteration 5, average log likelihood -1.418583
[ Info: iteration 6, average log likelihood -1.418493
[ Info: iteration 7, average log likelihood -1.418404
[ Info: iteration 8, average log likelihood -1.418327
[ Info: iteration 9, average log likelihood -1.418265
[ Info: iteration 10, average log likelihood -1.418220
[ Info: iteration 11, average log likelihood -1.418188
[ Info: iteration 12, average log likelihood -1.418164
[ Info: iteration 13, average log likelihood -1.418146
[ Info: iteration 14, average log likelihood -1.418132
[ Info: iteration 15, average log likelihood -1.418120
[ Info: iteration 16, average log likelihood -1.418110
[ Info: iteration 17, average log likelihood -1.418101
[ Info: iteration 18, average log likelihood -1.418092
[ Info: iteration 19, average log likelihood -1.418084
[ Info: iteration 20, average log likelihood -1.418076
[ Info: iteration 21, average log likelihood -1.418068
[ Info: iteration 22, average log likelihood -1.418060
[ Info: iteration 23, average log likelihood -1.418052
[ Info: iteration 24, average log likelihood -1.418043
[ Info: iteration 25, average log likelihood -1.418033
[ Info: iteration 26, average log likelihood -1.418023
[ Info: iteration 27, average log likelihood -1.418013
[ Info: iteration 28, average log likelihood -1.418001
[ Info: iteration 29, average log likelihood -1.417990
[ Info: iteration 30, average log likelihood -1.417978
[ Info: iteration 31, average log likelihood -1.417966
[ Info: iteration 32, average log likelihood -1.417954
[ Info: iteration 33, average log likelihood -1.417942
[ Info: iteration 34, average log likelihood -1.417931
[ Info: iteration 35, average log likelihood -1.417919
[ Info: iteration 36, average log likelihood -1.417908
[ Info: iteration 37, average log likelihood -1.417898
[ Info: iteration 38, average log likelihood -1.417889
[ Info: iteration 39, average log likelihood -1.417880
[ Info: iteration 40, average log likelihood -1.417872
[ Info: iteration 41, average log likelihood -1.417865
[ Info: iteration 42, average log likelihood -1.417859
[ Info: iteration 43, average log likelihood -1.417853
[ Info: iteration 44, average log likelihood -1.417848
[ Info: iteration 45, average log likelihood -1.417843
[ Info: iteration 46, average log likelihood -1.417839
[ Info: iteration 47, average log likelihood -1.417835
[ Info: iteration 48, average log likelihood -1.417832
[ Info: iteration 49, average log likelihood -1.417829
[ Info: iteration 50, average log likelihood -1.417826
┌ Info: EM with 100000 data points 50 iterations avll -1.417826
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4188616491733146
│     -1.4187905936897278
│      ⋮
└     -1.4178258608890504
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417833
[ Info: iteration 2, average log likelihood -1.417775
[ Info: iteration 3, average log likelihood -1.417719
[ Info: iteration 4, average log likelihood -1.417647
[ Info: iteration 5, average log likelihood -1.417551
[ Info: iteration 6, average log likelihood -1.417428
[ Info: iteration 7, average log likelihood -1.417281
[ Info: iteration 8, average log likelihood -1.417122
[ Info: iteration 9, average log likelihood -1.416967
[ Info: iteration 10, average log likelihood -1.416828
[ Info: iteration 11, average log likelihood -1.416710
[ Info: iteration 12, average log likelihood -1.416614
[ Info: iteration 13, average log likelihood -1.416539
[ Info: iteration 14, average log likelihood -1.416482
[ Info: iteration 15, average log likelihood -1.416439
[ Info: iteration 16, average log likelihood -1.416407
[ Info: iteration 17, average log likelihood -1.416383
[ Info: iteration 18, average log likelihood -1.416364
[ Info: iteration 19, average log likelihood -1.416350
[ Info: iteration 20, average log likelihood -1.416337
[ Info: iteration 21, average log likelihood -1.416326
[ Info: iteration 22, average log likelihood -1.416317
[ Info: iteration 23, average log likelihood -1.416308
[ Info: iteration 24, average log likelihood -1.416300
[ Info: iteration 25, average log likelihood -1.416292
[ Info: iteration 26, average log likelihood -1.416285
[ Info: iteration 27, average log likelihood -1.416278
[ Info: iteration 28, average log likelihood -1.416271
[ Info: iteration 29, average log likelihood -1.416265
[ Info: iteration 30, average log likelihood -1.416258
[ Info: iteration 31, average log likelihood -1.416251
[ Info: iteration 32, average log likelihood -1.416245
[ Info: iteration 33, average log likelihood -1.416238
[ Info: iteration 34, average log likelihood -1.416231
[ Info: iteration 35, average log likelihood -1.416225
[ Info: iteration 36, average log likelihood -1.416218
[ Info: iteration 37, average log likelihood -1.416211
[ Info: iteration 38, average log likelihood -1.416204
[ Info: iteration 39, average log likelihood -1.416197
[ Info: iteration 40, average log likelihood -1.416190
[ Info: iteration 41, average log likelihood -1.416182
[ Info: iteration 42, average log likelihood -1.416175
[ Info: iteration 43, average log likelihood -1.416167
[ Info: iteration 44, average log likelihood -1.416159
[ Info: iteration 45, average log likelihood -1.416152
[ Info: iteration 46, average log likelihood -1.416144
[ Info: iteration 47, average log likelihood -1.416136
[ Info: iteration 48, average log likelihood -1.416128
[ Info: iteration 49, average log likelihood -1.416119
[ Info: iteration 50, average log likelihood -1.416111
┌ Info: EM with 100000 data points 50 iterations avll -1.416111
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4178330489472613
│     -1.4177752564107282
│      ⋮
└     -1.4161110931854841
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416110
[ Info: iteration 2, average log likelihood -1.416049
[ Info: iteration 3, average log likelihood -1.415991
[ Info: iteration 4, average log likelihood -1.415924
[ Info: iteration 5, average log likelihood -1.415843
[ Info: iteration 6, average log likelihood -1.415745
[ Info: iteration 7, average log likelihood -1.415629
[ Info: iteration 8, average log likelihood -1.415500
[ Info: iteration 9, average log likelihood -1.415366
[ Info: iteration 10, average log likelihood -1.415235
[ Info: iteration 11, average log likelihood -1.415112
[ Info: iteration 12, average log likelihood -1.415001
[ Info: iteration 13, average log likelihood -1.414904
[ Info: iteration 14, average log likelihood -1.414820
[ Info: iteration 15, average log likelihood -1.414749
[ Info: iteration 16, average log likelihood -1.414688
[ Info: iteration 17, average log likelihood -1.414637
[ Info: iteration 18, average log likelihood -1.414594
[ Info: iteration 19, average log likelihood -1.414557
[ Info: iteration 20, average log likelihood -1.414525
[ Info: iteration 21, average log likelihood -1.414497
[ Info: iteration 22, average log likelihood -1.414473
[ Info: iteration 23, average log likelihood -1.414450
[ Info: iteration 24, average log likelihood -1.414429
[ Info: iteration 25, average log likelihood -1.414410
[ Info: iteration 26, average log likelihood -1.414392
[ Info: iteration 27, average log likelihood -1.414375
[ Info: iteration 28, average log likelihood -1.414358
[ Info: iteration 29, average log likelihood -1.414342
[ Info: iteration 30, average log likelihood -1.414326
[ Info: iteration 31, average log likelihood -1.414312
[ Info: iteration 32, average log likelihood -1.414297
[ Info: iteration 33, average log likelihood -1.414283
[ Info: iteration 34, average log likelihood -1.414269
[ Info: iteration 35, average log likelihood -1.414256
[ Info: iteration 36, average log likelihood -1.414243
[ Info: iteration 37, average log likelihood -1.414230
[ Info: iteration 38, average log likelihood -1.414218
[ Info: iteration 39, average log likelihood -1.414206
[ Info: iteration 40, average log likelihood -1.414195
[ Info: iteration 41, average log likelihood -1.414184
[ Info: iteration 42, average log likelihood -1.414173
[ Info: iteration 43, average log likelihood -1.414162
[ Info: iteration 44, average log likelihood -1.414152
[ Info: iteration 45, average log likelihood -1.414142
[ Info: iteration 46, average log likelihood -1.414133
[ Info: iteration 47, average log likelihood -1.414124
[ Info: iteration 48, average log likelihood -1.414115
[ Info: iteration 49, average log likelihood -1.414106
[ Info: iteration 50, average log likelihood -1.414097
┌ Info: EM with 100000 data points 50 iterations avll -1.414097
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4161104843408667
│     -1.4160491829105049
│      ⋮
└     -1.4140974066131933
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414098
[ Info: iteration 2, average log likelihood -1.414035
[ Info: iteration 3, average log likelihood -1.413976
[ Info: iteration 4, average log likelihood -1.413909
[ Info: iteration 5, average log likelihood -1.413826
[ Info: iteration 6, average log likelihood -1.413722
[ Info: iteration 7, average log likelihood -1.413597
[ Info: iteration 8, average log likelihood -1.413453
[ Info: iteration 9, average log likelihood -1.413297
[ Info: iteration 10, average log likelihood -1.413138
[ Info: iteration 11, average log likelihood -1.412982
[ Info: iteration 12, average log likelihood -1.412834
[ Info: iteration 13, average log likelihood -1.412698
[ Info: iteration 14, average log likelihood -1.412575
[ Info: iteration 15, average log likelihood -1.412464
[ Info: iteration 16, average log likelihood -1.412366
[ Info: iteration 17, average log likelihood -1.412278
[ Info: iteration 18, average log likelihood -1.412201
[ Info: iteration 19, average log likelihood -1.412131
[ Info: iteration 20, average log likelihood -1.412070
[ Info: iteration 21, average log likelihood -1.412015
[ Info: iteration 22, average log likelihood -1.411965
[ Info: iteration 23, average log likelihood -1.411920
[ Info: iteration 24, average log likelihood -1.411879
[ Info: iteration 25, average log likelihood -1.411841
[ Info: iteration 26, average log likelihood -1.411807
[ Info: iteration 27, average log likelihood -1.411774
[ Info: iteration 28, average log likelihood -1.411744
[ Info: iteration 29, average log likelihood -1.411716
[ Info: iteration 30, average log likelihood -1.411689
[ Info: iteration 31, average log likelihood -1.411664
[ Info: iteration 32, average log likelihood -1.411641
[ Info: iteration 33, average log likelihood -1.411618
[ Info: iteration 34, average log likelihood -1.411597
[ Info: iteration 35, average log likelihood -1.411577
[ Info: iteration 36, average log likelihood -1.411558
[ Info: iteration 37, average log likelihood -1.411540
[ Info: iteration 38, average log likelihood -1.411522
[ Info: iteration 39, average log likelihood -1.411506
[ Info: iteration 40, average log likelihood -1.411490
[ Info: iteration 41, average log likelihood -1.411475
[ Info: iteration 42, average log likelihood -1.411461
[ Info: iteration 43, average log likelihood -1.411447
[ Info: iteration 44, average log likelihood -1.411434
[ Info: iteration 45, average log likelihood -1.411422
[ Info: iteration 46, average log likelihood -1.411409
[ Info: iteration 47, average log likelihood -1.411398
[ Info: iteration 48, average log likelihood -1.411387
[ Info: iteration 49, average log likelihood -1.411376
[ Info: iteration 50, average log likelihood -1.411365
┌ Info: EM with 100000 data points 50 iterations avll -1.411365
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.414097888861059
│     -1.41403488986897
│      ⋮
└     -1.4113650495840477
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4242507126866037
│     -1.4242696229380638
│     -1.4242021774903155
│     -1.4241480018908594
│      ⋮
│     -1.4113865236195904
│     -1.4113756200380647
└     -1.4113650495840477
32×26 Array{Float64,2}:
  0.730075     0.0633509    0.220436    -0.0432696   0.24507    -0.140304    -0.151853    -0.247766   -0.288236   -0.00395608  -0.2533     -0.823728     0.70614      0.396459    -0.0142537  -0.0535694   -0.202331    0.366687    -0.00676873   0.413055    -0.0239422   0.412209    -0.36119     0.262225   -0.279483    0.549563
  0.296664    -0.0608349    0.0823369    0.686537    0.5916     -0.62593     -0.419226     0.0877507   0.0471301  -0.832016    -0.378874    0.487093     0.606616     0.248916    -0.0577703  -0.359273    -0.19326     0.236653     0.104105    -0.627396     0.123295    0.318202    -0.531413   -0.0467662  -0.458156    0.101669
  0.168604    -0.152339    -0.00610706  -0.291196    0.247774    0.600253    -0.0216423   -0.513038   -0.146247   -0.503808     0.275987   -0.164236    -0.396256    -0.034224    -0.486      -0.0454693    0.606849   -0.266149    -0.0334568   -0.0525066   -0.0880806   0.0831103   -0.634936    0.886074   -0.256957    0.0831691
  0.0908237   -0.434325     0.276788    -0.0718048  -0.199097    1.02332     -0.183957    -0.467359    0.236364   -0.0182461   -0.0704448  -0.136438    -0.480063    -0.00384214   0.560835    0.306509    -0.0533429  -0.159178     0.385978    -0.566313    -0.660427   -0.415348    -0.130609    0.238902   -0.586667    0.37309
  0.0236413    0.0538792   -0.096487    -0.0508686   0.661025   -0.106415     0.719733     0.778718   -0.639252    0.235181     0.691694    0.119098    -0.161029    -0.145338    -0.258249   -0.411399    -0.0226049  -0.837547     0.0336896   -0.440628    -0.304439    0.0677142    0.477697   -0.651093    0.18044     0.487809
 -0.511074     0.125552     0.193379    -0.110899   -0.476832   -0.0253859    0.50996      0.0401669  -0.113688    0.3364       0.395625    0.757953    -0.881938    -0.168102    -0.331797    0.0977906    0.115664   -0.407443     0.0364758   -0.371084    -0.0912682  -0.458473     0.401412    0.0996682   0.182288    0.0236584
 -0.325868    -0.58059     -0.61686      0.132403    0.151021   -0.495861     0.302478     0.253891    0.0298186   0.0223444    0.204507    0.141575     0.30277     -0.30178     -0.798671    0.00141311  -0.423474    0.0159612   -0.153314    -0.191436    -0.0921893  -0.369155     0.0192433  -0.328419   -0.0423047  -0.294892
  0.120364     0.774297     0.12965     -0.133086   -0.292741   -0.769366    -0.0934481    0.389268   -0.42807    -0.26173      0.418011    0.487279     0.18519      0.0891079   -0.490773    0.133271     0.10651     0.352473    -0.327831    -0.415888    -0.634647    0.437378    -0.109679   -0.0505783  -0.338111   -0.44942
  0.399114    -0.0110095   -0.1645      -0.0503399   0.160738    0.586541    -0.693045     0.0393044   0.308441   -0.19744      0.0299292  -0.357089    -0.0175434    0.0947816    0.867308   -0.429115     0.481396   -0.00526836  -0.0512797    0.0904067   -0.1737      0.424408     0.198179   -0.196845   -0.0136165   0.116228
  0.0491073   -0.0606465   -0.0730968    0.1175     -0.142499   -0.21452     -0.132821    -0.0451214   0.236061    0.171824    -0.140441    0.204129    -0.0299231    0.138999    -0.0949162   0.0707034   -0.160411    0.28598     -0.13585      0.0211209    0.130606   -0.157946    -0.0579254   0.0270247   0.0499782  -0.0827842
 -0.574321    -0.00333529   0.0465433    0.266479   -0.0775376   0.0844461   -0.624651     0.0776679   0.36273     0.153029    -0.241306   -0.452839     0.518403     0.163146     0.421132    0.0849587   -0.0794446  -0.327058    -0.40078      0.759357    -0.154778   -0.303461     0.0288215   0.513421    0.185795    0.135074
 -0.616746     0.00179868   0.355921     0.378651   -0.568524    0.196275    -0.262701     0.998784    0.358339    0.344945     0.103567   -0.24225      0.221062    -0.0894018    0.499896   -0.193778    -0.66697    -0.0863548   -0.359734    -0.0936095   -0.0996789  -0.00395471   0.0676159  -0.0920816   0.121091   -0.0666218
 -0.649588     0.557613    -0.284562    -0.148401   -0.37366    -0.176863     0.596013     0.2739     -0.493049   -0.156338    -0.235263   -0.434574     0.822354     0.0797757   -0.300076    0.0456153    0.0788645  -0.582092     0.507258     0.00736121  -0.201769    0.363951     0.153411    0.231405    0.306548   -0.0718558
 -0.249797    -0.431984     0.419873    -0.27503    -0.319007   -0.0434706    0.0458517   -0.355561   -0.466781    0.188856    -0.388237   -0.371536     0.866657    -0.0281063   -0.156418    0.971334    -0.013871   -0.039921     0.569318     0.261687    -0.029768    0.0294055   -0.73326     0.180026   -0.0497938  -0.351893
 -0.209977    -0.197993     1.00345     -0.419381   -0.243809   -0.0883527    0.0934617    0.55654     0.0400176   0.549625     0.0478926  -0.191511     0.0937828    0.0754846   -0.60766     0.817334     0.334837    0.146223    -1.29436      0.0204148    0.0229552  -0.393032     0.458971    0.462258    0.0183601  -0.000911939
 -0.325379     0.751922     0.382179    -0.319334   -0.437045   -0.116022    -0.270544    -0.2728      0.409576    0.8039       0.076164    0.39145      0.0068695   -0.0464195    0.321515    0.440019     0.25545     0.276148     0.0245459    0.43892     -0.0400316   0.530776     0.624588   -0.134919    0.0618708  -0.0416039
  0.646738    -0.305407    -0.675749     0.0640152   0.50696     0.197427     0.207892    -0.0213041   0.45981    -0.295681    -0.258778   -0.396315    -0.458123    -0.31331      0.336225   -0.969043     0.155536   -0.133378     0.196373     0.226049     0.329667    0.0500641    0.291081    0.270665   -0.225214    0.33154
 -0.0902936    0.289248    -0.475649     0.463595    0.376658   -0.163241    -0.372208     0.313741    0.273089   -0.487299     0.558449    0.427289    -0.751385    -0.46861     -0.0302951  -0.312397     0.25938    -0.293859    -0.119305    -0.498219    -0.352211   -0.167375     0.667403    0.2574     -0.318142   -0.0199306
  0.635247     0.123215     0.112607     0.0556405   0.0973038  -0.635192     0.0231216   -0.274779   -0.22299     0.23943      0.11773     0.185931    -0.414525     0.475709    -0.0904246   0.289074     0.414893    0.125273    -0.0324177   -0.219073    -0.406888   -0.468145     0.224126    0.238582   -0.253363    0.459388
  0.00372127  -0.380459    -0.0195938   -0.204731    0.352734    0.212855    -0.499487    -0.183914    0.546768    0.0629045    0.164113    0.551103    -0.74446      0.042373    -0.0370041   0.0181544   -0.271264    0.464839    -0.463561     0.438084    -0.226146   -0.258417    -0.406169   -0.197753   -0.0134265  -0.503318
 -0.00469679  -0.436685     0.123453    -0.0344882   0.718811    0.145164    -0.0283619   -0.0134445  -0.701803   -0.326726     0.273002   -0.275338     0.360943     0.15047     -0.0506227  -0.2812      -0.401651   -0.179696    -0.301064     0.316582     0.420922    0.0784057   -0.683137   -0.216275    0.60204    -0.312799
  0.146495    -0.58958      0.559288    -0.351472    0.362791   -0.268292     0.238563    -0.13661     0.110782   -0.310569     0.38055    -0.0839626    0.238956     0.198999    -0.256091   -0.556749    -0.328282   -0.596628     0.131409     0.716906     0.400993   -0.539797     0.714731   -0.240204    0.118494   -0.180419
  0.0123354   -0.238379    -0.00378338  -0.384394   -0.0321716   0.0786423    0.00612186  -0.0115636   0.150835    0.219828    -0.780723   -0.13384      0.140866    -0.0112046    0.347838   -0.49509     -0.36191     0.265697     0.187721     0.211966     0.704009   -0.131766    -0.292852   -0.375409    0.689208   -0.021664
 -0.152459    -0.455543    -0.24555      0.18322     0.0553221   0.561954     0.43851     -0.256587    0.493519    0.0468286    0.440649    0.232388    -0.473676     0.118659     0.601177   -0.171704    -0.0884022  -0.0898233    0.0279098    0.426935     0.820191   -0.11058      0.488952   -0.152744    0.489655    0.0436272
 -0.0433828   -0.129305     0.220751    -0.139507   -0.215036   -0.0479245   -0.0196746    0.265291    0.040918    0.134363     0.339674    0.084334    -0.15637      0.144321    -0.20507    -0.400391     0.0997039  -0.353025    -0.221608    -0.445653     0.0525029  -0.351007     0.122642    0.0149005   0.335187    0.22482
 -0.397636     0.110402    -0.0775371   -0.0742944  -0.431975    0.112873     0.265757     0.113947   -0.137216    0.524784     0.219242   -0.0518649    0.0196857   -0.0537499    0.0186859   0.438346    -0.138083   -0.200724     0.036307     0.101616    -0.207725   -0.13898      0.152811   -0.217465    0.275874   -0.132506
 -0.058641    -0.329336    -0.141422     0.0682556   0.113921    0.0118297   -0.137359    -0.184462   -0.0898779  -0.155008     0.111358   -0.0731217    0.216291     0.0378274   -0.032993    0.0738654    0.0666404  -0.0722652    0.041335     0.109292    -0.349664    0.117836    -0.0388362  -0.0981074  -0.367593   -0.0937846
  0.108941     0.0528454   -0.0843804    0.0999877   0.098836   -0.0301733    0.0303589    0.0554407   0.0153198  -0.0314256   -0.0461121   0.00288887  -0.0198137    0.092874     0.0552547  -0.0539321   -0.0283938   0.160644    -0.0348247    0.0595734    0.137888    0.0689949   -0.0431343   0.031533    0.0413077  -0.048322
  0.683872     0.177543    -0.328147     0.0325342   0.0767587   0.11424      0.505296    -0.649896   -0.341879   -0.301332     0.165944    0.166574    -0.167147    -0.135492     0.0798734  -0.332612     0.127853    0.29769      0.591991    -0.44153      0.0641679   0.55674     -0.259891   -0.721385   -0.0765593  -0.459375
  0.0103451    0.303406    -0.820246     0.221734   -0.0707172   0.00730051   0.413872     0.387311    0.0914192   0.346136    -0.340984    0.155784    -0.143314[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
    -0.0623619   -0.320163    0.451443     0.294937    0.390947    -0.0686996   -0.402677     0.135227    0.501908    -0.345004   -0.294382   -0.0210152   0.0364575
 -0.0122112    0.380692     0.670705    -0.236438    0.0230131   0.103411     0.0361737   -0.105712   -0.346262   -0.019471    -0.0162253  -0.114718     0.00442871  -0.0157732   -0.224348    0.0708867    0.0714669  -0.300038     0.389606    -0.130235     0.0082049   0.249635    -0.344501    0.452092   -0.0781828   0.0577577
  0.221582     0.368781     0.490577    -0.0384557  -0.483799   -0.0687929   -0.564296    -0.398919    0.315831   -0.106722    -0.331301   -0.0560127    0.0303479    0.131377     0.358111   -0.0160318    0.164662    0.409624    -0.135186     0.0181199    0.252969    0.110323    -0.281291    0.777749   -0.0541232  -0.239196[ Info: iteration 1, average log likelihood -1.411355
[ Info: iteration 2, average log likelihood -1.411345
[ Info: iteration 3, average log likelihood -1.411335
[ Info: iteration 4, average log likelihood -1.411326
[ Info: iteration 5, average log likelihood -1.411316
[ Info: iteration 6, average log likelihood -1.411307
[ Info: iteration 7, average log likelihood -1.411298
[ Info: iteration 8, average log likelihood -1.411290
[ Info: iteration 9, average log likelihood -1.411281
[ Info: iteration 10, average log likelihood -1.411273
┌ Info: EM with 100000 data points 10 iterations avll -1.411273
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.136598e+05
      1       7.076498e+05      -2.060100e+05 |       32
      2       6.928363e+05      -1.481353e+04 |       32
      3       6.868529e+05      -5.983369e+03 |       32
      4       6.840563e+05      -2.796598e+03 |       32
      5       6.824525e+05      -1.603821e+03 |       32
      6       6.812967e+05      -1.155800e+03 |       32
      7       6.803819e+05      -9.148122e+02 |       32
      8       6.796419e+05      -7.399234e+02 |       32
      9       6.790477e+05      -5.942839e+02 |       32
     10       6.785356e+05      -5.120816e+02 |       32
     11       6.780704e+05      -4.651836e+02 |       32
     12       6.776503e+05      -4.200476e+02 |       32
     13       6.772711e+05      -3.792807e+02 |       32
     14       6.769364e+05      -3.346257e+02 |       32
     15       6.766183e+05      -3.181532e+02 |       32
     16       6.763260e+05      -2.922324e+02 |       32
     17       6.760837e+05      -2.423642e+02 |       32
     18       6.758390e+05      -2.447253e+02 |       32
     19       6.756057e+05      -2.332120e+02 |       32
     20       6.753752e+05      -2.305109e+02 |       32
     21       6.751583e+05      -2.169237e+02 |       32
     22       6.749528e+05      -2.055371e+02 |       32
     23       6.747640e+05      -1.887995e+02 |       32
     24       6.745962e+05      -1.678170e+02 |       32
     25       6.744480e+05      -1.482051e+02 |       32
     26       6.743144e+05      -1.335741e+02 |       32
     27       6.741888e+05      -1.255339e+02 |       32
     28       6.740678e+05      -1.210155e+02 |       32
     29       6.739502e+05      -1.175999e+02 |       32
     30       6.738455e+05      -1.047767e+02 |       32
     31       6.737584e+05      -8.701985e+01 |       32
     32       6.736835e+05      -7.491311e+01 |       32
     33       6.736037e+05      -7.984735e+01 |       32
     34       6.735356e+05      -6.810256e+01 |       32
     35       6.734715e+05      -6.409673e+01 |       32
     36       6.734152e+05      -5.628086e+01 |       32
     37       6.733616e+05      -5.356115e+01 |       32
     38       6.733065e+05      -5.516666e+01 |       32
     39       6.732532e+05      -5.328447e+01 |       32
     40       6.732031e+05      -5.005449e+01 |       32
     41       6.731522e+05      -5.091288e+01 |       32
     42       6.731038e+05      -4.838557e+01 |       32
     43       6.730608e+05      -4.298108e+01 |       32
     44       6.730221e+05      -3.877491e+01 |       32
     45       6.729830e+05      -3.902836e+01 |       32
     46       6.729452e+05      -3.781189e+01 |       32
     47       6.729111e+05      -3.410346e+01 |       32
     48       6.728794e+05      -3.174647e+01 |       32
     49       6.728503e+05      -2.907765e+01 |       32
     50       6.728290e+05      -2.128913e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 672829.0152934989)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422904
[ Info: iteration 2, average log likelihood -1.418026
[ Info: iteration 3, average log likelihood -1.416787
[ Info: iteration 4, average log likelihood -1.415906
[ Info: iteration 5, average log likelihood -1.414939
[ Info: iteration 6, average log likelihood -1.413950
[ Info: iteration 7, average log likelihood -1.413185
[ Info: iteration 8, average log likelihood -1.412723
[ Info: iteration 9, average log likelihood -1.412458
[ Info: iteration 10, average log likelihood -1.412288
[ Info: iteration 11, average log likelihood -1.412163
[ Info: iteration 12, average log likelihood -1.412064
[ Info: iteration 13, average log likelihood -1.411981
[ Info: iteration 14, average log likelihood -1.411909
[ Info: iteration 15, average log likelihood -1.411847
[ Info: iteration 16, average log likelihood -1.411793
[ Info: iteration 17, average log likelihood -1.411744
[ Info: iteration 18, average log likelihood -1.411701
[ Info: iteration 19, average log likelihood -1.411661
[ Info: iteration 20, average log likelihood -1.411625
[ Info: iteration 21, average log likelihood -1.411593
[ Info: iteration 22, average log likelihood -1.411562
[ Info: iteration 23, average log likelihood -1.411534
[ Info: iteration 24, average log likelihood -1.411508
[ Info: iteration 25, average log likelihood -1.411484
[ Info: iteration 26, average log likelihood -1.411462
[ Info: iteration 27, average log likelihood -1.411441
[ Info: iteration 28, average log likelihood -1.411421
[ Info: iteration 29, average log likelihood -1.411402
[ Info: iteration 30, average log likelihood -1.411384
[ Info: iteration 31, average log likelihood -1.411368
[ Info: iteration 32, average log likelihood -1.411352
[ Info: iteration 33, average log likelihood -1.411337
[ Info: iteration 34, average log likelihood -1.411323
[ Info: iteration 35, average log likelihood -1.411309
[ Info: iteration 36, average log likelihood -1.411296
[ Info: iteration 37, average log likelihood -1.411284
[ Info: iteration 38, average log likelihood -1.411272
[ Info: iteration 39, average log likelihood -1.411261
[ Info: iteration 40, average log likelihood -1.411250
[ Info: iteration 41, average log likelihood -1.411240
[ Info: iteration 42, average log likelihood -1.411230
[ Info: iteration 43, average log likelihood -1.411220
[ Info: iteration 44, average log likelihood -1.411210
[ Info: iteration 45, average log likelihood -1.411201
[ Info: iteration 46, average log likelihood -1.411192
[ Info: iteration 47, average log likelihood -1.411183
[ Info: iteration 48, average log likelihood -1.411174
[ Info: iteration 49, average log likelihood -1.411166
[ Info: iteration 50, average log likelihood -1.411157
┌ Info: EM with 100000 data points 50 iterations avll -1.411157
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.228243     0.402492     0.337557    -0.000697112  -0.589989    -0.131637    -0.140608    0.537538    0.124454    0.318193     0.379019     0.0915024    0.159975     0.506801    0.106239    -0.166586     0.00887832  -0.511967   -0.47444    -0.035011    0.209751    -0.2043      0.621948    0.123402    0.619494     0.165245
 -0.196993    -0.0508939    0.0604982   -0.476574     -0.225851     0.626499     0.261663   -0.375718   -0.275953    0.212009     0.178597    -0.239531    -0.0482467   -0.0544678   0.11457      0.324697     0.178314    -0.406847    0.42268     0.164173    0.0406903    0.0518663  -0.0696659   0.0709678   0.166883    -0.0931915
 -0.459816    -0.0474317    0.279162     0.218967     -0.0884501    0.11054     -0.524005    0.0633055   0.413584    0.161281    -0.23838     -0.442268     0.426821    -0.0198839   0.464157     0.144524    -0.21974     -0.113252   -0.392591    0.738769   -0.21286     -0.196992   -0.102928    0.506145   -0.0655368    0.00920129
 -0.168677     0.238582     0.688862    -0.546216     -0.628643    -0.593545    -0.0320535   0.5284     -0.839213   -0.0102659    0.378689     0.0122583    0.536892     0.132641   -0.149899     0.608446     0.165481     0.188868   -0.129997   -0.0889703  -0.883981     0.211246   -0.372565   -0.0795275  -0.280976    -0.758214
  0.530248     0.188267    -0.209219    -0.149528     -0.068218     0.00411585   0.282467   -0.0922525  -0.119544   -0.355777     0.102414     0.27558     -0.255661    -0.0674694  -0.0720162   -0.380439     0.330377     0.238657    0.263738   -0.6703      0.131792     0.351333   -0.264696   -0.513026   -0.0110421   -0.259634
  0.543835    -0.254274    -0.65812      0.0412        0.40919      0.401757     0.219307   -0.115935    0.701234   -0.187964    -0.244343    -0.235956    -0.504785    -0.25486     0.350778    -0.882364     0.217574    -0.204933    0.138798    0.300302    0.565346     0.128433    0.39402     0.244536   -0.0907681    0.263557
  0.127631    -0.0176804    0.22076      0.0437271    -0.503847    -0.491965     0.484468   -0.0752573  -0.282332    0.548222    -0.133684     0.193246    -0.213417     0.591466   -0.166133     0.296906    -0.055462     0.100599   -0.103097   -0.503005   -0.130991    -0.555051    0.0340027   0.137459   -0.00553684   0.449515
  0.335207     0.00751484   0.00464415  -0.034151      0.015355     0.301772    -0.41678    -0.0190995   0.276553   -0.310917     0.00252638  -0.00668958  -0.0793092    0.303676    0.516513    -0.365889     0.354621     0.0875872  -0.234267    0.0758017  -0.0104301    0.312238   -0.0385382   0.0178104  -0.018628     0.00778342
  0.437993    -0.23181     -0.208005     0.083045      0.365774     0.108972     0.322789   -0.930273   -0.499978   -0.345102    -0.21069      0.0496914   -0.0497289   -0.329014   -0.145819     0.0909699   -0.0138638    0.457134    0.4048     -0.332322   -0.284981     0.322857   -0.786982   -0.0616716  -0.427616    -0.287261
 -0.0584209   -0.214991     0.335112    -0.218085      0.250857     0.400779    -0.0403996   0.265087   -0.506054    0.127741     0.404666    -0.549542    -0.194442    -0.524962    0.460184    -0.843077    -0.0913682   -0.340798    0.349586   -0.238386   -0.298102    -0.179608   -0.0778971   0.468063    0.512615     0.938359
  0.0908543    0.130465    -0.239231     0.808371      0.283557    -0.588806    -0.598666    0.346255    0.209865   -0.83082     -0.0461549    0.30813     -0.0762815   -0.162508   -0.137424    -0.572714    -0.16745     -0.0118324  -0.185705   -0.653062   -0.340811    -0.0840018   0.16982     0.0694174  -0.575265     0.00971864
 -0.343273    -0.03849      0.0758296    0.118907     -0.656149    -0.0120862    0.097303    0.239753    0.318232    1.10585     -0.0426393    0.0302949    0.087355    -0.128016    0.00820033   0.570516    -0.214643     0.0497337  -0.152895    0.0333862   0.0683938   -0.230078    0.213031   -0.0163741   0.0124493    0.154664
  0.319512    -0.224397     0.631715    -0.232347      0.340564    -0.0288192   -0.664519    0.0494411  -0.139487   -0.147809    -0.15448     -0.239782     0.802802     0.424271   -0.589729     0.0454447    0.0976442   -0.332126    0.140627   -0.15319     0.109891     0.500236   -0.851658    0.412777   -0.740845     0.48121
 -0.117598     0.152922    -0.456164     0.714835      0.0615723    0.187218     0.253694    0.438474   -0.151511    0.415774    -0.0224765    0.0954724   -0.0781872   -0.163355   -0.00716643   0.310721    -0.133453     0.173765   -0.0987791  -0.108415    0.00388639   0.496605   -0.235851   -0.19076    -0.219742    -0.00904751
 -0.180142     0.0725509    0.287326    -0.157123     -0.169647     0.240008    -0.0140645  -0.0110281   0.431776   -0.0956756    0.726064     0.202996    -0.734011    -0.221156   -0.262784     0.575928     0.816459    -0.492802   -0.105602   -0.127023   -0.376202    -0.0332238   0.154749    0.914908   -0.648899     0.105879
 -0.024556    -0.0540973   -0.0101277    0.0431717     0.00573802  -0.0444223   -0.0297724   0.0308299   0.0160294   0.00500318   0.0673148    0.00396282  -0.00799059   0.0746999  -0.0230111   -0.00761458  -8.86137e-5  -0.022679   -0.0566037   0.0332311  -0.0523012   -0.0527107   0.0535666   0.0420871  -0.0156618   -0.0213798
  0.693561     0.230671    -0.118711     0.302488      0.382261    -0.507985    -0.0730935  -0.333411   -0.295482   -0.101565    -0.0125399   -0.527291     0.160041     0.324935    0.221002    -0.040862     0.441415     0.182258    0.0848782   0.212187   -0.147804     0.291863    0.0385288   0.336299   -0.324282     0.606717
 -0.402589     0.243409    -0.809986     0.162452     -0.352442    -0.466488     0.147535    0.0160758   0.615609   -0.249492    -0.410744     0.252498     0.420938     0.0719927  -0.928158     0.547593    -0.00581122   0.26982    -0.376005   -0.23231     0.820457     0.524952   -0.111746    0.0439054  -0.18805     -0.930352
 -0.526431    -0.0728191   -0.653007     0.236957      0.00626299  -0.170379     0.535276    0.0990162  -0.576032   -0.426814     0.214955    -0.182857     0.8076       0.110364   -0.530947    -0.0249832   -0.0707308   -0.424549    0.167414    0.0703824  -0.35369      0.06424    -0.144297   -0.0182573   0.193608    -0.398595
  0.411253    -0.458311    -0.201094    -0.1152        0.662021    -0.214012    -0.13789     0.0191786   0.0504488   0.306814     0.618355     0.300223    -0.316264     0.142195   -0.411958     0.276777     0.123167     0.156461   -0.364627    0.0937461  -0.441031    -0.346323    0.0571588  -0.451911   -0.226874     0.0164992
  0.0239719   -0.65488      0.480107    -0.314347      0.535551    -0.106872     0.345236   -0.103411   -0.0601745  -0.493973     0.388241    -0.00537471   0.142108     0.184511   -0.226162    -0.414237    -0.261169    -0.79281     0.172366    0.593918    0.402711    -0.35137     0.377582   -0.353266    0.0959751   -0.15734
  0.0425245    0.498252     0.0743198    0.121704      0.180779    -0.566081     0.490913    0.330968   -0.667097   -0.0620215    0.36882      0.427147    -0.243899    -0.24564    -0.761127     0.0233734   -0.211572    -0.305056    0.177841   -0.608867   -0.224016     0.0777169   0.118621   -0.120131   -0.0254377    0.00416339
 -0.0909923   -0.41094      0.0608463   -0.264967      0.051619     0.246502    -0.452331   -0.327192    0.487599   -0.228376    -0.0348778    0.362013    -0.786335     0.343967    0.0335886   -0.197248    -0.145692     0.421284   -0.385422    0.300987    0.0368238   -0.601081   -0.386625    0.335907    0.224754    -0.350726
 -0.165007     0.821872     0.229502    -0.361602     -0.327528    -0.169788    -0.365016   -0.337692    0.354159    0.571789    -0.174889     0.430818    -0.0912012   -0.017539    0.341917     0.412566     0.399805     0.493459    0.0935099   0.422422   -0.114596     0.610507    0.460917   -0.17199     0.0513796   -0.213676
  0.194127     0.36131      0.696391    -0.115936     -0.137549    -0.0241392   -0.297792   -0.425898   -0.114147   -0.187139    -0.1943      -0.0702446    0.0436193    0.107015    0.075886    -0.164255     0.0416328    0.138018    0.203604   -0.0921072   0.257066     0.144241   -0.420327    0.782639    0.00307013  -0.155864
 -0.795537    -0.279816    -0.0686432   -0.275352     -0.123764     0.131552    -0.0453706   0.321368    0.426602    0.382538     0.157549     0.0641657   -0.0109065   -0.559571   -0.267359    -0.179721    -0.653592    -0.300309    0.0598084  -0.206864   -0.151743    -0.165181   -0.0386497  -0.523198    0.289655    -0.387361
  0.260492    -0.0441382   -0.293522     0.0302079    -0.118231     0.940378    -0.8639     -0.207371    0.862118   -0.252715    -0.4002      -0.282583    -0.141631     0.160183    0.638933     0.047082     0.167469    -0.0984977   0.429494   -0.64929    -0.978488    -0.216205    0.518315   -0.370485   -0.489948     0.337943
 -0.402036     0.00462399  -0.330101     0.155818      0.122895     0.214897     0.656906    0.136309    0.0212318   0.262835     0.813622     0.709872    -0.973242    -0.265564    0.290889    -0.479214     0.187329    -0.194245   -0.157696   -0.300031    0.0687041   -0.346915    0.87761    -0.28272     0.444561     0.00646962
 -0.217816     0.286007    -0.0686191   -0.502815      0.108107    -0.221295     0.285397    0.788362   -0.195592    0.227827    -0.485677     0.0487042    0.172885    -0.301584   -0.787145     0.319502     0.490292     0.174123   -0.309501   -0.720358   -0.269558    -0.041537   -0.137291   -0.0205963   0.151596     0.437916
 -0.00530311  -0.0896409    0.382125    -0.222326     -0.275514     0.163577    -0.14096    -0.189946   -0.193144    0.0346999   -0.648686    -0.716687     0.907248     0.173087    0.16106      0.327318    -0.352667     0.244781    0.264213    0.49316     0.346864     0.215016   -0.575591    0.250556    0.34258     -0.178332
  0.253597    -0.206587    -0.530376     0.647301      0.0953438   -0.362127     0.203358   -0.136985    0.0722867  -0.251388     0.280196     0.126105     0.0109847    0.0732136   0.75367     -0.120206    -0.628384     0.665559    0.41786     0.492425    0.328358    -0.0780929   0.505631   -1.16822     0.307939    -0.423893
  0.1388      -0.466269    -0.0585658   -0.233644      0.354031     0.100165    -0.0871446   0.0932375  -0.138588    0.0633032   -0.320837    -0.190127     0.347481     0.134131    0.0889828   -0.422439    -0.396269     0.104385   -0.242903    0.347139    0.673568    -0.0132162  -0.39139    -0.343376    0.69552      0.0153616[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411149
[ Info: iteration 2, average log likelihood -1.411141
[ Info: iteration 3, average log likelihood -1.411133
[ Info: iteration 4, average log likelihood -1.411125
[ Info: iteration 5, average log likelihood -1.411117
[ Info: iteration 6, average log likelihood -1.411109
[ Info: iteration 7, average log likelihood -1.411102
[ Info: iteration 8, average log likelihood -1.411094
[ Info: iteration 9, average log likelihood -1.411087
[ Info: iteration 10, average log likelihood -1.411079
┌ Info: EM with 100000 data points 10 iterations avll -1.411079
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
