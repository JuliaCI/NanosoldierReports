Julia Version 1.4.0-DEV.666
Commit 2835347ff0 (2019-12-26 15:28 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed DataAPI ──────────── v1.1.0
 Installed GaussianMixtures ─── v0.3.0
 Installed URIParser ────────── v0.4.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed PDMats ───────────── v0.9.10
 Installed Missings ─────────── v0.4.3
 Installed OrderedCollections ─ v1.1.0
 Installed Parameters ───────── v0.12.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed CMake ────────────── v1.1.2
 Installed Rmath ────────────── v0.6.0
 Installed BinaryProvider ───── v0.5.8
 Installed DataStructures ───── v0.17.6
 Installed StatsFuns ────────── v0.9.3
 Installed Clustering ───────── v0.13.3
 Installed BinDeps ──────────── v1.0.0
 Installed OpenBLAS_jll ─────── v0.3.7+1
 Installed Distances ────────── v0.8.2
 Installed HDF5 ─────────────── v0.12.5
 Installed SpecialFunctions ─── v0.9.0
 Installed Distributions ────── v0.21.11
 Installed JLD ──────────────── v0.9.1
 Installed StaticArrays ─────── v0.12.1
 Installed StatsBase ────────── v0.32.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed Blosc ────────────── v0.5.1
 Installed FileIO ───────────── v1.2.0
 Installed FillArrays ───────── v0.8.2
 Installed QuadGK ───────────── v2.3.1
 Installed NearestNeighbors ─── v0.4.4
 Installed SortingAlgorithms ── v0.3.1
 Installed LegacyStrings ────── v0.4.1
 Installed Compat ───────────── v2.2.0
 Installed Arpack ───────────── v0.4.0
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_1htoan/Project.toml`
 [no changes]
  Updating `/tmp/jl_1htoan/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_e8MzjX/Project.toml`
 [no changes]
  Updating `/tmp/jl_e8MzjX/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_bwnIR5/Project.toml`
 [no changes]
  Updating `/tmp/jl_bwnIR5/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_ehSaUT/Project.toml`
 [no changes]
  Updating `/tmp/jl_ehSaUT/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_DLMK79/Project.toml`
 [no changes]
  Updating `/tmp/jl_DLMK79/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_DLMK79/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.0
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.4459718496812708e6, [68229.74177923001, 31770.25822077], [-19047.399551061633 -2914.8744820902593 -17992.92141891059; 19306.54833799978 3396.130521647742 17899.048393769037], [[63067.04206367219 -2741.973846564114 4344.108996318904; -2741.973846564115 70410.46642914892 -6965.602274070498; 4344.108996318904 -6965.602274070498 72417.4510090902], [36718.58755567715 2868.2994441680557 -4214.569505347815; 2868.2994441680557 29591.68391163828 7523.749725763484; -4214.569505347814 7523.749725763484 27994.599743206898]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.292721e+03
      1       9.580276e+02      -3.346938e+02 |        6
      2       8.771404e+02      -8.088723e+01 |        5
      3       8.136883e+02      -6.345207e+01 |        2
      4       7.972853e+02      -1.640299e+01 |        0
      5       7.972853e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 797.2853036418765)
┌ Info: K-means with 272 data points using 5 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.054830
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.808658
[ Info: iteration 2, lowerbound -3.689993
[ Info: iteration 3, lowerbound -3.557616
[ Info: iteration 4, lowerbound -3.400950
[ Info: iteration 5, lowerbound -3.236448
[ Info: iteration 6, lowerbound -3.084259
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.952876
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.843437
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.749415
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.658172
[ Info: iteration 11, lowerbound -2.577859
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.504898
[ Info: iteration 13, lowerbound -2.438422
[ Info: iteration 14, lowerbound -2.388401
[ Info: iteration 15, lowerbound -2.350943
[ Info: iteration 16, lowerbound -2.324193
[ Info: iteration 17, lowerbound -2.309489
[ Info: iteration 18, lowerbound -2.308596
[ Info: dropping number of Gaussions to 2
[ Info: iteration 19, lowerbound -2.302915
[ Info: iteration 20, lowerbound -2.299259
[ Info: iteration 21, lowerbound -2.299256
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299254
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sat Dec 28 11:41:41 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sat Dec 28 11:41:49 2019: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Sat Dec 28 11:41:51 2019: EM with 272 data points 0 iterations avll -2.054830
5.8 data points per parameter
, Sat Dec 28 11:41:53 2019: GMM converted to Variational GMM
, Sat Dec 28 11:42:01 2019: iteration 1, lowerbound -3.808658
, Sat Dec 28 11:42:01 2019: iteration 2, lowerbound -3.689993
, Sat Dec 28 11:42:01 2019: iteration 3, lowerbound -3.557616
, Sat Dec 28 11:42:01 2019: iteration 4, lowerbound -3.400950
, Sat Dec 28 11:42:01 2019: iteration 5, lowerbound -3.236448
, Sat Dec 28 11:42:01 2019: iteration 6, lowerbound -3.084259
, Sat Dec 28 11:42:02 2019: dropping number of Gaussions to 7
, Sat Dec 28 11:42:02 2019: iteration 7, lowerbound -2.952876
, Sat Dec 28 11:42:02 2019: dropping number of Gaussions to 6
, Sat Dec 28 11:42:02 2019: iteration 8, lowerbound -2.843437
, Sat Dec 28 11:42:02 2019: dropping number of Gaussions to 5
, Sat Dec 28 11:42:02 2019: iteration 9, lowerbound -2.749415
, Sat Dec 28 11:42:02 2019: dropping number of Gaussions to 4
, Sat Dec 28 11:42:02 2019: iteration 10, lowerbound -2.658172
, Sat Dec 28 11:42:02 2019: iteration 11, lowerbound -2.577859
, Sat Dec 28 11:42:02 2019: dropping number of Gaussions to 3
, Sat Dec 28 11:42:02 2019: iteration 12, lowerbound -2.504898
, Sat Dec 28 11:42:02 2019: iteration 13, lowerbound -2.438422
, Sat Dec 28 11:42:02 2019: iteration 14, lowerbound -2.388401
, Sat Dec 28 11:42:02 2019: iteration 15, lowerbound -2.350943
, Sat Dec 28 11:42:02 2019: iteration 16, lowerbound -2.324193
, Sat Dec 28 11:42:02 2019: iteration 17, lowerbound -2.309489
, Sat Dec 28 11:42:02 2019: iteration 18, lowerbound -2.308596
, Sat Dec 28 11:42:02 2019: dropping number of Gaussions to 2
, Sat Dec 28 11:42:02 2019: iteration 19, lowerbound -2.302915
, Sat Dec 28 11:42:02 2019: iteration 20, lowerbound -2.299259
, Sat Dec 28 11:42:02 2019: iteration 21, lowerbound -2.299256
, Sat Dec 28 11:42:02 2019: iteration 22, lowerbound -2.299254
, Sat Dec 28 11:42:02 2019: iteration 23, lowerbound -2.299254
, Sat Dec 28 11:42:02 2019: iteration 24, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 25, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 26, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 27, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 28, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 29, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 30, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 31, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 32, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 33, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 34, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 35, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 36, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 37, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 38, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 39, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 40, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 41, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 42, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 43, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 44, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 45, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 46, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 47, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 48, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 49, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: iteration 50, lowerbound -2.299253
, Sat Dec 28 11:42:02 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398595, 178.0450922260141]
β = [95.95490777398595, 178.0450922260141]
m = [2.0002292577753686 53.85198717246128; 4.250300733269906 79.28686694436179]
ν = [97.95490777398595, 180.0450922260141]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763611948439 -0.00895312382734591; 0.0 0.012748664777409303], [0.18404155547484718 -0.007644049042327703; 0.0 0.008581705166333305]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.012324862462705
avll from llpg:  -1.0123248624627041
avll direct:     -1.0123248624627041
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9235252309246952
avll from llpg:  -0.9235252309246952
avll direct:     -0.9235252309246953
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.0258937  -0.0477415    0.0435039   -0.260479      0.00921238  -0.074404     0.117151    -0.0366567   -0.0616966    0.0206397    0.256549    -0.1307       0.137109     -0.0115346    0.0144168    0.130234    -0.0620764     0.0794861    0.0295036    0.0926935   -0.121461     -0.0896134  -0.00152708   0.0107145     0.0350591   -0.00731031
 -0.142832   -0.110076     0.120033     0.18442       0.100518    -0.0263619   -0.0018258    0.108221     0.18431     -0.238215    -0.0783848    0.138394     0.212004     -0.0298653   -0.206617    -0.322745    -0.0337477     0.226788    -0.0824       0.0227177    0.187317     -0.0319807  -0.021369     0.0662936     0.0403489    0.130865
 -0.0414942  -0.1278       0.00130371   0.028659      0.101502     0.141638     0.0677123   -0.113313    -0.132837     0.139912     0.111736    -0.0150823    0.0074944    -0.176157    -0.0118624    0.0201919    0.109527     -0.0141047   -0.0497477   -0.0651454   -0.0503018     0.100412   -0.0215857   -0.125723     -0.25325      0.0406854
  0.196838   -0.0884822    0.090966     0.144077      0.193031    -0.04246      0.0211963    0.0515501    0.0773026   -0.129406     0.205771    -0.0968727    0.0571421    -0.149884     0.127335     0.141508     0.0408609    -0.119121    -0.0771448   -0.120674    -0.0142045     0.0464474   0.0866227    0.222172     -0.129635    -0.165443
  0.150026    0.149043     0.0841111   -0.0312479    -0.0752089    0.0623412    0.0313482   -0.0416125   -0.13885     -0.0474944    0.0615708    0.04782      0.125784      0.130539     0.113573     0.0206518   -0.251615      0.211906    -0.0411876    0.148114    -0.0148825     0.149      -0.0195729   -0.0752745    -0.00482898  -0.0606479
  0.0365605  -0.0594544    0.143891     0.0262277     0.0434157   -0.0540604    0.0483697   -0.0898862    0.0818147    0.0373568    0.0354274    0.24407      0.0231012     0.0548557   -0.073627     0.107038     0.0185576    -0.138181     0.00034851   0.0923173    0.0727521    -0.029114   -0.0313267   -0.137947     -0.0374963   -0.090461
  0.0165363   0.0557251    0.0547014   -0.129191      0.0815438    0.0111493   -0.0523488    0.048396    -0.0144863    0.119442    -0.0746761   -0.00662148   0.0741501     0.118759     0.0411978    0.143957    -0.142788     -0.242213    -0.0620723   -0.00193833   0.005009      0.0457939  -0.0515444    0.0730037    -0.0921259   -0.100031
  0.157087    0.150477     0.0962365    0.0196251    -0.0669283    0.0307672   -0.00822488   0.0938109    0.120581    -0.0338546   -0.0619385   -0.107105     0.0160201     0.0586525   -0.0595202   -0.151708     0.0152624     0.0925761    0.018269     0.120929     0.0152063    -0.0510912  -0.0851257   -0.0732731     0.179031     0.0579074
 -0.0394635   0.116173     0.0854141   -0.18686       0.0773      -0.127769     0.0281488    0.203525     0.089291    -0.0051857    0.00381837   0.00973664   0.0875234     0.0159251   -0.0644871    0.123206    -0.120494     -0.0452667   -0.0233027    0.112264     0.096956     -0.0544864   0.023363     0.138198     -0.0201864   -0.0593908
  0.0763563   0.0352756    0.182452    -0.0748402    -0.0318419   -0.155702     0.100021    -0.102386    -0.0564246    0.227971    -0.102229    -0.0480649    0.0656069    -0.14208     -0.154119     0.139308    -0.188198     -0.0843855    0.189817     0.0594688   -0.163075      0.120798    0.0909232    0.0618527     0.0296504    0.0285043
  0.159753   -0.0590577    0.0403896   -0.179359      0.0782068   -0.0536995   -0.0574558   -0.00777301  -0.141464    -0.0540385    0.0508943   -0.0760962    0.0123417     0.117694    -0.00842029   0.240715     0.0818085    -0.111928     0.0284355   -0.0809661    0.00405244    0.0130566   0.116612    -0.0647511    -0.25476     -0.0548455
  0.0720945   0.023677    -0.0536919   -0.0594567    -0.129879    -0.00113576  -0.105039     0.128632     0.118065     0.094448    -0.124882    -0.0101763    0.295401      0.0350319    0.171821    -0.213184     0.0374935    -0.048998     0.0680311    0.198783     0.0298553    -0.165914    0.195255     0.0346138     0.0562013   -0.144915
 -0.193308   -0.0999852   -0.0812149    0.073406     -0.0054453    0.0810226    0.126048     0.0527455   -0.0573559    0.105744    -0.0276491   -0.0447087   -0.0466116    -0.175823     0.0108387   -0.107199     0.134275      0.25095     -0.0509061    0.186175     0.017448      0.0922605  -0.0590675    0.228695      0.0261341   -0.0352023
  0.0466759   0.147876     0.207499    -0.170262     -0.0359981   -0.117063    -0.16422     -0.222391    -0.0739687   -0.0170225    0.121425     0.019623     0.237148     -0.0587431    0.0723394   -0.0967202    0.0159723    -0.129137     0.0963295   -0.0526159   -0.198622      0.0947227  -0.048442     0.0112285     0.0744888   -0.0208956
 -0.118315   -0.0785479    0.0978399   -0.164993      0.290849    -0.0341984    0.267863     0.0439296    0.00656104  -0.023539     0.171569     0.0879869    0.0400462    -0.0713704    0.0675118    0.139249     0.0286791     0.16106      0.168953    -0.0402682   -0.000437051   0.0151469  -0.0130288    0.000288359  -0.109838    -0.136427
  0.0273408   0.0446004   -0.14522     -0.131928     -0.0141277   -0.157199     0.0595436    0.175626     0.0986794   -0.156443    -0.0176227    0.0561716    0.0451216     0.0631653    0.0810279   -0.0504067   -0.136359     -0.18655     -0.106363     0.121126    -0.0658167     0.0384577  -0.0563778    0.07435      -0.0163606    0.0385301
  0.129484   -0.0730475    0.0804595   -0.000174917   0.208038     0.134587     0.0925797    0.0583372   -0.0776679   -0.216241    -0.0282261   -0.0328828    0.107966      0.0422133   -0.12445     -0.0955293    0.0201344     0.144164    -0.194059    -0.00224151   0.00685695   -0.108004    0.128322    -0.0710342    -0.0919845   -0.0875398
  0.112695   -0.021214     0.10417      0.0248873     0.0832158   -0.0294341   -0.0948539   -0.0415898   -0.196957    -0.00178155   0.0737958   -0.050403     0.035128     -0.101576    -0.0575102    0.124683    -0.000946315  -0.0267552   -0.14934     -0.139778     0.00818392    0.0606294   0.0131969    0.0487293    -0.0705994   -0.0198992
  0.022491   -0.157528     0.0353042   -0.0782034    -0.00833072  -0.0332844    0.0608756    0.107732     0.0105985    0.0587003    0.0593697    0.00652865  -0.0432077    -0.00887207   0.172109    -0.0624444    0.0564625    -0.0507616   -0.109235     0.200113     0.0130909    -0.076973    0.0591966    0.0447182    -0.0285964    0.112543
  0.0110058   0.13332      0.117519     0.0333064     0.0925448   -0.0803826    0.0199812   -0.0128101   -0.209118     0.149319     0.263536    -0.0543421   -0.111736     -0.206769     0.121793    -0.113991    -0.0358794     0.0103484    0.0870312   -0.102356    -0.0810281     0.096575    0.192837    -0.0184465    -0.0124892   -0.214638
 -0.149162   -0.0635284   -0.00578659   0.0549515    -0.0401879   -0.0564027   -0.0867256   -0.155729     0.00883494  -0.14676      0.0427365   -0.0245764   -0.000665814   0.0140869   -0.0187886   -0.101559    -0.0463869     0.0530838    0.179062     0.0502278   -0.168219      0.0278418   0.0509616    0.0589676     0.0630836    0.0309497
 -0.03775     0.0130036    0.0364168    0.068105      0.0374102   -0.0926738    0.00859344   0.0260415    0.0161066    0.0884066   -0.0723216    0.159131    -0.0766348     0.0768437   -0.119481     0.0160364   -0.0323547    -0.006848     0.0411915   -0.138803     0.0692274    -0.104413    0.0911221   -0.0995043     0.0899613    0.0878313
 -0.145872    0.0111179   -0.150985    -0.0564609    -0.20824     -0.110571     0.0549165    0.0394662    0.171468     0.0157427    0.276344    -0.0306503    0.0199761     0.0423958    0.168356     0.0321631    0.00586628    0.0784273   -0.0940006    0.0927805   -0.000317996  -0.135239    0.0931699    0.0447658     0.0549953    0.0169317
  0.0682864  -0.0391553    0.0344558    0.0820053    -0.017035    -0.105212     0.0131388   -0.172135    -0.0454443   -0.216839     0.114327     0.120977     0.174537     -0.00709942  -0.00923609  -0.215791     0.185091      0.150463    -0.165701    -0.0202634   -0.0659175    -0.0459709  -0.0122269   -0.0550006    -0.108702     0.057765
  0.0452375   0.00943181  -0.0528046    0.0180064    -0.144091     0.159402     0.0745       0.132225    -0.117573     0.191283    -0.0677374   -0.0706248    0.0634506     0.00541644  -0.00709429   0.0521428    0.146625      0.0880572   -0.0980954    0.114609    -0.149892      0.0962999   0.160407     0.0299852    -0.00404683   0.0232029
  0.134237   -0.0340666   -0.0229299   -0.0129255    -0.0802789   -0.128327    -0.0069022   -0.105715     6.36066e-5   0.0181141    0.0389999   -0.197529     0.0373571     0.0328908   -0.126631    -0.0844254   -0.085303      0.0860113   -0.0576237    0.0286437   -0.174306     -0.0241374  -0.0357496   -0.12966      -0.0230834   -0.00621245
 -0.0792476  -0.0635797   -0.0607771    0.253211      0.262297     0.117211    -0.0227618   -0.0871557   -0.0727393    0.136645     0.0850255    0.0139725   -0.0173911     0.0541999    0.0688914   -0.00842072  -0.178373     -0.0748883    0.00609709   1.58325e-5   0.0222791    -0.149415    0.0574582    0.0308837     0.204513    -0.0592492
 -0.176327    0.0614043    0.0463152    0.0421968    -0.202029     0.0547112   -0.0327095    0.0592586   -0.071504    -0.0818678    0.0735857    0.00524984   0.0384438     0.117913    -0.00692298  -0.0873059    0.17438      -0.193819    -0.136348     0.178794     0.0824713     0.063505    0.0815632   -0.0568652     0.118407    -0.0760115
  0.0311355   0.17145      0.236315     0.159567      0.0146274    0.00138888  -0.0128296    0.131611     0.0140707   -0.0717716    0.0768766   -0.103138     0.10604      -0.141765     6.26009e-5   0.0405905    0.0493884    -0.0982053    0.0744604   -0.0631034   -0.0658924    -0.0679237   0.00258525  -0.081742     -0.0570003   -0.0205514
 -0.136297   -0.0773421   -0.128885     0.0700493     0.0227493   -0.103286     0.14418     -0.0935667   -0.062381    -0.128399    -0.17257      0.00529057   0.133654      0.0146747   -0.117615     0.0512281    0.0351596    -0.0735401   -0.167886    -0.0224829   -0.130087      0.0791282  -0.04524      0.0487309     0.0223181   -0.121659
  0.0407031   0.11227      0.0781051    0.0347455     0.0818137    0.0300307    0.212688     0.229071    -0.092626    -0.080289     0.0967869    0.0295157    0.0276324     0.0332266    0.00217023  -0.0254344    0.0602425    -0.00654947  -0.0670282    0.0232895   -0.15618      -0.159817   -0.122947    -0.144728     -0.0114397    0.0321357
  0.0255909  -0.159203    -0.104586    -0.0897485     0.0488116   -0.240221     0.0653936    0.0437347    0.0848429   -0.146491     0.0569356    0.0665925    0.0322193    -0.00794336  -0.0672435   -0.0197101   -0.0424533     0.0710733    0.0277719   -0.045861     0.0273212    -0.117195    0.110214    -0.0620748    -0.0722831   -0.0167724kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.452664064232059
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.452729
[ Info: iteration 2, average log likelihood -1.452649
[ Info: iteration 3, average log likelihood -1.451922
[ Info: iteration 4, average log likelihood -1.444810
[ Info: iteration 5, average log likelihood -1.429530
[ Info: iteration 6, average log likelihood -1.424042
[ Info: iteration 7, average log likelihood -1.422965
[ Info: iteration 8, average log likelihood -1.422290
[ Info: iteration 9, average log likelihood -1.421671
[ Info: iteration 10, average log likelihood -1.421074
[ Info: iteration 11, average log likelihood -1.420480
[ Info: iteration 12, average log likelihood -1.419859
[ Info: iteration 13, average log likelihood -1.419194
[ Info: iteration 14, average log likelihood -1.418493
[ Info: iteration 15, average log likelihood -1.417810
[ Info: iteration 16, average log likelihood -1.417165
[ Info: iteration 17, average log likelihood -1.416558
[ Info: iteration 18, average log likelihood -1.415992
[ Info: iteration 19, average log likelihood -1.415422
[ Info: iteration 20, average log likelihood -1.414879
[ Info: iteration 21, average log likelihood -1.414447
[ Info: iteration 22, average log likelihood -1.414126
[ Info: iteration 23, average log likelihood -1.413901
[ Info: iteration 24, average log likelihood -1.413740
[ Info: iteration 25, average log likelihood -1.413617
[ Info: iteration 26, average log likelihood -1.413517
[ Info: iteration 27, average log likelihood -1.413431
[ Info: iteration 28, average log likelihood -1.413346
[ Info: iteration 29, average log likelihood -1.413250
[ Info: iteration 30, average log likelihood -1.413128
[ Info: iteration 31, average log likelihood -1.412965
[ Info: iteration 32, average log likelihood -1.412767
[ Info: iteration 33, average log likelihood -1.412549
[ Info: iteration 34, average log likelihood -1.412334
[ Info: iteration 35, average log likelihood -1.412147
[ Info: iteration 36, average log likelihood -1.411999
[ Info: iteration 37, average log likelihood -1.411886
[ Info: iteration 38, average log likelihood -1.411804
[ Info: iteration 39, average log likelihood -1.411744
[ Info: iteration 40, average log likelihood -1.411699
[ Info: iteration 41, average log likelihood -1.411664
[ Info: iteration 42, average log likelihood -1.411635
[ Info: iteration 43, average log likelihood -1.411610
[ Info: iteration 44, average log likelihood -1.411590
[ Info: iteration 45, average log likelihood -1.411572
[ Info: iteration 46, average log likelihood -1.411557
[ Info: iteration 47, average log likelihood -1.411545
[ Info: iteration 48, average log likelihood -1.411536
[ Info: iteration 49, average log likelihood -1.411528
[ Info: iteration 50, average log likelihood -1.411521
┌ Info: EM with 100000 data points 50 iterations avll -1.411521
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4527290626683562
│     -1.4526492854739443
│      ⋮
└     -1.4115209771684774
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411665
[ Info: iteration 2, average log likelihood -1.411545
[ Info: iteration 3, average log likelihood -1.411172
[ Info: iteration 4, average log likelihood -1.406578
[ Info: iteration 5, average log likelihood -1.388579
[ Info: iteration 6, average log likelihood -1.375558
[ Info: iteration 7, average log likelihood -1.371197
[ Info: iteration 8, average log likelihood -1.369067
[ Info: iteration 9, average log likelihood -1.367442
[ Info: iteration 10, average log likelihood -1.365942
[ Info: iteration 11, average log likelihood -1.364409
[ Info: iteration 12, average log likelihood -1.362933
[ Info: iteration 13, average log likelihood -1.361734
[ Info: iteration 14, average log likelihood -1.360851
[ Info: iteration 15, average log likelihood -1.360182
[ Info: iteration 16, average log likelihood -1.359632
[ Info: iteration 17, average log likelihood -1.359153
[ Info: iteration 18, average log likelihood -1.358709
[ Info: iteration 19, average log likelihood -1.358293
[ Info: iteration 20, average log likelihood -1.357918
[ Info: iteration 21, average log likelihood -1.357595
[ Info: iteration 22, average log likelihood -1.357348
[ Info: iteration 23, average log likelihood -1.357185
[ Info: iteration 24, average log likelihood -1.357085
[ Info: iteration 25, average log likelihood -1.357022
[ Info: iteration 26, average log likelihood -1.356979
[ Info: iteration 27, average log likelihood -1.356946
[ Info: iteration 28, average log likelihood -1.356919
[ Info: iteration 29, average log likelihood -1.356896
[ Info: iteration 30, average log likelihood -1.356876
[ Info: iteration 31, average log likelihood -1.356858
[ Info: iteration 32, average log likelihood -1.356842
[ Info: iteration 33, average log likelihood -1.356827
[ Info: iteration 34, average log likelihood -1.356814
[ Info: iteration 35, average log likelihood -1.356802
[ Info: iteration 36, average log likelihood -1.356792
[ Info: iteration 37, average log likelihood -1.356783
[ Info: iteration 38, average log likelihood -1.356774
[ Info: iteration 39, average log likelihood -1.356767
[ Info: iteration 40, average log likelihood -1.356760
[ Info: iteration 41, average log likelihood -1.356753
[ Info: iteration 42, average log likelihood -1.356747
[ Info: iteration 43, average log likelihood -1.356741
[ Info: iteration 44, average log likelihood -1.356736
[ Info: iteration 45, average log likelihood -1.356731
[ Info: iteration 46, average log likelihood -1.356726
[ Info: iteration 47, average log likelihood -1.356721
[ Info: iteration 48, average log likelihood -1.356716
[ Info: iteration 49, average log likelihood -1.356712
[ Info: iteration 50, average log likelihood -1.356707
┌ Info: EM with 100000 data points 50 iterations avll -1.356707
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4116651990709188
│     -1.4115449244082516
│      ⋮
└     -1.35670657614242
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.356895
[ Info: iteration 2, average log likelihood -1.356717
[ Info: iteration 3, average log likelihood -1.356453
[ Info: iteration 4, average log likelihood -1.354161
[ Info: iteration 5, average log likelihood -1.342420
[ Info: iteration 6, average log likelihood -1.325225
[ Info: iteration 7, average log likelihood -1.315942
[ Info: iteration 8, average log likelihood -1.310917
[ Info: iteration 9, average log likelihood -1.307358
[ Info: iteration 10, average log likelihood -1.304706
[ Info: iteration 11, average log likelihood -1.302777
[ Info: iteration 12, average log likelihood -1.301618
[ Info: iteration 13, average log likelihood -1.301052
[ Info: iteration 14, average log likelihood -1.300802
[ Info: iteration 15, average log likelihood -1.300676
[ Info: iteration 16, average log likelihood -1.300596
[ Info: iteration 17, average log likelihood -1.300538
[ Info: iteration 18, average log likelihood -1.300488
[ Info: iteration 19, average log likelihood -1.300441
[ Info: iteration 20, average log likelihood -1.300389
[ Info: iteration 21, average log likelihood -1.300320
[ Info: iteration 22, average log likelihood -1.300221
[ Info: iteration 23, average log likelihood -1.300081
[ Info: iteration 24, average log likelihood -1.299890
[ Info: iteration 25, average log likelihood -1.299642
[ Info: iteration 26, average log likelihood -1.299350
[ Info: iteration 27, average log likelihood -1.299058
[ Info: iteration 28, average log likelihood -1.298801
[ Info: iteration 29, average log likelihood -1.298636
[ Info: iteration 30, average log likelihood -1.298570
[ Info: iteration 31, average log likelihood -1.298548
[ Info: iteration 32, average log likelihood -1.298539
[ Info: iteration 33, average log likelihood -1.298535
[ Info: iteration 34, average log likelihood -1.298531
[ Info: iteration 35, average log likelihood -1.298529
[ Info: iteration 36, average log likelihood -1.298527
[ Info: iteration 37, average log likelihood -1.298525
[ Info: iteration 38, average log likelihood -1.298523
[ Info: iteration 39, average log likelihood -1.298522
[ Info: iteration 40, average log likelihood -1.298521
[ Info: iteration 41, average log likelihood -1.298519
[ Info: iteration 42, average log likelihood -1.298518
[ Info: iteration 43, average log likelihood -1.298517
[ Info: iteration 44, average log likelihood -1.298516
[ Info: iteration 45, average log likelihood -1.298515
[ Info: iteration 46, average log likelihood -1.298514
[ Info: iteration 47, average log likelihood -1.298512
[ Info: iteration 48, average log likelihood -1.298511
[ Info: iteration 49, average log likelihood -1.298509
[ Info: iteration 50, average log likelihood -1.298507
┌ Info: EM with 100000 data points 50 iterations avll -1.298507
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3568948942084245
│     -1.3567169671566064
│      ⋮
└     -1.2985070086178256
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.298745
[ Info: iteration 2, average log likelihood -1.298481
[ Info: iteration 3, average log likelihood -1.297361
[ Info: iteration 4, average log likelihood -1.284758
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     7
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.252402
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.232426
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.220429
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.202011
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.212180
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.202008
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      8
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.201514
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.224761
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.213681
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.196681
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.208174
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.209869
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.206429
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.209417
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      8
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.210769
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.209886
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      8
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.195963
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.218715
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.208518
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      7
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.199606
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.209318
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.204902
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.197724
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.196232
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.206702
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.208379
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.193648
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.200675
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      8
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.203088
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.201640
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.199010
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.206333
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.210171
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│      7
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.189159
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.209320
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.208469
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.198983
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      7
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.193325
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.212771
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.210281
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.194202
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.190400
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      8
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.205912
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.202254
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.200188
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.206616
┌ Info: EM with 100000 data points 50 iterations avll -1.206616
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2987452291877866
│     -1.2984812095878617
│      ⋮
└     -1.2066156670761867
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     15
│     16
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.200304
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│      8
│     13
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.177054
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│     15
│     16
│     25
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.186636
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│      8
│     11
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.155536
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     10
│     12
│      ⋮
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.128817
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.110068
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     10
│     15
│     16
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.124471
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.096697
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     10
│     15
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.118249
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.114781
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     10
│     11
│      ⋮
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.104619
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.110328
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     10
│     11
│      ⋮
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.122646
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.105696
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      7
│      8
│     10
│     11
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.112761
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.114576
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     10
│     11
│      ⋮
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.104132
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.110474
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     10
│     15
│     16
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.122631
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.097894
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      7
│      8
│     10
│     12
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.106772
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.115319
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     10
│     15
│     16
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.114485
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.093935
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     10
│     15
│     16
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.127957
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.108026
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      7
│      8
│     10
│     11
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.101958
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.120738
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     10
│     11
│      ⋮
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.114907
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.102116
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     10
│     11
│      ⋮
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.122547
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.107299
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      7
│      8
│     10
│     11
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.101336
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.120587
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     10
│     15
│     16
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.114802
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.093972
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     10
│     12
│      ⋮
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.115962
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.104683
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     10
│     15
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.101554
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.090264
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     10
│     15
│     16
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.105147
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.087607
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     10
│     12
│      ⋮
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.113527
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.097738
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     10
│     15
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.099267
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.090317
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     10
│     15
│      ⋮
│     25
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.105911
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.089976
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      7
│      8
│     10
│      ⋮
│     18
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.094966
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.107242
┌ Info: EM with 100000 data points 50 iterations avll -1.107242
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2003043157192799
│     -1.1770542697270645
│      ⋮
└     -1.107242232312168
32×26 Array{Float64,2}:
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.452664064232059
│     -1.4527290626683562
│     -1.4526492854739443
│     -1.4519217054786977
│      ⋮
│     -1.089976139316026
│     -1.0949660216381703
└     -1.107242232312168
 -0.226023   -0.0486465   -0.0323301    0.0525475   -0.0573143    0.0279736    0.0158635   -0.0427079  -0.0316539   -0.030441      0.0205222   -0.0221067   -0.0113911   -0.0415547   -0.000843372  -0.090607     0.0849891    0.08804     0.0282545    0.123669    -0.0156633    0.0591057   0.0181419    0.113527    0.0751093   -0.0300179
  0.130338    0.144897     0.0830931   -0.00675607  -0.0676917    0.0504248    0.0259587   -0.0384308  -0.115391    -0.0675269     0.058155     0.086991     0.108514     0.121189     0.120409     -0.00451733  -0.2346       0.157146   -0.0417319    0.121128    -0.00704681   0.117834   -0.0136567   -0.0718703   0.0102014   -0.0634647
  0.0884288  -0.0998263    0.0035706    0.0399736    0.00498608   0.0182031    0.0535718    0.118339   -0.012185     0.0457153     0.0700568   -0.0661633    0.0230743   -0.0650043    0.107227      0.0451841    0.0809874   -0.0266431  -0.112853     0.0608326   -0.0441683    0.0269165   0.102832     0.0935009  -0.0507603   -0.0215413
  0.022804    0.00383691   0.0632215   -0.183398     0.0553988   -0.0782252    0.0457784    0.001103   -0.041254     0.0654815     0.0966981   -0.0633232    0.104661     0.0642513    0.0227985     0.133158    -0.0968852   -0.0701416   0.00148761   0.0711767   -0.0579174   -0.0203772  -0.0337763    0.0361678  -0.0244758   -0.0572135
 -0.0600576  -0.097403     0.00121392  -0.00962775  -0.854921     0.103455     0.059659    -0.112071   -0.200166     0.137934      0.222114    -0.0520272    0.0435978   -0.177097     0.0247264    -0.127945     0.107652    -0.0126517  -0.0763138   -0.0550852   -0.0464391   -0.0764992   0.0865849   -0.129155   -0.412371     0.0399215
 -0.0440105  -0.133608     0.0012105    0.044767     0.683872     0.0629655    0.0715231   -0.0949935  -0.0785414    0.136512      0.0488914   -0.00848671   0.0171329   -0.177223    -0.0188697     0.065454     0.10945     -0.0132762  -0.0407849   -0.0589065   -0.0627091    0.289597   -0.00997582  -0.130316   -0.163375     0.0401121
 -0.142451   -0.110668     0.12198      0.215159    -0.208564    -0.111781    -0.0267672    0.104577    0.263302    -0.362108     -0.0784454    0.16111      0.202479     0.00467983  -0.208964     -0.365541    -0.00200932   0.224008    0.352647    -0.0366464    0.186289     0.156166   -0.1974       0.0641687   0.0254503   -0.21216
 -0.142261   -0.104393     0.122586     0.161165     0.262815     0.0174161   -0.00815839   0.105838    0.0673355   -0.17384      -0.0767513    0.125745     0.214522    -0.0352074   -0.201141     -0.27681     -0.0634932    0.221453   -0.219154     0.0410037    0.191203    -0.144036    0.028466     0.0631343   0.0515383    0.417915
  0.0267015   0.148259     0.0951823   -0.178749     0.0780702   -0.137571     0.0284508    0.190064    0.0884728   -0.00650655    0.0181297   -0.0213166    0.0897606    0.0195754   -0.054965      0.125294    -0.118223    -0.0705583  -0.0576672    0.109695     0.136477    -0.0597421   0.0183303    0.122054   -0.0257164   -0.0585553
 -0.137351   -0.0412095   -0.108856     0.0356379    0.0224158   -0.118182     0.143611    -0.111598   -0.0591122   -0.128209     -0.171839     0.00279782   0.135807     0.0227749   -0.118584      0.0476986    0.0580494   -0.0776638  -0.162228    -0.0115617   -0.135154     0.0797208  -0.0328538    0.0224572   0.0332792   -0.122969
 -0.0138717   0.127846     0.116661     0.0305008    0.0705799   -0.0145372    0.0148101   -0.0108146  -0.214916     0.148974      0.22271     -0.0432408   -0.108568    -0.171682     0.117267     -0.107008    -0.0475897    0.0163509   0.06121     -0.0990239   -0.00357964   0.0902779   0.186766    -0.0169931  -0.00100218  -0.239286
 -0.109636    0.0283494   -0.128095    -0.0281164   -0.200184    -0.114053     0.0279258    0.0379213   0.145904     0.0119613     0.273145    -0.0219858    0.0104024    0.0514554    0.154449      0.0241287    0.002673     0.0513409  -0.0904675    0.10768      0.00120234  -0.122948    0.087612     0.0416025   0.0586019    0.00540495
  0.033472   -0.0659848    0.154616     0.0335614    0.0276843   -0.0507233    0.0643487   -0.0865705  -0.041228     0.0452682     0.0170975    0.24121      0.0342857    0.0567225   -0.0754861     0.212093     0.0129817   -0.11935    -0.0982258    0.0924821    0.0879322   -0.0283307  -0.0286598   -1.86988    -0.0366735   -0.081481
  0.0328615  -0.065641     0.176726     0.0274528    0.0395728   -0.0527574    0.0263011   -0.0960826   0.186117     0.0172603     0.0533843    0.243923    -0.0332193    0.0531423   -0.0767138     0.0687238    0.0226985   -0.139041    0.0135156    0.0921068    0.0240366   -0.0306079  -0.0395062    1.72032    -0.0514824   -0.0982597
 -0.291525   -0.15789      0.00342641   0.0454969    0.0607843   -0.242188     0.0607049    0.077809    0.110963     0.252307      0.0584086   -0.144193     0.0359723   -0.0619852   -0.0370631     0.0818532   -0.0481727   -0.0160606  -0.0949602   -0.0457541    0.00166396  -0.0614142   0.110144    -0.0712811  -0.0644867    0.00240447
  0.450257   -0.159459    -0.190074    -0.202732     0.018333    -0.200443     0.0646744    0.0479196  -0.0656664   -0.492385      0.0555222    0.248414     0.0539805    0.0589143   -0.113452     -0.127839    -0.0280742    0.142881    0.173181    -0.045569     0.0890187   -0.132524    0.110399    -0.0502596  -0.0990402   -0.0318221
  0.0103566   0.113289     0.0783528    0.0529328    0.0874972    0.0545069    0.213151     0.248853   -0.0930583   -0.0653178     0.0945134    0.0216961    0.0212667    0.0350195    0.0119591     0.00684786   0.0625457   -0.0165789  -0.05956      0.0092492   -0.179542    -0.179586   -0.157976    -0.166895   -0.0774878    0.0384558
  0.0475308  -0.0243763    0.0286476    0.127088    -0.0182201   -0.100063    -0.00432657  -0.160126   -0.0522392   -0.185745      0.109688     0.116529     0.19013     -0.0120334   -0.00252651   -0.232225     0.19683      0.0972476  -0.161709    -0.0244567   -0.0730002   -0.0360141  -0.0245222   -0.0562354  -0.108794     0.0443991
  0.142359   -0.0321007   -0.0134091   -0.0124621   -0.0800924   -0.118266    -0.0474826   -0.137247    0.0156643    0.0169788     0.00393001  -0.200897     0.00487456   0.019899    -0.116351     -0.0860923   -0.0491119    0.0740466  -0.0601603    0.0162819   -0.172837    -0.0114702  -0.049056    -0.140584    0.00522917  -0.0126081
  0.0592802   0.150147     0.198803    -0.171964    -0.0647176   -0.0623828   -0.11928     -0.202501   -0.0772404   -0.0278045     0.0882335    0.0183561    0.210156    -0.0225737    0.0161185    -0.0549929    0.0232319   -0.142509    0.085011    -0.0437625   -0.179293     0.0966387  -0.0470512   -0.0620765   0.0817247   -0.0175299
 -0.0223791  -0.0243873    0.00714925  -0.114037     0.0813102   -0.0281138    0.0951295    0.0849004   0.0542423    0.0389273     0.0432139    0.0330616    0.180974    -0.0068834    0.11528      -0.0396273    0.0324631    0.0842301   0.127812     0.0688273    0.0304396   -0.068334    0.0889172   -0.0113609  -0.0176444   -0.138263
  0.0999969  -0.00994362  -0.0744894   -0.158003     0.00259916  -0.0850263    0.00929116   0.0699487  -0.0119463   -0.0957228     0.0187852   -0.0111603    0.0304719    0.0737       0.0313462     0.115537    -0.0410033   -0.150328   -0.0521093    0.0180771    0.00970827   0.0101956   0.0424545    0.0211877  -0.125981    -0.0149458
  0.144503    0.207805     0.0915589    0.0436813   -0.0671988    0.0461735    0.0222123    0.0622536   0.108435    -0.0663125    -0.0546167   -0.103249     0.0335303    0.070453    -0.0594182    -0.157917     0.0129635    0.0737438   0.0386725    0.116226     0.0131568   -0.0518834  -0.0983548   -0.0635689   0.170087     0.0543191
  0.0665598   0.0410975    0.177163    -0.0666857   -0.0174589   -0.147425     0.0621964   -0.10263    -0.0525913    0.225559     -0.0978457   -0.0479202    0.0593785   -0.142412    -0.152459      0.173444    -0.167439    -0.11382     0.149019     0.0638537   -0.134467     0.140959    0.0906811    0.0584963   0.0261616    0.0268114
 -0.0772199  -0.15479     -0.272948     0.247729     0.174843     0.164766    -0.101214    -0.111986   -0.125853     0.121923     -0.0339409   -0.0131339   -0.0167249   -0.00230002  -0.0100987     0.00717456  -0.0761706   -0.0648809   0.02511     -0.00885932   0.0227254   -0.0031781   0.051182     0.0366768   0.465674    -0.168572
 -0.0753071   0.0616995    0.359433     0.241621     0.298408     0.0752114    0.0907082   -0.0523547  -0.0348247    0.132449      0.12161      0.0686226   -0.0168202    0.132469     0.197751     -0.00933708  -0.277671    -0.0786768   0.00709254   0.00384253   0.0195112   -0.302341    0.0647241    0.0377519  -0.0947567    0.0536162
  0.109115   -0.112793     0.024485    -0.00167169   0.20064      0.11258      0.0907248    0.0461563  -0.0921931   -0.227664     -0.0718598   -0.0524223    0.108886     0.00620952  -0.076388     -0.10703      0.0185767    0.137137   -0.196584    -0.00165317  -0.0279948   -0.108239    0.154232    -0.0686833  -0.126443    -0.0995145
 -0.036698    0.0564046    0.0677705    0.0642308    0.0767728   -0.0715199    0.00790449   0.0533676   0.0141506    0.0926781    -0.0695638    0.164873    -0.0735513    0.144003    -0.123089     -0.0570733   -0.0355576   -0.0437943   0.041527    -0.134564     0.0640483   -0.119037    0.126145    -0.106388    0.0844381    0.0455371
  0.0309194   0.176356     0.235964     0.160144     0.013692    -0.00117928  -0.0164449    0.129126    0.022347    -0.064941      0.0874822   -0.142155     0.111563    -0.129022    -0.00134838    0.0719437    0.0484589   -0.0973818   0.068999    -0.0624946   -0.0765878   -0.0555338   0.0152561   -0.0804151  -0.0570103   -0.0101275
  0.0457837   0.0840669    0.139584     0.0116241   -0.0516401   -0.0377893   -0.0060388    0.0904867   5.05757e-5   0.0511128     0.0667938   -0.0385216    0.146282    -0.105947     0.030008     -0.336773     0.0388194   -0.0856961  -0.0357971    0.0183296   -0.00719981   0.0257743   0.0623987   -0.073214   -0.0304822    0.0327679
  0.108265   -0.0179692    0.162444     0.010522     0.0865816    0.043926    -0.0887205   -0.0523902  -0.194317    -0.00509584    0.035073    -0.0489638    0.0208827   -0.0872334   -0.0100341     0.102236    -0.00889694  -0.0256238  -0.133747    -0.0770775   -0.0637663    0.0610598  -0.00426614   0.0481816  -1.53972     -0.14215
  0.104353   -0.0259747    0.065948     0.0372937    0.0843894   -0.085323    -0.103018    -0.0500039  -0.197718    -0.000253569   0.0601267   -0.0641365    0.041655    -0.105853    -0.0956594     0.11148     -0.02265     -0.0264053  -0.130226    -0.179586     0.0170528    0.0601978   0.0207161    0.0522571   1.39434      0.058332[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     10
│     11
│      ⋮
│     25
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.102149
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.069862
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      7
│      8
│     10
│     11
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.093306
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.064839
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      7
│      8
│     10
│     11
│      ⋮
│     26
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.094431
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.065052
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      7
│      8
│     10
│     11
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.091691
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.074411
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      7
│      8
│     10
│     11
│      ⋮
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.091157
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.062733
┌ Info: EM with 100000 data points 10 iterations avll -1.062733
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.627074e+05
      1       7.476449e+05      -2.150625e+05 |       32
      2       7.152812e+05      -3.236367e+04 |       32
      3       6.945980e+05      -2.068323e+04 |       32
      4       6.815770e+05      -1.302094e+04 |       32
      5       6.740098e+05      -7.567222e+03 |       32
      6       6.683289e+05      -5.680935e+03 |       32
      7       6.644538e+05      -3.875037e+03 |       32
      8       6.626151e+05      -1.838760e+03 |       32
      9       6.615007e+05      -1.114360e+03 |       32
     10       6.605201e+05      -9.806151e+02 |       32
     11       6.596011e+05      -9.189469e+02 |       32
     12       6.589746e+05      -6.265385e+02 |       32
     13       6.586056e+05      -3.690551e+02 |       32
     14       6.583497e+05      -2.558804e+02 |       32
     15       6.580645e+05      -2.851414e+02 |       32
     16       6.576789e+05      -3.856611e+02 |       32
     17       6.571706e+05      -5.082701e+02 |       32
     18       6.566655e+05      -5.050852e+02 |       32
     19       6.562709e+05      -3.946375e+02 |       32
     20       6.559466e+05      -3.242491e+02 |       32
     21       6.556142e+05      -3.324756e+02 |       32
     22       6.552448e+05      -3.693126e+02 |       32
     23       6.548351e+05      -4.097238e+02 |       32
     24       6.544580e+05      -3.770890e+02 |       32
     25       6.541616e+05      -2.963801e+02 |       32
     26       6.539537e+05      -2.079584e+02 |       32
     27       6.538490e+05      -1.047267e+02 |       32
     28       6.538013e+05      -4.769617e+01 |       31
     29       6.537732e+05      -2.806632e+01 |       31
     30       6.537544e+05      -1.877181e+01 |       31
     31       6.537424e+05      -1.205097e+01 |       29
     32       6.537363e+05      -6.095285e+00 |       24
     33       6.537327e+05      -3.574236e+00 |       27
     34       6.537298e+05      -2.911783e+00 |       20
     35       6.537282e+05      -1.592989e+00 |       18
     36       6.537265e+05      -1.716141e+00 |       16
     37       6.537247e+05      -1.743733e+00 |       18
     38       6.537235e+05      -1.204316e+00 |       15
     39       6.537229e+05      -6.034986e-01 |       15
     40       6.537222e+05      -7.175043e-01 |       12
     41       6.537217e+05      -5.401270e-01 |       11
     42       6.537212e+05      -5.073377e-01 |       13
     43       6.537207e+05      -4.689428e-01 |        8
     44       6.537206e+05      -1.381074e-01 |        4
     45       6.537205e+05      -7.553252e-02 |        2
     46       6.537204e+05      -4.139352e-02 |        4
     47       6.537204e+05      -8.050254e-02 |        3
     48       6.537203e+05      -7.267694e-02 |        0
     49       6.537203e+05       0.000000e+00 |        0
K-means converged with 49 iterations (objv = 653720.2945050686)
┌ Info: K-means with 32000 data points using 49 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.363766
[ Info: iteration 2, average log likelihood -1.332687
[ Info: iteration 3, average log likelihood -1.300393
[ Info: iteration 4, average log likelihood -1.251401
[ Info: iteration 5, average log likelihood -1.188444
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      5
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.130276
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     14
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.136003
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.131859
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.115990
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│      7
│      ⋮
│     14
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.079906
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.167560
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     17
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.127536
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     14
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.106819
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      7
│     20
│     21
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.086161
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      9
│     11
│     12
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.111480
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.156440
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.122513
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.091442
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      6
│      9
│     12
│      ⋮
│     24
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.038293
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.174185
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.144997
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.107856
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      6
│      9
│     12
│      ⋮
│     21
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.052458
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.171576
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.125884
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│     17
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.092406
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      6
│      9
│     12
│     14
│     20
│     23
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.086076
[ Info: iteration 28, average log likelihood -1.178794
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.105615
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      9
│     12
│     14
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.073166
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.160795
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.130117
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.089215
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│      7
│      9
│     12
│     17
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.081702
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     11
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.150418
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.140169
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      5
│     14
│     19
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.080703
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│      9
│     12
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.107314
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     20
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.118964
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.136924
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      5
│      6
│     17
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.082960
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│      9
│     12
│     14
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.085367
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     20
│     21
│     23
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.120981
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.157015
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     11
│     14
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.107600
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      7
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.094358
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│     17
│     20
│     23
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.081587
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     12
│     21
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.127472
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.136174
32×26 Array{Float64,2}:
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      4
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.101659
┌ Info: EM with 100000 data points 50 iterations avll -1.101659
└ 59.0 data points per parameter
  0.0651695    0.0405316    0.176848    -0.0671437   -0.0149984   -0.143544     0.0586512   -0.103757    -0.0523563    0.2249       -0.0975124   -0.047062      0.0594609   -0.142824    -0.152178     0.182653    -0.166028   -0.116604    0.151263     0.0600726   -0.131996      0.132014     0.0889386    0.055698     0.0254499    0.0278002
  0.0225107   -0.0458595    0.028313    -0.242258     0.0333398   -0.0754206    0.118345    -0.050371    -0.0634898    0.022477      0.264583    -0.121923      0.129567     0.00698844   0.00849024   0.122674    -0.0546466   0.0913216   0.0465346    0.122798    -0.127356     -0.0948582   -0.023351     0.00928785   0.0265904   -0.00843205
 -0.141864    -0.106252     0.121216     0.181613     0.0957128   -0.0265078   -0.0133892    0.104295     0.133836    -0.237916     -0.0771288    0.136959      0.210099    -0.0230421   -0.204397    -0.308595    -0.0426003   0.220422   -0.020649     0.0136398    0.186852     -0.0435163   -0.0451719    0.0620119    0.0418609    0.198204
  0.0502035   -0.032967     0.0264076    0.134387    -0.0143926   -0.102456    -0.00755894  -0.173273    -0.0485659   -0.180165      0.114389     0.120893      0.193356    -0.0202903    0.00136609  -0.239186     0.190974    0.119371   -0.164976    -0.0311963   -0.0737156    -0.037662    -0.0257029   -0.0632247   -0.113427     0.0444932
 -0.0718097   -0.0681912    0.0561512    0.266472     0.310024     0.126442    -0.0213545   -0.081569    -0.0781404    0.130185      0.0423536    0.0274565    -0.0209568    0.0487908    0.0854088   -0.00980881  -0.144543   -0.076442    0.019585    -0.00664714   0.0137827    -0.235284     0.0600987    0.0218048    0.279995    -0.0418696
  0.034349    -0.0682141    0.162624     0.0249894    0.0355468   -0.0523838    0.0455478   -0.090382     0.0694366    0.0308492     0.0350538    0.238438      0.00445882   0.0537037   -0.0732491    0.148768     0.0205848  -0.130091   -0.0451316    0.0892509    0.0522272    -0.029152    -0.033137    -0.145411    -0.0441722   -0.0860652
  0.15083      0.161909     0.0876069   -0.0151475   -0.0562326    0.0621154    0.0417228   -0.0362805   -0.138776    -0.0548617     0.056061     0.0799417     0.151403     0.129875     0.141153     0.0157332   -0.241754    0.211342   -0.0553656    0.113155     0.00507489    0.150939    -0.0224373   -0.0804734   -0.0169064   -0.0602493
 -0.00850281   0.0764299    0.0765229    0.0929414   -0.00169704   0.0714898    0.0665995   -0.0415161   -0.0927874    0.0657831     0.0353326    0.032903      0.0609474    0.0584535    0.103183     0.0454261   -0.18812    -0.0164263  -0.00480878   0.00501385   0.0112909     0.128369     0.0213675   -0.0128868   -0.0107759   -0.0410077
  0.0935407    0.164764     0.15903     -0.285226     0.0885657   -0.126101     0.0467163    0.219942     0.107103    -0.00411704    0.121792    -0.0114461     0.0880927    0.00585908  -0.0352284    0.200779    -0.122442   -0.0414516  -0.00985386   0.0861882    0.161474     -0.0662712    0.0145624    0.105526    -0.0502195   -0.0634348
 -0.0381856    0.0591201    0.0712194    0.074913     0.0776857   -0.0690193    0.00860947   0.0569041    0.0147934    0.0916445    -0.0692209    0.165134     -0.0709222    0.138832    -0.121058    -0.0571421   -0.0361706  -0.0423095   0.0430232   -0.131189     0.0630644    -0.120596     0.11916     -0.103948     0.0815575    0.0421146
  0.0716003    0.0252014   -0.0642088   -0.0539299   -0.0993356   -0.0121539   -0.0942119    0.121884     0.0943408    0.119397     -0.092354    -0.0194936     0.27525      0.0160115    0.154948    -0.229325     0.0339129  -0.0371935   0.0773539    0.147323     0.0279317    -0.146209     0.175509     0.0315055    0.0320333   -0.148085
 -0.165777    -0.0448988   -0.017713     0.0967132    0.0632786   -0.126119     0.0467346    0.0511896   -0.00388667  -0.0103464    -0.196412     0.000857953   0.0889742    0.00859917  -0.0521991    0.0391093   -0.0465512  -0.0771843  -0.131937     0.0710179   -0.0156283    -0.0205967    0.0205245    0.06256     -0.00368727  -0.0666162
  0.0768895    0.148474     0.208309    -0.178555    -0.055028    -0.0800075   -0.122788    -0.224891    -0.0747589   -0.0240553     0.0903087    0.0194215     0.216877    -0.0330371    0.0127135   -0.0511829    0.0144632  -0.146298    0.0948786   -0.0583308   -0.189085      0.0968355   -0.0545311   -0.0659909    0.0882572   -0.0168849
 -0.0572907   -0.127938    -0.0086591    0.0139652    0.0474156    0.0816403    0.0742266   -0.0871156   -0.152437     0.12788       0.104781    -0.0282577     0.0409292   -0.162877     0.003165    -0.0477712    0.0950874  -0.0359634  -0.123604    -0.0551884   -0.0586461     0.249949     0.0110874   -0.124239    -0.402906     0.0332346
 -0.184586    -0.0521977   -0.00454365   0.0147605   -0.0364861   -0.0671006   -0.0810529   -0.173948     0.0115077   -0.12522       0.0444805   -0.00502255    0.00376633   0.00927729  -0.0358456   -0.0754585   -0.0613773   0.07183     0.172556     0.0767334   -0.135816      0.00708555   0.0573257    0.0557842    0.0981573    0.0134682
 -0.0452627    0.047152    -0.0344004   -0.0706025   -0.0646768   -0.0892521    0.00299157   0.0439631    0.060141     0.0664738     0.107616    -0.0147818     0.0430243    0.0787656    0.10219      0.0859809   -0.0679621  -0.0792503  -0.0643487    0.0525859    0.000293854  -0.0456275    0.02861      0.0524053   -0.01115     -0.0451117
  0.141145    -0.0315378   -0.0419798   -0.169581     0.0180326   -0.0564285   -0.0121599    0.0102475   -0.0799598   -0.0703659     0.0320117   -0.0509234     0.0264842    0.0737172    0.0136647    0.19287      0.0320326  -0.126195   -0.0223473   -0.0394927    0.0332368     0.0247716    0.0801398   -0.0261838   -0.237199    -0.0393898
 -0.200798    -0.0648168   -0.0811552    0.0767483   -0.00291628   0.0839724    0.123988     0.0268714   -0.05023      0.111365     -0.0188583   -0.0539867    -0.0253169   -0.177549     0.0252656   -0.110153     0.155851    0.273098   -0.0275365    0.122245     0.03132       0.101592    -0.0485062    0.223699     0.00789882  -0.0452384
  0.0447837    0.00919507  -0.0821644    0.0449618   -0.14405      0.142657     0.0623964    0.113673    -0.132745     0.196335     -0.0691835   -0.0806056     0.041105     0.00471903   0.0115419    0.0662741    0.140809    0.0877899  -0.118238     0.116048    -0.139368      0.101867     0.126196     0.0296818   -0.00365426   0.0108421
  0.10033     -0.0187886    0.128111     0.0353172    0.0819426   -0.0223643   -0.0964731   -0.0476368   -0.193516     0.000413087   0.0590316   -0.0596115     0.0270481   -0.0955464   -0.0408417    0.0844033   -0.0156749  -0.0300458  -0.117299    -0.126772    -0.0199989     0.064521     0.013195     0.0410621   -0.0504833   -0.043085
 -0.0761037   -0.0444531    0.00697787  -0.148491     0.209073    -0.0825221    0.216557     0.0999494    0.0625636   -0.0841719     0.137352     0.094299      0.0426731    0.0045434    0.0677929    0.0700214   -0.0576791   0.0550666   0.0781469    0.0231174   -0.00973902   -0.015251    -0.0206296    0.0198331   -0.00561641  -0.0566376
  0.0317184   -0.180402     0.035105    -0.0741133   -0.00998451  -0.0308212    0.0794583    0.113879     0.0103717    0.0616929     0.0609761    0.000900386  -0.0506877   -0.0459105    0.168795    -0.0694588    0.0468704  -0.0674516  -0.118295     0.189642     0.0115025    -0.103872     0.0318656    0.0317351   -0.0227884    0.0758592
 -0.180913     0.0622676    0.0494115    0.0451525   -0.172383     0.0631462   -0.0241437    0.0478322   -0.0815679   -0.0840518     0.0718962    0.00516867   -0.00128619   0.112952     0.006291    -0.0741073    0.0837006  -0.187617   -0.126403     0.158519     0.104113      0.0817704    0.0760834   -0.038171     0.106263    -0.0904079
  0.0230577    0.246219     0.206315     0.161006     0.0227534   -0.00557801  -0.00558076   0.150435     0.0457527   -0.0493034     0.0684334   -0.230505      0.105664    -0.165307     0.00245948   0.175036     0.0515592  -0.0887295   0.117767    -0.053427    -0.0872662    -0.0671704   -0.00964782  -0.0810894   -0.0473909    0.0373572
  0.140795    -0.0322081   -0.0147026   -0.00960772  -0.0801955   -0.116507    -0.0510326   -0.137358     0.0165799    0.0175922     0.00678809  -0.198217      0.00472357   0.0227602   -0.116741    -0.0854486   -0.0540322   0.0725353  -0.0593892    0.0135772   -0.171343     -0.0180592   -0.0535965   -0.139414     0.00428412  -0.0123406
  0.198901    -0.128727     0.0716038    0.12115      0.189847    -0.0726259    0.0222808    0.120097     0.0781913   -0.126818      0.221531    -0.0918263     0.0619832   -0.145522     0.165367     0.136495     0.037396   -0.115387   -0.0805445   -0.116695    -0.0212368     0.0466072    0.15565      0.219425    -0.116893    -0.17274
  0.108235    -0.112668     0.0319342    0.00211791   0.20182      0.119415     0.0886565    0.0511402   -0.0872218   -0.227939     -0.0758971   -0.0534565     0.107519     0.0100655   -0.0799539   -0.112303     0.0214783   0.136239   -0.193217    -0.00681841  -0.0263834    -0.105868     0.152923    -0.069546    -0.114228    -0.101525
 -0.134425    -0.0374685   -0.0977235    0.0445532    0.0218685   -0.112956     0.141361    -0.108358    -0.0593637   -0.124872     -0.168618     0.00109694    0.13421      0.0200628   -0.112994     0.0451465    0.0542288  -0.0768454  -0.162505    -0.0116802   -0.136614      0.0773763   -0.0335728    0.0206328    0.0305886   -0.120605
  0.0803137   -0.150611    -0.0876024   -0.0799201    0.0418701   -0.212699     0.0623923    0.0590502    0.0117953   -0.112681      0.0570623    0.0503008     0.0433354   -0.00608486  -0.0696446   -0.0227947   -0.0377076   0.0603479   0.0345533   -0.0433317    0.0465687    -0.0930624    0.11177     -0.0589753   -0.0824226   -0.0150069
  0.0139134    0.158565     0.144245     0.0454327    0.0872326   -0.0347828    0.0231216   -0.00318875  -0.168565     0.111327      0.307384    -0.0527252    -0.078792    -0.248661     0.0957486   -0.126821    -0.0313505   0.03478     0.133235    -0.115413    -0.0320321     0.0824387    0.183967    -0.0351245   -0.0126017   -0.23685
  0.0184288    0.113031     0.0786017    0.0556297    0.0856781    0.0461793    0.212532     0.233916    -0.0921738   -0.0728688     0.0940212    0.0267232     0.0233746    0.0295718    0.0150411   -0.00662985   0.0658825  -0.0134772  -0.0635293    0.00180403  -0.177939     -0.173878    -0.158466    -0.163297    -0.0819828    0.0390101
  0.139617     0.208851     0.0932298    0.0432117   -0.0674399    0.0429237    0.0206682    0.0585723    0.119107    -0.0600035    -0.0586476   -0.1019        0.0314268    0.0699156   -0.0592891   -0.151618     0.0157384   0.0740296   0.0389673    0.114643     0.0162902    -0.0527196   -0.100448    -0.0632728    0.170781[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
     0.0543659┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      7
│     11
│     20
│     23
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.074149
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      7
│      9
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.020071
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      6
│      7
│      ⋮
│     23
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.027210
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│      7
│      9
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.043701
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      6
│      7
│      9
│     11
│      ⋮
│     23
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.042650
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.993251
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│      7
│     11
│     12
│     20
│     23
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.072922
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      7
│      9
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.022185
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      6
│      7
│      ⋮
│     23
│     28
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.026988
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│      7
│      9
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.040794
┌ Info: EM with 100000 data points 10 iterations avll -1.040794
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0227103    0.167635      0.0433819   -0.000963467  -0.00270213   -0.0966137    0.012735     0.0188326   -0.174303     -0.0677896   -0.0596081    0.128767     0.078121    -0.182893     0.0746111     0.0215435   -0.0390762   -0.0761857     0.0847064    0.0286687    0.105129    0.0121241   -0.0360733    0.0100308   -0.105218    -0.0963752
  0.0177242    0.0619609     0.0962612   -0.0359337     0.0187436    -0.0226339   -0.279305     0.162212     0.0740651     0.104653     0.105087     0.0763712   -0.0187827    0.136539    -0.0750159    -0.00145047  -0.00197184   0.0425989    -0.0504281   -0.0825167   -0.182927    0.154285    -0.0379518   -0.128178    -0.0426944   -0.0477311
 -0.103119    -0.189188      0.00840002   0.0254396     0.123639     -0.10604      0.171847    -0.091        0.0725655     0.172874     0.0149006   -0.0695142   -0.0814147   -0.0497523    0.00903398    0.0692749   -0.022117    -0.000478161  -0.0877511    0.0754488   -0.05784     0.110286     0.0510792   -0.0243463   -0.0420207   -0.00196875
 -0.0866852    0.0911141     0.0912477   -0.149379     -0.0353986    -0.0841257   -0.0161782   -0.0161888    0.0391563    -0.210628    -0.0599592    0.0741868    0.0361615   -0.0264164    0.000312525  -0.0761629   -0.0336163    0.061079      0.11838      0.123196    -0.0169535  -0.119115     0.0456404    0.0659151    0.0832248   -0.00619002
 -0.11571     -0.071754      0.0537032    0.0247615    -0.100934     -0.0520972    0.161982    -0.00898538   0.00409154   -0.0239817   -0.0194988    0.0254382   -0.043509     0.0531813   -0.0604577    -0.109441     0.0830562   -0.164238     -0.136942    -0.0492701   -0.0767964  -0.0358465    0.104949     0.20331     -0.0252908    0.0573299
 -0.0493862    0.00621612    0.016926     0.0480314     0.0631006    -0.0429383    0.108913    -0.0383301    0.105257      0.0590034    0.0399873   -0.0634575    0.0450907   -0.0353279   -0.160014     -0.131556    -0.0381994   -0.0584405     0.0581564    0.0492546   -0.0714331  -0.0225596   -0.0490322   -0.0984377    0.0314556    0.116941
 -0.133234     0.0696178    -0.0473082   -0.0956497    -0.0337727    -0.0278078   -0.07159      0.0287166    0.0658059     0.0233202    0.0808329    0.0876465    0.105975    -0.0632999    0.145356     -0.140565     0.216271     0.056374      0.00755223  -0.055528    -0.167709    0.186334     0.0565771    0.108757     0.0639749    0.0535652
 -0.037821     0.181987     -0.153845     0.0213209     0.132162      0.0969727   -0.308353     0.123174     0.1751       -0.00778868   0.0354162    0.0453476    0.00704564   0.00173504   0.238602     -0.177585    -0.0840299   -0.0676154    -0.138928     0.0770817   -0.0166791  -0.0522457   -0.222572     0.11628     -0.295703    -0.0325191
 -0.162096     0.123564     -0.0108561    0.027552      0.110144      0.194134    -0.203754    -0.0308655   -0.152727     -0.271472     0.112191     0.0682491    0.149895    -0.117714     0.00581152   -0.0736379   -0.0146491   -0.0516052     0.0996978    0.0179438    0.13165    -0.0129495    0.100002    -0.00953631  -0.0391963   -0.214377
 -0.165196    -0.0255472    -0.043713     0.0381807     0.0634597    -0.106695     0.00697805   0.0376026   -0.158167      0.0805398   -0.105613     0.109437    -0.102618     0.0176356    0.00760854   -0.0414453    0.0646186    0.0203719    -0.12869      0.0586323   -0.104432   -0.0763335    0.0515351    0.0526744    0.0580928    0.186067
 -0.0542793   -0.0640571     0.0601188   -0.0176442     0.248727     -0.0872604   -0.0210699    0.186853    -0.037509     -0.0370361    0.0779443    0.0750248    0.0224516    0.127629     0.00373028    0.101422    -0.150009     0.105903     -0.0285544    0.0146965   -0.019657    0.10758      0.0289155   -0.0369701    0.0485379   -0.131108
  0.123364    -0.0168824     0.170762    -0.0225594     0.0538294    -0.147615    -0.0373815    0.0437347    0.0248072    -0.0526076   -0.0302029    0.0817856   -0.0141266    0.0790545   -0.0578048     0.0634413    0.0697894   -0.0218584    -0.0828432    0.00830925   0.0624416  -0.0637603    0.166792     0.00303262  -0.0796138   -0.0602983
 -0.159991     0.174317      0.0237442    0.0329962     0.100924     -0.00111014   0.118408     0.0903326   -0.187929     -0.266836    -0.0246834    0.0147748   -0.0193022   -0.0407246   -0.0630988    -0.071983    -0.00649663   0.0235051    -0.0105453    0.0900488    0.0295387   0.0528781   -0.0660521    0.00699779   0.00114744   0.111937
 -0.0957239    0.00404092    0.097168     0.116241      0.0161196     0.0137332   -0.060271     0.146324     0.0113616     0.102082     0.0667754   -0.0121778   -0.03982     -0.123513     0.0128782     0.142889     0.0652906    0.087705     -0.0450374    0.115668     0.131729   -0.0677929    0.0278659   -0.127337    -0.00178801  -0.149169
 -0.00638619  -0.0372156     0.0515504   -0.129168      0.15267       0.166579    -0.0767348    0.00773937   0.0353831    -0.0944908   -0.00569336  -0.0516228   -0.0518365    0.133466     0.0193019    -0.0667445    0.0616601    0.00987236   -0.0164401   -0.147311     0.215454    0.0110162   -0.0900371    0.158852    -0.193499    -0.15152
 -0.0170749   -0.0657212     0.0201299   -0.199509     -0.00725288    0.0571436    0.293172    -0.0416242    0.0947599    -0.0419528   -0.123067    -0.0707131   -0.0710374    0.0256086    0.000567333   0.260192     0.0597903    0.0198692     0.0333223    0.0471157    0.123095   -0.0724233   -0.00642744   0.0323659    0.1498       0.0482076
 -0.108587    -0.217017     -0.0554435   -0.143389      0.0378089     0.0972587    0.00331485  -0.056814     0.00723238   -0.0249018    0.0461177    0.0211654   -0.0191987    0.110296     0.0599642    -0.245249    -0.0183938    0.00456253   -0.00780773  -0.273556     0.15402    -0.0383421    0.0232486   -0.178207    -0.144208     0.126417
  0.247135    -0.225546      0.190178     0.000670692   0.11964       0.0674981    0.0606241    0.0775552   -0.00546443   -0.0213715    0.138021    -0.006503    -0.109903     0.0298677   -0.136244     -0.101826     0.112156    -0.0362886    -0.0347841    0.0214931   -0.0222565   0.114814    -0.0705489   -0.045982    -0.0212131   -0.088247
  0.0569423   -0.0716056     0.16137      0.10268      -0.0744998     0.0870412    0.0732574   -0.0694858   -0.0565979    -0.103424    -0.193221     0.0818617    0.176072     0.0364465   -0.152633     -0.0584049    0.0297555   -0.183987     -0.036289     0.21147      0.0421365   0.119045     0.0452352   -0.0827867   -0.15004     -0.0584061
 -0.12166      0.0383813    -0.236508     0.12468      -0.0152371     0.0261988   -0.0287559    0.110567     0.0217291    -0.00509626  -0.0957257   -0.119063     0.0497641    0.117032    -0.108052      0.0211158   -0.00194167  -0.079373      0.0431279   -0.0720002    0.0473751   0.00144961   0.0113637    0.00120571  -0.0725569   -0.128637
 -0.0513523    0.121983     -0.0236863   -0.100646      0.146085     -0.065863     0.027903    -0.111007     0.0125367    -0.0626627    0.0583817   -0.023295     0.104605     0.0104217   -0.121675     -0.0464275   -0.0649703   -0.026973     -0.0844299   -0.0639172    0.0385953  -0.0154572    0.0282256    0.054672    -0.0373024   -0.0913382
  0.0994614   -0.000726899   0.125971     0.0335524    -0.138823      0.171766    -0.00582072  -0.0623645    0.0567815     0.0685001    0.0226175   -0.0953989   -0.0671484   -0.070002    -0.29041      -0.0145707    0.11747      0.194713      0.0310724    0.106624    -0.0628553   0.105893    -0.127428     0.0477521    0.0814164   -0.0206898
  0.174571     0.159487      0.178458    -0.211774      0.0754504    -0.135448    -0.0581391   -0.123819    -0.0465017    -0.166717     0.158743     0.20207     -0.0110827    0.0566017   -0.022879     -0.0609053    0.0761582   -0.0454374    -0.160962     0.0127499    0.0557769   0.0153327   -0.00898144  -0.217397    -0.0843813    0.0444988
 -0.272113     0.0440875     0.0279672   -0.00861861   -0.0520123     0.0273156    0.0495584   -0.0851553    0.000318364  -0.0294207    0.0887007    0.0268102    0.132222     0.116664     0.0347609    -0.145212    -0.0333512   -0.103814      0.167299     0.148974    -0.0578571   0.0806534   -0.0705534   -0.060592     0.0784971    0.182648
  0.0639843    0.135913      0.127625    -0.06966       0.100273     -0.0253589   -0.107715    -0.0233284   -0.026895      0.050469    -0.169127    -0.0957499   -0.0229301   -0.0839923   -0.154114      0.0333807    0.182707    -0.0759925     0.073422    -0.18272     -0.098045    0.127232     0.0908969    0.00608961  -0.0518902   -0.116172
  0.0589697   -0.0528005     0.0192059   -0.0315288    -0.000774496   0.185928    -0.108193    -0.0817764    0.00740327    0.0857547    0.104127    -0.0709401   -0.0498443    0.0630967    0.0793859    -0.1003      -0.157033    -0.124924     -0.0358603   -0.0921068    0.0220043  -0.00844607  -0.0312873   -0.0825193   -0.0994934    0.184199
  0.0260657   -0.11068      -0.0883043   -0.0551817    -0.115296     -0.100965     0.00692094  -0.016837    -0.0658329     0.243005     0.032874     0.00597241   0.0582471   -0.100452    -0.0732525    -0.0034439   -0.0822158    0.0252175    -0.0580896    0.0655654   -0.059886    0.119534     0.133958     0.177089     0.0209237   -0.0582336
 -0.154251     0.129057      0.00902141  -0.00954457    0.0677173     0.0743729    0.066742    -0.0273932    0.0491753     0.263229    -0.194652     0.0664412    0.135255    -0.0161022   -0.0993324     0.240762     0.0396795   -0.0595022     0.0457784   -0.122658     0.0416979  -0.0585834    0.21632     -0.0783826   -0.12222      0.177794
  0.0310204   -0.0826042    -0.109222    -0.0430777    -0.047538      0.103471     0.0131352    0.0666071    0.0210597    -0.0304466   -0.0395731    0.0107746   -0.0550919   -0.188675     0.00725713    0.004161    -0.0313311    0.12092       0.122204     0.115122     0.0552539   0.0456478    0.0369575   -0.0409852   -0.0124419   -0.0344565
  0.109217    -0.191238      0.081442     0.181085     -0.143248      0.160327     0.0175377    0.0772236   -0.12641       0.00943445   0.113767    -0.0124111    0.0822127   -0.00277309  -0.0916908     0.00318712  -0.081706     0.087378      0.18684      0.101168    -0.131205   -0.167276    -0.127222     0.0212108   -0.0160479   -0.0359913
 -0.1233       0.147898      0.0360015    0.0599158    -0.0229594     0.0861285   -0.00555334   0.0586605   -0.0762494     0.0272416   -0.011934    -0.0963788    0.0500611   -0.0985803   -0.172811      0.0128288   -0.207499     0.163083     -0.0251095   -0.0878706    0.201468    0.0179049    0.0170167   -0.181362    -0.0371392    0.0475478
 -0.0569557    0.113997     -0.0638478    0.123337      0.017873      0.0601778    0.163338     0.00856295  -0.0309761    -0.0721268   -0.111936     0.0662677   -0.142302    -0.0539327   -0.11716      -0.0591087    0.206419    -0.127427      0.0707861   -0.118966     0.0925382  -0.0650176    0.00150989  -0.021314     0.146486    -0.116243kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4275682959265377
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.427589
[ Info: iteration 2, average log likelihood -1.427534
[ Info: iteration 3, average log likelihood -1.427503
[ Info: iteration 4, average log likelihood -1.427469
[ Info: iteration 5, average log likelihood -1.427426
[ Info: iteration 6, average log likelihood -1.427358
[ Info: iteration 7, average log likelihood -1.427224
[ Info: iteration 8, average log likelihood -1.426922
[ Info: iteration 9, average log likelihood -1.426265
[ Info: iteration 10, average log likelihood -1.425137
[ Info: iteration 11, average log likelihood -1.423876
[ Info: iteration 12, average log likelihood -1.423034
[ Info: iteration 13, average log likelihood -1.422664
[ Info: iteration 14, average log likelihood -1.422529
[ Info: iteration 15, average log likelihood -1.422481
[ Info: iteration 16, average log likelihood -1.422462
[ Info: iteration 17, average log likelihood -1.422454
[ Info: iteration 18, average log likelihood -1.422451
[ Info: iteration 19, average log likelihood -1.422449
[ Info: iteration 20, average log likelihood -1.422448
[ Info: iteration 21, average log likelihood -1.422448
[ Info: iteration 22, average log likelihood -1.422447
[ Info: iteration 23, average log likelihood -1.422447
[ Info: iteration 24, average log likelihood -1.422447
[ Info: iteration 25, average log likelihood -1.422446
[ Info: iteration 26, average log likelihood -1.422446
[ Info: iteration 27, average log likelihood -1.422446
[ Info: iteration 28, average log likelihood -1.422446
[ Info: iteration 29, average log likelihood -1.422446
[ Info: iteration 30, average log likelihood -1.422445
[ Info: iteration 31, average log likelihood -1.422445
[ Info: iteration 32, average log likelihood -1.422445
[ Info: iteration 33, average log likelihood -1.422445
[ Info: iteration 34, average log likelihood -1.422445
[ Info: iteration 35, average log likelihood -1.422445
[ Info: iteration 36, average log likelihood -1.422445
[ Info: iteration 37, average log likelihood -1.422445
[ Info: iteration 38, average log likelihood -1.422444
[ Info: iteration 39, average log likelihood -1.422444
[ Info: iteration 40, average log likelihood -1.422444
[ Info: iteration 41, average log likelihood -1.422444
[ Info: iteration 42, average log likelihood -1.422444
[ Info: iteration 43, average log likelihood -1.422444
[ Info: iteration 44, average log likelihood -1.422444
[ Info: iteration 45, average log likelihood -1.422444
[ Info: iteration 46, average log likelihood -1.422444
[ Info: iteration 47, average log likelihood -1.422444
[ Info: iteration 48, average log likelihood -1.422444
[ Info: iteration 49, average log likelihood -1.422444
[ Info: iteration 50, average log likelihood -1.422444
┌ Info: EM with 100000 data points 50 iterations avll -1.422444
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4275889963091062
│     -1.4275343648755385
│      ⋮
└     -1.4224440004258365
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422464
[ Info: iteration 2, average log likelihood -1.422408
[ Info: iteration 3, average log likelihood -1.422376
[ Info: iteration 4, average log likelihood -1.422343
[ Info: iteration 5, average log likelihood -1.422307
[ Info: iteration 6, average log likelihood -1.422266
[ Info: iteration 7, average log likelihood -1.422220
[ Info: iteration 8, average log likelihood -1.422170
[ Info: iteration 9, average log likelihood -1.422118
[ Info: iteration 10, average log likelihood -1.422067
[ Info: iteration 11, average log likelihood -1.422018
[ Info: iteration 12, average log likelihood -1.421971
[ Info: iteration 13, average log likelihood -1.421924
[ Info: iteration 14, average log likelihood -1.421877
[ Info: iteration 15, average log likelihood -1.421829
[ Info: iteration 16, average log likelihood -1.421779
[ Info: iteration 17, average log likelihood -1.421729
[ Info: iteration 18, average log likelihood -1.421679
[ Info: iteration 19, average log likelihood -1.421630
[ Info: iteration 20, average log likelihood -1.421586
[ Info: iteration 21, average log likelihood -1.421546
[ Info: iteration 22, average log likelihood -1.421511
[ Info: iteration 23, average log likelihood -1.421482
[ Info: iteration 24, average log likelihood -1.421457
[ Info: iteration 25, average log likelihood -1.421435
[ Info: iteration 26, average log likelihood -1.421418
[ Info: iteration 27, average log likelihood -1.421402
[ Info: iteration 28, average log likelihood -1.421389
[ Info: iteration 29, average log likelihood -1.421378
[ Info: iteration 30, average log likelihood -1.421368
[ Info: iteration 31, average log likelihood -1.421360
[ Info: iteration 32, average log likelihood -1.421353
[ Info: iteration 33, average log likelihood -1.421347
[ Info: iteration 34, average log likelihood -1.421341
[ Info: iteration 35, average log likelihood -1.421337
[ Info: iteration 36, average log likelihood -1.421332
[ Info: iteration 37, average log likelihood -1.421329
[ Info: iteration 38, average log likelihood -1.421326
[ Info: iteration 39, average log likelihood -1.421323
[ Info: iteration 40, average log likelihood -1.421321
[ Info: iteration 41, average log likelihood -1.421319
[ Info: iteration 42, average log likelihood -1.421317
[ Info: iteration 43, average log likelihood -1.421315
[ Info: iteration 44, average log likelihood -1.421314
[ Info: iteration 45, average log likelihood -1.421312
[ Info: iteration 46, average log likelihood -1.421311
[ Info: iteration 47, average log likelihood -1.421310
[ Info: iteration 48, average log likelihood -1.421309
[ Info: iteration 49, average log likelihood -1.421308
[ Info: iteration 50, average log likelihood -1.421307
┌ Info: EM with 100000 data points 50 iterations avll -1.421307
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.422464440252105
│     -1.4224081872697647
│      ⋮
└     -1.421307272811609
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421323
[ Info: iteration 2, average log likelihood -1.421273
[ Info: iteration 3, average log likelihood -1.421241
[ Info: iteration 4, average log likelihood -1.421209
[ Info: iteration 5, average log likelihood -1.421174
[ Info: iteration 6, average log likelihood -1.421134
[ Info: iteration 7, average log likelihood -1.421090
[ Info: iteration 8, average log likelihood -1.421040
[ Info: iteration 9, average log likelihood -1.420985
[ Info: iteration 10, average log likelihood -1.420924
[ Info: iteration 11, average log likelihood -1.420859
[ Info: iteration 12, average log likelihood -1.420789
[ Info: iteration 13, average log likelihood -1.420716
[ Info: iteration 14, average log likelihood -1.420643
[ Info: iteration 15, average log likelihood -1.420573
[ Info: iteration 16, average log likelihood -1.420509
[ Info: iteration 17, average log likelihood -1.420452
[ Info: iteration 18, average log likelihood -1.420403
[ Info: iteration 19, average log likelihood -1.420361
[ Info: iteration 20, average log likelihood -1.420326
[ Info: iteration 21, average log likelihood -1.420295
[ Info: iteration 22, average log likelihood -1.420269
[ Info: iteration 23, average log likelihood -1.420246
[ Info: iteration 24, average log likelihood -1.420225
[ Info: iteration 25, average log likelihood -1.420206
[ Info: iteration 26, average log likelihood -1.420189
[ Info: iteration 27, average log likelihood -1.420174
[ Info: iteration 28, average log likelihood -1.420159
[ Info: iteration 29, average log likelihood -1.420145
[ Info: iteration 30, average log likelihood -1.420132
[ Info: iteration 31, average log likelihood -1.420120
[ Info: iteration 32, average log likelihood -1.420108
[ Info: iteration 33, average log likelihood -1.420097
[ Info: iteration 34, average log likelihood -1.420086
[ Info: iteration 35, average log likelihood -1.420075
[ Info: iteration 36, average log likelihood -1.420066
[ Info: iteration 37, average log likelihood -1.420056
[ Info: iteration 38, average log likelihood -1.420047
[ Info: iteration 39, average log likelihood -1.420038
[ Info: iteration 40, average log likelihood -1.420029
[ Info: iteration 41, average log likelihood -1.420021
[ Info: iteration 42, average log likelihood -1.420013
[ Info: iteration 43, average log likelihood -1.420005
[ Info: iteration 44, average log likelihood -1.419998
[ Info: iteration 45, average log likelihood -1.419991
[ Info: iteration 46, average log likelihood -1.419983
[ Info: iteration 47, average log likelihood -1.419977
[ Info: iteration 48, average log likelihood -1.419970
[ Info: iteration 49, average log likelihood -1.419963
[ Info: iteration 50, average log likelihood -1.419956
┌ Info: EM with 100000 data points 50 iterations avll -1.419956
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4213233019933513
│     -1.4212726605304933
│      ⋮
└     -1.4199564668456128
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419960
[ Info: iteration 2, average log likelihood -1.419906
[ Info: iteration 3, average log likelihood -1.419860
[ Info: iteration 4, average log likelihood -1.419811
[ Info: iteration 5, average log likelihood -1.419754
[ Info: iteration 6, average log likelihood -1.419686
[ Info: iteration 7, average log likelihood -1.419608
[ Info: iteration 8, average log likelihood -1.419522
[ Info: iteration 9, average log likelihood -1.419431
[ Info: iteration 10, average log likelihood -1.419339
[ Info: iteration 11, average log likelihood -1.419250
[ Info: iteration 12, average log likelihood -1.419167
[ Info: iteration 13, average log likelihood -1.419091
[ Info: iteration 14, average log likelihood -1.419021
[ Info: iteration 15, average log likelihood -1.418957
[ Info: iteration 16, average log likelihood -1.418898
[ Info: iteration 17, average log likelihood -1.418843
[ Info: iteration 18, average log likelihood -1.418791
[ Info: iteration 19, average log likelihood -1.418742
[ Info: iteration 20, average log likelihood -1.418696
[ Info: iteration 21, average log likelihood -1.418653
[ Info: iteration 22, average log likelihood -1.418613
[ Info: iteration 23, average log likelihood -1.418574
[ Info: iteration 24, average log likelihood -1.418539
[ Info: iteration 25, average log likelihood -1.418505
[ Info: iteration 26, average log likelihood -1.418474
[ Info: iteration 27, average log likelihood -1.418445
[ Info: iteration 28, average log likelihood -1.418417
[ Info: iteration 29, average log likelihood -1.418391
[ Info: iteration 30, average log likelihood -1.418366
[ Info: iteration 31, average log likelihood -1.418343
[ Info: iteration 32, average log likelihood -1.418321
[ Info: iteration 33, average log likelihood -1.418301
[ Info: iteration 34, average log likelihood -1.418281
[ Info: iteration 35, average log likelihood -1.418262
[ Info: iteration 36, average log likelihood -1.418245
[ Info: iteration 37, average log likelihood -1.418228
[ Info: iteration 38, average log likelihood -1.418212
[ Info: iteration 39, average log likelihood -1.418197
[ Info: iteration 40, average log likelihood -1.418183
[ Info: iteration 41, average log likelihood -1.418169
[ Info: iteration 42, average log likelihood -1.418156
[ Info: iteration 43, average log likelihood -1.418143
[ Info: iteration 44, average log likelihood -1.418131
[ Info: iteration 45, average log likelihood -1.418120
[ Info: iteration 46, average log likelihood -1.418109
[ Info: iteration 47, average log likelihood -1.418098
[ Info: iteration 48, average log likelihood -1.418088
[ Info: iteration 49, average log likelihood -1.418078
[ Info: iteration 50, average log likelihood -1.418069
┌ Info: EM with 100000 data points 50 iterations avll -1.418069
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4199601039380951
│     -1.4199058981255985
│      ⋮
└     -1.41806895153265
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418069
[ Info: iteration 2, average log likelihood -1.418008
[ Info: iteration 3, average log likelihood -1.417951
[ Info: iteration 4, average log likelihood -1.417886
[ Info: iteration 5, average log likelihood -1.417807
[ Info: iteration 6, average log likelihood -1.417710
[ Info: iteration 7, average log likelihood -1.417593
[ Info: iteration 8, average log likelihood -1.417461
[ Info: iteration 9, average log likelihood -1.417318
[ Info: iteration 10, average log likelihood -1.417172
[ Info: iteration 11, average log likelihood -1.417029
[ Info: iteration 12, average log likelihood -1.416894
[ Info: iteration 13, average log likelihood -1.416769
[ Info: iteration 14, average log likelihood -1.416656
[ Info: iteration 15, average log likelihood -1.416554
[ Info: iteration 16, average log likelihood -1.416463
[ Info: iteration 17, average log likelihood -1.416381
[ Info: iteration 18, average log likelihood -1.416307
[ Info: iteration 19, average log likelihood -1.416240
[ Info: iteration 20, average log likelihood -1.416180
[ Info: iteration 21, average log likelihood -1.416125
[ Info: iteration 22, average log likelihood -1.416074
[ Info: iteration 23, average log likelihood -1.416026
[ Info: iteration 24, average log likelihood -1.415982
[ Info: iteration 25, average log likelihood -1.415940
[ Info: iteration 26, average log likelihood -1.415900
[ Info: iteration 27, average log likelihood -1.415862
[ Info: iteration 28, average log likelihood -1.415826
[ Info: iteration 29, average log likelihood -1.415791
[ Info: iteration 30, average log likelihood -1.415758
[ Info: iteration 31, average log likelihood -1.415726
[ Info: iteration 32, average log likelihood -1.415695
[ Info: iteration 33, average log likelihood -1.415665
[ Info: iteration 34, average log likelihood -1.415637
[ Info: iteration 35, average log likelihood -1.415609
[ Info: iteration 36, average log likelihood -1.415583
[ Info: iteration 37, average log likelihood -1.415557
[ Info: iteration 38, average log likelihood -1.415533
[ Info: iteration 39, average log likelihood -1.415509
[ Info: iteration 40, average log likelihood -1.415486
[ Info: iteration 41, average log likelihood -1.415464
[ Info: iteration 42, average log likelihood -1.415443
[ Info: iteration 43, average log likelihood -1.415422
[ Info: iteration 44, average log likelihood -1.415403
[ Info: iteration 45, average log likelihood -1.415384
[ Info: iteration 46, average log likelihood -1.415366
[ Info: iteration 47, average log likelihood -1.415349
[ Info: iteration 48, average log likelihood -1.415332
[ Info: iteration 49, average log likelihood -1.415316
[ Info: iteration 50, average log likelihood -1.415300
┌ Info: EM with 100000 data points 50 iterations avll -1.415300
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.418068856911299
│     -1.4180076118724203
│      ⋮
└     -1.4153003865299678
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4275682959265377
│     -1.4275889963091062
│     -1.4275343648755385
│     -1.4275029380627005
│      ⋮
│     -1.4153319060800862
│     -1.4153158524907925
└     -1.4153003865299678
32×26 Array{Float64,2}:
 -0.163984    -0.203207    -0.157025   -0.346949      0.1129      0.200809     0.0322102    0.245211   -0.0205077     0.130124   -0.501171   -0.610638   -0.0942848  -0.337041     0.35214    -0.105096    0.176839    0.0870437     0.11432     -0.243534   -0.182836   -0.269213    0.110771    0.138306     0.145542     0.0376015
  0.0615062    0.207132     0.244766    0.263469      0.018266   -0.00337939  -0.215444    -0.201888    0.100122     -0.0115396   0.250299    0.387742    0.0975838   0.155471    -0.256373    0.140012   -0.132669   -0.00221164    0.0372974    0.0791688   0.152448    0.188869   -0.125742   -0.04597     -0.0951266    0.109886
 -0.0791794    0.295054     0.171006   -0.242495     -0.333384   -0.0445253   -0.18912      0.305951    0.173473     -0.134885    0.180069   -0.277985    0.320272   -0.219474    -0.0667724  -0.296019    0.247895   -0.612308     -0.300667    -0.394981   -0.649613    0.0843125   0.680299    0.00863465  -0.112973     0.742572
  0.0590233    0.0536588   -0.133108   -0.385231      0.022696    0.038308    -0.00895157  -0.331452   -0.319877      0.465237    0.546614   -0.585672   -0.251732    0.0351935   -0.104159    0.14948    -0.135354   -0.214987      0.444335    -0.995546   -0.292505    0.180243   -0.25891    -0.573209     0.642335     0.31719
  0.218519     0.317739     0.0877972   0.192364      0.211805    0.107462     0.164946     0.243544    0.201247      0.444076    0.0249911   0.188719   -0.617914   -0.320331     0.399899   -0.364956    0.577948    0.281821     -0.0876992    0.18101    -0.11491    -0.561013   -0.0195128   0.339605    -0.364699    -0.133632
 -0.036959    -0.423911    -0.0250027   0.152051      0.0935477   0.140753     0.59388      0.706805   -0.0198897     0.569465    0.63428    -0.0350007  -0.587365   -0.443221     0.197001   -0.207404    0.420964   -0.0844977     0.251762    -0.0553274  -0.233075    0.218425   -0.0979553  -0.0924043   -0.31654     -0.69963
 -0.00625136  -0.0716016   -0.621012    0.000563344  -0.145326   -0.125977     0.473935    -1.03967     0.404904      0.495045   -0.141571    0.0663421  -0.571837   -0.00976428   0.0116166   0.0757654  -0.0176005   0.216656      0.0824802    0.231017    0.443154   -0.0399666   0.248748   -0.0617468    0.0780357   -0.0288598
  0.186581    -0.0729195   -0.327259    0.0676872    -0.25965     0.340519    -0.0664687   -0.28757    -0.331138      0.188953    0.468097    0.0875743   0.521503   -0.318616    -0.0203031  -0.450399   -0.451146    0.328394      0.235782     0.615464    0.758438    0.11954    -0.156085    0.626719     0.127095    -0.109673
  0.0244195   -0.38487      0.346961   -0.0639276    -0.47766    -0.907412    -0.276563     0.0726433  -0.120834     -0.74836    -0.172895    0.143219    0.519379   -0.335717     0.0220134  -0.419224    0.211104    0.142137      0.165482    -0.30938     0.0880186  -0.509761    0.213206   -0.0216191   -0.300632    -0.274611
  0.0622566    0.304893     0.0489115  -0.154244      0.142728    0.402222    -0.633499     0.191255    0.138613     -0.768226   -0.19949     0.718263    0.523146    0.0566143    0.128037   -0.660468    0.211519    0.277777      0.288207     0.258047    0.253118   -0.230302   -0.0143331   0.00317027  -0.0870557   -0.219807
  0.223621    -0.476781    -0.103702   -0.0721929    -0.194154   -0.63672      0.660951     0.331233   -0.504613     -0.32053    -0.153804    0.146894    0.123412    0.289609    -0.684923   -0.10829     0.196426   -0.00596119   -0.699234     0.492913   -0.292427    0.438754    0.134616   -0.327205     0.200574    -0.459456
 -0.357322     0.159819     0.350515   -0.246722      0.139918   -0.351386     0.234691    -0.182246   -0.0807415    -0.769831    0.354471   -0.044827    0.144422    0.358092    -0.195716   -0.295304    0.40357     0.158087      0.442761     0.611145   -0.468573   -0.121331    0.160552    0.271882     0.403114    -0.0629527
  0.3505      -0.237363    -0.258214   -0.0921403     0.21684     0.141537     0.0319935    0.842677   -0.0901435    -0.667563   -0.381196    0.180859   -0.262019    0.378082     0.18139    -0.0956422  -0.231831   -0.258574     -0.363591     0.730955    0.0898547  -0.193211    0.268228    0.697525    -0.466611    -0.468822
  0.167371     0.0521809   -0.054189   -0.629268      0.169718    0.480536    -0.542817    -0.06231    -0.432027     -0.228181    0.482435    0.364068    0.0580969   0.919921     0.0898523   0.630419   -0.274078   -0.975394     -0.175626     0.292694   -0.0158033  -0.262709    0.0630101   0.29755     -0.417859    -0.0966897
  0.340401     0.516989     0.471235    0.294124     -0.25692     0.662233    -0.212389     0.104993    0.191315      0.204506    0.395824    0.580703   -0.799895    0.615424    -0.857392    0.0864203  -0.149269   -0.596237     -0.691525    -0.790143    0.349994    0.169409    0.323458   -0.67612     -1.10105     -0.507216
 -0.140552     0.0131338    0.0792076   0.414785      0.860008    0.0854998   -0.0274069   -0.532717    0.295748     -0.199752    0.694741    0.561538    0.122953    0.476655    -0.156371   -0.0109341  -0.531407   -0.0154913    -0.0136816   -0.134686    0.037714    0.652132    0.0980409  -0.851042     0.311665    -0.120076
  0.269901     0.0300453   -0.288205    0.322413      0.276206    0.285493     0.428525     0.622192   -0.0575469     0.350234   -0.63884     0.166997   -0.187195   -0.220187    -0.130907    0.953478   -0.238554   -0.0106924    -0.246782    -0.12885     0.0847055   0.0814006  -0.462988   -0.333099    -0.45888     -0.205589
 -0.145344    -0.02521     -0.232527    0.148747      0.210891    0.0679359    0.439827     0.0263213  -0.325669      0.258114   -0.472582   -0.582691   -0.535781    0.413898    -0.316727    0.646835    0.235748    0.395777     -0.303116     0.392864   -0.0289166   0.30615    -0.298729    0.826245    -0.0199578    0.384168
 -0.184908     0.0886824    0.203389    0.0625828     0.486879   -0.505336    -0.337748    -0.0562727   0.121783     -0.0137753  -0.477525   -0.0737263  -0.2091      0.525674     0.212272    0.715561    0.26407    -0.420459     -0.123345    -0.945353   -0.233764   -0.205143    0.0979059  -0.192203    -0.357587     0.1221
 -0.320528     0.267258     0.349609    0.182756     -0.139026    0.349894    -0.00481922  -0.104866    0.19976       0.857366    0.347769   -0.443733   -0.117369   -0.197433     0.253967    0.500746   -0.157126   -0.385176     -0.0605712   -0.283848    0.104326    0.0351877  -0.462288    0.071642    -0.290677     0.181884
  0.07334      0.0175552   -0.122587    0.149054      0.100621   -0.251503     0.143819     0.0558498   0.000761197  -0.182392   -0.135466    0.188664   -0.165359    0.070847     0.0603422   0.0584015   0.241398    0.14489      -0.00681576   0.179598   -0.0703433  -0.197516    0.0739265   0.122302    -0.336546    -0.167877
 -0.0405975    0.0168317    0.111793   -0.0651177    -0.0727169  -0.0403468   -0.129877    -0.192182   -0.0673508    -0.118274    0.0463905   0.0369415   0.176643    0.100109    -0.176547    0.0577208  -0.187169   -0.117112     -0.0156414   -0.0612456   0.0751395   0.124775    0.0667702  -0.0899708    0.032481     0.149085
  0.300721    -0.218321     0.0685128   0.0694031     0.236899    0.333411    -0.371031     0.719132   -0.26868      -0.22166    -0.0462981   0.104113    0.114964    0.0807827   -0.0430619  -0.240309   -0.220948   -0.0862683    -0.169322    -0.0443343   0.138821    0.207329   -0.254162   -0.0460644   -0.0944181   -0.311702
  0.206236     0.015542    -0.191987   -0.0741484    -0.122997    0.283259    -0.0291275   -0.1399      0.763175     -0.0217606   0.199563   -0.0175458   0.167852    0.547987    -0.120706    0.0979102   0.251893    0.00744489   -0.448907     0.0865407  -0.210512    0.0820127  -0.261867    0.334434     0.362182    -0.312488
 -0.531564     0.153298     0.129948    0.190458      0.124839   -0.570151    -0.0266489    0.114946   -0.066888      0.187301   -0.539287   -0.11492     0.315069   -0.846062    -0.0194768  -0.490413   -0.149346    0.710084      0.664281     0.172391   -0.135214    0.231832   -0.157114   -0.452237     0.323374     0.243368
  0.0766107   -0.393634     0.29418     0.295923     -0.350333   -0.00588348  -0.18119     -0.276677    0.249881      0.462943   -0.523774   -0.453021    0.185325   -0.668082    -0.184798   -0.220585    0.888428    0.0719559     0.06256     -0.807623   -0.150993    0.471097    0.103341   -0.460443     0.252801    -0.0474349
 -0.0360532    0.151965     0.0906704  -0.296799     -0.0116836   0.34092      0.395251     0.30473    -0.29473       0.14489     0.246563   -0.24739    -0.192808   -0.39677     -0.292718   -0.48574    -0.0491126   0.263298      0.109477     0.152217   -0.143931   -0.143597    0.164238    0.171086     0.186585     0.21729
 -0.260258    -0.00486501  -0.381654   -0.0837704     0.195893    0.13179      0.00173143   0.0800297   0.183019      0.297448   -0.067262   -0.327231   -0.258834   -0.279854     0.657249   -0.292439    0.194824    0.00780014    0.245796    -0.0107145  -0.0158866  -0.0489747   0.146655    0.008392     0.307083    -0.278327
 -0.0259768    0.291432     0.257975   -0.207839      0.405613    0.265179    -0.202903    -0.18316    -0.148316     -0.295101   -0.346174    0.136704    0.105041   -0.265128    -0.452153    0.330606   -0.798623    0.224147      0.0357752   -0.19932     0.642344   -0.107429    0.141122   -0.301061    -0.311419     0.802172
 -0.330613    -0.0997351    0.265853    0.109656     -0.587599   -0.125058    -0.349865    -0.460208   -0.280505     -0.0736331  -0.579125   -0.443966    0.770514    0.63112     -0.390826    0.270032   -0.427896   -0.000354799  -0.255098     0.0152408   0.0933925   0.377178   -0.258611    0.14614      0.267927     0.425003
 -0.469865    -0.239257     0.535896   -0.328789     -0.539105    0.052006     0.065693    [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
-0.0599525  -0.109064     -0.320923    0.771241    0.301278    0.697163   -0.2483       0.0224764  -0.350022   -0.666532   -0.674687      0.135122     0.0415977   0.564027    0.0823836   0.182842   -0.424689     0.110128    -0.219779
 -0.825758     0.310374     0.374193    0.171065     -0.197981   -0.311912     0.0572799   -0.768854   -0.00256005    0.291628    0.391837    0.71297     0.0359722  -0.195326    -0.33944    -0.181754    0.414425    0.292498      0.16504      0.331422   -0.308106   -0.0209053  -0.0567347  -0.462661    -0.00858994   0.508023[ Info: iteration 1, average log likelihood -1.415285
[ Info: iteration 2, average log likelihood -1.415271
[ Info: iteration 3, average log likelihood -1.415257
[ Info: iteration 4, average log likelihood -1.415244
[ Info: iteration 5, average log likelihood -1.415231
[ Info: iteration 6, average log likelihood -1.415218
[ Info: iteration 7, average log likelihood -1.415205
[ Info: iteration 8, average log likelihood -1.415193
[ Info: iteration 9, average log likelihood -1.415181
[ Info: iteration 10, average log likelihood -1.415170
┌ Info: EM with 100000 data points 10 iterations avll -1.415170
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.317952e+05
      1       7.171796e+05      -2.146156e+05 |       32
      2       7.009214e+05      -1.625820e+04 |       32
      3       6.957790e+05      -5.142421e+03 |       32
      4       6.930720e+05      -2.707006e+03 |       32
      5       6.912818e+05      -1.790170e+03 |       32
      6       6.900052e+05      -1.276606e+03 |       32
      7       6.890505e+05      -9.547138e+02 |       32
      8       6.882938e+05      -7.567343e+02 |       32
      9       6.876827e+05      -6.110773e+02 |       32
     10       6.871313e+05      -5.514091e+02 |       32
     11       6.866612e+05      -4.700977e+02 |       32
     12       6.862574e+05      -4.037869e+02 |       32
     13       6.859206e+05      -3.368105e+02 |       32
     14       6.855957e+05      -3.249354e+02 |       32
     15       6.852795e+05      -3.161374e+02 |       32
     16       6.849932e+05      -2.863722e+02 |       32
     17       6.847535e+05      -2.396425e+02 |       32
     18       6.845381e+05      -2.153780e+02 |       32
     19       6.843400e+05      -1.980896e+02 |       32
     20       6.841623e+05      -1.777202e+02 |       32
     21       6.839958e+05      -1.665464e+02 |       32
     22       6.838297e+05      -1.660740e+02 |       32
     23       6.836643e+05      -1.653680e+02 |       32
     24       6.835211e+05      -1.432489e+02 |       32
     25       6.833908e+05      -1.302704e+02 |       32
     26       6.832633e+05      -1.274792e+02 |       32
     27       6.831375e+05      -1.258282e+02 |       32
     28       6.829982e+05      -1.393489e+02 |       32
     29       6.828585e+05      -1.396636e+02 |       32
     30       6.827305e+05      -1.279548e+02 |       32
     31       6.826120e+05      -1.185239e+02 |       32
     32       6.825116e+05      -1.003869e+02 |       32
     33       6.824171e+05      -9.451062e+01 |       32
     34       6.823346e+05      -8.247696e+01 |       32
     35       6.822601e+05      -7.457001e+01 |       32
     36       6.821816e+05      -7.849546e+01 |       32
     37       6.820895e+05      -9.205879e+01 |       32
     38       6.820029e+05      -8.663690e+01 |       32
     39       6.819194e+05      -8.348290e+01 |       32
     40       6.818414e+05      -7.795551e+01 |       32
     41       6.817689e+05      -7.255909e+01 |       32
     42       6.817071e+05      -6.174587e+01 |       32
     43       6.816475e+05      -5.959395e+01 |       32
     44       6.815881e+05      -5.948148e+01 |       32
     45       6.815346e+05      -5.344499e+01 |       32
     46       6.814811e+05      -5.350847e+01 |       32
     47       6.814263e+05      -5.476701e+01 |       32
     48       6.813767e+05      -4.960564e+01 |       32
     49       6.813304e+05      -4.634756e+01 |       32
     50       6.812826e+05      -4.776983e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 681282.6185251961)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.426528
[ Info: iteration 2, average log likelihood -1.421684
[ Info: iteration 3, average log likelihood -1.420430
[ Info: iteration 4, average log likelihood -1.419568
[ Info: iteration 5, average log likelihood -1.418668
[ Info: iteration 6, average log likelihood -1.417752
[ Info: iteration 7, average log likelihood -1.417023
[ Info: iteration 8, average log likelihood -1.416576
[ Info: iteration 9, average log likelihood -1.416329
[ Info: iteration 10, average log likelihood -1.416181
[ Info: iteration 11, average log likelihood -1.416080
[ Info: iteration 12, average log likelihood -1.416002
[ Info: iteration 13, average log likelihood -1.415937
[ Info: iteration 14, average log likelihood -1.415882
[ Info: iteration 15, average log likelihood -1.415833
[ Info: iteration 16, average log likelihood -1.415790
[ Info: iteration 17, average log likelihood -1.415752
[ Info: iteration 18, average log likelihood -1.415718
[ Info: iteration 19, average log likelihood -1.415687
[ Info: iteration 20, average log likelihood -1.415658
[ Info: iteration 21, average log likelihood -1.415632
[ Info: iteration 22, average log likelihood -1.415609
[ Info: iteration 23, average log likelihood -1.415587
[ Info: iteration 24, average log likelihood -1.415567
[ Info: iteration 25, average log likelihood -1.415548
[ Info: iteration 26, average log likelihood -1.415531
[ Info: iteration 27, average log likelihood -1.415514
[ Info: iteration 28, average log likelihood -1.415499
[ Info: iteration 29, average log likelihood -1.415484
[ Info: iteration 30, average log likelihood -1.415470
[ Info: iteration 31, average log likelihood -1.415457
[ Info: iteration 32, average log likelihood -1.415444
[ Info: iteration 33, average log likelihood -1.415432
[ Info: iteration 34, average log likelihood -1.415420
[ Info: iteration 35, average log likelihood -1.415409
[ Info: iteration 36, average log likelihood -1.415398
[ Info: iteration 37, average log likelihood -1.415387
[ Info: iteration 38, average log likelihood -1.415377
[ Info: iteration 39, average log likelihood -1.415366
[ Info: iteration 40, average log likelihood -1.415356
[ Info: iteration 41, average log likelihood -1.415346
[ Info: iteration 42, average log likelihood -1.415336
[ Info: iteration 43, average log likelihood -1.415326
[ Info: iteration 44, average log likelihood -1.415317
[ Info: iteration 45, average log likelihood -1.415307
[ Info: iteration 46, average log likelihood -1.415297
[ Info: iteration 47, average log likelihood -1.415287
[ Info: iteration 48, average log likelihood -1.415277
[ Info: iteration 49, average log likelihood -1.415268
[ Info: iteration 50, average log likelihood -1.415258
32×26 ┌ Info: EM with 100000 data points 50 iterations avll -1.415258
└ 59.0 data points per parameter
Array{Float64,2}:
 -0.130467    0.147978   -0.152413   -0.0367389    0.609326   -0.293157     0.1869     -0.0560019    0.188343      0.150936   -0.846827    -0.28987     -0.728457     0.153633      0.0437484    0.428177     0.115561    0.0350225  -0.243561    -0.730271     -0.310292    -0.248766     0.481462    -0.278284    -0.250391    0.337361
 -0.251604    0.352967   -0.113117    0.62359      0.443871    0.0682817   -0.0881337  -0.334828    -0.0148351     0.695879    0.216297     0.298263    -0.566025    -0.118942      0.484642     0.26229      0.386749    0.52531    -0.00312705   0.503694     -0.808482    -0.305396    -0.359906    -0.193986    -0.214424    0.0291688
 -0.277923   -0.10156     0.169261   -0.271443    -0.316517    0.0992014   -0.0771976  -0.230312    -0.346548     -0.384176    0.712379     0.0899586    0.681808    -0.0707993     0.116793    -0.447444    -0.936841   -0.23582     0.178519     0.391661      0.704451    -0.00800331   0.0824996    0.012956     0.256168   -0.106606
 -0.556384   -0.063485    0.346642    0.365053    -0.0733872  -0.579315     0.152577   -0.151445     0.137643      0.0171605  -0.407297    -0.0305896    0.244277    -0.790037     -0.109723    -0.48846      0.0815355   0.875853    0.664228     0.00445219    0.0225409    0.372277    -0.273471    -0.690372     0.364219    0.00352858
 -0.0223234   0.11858    -0.289398    0.0762508    0.278508   -0.115218    -0.0172913  -0.934955    -0.100487      0.625492    0.629383    -0.0832386   -0.228637     0.000833263  -0.407946     0.100202    -0.173992    0.0650548   0.162891    -0.892822      0.266478     0.590556    -0.182552    -0.826535     0.739097    0.303166
  0.0818056  -0.0597744  -0.0979192  -0.372218    -0.170705    0.0439917   -0.619115    0.0143978   -0.0587137    -0.621455   -0.170894     0.173887     0.360022     0.291742      0.0516002   -0.401552     0.120567    0.260581   -0.0388903    0.214642      0.18515     -0.0398794   -0.0707095    0.241641     0.075138   -0.0346403
  0.295416   -0.118232    0.064452   -0.178028     0.0609921   0.184046    -0.155522    0.805973    -0.278542     -0.559578   -0.300391     0.243723    -0.0371485    0.149705      0.172373    -0.218364     0.0659355  -0.10603    -0.342212     0.550441     -0.0172862   -0.535917     0.112684     0.555059    -0.641059   -0.319742
 -0.155335   -0.407747   -0.521926   -0.210931     0.24137     0.418073     0.302209   -0.170032     0.541078      0.168441   -0.0317917    0.466548    -0.534954    -0.0692536     0.695004    -0.403072     0.37848     0.152079    0.221339     0.467969      0.570242    -0.0254901    0.227453     0.242394    -0.187653   -0.547161
  0.23512     0.173985   -0.314286   -0.60858      0.0724533   0.103651    -0.390895    0.055885    -0.190086     -0.117524    0.453009    -0.278899    -0.116457     0.890917      0.0234198    0.80259      0.0258865  -1.16748    -0.15486     -0.391638     -0.532147     0.0289561    0.285948     0.0954506    0.0647632  -0.0413556
 -0.270728   -0.0188536   0.681445    0.0530487   -0.301145   -0.281925    -0.126767   -0.285811    -0.0644578     0.219615    0.249378    -0.247035     0.0800729   -0.119397      0.153165    -0.0317619    0.194085   -0.280173    0.0482494   -0.372774      0.0545833   -0.055911     0.128987     0.0620059   -0.0824479   0.266573
  0.104202    0.0440635  -0.0208806   0.119129     0.0594816  -0.15738      0.240584   -0.0611602   -0.0606112    -0.348252   -0.101824     0.245756    -0.0550305    0.282427     -0.257405     0.279581    -0.0172506   0.0119325  -0.226063     0.280534      0.00272327   0.102581     0.0582949    0.0915455   -0.208381   -0.105393
 -0.150564    0.0636278   0.0678892   0.0120193   -0.264756    0.488754    -0.0379852  -0.0251276    0.782017      0.414893    0.404759    -0.17292      0.0999973    0.209035      0.00058328   0.144095     0.287657   -0.108082   -0.150367    -0.277018     -0.216344     0.0478061   -0.515647     0.0848517    0.263237   -0.259448
  0.215563    0.306157    0.17159    -0.103162     0.418471    0.657042    -0.578375   -0.428099     0.000616597  -0.286218   -0.512562     0.321328    -0.0112307   -0.509952     -0.136721     0.34822     -0.557675    0.448422    0.438979     0.0317696     0.991431    -0.440415    -0.0936986    0.01261     -0.180043    0.65694
 -0.461281   -0.0274136   0.242762    0.146952    -0.31078    -0.130968    -0.145348   -0.468789    -0.284227      0.0859779  -0.867592    -0.720517     0.499436     0.713362     -0.365095     0.427138    -0.166256    0.251749   -0.437234    -0.000457022  -0.185853     0.0652631   -0.305798     0.300966     0.354965    0.543236
 -0.194666    0.234563   -0.1276     -0.381775     0.0262566   0.493168     0.713324    0.377436    -0.169467      0.424696    0.0651131   -0.427504    -0.526322    -0.628367     -0.0172413   -0.479962     0.181935    0.302197    0.0886077    0.473432      0.00638539  -0.0280926    0.102392     0.364511     0.43836     0.133573
  0.192878    0.169203    0.420723    0.123799    -0.0272395   0.443103    -0.188488    0.248737     0.292263      0.164845    0.376437     0.665499    -0.536322     0.0750743    -0.33635     -0.230067     0.0702711  -0.830413   -0.320321    -0.699054      0.0424149    0.0467153    0.515761    -0.708097    -0.854684   -0.387042
  0.0848625  -0.16173    -0.0386267  -0.0682871   -0.412473   -0.102432    -0.384027    0.334265     0.133877      0.119272   -0.28889     -0.580754     0.505264    -0.74921       0.182209    -0.448759     0.505386   -0.138253    0.15265     -0.776004     -0.285552    -0.195124     0.228873    -0.0840217   -0.0785675   0.200022
  0.0418291   0.0838565   0.398451    0.201532     0.587643   -0.415031    -0.686542   -0.284205     0.181092     -0.584015   -0.0172418    0.574041     0.431284     0.773296      0.276739     0.475191    -0.0370462  -0.252119   -0.0477221   -0.60457      -0.0999696   -0.00260419  -0.0193838   -0.406699    -0.367114    0.0759773
  0.104797   -0.21283    -0.120529    0.338765     0.215935    0.0277454    0.508784    0.725873    -0.181708      0.531356   -0.184571    -0.0977684   -0.303719    -0.388358      0.189234     0.462704     0.0105872  -0.095309    0.058573    -0.403204     -0.147181    -0.160868    -0.519289    -0.181335    -0.508131   -0.497388
 -0.164595   -0.463282    0.0768474  -0.150902    -0.42234    -0.450748     0.457506    0.308816    -0.26335       0.100991    0.417922    -0.49417     -0.158984     0.457598     -0.0685513   -0.339183     0.717567    0.0329508  -0.111039     0.30783      -1.01288      0.519988    -0.0954507    0.152755     0.381876   -0.437872
  0.0784821  -0.206699    0.0342489   0.0480814   -0.575147   -0.00422722  -0.349414   -0.250419     0.00139853    0.146053    0.160478     0.762755     1.11483      0.0439343    -0.435084     0.265804    -0.0352665  -0.422601    0.288774     0.0957272     0.579396     0.159695    -0.422871     0.202708    -0.32875    -0.398524
 -0.122523    0.162028   -0.0721087   0.0842236    0.14122     0.64731      0.124451    0.0734969   -0.130115      0.610766    0.00806427  -0.561002    -0.36275      0.0564396     0.0255829    0.892865    -0.317658   -0.219034   -0.53223      0.00745736    0.477406     0.465975    -0.386854     0.288012    -0.440729    0.602491
 -0.0770944   0.029636    0.115707   -0.118396     0.037599    0.088136    -0.201809    6.63356e-5   0.0515211     0.0326203  -0.0446959   -0.25134      0.031926    -0.116781      0.188748    -0.0370207    0.0717331   0.0533632   0.205753    -0.207733     -0.110889    -0.122371     0.00366391   0.0777427    0.0833595   0.0985115
  0.914992    0.232412    0.196765    0.834167     0.343593    0.355605    -0.379774    0.348402     0.0434337     0.0840432   0.15099      0.219029     0.00939312  -0.0732638    -0.472704    -0.257054    -0.0271418   0.0218987  -0.27218     -0.0192211     0.550179     0.572384    -0.072223    -0.00825549   0.171121   -0.517742
 -0.206292   -0.0926405   0.285757   -0.558159     0.5498      0.493236     0.350151   -0.0662342    0.031402     -0.382549    0.829601     0.570665    -0.426224     0.919483     -0.696263     0.225618    -0.767057   -0.0592491  -0.0724004    0.567507     -0.082372     0.0502927   -0.367475    -0.267294     0.0123602  -0.227113
 -0.467803    0.177338    0.289842   -0.283908    -0.597448   -0.46114     -0.127902   -0.812595     0.302994      0.0217978  -0.0272855    0.412916     0.0342179   -0.0971127    -0.656147    -0.252333     0.450733   -0.0365645  -0.0801013    0.441197     -0.0957102    0.425167     0.654234    -0.0486971   -0.12822     0.807126
  0.230765   -0.55461    -0.404461   -0.00699159  -0.173692    0.150754     0.260102    0.522302     0.247607     -0.31959    -0.596902    -0.663652     0.225444     0.442217     -0.180465     0.0463771   -0.594337   -0.286426    0.0880798   -0.152773      0.547288     0.828322    -0.102443     0.284925     0.37929    -0.567319
 -0.0242698   0.0772186  -0.504601   -0.00657212  -0.237978   -0.185981     0.407828   -0.685175     0.231256      0.376172   -0.0211854   -0.162057    -0.299454    -0.0427898    -0.0145777    0.103572    -0.0309855   0.138317    0.1131       0.134355      0.223687    -0.245162     0.0798825    0.103513     0.0157765  -0.0168921
 -0.0510095   0.0181666  -0.167907    0.0647222    0.274208    0.102792    -0.0246361   0.256282     0.0214313     0.191345   -6.31511e-5  -0.0732671   -0.161632    -0.219019      0.314028    -0.18694      0.0873218   0.0448099   0.143023    -0.0344945    -0.0742508   -0.0567958    0.0407941   -0.0247754    0.0450302  -0.181684
 -0.205901    0.381943    0.27318     0.133143     0.318533   -0.137327    -0.016149    0.0474194    0.122448     -0.59495     0.394122     0.366281     0.463746    -0.0227687    -0.142186    -0.67163      0.317178    0.189041    0.476957     0.375762     -0.563091    -0.293546     0.204773    -0.0133996    0.402816   -0.0796675
 -0.139557    0.0305355   0.281029   -0.191256     0.0610986   0.0920938   -0.0895595   0.1549      -0.384347     -0.157815    0.068482     0.00943917   0.269538    -0.126409     -0.37761     -0.00660285  -0.486769   -0.110107   -0.0044586   -0.260257     -0.0188552    0.19125      0.0692892   -0.404941    -0.0856228   0.414007
  0.372134   -0.174546   -0.234339    0.255453     0.110559   -0.446086     0.618634    0.147915    -0.305124     -0.27508    -0.191151     0.51572     -0.0783441    0.229468     -0.575475     0.19457     -0.0669459   0.195303   -0.521409     0.629675      0.0719669    0.246625     0.0800955    0.0284966   -0.10024    -0.281101[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415248
[ Info: iteration 2, average log likelihood -1.415238
[ Info: iteration 3, average log likelihood -1.415228
[ Info: iteration 4, average log likelihood -1.415218
[ Info: iteration 5, average log likelihood -1.415208
[ Info: iteration 6, average log likelihood -1.415198
[ Info: iteration 7, average log likelihood -1.415188
[ Info: iteration 8, average log likelihood -1.415178
[ Info: iteration 9, average log likelihood -1.415168
[ Info: iteration 10, average log likelihood -1.415158
┌ Info: EM with 100000 data points 10 iterations avll -1.415158
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
