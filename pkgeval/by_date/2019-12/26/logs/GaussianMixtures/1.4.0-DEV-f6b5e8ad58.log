Julia Version 1.4.0-DEV.661
Commit f6b5e8ad58 (2019-12-24 15:13 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed SortingAlgorithms ── v0.3.1
 Installed GaussianMixtures ─── v0.3.0
 Installed Missings ─────────── v0.4.3
 Installed Arpack_jll ───────── v3.5.0+2
 Installed Blosc ────────────── v0.5.1
 Installed Compat ───────────── v2.2.0
 Installed OrderedCollections ─ v1.1.0
 Installed FileIO ───────────── v1.2.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed Rmath ────────────── v0.6.0
 Installed PDMats ───────────── v0.9.10
 Installed CMake ────────────── v1.1.2
 Installed LegacyStrings ────── v0.4.1
 Installed NearestNeighbors ─── v0.4.4
 Installed QuadGK ───────────── v2.3.1
 Installed StaticArrays ─────── v0.12.1
 Installed URIParser ────────── v0.4.0
 Installed Parameters ───────── v0.12.0
 Installed StatsFuns ────────── v0.9.3
 Installed JLD ──────────────── v0.9.1
 Installed OpenBLAS_jll ─────── v0.3.7+1
 Installed StatsBase ────────── v0.32.0
 Installed BinDeps ──────────── v1.0.0
 Installed BinaryProvider ───── v0.5.8
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed FillArrays ───────── v0.8.2
 Installed DataStructures ───── v0.17.6
 Installed CMakeWrapper ─────── v0.2.3
 Installed SpecialFunctions ─── v0.9.0
 Installed DataAPI ──────────── v1.1.0
 Installed Distances ────────── v0.8.2
 Installed Arpack ───────────── v0.4.0
 Installed Clustering ───────── v0.13.3
 Installed HDF5 ─────────────── v0.12.5
 Installed Distributions ────── v0.21.11
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_pFntc9/Project.toml`
 [no changes]
  Updating `/tmp/jl_pFntc9/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_wvNoYf/Project.toml`
 [no changes]
  Updating `/tmp/jl_wvNoYf/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_pQEIpu/Project.toml`
 [no changes]
  Updating `/tmp/jl_pQEIpu/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_w9Kwu0/Project.toml`
 [no changes]
  Updating `/tmp/jl_w9Kwu0/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_TxcBEZ/Project.toml`
 [no changes]
  Updating `/tmp/jl_TxcBEZ/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_TxcBEZ/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.0
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -4.922426229273247e6, [87148.90415189476, 12851.095848105246], [-1878.3259388331649 -13112.326819527385 2433.8932969333355; 2380.880051841234 13986.561879699419 -2071.566944388617], [[84529.25496424451 -491.0029973992372 -1116.094480126318; -491.0029973992371 82751.40017206033 -603.2046398465138; -1116.0944801263179 -603.2046398465138 87337.2249888206], [15400.61287489744 326.2535512035145 1109.500544025907; 326.2535512035145 16945.82752379219 736.6110402141445; 1109.5005440259067 736.6110402141445 12290.540421560721]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.007321e+03
      1       8.840440e+02      -1.232767e+02 |        6
      2       8.629298e+02      -2.111416e+01 |        0
      3       8.629298e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 862.9298482946042)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.075278
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.781857
[ Info: iteration 2, lowerbound -3.647123
[ Info: iteration 3, lowerbound -3.508671
[ Info: iteration 4, lowerbound -3.363309
[ Info: iteration 5, lowerbound -3.222595
[ Info: iteration 6, lowerbound -3.092045
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.973386
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.874331
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.803839
[ Info: iteration 10, lowerbound -2.771124
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.747394
[ Info: iteration 12, lowerbound -2.714333
[ Info: iteration 13, lowerbound -2.675982
[ Info: iteration 14, lowerbound -2.623011
[ Info: iteration 15, lowerbound -2.557904
[ Info: iteration 16, lowerbound -2.489437
[ Info: iteration 17, lowerbound -2.428562
[ Info: iteration 18, lowerbound -2.380820
[ Info: iteration 19, lowerbound -2.345307
[ Info: iteration 20, lowerbound -2.320524
[ Info: iteration 21, lowerbound -2.308319
[ Info: dropping number of Gaussions to 2
[ Info: iteration 22, lowerbound -2.303104
[ Info: iteration 23, lowerbound -2.299264
[ Info: iteration 24, lowerbound -2.299258
[ Info: iteration 25, lowerbound -2.299255
[ Info: iteration 26, lowerbound -2.299254
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Thu Dec 26 14:25:07 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Thu Dec 26 14:25:16 2019: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Thu Dec 26 14:25:19 2019: EM with 272 data points 0 iterations avll -2.075278
5.8 data points per parameter
, Thu Dec 26 14:25:21 2019: GMM converted to Variational GMM
, Thu Dec 26 14:25:31 2019: iteration 1, lowerbound -3.781857
, Thu Dec 26 14:25:31 2019: iteration 2, lowerbound -3.647123
, Thu Dec 26 14:25:31 2019: iteration 3, lowerbound -3.508671
, Thu Dec 26 14:25:31 2019: iteration 4, lowerbound -3.363309
, Thu Dec 26 14:25:31 2019: iteration 5, lowerbound -3.222595
, Thu Dec 26 14:25:31 2019: iteration 6, lowerbound -3.092045
, Thu Dec 26 14:25:31 2019: dropping number of Gaussions to 7
, Thu Dec 26 14:25:31 2019: iteration 7, lowerbound -2.973386
, Thu Dec 26 14:25:31 2019: dropping number of Gaussions to 6
, Thu Dec 26 14:25:31 2019: iteration 8, lowerbound -2.874331
, Thu Dec 26 14:25:31 2019: dropping number of Gaussions to 5
, Thu Dec 26 14:25:31 2019: iteration 9, lowerbound -2.803839
, Thu Dec 26 14:25:31 2019: iteration 10, lowerbound -2.771124
, Thu Dec 26 14:25:31 2019: dropping number of Gaussions to 3
, Thu Dec 26 14:25:31 2019: iteration 11, lowerbound -2.747394
, Thu Dec 26 14:25:31 2019: iteration 12, lowerbound -2.714333
, Thu Dec 26 14:25:31 2019: iteration 13, lowerbound -2.675982
, Thu Dec 26 14:25:31 2019: iteration 14, lowerbound -2.623011
, Thu Dec 26 14:25:31 2019: iteration 15, lowerbound -2.557904
, Thu Dec 26 14:25:31 2019: iteration 16, lowerbound -2.489437
, Thu Dec 26 14:25:31 2019: iteration 17, lowerbound -2.428562
, Thu Dec 26 14:25:31 2019: iteration 18, lowerbound -2.380820
, Thu Dec 26 14:25:31 2019: iteration 19, lowerbound -2.345307
, Thu Dec 26 14:25:31 2019: iteration 20, lowerbound -2.320524
, Thu Dec 26 14:25:31 2019: iteration 21, lowerbound -2.308319
, Thu Dec 26 14:25:31 2019: dropping number of Gaussions to 2
, Thu Dec 26 14:25:31 2019: iteration 22, lowerbound -2.303104
, Thu Dec 26 14:25:31 2019: iteration 23, lowerbound -2.299264
, Thu Dec 26 14:25:31 2019: iteration 24, lowerbound -2.299258
, Thu Dec 26 14:25:31 2019: iteration 25, lowerbound -2.299255
, Thu Dec 26 14:25:31 2019: iteration 26, lowerbound -2.299254
, Thu Dec 26 14:25:31 2019: iteration 27, lowerbound -2.299253
, Thu Dec 26 14:25:31 2019: iteration 28, lowerbound -2.299253
, Thu Dec 26 14:25:31 2019: iteration 29, lowerbound -2.299253
, Thu Dec 26 14:25:31 2019: iteration 30, lowerbound -2.299253
, Thu Dec 26 14:25:31 2019: iteration 31, lowerbound -2.299253
, Thu Dec 26 14:25:31 2019: iteration 32, lowerbound -2.299253
, Thu Dec 26 14:25:32 2019: iteration 33, lowerbound -2.299253
, Thu Dec 26 14:25:32 2019: iteration 34, lowerbound -2.299253
, Thu Dec 26 14:25:32 2019: iteration 35, lowerbound -2.299253
, Thu Dec 26 14:25:32 2019: iteration 36, lowerbound -2.299253
, Thu Dec 26 14:25:32 2019: iteration 37, lowerbound -2.299253
, Thu Dec 26 14:25:32 2019: iteration 38, lowerbound -2.299253
, Thu Dec 26 14:25:32 2019: iteration 39, lowerbound -2.299253
, Thu Dec 26 14:25:32 2019: iteration 40, lowerbound -2.299253
, Thu Dec 26 14:25:32 2019: iteration 41, lowerbound -2.299253
, Thu Dec 26 14:25:32 2019: iteration 42, lowerbound -2.299253
, Thu Dec 26 14:25:32 2019: iteration 43, lowerbound -2.299253
, Thu Dec 26 14:25:32 2019: iteration 44, lowerbound -2.299253
, Thu Dec 26 14:25:32 2019: iteration 45, lowerbound -2.299253
, Thu Dec 26 14:25:32 2019: iteration 46, lowerbound -2.299253
, Thu Dec 26 14:25:32 2019: iteration 47, lowerbound -2.299253
, Thu Dec 26 14:25:32 2019: iteration 48, lowerbound -2.299253
, Thu Dec 26 14:25:32 2019: iteration 49, lowerbound -2.299253
, Thu Dec 26 14:25:32 2019: iteration 50, lowerbound -2.299253
, Thu Dec 26 14:25:32 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601814, 95.95490777398179]
β = [178.04509222601814, 95.95490777398179]
m = [4.250300733269876 79.28686694436135; 2.0002292577753344 53.851987172461115]
ν = [180.04509222601814, 97.95490777398179]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547483814 -0.007644049042327559; 0.0 0.00858170516633297], [0.3758763611948986 -0.008953123827346662; 0.0 0.012748664777409602]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999997
avll from stats: -1.0142429089076597
avll from llpg:  -1.0142429089076592
avll direct:     -1.0142429089076592
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9862475752280127
avll from llpg:  -0.9862475752280127
avll direct:     -0.9862475752280127
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.167597     -0.0156158    0.0239589   -0.119629    -0.0892636    0.0400087   -0.126008     0.0877612    0.0785356   -0.100607    -0.114203     -0.329959    -0.144227     0.0723148    0.0788416     0.0317582     0.00414488   0.00924849   0.0125347    0.143019    -0.039259     0.0557513   -0.0890122  -0.00830766   0.126446    -0.260459
 -0.00738605    0.0219584   -0.00481714   0.0960736    0.0428462    0.0645548   -0.0859228    0.00786922  -0.0137177   -0.126466     0.119433     -0.191621     0.130322     0.117806     0.133089      0.0133909    -0.0345318    0.145152    -0.0245936   -0.230371     0.0254863    0.0841507   -0.0509356   0.167199     0.113222     0.0143246
 -0.123712      0.00547262  -0.0723888   -0.086905     0.0344664   -0.0697899   -0.200693    -0.123632     0.01693      0.131395     0.036984      0.0893548   -0.0370441    0.234546     0.151358     -0.0980877     0.164786    -0.121548     0.0696389    0.02566     -0.00186146   0.0371588    0.0872549  -0.122127    -0.198647    -0.0441831
  0.0383594    -0.186394     0.146025    -0.135135     0.0283517   -0.134058     0.15952      0.133043     0.0457882   -0.0306726    0.19539       0.0299422   -0.0994235   -0.00948493  -0.0725373    -0.0632485    -0.0407192   -0.00745792  -0.12692      0.116544     0.111359    -0.0144594    0.0791121  -0.00309049   0.0551215    0.0213128
 -0.0589477     0.0300616   -0.0202415   -0.049636     0.0871463    0.128209    -0.0702008    0.0177831    0.030542     0.158483    -0.0453853     0.170064     0.0601569   -0.108345     0.0401011     0.0596618     0.114952    -0.113213     0.00356435   0.102624     0.0405457    0.0259085    0.0425574   0.0592226    0.127808     0.0289256
 -0.0366329     0.0660722   -0.112994    -0.103574     0.102992    -0.14567     -0.120972    -0.0521908    0.139367    -0.137456     0.070138     -0.0103164   -0.0218403    0.0793508    0.216766      0.17232       0.0771259   -0.0284369   -0.0428474    0.118362     0.0207093    0.0321129   -0.0668656   0.091713    -0.127749    -0.187587
 -0.0483404    -0.0602827   -0.159672     0.0764022    0.00676785  -0.0642876   -0.0610689    0.0497911    0.0392174    0.0833279   -0.0143064     0.17474      0.0870246   -0.0652171   -0.0187811     0.000532183  -0.0693907   -0.138256     0.0371594    0.12938     -0.110074    -0.207722     0.0160798  -0.0385031    0.104242    -0.11582
 -0.0665514    -0.0118597    0.108083     0.0176774   -0.0643594   -0.023444    -0.0631907    0.029694    -0.0713203   -0.0573781   -0.181352     -0.0553628    0.170295    -0.0617955   -0.0404376    -0.0364509    -0.0849086   -0.0240071    0.112842    -0.0693709    0.00159963   0.0987212   -0.0741664   0.0197339   -0.124537     0.0124999
 -0.0059841    -0.0115777   -0.0744356    0.179922    -0.0464205   -0.118722    -0.0289991    0.0602701   -0.139488    -0.00361803   0.033323     -0.0102031    0.0835434    0.0880044   -0.183551      0.0721764    -0.139887     0.0678038    0.173906    -0.14413     -0.08528      0.117503    -0.188765   -0.0471863    0.0381878    0.118774
 -0.0157515    -0.0126733    0.0686458   -0.00656042  -0.00717047  -0.0328502    0.0868653    0.0303268   -0.134894     0.16819      0.100596     -0.0677081    0.0769217    0.159251     0.110956     -0.190384      0.385105     0.107467     0.0506621    0.0286176    0.104317    -0.0701774    0.0645274   0.0126824    0.1739      -0.0545816
  0.0499461    -0.0786918    0.115741    -0.0806308    0.0647358    0.0206071   -0.0359357    0.131761    -0.14059     -0.0264187   -0.0226857    -0.0362034   -0.0188119    0.0776817   -0.145636     -0.164063      0.177407    -0.0407061    0.0705587    0.063375    -0.0970811   -0.131942    -0.128838   -0.160552     0.0875175   -0.213573
 -0.0392475    -0.121047     0.169227    -0.0261832   -0.0548477   -0.0729205   -0.081448    -0.137405    -0.121475    -0.0550807    0.0778225    -0.0910287   -0.0119491    0.184347    -0.186557      0.0737181    -0.0446337   -0.0636833    0.0848557    0.0182023   -0.0846853    0.0920664   -0.120425   -0.0308052   -0.0285967    0.15018
 -0.0550895     0.0723177   -0.0377315   -0.0335126   -0.0291435   -0.0122567   -0.200326     0.170076    -0.0750018    0.0117697   -0.0766588    -0.179324     0.0124352    0.0319818   -0.0292124    -0.0281933    -0.0158662   -0.0767011    0.0275888   -0.0227997   -0.0642347   -0.0318773   -0.0932143  -0.0862985   -0.0187566   -0.0818997
  0.139655     -0.0250376    0.0959451    0.0176282   -0.0491025   -0.0448865    0.185437     0.083869     0.00746888  -0.13166      0.000622877   0.106384    -0.00953803   0.0160808   -0.0900778     0.148511      0.0912697   -0.167146    -0.0270104   -0.017274     0.0862243   -0.0719956    0.175242   -0.140451    -0.119568    -0.060176
 -0.0821514     0.129428     0.039946    -0.00507776  -0.0890563   -0.0703766   -0.0322117   -0.00688568   0.0435122   -0.0248711    0.0543939    -0.130036     0.199962    -0.00220571  -0.00173482   -0.0689493    -0.133007     0.149605     0.055301     0.191733     0.0596454    0.0520874   -0.0325844  -0.29745     -0.0712669    0.027453
 -0.17805       0.0205137    0.0965148   -0.0151181   -0.0639569    0.0261567    0.104163    -0.109901     0.0325561   -0.165844     0.170198      0.0260686    0.00780814  -0.139741    -0.000482291  -0.0709838     0.0532287    0.16599      0.0444759    0.0224224    0.122152     0.0296732   -0.105985    0.0625591    0.0869863   -0.178025
 -0.0655784    -0.00356433  -0.129772    -0.133553     0.0504506   -0.00919937  -0.151757     0.148754     0.0537492   -0.0166377   -0.172459      0.00934203   0.0678598   -0.112755    -0.17807      -0.0607539     0.0427942    0.159291    -0.0515345    0.00118741   0.0889772    0.00396835   0.101289    0.0200434    0.00557445   0.184684
 -0.00348494    0.0970307    0.193552     0.0720641    0.0625416    0.0329744    0.00748679  -0.0214954    0.0438923    0.137993    -0.0458985     0.254686    -0.107795     0.0136119    0.053308      0.259183     -0.28027     -0.00209508   0.0155727    0.0262362    0.124409    -0.123606     0.0941735  -0.134353     0.0719995   -0.0327683
 -0.0453969     0.0539774    0.0568054    0.0217828   -0.0298236    0.114032    -0.0664784    0.0653996    0.0294666   -0.00644519   0.0966371    -0.0358181   -0.0444158    0.255843    -0.106211     -0.0641248     0.0905676    0.0850095    0.0389488    0.0933682    0.103089     0.140293    -0.0416048  -0.0666061    0.122144     0.192661
 -0.112568      0.161901    -0.0476785   -0.123995    -0.0477818   -0.0240904   -0.023007     0.0447632    0.157157     0.0446403   -0.146443     -0.0414057   -0.0821948    0.090623    -0.055296     -0.178125      0.142013     0.0205545    0.00829188  -0.0029948    0.0588089    0.00693782  -0.0483418   0.00988836   0.0307852   -0.197874
  0.000910716  -0.228282     0.0386346    0.115468     0.00092459   0.0202403   -0.190451    -0.0234515   -0.0874879   -0.108313    -0.0335143     0.0791284   -0.0653196   -0.138244    -0.149846     -0.0470861     0.126547     0.0628932    0.107918    -0.0394267    0.0663864   -0.0463565    0.0940773  -0.0377305   -0.0443158    0.12522
 -0.0378755    -0.0416466   -0.0308113    0.029976    -0.115569    -0.0160844   -0.134843     0.0578789   -0.0104532   -0.0875891   -0.138906     -0.0592849    0.0473463   -0.0774039   -0.0671119    -0.0479641     0.00204213  -0.0683757    0.0339014    0.0709069    0.0424139   -0.0191886    0.0606427   0.0198605   -0.127368     0.186965
 -0.0531092    -0.0805631   -0.229886     0.148536     0.0123946    0.104229    -0.0455948    0.0264822   -0.0689001    0.060574    -0.0647552    -0.0379632   -0.0185782    0.0897108    0.107474      0.119602      0.147785     0.00640587  -0.0471864   -0.15041      0.0899851    0.0559551    0.0185403  -0.0209843   -0.316164     0.0553055
  0.0864553     0.0695056    0.220374    -0.0529958    0.166033     0.129285     0.0164422    0.128511    -0.0403815   -0.00618767  -0.100859      0.167338     0.0798307   -0.0697053   -0.0780281    -0.0799338    -0.065434     0.226608     0.0331931   -0.154329    -0.139088     0.0747199    0.0680635  -0.00849109  -0.126209     0.144801
 -0.130083      0.0514731    0.167109     0.012751     0.246242     0.10124     -0.102342    -0.0128102   -0.0963299   -0.0702959   -0.0289289    -0.0924503    0.0854143   -0.126172    -0.204061     -0.0330635     0.312078    -0.118392     0.112881    -0.0170258   -0.112115    -0.00779618   0.046749    0.0393517    0.074223     0.241926
 -0.0855297     0.0242187   -0.109992     0.0121655   -0.120076    -0.114196     0.0675568    0.0156407    0.0128291   -0.0117077    0.0398289    -0.03368     -0.0461159   -0.0300595   -0.0390988     0.0258927    -0.232177    -0.0946604   -0.00375473   0.242158    -0.0886885   -0.0476861    0.114675   -0.0624081   -0.0656804    0.185229
  0.0864101     0.0336337   -0.0555946    0.225447     0.239128    -0.035927    -0.0185762   -0.0733764   -0.0967372   -0.00651016   0.039112     -0.0992837   -0.187422     0.0581523   -0.0280011     0.0137934     0.014822     0.0109623    0.135319    -0.0887538    0.0184317   -0.0856171    0.204808   -0.123021    -0.0823204   -0.0733197
  0.237332      0.189971     0.0187423    0.00466439  -0.00654185   0.169741     0.0304578    0.0906009   -0.00462006  -0.155931    -0.136651      0.101949    -0.0818052   -0.141073    -0.159382     -0.0547203     0.037196    -0.171612     0.114993     0.0888801   -0.0194333    0.0879048   -0.082268   -0.041031     0.0221754   -0.0666341
  0.020706      0.051369     0.0708784    0.0540036   -0.00499669   0.00113446  -0.124062    -0.0879001   -0.0607189    0.0233511    0.0534543     0.209168    -0.184237    -0.00413309   0.128967     -0.0111238    -0.167783     0.0127803   -0.0986058    0.0867776    0.094509    -0.1046       0.153056   -0.0381445   -0.073364     0.0529502
 -0.0930829     0.0439351   -0.0901957    0.197293    -0.173441     0.094364     0.038601     0.0873409    0.0621317    0.0170988   -0.141824      0.0125331   -0.075899    -0.126657    -0.0566532    -0.0836389    -0.0691237   -0.0703138    0.0612572   -0.0341338   -0.0554402   -0.0914617    0.0825414  -0.0148031   -0.120124     0.0771092
 -0.0936767     0.0351783   -0.134607    -0.116492    -0.156387    -0.128937    -0.0175544    0.0326097   -0.00842835  -0.0434576    0.0616538     0.1664       0.113632     0.116647     0.0826658     0.146565      0.0327784   -0.0263837    0.0756237   -0.148325    -0.170321    -0.0792756   -0.0706437  -0.0854558   -0.0639535   -0.243545
  0.029106     -0.0863477   -0.104196     0.149198    -0.099164     0.0284454    0.0575932    0.0430501    0.00880279  -0.0831387    0.0294333    -0.115672    -0.102245    -0.0367514    0.0958831    -0.19487       0.0338064    0.00150085   0.093844     0.0835362   -0.131891    -0.00193698   0.177154   -0.0896123   -0.140286    -0.0797562kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.434496671923532
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.434555
[ Info: iteration 2, average log likelihood -1.434496
[ Info: iteration 3, average log likelihood -1.433842
[ Info: iteration 4, average log likelihood -1.425326
[ Info: iteration 5, average log likelihood -1.405572
[ Info: iteration 6, average log likelihood -1.396983
[ Info: iteration 7, average log likelihood -1.394695
[ Info: iteration 8, average log likelihood -1.393836
[ Info: iteration 9, average log likelihood -1.393467
[ Info: iteration 10, average log likelihood -1.393249
[ Info: iteration 11, average log likelihood -1.393056
[ Info: iteration 12, average log likelihood -1.392873
[ Info: iteration 13, average log likelihood -1.392714
[ Info: iteration 14, average log likelihood -1.392583
[ Info: iteration 15, average log likelihood -1.392467
[ Info: iteration 16, average log likelihood -1.392341
[ Info: iteration 17, average log likelihood -1.392170
[ Info: iteration 18, average log likelihood -1.391966
[ Info: iteration 19, average log likelihood -1.391758
[ Info: iteration 20, average log likelihood -1.391576
[ Info: iteration 21, average log likelihood -1.391416
[ Info: iteration 22, average log likelihood -1.391289
[ Info: iteration 23, average log likelihood -1.391191
[ Info: iteration 24, average log likelihood -1.391106
[ Info: iteration 25, average log likelihood -1.391024
[ Info: iteration 26, average log likelihood -1.390936
[ Info: iteration 27, average log likelihood -1.390837
[ Info: iteration 28, average log likelihood -1.390729
[ Info: iteration 29, average log likelihood -1.390619
[ Info: iteration 30, average log likelihood -1.390520
[ Info: iteration 31, average log likelihood -1.390438
[ Info: iteration 32, average log likelihood -1.390376
[ Info: iteration 33, average log likelihood -1.390330
[ Info: iteration 34, average log likelihood -1.390296
[ Info: iteration 35, average log likelihood -1.390271
[ Info: iteration 36, average log likelihood -1.390251
[ Info: iteration 37, average log likelihood -1.390235
[ Info: iteration 38, average log likelihood -1.390223
[ Info: iteration 39, average log likelihood -1.390214
[ Info: iteration 40, average log likelihood -1.390208
[ Info: iteration 41, average log likelihood -1.390205
[ Info: iteration 42, average log likelihood -1.390202
[ Info: iteration 43, average log likelihood -1.390200
[ Info: iteration 44, average log likelihood -1.390199
[ Info: iteration 45, average log likelihood -1.390199
[ Info: iteration 46, average log likelihood -1.390198
[ Info: iteration 47, average log likelihood -1.390198
[ Info: iteration 48, average log likelihood -1.390198
[ Info: iteration 49, average log likelihood -1.390198
[ Info: iteration 50, average log likelihood -1.390198
┌ Info: EM with 100000 data points 50 iterations avll -1.390198
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4345548788511453
│     -1.4344955264436021
│      ⋮
└     -1.3901975131521722
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.390357
[ Info: iteration 2, average log likelihood -1.390211
[ Info: iteration 3, average log likelihood -1.389692
[ Info: iteration 4, average log likelihood -1.385306
[ Info: iteration 5, average log likelihood -1.372630
[ Info: iteration 6, average log likelihood -1.362013
[ Info: iteration 7, average log likelihood -1.357755
[ Info: iteration 8, average log likelihood -1.355587
[ Info: iteration 9, average log likelihood -1.354148
[ Info: iteration 10, average log likelihood -1.353072
[ Info: iteration 11, average log likelihood -1.352147
[ Info: iteration 12, average log likelihood -1.351239
[ Info: iteration 13, average log likelihood -1.350290
[ Info: iteration 14, average log likelihood -1.349363
[ Info: iteration 15, average log likelihood -1.348585
[ Info: iteration 16, average log likelihood -1.348015
[ Info: iteration 17, average log likelihood -1.347630
[ Info: iteration 18, average log likelihood -1.347355
[ Info: iteration 19, average log likelihood -1.347137
[ Info: iteration 20, average log likelihood -1.346941
[ Info: iteration 21, average log likelihood -1.346742
[ Info: iteration 22, average log likelihood -1.346512
[ Info: iteration 23, average log likelihood -1.346222
[ Info: iteration 24, average log likelihood -1.345860
[ Info: iteration 25, average log likelihood -1.345426
[ Info: iteration 26, average log likelihood -1.344938
[ Info: iteration 27, average log likelihood -1.344453
[ Info: iteration 28, average log likelihood -1.344065
[ Info: iteration 29, average log likelihood -1.343817
[ Info: iteration 30, average log likelihood -1.343670
[ Info: iteration 31, average log likelihood -1.343577
[ Info: iteration 32, average log likelihood -1.343512
[ Info: iteration 33, average log likelihood -1.343461
[ Info: iteration 34, average log likelihood -1.343417
[ Info: iteration 35, average log likelihood -1.343380
[ Info: iteration 36, average log likelihood -1.343348
[ Info: iteration 37, average log likelihood -1.343319
[ Info: iteration 38, average log likelihood -1.343294
[ Info: iteration 39, average log likelihood -1.343271
[ Info: iteration 40, average log likelihood -1.343250
[ Info: iteration 41, average log likelihood -1.343231
[ Info: iteration 42, average log likelihood -1.343213
[ Info: iteration 43, average log likelihood -1.343197
[ Info: iteration 44, average log likelihood -1.343183
[ Info: iteration 45, average log likelihood -1.343171
[ Info: iteration 46, average log likelihood -1.343159
[ Info: iteration 47, average log likelihood -1.343149
[ Info: iteration 48, average log likelihood -1.343140
[ Info: iteration 49, average log likelihood -1.343132
[ Info: iteration 50, average log likelihood -1.343125
┌ Info: EM with 100000 data points 50 iterations avll -1.343125
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3903567886837291
│     -1.3902105119131714
│      ⋮
└     -1.343124514374437
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.343324
[ Info: iteration 2, average log likelihood -1.343125
[ Info: iteration 3, average log likelihood -1.342670
[ Info: iteration 4, average log likelihood -1.338830
[ Info: iteration 5, average log likelihood -1.325277
[ Info: iteration 6, average log likelihood -1.311060
[ Info: iteration 7, average log likelihood -1.301132
[ Info: iteration 8, average log likelihood -1.295331
[ Info: iteration 9, average log likelihood -1.291939
[ Info: iteration 10, average log likelihood -1.289767
[ Info: iteration 11, average log likelihood -1.288457
[ Info: iteration 12, average log likelihood -1.287597
[ Info: iteration 13, average log likelihood -1.287048
[ Info: iteration 14, average log likelihood -1.286727
[ Info: iteration 15, average log likelihood -1.286537
[ Info: iteration 16, average log likelihood -1.286410
[ Info: iteration 17, average log likelihood -1.286311
[ Info: iteration 18, average log likelihood -1.286222
[ Info: iteration 19, average log likelihood -1.286135
[ Info: iteration 20, average log likelihood -1.286043
[ Info: iteration 21, average log likelihood -1.285936
[ Info: iteration 22, average log likelihood -1.285786
[ Info: iteration 23, average log likelihood -1.285523
[ Info: iteration 24, average log likelihood -1.284962
[ Info: iteration 25, average log likelihood -1.283680
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.281282
[ Info: iteration 27, average log likelihood -1.295566
[ Info: iteration 28, average log likelihood -1.290155
[ Info: iteration 29, average log likelihood -1.288731
[ Info: iteration 30, average log likelihood -1.288345
[ Info: iteration 31, average log likelihood -1.288058
[ Info: iteration 32, average log likelihood -1.287669
[ Info: iteration 33, average log likelihood -1.287019
[ Info: iteration 34, average log likelihood -1.286042
[ Info: iteration 35, average log likelihood -1.284821
[ Info: iteration 36, average log likelihood -1.283312
[ Info: iteration 37, average log likelihood -1.281297
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.278864
[ Info: iteration 39, average log likelihood -1.295055
[ Info: iteration 40, average log likelihood -1.289911
[ Info: iteration 41, average log likelihood -1.288313
[ Info: iteration 42, average log likelihood -1.287537
[ Info: iteration 43, average log likelihood -1.286926
[ Info: iteration 44, average log likelihood -1.286420
[ Info: iteration 45, average log likelihood -1.285905
[ Info: iteration 46, average log likelihood -1.285137
[ Info: iteration 47, average log likelihood -1.283907
[ Info: iteration 48, average log likelihood -1.282183
[ Info: iteration 49, average log likelihood -1.279929
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.277257
┌ Info: EM with 100000 data points 50 iterations avll -1.277257
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.343323985384665
│     -1.3431250602774711
│      ⋮
└     -1.2772568713737005
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.294944
[ Info: iteration 2, average log likelihood -1.289529
[ Info: iteration 3, average log likelihood -1.285939
[ Info: iteration 4, average log likelihood -1.273429
[ Info: iteration 5, average log likelihood -1.247201
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.223529
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.227665
[ Info: iteration 8, average log likelihood -1.226035
[ Info: iteration 9, average log likelihood -1.211489
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.202132
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.203806
[ Info: iteration 12, average log likelihood -1.209165
[ Info: iteration 13, average log likelihood -1.201535
[ Info: iteration 14, average log likelihood -1.196454
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.192852
[ Info: iteration 16, average log likelihood -1.203766
[ Info: iteration 17, average log likelihood -1.198433
[ Info: iteration 18, average log likelihood -1.194870
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.192137
[ Info: iteration 20, average log likelihood -1.203460
[ Info: iteration 21, average log likelihood -1.198264
[ Info: iteration 22, average log likelihood -1.194750
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.192059
[ Info: iteration 24, average log likelihood -1.203435
[ Info: iteration 25, average log likelihood -1.198234
[ Info: iteration 26, average log likelihood -1.194696
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.192010
[ Info: iteration 28, average log likelihood -1.203418
[ Info: iteration 29, average log likelihood -1.198198
[ Info: iteration 30, average log likelihood -1.194634
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.191952
[ Info: iteration 32, average log likelihood -1.203398
[ Info: iteration 33, average log likelihood -1.198142
[ Info: iteration 34, average log likelihood -1.194546
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.191874
[ Info: iteration 36, average log likelihood -1.203371
[ Info: iteration 37, average log likelihood -1.198075
[ Info: iteration 38, average log likelihood -1.194454
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.191802
[ Info: iteration 40, average log likelihood -1.203355
[ Info: iteration 41, average log likelihood -1.198031
[ Info: iteration 42, average log likelihood -1.194397
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.191760
[ Info: iteration 44, average log likelihood -1.203351
[ Info: iteration 45, average log likelihood -1.198013
[ Info: iteration 46, average log likelihood -1.194372
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.191742
[ Info: iteration 48, average log likelihood -1.203350
[ Info: iteration 49, average log likelihood -1.198006
[ Info: iteration 50, average log likelihood -1.194363
┌ Info: EM with 100000 data points 50 iterations avll -1.194363
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2949435908795885
│     -1.2895293627051323
│      ⋮
└     -1.1943625968658382
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.192029
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.191651
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.188986
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.154601
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      5
│      7
│      8
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.067500
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      6
│     13
│     14
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.082112
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│      8
│     13
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.060169
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      3
│      9
│     13
│     14
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.067908
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.057433
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      3
│     13
│     14
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.079500
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      7
│      8
│      9
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.064177
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.079583
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      6
│      7
│      8
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.044059
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      5
│      9
│     13
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.081043
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      7
│      8
│     13
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.048786
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      3
│      5
│      6
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.073896
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│      9
│     13
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.059229
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      3
│     13
│     14
│     15
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.078193
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      7
│      8
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.058390
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      3
│      6
│      9
│     13
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.077923
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      7
│      8
│     13
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.059513
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      3
│     13
│     14
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.074131
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.052758
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.091166
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      7
│      8
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.041311
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      5
│      9
│     13
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.080044
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      6
│      7
│      8
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.050504
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      5
│     13
│     14
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.079714
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      3
│      7
│      8
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.056757
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.082432
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      7
│      8
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.047834
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      9
│     13
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.088612
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      5
│      7
│      8
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.047633
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      6
│     13
│     14
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.076141
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      7
│      8
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.057382
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.082641
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.038411
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      3
│      9
│     13
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.085957
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     13
│     14
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.061044
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      3
│      5
│     13
│     14
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.067819
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      6
│      7
│      8
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.058376
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.086451
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      3
│      7
│      8
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.039099
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      5
│      6
│      9
│     13
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.077152
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     13
│     14
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.059038
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      3
│     13
│     14
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.073390
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      7
│      8
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.055581
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      6
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.082678
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      7
│      8
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.047988
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      3
│      9
│     13
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.080495
┌ Info: EM with 100000 data points 50 iterations avll -1.080495
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1920287313324192
│     -1.1916510752330758
│      ⋮
└     -1.0804951640418698
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.434496671923532
│     -1.4345548788511453
│     -1.4344955264436021
│     -1.4338417357453812
│      ⋮
│     -1.08267754884402
│     -1.0479881113245277
└     -1.0804951640418698
32×26 Array{Float64,2}:
  0.0498494    -0.0848491    0.115343     -0.0795237    0.0911708     0.0184324    -0.0306333    0.114796   -0.140361    -0.112714     -0.0356706   -0.0160049    -0.0433905    0.0420646   -0.134322     -0.144701     0.203644    -0.0374817    0.0877085    0.0743068  -0.0802638   -0.149063    -0.120464   -0.173353      0.0956358  -0.207782
 -0.120764      0.00165384  -0.0787293    -0.111827     0.0378       -0.0727335    -0.204865    -0.141652   -0.0242741    0.132072      0.0333497    0.0895391    -0.0774387    0.230341     0.156034     -0.103404     0.184816    -0.127273     0.0735035    0.0243186   0.0129459    0.0275613    0.0876423  -0.124568     -0.198302   -0.0446362
 -0.0839734     0.0280531   -0.128728     -0.148278     0.0494823    -0.0033614    -0.131415     0.176155    0.0608621   -0.0224583    -0.169184     0.000783274   0.0607906   -0.0935882   -0.17964      -0.047165     0.0295858    0.156633    -0.0636875   -0.0518236   0.084288     0.0245871    0.101332    0.0240067     0.0151045   0.183812
  0.0384268    -0.167371     0.173468     -0.057603    -0.000718088  -0.138255      0.159262     0.111465    0.0667333   -0.0371462     0.200466     0.0150072    -0.102863    -0.0766018   -0.0915403    -0.0637034   -0.0595851   -0.0354302   -0.122865     0.109676    0.112207    -0.00499087   0.079051    0.00970295    0.0285985   0.0194381
 -0.0919597     0.021439    -0.0953833     0.0109523   -0.132762     -0.121481      0.0371497   -0.0101669   0.0746199    0.0266092     0.0501277   -0.0205107    -0.0443792   -0.0301245   -0.0422666     0.026277    -0.228501    -0.0970638   -0.0039635    0.243866   -0.116205    -0.0539537    0.120065   -0.0392109    -0.0646327   0.185357
 -0.0754065    -0.0133055    0.102098      0.0204693   -0.0311904    -0.0264686    -0.0692894    0.019434   -0.0700554   -0.056354     -0.177498    -0.0622988     0.121455    -0.052585    -0.0341714    -0.0321601   -0.0794195   -0.0188336    0.156913    -0.0454164   0.0217496    0.0931391   -0.069991    0.0239158    -0.0706601   0.00672405
 -0.0829694     0.113421     0.0484869     0.00217749  -0.136669     -0.0333141    -0.0422799    0.029382    0.0283906   -0.00405358   -0.0121496   -0.128172      0.204914    -0.037069     0.00268041   -0.0542354   -0.144198     0.141061     0.0448432    0.205427    0.0746411    0.0494177   -0.0250555  -0.310155     -0.0950203   0.0337835
  0.000749361   0.0342876   -0.0125456     0.111843     0.0694465     0.0678169    -0.0753695    0.0161492  -0.0406967   -0.154678      0.0993323   -0.20904       0.110477     0.114334     0.127185      0.0389036   -0.0320523    0.112182    -0.0284182   -0.316536    0.0312375    0.0809334   -0.0320608   0.235258      0.168845    0.0105204
  0.236904      0.186516     0.0223072     0.00235536  -0.00518237    0.171928      0.0227381    0.099874   -0.0078824   -0.118265     -0.150526     0.113873     -0.0834163   -0.138822    -0.1545       -0.0663537    0.0464511   -0.149969     0.0696066    0.135947   -0.0431917    0.0955049   -0.0863061  -0.0413904     0.0185033  -0.00778708
 -0.187619      0.0116117    0.09507      -0.00962097  -0.059897      0.0298349     0.097379    -0.0811352   0.0572836   -0.187769      0.176287     0.00900043   -0.00473384  -0.139294    -0.000545889  -0.0591991    0.028395     0.156827     0.0686769    0.0244791   0.125885     0.0290832   -0.0883212   0.0651023     0.0853042  -0.158955
 -0.11232       0.166735    -0.0385303    -0.126058    -0.0310416    -0.0228876    -0.0231708    0.0578191   0.176274     0.0380147    -0.148613    -0.0419787    -0.0862148    0.0939374   -0.0576897    -0.178598     0.14662     -0.0103734    0.0171671    0.028883    0.0482128    0.00692526  -0.0584059   0.0724382     0.0321174  -0.202057
 -0.0577372     0.0811733   -0.0367827    -0.0328111   -0.0404513    -0.0165436    -0.209445     0.168989   -0.103714     0.0325826    -0.0771753   -0.175846     -0.016217     0.0331209   -0.024788     -0.027403    -0.016848    -0.144546     0.0169428   -0.0228903  -0.0639358   -0.0319819   -0.0716307  -0.101993     -0.0140161  -0.0835667
 -0.0488094    -0.0803718   -0.194508      0.150188     0.00790231    0.138845     -0.0654927    0.0566063  -0.0862753    0.139234     -0.166562    -0.0575141    -0.0378884    0.121272     0.131372      0.112464     0.164445     0.00339916  -0.0483809   -0.171791    0.218932     0.0570128   -0.0826022  -0.0272694    -0.199109   -0.235934
 -0.074619     -0.0803503   -0.29834       0.148001     0.0192253     0.0684641    -0.0498581    0.0118996  -0.0500404   -0.0473964    -0.00547424  -0.035526      0.0157606    0.0936835    0.108127      0.118837     0.118571     0.00858819  -0.0463982   -0.121434   -0.0553478    0.0531237    0.0488816  -0.0189935    -0.341122    0.365177
 -0.0369163    -0.0286045    0.0429079     0.0279275   -0.13657      -0.0102819    -0.134774     0.0547168  -0.024119    -0.0826716    -0.107336    -0.0636504     0.0392185   -0.0815735   -0.064378     -0.0460748    0.00653985  -0.068784     0.0325496    0.07225     0.0376865   -0.00223744   0.0660044   0.0260486    -0.122684    0.193463
 -0.0486052    -0.0741827   -0.18549       0.0827456    0.00617163   -0.0636973    -0.0539508    0.0542277   0.0536695    0.0992896    -0.00629777   0.196648      0.0891706   -0.0660644   -0.0509577    -0.0101539   -0.0428796   -0.136394     0.0348486    0.145249   -0.144073    -0.239002     0.0310107  -0.00509989    0.130195   -0.167635
 -0.109997      0.0281244   -0.146808     -0.118458    -0.190364     -0.145231      0.0367466    0.0374595   0.00111863  -0.0652687     0.069378     0.13896       0.0849066    0.151496     0.0556432     0.144917     0.0253371   -0.0247388    0.106702    -0.118687   -0.178039    -0.0835441   -0.179106   -0.0673281    -0.0665394  -0.270177
 -0.120503      0.0511916    0.184364      0.0105681    0.274095      0.103614     -0.137057    -0.0362592  -0.0847192   -0.0565511    -0.0571807   -0.0780634     0.114662    -0.115069    -0.17716      -0.0420905    0.331397    -0.116564     0.0869961   -0.0167023  -0.120146    -0.00581549   0.0849129   0.0476132     0.078643    0.346767
  0.116141      0.0124433    0.161384     -0.0279452    0.139266      0.132274      0.0262967    0.166921   -0.061796    -0.022015     -0.064283     0.157057      0.0756636   -0.055976    -0.0665781    -0.042339     0.0152791    0.241086    -0.660776    -0.177904   -0.112055     0.0760496    0.0716194   0.0169327    -0.130764    0.0291281
  0.0217826     0.111954     0.298053     -0.0744205    0.162107      0.0985046     0.0109919    0.0853428  -0.0171236    0.0205057    -0.0982974    0.171034      0.106641    -0.119732    -0.0723954    -0.0886142   -0.0706447    0.268712     0.695206    -0.14343    -0.155825     0.0696785    0.0821495  -0.0318728    -0.125034    0.218985
  0.0103322     0.0477667    0.0686603     0.0471986   -0.00168431    0.000556369  -0.118668    -0.084508   -0.0431039    0.0300526     0.0484429    0.198387     -0.173663    -0.0302197    0.147726     -0.054673    -0.218443     0.0174906   -0.0930396    0.0801772   0.0847646   -0.0994946    0.149205   -0.0246269    -0.0731261   0.0581258
 -0.0319076     0.0393797   -0.0222055    -0.059578     0.092801      0.177739     -0.0521016   -0.0208075   0.0771917    0.165017     -0.0821577    0.191333      0.086942    -0.111927     0.0700671     0.03031      0.10631     -0.105414     0.0224759    0.119963    0.0501117    0.0291376    0.0311658   0.0506712     0.148931   -0.00233837
  0.0787206    -0.0547409    0.000498902   0.0828368   -0.0629386    -0.00781759    0.118447     0.0645878   0.0192757   -0.12904       0.0142791   -0.00987753   -0.0459816   -0.00858679   0.00152114    0.00161415   0.0479431   -0.0869132    0.0406913    0.0128306  -0.0194664   -0.0415492    0.18002    -0.0908092    -0.13084    -0.0672829
 -0.0810405     0.0533451    0.0701772     0.0332205   -0.0368867     0.158841     -0.0598577    0.0706726   0.0339347   -0.0327786     0.127544    -0.0384042    -0.0658241    0.249823    -0.100403     -0.07274      0.119686     0.0803748    0.00456276   0.0851599   0.10874      0.125072     0.0151464  -0.0297793     0.0990613   0.192604
 -0.0386152    -0.00179095   0.0138779    -0.0673009    0.0298171    -0.0890729    -0.10186     -0.111586    0.00218981  -0.0985643     0.0766242   -0.0574976    -0.0114985    0.116038     0.0203815     0.12108      0.0273299   -0.0445663    0.0139695    0.0693132  -0.0297817    0.0629391   -0.080463    0.0350269    -0.0814568  -0.0237475
 -0.172735     -0.0463538    0.0233146    -0.114513    -0.054869      0.0362926    -0.118823     0.0895878   0.0850633   -0.0934808    -0.108121    -0.329337     -0.155709     0.0667391    0.101157      0.00326763  -0.00650084   0.0152083    0.0138738    0.157188   -0.0387581    0.0588585   -0.114912   -0.000175309   0.128532   -0.253021
  0.00858849   -0.226243     0.0401577     0.105274    -0.0535356     0.042637     -0.182424    -0.0244859  -0.0722943   -0.108974     -0.0482173    0.0620609    -0.0617091   -0.135923    -0.150642     -0.0652681    0.168122     0.076463     0.129427    -0.052661    0.053281    -0.0446218    0.110532   -0.0385341    -0.040603    0.124378
  0.0864264     0.041229    -0.0797746     0.203731     0.200814     -0.0523196     0.0262808   -0.0771712  -0.103886    -0.000902745   0.02894     -0.0684072    -0.18829      0.0569627   -0.025495      0.0279658    0.0215371    0.0250469    0.145112    -0.0827542   0.00388234  -0.112489     0.22183    -0.109858     -0.102866   -0.0693275
 -0.0162845    -0.0443006    0.0559411    -0.00639701  -0.013145     -0.0354965     0.0702466    0.0386997  -0.137104     0.162599      0.106793    -0.0458261     0.0866023    0.180411     0.108839     -0.176769     0.361545     0.141333     0.0438283    0.0250788   0.103453    -0.0917342    0.0593445   0.00683388    0.169237   -0.0514016
 -0.0921376     0.0548819   -0.127766      0.202903    -0.173845      0.118528     -0.00289889   0.0821166   0.0531806    0.0062956    -0.123926    -0.0431141    -0.0775618   -0.119838    -0.0759243    -0.0544724   -0.0822992   -0.104531     0.0520364   -0.0337622  -0.0712942   -0.0858779    0.077714   -0.0267843    -0.132267    0.0767255
 -0.00693714   -0.0346206   -0.075901      0.199586    -0.0429125    -0.135103     -0.0392667    0.0897106  -0.132564    -0.00459746    0.0382259    0.00494853    0.086106     0.0881878   -0.179298      0.0616849   -0.130289     0.0733495    0.151408    -0.151558   -0.0898273    0.142382    -0.190173   -0.0391184     0.0457636   0.127048
  0.010991      0.0991937    0.178239      0.0639761    0.0470968     0.0251298    -0.0135142   -0.0184218   0.0390283    0.125112     -0.0513881    0.256762     -0.112443     0.0235809    0.0553941     0.233561    -0.29561      0.0267007    0.0126142    0.0627616   0.123184    -0.104763     0.0978697  -0.137198      0.0650767  -0.0293009[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.049988
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      3
│      5
│      6
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.028584
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.042519
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.044078
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.033812
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      3
│      5
│      6
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.036506
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.049678
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      3
│      5
│      6
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.028533
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      5
│      6
│      7
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.042517
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      5
│      6
│      7
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.044076
┌ Info: EM with 100000 data points 10 iterations avll -1.044076
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.271220e+05
      1       7.166941e+05      -2.104279e+05 |       32
      2       6.902415e+05      -2.645263e+04 |       32
      3       6.770353e+05      -1.320624e+04 |       32
      4       6.671791e+05      -9.856125e+03 |       32
      5       6.604290e+05      -6.750108e+03 |       32
      6       6.561690e+05      -4.260025e+03 |       32
      7       6.530166e+05      -3.152450e+03 |       32
      8       6.502884e+05      -2.728114e+03 |       32
      9       6.473410e+05      -2.947440e+03 |       32
     10       6.444832e+05      -2.857813e+03 |       32
     11       6.425535e+05      -1.929735e+03 |       32
     12       6.415467e+05      -1.006753e+03 |       32
     13       6.408945e+05      -6.521577e+02 |       32
     14       6.403966e+05      -4.979718e+02 |       32
     15       6.399773e+05      -4.192775e+02 |       32
     16       6.396851e+05      -2.922384e+02 |       32
     17       6.394305e+05      -2.545291e+02 |       32
     18       6.389371e+05      -4.934067e+02 |       32
     19       6.379421e+05      -9.950250e+02 |       32
     20       6.366123e+05      -1.329820e+03 |       32
     21       6.356751e+05      -9.371903e+02 |       32
     22       6.354007e+05      -2.744349e+02 |       32
     23       6.353215e+05      -7.919842e+01 |       31
     24       6.352962e+05      -2.525934e+01 |       32
     25       6.352850e+05      -1.121240e+01 |       31
     26       6.352763e+05      -8.671790e+00 |       30
     27       6.352680e+05      -8.268387e+00 |       29
     28       6.352602e+05      -7.811020e+00 |       26
     29       6.352539e+05      -6.377464e+00 |       26
     30       6.352471e+05      -6.709440e+00 |       26
     31       6.352407e+05      -6.396430e+00 |       27
     32       6.352334e+05      -7.365612e+00 |       25
     33       6.352255e+05      -7.878759e+00 |       23
     34       6.352169e+05      -8.555617e+00 |       28
     35       6.352113e+05      -5.633905e+00 |       24
     36       6.352080e+05      -3.351555e+00 |       25
     37       6.352031e+05      -4.833881e+00 |       24
     38       6.351992e+05      -3.959711e+00 |       23
     39       6.351942e+05      -4.930072e+00 |       26
     40       6.351886e+05      -5.636924e+00 |       21
     41       6.351831e+05      -5.508866e+00 |       22
     42       6.351784e+05      -4.681421e+00 |       17
     43       6.351748e+05      -3.567039e+00 |       20
     44       6.351717e+05      -3.161058e+00 |       23
     45       6.351677e+05      -3.976739e+00 |       24
     46       6.351607e+05      -6.976242e+00 |       29
     47       6.351525e+05      -8.209365e+00 |       24
     48       6.351445e+05      -8.004008e+00 |       30
     49       6.351351e+05      -9.409389e+00 |       28
     50       6.351263e+05      -8.764649e+00 |       25
K-means terminated without convergence after 50 iterations (objv = 635126.3419703309)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.340517
[ Info: iteration 2, average log likelihood -1.307998
[ Info: iteration 3, average log likelihood -1.276263
[ Info: iteration 4, average log likelihood -1.239687
[ Info: iteration 5, average log likelihood -1.194264
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     22
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.140262
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.144463
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.106788
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     13
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.091168
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     10
│     12
│     17
│     22
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.094938
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.115271
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     21
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.105133
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.100453
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     10
│     12
│     13
│     17
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.071322
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.138527
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.113874
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      8
│      9
│     21
│     24
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.063298
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     10
│     17
│     22
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.104189
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.148538
[ Info: iteration 20, average log likelihood -1.109038
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│      9
│     14
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.047454
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      4
│     17
│     21
│     22
│     24
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.104372
[ Info: iteration 23, average log likelihood -1.154920
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     10
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.093558
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     14
│     21
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.103171
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     17
│     22
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.082021
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     13
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.096689
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      9
│     10
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.096601
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     21
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.092764
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     12
│     14
│     22
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.087199
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.121406
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      9
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.086044
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     10
│     17
│     21
│     24
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.074221
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     14
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.105728
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     12
│     13
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.118342
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.110802
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     10
│     24
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.060686
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      9
│     17
│     21
│     22
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.078409
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.133857
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.119889
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.070471
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      4
│      9
│     10
│      ⋮
│     25
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.050734
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.142557
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.131329
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.093790
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      9
│     10
│     12
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.065737
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     13
│     17
│     25
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.093864
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.134177
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.106979
32×26 Array{Float64,2}:
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.077666
┌ Info: EM with 100000 data points 50 iterations avll -1.077666
└ 59.0 data points per parameter
 -0.0690559    0.048038    -0.0893466   0.210285    -0.173115     0.157231     0.0105674   0.0688352   0.0287724    0.0212582    -0.111047    0.458444    -0.0771979   -0.0779312  -0.0592087    -0.0194592   -0.0866341   -0.118202     0.100783    -0.0445098   -0.108424   -0.0809371     0.0833502  -0.0128589   -0.130121    0.0783742
 -0.0759348   -0.00697773   0.104728    0.0209962   -0.0208285   -0.0260526   -0.0749179   0.0129595  -0.0707387   -0.0596394    -0.180706   -0.0635907    0.140298    -0.057861   -0.0327798    -0.0363724   -0.0760344   -0.0221011    0.174439    -0.0529313    0.0188473   0.103591     -0.0659769   0.0286258   -0.0636546   0.0206032
  0.0114001    0.0968287    0.18612     0.0670871    0.0488649    0.0280439   -0.0159502  -0.0181142   0.0353893    0.13116      -0.0508015   0.263815    -0.119171     0.0232456   0.0596657     0.238404    -0.304209     0.016684     0.01103      0.0663101    0.123781   -0.109785      0.0989443  -0.138013     0.0645448  -0.0319139
  0.236529     0.183734     0.0242996   0.00414566  -0.00734824   0.172258     0.0209746   0.0964629  -0.00666309  -0.116042     -0.14585     0.114595    -0.0851884   -0.133017   -0.150884     -0.0683448    0.0440099   -0.143497     0.0653428    0.128501    -0.0424302   0.092751     -0.0823648  -0.0413331    0.018198   -0.0107215
 -0.1876       0.0120746    0.0950985  -0.00952546  -0.0589915    0.030489     0.0979826  -0.0826375   0.0581695   -0.187795      0.176592    0.00983092  -0.00569528  -0.139255   -0.000615847  -0.0591092    0.0286227    0.156273     0.0680993    0.0244718    0.127112    0.0287472    -0.0887003   0.0654163    0.0851648  -0.158279
  0.0299084   -0.165695     0.160084   -0.0558705    0.00279527  -0.131449     0.148243    0.112574    0.0664361   -0.0400548     0.183569    0.016343    -0.0998883   -0.0675151  -0.0906537    -0.0636456   -0.0600671   -0.0249579   -0.112424     0.100284     0.109427   -0.00607731    0.0805946   0.00907191   0.0247673   0.0251438
  0.086209     0.0399719   -0.0796081   0.203426     0.204813    -0.0492837    0.0237582  -0.0784026  -0.103598    -0.00121218    0.0282361  -0.0742625   -0.189154     0.0567728  -0.0260894     0.0257885    0.0223392    0.0226356    0.145335    -0.0827173    0.0029393  -0.112954      0.221818   -0.112439    -0.104172   -0.070015
 -0.0838597    0.0171041   -0.105748    0.0126318   -0.11445     -0.129086     0.0583015  -0.0103988   0.114151     0.0496482     0.0387581  -0.0278002   -0.0458957   -0.0246325  -0.030204      0.0281624   -0.209529    -0.079373    -0.0109881    0.321557    -0.165715   -0.0645759     0.124195   -0.0954129   -0.0702548   0.171479
  0.050138    -0.0843958    0.116567   -0.0797775    0.0943348    0.020642    -0.0284238   0.121669   -0.139754    -0.114315     -0.0379978  -0.0158381   -0.04718      0.0446024  -0.137318     -0.145435     0.195832    -0.0379851    0.0897095    0.0742747   -0.0791405  -0.146999     -0.119756   -0.175408     0.0961781  -0.209455
  0.0202868   -0.0828791   -0.105617    0.15315     -0.110065     0.0327736    0.0434579   0.0401044   0.0164937   -0.0801728     0.0463154  -0.129063    -0.0850783   -0.0348046   0.0915614    -0.156211    -0.00502425   0.0062529    0.101948     0.0578492   -0.123119   -0.00229413    0.185881   -0.0474783   -0.150466   -0.0743877
 -0.13354      0.0783776   -0.210998    0.178968    -0.174114     0.0259363   -0.0329348   0.110252    0.102094    -0.0281053    -0.141999   -1.22019     -0.0794859   -0.20765    -0.0977921    -0.136076    -0.0731705   -0.0503274   -0.068122    -0.00954896   0.0158074  -0.0995743     0.0671184  -0.0585408   -0.136099    0.0716336
 -0.0457486   -0.0640587   -0.140963    0.0673114   -0.025773    -0.0585967   -0.0741216   0.0518723   0.0448208    0.0571133    -0.0111742   0.131126     0.0819815   -0.0731552  -0.0259641    -0.0100104   -0.0337663   -0.121965     0.0360986    0.129344    -0.104109   -0.178811      0.0341693  -0.0102036    0.0971392  -0.0736322
 -0.0335905   -0.141637     0.170806   -0.0266389   -0.0644097   -0.0857078   -0.0823453  -0.218266   -0.183256    -0.0509836     0.0751973  -0.0991139   -0.0207357    0.174658   -0.219486      0.0695648   -0.0358155   -0.0625996    0.102778     0.00707074  -0.0829291   0.0869571    -0.134969   -0.0472673   -0.0361628   0.157301
 -0.0218625    0.0263231   -0.0060517   0.106548     0.0428838    0.0768264   -0.0732606   0.0216411  -0.0374218   -0.150208      0.0996588  -0.225106     0.124398     0.092234    0.114368      0.0227963   -0.0515738    0.106762    -0.018803    -0.319658     0.0558088   0.0694346    -0.0368406   0.225696     0.154471    0.0197678
 -0.0219472    0.0407282   -0.0175158  -0.0408328    0.0766356    0.14464     -0.0608048  -0.0269379   0.0608795    0.153063     -0.0677378   0.193177     0.0424831   -0.0971274   0.080548      0.0216815    0.0406541   -0.106508     0.00181797   0.123714     0.0526186   0.00300337    0.0525183   0.0357933    0.11247     0.00444373
  0.068147     0.0661948    0.236129   -0.0509726    0.149023     0.114016     0.0172102   0.120644   -0.0400716    0.000525272  -0.0821448   0.166593     0.0899412   -0.0875835  -0.0691424    -0.0658407   -0.0281307    0.254003     0.0384354   -0.159256    -0.132148    0.0703477     0.078638   -0.00915212  -0.133004    0.125197
 -0.0177004   -0.0427237    0.066552   -0.00494608  -0.0115256   -0.0456973    0.069348    0.033918   -0.135618     0.156677      0.106191   -0.0517289    0.07843      0.172153    0.109633     -0.16624      0.348648     0.135855     0.0429343    0.0370502    0.0997596  -0.0812596     0.0613577   0.00636368   0.169461   -0.0487987
 -0.0789131    0.0535645    0.0741219   0.033135    -0.0384695    0.156634    -0.0537897   0.0677379   0.0368944   -0.0317269     0.122866   -0.0372791   -0.0668829    0.245555   -0.101393     -0.0676859    0.121178     0.0829031    0.0060641    0.0839511    0.108739    0.122581      0.0124263  -0.0292881    0.104368    0.192912
 -0.00892078  -0.026395    -0.0754728   0.197646    -0.0469386   -0.149965    -0.0373351   0.092942   -0.133138    -0.0149893     0.0428144   0.00299782   0.0859804    0.0904639  -0.187542      0.0630779   -0.134257     0.0687387    0.150612    -0.148583    -0.0896864   0.135586     -0.183008   -0.0328228    0.0459274   0.13337
  0.00793723  -0.225443     0.0372772   0.107966    -0.0546862    0.0430958   -0.183254   -0.0222593  -0.0708673   -0.109459     -0.048284    0.0650111   -0.0621351   -0.135715   -0.153004     -0.0663367    0.168315     0.0756107    0.131505    -0.0508099    0.0530762  -0.0448191     0.113243   -0.0382379   -0.040819    0.127971
 -0.0420411    0.0995384   -0.116191   -0.0992878    0.102928    -0.0927662   -0.124628   -0.0488896   0.135817    -0.135911      0.082398   -0.0199337   -0.0157927    0.0775067   0.204994      0.163587     0.0716107   -0.0306073   -0.0549047    0.119335     0.0172005   0.0464735    -0.0339881   0.0847415   -0.12361    -0.176141
 -0.0629575   -0.0781942   -0.237292    0.145655     0.013437     0.101053    -0.0590379   0.0359799  -0.0715385    0.0450887    -0.0784273  -0.0479094   -0.0141194    0.102737    0.112292      0.112693     0.138244     0.00474414  -0.0451702   -0.140777     0.0785138   0.0531249    -0.0108861  -0.0209153   -0.267009    0.0602788
 -0.0991241    0.0648742   -0.0152886  -0.0551164   -0.0359224   -0.055688    -0.128938   -0.0648817  -0.00440009   0.0640653     0.0157903  -0.00945093   0.0505022    0.102086    0.0863051    -0.0754536    0.0309779   -0.00121906   0.0606398    0.102224     0.0470743   0.0394119     0.0326282  -0.20344     -0.140718   -0.00884265
 -0.00412268   0.0537602    0.0725604   0.0545063   -0.0114316   -0.0139254   -0.124607   -0.0838687  -0.0717019    0.00606683    0.0803367   0.271828    -0.182358    -0.0135009   0.185824     -0.032267    -0.299545     0.0596762   -0.0927876    0.104177     0.0949954  -0.0841787     0.149935   -0.030555    -0.130395    0.070659
 -0.0774361    0.031658    -0.130961   -0.152326     0.0493834   -0.00916158  -0.134272    0.163185    0.0726326   -0.0220398    -0.172777    0.0022611    0.0659144   -0.0956731  -0.163044     -0.0491234    0.0336266    0.157622    -0.0695339   -0.050192     0.0861537   0.0226502     0.100433    0.0231816    0.0142103   0.182333
  0.130085    -0.0244656    0.104736    0.0153593   -0.0185484   -0.0445588    0.181283    0.0797165   0.0171719   -0.172685     -0.0112729   0.101492    -0.00634641   0.0110374  -0.0897108     0.1319       0.0852848   -0.16829     -0.0228148   -0.0322112    0.0829145  -0.0777021     0.167006   -0.123019    -0.10024    -0.0486273
 -0.113132     0.0482824    0.173037    0.00489323   0.231495     0.0949684   -0.144574   -0.0338572  -0.0782125   -0.054327     -0.0467682  -0.071487     0.120899    -0.101812   -0.182924     -0.0327673    0.317523    -0.138988     0.0666286   -0.0246305   -0.114322   -0.016645      0.0721816   0.0371906    0.0786465   0.315386
 -0.172902    -0.0459878    0.0233251  -0.114908    -0.0550109    0.0369652   -0.119608    0.0891967   0.0860962   -0.092913     -0.108679   -0.329564    -0.156281     0.0665293   0.102445      0.00312465  -0.00733356   0.0143579    0.0137247    0.156903    -0.0387832   0.0586449    -0.115946    0.00057235   0.12864    -0.25383
 -0.105149     0.0300402   -0.131286   -0.117077    -0.176427    -0.134746     0.031294    0.0304981  -0.003535    -0.0603967     0.0660119   0.13498      0.078295     0.139985    0.0826845     0.135452     0.0359748   -0.0258661    0.107057    -0.119324    -0.175196   -0.0808465    -0.179458   -0.0598688   -0.0633715  -0.245698
 -0.0578321    0.0821859   -0.0367122  -0.0328259[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
   -0.0407819   -0.0175853   -0.210178    0.169234   -0.105303     0.0310205    -0.0765849  -0.176117    -0.0143249    0.0338573  -0.0241939    -0.0276382   -0.0169455   -0.143467     0.0145985   -0.0226344   -0.0644646  -0.0311325    -0.0703801  -0.102251    -0.0138963  -0.0840674
 -0.0456529   -0.00848621   0.0615718   0.0286287   -0.156201     0.00480888  -0.127355    0.0561804  -0.0396441   -0.080345     -0.132286   -0.0638358    0.00976163  -0.078437   -0.102348     -0.0502901   -0.00947749  -0.0617039    0.0212192    0.0799713    0.0429941   0.000202907   0.0700503   0.0499055   -0.17801     0.172275
 -0.11336      0.167923    -0.0388606  -0.126348    -0.0282119   -0.0226107   -0.0234132   0.0578319   0.177561     0.0387409    -0.148251   -0.0427088   -0.08637      0.0943516  -0.0575328    -0.180352     0.146574    -0.00812761   0.0175491    0.0298476    0.0483347   0.00692611   -0.0599714   0.0713071    0.0322731  -0.202519┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     12
│     13
│     17
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.085819
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      4
│      8
│     12
│      ⋮
│     26
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.037283
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      9
│     10
│     12
│      ⋮
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.026634
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      4
│      8
│     12
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.057707
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     12
│     13
│     17
│     25
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.046626
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      2
│      4
│      8
│      9
│      ⋮
│     27
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.007395
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     12
│     13
│     17
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.085230
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      4
│      8
│     12
│      ⋮
│     26
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.037651
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      9
│     10
│     12
│      ⋮
│     26
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.026932
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      4
│      8
│     12
│      ⋮
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.057660
┌ Info: EM with 100000 data points 10 iterations avll -1.057660
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0279642    0.129078    -0.00879971  -0.173777     0.0225477    0.0158897    0.071523     0.0803691    0.0400995   -0.0407005     0.025336     -0.0405049    0.0114661     0.0213041  -0.00643258   0.113773      0.0281014    0.00827564  -0.0208898  -0.132212     0.0942893    0.0236397   -0.0561917     0.0810766    0.0759802   -0.0534565
 -0.0288465    0.11553     -0.0537994    0.0302986    0.102879     0.261673    -0.0536095   -0.00591485   0.0583503    0.0139685     0.141221      0.00412564   0.0429895    -0.0271864   0.0357703   -0.11899      -0.0438627   -0.0732066   -0.0805969   0.0321344   -0.0905424    0.0735551   -0.0586351    -0.0904051    0.0966846    0.00134624
  0.00888449   0.0757561    0.0427707    0.203273     0.0215652    0.136735    -0.108839     0.0759455   -0.0465052    0.128768     -0.11845       0.0533026   -0.141323      0.0911006   0.0148057    0.202635     -0.0902511   -0.112961    -0.0416456   0.184136     0.119896    -0.0233401    0.0642825     0.0576973    0.141462    -0.0666639
 -0.181971    -0.0381407    0.282376    -0.144656     0.0870128    0.0553754   -0.0937433    0.164337    -0.21794      0.0791639     0.0470205     0.0368915   -0.121797     -0.0386413  -0.0435262   -0.132754      0.0199957    0.0162688    0.170601   -0.126296    -0.0275077    0.198095    -0.0113254     0.0203714    0.0251778    0.0732364
 -0.102981    -0.0112396    0.0243395    0.160632    -0.136325     0.00598512  -0.0203369    0.0892748   -0.136614    -0.0238551    -0.0268501     0.0443385    0.0505513    -0.010342   -0.170375     0.000391349  -0.0947564    0.00957896  -0.0307052  -0.0427594   -0.114885     0.0447333   -0.230759     -0.0839408   -0.0295238   -0.0661882
  0.0907399    0.14003     -0.171823    -0.128102     0.0428896   -0.136455    -0.00388094  -0.00476293  -0.0740228   -0.048909      0.0725623    -0.0356153   -0.00274079    0.0413469  -0.0522563   -0.00369077   -0.055669     0.00735149   0.0557991   0.0205187    0.0317296   -0.0156341   -0.00109509    0.0767546    0.0828921    0.0157896
  0.0293931    0.179678    -0.119315     0.102503     0.125965     0.0379739   -0.0717588   -0.009657    -0.00779816  -0.0643621    -0.0664662     0.0262868   -0.0333069     0.0504862  -0.0843595   -0.108011     -0.134243    -0.0880411    0.041069   -0.0506595    0.120906     0.145875     0.00532511   -0.119328     0.128701     0.176298
  0.194064     0.0186198    0.0588685   -0.163878     0.109331     0.114677    -0.211819    -0.198323    -0.0285274    0.000612962  -0.165162     -0.210337     0.195065     -0.0463121   0.103878    -0.146558      0.00772611   0.0250191    0.094605   -0.0606547    0.107168    -0.0805466    0.186966      0.130115    -0.0228994   -0.0172661
  0.0723259   -0.148419     0.00853799  -0.0277225    0.0795759    0.14883      0.0125531    0.0735902   -0.0167519    0.00563118    0.20602       0.0837693   -0.000954505  -0.231673    0.100732    -0.19563      -0.114378     0.0579448   -0.0629191   0.119413     0.0834838    0.0737371    0.0665181    -0.20422      0.06357      0.0913578
  0.0453628    0.184683    -0.0974418   -0.0113453    0.132922    -0.158715    -0.0409093    0.130136    -0.0796743   -0.157943      0.018667     -0.0988531    0.108751      0.0413384   0.0172531    0.122787      0.0403102    0.0540545   -0.0275536  -0.178825    -0.0713765   -0.0858482    0.0493697     0.0423209   -0.0333673   -0.24599
 -0.00453047  -0.00151151  -0.00778853  -0.0453891    0.0288586   -0.110219     0.0939682   -0.0195962   -0.0197157   -0.00216995    0.0162071     0.152514     0.113144      0.0242629  -0.0235379   -0.0483447     0.0333268   -0.072316     0.12969     0.0882076   -0.14636     -0.0243435    0.00136362    0.00887433   0.256993     0.0777813
  0.00937235   0.0917165    0.0400921   -0.0596241    0.0540959   -0.0132419   -0.215609    -0.0940867    0.0144915   -0.0251485    -0.00478911   -0.0642954   -0.0085539     0.0185324  -0.0650236   -0.0388321     0.153078    -0.067676     0.119504   -0.0977192   -0.00419031   0.0268011    0.0854355     0.105731    -0.095965     0.0880976
 -0.108473    -0.0893677    0.0771783   -0.0004425    0.0585528   -0.132518    -0.026763     0.160902     0.0716261   -0.0318923     0.0324083    -0.102103     0.143184      0.0686064  -0.126421    -0.117129      0.111391     0.0476796   -0.0823761  -0.109168    -0.0464633   -0.171137    -0.013874     -0.0789613    0.0275223   -0.0368267
  0.0926751   -0.0131226   -0.0162959   -0.0392224    0.00456521   0.131372     0.159962     0.133014     0.0573204   -0.0839535     0.0150194    -0.105838    -0.00832217   -0.123517   -0.0317533   -0.0624159    -0.159794     0.105219    -0.0643924   0.0449238    0.0860535    0.0180837   -0.0102305    -0.0483589   -0.0559208   -0.0466967
  0.086029     0.00530638  -0.00793685   0.044769    -0.191562     0.156987    -0.00997145   0.0381369    0.0228633    0.0146979     0.0636155    -0.0543757   -0.00740569    0.137587    0.00647077   0.146398      0.117687    -0.101661     0.122407   -0.00643014   0.117173     0.104234     0.170676     -0.214926     0.0475171    0.0730441
  0.0209305   -0.0321005   -0.0417847    0.0237731   -0.0836972    0.0151307   -0.0214393    0.0166753   -0.0258339    0.113218     -0.00749543    0.0595421   -0.149824      0.134461    0.0861784    0.0382643     0.00128114  -0.0674154    0.0472852  -0.0641173   -0.1916       0.0613733    0.0342082    -0.00250557   0.00200065   0.0453415
  0.170342     0.151578     0.172013    -0.128798    -0.00490782   0.10952     -0.170156     0.0584689    0.199049     0.221646      0.00903358   -0.0510634    0.0412972    -0.123219   -0.0276046   -0.0147013     0.122391    -0.0783298    0.0872595  -0.0360432   -0.0403654    0.00986017   0.0362122    -0.00668664   0.0014766   -0.217413
  0.00279677   0.117818    -0.0934894    0.00502195  -0.130683    -0.014041    -0.144905     0.0588838   -0.116623     0.0396565     0.0393706    -0.0821493    0.0425935    -0.0360043   0.101841     0.0855237    -0.150139    -0.121548    -0.117065    0.069837     0.145942    -0.135514     0.11852      -0.00612864  -0.00403239   0.0278449
  0.0183244    0.0507331   -0.112329     0.0485871    0.185262    -0.113465     0.10087     -0.0549333    0.101945    -0.112834     -0.0854862     0.102693     0.00283403    0.0401534  -0.109115    -0.0151716    -0.161357     0.0115052   -0.287439    0.0522072    0.173669    -0.103054     0.0325966    -0.246878    -0.0188047   -0.0480981
 -0.067719    -0.0150511    0.12846      0.061955    -0.0076346   -0.0130986    0.0661992   -0.0465508   -0.0915819   -0.0297868    -0.0787751     0.00832645   0.00235877    0.0600004   0.0178709   -0.219661      0.117971     0.0962918    0.0426272   0.0549279    0.0748297   -0.0183954   -0.131871     -0.112604    -0.0142324    0.105527
 -0.0540105   -0.22341     -0.0959012    0.0475256   -0.0610007    0.0436937    0.0277602   -0.0714473    0.0980405    0.0207621     0.0164796    -0.0224021   -0.011057      0.241307    0.0260166    0.0703722    -0.0390487    0.124982     0.0945252  -0.00934064   0.0629218    0.0908943   -0.00732863   -0.164403    -0.141094     0.0680793
  0.0887606   -0.132359     0.0353049   -0.0831761    0.0763304    0.115552    -0.00107017  -0.00849209   0.164339    -0.11744      -0.00444802   -0.0774513    0.070474     -0.263506    0.0131661    0.111652     -0.0120336    0.105482    -0.192617    0.069419     0.0327809    0.0282996   -0.139587     -0.0353709    0.294876     0.123274
  0.0338256   -0.101059     0.0986285    0.0167496    0.105412     0.0471103   -0.165208     0.00972888   0.13606     -0.0190562     0.0180617    -0.0753967   -0.0148675    -0.135634    0.0825567    0.123457      0.0499402   -0.227979    -0.138756   -0.0828899   -0.0184543    0.0562194   -0.130306      0.0588803    0.00119066   0.0501701
 -0.07803      0.0703068    0.0610378   -0.0795441   -0.191338    -0.0603616   -0.0550143    0.321588     0.130685    -0.0641739     0.044905     -0.102085    -0.0263032    -0.0706776  -0.118488     0.119749      0.238454     0.0510312   -0.04411    -0.105163    -0.0339893   -0.00372444  -0.226751      0.0166021    0.0235136   -0.0364198
  0.0841506   -0.0485561    0.12439      0.0846636   -0.0309907   -0.035324    -0.147118     0.0513991    0.0593767   -0.02814       0.0992283    -0.0223415   -0.0632908    -0.0434282   0.0160664   -0.0475777     0.0111684   -0.116383     0.0289556   0.131261    -0.212515    -0.065634    -0.0115119    -0.0503406    0.0441431    0.0376155
 -0.0947192   -0.116433    -0.111758    -0.0227854   -0.18741      0.133797    -0.175121    -0.0226866   -0.0339305   -0.0284658     0.0278564    -0.0187713   -0.0766893    -0.198963   -0.167544     0.116919      0.0552612   -0.201032     0.0120552   0.0122805   -0.0590833   -0.121032     0.244191     -0.338611     0.00437854  -0.00179178
 -0.0210013   -0.0251849    0.0835119   -0.0281927   -0.0256157   -0.0327285    0.227815     0.0772081   -0.0755375   -0.0795632     0.000634632  -0.0520532    0.0442008    -0.168868    0.0533959    0.0686294    -0.270727    -0.112682    -0.0790713   0.152418     0.0658752   -0.0876213    0.000593222   0.0094114   -0.00875819   0.00612148
  0.169633     0.0456339   -0.275815    -0.190506     0.124278    -0.122264     0.0174673    0.102402     0.104806    -0.218728     -0.233704      0.0272707   -0.0844099     0.227809    0.0560099   -0.0624174     0.0194532    0.0421014   -0.10337     0.0936876   -0.057837    -0.158417     0.053383     -0.0227406    0.115489    -0.0807345
 -0.313734    -0.0610128    0.0662436   -0.077878     0.142541    -0.132553    -0.0291273   -0.122732     0.0761737    0.138952      0.179567     -0.0514556    0.0927766    -0.021934   -0.0995378   -0.0264495     0.00908652   0.131274    -0.0324613   0.0423601    0.0268415    0.00745081   0.0616446     0.0432168    0.176614     0.119324
 -0.163434     0.0267094    0.0467013    0.0300368   -0.0794746    0.153851     0.0300886   -0.0242945    0.0590829   -0.0288217     0.0406992     0.00678286  -0.0606631     0.085679    0.0868315   -0.0108485     0.0848338   -0.0388033    0.0468164  -0.0219461    0.0949304    0.0678321    0.0497788    -0.212192     0.175481     0.0479007
  0.0203199    0.159419    -0.0491653   -0.10567      0.0103583    0.194721     0.128712     0.0361739    0.100897     0.0789385     0.173225      0.16037      0.27837      -0.0930707  -0.0739401    0.069833     -0.137664     0.0897086    0.215738   -0.0277106    0.00398471  -0.0733334   -0.130897     -0.0655361   -0.302126    -0.0278289
 -0.0537285   -0.0756888   -0.0320421   -0.0584302   -0.0442169   -0.118026     0.0155318   -0.0623241    0.199257     0.0031404     0.0541697     0.0101661    0.0340243    -0.119621    0.00407067   0.0480407    -0.158334    -0.097202     0.0497678   0.00938673   0.0136205   -0.102652     0.0967803    -0.0340445    0.219638     0.14568kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4172591530122605
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417279
[ Info: iteration 2, average log likelihood -1.417179
[ Info: iteration 3, average log likelihood -1.417089
[ Info: iteration 4, average log likelihood -1.416978
[ Info: iteration 5, average log likelihood -1.416842
[ Info: iteration 6, average log likelihood -1.416688
[ Info: iteration 7, average log likelihood -1.416531
[ Info: iteration 8, average log likelihood -1.416375
[ Info: iteration 9, average log likelihood -1.416198
[ Info: iteration 10, average log likelihood -1.415951
[ Info: iteration 11, average log likelihood -1.415557
[ Info: iteration 12, average log likelihood -1.414948
[ Info: iteration 13, average log likelihood -1.414126
[ Info: iteration 14, average log likelihood -1.413257
[ Info: iteration 15, average log likelihood -1.412581
[ Info: iteration 16, average log likelihood -1.412188
[ Info: iteration 17, average log likelihood -1.411999
[ Info: iteration 18, average log likelihood -1.411916
[ Info: iteration 19, average log likelihood -1.411880
[ Info: iteration 20, average log likelihood -1.411865
[ Info: iteration 21, average log likelihood -1.411858
[ Info: iteration 22, average log likelihood -1.411855
[ Info: iteration 23, average log likelihood -1.411854
[ Info: iteration 24, average log likelihood -1.411854
[ Info: iteration 25, average log likelihood -1.411853
[ Info: iteration 26, average log likelihood -1.411853
[ Info: iteration 27, average log likelihood -1.411853
[ Info: iteration 28, average log likelihood -1.411853
[ Info: iteration 29, average log likelihood -1.411853
[ Info: iteration 30, average log likelihood -1.411853
[ Info: iteration 31, average log likelihood -1.411853
[ Info: iteration 32, average log likelihood -1.411853
[ Info: iteration 33, average log likelihood -1.411852
[ Info: iteration 34, average log likelihood -1.411852
[ Info: iteration 35, average log likelihood -1.411852
[ Info: iteration 36, average log likelihood -1.411852
[ Info: iteration 37, average log likelihood -1.411852
[ Info: iteration 38, average log likelihood -1.411852
[ Info: iteration 39, average log likelihood -1.411852
[ Info: iteration 40, average log likelihood -1.411852
[ Info: iteration 41, average log likelihood -1.411852
[ Info: iteration 42, average log likelihood -1.411852
[ Info: iteration 43, average log likelihood -1.411852
[ Info: iteration 44, average log likelihood -1.411852
[ Info: iteration 45, average log likelihood -1.411852
[ Info: iteration 46, average log likelihood -1.411852
[ Info: iteration 47, average log likelihood -1.411852
[ Info: iteration 48, average log likelihood -1.411852
[ Info: iteration 49, average log likelihood -1.411852
[ Info: iteration 50, average log likelihood -1.411852
┌ Info: EM with 100000 data points 50 iterations avll -1.411852
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4172786303506695
│     -1.4171787565101182
│      ⋮
└     -1.4118520960822647
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411871
[ Info: iteration 2, average log likelihood -1.411769
[ Info: iteration 3, average log likelihood -1.411676
[ Info: iteration 4, average log likelihood -1.411560
[ Info: iteration 5, average log likelihood -1.411420
[ Info: iteration 6, average log likelihood -1.411273
[ Info: iteration 7, average log likelihood -1.411140
[ Info: iteration 8, average log likelihood -1.411038
[ Info: iteration 9, average log likelihood -1.410968
[ Info: iteration 10, average log likelihood -1.410922
[ Info: iteration 11, average log likelihood -1.410892
[ Info: iteration 12, average log likelihood -1.410871
[ Info: iteration 13, average log likelihood -1.410856
[ Info: iteration 14, average log likelihood -1.410844
[ Info: iteration 15, average log likelihood -1.410834
[ Info: iteration 16, average log likelihood -1.410825
[ Info: iteration 17, average log likelihood -1.410818
[ Info: iteration 18, average log likelihood -1.410811
[ Info: iteration 19, average log likelihood -1.410805
[ Info: iteration 20, average log likelihood -1.410799
[ Info: iteration 21, average log likelihood -1.410793
[ Info: iteration 22, average log likelihood -1.410787
[ Info: iteration 23, average log likelihood -1.410781
[ Info: iteration 24, average log likelihood -1.410776
[ Info: iteration 25, average log likelihood -1.410770
[ Info: iteration 26, average log likelihood -1.410764
[ Info: iteration 27, average log likelihood -1.410759
[ Info: iteration 28, average log likelihood -1.410753
[ Info: iteration 29, average log likelihood -1.410748
[ Info: iteration 30, average log likelihood -1.410743
[ Info: iteration 31, average log likelihood -1.410738
[ Info: iteration 32, average log likelihood -1.410734
[ Info: iteration 33, average log likelihood -1.410729
[ Info: iteration 34, average log likelihood -1.410725
[ Info: iteration 35, average log likelihood -1.410721
[ Info: iteration 36, average log likelihood -1.410718
[ Info: iteration 37, average log likelihood -1.410715
[ Info: iteration 38, average log likelihood -1.410711
[ Info: iteration 39, average log likelihood -1.410709
[ Info: iteration 40, average log likelihood -1.410706
[ Info: iteration 41, average log likelihood -1.410703
[ Info: iteration 42, average log likelihood -1.410701
[ Info: iteration 43, average log likelihood -1.410699
[ Info: iteration 44, average log likelihood -1.410697
[ Info: iteration 45, average log likelihood -1.410695
[ Info: iteration 46, average log likelihood -1.410693
[ Info: iteration 47, average log likelihood -1.410691
[ Info: iteration 48, average log likelihood -1.410690
[ Info: iteration 49, average log likelihood -1.410688
[ Info: iteration 50, average log likelihood -1.410687
┌ Info: EM with 100000 data points 50 iterations avll -1.410687
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4118713088255845
│     -1.4117687463154978
│      ⋮
└     -1.4106868267792885
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410695
[ Info: iteration 2, average log likelihood -1.410631
[ Info: iteration 3, average log likelihood -1.410572
[ Info: iteration 4, average log likelihood -1.410502
[ Info: iteration 5, average log likelihood -1.410413
[ Info: iteration 6, average log likelihood -1.410301
[ Info: iteration 7, average log likelihood -1.410168
[ Info: iteration 8, average log likelihood -1.410021
[ Info: iteration 9, average log likelihood -1.409873
[ Info: iteration 10, average log likelihood -1.409733
[ Info: iteration 11, average log likelihood -1.409609
[ Info: iteration 12, average log likelihood -1.409505
[ Info: iteration 13, average log likelihood -1.409420
[ Info: iteration 14, average log likelihood -1.409353
[ Info: iteration 15, average log likelihood -1.409301
[ Info: iteration 16, average log likelihood -1.409261
[ Info: iteration 17, average log likelihood -1.409230
[ Info: iteration 18, average log likelihood -1.409205
[ Info: iteration 19, average log likelihood -1.409185
[ Info: iteration 20, average log likelihood -1.409168
[ Info: iteration 21, average log likelihood -1.409154
[ Info: iteration 22, average log likelihood -1.409141
[ Info: iteration 23, average log likelihood -1.409129
[ Info: iteration 24, average log likelihood -1.409119
[ Info: iteration 25, average log likelihood -1.409109
[ Info: iteration 26, average log likelihood -1.409100
[ Info: iteration 27, average log likelihood -1.409092
[ Info: iteration 28, average log likelihood -1.409084
[ Info: iteration 29, average log likelihood -1.409077
[ Info: iteration 30, average log likelihood -1.409070
[ Info: iteration 31, average log likelihood -1.409063
[ Info: iteration 32, average log likelihood -1.409057
[ Info: iteration 33, average log likelihood -1.409051
[ Info: iteration 34, average log likelihood -1.409045
[ Info: iteration 35, average log likelihood -1.409039
[ Info: iteration 36, average log likelihood -1.409034
[ Info: iteration 37, average log likelihood -1.409029
[ Info: iteration 38, average log likelihood -1.409023
[ Info: iteration 39, average log likelihood -1.409018
[ Info: iteration 40, average log likelihood -1.409013
[ Info: iteration 41, average log likelihood -1.409008
[ Info: iteration 42, average log likelihood -1.409003
[ Info: iteration 43, average log likelihood -1.408998
[ Info: iteration 44, average log likelihood -1.408993
[ Info: iteration 45, average log likelihood -1.408988
[ Info: iteration 46, average log likelihood -1.408983
[ Info: iteration 47, average log likelihood -1.408978
[ Info: iteration 48, average log likelihood -1.408973
[ Info: iteration 49, average log likelihood -1.408968
[ Info: iteration 50, average log likelihood -1.408963
┌ Info: EM with 100000 data points 50 iterations avll -1.408963
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4106952303421278
│     -1.41063098316413
│      ⋮
└     -1.4089632902687914
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408967
[ Info: iteration 2, average log likelihood -1.408896
[ Info: iteration 3, average log likelihood -1.408825
[ Info: iteration 4, average log likelihood -1.408737
[ Info: iteration 5, average log likelihood -1.408621
[ Info: iteration 6, average log likelihood -1.408477
[ Info: iteration 7, average log likelihood -1.408309
[ Info: iteration 8, average log likelihood -1.408135
[ Info: iteration 9, average log likelihood -1.407969
[ Info: iteration 10, average log likelihood -1.407823
[ Info: iteration 11, average log likelihood -1.407699
[ Info: iteration 12, average log likelihood -1.407595
[ Info: iteration 13, average log likelihood -1.407505
[ Info: iteration 14, average log likelihood -1.407428
[ Info: iteration 15, average log likelihood -1.407361
[ Info: iteration 16, average log likelihood -1.407301
[ Info: iteration 17, average log likelihood -1.407250
[ Info: iteration 18, average log likelihood -1.407204
[ Info: iteration 19, average log likelihood -1.407165
[ Info: iteration 20, average log likelihood -1.407131
[ Info: iteration 21, average log likelihood -1.407100
[ Info: iteration 22, average log likelihood -1.407074
[ Info: iteration 23, average log likelihood -1.407049
[ Info: iteration 24, average log likelihood -1.407027
[ Info: iteration 25, average log likelihood -1.407007
[ Info: iteration 26, average log likelihood -1.406989
[ Info: iteration 27, average log likelihood -1.406971
[ Info: iteration 28, average log likelihood -1.406955
[ Info: iteration 29, average log likelihood -1.406939
[ Info: iteration 30, average log likelihood -1.406925
[ Info: iteration 31, average log likelihood -1.406911
[ Info: iteration 32, average log likelihood -1.406897
[ Info: iteration 33, average log likelihood -1.406885
[ Info: iteration 34, average log likelihood -1.406872
[ Info: iteration 35, average log likelihood -1.406861
[ Info: iteration 36, average log likelihood -1.406850
[ Info: iteration 37, average log likelihood -1.406839
[ Info: iteration 38, average log likelihood -1.406829
[ Info: iteration 39, average log likelihood -1.406820
[ Info: iteration 40, average log likelihood -1.406810
[ Info: iteration 41, average log likelihood -1.406802
[ Info: iteration 42, average log likelihood -1.406793
[ Info: iteration 43, average log likelihood -1.406785
[ Info: iteration 44, average log likelihood -1.406777
[ Info: iteration 45, average log likelihood -1.406770
[ Info: iteration 46, average log likelihood -1.406763
[ Info: iteration 47, average log likelihood -1.406756
[ Info: iteration 48, average log likelihood -1.406750
[ Info: iteration 49, average log likelihood -1.406744
[ Info: iteration 50, average log likelihood -1.406738
┌ Info: EM with 100000 data points 50 iterations avll -1.406738
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4089665996575054
│     -1.408895577566626
│      ⋮
└     -1.4067376103233868
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406740
[ Info: iteration 2, average log likelihood -1.406677
[ Info: iteration 3, average log likelihood -1.406618
[ Info: iteration 4, average log likelihood -1.406547
[ Info: iteration 5, average log likelihood -1.406458
[ Info: iteration 6, average log likelihood -1.406348
[ Info: iteration 7, average log likelihood -1.406219
[ Info: iteration 8, average log likelihood -1.406074
[ Info: iteration 9, average log likelihood -1.405922
[ Info: iteration 10, average log likelihood -1.405770
[ Info: iteration 11, average log likelihood -1.405625
[ Info: iteration 12, average log likelihood -1.405490
[ Info: iteration 13, average log likelihood -1.405368
[ Info: iteration 14, average log likelihood -1.405259
[ Info: iteration 15, average log likelihood -1.405162
[ Info: iteration 16, average log likelihood -1.405076
[ Info: iteration 17, average log likelihood -1.405000
[ Info: iteration 18, average log likelihood -1.404933
[ Info: iteration 19, average log likelihood -1.404872
[ Info: iteration 20, average log likelihood -1.404816
[ Info: iteration 21, average log likelihood -1.404765
[ Info: iteration 22, average log likelihood -1.404717
[ Info: iteration 23, average log likelihood -1.404673
[ Info: iteration 24, average log likelihood -1.404631
[ Info: iteration 25, average log likelihood -1.404592
[ Info: iteration 26, average log likelihood -1.404555
[ Info: iteration 27, average log likelihood -1.404519
[ Info: iteration 28, average log likelihood -1.404486
[ Info: iteration 29, average log likelihood -1.404454
[ Info: iteration 30, average log likelihood -1.404424
[ Info: iteration 31, average log likelihood -1.404396
[ Info: iteration 32, average log likelihood -1.404369
[ Info: iteration 33, average log likelihood -1.404343
[ Info: iteration 34, average log likelihood -1.404318
[ Info: iteration 35, average log likelihood -1.404295
[ Info: iteration 36, average log likelihood -1.404272
[ Info: iteration 37, average log likelihood -1.404251
[ Info: iteration 38, average log likelihood -1.404230
[ Info: iteration 39, average log likelihood -1.404210
[ Info: iteration 40, average log likelihood -1.404191
[ Info: iteration 41, average log likelihood -1.404173
[ Info: iteration 42, average log likelihood -1.404155
[ Info: iteration 43, average log likelihood -1.404139
[ Info: iteration 44, average log likelihood -1.404123
[ Info: iteration 45, average log likelihood -1.404107
[ Info: iteration 46, average log likelihood -1.404092
[ Info: iteration 47, average log likelihood -1.404078
[ Info: iteration 48, average log likelihood -1.404064
[ Info: iteration 49, average log likelihood -1.404051
[ Info: iteration 50, average log likelihood -1.404038
┌ Info: EM with 100000 data points 50 iterations avll -1.404038
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4067398616334272
│     -1.4066773316304768
│      ⋮
└     -1.404038071624344
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4172591530122605
│     -1.4172786303506695
│     -1.4171787565101182
│     -1.4170893769659734
│      ⋮
│     -1.4040640521549044
│     -1.4040508140834793
└     -1.404038071624344
32×26 Array{Float64,2}:
 -1.1748     -0.229267    0.542218    0.162423    -0.00392263  -0.52053    -0.0868457   -0.65623     -0.233264    -0.275776     -0.725684    -0.25774    -0.119123    -0.124465    0.126584     -0.441994    0.290897    -0.583633     0.450998      0.490967    0.334921     -0.871607    -0.678374   -0.424652    -0.370528    -0.269181
 -0.546126    0.0881097   0.350995   -0.0860902   -0.290128    -0.549152    0.31429     -0.166053    -0.0101553   -0.288511      0.360601     0.148031    0.283769    -0.369934   -0.202973      0.612168   -0.285745     0.573608     0.0755414     0.435681    0.310675     -0.508263    -0.392969   -0.49148     -0.232373    -0.100879
 -0.356281   -0.345527   -0.554297    0.119103    -0.483489    -0.030745   -0.299528     0.763473    -0.0545138    0.171468     -0.298334     0.536882    0.380637    -0.52863     0.174529      0.543455    0.16882     -1.00089      0.418814      0.246114    0.0400032    -0.123118    -0.307435   -0.290363    -0.5485       0.135098
 -0.411266    0.614477   -0.168416    0.475883     0.138956    -0.0703374   0.140121     0.507638     0.935042    -0.0352429     0.0763915    0.154913    0.113312     0.212109   -0.657801      0.310194    0.431849    -0.572935    -0.303886     -0.471524    0.230345      0.304192    -0.307982    0.232962    -0.462192    -0.722914
  0.316461    0.464598   -0.355531    0.111119    -0.440227    -0.33697    -0.26057     -0.220749     0.146202     0.760496      0.435381    -0.456331    0.334269     0.177225   -0.130936      0.556472   -0.0901465   -0.111298    -0.0828966    -0.412225    0.200605      0.0261878    0.694038    0.378978     0.164355    -0.0384223
  0.29518     0.0729897   0.337639    0.190161     0.0902145   -0.538951   -0.480843    -0.134971     0.323019     0.354564     -0.0329173   -0.203746   -0.226479     0.320067   -0.129592     -0.21374     0.21107     -0.15094      0.130011      0.210966    0.218647     -0.307078    -0.116902    0.618937    -0.21602     -0.223099
  0.755279    0.476667    0.165553    0.0127324    0.117129     0.8248     -0.282171    -0.368026    -0.00907798  -0.288279     -0.200488    -0.249335    0.210765     0.669339   -0.109101      0.589781   -0.0631023    0.407076     0.164557     -0.109154    0.0305051     0.859878    -0.0949092   0.00499682  -0.278609     0.0150418
  0.386005    0.162128   -0.198773   -0.180835     0.681079     0.423626    0.21501     -0.900126     0.382778     0.00449306    0.17298     -0.637171   -0.180569     0.476724    0.109784     -0.076438   -0.413342     0.518651    -0.370614      0.0706797   0.314289      0.0857233    0.35154    -0.427673    -0.01035     -0.136855
  0.0382499  -0.832826    0.869451   -0.461499    -0.19328      0.329709   -0.0237602   -0.485431    -0.285145    -0.370916     -0.257837    -0.409928   -0.278385     0.281585    0.16625      -0.464433   -0.0129684    0.571178     0.242519      0.0139134   0.0632457    -0.0102579   -0.604012   -0.214872    -0.11274      0.148119
 -0.291621   -0.400312    0.447547   -0.137347     0.555862     0.677587   -0.116706     0.959511     0.160402    -0.252585      0.100185     0.173335   -0.634581    -0.228754   -0.0824218    -0.561203    0.468406     0.599303     0.138745      0.331713   -0.278423      0.0186573   -0.333365   -0.296887    -0.339709    -0.336453
 -0.290976   -0.283056    0.448277    0.242024     0.175165     0.534125   -0.336306    -0.655637    -0.503096     0.168954      0.21334     -0.540456   -0.522237    -0.345556   -0.848781      0.0701247  -0.326626    -0.0712657   -0.000184761  -0.559012    0.000375541  -0.66851      0.478822   -0.317307    -0.0391896   -0.879276
 -0.182191   -0.516247   -0.327674    0.0007517   -0.00941726   0.110773    0.131783     0.40113      0.074521     0.299378     -0.418316    -0.69433    -0.0305924    0.419327    0.0935467    -0.0688245   0.0326894   -0.461022     0.344405     -0.335457   -0.408584     -0.217244     0.581555    0.0168554   -0.0540628   -0.365022
  0.308742    0.576996   -0.258449   -0.062348     0.216462    -0.600327   -0.00309611   0.542578     0.440012    -0.322263     -0.129699     0.571214    0.71107      0.357378    0.617654     -0.24726     0.482251    -0.0548843   -0.278778      0.446618    0.300504      0.538146    -0.419065    0.181963     0.189895     1.04581
 -0.0343784  -0.440985   -0.398235   -0.227209     0.117037     0.672612    0.273936     0.163721    -0.370212    -0.0900849    -0.0877044    0.0688452   0.0380097   -0.105066    0.202521     -0.32906    -0.195568    -0.213342    -0.0513016    -0.0948171  -0.328338      0.211037     0.33152    -0.46771      0.163395     0.276476
 -0.380086    0.855986   -0.240399   -0.412872     0.158597     0.111057    0.287019     0.391475     0.108172    -0.49905      -0.0577139   -0.0916132  -0.310212    -0.448366    0.0974401     0.592383   -0.600326     0.0442314    0.12633      -0.855935   -0.0512568     0.435804    -0.283484   -0.115046     1.53428     -0.0472551
  0.517562    0.429746    0.0689792   0.159953    -0.11748      0.363161    0.0735706    0.00182616  -0.165633    -0.203164      0.157081     1.12928    -0.450707    -0.651478   -0.205524      0.624424   -0.178145     0.36958     -0.181388      0.286857   -0.403776      0.289893    -0.237771   -0.227655     0.648606     0.0707117
 -0.270171    0.103974    0.332457    0.262708    -0.226715    -0.164672   -0.0629276   -0.235328    -0.323018     0.121921      0.306353    -0.4736      0.434505     0.105654    0.000789547   0.665562   -0.0629003    0.343866    -0.404308     -0.626411   -0.0716496    -0.322671     0.0923193   0.0548574   -0.224098    -0.315881
 -0.282594    0.21913    -0.049694    0.288       -0.396267    -0.749415   -0.122716    -0.289345    -0.131685     0.000159991   0.00669521  -0.321015    0.358778     0.220387   -0.393379      0.309782    0.108278     0.0042788   -0.0648804     0.605148    0.372995     -0.319855     0.241479   -0.20218     -0.301223    -0.0951336
 -0.182905   -0.123557   -0.0717848   0.00335203   0.0893083   -0.0658218  -0.250445     0.117114     0.0894231    0.0597258     0.053409    -0.0994864  -0.0175206   -0.048723   -0.0340089    -0.115499    0.122521    -0.243972     0.17187       0.0194868   0.0125441    -0.121813     0.118177    0.0666602   -0.0383286   -0.0412411
  0.0126577   0.0277562   0.15772    -0.0503161   -0.163341     0.137423    0.342996     0.0132266   -0.0833359   -0.11379      -0.00360135   0.10055     0.0613621   -0.0509111  -0.0605269     0.15304    -0.184615     0.220363    -0.132602     -0.0551078  -0.0278022     0.026754    -0.235356   -0.268058     0.00741177  -0.00471188
 -0.824739   -0.303202   -0.301926   -0.321716     0.206494    -0.244338   -0.491122    -0.199007    -0.108116    -0.282062      0.559174    -0.100536    0.0291414   -0.135159   -0.110658     -0.100481    0.213663    -0.11679      0.0292914    -0.191041    0.439432     -0.224826     0.697314   -0.10388      0.232896     0.439492
 -0.624109   -0.148654    0.0637648   0.0990098   -0.112783    -0.577494   -0.0178702    0.758668    -0.0853012    0.113332      0.0277341    0.496731    0.169226    -0.464064   -0.0294148    -0.648089    0.267291    -0.41399     -0.094042     -0.0860554  -0.177728     -0.247019    -0.163096    0.163122     0.7115       0.181343
  0.0778569   0.165412    0.0264097   0.137897     0.169159    -0.423317   -0.493027    -0.167192     0.666818    -0.216014      0.482206     0.233749    0.0332703   -0.127505    0.249485      0.0962065   0.00402263   0.292326    -0.0584823     0.322457    0.657536     -0.188058    -0.56943     0.339555    -0.00981762  -0.0295039
  0.46297    -0.10626    -0.0883112   0.145932     0.121213    -0.113408   -0.311287     0.191195     0.263387     0.366664      0.168531    -0.215639   -0.00309106   0.224011    0.397793     -0.513053   -0.0960132   -0.305131    -0.160697      0.359552    0.476804      0.00701455   0.373769    0.0973565   -0.146288    -0.21475
  0.337456   -0.285348   -0.14392    -0.644401    -0.408508    -0.0747551   0.395165     0.230796     0.444065     0.0953904    -0.211665     0.170548   -0.0561357   -0.0658013   0.384083     -0.489256   -0.328786    -0.0564282    0.299592      0.361947    0.298118      0.445339    -0.46115    -0.23236      0.359324     0.534058
  0.369728    0.469946    0.20123    -0.349282    -0.538916    -0.0910549  -0.0274145   -0.23569     -0.105141    -0.0296729    -0.0994227    0.268097    0.0296757   -0.116189   -0.30065       0.250464   -0.138273    -0.00118272   0.232066      0.152671   -0.0256369     0.15905     -0.491626    0.48556      0.0593271    0.593703
  0.516222   -0.272769    0.301957    0.405926    -0.42938      0.204275    0.341598     0.217377     0.319234     0.18837      -0.40375      0.0222918  -0.342954    -0.155902    0.10962       0.319862   -0.326842     0.1459      -0.00958698    0.267136   -0.634338     -0.105443    -0.453864   -0.283124    -0.0613128   -0.751639
  0.643607    0.491133    0.588192   -0.0405155    0.426828    -0.0317204   0.252631    -0.0593935   -0.0324444    0.280643     -0.225226     0.138139    0.11408     -0.266379   -0.17965      -0.193952    0.472784    -0.0133865   -0.0022885     0.0411241  -0.495982      0.0230885   -0.435635    0.231136    -0.348453    -0.258301
 -0.238794    0.130194   -0.221589   -0.15154      0.521083     0.716555    0.12727      0.200942    -0.277898    -0.215088     -0.284415     0.0897257   0.371302     0.021479    0.0149926    -0.383292   -0.200953    -0.365684    -0.485933     -0.768186   -0.0239408     0.0792455    0.0396243  -0.495592    -0.39837     -0.0170916
  0.0160576   0.129556   -0.615425   -0.245261     0.572847     0.301355   -0.118731     0.196071    -0.0863333   -0.442976      0.24239      0.101849    0.438697    -0.141445    0.354551     -0.254814    0.0809654   -0.00448933  -0.137125      0.320386    0.13302       0.362479     0.0491958  -0.0665024   -0.194991     0.713245
  0.198572   -0.129004    0.0303895  -0.470581     0.14669      0.28059     0.0454718   -0.0851702   -0.261599     0.0882459     0.0182703    0.0420165  -0.322726    -0.0151238   0.267852     -0.170477   -0.12965     -0.0259959   -0.105913     -0.475048   -0.304958      0.230292     0.26246     0.0756505    0.838849     0.265439
  0.0553905   0.3049     -0.406081    0.37087      0.0428248    0.310918    0.107581     0.291879     0.0646804   -0.147798      0.0102636    0.294176   -0.197973    -0.0216292  [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
-0.528195      0.195195    0.194943    -0.120533     0.127322     -0.0705231  -0.542296      0.0990332    0.662412    0.0360423    0.487626     0.11923[ Info: iteration 1, average log likelihood -1.404026
[ Info: iteration 2, average log likelihood -1.404014
[ Info: iteration 3, average log likelihood -1.404003
[ Info: iteration 4, average log likelihood -1.403992
[ Info: iteration 5, average log likelihood -1.403981
[ Info: iteration 6, average log likelihood -1.403971
[ Info: iteration 7, average log likelihood -1.403961
[ Info: iteration 8, average log likelihood -1.403951
[ Info: iteration 9, average log likelihood -1.403942
[ Info: iteration 10, average log likelihood -1.403932
┌ Info: EM with 100000 data points 10 iterations avll -1.403932
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind full, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.667992e+05
      1       7.069073e+05      -1.598919e+05 |       32
      2       6.867367e+05      -2.017057e+04 |       32
      3       6.802788e+05      -6.457907e+03 |       32
      4       6.770099e+05      -3.268937e+03 |       32
      5       6.749772e+05      -2.032690e+03 |       32
      6       6.736298e+05      -1.347336e+03 |       32
      7       6.726061e+05      -1.023706e+03 |       32
      8       6.718344e+05      -7.717356e+02 |       32
      9       6.711869e+05      -6.474534e+02 |       32
     10       6.706491e+05      -5.378893e+02 |       32
     11       6.701873e+05      -4.617593e+02 |       32
     12       6.698165e+05      -3.708421e+02 |       32
     13       6.695025e+05      -3.139433e+02 |       32
     14       6.692227e+05      -2.798303e+02 |       32
     15       6.690028e+05      -2.198869e+02 |       32
     16       6.687944e+05      -2.084420e+02 |       32
     17       6.686091e+05      -1.852595e+02 |       32
     18       6.684414e+05      -1.677396e+02 |       32
     19       6.683085e+05      -1.328132e+02 |       32
     20       6.681825e+05      -1.260429e+02 |       32
     21       6.680728e+05      -1.097143e+02 |       32
     22       6.679545e+05      -1.182497e+02 |       32
     23       6.678237e+05      -1.308493e+02 |       32
     24       6.676961e+05      -1.276261e+02 |       32
     25       6.675500e+05      -1.461012e+02 |       32
     26       6.674072e+05      -1.427139e+02 |       32
     27       6.672803e+05      -1.269433e+02 |       32
     28       6.671594e+05      -1.208592e+02 |       32
     29       6.670535e+05      -1.059219e+02 |       32
     30       6.669599e+05      -9.362183e+01 |       32
     31       6.668870e+05      -7.287677e+01 |       32
     32       6.668161e+05      -7.092447e+01 |       32
     33       6.667435e+05      -7.258387e+01 |       32
     34       6.666736e+05      -6.990689e+01 |       32
     35       6.666073e+05      -6.625916e+01 |       32
     36       6.665432e+05      -6.414048e+01 |       32
     37       6.664775e+05      -6.569164e+01 |       32
     38       6.664229e+05      -5.458761e+01 |       32
     39       6.663707e+05      -5.217966e+01 |       32
     40       6.663244e+05      -4.633064e+01 |       32
     41       6.662805e+05      -4.387098e+01 |       32
     42       6.662387e+05      -4.181178e+01 |       32
     43       6.661991e+05      -3.965921e+01 |       32
     44       6.661630e+05      -3.605805e+01 |       32
     45       6.661280e+05      -3.497906e+01 |       32
     46       6.660957e+05      -3.230243e+01 |       32
     47       6.660660e+05      -2.971132e+01 |       32
     48       6.660301e+05      -3.596215e+01 |       32
     49       6.659947e+05      -3.540741e+01 |       32
     50       6.659626e+05      -3.200799e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 665962.6427514057)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415709
[ Info: iteration 2, average log likelihood -1.410746
[ Info: iteration 3, average log likelihood -1.409360
[ Info: iteration 4, average log likelihood -1.408293
[ Info: iteration 5, average log likelihood -1.407219
[ Info: iteration 6, average log likelihood -1.406309
[ Info: iteration 7, average log likelihood -1.405708
[ Info: iteration 8, average log likelihood -1.405362
[ Info: iteration 9, average log likelihood -1.405155
[ Info: iteration 10, average log likelihood -1.405018
[ Info: iteration 11, average log likelihood -1.404916
[ Info: iteration 12, average log likelihood -1.404835
[ Info: iteration 13, average log likelihood -1.404767
[ Info: iteration 14, average log likelihood -1.404708
[ Info: iteration 15, average log likelihood -1.404656
[ Info: iteration 16, average log likelihood -1.404610
[ Info: iteration 17, average log likelihood -1.404568
[ Info: iteration 18, average log likelihood -1.404529
[ Info: iteration 19, average log likelihood -1.404494
[ Info: iteration 20, average log likelihood -1.404462
[ Info: iteration 21, average log likelihood -1.404432
[ Info: iteration 22, average log likelihood -1.404405
[ Info: iteration 23, average log likelihood -1.404379
[ Info: iteration 24, average log likelihood -1.404355
[ Info: iteration 25, average log likelihood -1.404333
[ Info: iteration 26, average log likelihood -1.404312
[ Info: iteration 27, average log likelihood -1.404292
[ Info: iteration 28, average log likelihood -1.404273
[ Info: iteration 29, average log likelihood -1.404255
[ Info: iteration 30, average log likelihood -1.404239
[ Info: iteration 31, average log likelihood -1.404223
[ Info: iteration 32, average log likelihood -1.404207
[ Info: iteration 33, average log likelihood -1.404193
[ Info: iteration 34, average log likelihood -1.404178
[ Info: iteration 35, average log likelihood -1.404165
[ Info: iteration 36, average log likelihood -1.404152
[ Info: iteration 37, average log likelihood -1.404139
[ Info: iteration 38, average log likelihood -1.404127
[ Info: iteration 39, average log likelihood -1.404115
[ Info: iteration 40, average log likelihood -1.404103
[ Info: iteration 41, average log likelihood -1.404092
[ Info: iteration 42, average log likelihood -1.404081
[ Info: iteration 43, average log likelihood -1.404070
[ Info: iteration 44, average log likelihood -1.404060
[ Info: iteration 45, average log likelihood -1.404050
[ Info: iteration 46, average log likelihood -1.404040
[ Info: iteration 47, average log likelihood -1.404030
[ Info: iteration 48, average log likelihood -1.404021
[ Info: iteration 49, average log likelihood -1.404012
[ Info: iteration 50, average log likelihood -1.404003
┌ Info: EM with 100000 data points 50 iterations avll -1.404003
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.230801    0.615184    -0.493393    -0.219899    0.416959   -0.423826   -0.177178     0.337926     0.412389    -0.806929     0.0125532    0.440113    0.773544    -0.0157603    0.866762    -0.0532311    0.234351    0.0227789   -0.337334    0.484936    0.120846    0.387845   -0.479159    0.236466    -0.0574647   1.02528
  0.170283    0.205074     0.175274     0.0416606   0.309242    0.167767    0.0358931    0.152807    -0.452387     0.0793383    0.0678015    0.15428     0.572045    -0.184256    -0.275817    -0.194093     0.755318   -0.0844305   -0.0843473   0.312486   -0.0863885  -0.0321499  -0.272592   -0.0644178   -0.732627   -0.0321065
 -0.160977   -0.74633      0.251796    -0.0735278   0.119262   -0.202706   -0.254079     0.00206342   0.158067     0.239027     0.138062    -0.563826   -0.0217328    0.269863     0.749805    -0.659298     0.112917   -0.0561139    0.154341    0.206187    0.513521   -0.239914   -0.0875395  -0.00885163  -0.268744   -0.137393
 -0.205459   -0.475624     0.145843    -0.412195   -0.47569     0.214079    0.318257    -0.227915    -0.539816    -0.0221225    0.268134     0.295298    0.221347    -0.936792     0.470521     0.140447    -0.323641    0.0591111    0.64875     0.396683    0.0286586  -0.670608   -0.267793   -0.328544    -0.248407    0.343202
  0.0185362   0.284988    -0.423313     0.148118   -0.481721   -0.281532   -0.269614    -0.0789354    0.0373878    0.618717     0.32731     -0.375113    0.62049      0.513923    -0.180877     0.719652     0.179564   -0.0430103    0.0844597  -0.246226    0.321711    0.031611    0.641091    0.42163     -0.131165    0.120605
  0.332812    0.224278     0.0527554   -0.344642   -0.262846   -0.470409   -0.0474442    0.134092     0.206467     0.234953     0.076065     0.517265   -0.112525    -0.0238519    0.127201    -0.110517    -0.153302   -0.0897409   -0.229692    0.219639    0.45685     0.131866   -0.421936   -0.0696145    0.323351    0.178657
 -0.667548   -0.272433    -0.11839     -0.125476    0.238716   -0.206495   -0.315156     0.452223    -0.179474    -0.11169      0.243683     0.35317     0.0237067   -0.395667    -0.00402831  -0.575921     0.270582   -0.309841    -0.153593   -0.22399     0.0392297  -0.173059    0.250124    0.0262849    0.502127    0.405049
 -0.137134    0.155839     0.0618989   -0.382942    0.468184    0.277696    0.309322    -0.15129     -0.150152    -0.160715    -0.877679    -0.173015    0.413713     0.710285    -0.229073    -0.438919    -0.55037    -0.222398    -0.173569   -0.227148    0.500593    0.403752    0.0894463  -0.536694    -0.848178    0.00698962
 -0.237751   -0.565566    -0.746626     0.17121    -0.303595    0.102175   -0.150106     0.477808     0.182757     0.0441283   -0.522873    -0.0101996   0.108172    -0.119925     0.348497     0.326412    -0.209711   -0.237077     0.621586    0.36492    -0.558006   -0.110819    0.466188   -0.496642     0.0846982  -0.122253
  0.71485     0.375069    -0.151004    -0.170355    0.26812     0.607333    0.238214    -0.847854     0.277705     0.0281379    0.188208    -0.427363   -0.132368     0.221594     0.137514     0.26147     -0.504744    0.618963    -0.393752    0.0541249   0.0414857   0.308206    0.110033   -0.330049     0.0744938  -0.0374396
 -0.336842    0.531486    -0.0505958   -0.4942      0.0795374   0.0488809   0.0205979    0.0920843    0.0222093   -0.141883     0.201243    -0.278949   -0.801392    -0.329856     0.235773     0.364769    -0.641232   -0.107678     0.0782534  -0.90035    -0.13101     0.264731    0.0269733   0.196976     1.39527    -0.102218
 -0.675571    0.182988     0.00527998  -0.333323    0.0105989  -0.453685   -0.553768    -0.417623     0.285638    -0.651234     0.649828     0.425911    0.0295465   -0.0558713   -0.404952     0.253701     0.203116    0.471021     0.608591    0.549669    0.570008   -0.259542   -0.106135    0.0353396    0.123841    0.457747
 -0.4591     -0.386572    -0.171276     0.121488   -0.177084    0.521972    0.309964    -0.0180916   -0.538522    -0.212246     0.00799157  -0.555295   -0.1609       0.202871    -0.749626    -0.112743    -0.155972   -0.316926     0.140727   -0.303831   -0.13825    -0.498399    0.659239   -0.482029    -0.0783757  -0.171974
 -0.470207    0.823184    -0.163337     0.354785   -0.016352    0.0841996   0.706725     0.609837     0.361437    -0.512308    -0.0885158    0.496596    0.485421    -0.211343    -0.464148     0.617041    -0.151778    0.0789456    0.0323489  -0.383628    0.125665    0.395235   -0.513327   -0.553356     0.300992   -0.151536
 -0.192079   -0.0153429   -0.043703    -0.0851508   0.0402515   0.0433981   0.0164083    0.0492042   -0.071062    -0.0176559    0.0560575   -0.0322788   0.0069001   -0.00916147  -0.0817054   -0.00520139   0.0397284  -0.0312289    0.0300312  -0.144158   -0.123618   -0.0222412   0.240649   -0.100836     0.188875    0.0631233
  0.596537    0.48445      0.682089     0.205035    0.0096532  -0.424963   -0.190394    -0.137565     0.354987     0.208773    -0.0430477    0.0845473   0.00654717   0.215425    -0.058812     0.0529738    0.181705    0.162515     0.0673792   0.173608    0.212597    0.0485109  -0.550419    0.64016     -0.239841   -0.0187584
  0.359281   -0.37621     -0.27917     -0.754806   -0.378555    0.0793775   0.395854     0.309563     0.373569    -0.0330106   -0.311122     0.121519   -0.0200916   -0.0953658    0.352408    -0.577456    -0.184103   -0.175378     0.578522    0.228385    0.122308    0.586508   -0.377202   -0.0451513    0.544269    0.871825
  0.406768    0.0527856   -0.14537     -0.192492    0.192424    0.39647    -0.463887    -0.26886     -0.0147861   -0.0769443   -0.142107    -0.340056   -0.28407      0.442127    -0.101321    -0.0834625    0.325962   -0.0810862    0.436444   -0.190921   -0.215847    0.382127    0.340612    0.598236     0.138317    0.200275
  0.243635   -0.0963737   -0.253867    -0.30403     0.322501    0.675076    0.396355     0.23861     -0.462453     0.205461     0.289982     0.0473283   0.416303    -0.0982652    0.278788    -0.223927    -0.0980479   0.00925524  -0.46792    -0.553087   -0.304699    0.700727    0.393639   -0.113345     0.444963    0.720401
 -0.0100919  -0.628452     0.847295    -0.413916   -0.126774    0.373518   -0.00400078  -0.501507    -0.463317    -0.777563    -0.206713    -0.352201   -0.103825     0.60639     -0.115061    -0.214054    -0.145147    1.00368      0.0138505  -0.074206    0.012081   -0.122043   -0.251171   -0.534848     0.131727    0.199128
  0.743013   -0.0733332    0.530263     0.366784   -0.288151    0.048454    0.0233359   -0.142302    -0.0572736    1.25766      0.0149905   -0.832761   -0.0868379    0.0666693   -0.248351    -0.133873    -0.390682   -0.116168    -0.249238   -0.239148   -0.220281   -0.0174913   0.816115   -0.166962     0.434609   -1.05097
 -0.315855    0.186201    -0.368162     0.202976    0.0400104  -0.358469   -0.153028     0.716287     0.683647     0.350607    -0.187904     0.128074    0.0712618   -0.102688    -0.392556    -0.0532024    0.35796    -1.20639      0.146731   -0.120448   -0.11222    -0.171054   -0.15474     0.446585    -0.330277   -0.499805
  0.495325    0.478118    -0.0121911    0.207095   -0.283665    0.299483    0.00709678   0.186883    -0.243165    -0.0524818    0.0449259    1.14102    -0.359835    -0.502332    -0.493287     0.522107    -0.0871523   0.180328     0.0314521   0.334332   -0.467185    0.312601   -0.0282177  -0.045528     0.595137    0.274072
  0.103885    0.107886    -0.553463     0.174013    0.33847     0.0876042  -0.339308     0.0717228    0.342638    -0.0936669    0.177869    -0.0378059   0.122016     0.0900593    0.14736     -0.035743    -0.122485   -0.198916    -0.257649    0.215226    0.530692    0.0456664   0.181057   -0.0202222   -0.155589   -0.00162788
 -0.507295   -0.0263194    0.191299     0.126182   -0.381071   -1.12721     0.165497    -0.129446    -0.220151     0.032797     0.0514666   -0.305025    0.543652    -0.0130246   -0.0246232    0.437508    -0.196051   -0.0379188   -0.298795    0.431904    0.387682   -0.423051   -0.174993   -0.48849     -0.27316    -0.268124
  0.319785    0.00506529   0.398374     0.0582028  -0.211707    0.212877    0.213614    -0.00265574   0.113167    -0.00694537  -0.141029     0.0207632  -0.0415309   -0.0404836    0.0438277    0.154608    -0.165498    0.186255     0.0594771   0.0522759  -0.206231    0.145095   -0.552396    0.0624853   -0.109701   -0.105575
 -0.214246   -0.227831    -0.307676    -0.0835963   0.0813384   0.063858    0.00913959   0.0947281   -0.0766385   -0.11476     -0.0535321    0.0740175   0.0323258   -0.042937     0.0968098   -0.203419     0.0555952  -0.30617     -0.0569851   0.0750542   0.0680677  -0.0222235   0.131289   -0.301852     0.067038    0.110015
 -0.224256    0.169579     0.298697     0.121508   -0.271106   -0.840816    0.1419      -0.542042    -0.00260527  -0.0660421   -0.447214    -0.159788   -0.333008     0.01406     -0.373049     0.218384     0.281661   -0.015289     0.0162426   0.0774132  -0.320881   -0.752039   -0.128346    0.151427     0.426814   -0.231519
  0.273602   -0.082252    -0.0944805    0.136758    0.153916    0.71363     0.276185     0.323277    -0.239653     0.103889    -0.262128     0.0704282  -0.128242    -0.169388     0.414869     0.0755966   -0.193876   -0.285952    -0.543491   -0.677604   -0.797999   -0.181499    0.102275   -0.235186     0.0443469  -0.522577
 -0.101483    0.496921     0.311856     0.402544   -0.233241   -0.379103   -0.227068    -0.220311     0.172706    -0.0243807    0.782148    -0.385448    0.219483    -0.226148    -0.326603     0.389842    -0.0926324   0.487954    -0.423774   -0.110507    0.279343   -0.461862    0.202365    0.0856269   -0.354579   -0.313626
 -0.555195   -0.244352     0.382728     0.282494    0.543804    0.243954   -0.737837    -0.823761    -0.306027    -0.0250309    0.114522    -0.382354   -0.442082    -0.460879    -0.663323     0.265748    -0.192369   -0.113058    -0.0572019  -0.370166    0.115931   -0.641802    0.302367   -0.236098    -0.380892   -0.803455
  0.0130714  -0.421715     0.577385    -0.0930758   0.151323    0.594036    0.131163     0.563671     0.297481    -0.206125    -0.168768     0.0794045  -0.726646    -0.29297     -0.120417    -0.279644     0.157693    0.540507     0.270003    0.278701   -0.515381    0.127619   -0.548947   -0.254338    -0.201599   -0.524874[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.403995
[ Info: iteration 2, average log likelihood -1.403987
[ Info: iteration 3, average log likelihood -1.403979
[ Info: iteration 4, average log likelihood -1.403971
[ Info: iteration 5, average log likelihood -1.403964
[ Info: iteration 6, average log likelihood -1.403956
[ Info: iteration 7, average log likelihood -1.403949
[ Info: iteration 8, average log likelihood -1.403943
[ Info: iteration 9, average log likelihood -1.403936
[ Info: iteration 10, average log likelihood -1.403930
┌ Info: EM with 100000 data points 10 iterations avll -1.403930
└ 59.0 data points per parameter
  Iters               objv        [ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
