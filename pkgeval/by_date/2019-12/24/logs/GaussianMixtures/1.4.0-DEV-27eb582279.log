Julia Version 1.4.0-DEV.660
Commit 27eb582279 (2019-12-23 19:29 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed OpenBLAS_jll ─────── v0.3.7+1
 Installed JLD ──────────────── v0.9.1
 Installed Distances ────────── v0.8.2
 Installed BinDeps ──────────── v1.0.0
 Installed QuadGK ───────────── v2.3.1
 Installed Distributions ────── v0.21.11
 Installed Missings ─────────── v0.4.3
 Installed OrderedCollections ─ v1.1.0
 Installed FillArrays ───────── v0.8.2
 Installed CMakeWrapper ─────── v0.2.3
 Installed NearestNeighbors ─── v0.4.4
 Installed Rmath ────────────── v0.6.0
 Installed DataStructures ───── v0.17.6
 Installed LegacyStrings ────── v0.4.1
 Installed StatsBase ────────── v0.32.0
 Installed Compat ───────────── v2.2.0
 Installed URIParser ────────── v0.4.0
 Installed FileIO ───────────── v1.2.0
 Installed HDF5 ─────────────── v0.12.5
 Installed Arpack ───────────── v0.4.0
 Installed CMake ────────────── v1.1.2
 Installed StaticArrays ─────── v0.12.1
 Installed SpecialFunctions ─── v0.9.0
 Installed PDMats ───────────── v0.9.10
 Installed ScikitLearnBase ──── v0.5.0
 Installed Blosc ────────────── v0.5.1
 Installed Parameters ───────── v0.12.0
 Installed Clustering ───────── v0.13.3
 Installed SortingAlgorithms ── v0.3.1
 Installed DataAPI ──────────── v1.1.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed BinaryProvider ───── v0.5.8
 Installed StatsFuns ────────── v0.9.3
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_TwgQQk/Project.toml`
 [no changes]
  Updating `/tmp/jl_TwgQQk/Manifest.toml`
 [no changes]
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_WjLPGY/Project.toml`
 [no changes]
  Updating `/tmp/jl_WjLPGY/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_J8pqp9/Project.toml`
 [no changes]
  Updating `/tmp/jl_J8pqp9/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_MvW7w1/Project.toml`
 [no changes]
  Updating `/tmp/jl_MvW7w1/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_R8i7vm/Project.toml`
 [no changes]
  Updating `/tmp/jl_R8i7vm/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_R8i7vm/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.0
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -2.0417662608390441e6, [18402.930209547627, 81597.06979045238], [-7229.736682506385 7081.76924440241 -21778.68297663022; 7329.299170849165 -7002.9650154574965 21691.238040241136], [[20268.798207667573 -6194.375173959241 8094.207404887454; -6194.375173959241 29169.80589062816 -6946.355973111062; 8094.207404887454 -6946.35597311106 35862.17844144095], [79463.07155344324 6235.962148863656 -7763.001518156551; 6235.962148863657 70883.23487013602 6890.20885070368; -7763.001518156551 6890.20885070368 64292.12116444149]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       2.065698e+03
      1       1.055490e+03      -1.010207e+03 |        6
      2       9.462037e+02      -1.092866e+02 |        2
      3       8.963951e+02      -4.980864e+01 |        3
      4       8.344286e+02      -6.196644e+01 |        2
      5       8.180256e+02      -1.640299e+01 |        0
      6       8.180256e+02       0.000000e+00 |        0
K-means converged with 6 iterations (objv = 818.0256481905999)
┌ Info: K-means with 272 data points using 6 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.045076
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.812272
[ Info: iteration 2, lowerbound -3.706909
[ Info: iteration 3, lowerbound -3.591701
[ Info: iteration 4, lowerbound -3.457968
[ Info: iteration 5, lowerbound -3.316131
[ Info: iteration 6, lowerbound -3.173755
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -3.030755
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.890724
[ Info: iteration 9, lowerbound -2.770832
[ Info: dropping number of Gaussions to 5
[ Info: iteration 10, lowerbound -2.670708
[ Info: dropping number of Gaussions to 4
[ Info: iteration 11, lowerbound -2.582731
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.505022
[ Info: iteration 13, lowerbound -2.438461
[ Info: iteration 14, lowerbound -2.388484
[ Info: iteration 15, lowerbound -2.351032
[ Info: iteration 16, lowerbound -2.324260
[ Info: iteration 17, lowerbound -2.309514
[ Info: iteration 18, lowerbound -2.308580
[ Info: dropping number of Gaussions to 2
[ Info: iteration 19, lowerbound -2.302915
[ Info: iteration 20, lowerbound -2.299259
[ Info: iteration 21, lowerbound -2.299256
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299254
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Tue Dec 24 05:31:08 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Tue Dec 24 05:31:16 2019: K-means with 272 data points using 6 iterations
11.3 data points per parameter
, Tue Dec 24 05:31:18 2019: EM with 272 data points 0 iterations avll -2.045076
5.8 data points per parameter
, Tue Dec 24 05:31:20 2019: GMM converted to Variational GMM
, Tue Dec 24 05:31:28 2019: iteration 1, lowerbound -3.812272
, Tue Dec 24 05:31:28 2019: iteration 2, lowerbound -3.706909
, Tue Dec 24 05:31:28 2019: iteration 3, lowerbound -3.591701
, Tue Dec 24 05:31:28 2019: iteration 4, lowerbound -3.457968
, Tue Dec 24 05:31:28 2019: iteration 5, lowerbound -3.316131
, Tue Dec 24 05:31:28 2019: iteration 6, lowerbound -3.173755
, Tue Dec 24 05:31:29 2019: dropping number of Gaussions to 7
, Tue Dec 24 05:31:29 2019: iteration 7, lowerbound -3.030755
, Tue Dec 24 05:31:29 2019: dropping number of Gaussions to 6
, Tue Dec 24 05:31:29 2019: iteration 8, lowerbound -2.890724
, Tue Dec 24 05:31:29 2019: iteration 9, lowerbound -2.770832
, Tue Dec 24 05:31:29 2019: dropping number of Gaussions to 5
, Tue Dec 24 05:31:29 2019: iteration 10, lowerbound -2.670708
, Tue Dec 24 05:31:29 2019: dropping number of Gaussions to 4
, Tue Dec 24 05:31:29 2019: iteration 11, lowerbound -2.582731
, Tue Dec 24 05:31:29 2019: dropping number of Gaussions to 3
, Tue Dec 24 05:31:29 2019: iteration 12, lowerbound -2.505022
, Tue Dec 24 05:31:29 2019: iteration 13, lowerbound -2.438461
, Tue Dec 24 05:31:29 2019: iteration 14, lowerbound -2.388484
, Tue Dec 24 05:31:29 2019: iteration 15, lowerbound -2.351032
, Tue Dec 24 05:31:29 2019: iteration 16, lowerbound -2.324260
, Tue Dec 24 05:31:29 2019: iteration 17, lowerbound -2.309514
, Tue Dec 24 05:31:29 2019: iteration 18, lowerbound -2.308580
, Tue Dec 24 05:31:29 2019: dropping number of Gaussions to 2
, Tue Dec 24 05:31:29 2019: iteration 19, lowerbound -2.302915
, Tue Dec 24 05:31:29 2019: iteration 20, lowerbound -2.299259
, Tue Dec 24 05:31:29 2019: iteration 21, lowerbound -2.299256
, Tue Dec 24 05:31:29 2019: iteration 22, lowerbound -2.299254
, Tue Dec 24 05:31:29 2019: iteration 23, lowerbound -2.299254
, Tue Dec 24 05:31:29 2019: iteration 24, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 25, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 26, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 27, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 28, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 29, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 30, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 31, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 32, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 33, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 34, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 35, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 36, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 37, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 38, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 39, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 40, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 41, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 42, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 43, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 44, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 45, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 46, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 47, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 48, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 49, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: iteration 50, lowerbound -2.299253
, Tue Dec 24 05:31:29 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.0450922260141, 95.95490777398591]
β = [178.0450922260141, 95.95490777398591]
m = [4.250300733269907 79.28686694436182; 2.0002292577753686 53.851987172461286]
ν = [180.0450922260141, 97.95490777398591]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484394 -0.007644049042327432; 0.0 0.008581705166333458], [0.37587636119484585 -0.008953123827346187; 0.0 0.012748664777409349]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9911297762419208
avll from llpg:  -0.9911297762419208
avll direct:     -0.9911297762419208
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -1.004861091389225
avll from llpg:  -1.004861091389225
avll direct:     -1.0048610913892249
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.184248     0.0431273  -0.143513    -0.0735503    0.0615761    0.0184321     0.0508517    0.00341214  -0.121729     0.127845     0.0243409    0.184149    -0.0337169    -0.0222444     0.0157429  -0.0716409    0.0439069   -0.0248329    0.0188582   -0.00245706  -0.128925     0.0339842    0.0186897   -0.107179     0.0750269  -0.0540244
  0.0220047    0.0251149   0.0683969   -0.154724     0.0247775   -0.0299381    -0.0299783    0.00201404   0.100386     0.143895     0.0437653    0.00742841   0.0692533     0.188997      0.0715905  -0.0349138    0.0513755   -0.14483     -0.0145025   -0.0395452   -0.0851946    0.0628117    0.0744104    0.10036     -0.0343844  -0.137215
  0.0176179    0.0406501   0.0169746    0.119925    -0.131101    -0.0260029     0.146387    -0.157884     0.18191     -0.19224     -0.0792731   -0.149479     0.0137037     0.123043     -0.04718    -0.0485507    0.00329617  -0.0146807   -0.0318521   -0.120591     0.110498    -0.0192652    0.135345     0.129298     0.031835    0.0573551
  0.0543189    0.15428     0.051758     0.111629    -0.0536992   -0.0630131    -0.0279484    0.197654    -0.133302     0.0465336   -0.0444936   -0.0409836   -0.0603212     0.0146194     0.091543   -0.034677     0.161567    -0.062475    -0.0163093   -0.0360479   -0.147235    -0.18013      0.0462068   -0.0396777    0.15274    -0.152652
 -0.117733    -0.0293587   0.123824    -0.138893     0.00673653   0.12587      -0.0399602   -0.13219      0.0111461    0.147373    -0.0399253    0.135132     0.0109042    -0.138622      0.0456267   0.0216521    0.0685502    0.129309    -0.195795     0.18175      0.0597596    0.00690565   0.0793193    0.0131969    0.194629    0.140831
 -0.0248654    0.0162085   0.0699973    0.0219849    0.101061     0.187162      0.12984     -0.0742569   -0.0429864   -0.018775     0.134432     0.114757     0.0471629     0.000391482   0.0330077   0.283652     0.00521253   0.157613     0.148558    -0.0629384    0.00626165   0.00961428   0.0295502    0.106426    -0.0692769  -0.0922384
 -0.0812662   -0.165317   -0.0241575    0.0702255    0.19998      0.0642347     0.0870952    0.0102233    0.112987    -0.0852454    0.0775344    0.0296756   -0.0362674     0.00771858   -0.0901463   0.107982     0.0349286   -0.0366722    0.0252292    0.180452     0.0273732    0.00692364  -0.0337187    0.23022     -0.13057    -0.139089
  0.0979592    0.108164   -0.0158402    0.169571     0.0216001    0.0786597    -0.19763     -0.0199356    0.0955856   -0.152353     0.0820219    0.0904378    0.132189     -0.058628      0.0202283  -0.114729     0.101334     0.0344816    0.0219507   -0.00628      0.108168    -0.0161852   -0.113874     0.215467     0.0644175   0.0813256
 -0.0342575    0.0101169   0.0760575    0.178983    -0.132167    -0.101723     -0.00455785  -0.0283931   -0.0916232   -0.039366    -0.145443     0.0323844   -0.0585647     0.0559553    -0.0866821  -0.0294703   -0.0603112    0.014544    -0.159227    -0.0324805   -0.049026    -0.0673769    0.0316352    0.0500718   -0.0874398   0.139945
 -0.11642     -0.0582368   0.0455344    0.0835948   -0.0603953    0.0114247     0.0724822    0.0913827    0.0823109   -0.0814154    0.0522287   -0.0847572    0.122193      0.177207     -0.100386   -0.0482204   -0.0548169   -0.0286739   -0.0280178   -0.0739621    0.0801473    0.0446711   -0.113325     0.182063     0.136434   -0.206268
  0.0248166    0.053073    0.129444     0.182588     0.0749162    0.00621999   -0.0257854    0.0561749    0.00871062   0.0713636   -0.0285913    0.0283741    0.00882137    0.0871033    -0.0471457  -0.00365945  -0.0159557   -0.0552588   -0.182252     0.0597185    0.0433708   -0.203645    -0.0791553    0.0294687    0.0675061  -0.0662877
 -0.0189525   -0.135959    0.0218033    0.0835533    0.119193     0.0212136    -0.0260667    0.0471218   -0.0752858    0.084628     0.039962     0.133938     0.132675     -0.148437      0.123551   -0.00241938   0.0461763    0.021318    -0.0650885   -0.0272021   -0.0504848    0.0952721    0.00979988   0.0638267   -0.0690704   0.0118094
  0.0889757   -0.104972    0.0181477   -0.187175     0.0684104   -0.108422      0.041774    -0.0589053   -0.14966     -0.056311     0.0694752   -0.139875    -0.0113775     0.0181016     0.0685602   0.296752     0.119162     0.0500461    0.0237132    0.0496899   -0.070959     0.0395883   -0.0784166   -0.0115566   -0.0061356   0.105484
 -0.0208421   -0.21728     0.0743064    0.152377    -0.121394     0.00801952   -0.134614     0.118902     0.0658623    0.0145908    0.125503    -0.0243065    0.110745     -0.134303     -0.0248598  -0.128031     0.135917     0.0025752    0.0653837   -0.112687     0.0954272    0.132689     0.0321948   -0.0746202   -0.156591    0.0491951
  0.212418     0.0381483   0.0116209    0.0389633    0.07022     -0.000752738   0.205385     0.0921799   -0.0528953    0.0460637    0.00326943   0.10327      0.188583      0.0234109    -0.0325294   0.0556532    0.241716    -0.0699386    0.031642    -0.0662173    0.0946984   -0.214489    -0.05866     -0.178797     0.0774063   0.0451525
 -0.066338     0.0776863  -0.0398825   -0.113135    -0.141251    -0.100214     -0.00888361   0.0989184    0.0153601   -0.0208207    0.0275427    0.0971202   -0.214407     -0.142426      0.0324819  -0.0905608   -0.00244686   0.0525321   -0.120368    -0.0676502    0.0496975   -0.0463365   -0.0723057   -0.0211025   -0.0346261  -0.189763
  0.0720642    0.0785978   0.0129705   -0.0201097   -0.00533954   0.0907531     0.0715416   -0.141527     0.113539     0.0491181   -0.23766     -0.0114854    0.0454812    -0.172132     -0.114484    0.0147456   -0.0596311   -0.0933911    0.0491003   -0.139217     0.0408948   -0.00510201  -0.0436281   -0.130527    -0.146909    0.00321119
 -0.144065     0.0639475  -0.133788     0.132531    -0.116944    -0.0694843     0.0326268    0.0635654    0.0283548    0.00928501   0.00506619  -0.12956      0.0121658     0.0799702     0.043621   -0.101438    -0.225989     0.06365     -0.0653956   -0.106936     0.148163     0.0969427    0.00283098   0.0210177   -0.157757   -0.028463
 -0.15924     -0.0480053  -0.205003    -0.116242     0.0287981   -0.0502488     0.042523     0.07951     -0.0394329    0.13245     -0.182928    -0.0545329    0.00617386    0.225332     -0.0762699  -0.0331967   -0.113257    -0.107431    -0.0329978   -0.0517542   -0.114139     0.09738     -0.00575528  -0.138218     0.0116536  -0.0608558
 -0.0965728    0.0275387   0.13139      0.20406     -0.00851288   0.0314616    -0.119013     0.0540441    0.0775824   -0.090046    -0.158307    -0.00636031  -0.0425844    -0.135825      0.0687778   0.120292     0.130083    -0.0497655    0.0965779   -0.141815    -0.0701602   -0.0159341    0.00134081   0.0757298   -0.0115442   0.0325417
 -0.0874105    0.0371918  -0.00402845  -0.0054485    0.091171     0.100503     -0.0799408    0.0109407   -0.0625883   -0.0595853    0.00821694  -0.0675165    0.000911896   0.0274169    -0.0791078   0.0348383    0.181778    -0.183398     0.0496091    0.0449094    0.0372912    0.118213     0.0433374   -0.0167007   -0.256469    0.0842548
  0.070327     0.197947   -0.165717     0.0632592    0.0158433   -0.0953071    -0.15929     -0.0996203   -0.0677641    0.0913769    0.00595933   0.00974639   0.0484952     0.00979015   -0.224192   -0.148043     0.109015     0.01975     -0.00842496   0.0772846    0.060932    -0.0137189    0.00766546   0.0804822    0.0297005   0.0990675
  0.118053    -0.0202492   0.0609284   -0.0629638    0.00834971   0.172222      0.287804    -0.221743    -0.109628     0.161478     0.201584    -0.0832282    0.0553922    -0.0696055     0.0785934  -0.0979055    0.10945     -0.0444575   -0.042943    -0.0485687   -0.160211     0.152761     0.0280566   -0.130885     0.147836    0.047048
  0.273921     0.0429074  -0.0054335   -0.033829    -0.0718361   -0.00113801    0.0799394   -0.150582    -0.20455      0.0574886    0.0920846    0.0829562   -0.00388438    0.180745     -0.150792   -0.157311    -0.0845709   -0.0271705   -0.00437806   0.011001     0.147142    -0.0164944   -0.0625365   -0.0409854   -0.113668   -0.0521333
 -0.127731     0.23694    -0.024059     0.104644    -0.00690015   0.0871043     0.185217     0.00781869  -0.0475037    0.0259994   -0.0868127   -0.158075     0.139123      0.0144494     0.183311    0.221837    -0.0622946   -0.0628423    0.0455317   -0.0555179   -0.0827066    0.0700251   -0.044137    -0.0973061   -0.0894464  -0.168889
  0.075861     0.147172    0.0418344    0.0115231    0.0230409   -0.0438832     0.0780456    0.0811811   -0.0739809    0.00426206  -0.154287    -0.186155    -0.108411     -0.00939629   -0.0930526  -0.175429    -0.0113421   -0.177385     0.0127165   -0.153235     0.0351476    0.0266422   -0.0494356    0.00290521   0.0514034  -0.167611
  0.142475     0.0107219   0.0342369   -0.0194219   -0.0902581    0.0264814     0.0564777   -0.0257564    0.0808351   -0.0110787    0.169173    -0.129111    -0.0710896     0.0818186    -0.177067    0.155747    -0.101479    -0.0328609    0.153892     0.113883    -0.167859     0.0779723   -0.102894    -0.0933964    0.171926    0.0802796
 -0.0340101    0.07886     0.302193    -0.059838     0.0508894    0.0254203    -0.0851716    0.0406758    0.0298472    0.0172127    0.0586644    0.0492249    0.0701661     0.0948508    -0.190813   -0.0849199    0.223758     0.00155     -0.0528214    0.0980008   -0.128012     0.0744141    0.0386751    0.0339562    0.188297   -0.013414
 -0.0367986   -0.138188   -0.110141    -0.0897354    0.0368998   -0.0069151    -0.134999     0.00156691   0.135182    -0.0120049   -0.0383565    0.123464    -0.0153049    -0.0805309    -0.104404   -0.0150197    0.128503    -0.00262222   0.00946107  -0.0391641   -0.131611    -0.0248417   -0.140061     0.157826     0.0252472   0.108575
 -0.00783675   0.0155167  -4.76327e-5   0.00834749  -0.0314175    0.0296805    -0.0721618   -0.117917    -0.0323326   -0.108617     0.0403234   -0.00758544  -0.133197      0.0611404     0.134694   -0.0572957    0.0845301    0.102084    -0.12619     -0.26791     -0.100116     0.187587     0.0405626   -0.0151775   -0.0604925   0.0775547
  0.0176288    0.0456528  -0.158876     0.138468    -0.0229303   -0.070955      0.0966018   -0.0257296    0.0638699    0.070607     0.0968694    0.118522     0.0381807     0.00446347    0.173359   -0.00957107  -0.0800076   -0.045653     0.0204756   -0.11751      0.114707    -0.0665252   -0.0878443   -0.177953     0.0503584  -0.0960487
 -0.24241      0.0862031   0.00426826  -0.116403    -0.0671215    0.163        -0.124583     0.00295907  -0.164753    -0.0438426    0.069785    -0.0122105    0.0391882     0.0277826     0.024835    0.0834417   -0.0336171    0.0421217    0.050435     0.171431    -0.0283584    0.0848041    0.169284     0.0206523    0.109274   -0.0333595kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4488575291341346
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.448953
[ Info: iteration 2, average log likelihood -1.448863
[ Info: iteration 3, average log likelihood -1.448169
[ Info: iteration 4, average log likelihood -1.439419
[ Info: iteration 5, average log likelihood -1.416044
[ Info: iteration 6, average log likelihood -1.406369
[ Info: iteration 7, average log likelihood -1.404590
[ Info: iteration 8, average log likelihood -1.404080
[ Info: iteration 9, average log likelihood -1.403900
[ Info: iteration 10, average log likelihood -1.403828
[ Info: iteration 11, average log likelihood -1.403796
[ Info: iteration 12, average log likelihood -1.403780
[ Info: iteration 13, average log likelihood -1.403772
[ Info: iteration 14, average log likelihood -1.403767
[ Info: iteration 15, average log likelihood -1.403765
[ Info: iteration 16, average log likelihood -1.403763
[ Info: iteration 17, average log likelihood -1.403763
[ Info: iteration 18, average log likelihood -1.403762
[ Info: iteration 19, average log likelihood -1.403762
[ Info: iteration 20, average log likelihood -1.403762
[ Info: iteration 21, average log likelihood -1.403762
[ Info: iteration 22, average log likelihood -1.403761
[ Info: iteration 23, average log likelihood -1.403761
[ Info: iteration 24, average log likelihood -1.403761
[ Info: iteration 25, average log likelihood -1.403761
[ Info: iteration 26, average log likelihood -1.403761
[ Info: iteration 27, average log likelihood -1.403761
[ Info: iteration 28, average log likelihood -1.403761
[ Info: iteration 29, average log likelihood -1.403761
[ Info: iteration 30, average log likelihood -1.403761
[ Info: iteration 31, average log likelihood -1.403761
[ Info: iteration 32, average log likelihood -1.403761
[ Info: iteration 33, average log likelihood -1.403761
[ Info: iteration 34, average log likelihood -1.403761
[ Info: iteration 35, average log likelihood -1.403761
[ Info: iteration 36, average log likelihood -1.403761
[ Info: iteration 37, average log likelihood -1.403761
[ Info: iteration 38, average log likelihood -1.403761
[ Info: iteration 39, average log likelihood -1.403761
[ Info: iteration 40, average log likelihood -1.403761
[ Info: iteration 41, average log likelihood -1.403761
[ Info: iteration 42, average log likelihood -1.403761
[ Info: iteration 43, average log likelihood -1.403761
[ Info: iteration 44, average log likelihood -1.403761
[ Info: iteration 45, average log likelihood -1.403761
[ Info: iteration 46, average log likelihood -1.403761
[ Info: iteration 47, average log likelihood -1.403761
[ Info: iteration 48, average log likelihood -1.403761
[ Info: iteration 49, average log likelihood -1.403761
[ Info: iteration 50, average log likelihood -1.403761
┌ Info: EM with 100000 data points 50 iterations avll -1.403761
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4489531510675047
│     -1.4488627405311247
│      ⋮
└     -1.4037613965287437
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.403960
[ Info: iteration 2, average log likelihood -1.403792
[ Info: iteration 3, average log likelihood -1.403110
[ Info: iteration 4, average log likelihood -1.395717
[ Info: iteration 5, average log likelihood -1.377120
[ Info: iteration 6, average log likelihood -1.366941
[ Info: iteration 7, average log likelihood -1.363471
[ Info: iteration 8, average log likelihood -1.362094
[ Info: iteration 9, average log likelihood -1.361148
[ Info: iteration 10, average log likelihood -1.360068
[ Info: iteration 11, average log likelihood -1.358950
[ Info: iteration 12, average log likelihood -1.358114
[ Info: iteration 13, average log likelihood -1.357594
[ Info: iteration 14, average log likelihood -1.357245
[ Info: iteration 15, average log likelihood -1.356978
[ Info: iteration 16, average log likelihood -1.356756
[ Info: iteration 17, average log likelihood -1.356569
[ Info: iteration 18, average log likelihood -1.356420
[ Info: iteration 19, average log likelihood -1.356305
[ Info: iteration 20, average log likelihood -1.356217
[ Info: iteration 21, average log likelihood -1.356151
[ Info: iteration 22, average log likelihood -1.356100
[ Info: iteration 23, average log likelihood -1.356058
[ Info: iteration 24, average log likelihood -1.356021
[ Info: iteration 25, average log likelihood -1.355987
[ Info: iteration 26, average log likelihood -1.355955
[ Info: iteration 27, average log likelihood -1.355926
[ Info: iteration 28, average log likelihood -1.355898
[ Info: iteration 29, average log likelihood -1.355871
[ Info: iteration 30, average log likelihood -1.355844
[ Info: iteration 31, average log likelihood -1.355818
[ Info: iteration 32, average log likelihood -1.355792
[ Info: iteration 33, average log likelihood -1.355765
[ Info: iteration 34, average log likelihood -1.355740
[ Info: iteration 35, average log likelihood -1.355715
[ Info: iteration 36, average log likelihood -1.355693
[ Info: iteration 37, average log likelihood -1.355674
[ Info: iteration 38, average log likelihood -1.355658
[ Info: iteration 39, average log likelihood -1.355644
[ Info: iteration 40, average log likelihood -1.355633
[ Info: iteration 41, average log likelihood -1.355624
[ Info: iteration 42, average log likelihood -1.355616
[ Info: iteration 43, average log likelihood -1.355610
[ Info: iteration 44, average log likelihood -1.355605
[ Info: iteration 45, average log likelihood -1.355601
[ Info: iteration 46, average log likelihood -1.355598
[ Info: iteration 47, average log likelihood -1.355596
[ Info: iteration 48, average log likelihood -1.355594
[ Info: iteration 49, average log likelihood -1.355592
[ Info: iteration 50, average log likelihood -1.355591
┌ Info: EM with 100000 data points 50 iterations avll -1.355591
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.403959862007079
│     -1.403791859760471
│      ⋮
└     -1.3555912607237033
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.355854
[ Info: iteration 2, average log likelihood -1.355625
[ Info: iteration 3, average log likelihood -1.354997
[ Info: iteration 4, average log likelihood -1.348089
[ Info: iteration 5, average log likelihood -1.325309
[ Info: iteration 6, average log likelihood -1.306183
[ Info: iteration 7, average log likelihood -1.299429
[ Info: iteration 8, average log likelihood -1.296848
[ Info: iteration 9, average log likelihood -1.295769
[ Info: iteration 10, average log likelihood -1.295036
[ Info: iteration 11, average log likelihood -1.294402
[ Info: iteration 12, average log likelihood -1.293805
[ Info: iteration 13, average log likelihood -1.293251
[ Info: iteration 14, average log likelihood -1.292740
[ Info: iteration 15, average log likelihood -1.292233
[ Info: iteration 16, average log likelihood -1.291747
[ Info: iteration 17, average log likelihood -1.291351
[ Info: iteration 18, average log likelihood -1.291098
[ Info: iteration 19, average log likelihood -1.290956
[ Info: iteration 20, average log likelihood -1.290866
[ Info: iteration 21, average log likelihood -1.290799
[ Info: iteration 22, average log likelihood -1.290739
[ Info: iteration 23, average log likelihood -1.290679
[ Info: iteration 24, average log likelihood -1.290609
[ Info: iteration 25, average log likelihood -1.290521
[ Info: iteration 26, average log likelihood -1.290411
[ Info: iteration 27, average log likelihood -1.290278
[ Info: iteration 28, average log likelihood -1.290128
[ Info: iteration 29, average log likelihood -1.289964
[ Info: iteration 30, average log likelihood -1.289785
[ Info: iteration 31, average log likelihood -1.289561
[ Info: iteration 32, average log likelihood -1.289202
[ Info: iteration 33, average log likelihood -1.288418
[ Info: iteration 34, average log likelihood -1.286796
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.284113
[ Info: iteration 36, average log likelihood -1.301065
[ Info: iteration 37, average log likelihood -1.293744
[ Info: iteration 38, average log likelihood -1.291735
[ Info: iteration 39, average log likelihood -1.290668
[ Info: iteration 40, average log likelihood -1.290009
[ Info: iteration 41, average log likelihood -1.289712
[ Info: iteration 42, average log likelihood -1.289500
[ Info: iteration 43, average log likelihood -1.289225
[ Info: iteration 44, average log likelihood -1.288712
[ Info: iteration 45, average log likelihood -1.287580
[ Info: iteration 46, average log likelihood -1.285431
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.282804
[ Info: iteration 48, average log likelihood -1.300916
[ Info: iteration 49, average log likelihood -1.293789
[ Info: iteration 50, average log likelihood -1.291748
┌ Info: EM with 100000 data points 50 iterations avll -1.291748
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3558544419118854
│     -1.3556250509065002
│      ⋮
└     -1.2917480679399471
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.290919
[ Info: iteration 2, average log likelihood -1.289580
[ Info: iteration 3, average log likelihood -1.287941
[ Info: iteration 4, average log likelihood -1.277201
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.246284
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.226039
[ Info: iteration 7, average log likelihood -1.216664
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.198352
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.199171
[ Info: iteration 10, average log likelihood -1.200836
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.189285
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.194077
[ Info: iteration 13, average log likelihood -1.197503
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.187408
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.192254
[ Info: iteration 16, average log likelihood -1.195666
[ Info: iteration 17, average log likelihood -1.185558
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.180809
[ Info: iteration 19, average log likelihood -1.197514
[ Info: iteration 20, average log likelihood -1.185892
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.181043
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.187898
[ Info: iteration 23, average log likelihood -1.190605
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.183497
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.189414
[ Info: iteration 26, average log likelihood -1.190560
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.183563
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.189404
[ Info: iteration 29, average log likelihood -1.190565
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.183655
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.189390
[ Info: iteration 32, average log likelihood -1.190583
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.183783
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.189379
[ Info: iteration 35, average log likelihood -1.190608
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.183963
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.189362
[ Info: iteration 38, average log likelihood -1.190639
[ Info: iteration 39, average log likelihood -1.184241
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.179707
[ Info: iteration 41, average log likelihood -1.197173
[ Info: iteration 42, average log likelihood -1.185390
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.180132
[ Info: iteration 44, average log likelihood -1.197165
[ Info: iteration 45, average log likelihood -1.185422
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.180169
[ Info: iteration 47, average log likelihood -1.197162
[ Info: iteration 48, average log likelihood -1.185428
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.180193
[ Info: iteration 50, average log likelihood -1.197160
┌ Info: EM with 100000 data points 50 iterations avll -1.197160
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2909194999865579
│     -1.2895798469589785
│      ⋮
└     -1.1971604870767008
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.185899
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     3
│     4
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.180133
[ Info: iteration 3, average log likelihood -1.184291
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     3
│     4
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.163525
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.125185
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     3
│     4
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.126400
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.101796
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.120678
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.103765
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.111158
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.096426
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.116324
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.098869
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     17
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.104752
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.099900
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.115452
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.095654
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     17
│     18
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.100038
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      3
│      4
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.108357
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.105670
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     17
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.089175
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     18
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.107550
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.099411
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.105084
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     17
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.088008
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     18
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.107464
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.099340
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.104989
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.097526
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     18
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.102780
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     17
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.096919
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.112445
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.092823
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.103655
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.093110
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.110617
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.093558
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     17
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.099351
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.104834
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     17
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.107099
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      3
│      4
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.094487
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     18
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.095758
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.103011
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.107831
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     17
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.090233
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.111054
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.097988
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     17
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.103248
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.098193
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      5
│      6
│     17
│     18
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.101957
┌ Info: EM with 100000 data points 50 iterations avll -1.101957
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1858993221824343
│     -1.1801325039563286
│      ⋮
└     -1.1019567371166354
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4488575291341346
│     -1.4489531510675047
│     -1.4488627405311247
│     -1.4481692232761205
│      ⋮
│     -1.1032478546690045
│     -1.098193374744763
└     -1.1019567371166354
32×26 Array{Float64,2}:
  0.0109067   0.0240735     0.0960354   -0.134907     0.0215258   -0.0404036    -0.0392415   0.0194727     0.112502     0.143316     0.0380674   -0.00317338    0.0720648    0.184722     0.0718441   0.0054794    0.0414915   -0.200958     -0.0113324   -0.0422609   -0.0840567    0.064365     0.0383386    0.0931586   -0.0113837   -0.139089
  0.0748619   0.0751251    -0.018957     0.0214581    0.0457436    0.0613446     0.0707237  -0.146878      0.146001     0.0386801   -0.233537    -0.00312002    0.0414897   -0.171554    -0.11188     0.060995    -0.0593178   -0.184039      0.057       -0.144785     0.0409361   -0.00446657  -0.0390007   -0.119509    -0.137176    -0.00169267
  0.0524059  -0.25194       0.136665    -0.0829578    0.165253     0.0111917     0.0145326   0.227579      0.0117074    0.0669531   -0.504207     0.134732      0.00815899   0.0907362   -0.0542976   0.00141734   0.0411706   -0.230186     -0.172574    -0.101483     0.0436316   -0.171946    -0.0740574    0.0373436   -0.012284    -0.0326179
  0.0467567   0.319562      0.135239     0.309756     0.0174836    0.018912     -0.101036   -0.133999      0.0126557    0.070315     0.421982    -0.0906173     0.0158415    0.0909612   -0.0512826  -0.00112671  -0.109082     0.137908     -0.172821     0.229107     0.0436536   -0.227166    -0.073356     0.0346077    0.142247    -0.0810614
  0.0541882   0.135595     -0.0221462    0.104849    -0.0603238   -0.0411221     0.160063    0.19404      -0.128173     0.111235     0.0245424   -0.0425584    -0.0594248    0.134738     0.0894492  -0.0361829    0.205487     0.0840588    -0.924303     0.00176958  -0.148906    -0.184793     0.103796    -0.0309669    0.153623    -0.143719
  0.0541793   0.0741948     0.0722924    0.107628    -0.101484    -0.102548     -0.237754    0.199171     -0.151228    -0.0374268   -0.136654    -0.0399188    -0.0605737   -0.0901396    0.0988238  -0.029992     0.0767479   -0.141662      0.758993    -0.0402729   -0.161257    -0.155763    -0.139416    -0.100874     0.151748    -0.144169
 -0.158582   -0.119807     -0.197786    -0.0801238    0.0108558   -0.0117623    -0.05665    -0.017286     -0.0468102    0.0691673   -0.173137    -0.085512     -0.187055     0.131638    -0.0749026  -0.0557312   -0.108558    -0.102232     -0.00860491  -0.029037    -0.108243     0.0486962    0.0745472   -0.914807     0.0294149   -0.0386977
 -0.180314   -0.00480664   -0.157805    -0.169607     0.0450197   -0.0901038     0.185448    0.118389     -0.00864099   0.182815    -0.219878    -0.0317183     0.100397     0.307682    -0.079381   -0.0134667   -0.119931    -0.110984     -0.0187172   -0.0864109   -0.119838     0.0883491   -0.0594852    0.581006    -0.0222134   -0.104312
  0.270959    0.0423365    -0.0359062   -0.0297698   -0.101375    -0.00370433    0.0798934  -0.169514     -0.202152     0.0657169    0.0806211    0.0748154    -0.00551041   0.179246    -0.148935   -0.168189    -0.0944955   -0.0240908     0.00583232   0.0104284    0.123779    -0.0198439   -0.0891298   -0.039504    -0.120444    -0.0174274
  0.0175005   0.000188629   0.0790633    0.0931928   -0.0234404    0.00644682   -0.0430335  -0.000375204   0.0673349   -0.0502271   -0.00197326  -0.0627566    -0.0428929   -0.0288748   -0.0565929   0.126338     0.0206646   -0.0194935     0.112885    -0.0201777   -0.109243     0.0175004   -0.0433819   -0.00596671   0.0715601    0.0563536
  0.0831054   0.0401627    -0.0320933    0.114597     0.0215875    0.0437715    -0.154606    0.0889501     0.0992772   -0.162448     0.00716415   0.0921304     0.130887    -0.0232704    0.110083   -0.135748     0.0698751   -0.358337     -0.0226536   -0.0194509    0.138004    -0.0271749   -0.0973376    0.199542     0.0403235    0.0648709
  0.113289    0.28075       0.027317     0.227587     0.0360304    0.0272544    -0.242526   -0.015799      0.112502    -0.269525     0.17763      0.048225      0.128596    -0.0400328   -0.0480748  -0.110717     0.210131     0.393663      0.0820995   -0.00250817   0.0748857   -0.00849608  -0.136076     0.232938     0.0590843    0.0809174
  0.0568659  -0.0972554    -0.233469    -0.197548     0.0647187   -0.2332       -1.27619    -0.166701     -0.168307    -0.0629598    0.0725778   -0.139781      0.0488141    0.214258     0.0651041   0.336318     0.118767     0.158853      0.0306505    0.0293942    0.00695429   0.0377487   -0.0798612   -0.0116015    0.043977     0.147291
  0.1107     -0.12421       0.317463    -0.160825     0.0772829   -0.0555336     1.35456     0.0279921    -0.122475    -0.0821612    0.0510803   -0.142345     -0.0836874   -0.0362349    0.0740808   0.225281     0.114096    -0.0160352     0.0668015    0.0687404   -0.133483     0.0380412   -0.0813502   -0.0129523   -0.0131576    0.000156364
  0.0760489   0.153489      0.0445797    0.00461345   0.0266721   -0.045701      0.0916034   0.0745035    -0.0744844    0.00700796  -0.177888    -0.173915     -0.161353     0.067214    -0.0796451  -0.174522    -0.00437557  -0.144094      0.0135949   -0.148995     0.0493897    0.0171074   -0.0508742    0.00902004   0.0605543   -0.187098
  0.221791    0.0347136     0.0396575    0.0188734    0.0686061   -0.0130235     0.192141    0.0773417    -0.0592088    0.0465883   -0.00195087   0.102141      0.167723     0.00476436  -0.0142091   0.0522511    0.275613    -0.094032      0.0334863   -0.0609379    0.0605086   -0.210081    -0.0739571   -0.173857     0.053712     0.0520818
  0.12039    -0.0491733     0.0253263   -0.0768844    0.00647665   0.162956      0.290673   -0.227954     -0.124681     0.161051     0.204475    -0.0673724     0.0431957   -0.0551155    0.0844489  -0.100086     0.106093    -0.046044     -0.0495575   -0.0238602   -0.146927     0.15605      0.0648585   -0.123274     0.129701     0.0640907
 -0.0250587   0.0248968     0.0534374    0.0624599    0.103068     0.191257      0.12616    -0.0917628    -0.0443129   -0.0188226    0.130639     0.149019      0.0489938   -0.0132655    0.0256626   0.255776    -0.0186564    0.152187      0.142697    -0.0561042    0.0259054    0.0136216    0.00348412   0.119559    -0.0681962   -0.0812963
 -0.0545683   0.00502328   -0.126804     0.0487772   -0.031545    -0.0462254     0.014414    0.00466658    0.0831049    0.0199066    0.0262445    0.0276986     0.00350783   0.00581073   0.0523     -0.0313996   -0.0643541    0.00429108   -0.0148554   -0.0939942    0.059188    -0.00203521  -0.0650866    0.00245922  -0.0329415   -0.0165666
  0.0202952   0.0214231     0.0113989    0.113141    -0.131707    -0.0427652     0.127448   -0.180277      0.214232    -0.192798    -0.0918786   -0.156954      0.00261212   0.129363    -0.0324075  -0.0458217    0.0039959   -0.0221371    -0.0509105   -0.121425     0.113271    -0.00826239   0.132573     0.135111     0.0458477    0.0553473
  0.0150817   0.0731377    -0.042584     0.0745864   -0.0343605   -0.0485056    -0.0800376  -0.0853534    -0.0677103   -0.0194928   -0.0234567    0.000184617  -0.0368074    0.036539    -0.0604355  -0.0821291    0.0608854    0.0492512    -0.108211    -0.0405891   -0.0229897    0.045066     0.015438     0.0423937   -0.0478471    0.104836
 -0.11247     0.055238     -0.0224988    0.0707941    0.0793557    0.0829814     0.146335    0.0358845     0.0344281   -0.0172761   -0.0151065   -0.0723795     0.0566812    0.00754141   0.0315898   0.172597    -0.0036165   -0.0439153     0.049088     0.0571401   -0.0272302    0.0451701   -0.0403513    0.0642008   -0.109027    -0.158508
  0.07427    -0.0386006    -0.0544549   -0.00418245   0.0702488    0.0188071     0.0193916   0.00936056   -0.110848     0.0938017    0.0261596    0.14187       0.0447621   -0.0708135    0.0543553  -0.0403294    0.0432674    0.000561908  -0.022287     0.0307966   -0.0905673    0.0656307   -0.00340771  -0.0270656    0.00724937  -0.0448246
 -0.0461049   0.0928595     0.286015    -0.0575719    0.066232     0.0250755    -0.0848822   0.0495699     0.029809     0.00673315   0.0503036    0.0660866     0.0751288    0.0882846   -0.183173   -0.0846679    0.247586     0.0297014    -0.0535677    0.103827    -0.117975     0.180866     0.0796503    0.0194952    0.215097     0.0198687
 -0.127034    0.0609622     0.10919      0.168163     0.102254     0.139405     -0.0544295   0.0146954    -0.0017139   -0.0289723   -0.00831103  -0.0384482     0.0162097    0.0108403   -0.0551188   0.0153922    0.183725    -0.208372      0.0672748   -0.664857     0.149765     0.117637     0.111836    -0.0521735   -0.272885     0.0666742
 -0.0655459   0.00150347   -0.0909889   -0.141116     0.094958     0.0809565    -0.0809478   0.0137566    -0.15114     -0.0846487    0.0146231   -0.0886167     0.0028512   -0.00132245  -0.0816924   0.0124266    0.178933    -0.144837      0.0337636    0.747413    -0.0321564    0.11854     -0.018693     0.0108387   -0.208778     0.079204
 -0.222038    0.0970478    -0.00610107   0.0140542   -0.12565      0.171456      0.139923   -0.000819668  -0.192639    -0.0805896   -0.0334132    0.0182935     0.173324     0.0203048   -0.618931    0.113536    -0.0402766    0.0358459     0.0594813    0.0286915   -0.0042775    0.0963242    0.170903     0.0387733    0.0662733    0.00919158
 -0.235596    0.0728522     0.0427284   -0.248386    -0.0183689    0.247476     -0.260239    0.00618677   -0.23488     -0.0232824    0.0934116   -0.0799246    -0.0568053    0.0321253    0.549753    0.0809447   -0.0209689    0.0464933     0.0447044    0.228627    -0.0451965    0.077866     0.146566     0.00720088   0.157523    -0.0645355
 -0.111432   -0.0844192     0.0194668   -0.004492    -0.021665     0.0251253     0.0698025   0.0751465     0.0769962   -0.0950516    0.0528455   -0.207102      0.115487     0.227255    -0.100441    0.0272265   -0.0298835    0.0410866    -0.0300509   -0.132597    -1.70754      0.0549488   -0.00954164   0.178026     0.152538    -0.204946
 -0.12398     0.013265     -0.0193069    0.103724    -0.114554    -0.008179      0.0759908   0.110744      0.0829235   -0.0522859    0.0519113    0.0305511     0.196106     0.14353     -0.108484   -0.0416616   -0.0726797   -0.0513194    -0.0396566   -0.0357217    1.67544      0.0272502   -0.208241     0.18031      0.122964    -0.199626
 -0.0315468  -0.225942      0.0832339    0.161122    -0.115558    -0.0153231    -0.13729     0.125039      0.0572126    0.0146415    0.128579    -0.0316181     0.112555    -0.167845    -0.0256547  -0.130045     0.128457     0.00548508    0.078766    -0.117591     0.0662224    0.108771     0.0305332   -0.0340818   -0.132682     0.0514008
 -0.0944591  -0.00144116    0.034781    -0.126139    -0.0811434   -0.000771812  -0.023241   -0.0115584     0.00737039   0.0476416    0.00472936   0.121479     -0.12807     -0.161097     0.0397443   0.0116487    0.0273904    0.0960933    -0.153667     0.0468034    0.0540178   -0.0187532   -0.0396424    0.0136213    0.0707088   -0.0351258[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      3
│      4
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.101076
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      6
│     16
│     18
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.085160
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     17
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.089046
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      6
│     16
│     18
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.084536
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     17
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.094542
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      6
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.089512
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     17
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.087882
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      6
│     16
│     18
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.084513
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│      4
│     16
│     17
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.094528
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      3
│      4
│      5
│      6
│     16
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.089510
┌ Info: EM with 100000 data points 10 iterations avll -1.089510
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.092991e+05
      1       7.422658e+05      -1.670333e+05 |       32
      2       7.090909e+05      -3.317492e+04 |       32
      3       6.916871e+05      -1.740373e+04 |       32
      4       6.809428e+05      -1.074433e+04 |       32
      5       6.741968e+05      -6.745989e+03 |       32
      6       6.695779e+05      -4.618909e+03 |       32
      7       6.665213e+05      -3.056660e+03 |       32
      8       6.644360e+05      -2.085296e+03 |       32
      9       6.632052e+05      -1.230777e+03 |       32
     10       6.622878e+05      -9.173526e+02 |       32
     11       6.614204e+05      -8.674770e+02 |       32
     12       6.603401e+05      -1.080224e+03 |       32
     13       6.590251e+05      -1.315018e+03 |       32
     14       6.577342e+05      -1.290871e+03 |       32
     15       6.562389e+05      -1.495336e+03 |       32
     16       6.547380e+05      -1.500892e+03 |       32
     17       6.535444e+05      -1.193635e+03 |       32
     18       6.530076e+05      -5.367613e+02 |       32
     19       6.527653e+05      -2.423550e+02 |       32
     20       6.526735e+05      -9.179703e+01 |       32
     21       6.526242e+05      -4.931573e+01 |       31
     22       6.525998e+05      -2.437094e+01 |       31
     23       6.525850e+05      -1.477010e+01 |       30
     24       6.525737e+05      -1.129073e+01 |       28
     25       6.525685e+05      -5.185828e+00 |       26
     26       6.525657e+05      -2.837554e+00 |       21
     27       6.525644e+05      -1.253090e+00 |       17
     28       6.525632e+05      -1.238919e+00 |       19
     29       6.525622e+05      -9.871802e-01 |       10
     30       6.525615e+05      -6.784487e-01 |       13
     31       6.525609e+05      -6.193182e-01 |       13
     32       6.525605e+05      -4.647566e-01 |        7
     33       6.525601e+05      -3.233683e-01 |        8
     34       6.525598e+05      -3.049356e-01 |        7
     35       6.525595e+05      -3.697753e-01 |       13
     36       6.525591e+05      -3.426837e-01 |        7
     37       6.525589e+05      -2.587365e-01 |        7
     38       6.525586e+05      -2.377946e-01 |        4
     39       6.525585e+05      -1.554649e-01 |        4
     40       6.525584e+05      -9.433548e-02 |        5
     41       6.525582e+05      -1.622601e-01 |        6
     42       6.525579e+05      -3.047878e-01 |       10
     43       6.525573e+05      -5.894815e-01 |       11
     44       6.525567e+05      -5.710407e-01 |        9
     45       6.525562e+05      -5.571957e-01 |       13
     46       6.525556e+05      -5.752337e-01 |       11
     47       6.525551e+05      -4.662378e-01 |        7
     48       6.525549e+05      -2.858018e-01 |        8
     49       6.525542e+05      -6.087551e-01 |        8
     50       6.525537e+05      -5.573005e-01 |       10
K-means terminated without convergence after 50 iterations (objv = 652553.6899571312)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.347441
[ Info: iteration 2, average log likelihood -1.304432
[ Info: iteration 3, average log likelihood -1.262534
[ Info: iteration 4, average log likelihood -1.222163
[ Info: iteration 5, average log likelihood -1.185082
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.142421
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.108940
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      9
│     16
│     17
│     22
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.051630
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      8
│     10
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.097304
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.120424
[ Info: iteration 11, average log likelihood -1.080178
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     10
│     11
│     16
│      ⋮
│     25
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.021105
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.145534
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.111960
[ Info: iteration 15, average log likelihood -1.070016
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     10
│     16
│     17
│     22
│     24
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.016697
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      8
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.126338
[ Info: iteration 18, average log likelihood -1.119956
[ Info: iteration 19, average log likelihood -1.067486
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     10
│     16
│     17
│      ⋮
│     25
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.018982
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      8
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.133872
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.105484
[ Info: iteration 23, average log likelihood -1.073423
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     10
│     16
│     17
│      ⋮
│     25
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.018308
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.131961
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.109684
[ Info: iteration 27, average log likelihood -1.065852
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     10
│     16
│     17
│     22
│     24
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.012179
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      8
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.125622
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.115807
[ Info: iteration 31, average log likelihood -1.066396
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      9
│     10
│     11
│      ⋮
│     24
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.012790
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.144414
[ Info: iteration 34, average log likelihood -1.119889
[ Info: iteration 35, average log likelihood -1.074278
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     17
│     22
│     24
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.027436
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.111480
[ Info: iteration 38, average log likelihood -1.112640
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      8
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.053890
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│      ⋮
│     22
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.044605
[ Info: iteration 41, average log likelihood -1.148429
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.094103
[ Info: iteration 43, average log likelihood -1.072263
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      8
│      9
│     10
│      ⋮
│     24
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.002856
[ Info: iteration 45, average log likelihood -1.168995
[ Info: iteration 46, average log likelihood -1.116729
[ Info: iteration 47, average log likelihood -1.072077
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     10
│     17
│     24
│     25
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.025078
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     12
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.104854
32×26 Array{Float64,2}:
 ┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      8
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.093856
┌ Info: EM with 100000 data points 50 iterations avll -1.093856
└ 59.0 data points per parameter
-0.170416    -0.0616391    -0.177315    -0.125087     0.0282973   -0.0555388    0.0669096    0.0509708   -0.0272299    0.125854    -0.194309    -0.0563973   -0.0409562    0.218933    -0.077086     -0.0347087   -0.113999    -0.10667     -0.0127613   -0.0577148  -0.114329    0.0685409    0.00577794  -0.158222     0.00210549   -0.0725677
 -0.0949308    0.0301659     0.00328889   0.0081749    0.098552     0.101777    -0.0684025    0.0151403   -0.0805808   -0.0582915    0.00483942  -0.0649368    0.0104099    0.00630849  -0.070146      0.0157909    0.181164    -0.173665     0.0515354    0.0719134   0.0569057   0.118612     0.0394713   -0.0185669   -0.243087      0.0730379
  0.0879774    0.200826     -0.15711      0.0683859   -0.0159867   -0.0991646   -0.170388    -0.0966262   -0.0928851    0.0709952    0.00595536  -0.0110736    0.0515867   -0.00245917  -0.223201     -0.14714      0.0899804    0.0384984   -0.00124377   0.0857384   0.0806794   0.025113    -0.0207538    0.0802589   -0.0405169     0.10169
  0.0761072    0.151341      0.0450477    0.00614315   0.026459    -0.0456511    0.0911873    0.0767115   -0.0739641    0.00683673  -0.173356    -0.169957    -0.148495     0.0728006   -0.0809041    -0.165966    -0.00269455  -0.142724     0.0133182   -0.147302    0.0510951   0.00824445  -0.0457603    0.00616068   0.0548728    -0.180875
 -0.00376763   0.0294184    -0.00279173   0.009311     0.00761072   0.0371149   -0.056655    -0.115693    -0.0239327   -0.115266     0.0346181   -0.0195655   -0.120998     0.062966     0.128489     -0.0460719    0.0833526    0.0982688   -0.116444    -0.180572   -0.0936667   0.181013     0.0436585   -0.00406171  -0.0191307     0.077555
 -0.228706     0.0844604     0.020658    -0.12126     -0.0684969    0.207659    -0.0702519    0.00295901  -0.214176    -0.0513295    0.0356827   -0.0310967    0.0530076    0.025986    -0.00366488    0.0985443   -0.0301537    0.0420155    0.0509573    0.137526   -0.0260261   0.0867413    0.155908     0.021988     0.11295      -0.0302613
 -0.11436     -0.0890009     0.0359652   -0.0364693    0.0497142    0.0461589    0.0718021    0.0450292    0.0699729   -0.126096     0.0524093   -0.35533      0.129552     0.243595    -0.103013      0.0157091   -0.0287955    0.0596461    0.0162659   -0.129838   -2.09584     0.0664606    0.0218201    0.165802     0.163299     -0.206937
  0.15192      0.0408502    -0.116582    -0.060089     0.0662058    0.0170803    0.0557816   -0.0216852   -0.106511     0.116618     0.0239038    0.135958    -0.030084    -0.00535729  -0.0028386    -0.0725799    0.0437434   -0.0255286    0.00548465   0.0563197  -0.126286    0.0345107   -0.00247425  -0.100058     0.0727057    -0.0722684
  0.0336246   -0.163518      0.0512592   -0.148388     0.0239595    0.148676     0.107016    -0.180881    -0.177649     0.0807119    0.16515     -0.142029     0.0613616   -0.0292795    0.0555407     0.0337044    0.0908596    0.0586633    0.0289624   -0.0168106  -0.0678594   0.10785      0.0493719   -0.0462928    0.0371399     0.0292121
  0.096824     0.0379715     0.12217      0.132793     0.0831399    0.00411825   0.0186063    0.0770469   -0.0122555    0.0686608   -0.00849404   0.0602316    0.0543706    0.0886694   -0.0403783     0.00465248   0.0255248   -0.0466946   -0.120391     0.0480363   0.0451851  -0.221205    -0.0750751   -0.0163347    0.0746236    -0.0523937
 -0.0348014   -0.351893      0.0641158    0.199201    -0.115804    -0.062856    -0.132587     0.1415       0.0581699    0.0154326    0.18532     -0.0316121    0.143548    -0.22098     -0.00412499   -0.142182     0.121657     0.00802406   0.103521    -0.143701    0.0661109   0.146562     0.0303281   -0.0759856   -0.155872      0.0453317
 -0.0471787   -0.000541795   0.0910731    0.149852    -0.0883234   -0.0754359   -0.0126988   -0.0194629   -0.0850825   -0.0110211   -0.117225     0.0198341   -0.0265704    0.0512118   -0.0564923    -0.040309    -0.0276577    0.00782584  -0.166785    -0.0729176  -0.0473918  -0.403828     0.0281234    0.0372564   -0.153697      0.144923
 -0.064954    -0.0509303     0.0289346    0.0685677    0.0214153    0.00379994  -0.11137      0.0329052    0.115949    -0.0543499   -0.10173      0.0528669   -0.0309602   -0.10938     -0.0113096     0.0727034    0.129005    -0.0255545    0.0546174   -0.0908704  -0.100593   -0.0131906   -0.054625     0.110415     0.000726921   0.0644106
 -0.0760809   -0.163409     -0.0219943    0.0155258    0.193989     0.0668935    0.107205     0.0117289    0.114589    -0.0751024    0.0771373    0.0296868   -0.0343601    0.0038973   -0.0895203     0.104164     0.0449127   -0.0276814    0.0253789    0.161845    0.0292791   0.0152141   -0.0346456    0.199743    -0.133641     -0.134435
  0.0172485    0.0246165     0.0963297   -0.133149     0.0219903   -0.039427    -0.038599     0.0201447    0.108945     0.143114     0.0353636   -0.00428381   0.0713866    0.183197     0.0714153     0.00427228   0.0423834   -0.201053    -0.0157562   -0.0421703  -0.0825784   0.0637159    0.0392268    0.0917023   -0.0169553    -0.137374
  0.116307    -0.0431257     0.0310636   -0.0638139    0.00778308   0.164895     0.279782    -0.22101     -0.122243     0.159504     0.202163    -0.070639     0.0427075   -0.0513459    0.0802925    -0.0915579    0.107256    -0.041143    -0.0469596   -0.0248178  -0.145785    0.152447     0.0600773   -0.122046     0.117653      0.0586265
 -0.0247386    0.0249237     0.0633563    0.0923752    0.0900853    0.189633     0.11617     -0.0531962   -0.0301629   -0.0220244    0.130111     0.172286     0.05319     -0.0157761    0.0261111     0.253004    -0.0311795    0.152298     0.142932    -0.0747868   0.0511426   0.00977551   0.010012     0.139228    -0.0733352    -0.087817
 -0.0577405    0.0588738    -0.150465     0.119717    -0.0586711   -0.0661522    0.0553938    0.00817432   0.0532962    0.0423699    0.0546937    0.00289049   0.0160905    0.0389749    0.120017     -0.0482734   -0.132204     0.00806503  -0.0187544   -0.115465    0.146211    0.00782695  -0.0461993   -0.0516194   -0.0432365    -0.0613769
 -0.138854     0.250114     -0.0244858    0.11273     -0.0076944    0.103568     0.179894     0.0458911   -0.0335024    0.0280509   -0.0932712   -0.173073     0.141345     0.0100691    0.142995      0.226231    -0.04809     -0.059501     0.0729171   -0.0474519  -0.0717093   0.0592792   -0.0422817   -0.098559    -0.0900534    -0.193615
 -0.0684825    0.0067117    -0.0401829   -0.110852    -0.157793    -0.0942456   -0.00818158   0.105701     0.0104397   -0.0193932    0.0533659    0.100037    -0.239999    -0.164932     0.0177767    -0.0426728   -0.00238136   0.0644894   -0.106429    -0.068294    0.0524161  -0.043186    -0.140799     0.00107309  -0.0332331    -0.188552
  0.0989585    0.167682     -0.00307742   0.174148     0.0249564    0.0330272   -0.199683     0.0388439    0.104293    -0.219028     0.0873239    0.0723439    0.12954     -0.0302978    0.028723     -0.122903     0.149761     0.031391     0.0336282   -0.01228     0.104908   -0.0173256   -0.114119     0.217246     0.049123      0.0731126
 -0.0558847    0.0714309     0.275164    -0.0283501    0.0263274    0.0176804   -0.0731614    0.0614901    0.0410295    0.00717285   0.0341353    0.0732732    0.0831889    0.0848324   -0.210695     -0.0721252    0.233739     0.0416101   -0.05187      0.133149   -0.122337    0.397817     0.0787865    0.0267895    0.242463      0.0183265
 -0.117133    -0.0290096     0.135561    -0.140255     0.00815999   0.109547    -0.0448402   -0.141788     0.00273635   0.127164    -0.0458066    0.127956     0.00935105  -0.154285     0.0503771     0.0614728    0.067686     0.111897    -0.197561     0.162368    0.0550549   0.0153975    0.0692888    0.0252453    0.193867      0.143635
  0.0504767    0.088022      0.0250018    0.105936    -0.0790125   -0.0674232   -0.0346253    0.18547     -0.139174     0.0395262   -0.0522192   -0.0407588   -0.045151     0.0268614    0.0937726    -0.0306942    0.134611    -0.0216982   -0.111728    -0.0223492  -0.14722    -0.186073    -0.0149758   -0.0616727    0.136994     -0.137765
 -0.00772585  -0.123725     -0.038712     0.0683027    0.0929323    0.0376658   -0.0116678    0.0516144   -0.135737     0.0625327    0.0442949    0.164441     0.131105    -0.216004     0.122516     -0.006143     0.0361351    0.034909    -0.0408318   -0.0285951  -0.0471574   0.321694    -0.00438383   0.063285    -0.104166     -0.0255961
  0.0842218   -0.109766      0.0312177   -0.181205     0.070435    -0.146608    -0.00202726  -0.0734396   -0.148529    -0.0726731    0.0610297   -0.141058    -0.0159022    0.0920299    0.0691819     0.282856     0.117604     0.072415     0.0477477    0.04828    -0.0597456   0.0373408   -0.080668    -0.0123576    0.0148947     0.0768327
  0.020319     0.0196685     0.0101119    0.116176    -0.131611    -0.0398438    0.126198    -0.177431     0.213562    -0.190971    -0.0888725   -0.157865     0.00139481   0.133751    -0.0328686    -0.0477773    0.00270658  -0.0223154   -0.0499641   -0.121146    0.113407   -0.00949996   0.133202     0.14011      0.0423057     0.0549257
  0.0610088    0.0722515     0.00196693  -0.00604496   0.0465772    0.0606278    0.0484614   -0.136962     0.134485     0.042657    -0.225868    -0.0159664    0.0366937   -0.142643    -0.101945      0.0331254   -0.0584834   -0.18712      0.0283825   -0.127577    0.043252   -0.0258478   -0.0449555   -0.0897725   -0.131103     -0.00575644
  0.135438     0.00039983    0.0231934   -0.0125833   -0.0602331    0.0125139    0.031171    -0.0463263    0.0692191   -0.0173845    0.16613     -0.136172    -0.0496649    0.0639907   -0.172612      0.143482    -0.0761581   -0.00359951   0.148042     0.10135    -0.149816    0.036854    -0.0910333   -0.087581     0.153137      0.0760419
  0.221868     0.0281051     0.0367832    0.0353183    0.0591788   -0.0235568    0.175883     0.0818847   -0.044208     0.0288346    0.019095     0.109151     0.180705    -0.0137075    0.000598505   0.0560998    0.303437    -0.0869195    0.0356887   -0.0704279   0.0719249  -0.232623    -0.0882712   -0.187519     0.0589706     0.0722802
 -0.118546    -0.0130361    -0.0125983    0.0860234   -0.11497     -0.00658652   0.0739269    0.11223      0.0835289   -0.052978     0.0524108    0.0170237    0.166352     0.162901    -0.104358     -0.0199898   -0.0607629   -0.0309862   -0.0549727   -0.0664052   0.815988    0.0300218   -0.161245     0.185243     0.128842     -0.20117
  0.271395     0.0409313    -0.0361589   -0.0297899   -0.102297    -0.00278229   [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
0.0800901   -0.169766    -0.202259     0.0645772    0.0795666    0.0735869   -0.00556594   0.178923    -0.148845     -0.167653    -0.093709    -0.0260725    0.00524452   0.0104507   0.123603   -0.0190683   -0.0875463   -0.0393532   -0.120498     -0.0173944┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.075777
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     10
│     11
│     17
│     24
│     25
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.033353
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│      9
│     12
│     17
│     22
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.034501
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     10
│     11
│     24
│     25
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.042388
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     17
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.050845
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      8
│     10
│     11
│     12
│      ⋮
│     25
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.004020
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.064902
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      9
│     10
│     11
│     17
│     24
│     25
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.028023
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     12
│     22
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.035561
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│     10
│     11
│     16
│      ⋮
│     25
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.035931
┌ Info: EM with 100000 data points 10 iterations avll -1.035931
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.148648    -0.163563      0.0268826     0.0911514    0.0781364  -0.0199085   -0.0513676    -0.108892     -0.195931    -0.000542081   0.00471774   0.31663     -0.124032    -0.123617    -0.012315      0.0439954   -0.0587454   -0.121749     0.0504275   0.0669231     0.00325564  -0.106342     0.0927307   -0.127511     0.00578053  -0.00297297
 -0.0219379   -0.116136      0.134632     -0.149842    -0.0464603  -0.159572     0.118429      0.0012297    -0.042348    -0.0406874    -0.0507134    0.0945108   -0.0112053    0.0698041   -0.044735     -0.0621544    0.0669977    0.117653     0.112398   -0.0983705     0.026229    -0.0563149    0.0693536   -0.0314137    0.0216027    0.0786511
 -0.0465164   -0.186592     -0.0525264    -0.0665967   -0.1227     -0.0414357    0.000864247   0.0232514    -0.0331138    0.134767     -0.074897    -0.0600899    0.0301836    0.00583704   0.0117377    -0.0571748   -0.00653659  -0.176819    -0.0146802   0.0894649     0.0153994   -0.10285      0.0217592    0.00907332   0.229638     0.139557
 -0.15201     -0.0192612    -0.140762     -0.00382153   0.0651951   0.120965     0.0170402     0.00956648    0.112242     0.160694      0.0161392   -0.126741    -0.0680218   -0.262376    -0.19289      -0.131326    -0.0198723    0.0211034    0.0174136   0.144696      0.119977    -0.0792391    0.00104639   0.152       -0.00257123   0.148563
 -0.0633827    0.0116441     0.0502       -0.178779    -0.0992073  -0.123181     0.0028353    -0.032354     -0.0635657    0.172548     -0.115432    -0.00574683  -0.0262766    0.110077     0.129634     -0.0320514    0.0260565    0.00266363  -0.0873201  -0.0334282    -0.0939769   -0.186724    -0.167048     0.112123    -0.0606339   -0.0383972
  0.0916679   -0.102302      0.00276882   -0.107146     0.163945   -0.0388722   -0.0362826    -0.0498702     0.0214951   -0.0465634     0.0310227    0.0845999    0.15248      0.0265819    0.00148307    0.0769371    0.158996    -0.0486007   -0.047255    0.00642408    0.123532    -0.0649321    0.0940738    0.130601     0.166743    -0.0578412
  0.10164     -0.0320863    -0.048953     -0.110552     0.0318115  -0.113886     0.1406       -0.160275     -0.0364268    0.0710692     0.0281885   -0.0787055   -0.0298346    0.0317047   -0.0943012    -0.013052    -0.00936687   0.0968495   -0.118532    0.00010928    0.120842     0.00632129  -0.0848534    0.0666528   -0.113788     0.298115
  0.10089      0.0779662    -0.0694355    -0.0554553    0.0297765  -0.112839    -0.0279067     0.000492315  -0.0438323    0.0019402     0.102435     0.201049    -0.0445754   -0.0848333   -0.098571      0.249014     0.0357834   -0.129991     0.0188455  -0.000932809   0.0182873    0.0845819   -0.152416    -0.0538069    0.0332586   -0.00388346
  0.115814     0.0956219    -0.0287134     0.0496145   -0.0114284  -0.138808     0.0113418    -0.103065     -0.11436      0.138842      0.158948     0.185949     0.0449494   -0.176385     0.0238539     0.16818     -0.00674891   0.0739686   -0.110598    0.0442071    -0.0169023   -0.0192003   -0.00983596  -0.0930102   -0.0865221    0.195498
  0.0147075    0.116744      0.0127361    -0.00742238  -0.126974   -0.0349747   -0.0358416     0.157381     -0.0376165    0.163948     -0.161194    -0.0630626    0.0255435   -0.0453098   -0.0856227     0.050766    -0.0982385    0.0704501    0.0289433  -0.0306987    -0.14183      0.157644    -0.0238011   -0.118298     0.142152     0.181638
 -0.119892     0.147518      0.0269989     0.0123873   -0.0473202  -0.0420848    0.0927584     0.12508       0.0838921   -0.098195      0.144836    -0.132424    -0.0498252   -0.0204044    0.069431      0.0616347    0.116431     0.106363     0.0627835  -0.110386      0.148318     0.0697487    0.00183556  -0.0553325    0.122006    -0.0531781
  0.188474     0.145076      0.103836      0.0021251    0.0451824  -0.116056    -0.0265876    -0.0299392    -0.0879112   -0.0519743    -0.0283748    0.0951981    0.154287    -0.00719265  -0.174627     -0.0366599   -0.128659    -0.106591     0.125371   -0.0920073    -0.181284     0.0870924    0.0270373   -0.0513437   -0.0886952    0.0357889
  0.117008     0.0360105    -0.0889424    -0.0117289   -0.0519656  -0.135451     0.0613293    -0.139734      0.115564    -0.0532626    -0.0459353    0.160191     0.0807168    0.138391    -0.000454931  -0.0197955   -0.13833     -0.0802943   -0.102718    0.0600537     0.0481313    0.0219797    0.0245678   -0.107989    -0.0249217    0.0352384
 -0.125478     0.212164     -0.0270497    -0.072114    -0.0576584  -0.145246    -0.0389447     0.025462     -0.137698    -0.153327      0.196811    -0.104516    -0.200959     0.153732    -0.20187       0.0304639   -0.136466    -0.169603    -0.064352    0.0382763    -0.0947507   -0.0812411   -0.0238862   -0.022165     0.0326937    0.0789175
 -0.0346692    0.0714922    -0.0844496     0.0528271    0.0306796   0.102263    -0.0906897    -0.0748842     0.108953    -0.127449      0.111796    -0.106807     0.0209886   -0.0671368   -0.073038      0.0346662   -0.143637     0.0642515   -0.0704908   0.0843873    -0.149251     0.0561323    0.0295291    0.0489507    0.0332783    0.0507323
  0.045757     0.0454274     0.127599     -0.0987075    0.0101238   0.0854772   -0.0784156     0.118687     -0.0496933    0.240607     -0.220875    -0.097308    -0.0165096   -0.00721568   0.0647916    -0.0871513    0.148914     0.00591414  -0.174961   -0.0399116    -0.027377     0.0608288    0.0863508    0.056419     0.0221299   -0.0976278
 -0.223808     0.0435851     0.0184558    -0.0177292    0.0320602   0.072755     0.0591078    -0.100797     -0.0887756    0.100218      0.00408903  -0.0404328    0.271593     0.107711    -0.0122196     0.0837519   -0.0208931    0.150117    -0.0373694   0.110876      0.0156579   -0.0398094    0.083631    -0.362418     0.0542683   -0.0903727
  0.0974345   -0.0718655     0.227839      0.158459    -0.0162099  -0.0657733    0.0258017    -0.11273      -0.124917    -0.0918257     0.00230648   0.0379941   -0.00551885   0.21974     -0.0308758     0.0889156   -0.25504      0.0257721   -0.0924704  -0.152132     -0.00198519  -0.036527    -0.0555938   -0.0263386    0.105234     0.131026
 -0.132037     0.0905756    -0.0189984    -0.112091    -0.0208833   0.0686015    0.11788      -0.0459009    -0.033046    -0.0550754     0.0534206   -0.0262049    0.0172561   -0.00102007  -0.038882      0.018401     0.012235     0.0873684   -0.0705108   0.030415      0.0197355   -0.130945    -0.0156771   -0.0584904    0.0870092   -0.0974777
  0.0999088    0.000745567   0.193031     -0.118085     0.163855   -0.0669933    0.0681185    -0.116399     -0.0657792   -0.0750741     0.00403729  -0.161228    -0.0366655   -0.0183744    0.132336     -0.0066111   -0.0668803   -0.0114081   -0.0838041   0.0474041     0.0427696   -0.0342613   -0.0657064    0.025083     0.144482    -0.115732
 -0.0463271    0.149747     -0.104335     -0.0615813   -0.0993101   0.0460113   -0.0546635    -0.0725715     0.0108016   -0.132777     -0.0281385    0.0725301   -0.0948971    0.0408355    0.0382916     0.0779426   -0.16464      0.0124634    0.0625185   0.141462     -0.00130473   0.146946     0.00824845  -0.0411444   -0.143114    -0.19023
 -0.097006     0.00689709    0.0742947    -0.166409     0.0943019  -0.194981    -0.117982     -0.250455      0.0262775   -0.0954226    -0.14741      0.00822562  -0.0775289   -0.0401093    0.204194     -0.0338781   -0.00153621  -0.139906    -0.0119283   0.0795529     0.128374    -0.154759     0.04227     -0.0281339    0.0177001   -0.201066
  0.140578     0.0870027    -0.0139221     0.0432044   -0.0702847   0.0333005   -0.0541823    -0.0677432    -0.136069    -0.125791      0.0284871    0.144059    -0.106467    -0.12671     -0.0486336    -0.141713    -0.0981645    0.119882    -0.0176204  -0.0275327    -0.0105298    0.156185     0.13562     -0.170231     0.0261962   -0.0537466
  0.0246516   -0.0651776     0.0404747    -0.0379305    0.194621    0.0276593   -0.218613      0.0553743     0.119615    -0.180918     -0.0420914   -0.145693     0.0236692   -0.0572814   -0.0155752    -0.0374666   -0.06867      0.171909     0.0245287   0.0235622    -0.0880364   -0.0390239    0.017756    -0.0527161   -0.0717333    0.0359113
 -0.00198775   0.101063     -0.151157     -0.116901    -0.115439    0.207504     0.00576323   -0.0160879    -0.0666251   -0.135534      0.00750218  -0.0776992    0.12538     -0.0065851   -0.212196      0.0813049    0.145583    -0.0712009    0.0370585   0.0107511     0.129446    -0.158091    -0.0475765   -0.0123226    0.0464627   -0.163584
 -0.200253     0.0526799    -0.106978      0.0280719   -0.0485679   0.0217428    0.111437     -0.0912497     0.00812887   0.0455309     0.0249024   -0.0218501   -0.0898854    0.00733116  -0.0389961    -0.0299037    0.149384    -0.0746761   -0.119104   -0.0306855    -0.149059     0.0568871    0.167519    -0.0661883    0.0793989   -0.0153913
  0.210803    -0.0155227    -0.170017     -0.0230916   -0.0430267   0.0585615   -0.0226783     0.042498     -0.00359606  -0.0114698     0.0661073    0.187205    -0.0760215   -0.00322575  -0.0622578     0.00279296  -0.139358    -0.231235    -0.0698265  -0.0338602     0.120939    -0.23764      0.0812444   -0.0525876    0.0905447   -0.0734893
  0.0379281   -0.0215998    -0.000617907   0.0451427   -0.113146   -0.110293    -0.122261     -0.0804159    -0.247193     0.047112     -0.127603    -0.0562379   -0.0623073   -0.268097    -0.0485978     0.0889878    0.0033047    0.0438901    0.141669    0.179808     -0.100328     0.0505642   -0.0339381    0.0451839    0.0106988    0.108456
  0.0554119    0.037299      0.152534      0.0336232   -0.167711    0.104513    -0.0543836    -0.0914352     0.0690581    0.0902908     0.142961     0.0574765    0.0843797    0.0945775   -0.0888965    -0.144094    -0.0618491   -0.123751     0.0956772  -0.0623112     0.072838     0.113162     0.0326644    0.0318489   -0.059105    -0.129706
 -0.054238    -0.0427185     0.0541844     0.0452751   -0.0463277  -0.0404204   -0.057432     -0.0376887    -0.138022    -0.0310985     0.0212119   -0.159807    -0.0965842   -0.0456115    0.0209754     0.0346087    0.00911067   0.0149652   -0.0938358   0.152577      0.0376019   -0.0564923   -0.0370427    0.0171951   -0.0349189   -0.09018
 -0.0116019   -0.160435      0.0647221     0.0425863    0.121606    0.00332655   0.0665057     0.0797594    -0.216336     0.26936      -0.0461836   -0.240064    -0.0113493   -0.00982957  -0.00727237    0.145747    -0.113013    -0.0275293   -0.0490454   0.0744492     0.322921    -0.131648    -0.124894     0.0803095    0.0530731   -0.0280795
 -0.0472719    0.132331      0.110938     -0.0277385   -0.0639162  -0.0255832    0.0366238    -0.0841564    -0.0805494   -0.159213      0.142299    -0.0260288    0.0598566   -0.172805     0.0301494    -0.0635987    0.19877      0.0163402   -0.111529   -0.190152      0.0446778   -0.0595011    0.124451    -0.0699984   -0.0671046   -0.0767194kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4229826566736414
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423001
[ Info: iteration 2, average log likelihood -1.422952
[ Info: iteration 3, average log likelihood -1.422914
[ Info: iteration 4, average log likelihood -1.422858
[ Info: iteration 5, average log likelihood -1.422762
[ Info: iteration 6, average log likelihood -1.422564
[ Info: iteration 7, average log likelihood -1.422121
[ Info: iteration 8, average log likelihood -1.421217
[ Info: iteration 9, average log likelihood -1.419873
[ Info: iteration 10, average log likelihood -1.418636
[ Info: iteration 11, average log likelihood -1.417940
[ Info: iteration 12, average log likelihood -1.417655
[ Info: iteration 13, average log likelihood -1.417548
[ Info: iteration 14, average log likelihood -1.417507
[ Info: iteration 15, average log likelihood -1.417491
[ Info: iteration 16, average log likelihood -1.417484
[ Info: iteration 17, average log likelihood -1.417481
[ Info: iteration 18, average log likelihood -1.417479
[ Info: iteration 19, average log likelihood -1.417479
[ Info: iteration 20, average log likelihood -1.417478
[ Info: iteration 21, average log likelihood -1.417478
[ Info: iteration 22, average log likelihood -1.417478
[ Info: iteration 23, average log likelihood -1.417478
[ Info: iteration 24, average log likelihood -1.417478
[ Info: iteration 25, average log likelihood -1.417478
[ Info: iteration 26, average log likelihood -1.417478
[ Info: iteration 27, average log likelihood -1.417477
[ Info: iteration 28, average log likelihood -1.417477
[ Info: iteration 29, average log likelihood -1.417477
[ Info: iteration 30, average log likelihood -1.417477
[ Info: iteration 31, average log likelihood -1.417477
[ Info: iteration 32, average log likelihood -1.417477
[ Info: iteration 33, average log likelihood -1.417477
[ Info: iteration 34, average log likelihood -1.417477
[ Info: iteration 35, average log likelihood -1.417477
[ Info: iteration 36, average log likelihood -1.417477
[ Info: iteration 37, average log likelihood -1.417477
[ Info: iteration 38, average log likelihood -1.417477
[ Info: iteration 39, average log likelihood -1.417477
[ Info: iteration 40, average log likelihood -1.417477
[ Info: iteration 41, average log likelihood -1.417477
[ Info: iteration 42, average log likelihood -1.417477
[ Info: iteration 43, average log likelihood -1.417477
[ Info: iteration 44, average log likelihood -1.417477
[ Info: iteration 45, average log likelihood -1.417477
[ Info: iteration 46, average log likelihood -1.417477
[ Info: iteration 47, average log likelihood -1.417477
[ Info: iteration 48, average log likelihood -1.417477
[ Info: iteration 49, average log likelihood -1.417477
[ Info: iteration 50, average log likelihood -1.417477
┌ Info: EM with 100000 data points 50 iterations avll -1.417477
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4230008615325729
│     -1.4229524996302154
│      ⋮
└     -1.4174768824555108
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417492
[ Info: iteration 2, average log likelihood -1.417446
[ Info: iteration 3, average log likelihood -1.417410
[ Info: iteration 4, average log likelihood -1.417365
[ Info: iteration 5, average log likelihood -1.417308
[ Info: iteration 6, average log likelihood -1.417236
[ Info: iteration 7, average log likelihood -1.417151
[ Info: iteration 8, average log likelihood -1.417057
[ Info: iteration 9, average log likelihood -1.416962
[ Info: iteration 10, average log likelihood -1.416870
[ Info: iteration 11, average log likelihood -1.416784
[ Info: iteration 12, average log likelihood -1.416705
[ Info: iteration 13, average log likelihood -1.416633
[ Info: iteration 14, average log likelihood -1.416568
[ Info: iteration 15, average log likelihood -1.416510
[ Info: iteration 16, average log likelihood -1.416459
[ Info: iteration 17, average log likelihood -1.416415
[ Info: iteration 18, average log likelihood -1.416377
[ Info: iteration 19, average log likelihood -1.416346
[ Info: iteration 20, average log likelihood -1.416321
[ Info: iteration 21, average log likelihood -1.416300
[ Info: iteration 22, average log likelihood -1.416283
[ Info: iteration 23, average log likelihood -1.416269
[ Info: iteration 24, average log likelihood -1.416257
[ Info: iteration 25, average log likelihood -1.416247
[ Info: iteration 26, average log likelihood -1.416239
[ Info: iteration 27, average log likelihood -1.416232
[ Info: iteration 28, average log likelihood -1.416225
[ Info: iteration 29, average log likelihood -1.416220
[ Info: iteration 30, average log likelihood -1.416215
[ Info: iteration 31, average log likelihood -1.416210
[ Info: iteration 32, average log likelihood -1.416206
[ Info: iteration 33, average log likelihood -1.416202
[ Info: iteration 34, average log likelihood -1.416199
[ Info: iteration 35, average log likelihood -1.416195
[ Info: iteration 36, average log likelihood -1.416192
[ Info: iteration 37, average log likelihood -1.416189
[ Info: iteration 38, average log likelihood -1.416187
[ Info: iteration 39, average log likelihood -1.416184
[ Info: iteration 40, average log likelihood -1.416182
[ Info: iteration 41, average log likelihood -1.416179
[ Info: iteration 42, average log likelihood -1.416177
[ Info: iteration 43, average log likelihood -1.416175
[ Info: iteration 44, average log likelihood -1.416173
[ Info: iteration 45, average log likelihood -1.416171
[ Info: iteration 46, average log likelihood -1.416169
[ Info: iteration 47, average log likelihood -1.416168
[ Info: iteration 48, average log likelihood -1.416166
[ Info: iteration 49, average log likelihood -1.416164
[ Info: iteration 50, average log likelihood -1.416163
┌ Info: EM with 100000 data points 50 iterations avll -1.416163
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4174915355896622
│     -1.4174463288667656
│      ⋮
└     -1.4161626977359167
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416172
[ Info: iteration 2, average log likelihood -1.416116
[ Info: iteration 3, average log likelihood -1.416065
[ Info: iteration 4, average log likelihood -1.416001
[ Info: iteration 5, average log likelihood -1.415921
[ Info: iteration 6, average log likelihood -1.415821
[ Info: iteration 7, average log likelihood -1.415705
[ Info: iteration 8, average log likelihood -1.415583
[ Info: iteration 9, average log likelihood -1.415466
[ Info: iteration 10, average log likelihood -1.415361
[ Info: iteration 11, average log likelihood -1.415272
[ Info: iteration 12, average log likelihood -1.415199
[ Info: iteration 13, average log likelihood -1.415139
[ Info: iteration 14, average log likelihood -1.415088
[ Info: iteration 15, average log likelihood -1.415044
[ Info: iteration 16, average log likelihood -1.415006
[ Info: iteration 17, average log likelihood -1.414972
[ Info: iteration 18, average log likelihood -1.414942
[ Info: iteration 19, average log likelihood -1.414916
[ Info: iteration 20, average log likelihood -1.414894
[ Info: iteration 21, average log likelihood -1.414874
[ Info: iteration 22, average log likelihood -1.414857
[ Info: iteration 23, average log likelihood -1.414841
[ Info: iteration 24, average log likelihood -1.414828
[ Info: iteration 25, average log likelihood -1.414815
[ Info: iteration 26, average log likelihood -1.414804
[ Info: iteration 27, average log likelihood -1.414793
[ Info: iteration 28, average log likelihood -1.414782
[ Info: iteration 29, average log likelihood -1.414772
[ Info: iteration 30, average log likelihood -1.414762
[ Info: iteration 31, average log likelihood -1.414752
[ Info: iteration 32, average log likelihood -1.414742
[ Info: iteration 33, average log likelihood -1.414731
[ Info: iteration 34, average log likelihood -1.414721
[ Info: iteration 35, average log likelihood -1.414711
[ Info: iteration 36, average log likelihood -1.414700
[ Info: iteration 37, average log likelihood -1.414689
[ Info: iteration 38, average log likelihood -1.414678
[ Info: iteration 39, average log likelihood -1.414667
[ Info: iteration 40, average log likelihood -1.414655
[ Info: iteration 41, average log likelihood -1.414644
[ Info: iteration 42, average log likelihood -1.414632
[ Info: iteration 43, average log likelihood -1.414620
[ Info: iteration 44, average log likelihood -1.414608
[ Info: iteration 45, average log likelihood -1.414596
[ Info: iteration 46, average log likelihood -1.414584
[ Info: iteration 47, average log likelihood -1.414572
[ Info: iteration 48, average log likelihood -1.414560
[ Info: iteration 49, average log likelihood -1.414548
[ Info: iteration 50, average log likelihood -1.414537
┌ Info: EM with 100000 data points 50 iterations avll -1.414537
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.416172293162923
│     -1.4161163378889887
│      ⋮
└     -1.4145366155529124
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414535
[ Info: iteration 2, average log likelihood -1.414482
[ Info: iteration 3, average log likelihood -1.414435
[ Info: iteration 4, average log likelihood -1.414382
[ Info: iteration 5, average log likelihood -1.414320
[ Info: iteration 6, average log likelihood -1.414245
[ Info: iteration 7, average log likelihood -1.414156
[ Info: iteration 8, average log likelihood -1.414056
[ Info: iteration 9, average log likelihood -1.413947
[ Info: iteration 10, average log likelihood -1.413833
[ Info: iteration 11, average log likelihood -1.413720
[ Info: iteration 12, average log likelihood -1.413610
[ Info: iteration 13, average log likelihood -1.413506
[ Info: iteration 14, average log likelihood -1.413412
[ Info: iteration 15, average log likelihood -1.413327
[ Info: iteration 16, average log likelihood -1.413253
[ Info: iteration 17, average log likelihood -1.413189
[ Info: iteration 18, average log likelihood -1.413133
[ Info: iteration 19, average log likelihood -1.413085
[ Info: iteration 20, average log likelihood -1.413042
[ Info: iteration 21, average log likelihood -1.413004
[ Info: iteration 22, average log likelihood -1.412970
[ Info: iteration 23, average log likelihood -1.412939
[ Info: iteration 24, average log likelihood -1.412911
[ Info: iteration 25, average log likelihood -1.412885
[ Info: iteration 26, average log likelihood -1.412861
[ Info: iteration 27, average log likelihood -1.412839
[ Info: iteration 28, average log likelihood -1.412818
[ Info: iteration 29, average log likelihood -1.412798
[ Info: iteration 30, average log likelihood -1.412779
[ Info: iteration 31, average log likelihood -1.412762
[ Info: iteration 32, average log likelihood -1.412745
[ Info: iteration 33, average log likelihood -1.412729
[ Info: iteration 34, average log likelihood -1.412714
[ Info: iteration 35, average log likelihood -1.412699
[ Info: iteration 36, average log likelihood -1.412685
[ Info: iteration 37, average log likelihood -1.412672
[ Info: iteration 38, average log likelihood -1.412659
[ Info: iteration 39, average log likelihood -1.412647
[ Info: iteration 40, average log likelihood -1.412635
[ Info: iteration 41, average log likelihood -1.412623
[ Info: iteration 42, average log likelihood -1.412612
[ Info: iteration 43, average log likelihood -1.412601
[ Info: iteration 44, average log likelihood -1.412590
[ Info: iteration 45, average log likelihood -1.412580
[ Info: iteration 46, average log likelihood -1.412569
[ Info: iteration 47, average log likelihood -1.412560
[ Info: iteration 48, average log likelihood -1.412550
[ Info: iteration 49, average log likelihood -1.412540
[ Info: iteration 50, average log likelihood -1.412531
┌ Info: EM with 100000 data points 50 iterations avll -1.412531
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4145349019329176
│     -1.4144816950035417
│      ⋮
└     -1.4125312146298317
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412531
[ Info: iteration 2, average log likelihood -1.412470
[ Info: iteration 3, average log likelihood -1.412411
[ Info: iteration 4, average log likelihood -1.412341
[ Info: iteration 5, average log likelihood -1.412253
[ Info: iteration 6, average log likelihood -1.412146
[ Info: iteration 7, average log likelihood -1.412021
[ Info: iteration 8, average log likelihood -1.411882
[ Info: iteration 9, average log likelihood -1.411734
[ Info: iteration 10, average log likelihood -1.411583
[ Info: iteration 11, average log likelihood -1.411436
[ Info: iteration 12, average log likelihood -1.411295
[ Info: iteration 13, average log likelihood -1.411165
[ Info: iteration 14, average log likelihood -1.411048
[ Info: iteration 15, average log likelihood -1.410942
[ Info: iteration 16, average log likelihood -1.410849
[ Info: iteration 17, average log likelihood -1.410766
[ Info: iteration 18, average log likelihood -1.410692
[ Info: iteration 19, average log likelihood -1.410626
[ Info: iteration 20, average log likelihood -1.410567
[ Info: iteration 21, average log likelihood -1.410512
[ Info: iteration 22, average log likelihood -1.410463
[ Info: iteration 23, average log likelihood -1.410417
[ Info: iteration 24, average log likelihood -1.410375
[ Info: iteration 25, average log likelihood -1.410336
[ Info: iteration 26, average log likelihood -1.410299
[ Info: iteration 27, average log likelihood -1.410266
[ Info: iteration 28, average log likelihood -1.410234
[ Info: iteration 29, average log likelihood -1.410205
[ Info: iteration 30, average log likelihood -1.410178
[ Info: iteration 31, average log likelihood -1.410153
[ Info: iteration 32, average log likelihood -1.410129
[ Info: iteration 33, average log likelihood -1.410108
[ Info: iteration 34, average log likelihood -1.410087
[ Info: iteration 35, average log likelihood -1.410068
[ Info: iteration 36, average log likelihood -1.410050
[ Info: iteration 37, average log likelihood -1.410033
[ Info: iteration 38, average log likelihood -1.410017
[ Info: iteration 39, average log likelihood -1.410002
[ Info: iteration 40, average log likelihood -1.409987
[ Info: iteration 41, average log likelihood -1.409974
[ Info: iteration 42, average log likelihood -1.409960
[ Info: iteration 43, average log likelihood -1.409947
[ Info: iteration 44, average log likelihood -1.409935
[ Info: iteration 45, average log likelihood -1.409923
[ Info: iteration 46, average log likelihood -1.409912
[ Info: iteration 47, average log likelihood -1.409900
[ Info: iteration 48, average log likelihood -1.409890
[ Info: iteration 49, average log likelihood -1.409879
[ Info: iteration 50, average log likelihood -1.409869
┌ Info: EM with 100000 data points 50 iterations avll -1.409869
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4125306965687656
│     -1.41247008862192
│      ⋮
└     -1.4098689703914098
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4229826566736414
│     -1.4230008615325729
│     -1.4229524996302154
│     -1.4229139895890137
│      ⋮
│     -1.4098896585269975
│     -1.4098791614198334
└     -1.4098689703914098
32×26 Array{Float64,2}:
 -0.0752728   -0.0203217  -0.468748   -0.0740621   -0.445191     0.838693    -0.406413   -0.343228     0.282188    0.0479062  -0.105321    -0.0721216  -0.593646    0.100817   -0.237788    -0.391833     0.146449      0.861639    0.00900058   -0.2836       0.120588      0.0239888  -0.138184    -0.449974   -0.268037    0.0678804
  0.195756    -0.424427    0.372125   -0.334392    -0.0228687    0.659752     0.235765    0.0321475    0.0972527   0.175255    0.0660192    0.227051   -0.12014    -0.226804   -0.36667     -0.0544003   -0.219526     -0.109596    0.361653     -0.0324404    0.100157     -0.200936    0.360825    -0.650163   -0.650949   -0.267433
  0.0612372   -0.466448   -0.424619   -0.0470098    0.103763    -0.0414255    0.335403   -0.428822     0.102179   -0.433622   -0.22164      0.37724     0.269704   -0.4069     -0.768633     0.53806     -0.385584      0.448067    0.402729     -0.623245    -0.000278189  -0.198317    0.0189231    0.366725    0.0509141   0.063411
  0.165955    -0.0389017  -0.673491   -0.234181    -0.485182     0.482389     0.345216    0.152582    -0.185022    0.756476    0.202186     0.198109   -0.348126   -1.04005    -0.837132     0.347285    -0.118891      0.239445    0.338395      0.0452316    0.0159296    -0.0743495   0.0534521    0.254465   -0.0492047   0.188758
 -0.0506293   -0.0467453   0.0469981  -0.0317746   -0.284668     0.0738088    0.133781    0.155815    -0.0434334   0.139782   -0.106956    -0.0449586  -0.541755    0.22619    -0.123077    -0.0341021   -0.284153     -0.026968    0.0195495     0.08014      0.0775246     0.102593    0.141274    -0.0405738  -0.177296    0.0318771
  0.262505    -0.0702726   0.301149    0.105661    -0.133268     0.0367835   -0.0750814   0.00538994  -0.14678     0.11175     0.0182447   -0.108456    0.277985    0.0818702   0.03217     -0.235367     0.170001      0.0605316   0.146579      0.0114528   -0.206406     -0.0369482  -0.153679    -0.394748    0.181936    0.0913098
 -0.168184     0.29158    -0.234931   -0.179122     0.0912488   -0.124022     0.0209336  -0.232072    -0.172827   -0.0927419   0.109035     0.420572    0.0977946  -0.131899   -0.0566893    0.279845    -0.000944935  -0.0118534   0.000328925   0.0472916   -0.0021411     0.0619889  -0.0144804    0.0852672  -0.0471148  -0.0291507
 -0.133857    -0.180292    0.0235368   0.138764     0.111939     0.233341    -0.193629   -0.0283023    0.434967   -0.258459   -0.0594304   -0.170318    0.0275971  -0.367923   -0.0330122   -0.124549    -0.0703123     0.0991609  -0.164498     -0.049898     0.193475     -0.378673    0.149858     0.232924    0.0861397  -0.150906
  0.0178778    0.554469   -0.157428   -0.310553    -0.095209    -0.846103    -0.609856   -0.439509    -0.508884    0.0453734   0.398737     0.214475   -0.0632519   0.120341    0.285621    -0.287287     0.469093     -0.235499   -0.57844       0.42141     -0.0578739     0.119842   -0.177444    -0.359299    0.134999    0.237933
  0.206235     0.110339    0.193848   -0.763206     0.0649009   -0.0490243   -0.202988   -0.621       -0.703916   -0.0872317  -0.366095     0.432451    0.253379    0.676205   -0.168209     0.334632     0.633921     -0.448963    0.0708706    -0.152581    -0.0791686     0.17367     0.331331    -0.698014   -0.328234    0.220627
 -0.17925      0.0679434   0.152297    0.192655     0.00256787  -0.518157     0.778306    0.200876    -0.538263   -0.178965    0.252762     0.251174    0.0446544   0.195077    0.122676     0.191064    -0.258962     -0.466839    0.0492759     0.396467     0.0157577     0.0206424   0.264791     0.0942075  -0.0807764   0.46776
 -0.0622164    0.182406   -0.617353    0.251245    -0.212652    -0.422238     0.425862   -0.227301     0.471441    0.108434   -0.547177    -0.330744   -0.179692    0.0163247  -0.196608     0.387057     0.197678     -0.881026   -0.17538       0.323766    -0.314854      0.452014    0.386366    -0.155896   -0.238151    0.0563156
 -0.605894     0.246018   -0.544312   -0.14301      0.0612471   -0.47542     -0.508526   -0.627681    -0.138493   -0.0608117  -0.483805     0.325133   -0.087378   -0.592577    0.0714771   -0.095505     0.229742      0.468037   -0.496214      0.00951534  -0.413271     -0.138821    0.0663912    0.430757   -0.0124851  -0.314927
  0.0948469   -0.122202   -0.0751157  -0.434245     0.153883    -0.36851     -0.395679   -0.171894    -0.218623    0.177056   -0.454092    -0.352621   -0.213835    0.135779    0.00372653   0.559933    -0.0500932    -0.117795   -0.474502     -0.293659     0.187668      0.203531   -0.141873     0.36668     0.234063   -0.23037
  0.0298283    0.184771   -0.598379    0.237116     0.22987     -0.482882    -0.0197392  -0.427506     0.273667   -0.0841426   0.00674603  -0.477676    0.0596736   0.0903909  -0.302913    -0.529602    -0.312328      0.111525    0.391552      0.00402413   0.117265      0.475055   -0.296788     0.160147    0.652171    0.605377
  0.0600646    0.443264   -0.853945   -0.28599      0.563082    -0.326148    -0.193015   -0.407099     0.305194   -0.369348    0.470143     0.168349    0.0108883   0.207238    0.420948     0.589482    -0.137125     -0.0286423  -0.374735     -0.147079     0.284945     -0.278637    0.120515     0.487138    0.801913    0.335488
 -0.439274     0.257505    0.38328     0.524528    -0.455068     0.293059     0.449013    0.297769     0.171916    0.0271318   0.136673     0.0809481   0.149468   -0.286884   -0.0881253   -0.706835     0.202157      0.414525    0.20699       0.565407    -0.323228     -0.563418   -0.208868    -0.310493    0.101139    0.367048
 -0.26001      0.434127    0.030002    0.316018    -0.0507622    0.34187      0.738889   -0.0392356    0.166161   -0.187283    0.479976    -0.0820296  -0.0513534   0.621078   -0.309649    -0.177031    -0.103443      0.0375436   0.609196     -0.100252    -0.112239      0.0366805   0.342488    -0.202548   -0.247303    1.03045
  0.807084    -0.155241    0.669843    0.0385951   -0.182364    -0.0154481    0.0740686   0.626027    -0.0348278   0.0203255   0.399033    -0.507022    0.456309    0.0105765   0.319966    -0.0080247    0.0366733    -0.181455   -0.00304124   -0.209746     0.209301      0.0906254   0.0826733   -0.555062    0.560811    0.0474757
  0.602632    -0.08442     0.705664    0.150991     0.530793     0.0908516   -0.193081    0.0503474    0.111772   -0.740617    0.340291    -0.566298    0.235249    0.13644     0.540643     0.221441    -0.481464     -0.146112   -0.212437      0.49586     -0.180687     -0.158263   -0.00537903   0.10219     0.135608    0.534325
  0.168567    -0.657782    0.0953945  -0.428764    -0.0681478    0.029832    -0.443796    0.363677     0.0459748   0.861553   -0.695717    -0.0127825   0.783323   -0.987584    0.403861     0.229364     0.676955     -0.205407   -0.640252      0.257237     0.0678365    -0.405214   -0.0482964    0.414642    0.519453   -1.43527
  0.0527842   -0.0464494  -0.0389304   0.148085     0.0602021    0.2239      -0.205178    0.520743    -0.364199   -0.134074   -0.013747    -0.355511    0.475254    0.0132959   0.0262357   -0.0552141    1.00785      -0.13888    -0.268482     -0.494875    -0.375856     -0.649717    0.266736     0.212542    0.168821    0.315679
 -0.24052      0.109452    0.545924   -0.185778     0.42772      0.329784    -0.514963    0.169343    -0.893306   -0.35397     0.867186     0.345       0.0312324   0.151206    0.155257    -0.246026    -0.707119      0.676499    0.149455     -0.482607     0.464401     -0.546493   -0.375515     0.189584    0.123627    0.0759015
 -0.463018    -0.369432   -0.0233301   0.346735     0.0381502    0.42987     -0.048398    0.480904     0.613922   -0.167597    0.206709    -0.504805   -0.352948   -0.42015     0.205997    -0.124096    -0.489256      0.455727   -0.372688      0.0746902    0.0517292    -0.531901   -0.0598324    0.724346    0.248257   -0.157856
 -0.0195574   -0.0403347  -0.0702286  -0.603508     0.322374     0.31023      0.0694382  -0.304017    -0.266204   -0.576663   -0.083575     0.272879    0.271228   -0.225546   -0.0413025    0.443863     0.1952        0.175986   -0.120094     -0.088405     0.0741224    -0.084543    0.290732    -0.297547    0.0473538   0.00858143
  0.110581    -0.0392897  -0.0603435   0.218914     0.066411    -0.230172    -0.0893997   0.135578    -0.0869168   0.151526    0.102859    -0.320842    0.163289    0.0182279   0.055306    -0.174937     0.105815     -0.177135    0.0248033    -0.0463542   -0.0495276    -0.209967   -0.106005     0.219648    0.232899    0.0982797
 -0.0567681    0.342044   -0.278425   -0.47011     -0.168258    -0.493372    -0.0690216  -0.471741     0.0725113   0.124581   -0.105142     0.385277   -0.824546    0.142574    0.0972643    0.554289    -0.906309     -0.0692475  -0.272412      0.303936     0.40064       0.695697   -0.178762    -0.0159454   0.0815772  -0.303248
 -0.089599    -0.0331548   0.15478    -0.173381    -0.14939      0.00921484  -0.056709   -0.891881     0.397693    0.161178    0.0357152    0.252552    0.368001   -0.0465097   0.211899    -0.155556    -0.677997      0.483221    0.182372      0.603482     0.126191      0.539378   -0.930007    -0.236209   -0.127693   -0.386667
 -0.344323    -0.179621    0.523995   -0.183035    -0.760845     0.168799     0.0439568   0.279758    -0.186139    0.613801   -0.873252    -0.289987   -0.520828    0.279308   -0.437907    -0.427695     0.248383     -0.17289     0.0573254     0.0715223   -0.307853      0.0429083  -0.342709    -0.434428   -0.535651   -0.180084
 -0.00680291   0.255041    0.858581    0.0160923    0.273561    -0.380866     0.0112893   0.26097      0.0732143   0.368801   -0.397362    -0.370985   -0.280463    1.1123      0.928793    -0.428445    -0.0402645    -0.175334   -0.333978     -0.0461204    0.313293     -0.180157   -0.093906     0.376287   -0.0681895  -0.100436
 -0.284053     0.19883     0.144019   -0.00164947  -0.0796097   -0.00594845   0.217163    0.178114    -0.264551   -0.0690441   0.296959     0.464573   -0.0958452  -0.513576   -0.0232957    0.403864     0.0835094    -0.303179   -0.566398      0.256775     0.217174      0.0348484   0.254766    -0.120269   -0.642482   -1.11837
  0.0855254   -0.0168877   0.0882044   0.252268     0.13841     -0.399826    -0.0444547   0.0793778   -0.389891    0.506718   -0.0927581    0.465136    0.249242    0.119457   -0.339154     0.00115667  -0.0706618    -0.559478    0.552462     -0.0323451    0.175496      0.670584   -0.0108216    0.0642767  -0.116787   -0.887045[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409859
[ Info: iteration 2, average log likelihood -1.409849
[ Info: iteration 3, average log likelihood -1.409840
[ Info: iteration 4, average log likelihood -1.409831
[ Info: iteration 5, average log likelihood -1.409822
[ Info: iteration 6, average log likelihood -1.409813
[ Info: iteration 7, average log likelihood -1.409805
[ Info: iteration 8, average log likelihood -1.409796
[ Info: iteration 9, average log likelihood -1.409788
kind full, method kmeans
[ Info: iteration 10, average log likelihood -1.409780
┌ Info: EM with 100000 data points 10 iterations avll -1.409780
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.236067e+05
      1       7.093144e+05      -2.142924e+05 |       32
      2       6.944235e+05      -1.489086e+04 |       32
      3       6.889650e+05      -5.458478e+03 |       32
      4       6.862511e+05      -2.713911e+03 |       32
      5       6.846095e+05      -1.641637e+03 |       32
      6       6.834401e+05      -1.169361e+03 |       32
      7       6.824484e+05      -9.917121e+02 |       32
      8       6.816660e+05      -7.824113e+02 |       32
      9       6.810762e+05      -5.897970e+02 |       32
     10       6.805274e+05      -5.487770e+02 |       32
     11       6.800330e+05      -4.943894e+02 |       32
     12       6.796057e+05      -4.273113e+02 |       32
     13       6.792264e+05      -3.792695e+02 |       32
     14       6.788767e+05      -3.497561e+02 |       32
     15       6.785613e+05      -3.154258e+02 |       32
     16       6.782918e+05      -2.694693e+02 |       32
     17       6.780589e+05      -2.328955e+02 |       32
     18       6.778763e+05      -1.825826e+02 |       32
     19       6.777188e+05      -1.575117e+02 |       32
     20       6.775595e+05      -1.593419e+02 |       32
     21       6.774222e+05      -1.372248e+02 |       32
     22       6.772911e+05      -1.311163e+02 |       32
     23       6.771695e+05      -1.216338e+02 |       32
     24       6.770553e+05      -1.141430e+02 |       32
     25       6.769542e+05      -1.011128e+02 |       32
     26       6.768639e+05      -9.034306e+01 |       32
     27       6.767767e+05      -8.713741e+01 |       32
     28       6.766859e+05      -9.084704e+01 |       32
     29       6.766047e+05      -8.119006e+01 |       32
     30       6.765319e+05      -7.284469e+01 |       32
     31       6.764576e+05      -7.426903e+01 |       32
     32       6.763910e+05      -6.659696e+01 |       32
     33       6.763275e+05      -6.352460e+01 |       32
     34       6.762666e+05      -6.091956e+01 |       32
     35       6.762083e+05      -5.821277e+01 |       32
     36       6.761629e+05      -4.539278e+01 |       32
     37       6.761193e+05      -4.360375e+01 |       32
     38       6.760813e+05      -3.805517e+01 |       32
     39       6.760381e+05      -4.322178e+01 |       32
     40       6.759987e+05      -3.938108e+01 |       32
     41       6.759552e+05      -4.351881e+01 |       32
     42       6.759191e+05      -3.608905e+01 |       32
     43       6.758814e+05      -3.771882e+01 |       32
     44       6.758472e+05      -3.417349e+01 |       32
     45       6.758110e+05      -3.615171e+01 |       32
     46       6.757786e+05      -3.243942e+01 |       32
     47       6.757508e+05      -2.781829e+01 |       32
     48       6.757277e+05      -2.306828e+01 |       32
     49       6.757063e+05      -2.142490e+01 |       32
     50       6.756898e+05      -1.651249e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 675689.7713495673)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422052
[ Info: iteration 2, average log likelihood -1.416995
[ Info: iteration 3, average log likelihood -1.415618
[ Info: iteration 4, average log likelihood -1.414585
[ Info: iteration 5, average log likelihood -1.413483
[ Info: iteration 6, average log likelihood -1.412448
[ Info: iteration 7, average log likelihood -1.411722
[ Info: iteration 8, average log likelihood -1.411313
[ Info: iteration 9, average log likelihood -1.411090
[ Info: iteration 10, average log likelihood -1.410953
[ Info: iteration 11, average log likelihood -1.410856
[ Info: iteration 12, average log likelihood -1.410780
[ Info: iteration 13, average log likelihood -1.410716
[ Info: iteration 14, average log likelihood -1.410662
[ Info: iteration 15, average log likelihood -1.410613
[ Info: iteration 16, average log likelihood -1.410570
[ Info: iteration 17, average log likelihood -1.410530
[ Info: iteration 18, average log likelihood -1.410493
[ Info: iteration 19, average log likelihood -1.410458
[ Info: iteration 20, average log likelihood -1.410426
[ Info: iteration 21, average log likelihood -1.410395
[ Info: iteration 22, average log likelihood -1.410365
[ Info: iteration 23, average log likelihood -1.410337
[ Info: iteration 24, average log likelihood -1.410310
[ Info: iteration 25, average log likelihood -1.410283
[ Info: iteration 26, average log likelihood -1.410258
[ Info: iteration 27, average log likelihood -1.410233
[ Info: iteration 28, average log likelihood -1.410209
[ Info: iteration 29, average log likelihood -1.410185
[ Info: iteration 30, average log likelihood -1.410162
[ Info: iteration 31, average log likelihood -1.410139
[ Info: iteration 32, average log likelihood -1.410116
[ Info: iteration 33, average log likelihood -1.410095
[ Info: iteration 34, average log likelihood -1.410073
[ Info: iteration 35, average log likelihood -1.410052
[ Info: iteration 36, average log likelihood -1.410032
[ Info: iteration 37, average log likelihood -1.410012
[ Info: iteration 38, average log likelihood -1.409992
[ Info: iteration 39, average log likelihood -1.409973
[ Info: iteration 40, average log likelihood -1.409955
[ Info: iteration 41, average log likelihood -1.409937
[ Info: iteration 42, average log likelihood -1.409920
[ Info: iteration 43, average log likelihood -1.409903
[ Info: iteration 44, average log likelihood -1.409887
[ Info: iteration 45, average log likelihood -1.409871
[ Info: iteration 46, average log likelihood -1.409856
[ Info: iteration 47, average log likelihood -1.409841
[ Info: iteration 48, average log likelihood -1.409827
[ Info: iteration 49, average log likelihood -1.409813
[ Info: iteration 50, average log likelihood -1.409799
┌ Info: EM with 100000 data points 50 iterations avll -1.409799
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.180409      0.116054    0.215393    -0.183286    -0.0957775  -0.147016   -0.191315   -0.955105     0.265179    0.0831813   -0.00124949   0.399619    0.311938    0.0764526   0.421104    -0.0393198  -0.565979      0.375873     0.0489627    0.660955    0.122257     0.36122    -1.04147     -0.13642    -0.179274    -0.32985
  0.314595     -0.562531    0.295309    -0.11802      0.308636    0.721916    0.173802    0.0607129    0.328547   -0.816649     0.0131381   -0.322677    0.102163   -0.282818    0.164799     0.155584   -0.524513      0.63672      0.201752    -0.0681537   0.145011    -0.0160272   0.1975      -0.317502    0.0912434    0.106223
 -0.526002      0.635084   -0.0499093    0.515087     0.0348868  -0.119601   -0.420482   -0.244409    -0.214425   -0.0391363    0.327664     0.168088   -0.350559   -0.247455   -0.258898    -0.919646    0.304551      0.228091    -0.186516     0.569263   -0.243688    -0.0268067  -0.225064    -0.154011    0.276417    -0.139741
  0.253343      0.188224    0.720233     0.07327      0.0994158  -0.350206    0.341471    0.603986    -0.353172   -0.352125     0.387054    -0.225449    0.505494   -0.332516    0.316759     0.327016   -0.206769     -0.426159    -0.393272    -0.0168123   0.109087     0.152656    0.327622    -0.321513    0.118626    -0.306641
 -0.0396485    -0.348645    0.759099    -0.28184     -0.342705    0.406565    0.119068    0.166204    -0.286986    0.602466    -0.357624     0.29174    -0.148401    0.0288021  -0.301493    -0.115325   -0.000608312  -0.159051     0.434358     0.0100781  -0.109615    -0.200513    0.0334978   -0.524054   -0.744708    -0.370907
  0.132396      0.0628595   0.768753     0.138474     0.399139   -0.365955    0.0508005   0.373974    -0.0445687   0.209651    -0.458692    -0.577699   -0.199505    1.14084     0.624189    -0.421567   -0.223873     -0.216785    -0.0116013   -0.278697    0.18035     -0.0504981  -0.131694     0.364082    0.00367427   0.0344086
  0.13398       0.122337    0.215145    -0.683387     0.126686   -0.156681   -0.0495486  -0.627324    -0.7621     -0.171853    -0.243654     0.526064    0.177065    0.804215   -0.147984     0.238501    0.460582     -0.47538     -0.00424216   0.0674603   0.0438637    0.299217    0.548505    -0.650996   -0.384933     0.218748
 -0.259276     -0.269119   -0.200596    -0.0866763    0.283916   -0.0272898  -0.432737   -0.610687     0.431745   -0.294049    -0.354558     0.117375    0.0182728  -0.611118    0.172946    -0.0621996  -0.203056      0.38099     -0.597519    -0.178169    0.0808026   -0.14965     0.509251     0.475834    0.0637711   -0.323703
 -0.068478      0.23256    -0.0637489   -0.209714     0.0379242  -0.281428   -0.122246   -0.331629    -0.140836    0.0781249    0.111019     0.160767   -0.150415    0.147083    0.1612       0.097709   -0.24674      -0.0643356   -0.131885     0.189008    0.15083      0.162408   -0.112767    -0.0500066   0.0721196   -0.104465
  0.206341      0.190339    0.181758    -0.318784    -0.0439147  -0.390822   -0.69513    -0.112488    -0.45152    -0.100592    -0.0532148   -0.153762    0.278115    0.0272035   0.514905    -0.0296474   0.768793      0.115598    -0.489855    -0.100782   -0.428904    -0.295096   -0.176422    -0.329426    0.228242     0.281864
  0.265084     -0.096798   -0.15997     -0.391951     0.339408   -0.101979   -0.586917    0.00344781  -0.288004    0.322692    -0.236648     0.31757    -0.232569   -0.0243262  -0.334157     0.55378     0.0991682    -0.394145    -0.0742404   -0.506416    0.262631     0.639791   -0.0889957   -0.107289   -0.0191077   -0.801435
  0.0484935     0.352456   -0.399711     0.230204    -0.312977   -0.465143    0.562961   -0.231665    -0.387227    0.352722     0.331001     0.399609    0.172205   -0.208244    0.0178052    0.563701    0.868711     -0.917287     0.187614     0.188147    0.172529     0.290346   -0.357201    -0.288379   -0.738527    -0.383065
 -0.149825      0.0153743  -0.290127     0.0888693    0.259959    0.113455    0.0721648   0.218142    -0.297588   -0.216065    -0.102919    -0.132129    0.317456   -0.126997   -0.325121     0.0721758   0.826927     -0.261266    -0.0218877   -0.488353   -0.230046    -0.630414    0.449071     0.337558    0.0956389    0.386507
 -0.0340822    -0.0894356  -0.835883    -0.622055    -0.452728   -0.0214261   0.167378   -0.386875    -0.167788    0.209968    -0.0398565    0.501435   -0.187941   -0.723112   -0.781994     0.459339   -0.282054      0.381559     0.190594    -0.379971   -0.208797    -0.226728   -0.0398352    0.137524    0.0141627    0.0114962
 -0.423065      0.989659   -1.04242      0.167831     0.152587   -0.655202   -0.267429   -0.655831     0.0977635  -0.781467    -0.187038     0.075271   -0.197235    0.373918    0.289143     0.0696365   0.100498     -0.335887    -0.1245       0.172087   -0.178575     0.38722     0.286795    -0.246612    0.23896      0.383491
 -0.0447261    -0.0899009  -0.0721574    0.188731     0.0842869   0.0352667   0.0618774   0.328113     0.0546385  -0.228127    -0.110289    -0.44216     0.249047   -0.0160793  -0.112255     0.123594    0.270097     -0.19463      0.0215605   -0.227707    0.0182389   -0.500004    0.12754      0.45858     0.218562     0.258937
 -0.177878      0.270115   -0.251958    -0.166153     0.047983   -0.297766   -0.0278595  -0.231253    -0.173135    0.0368733   -0.0553393    0.2731     -0.0117766   0.0102036  -0.00169086   0.188571    0.0486452    -0.0653506   -0.0653007    0.0498119  -0.0628006    0.122687   -0.00783419   0.131971    0.0101181    0.0479709
  0.216965      0.179657   -0.247464    -0.384923     0.463722   -0.284854   -0.426703   -0.309261    -0.0616522  -0.19056      0.401832    -0.0978328  -0.131774    0.338768    0.501484     0.570185   -0.344537      0.126134    -0.645808    -0.0436041   0.361643    -0.0853617   0.025248     0.645117    0.531987     0.197879
  0.510038      0.0676603  -0.00233679  -0.0957206   -0.153982    0.0719      0.365396    0.274062     0.794915    0.496375    -0.0837368   -0.68411    -0.0254422  -0.104542   -0.00123257  -0.212036    0.333353     -1.05023     -0.688276     0.514557   -0.227867    -0.212412    0.660208    -0.586568   -0.0218905   -0.131894
 -0.278107      0.334682   -0.0812736    0.130817    -0.0955339  -0.163621    0.833926    0.146489    -0.0445792  -0.0810612    0.385566     0.133647   -0.30223     0.463733   -0.101323     0.176345   -0.530464     -0.205268     0.27296      0.303675   -0.00667382   0.152525    0.30818      0.193708   -0.0799593    0.742668
  0.000634645   0.0688459  -0.433723     0.337494     0.0998216   0.131211    0.229802   -0.0822378    0.0121186   0.531183     0.0173831    0.120613    0.398817   -0.303028   -0.886521    -0.565068   -0.238382      0.0189058    0.492321     0.427187    0.450336     0.875278    0.34794      0.130014    0.0302642   -0.354595
 -0.424768     -0.156599   -0.0649019    0.518492     0.036561    0.208671   -0.0164799   0.642702     0.390128    0.00851919   0.509638    -0.316785   -0.144155   -0.572126    0.197257    -0.137565   -0.351211      0.503448    -0.342002     0.0406793  -0.0428673   -0.726483   -0.317063     1.01224     0.188128    -0.160591
 -0.267456     -0.0566347  -0.102512    -0.159549    -0.639423   -0.167337   -0.201912   -0.138419     0.12113     0.312114    -0.988441    -0.573125   -0.654153    0.0742406  -0.325134     0.0132819  -0.153203      0.0180162   -0.438519     0.279717    0.0563221    0.491245   -0.519784    -0.0722905   0.128949    -0.112842
 -0.260656     -0.236586   -0.0348643    0.167096    -0.0738226  -0.974012    0.49209    -0.0272336   -0.0852377   0.031027    -0.413947     0.423087    0.0270276  -0.145597   -0.139421     0.515521   -0.516929     -0.701865     0.101043     0.332405   -0.0942838    0.499119    0.233672     0.54265    -0.00489325  -0.337053
  0.0242737    -0.542974    0.0668632   -0.322066    -0.14218     0.152505   -0.477205    0.327942    -0.0872218   0.655258    -0.482249    -0.0515601   0.738922   -0.820993    0.37243      0.202545    0.828985     -0.115488    -0.74092      0.166708   -0.00850081  -0.513045   -0.0555003    0.397545    0.276001    -1.26754
 -0.0779879     0.204758   -0.00729283  -0.205751     0.348061    0.411161    0.252589   -0.298128    -0.102436   -0.270842     0.413869     0.734565    0.249396   -0.398292   -0.332436     0.237969   -0.265437      0.286539     0.232435    -0.138338    0.172692    -0.306487   -0.0361195   -0.147385   -0.0929899   -0.21311
  0.635914     -0.151623    0.639282     0.168587    -0.0247885   0.265134   -0.0472599   0.517844    -0.35405    -0.00741154   0.938714    -0.223424    0.19873     0.378664    0.367124    -0.20802    -0.044535     -0.00784546   0.179681    -0.0476561   0.32517     -0.130576   -0.167412    -0.565502    0.361592     0.408976
 -0.22005       0.0948316   0.463543     0.507734    -0.514761    0.360168    0.513954    0.244821     0.262483   -0.00573559   0.0996198   -0.140429    0.302749   -0.0131204  -0.105128    -0.71294     0.160195      0.338443     0.489089     0.227156   -0.53573     -0.54543    -0.092952    -0.459656   -0.00321093   0.644184
  0.314588     -0.162382    0.300158     0.0679551   -0.129003    0.104987   -0.053425    0.0157093   -0.0535858   0.068831     0.0303591   -0.116158    0.168938    0.0922745   0.00111335  -0.219621   -0.00305868    0.0405521    0.172258    -0.0035078  -0.0762122    0.0331315  -0.0612274   -0.398449    0.154625     0.0973941
  0.253502     -0.0197238  -0.597649     0.21577      0.164112   -0.533595   -0.0459217  -0.577129     0.411003   -0.0487152    0.106601    -0.683119    0.0799509  -0.0530904  -0.252632    -0.411792   -0.436664      0.171845     0.414296    -0.172493    0.154297     0.455904   -0.581906     0.206274    0.692358     0.594887
 -0.158131     -0.183927    0.0372546   -0.00942671  -0.265599    0.318547    0.0664319   0.149619     0.0677579   0.0730494   -0.0384053    0.0125919  -0.600674   -0.156074   -0.16341   [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
   0.0221472  -0.260983      0.0454551   -0.11795      0.174314    0.164444    -0.117548    0.168601    -0.0325554  -0.385743    -0.29014
 -0.199326      0.0105786  -0.631282    -0.0802554   -0.495706    0.820273   -0.211512   -0.261473     0.351277    0.0413056   -0.0822098   -0.0376201  -0.485691    0.174276   -0.371699    -0.363002    0.274429      0.916994     0.15666     -0.472273    0.086433    -0.0369641  -0.0794083   -0.36114    -0.479855     0.18464[ Info: iteration 1, average log likelihood -1.409786
[ Info: iteration 2, average log likelihood -1.409773
[ Info: iteration 3, average log likelihood -1.409761
[ Info: iteration 4, average log likelihood -1.409749
[ Info: iteration 5, average log likelihood -1.409738
[ Info: iteration 6, average log likelihood -1.409726
[ Info: iteration 7, average log likelihood -1.409715
[ Info: iteration 8, average log likelihood -1.409705
[ Info: iteration 9, average log likelihood -1.409695
[ Info: iteration 10, average log likelihood -1.409685
┌ Info: EM with 100000 data points 10 iterations avll -1.409685
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
