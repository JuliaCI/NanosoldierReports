Julia Version 1.4.0-DEV.596
Commit 1c87f695be (2019-12-12 22:34 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed OpenBLAS_jll ─────── v0.3.7+1
 Installed FillArrays ───────── v0.8.2
 Installed Distances ────────── v0.8.2
 Installed Compat ───────────── v2.2.0
 Installed NearestNeighbors ─── v0.4.4
 Installed SortingAlgorithms ── v0.3.1
 Installed Rmath ────────────── v0.6.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed SpecialFunctions ─── v0.9.0
 Installed DataStructures ───── v0.17.6
 Installed CMake ────────────── v1.1.2
 Installed StatsBase ────────── v0.32.0
 Installed Clustering ───────── v0.13.3
 Installed PDMats ───────────── v0.9.10
 Installed StaticArrays ─────── v0.12.1
 Installed QuadGK ───────────── v2.3.1
 Installed BinaryProvider ───── v0.5.8
 Installed Missings ─────────── v0.4.3
 Installed URIParser ────────── v0.4.0
 Installed Distributions ────── v0.21.11
 Installed FileIO ───────────── v1.2.0
 Installed DataAPI ──────────── v1.1.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed LegacyStrings ────── v0.4.1
 Installed Blosc ────────────── v0.5.1
 Installed JLD ──────────────── v0.9.1
 Installed HDF5 ─────────────── v0.12.5
 Installed Arpack ───────────── v0.4.0
 Installed Parameters ───────── v0.12.0
 Installed OrderedCollections ─ v1.1.0
 Installed StatsFuns ────────── v0.9.3
 Installed BinDeps ──────────── v1.0.0
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Testing GaussianMixtures
Status `/tmp/jl_E66CBc/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.6
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.0
  [1a297f60] FillArrays v0.8.2
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+1
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
┌ Warning: Replacing docs for `FileIO.filename :: Tuple{Any}` in module `FileIO`
└ @ Base.Docs docs/Docs.jl:223
┌ Warning: Replacing docs for `FileIO.file_extension :: Tuple{Any}` in module `FileIO`
└ @ Base.Docs docs/Docs.jl:223
[ Info: Testing Data
(100000, -1.7534296994683922e6, [28405.103549070544, 71594.89645092946], [18026.13813112798 12844.08144779743 -2339.88413011362; -17751.552639917732 -13030.287836253849 2439.1867631241803], [[26064.357593347973 -1934.7460780560755 7240.682905771162; -1934.7460780560755 26009.89690953056 4827.292595421755; 7240.682905771162 4827.292595421754 34017.203118666395], [73199.39675045166 2509.7479586782165 -7318.359444524096; 2509.7479586782165 74374.56083628167 -4229.910288603022; -7318.359444524096 -4229.910288603021 65554.64987391011]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.617799e+03
      1       9.681984e+02      -6.496001e+02 |        8
      2       9.103685e+02      -5.782991e+01 |        4
      3       8.909076e+02      -1.946095e+01 |        3
      4       8.763937e+02      -1.451390e+01 |        0
      5       8.763937e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 876.393657801812)
┌ Info: K-means with 272 data points using 5 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.067534
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.851580
[ Info: iteration 2, lowerbound -3.762080
[ Info: iteration 3, lowerbound -3.661876
[ Info: iteration 4, lowerbound -3.531291
[ Info: iteration 5, lowerbound -3.375213
[ Info: iteration 6, lowerbound -3.208048
[ Info: iteration 7, lowerbound -3.048581
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.903690
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.758907
[ Info: iteration 10, lowerbound -2.639107
[ Info: iteration 11, lowerbound -2.547493
[ Info: dropping number of Gaussions to 4
[ Info: iteration 12, lowerbound -2.469479
[ Info: iteration 13, lowerbound -2.404702
[ Info: iteration 14, lowerbound -2.360156
[ Info: iteration 15, lowerbound -2.334816
[ Info: dropping number of Gaussions to 3
[ Info: iteration 16, lowerbound -2.313845
[ Info: iteration 17, lowerbound -2.308244
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.302916
[ Info: iteration 19, lowerbound -2.299259
[ Info: iteration 20, lowerbound -2.299256
[ Info: iteration 21, lowerbound -2.299254
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Tue Dec 17 12:18:52 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Tue Dec 17 12:19:00 2019: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Tue Dec 17 12:19:02 2019: EM with 272 data points 0 iterations avll -2.067534
5.8 data points per parameter
, Tue Dec 17 12:19:04 2019: GMM converted to Variational GMM
, Tue Dec 17 12:19:13 2019: iteration 1, lowerbound -3.851580
, Tue Dec 17 12:19:13 2019: iteration 2, lowerbound -3.762080
, Tue Dec 17 12:19:13 2019: iteration 3, lowerbound -3.661876
, Tue Dec 17 12:19:13 2019: iteration 4, lowerbound -3.531291
, Tue Dec 17 12:19:13 2019: iteration 5, lowerbound -3.375213
, Tue Dec 17 12:19:13 2019: iteration 6, lowerbound -3.208048
, Tue Dec 17 12:19:13 2019: iteration 7, lowerbound -3.048581
, Tue Dec 17 12:19:14 2019: dropping number of Gaussions to 6
, Tue Dec 17 12:19:14 2019: iteration 8, lowerbound -2.903690
, Tue Dec 17 12:19:14 2019: dropping number of Gaussions to 5
, Tue Dec 17 12:19:14 2019: iteration 9, lowerbound -2.758907
, Tue Dec 17 12:19:14 2019: iteration 10, lowerbound -2.639107
, Tue Dec 17 12:19:14 2019: iteration 11, lowerbound -2.547493
, Tue Dec 17 12:19:14 2019: dropping number of Gaussions to 4
, Tue Dec 17 12:19:14 2019: iteration 12, lowerbound -2.469479
, Tue Dec 17 12:19:14 2019: iteration 13, lowerbound -2.404702
, Tue Dec 17 12:19:14 2019: iteration 14, lowerbound -2.360156
, Tue Dec 17 12:19:14 2019: iteration 15, lowerbound -2.334816
, Tue Dec 17 12:19:14 2019: dropping number of Gaussions to 3
, Tue Dec 17 12:19:14 2019: iteration 16, lowerbound -2.313845
, Tue Dec 17 12:19:14 2019: iteration 17, lowerbound -2.308244
, Tue Dec 17 12:19:14 2019: dropping number of Gaussions to 2
, Tue Dec 17 12:19:14 2019: iteration 18, lowerbound -2.302916
, Tue Dec 17 12:19:14 2019: iteration 19, lowerbound -2.299259
, Tue Dec 17 12:19:14 2019: iteration 20, lowerbound -2.299256
, Tue Dec 17 12:19:14 2019: iteration 21, lowerbound -2.299254
, Tue Dec 17 12:19:14 2019: iteration 22, lowerbound -2.299254
, Tue Dec 17 12:19:14 2019: iteration 23, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 24, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 25, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 26, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 27, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 28, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 29, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 30, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 31, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 32, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 33, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 34, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 35, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 36, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 37, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 38, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 39, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 40, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 41, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 42, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 43, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 44, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 45, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 46, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 47, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 48, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 49, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: iteration 50, lowerbound -2.299253
, Tue Dec 17 12:19:14 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601394, 95.95490777398608]
β = [178.04509222601394, 95.95490777398608]
m = [4.250300733269908 79.28686694436183; 2.00022925777537 53.8519871724613]
ν = [180.04509222601394, 97.95490777398608]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484755 -0.0076440490423278105; 0.0 0.00858170516633351], [0.3758763611948428 -0.008953123827346157; 0.0 0.012748664777409428]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999996
avll from stats: -1.0132930625663614
avll from llpg:  -1.0132930625663734
avll direct:     -1.0132930625663734
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9986271101605178
avll from llpg:  -0.9986271101605178
avll direct:     -0.9986271101605178
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.106168     0.110017     0.0860647     0.00837422  -0.0384696    -0.124708    -0.0854695     0.109772      0.187488    -0.0546417   -0.0118026   -0.0190413   -0.0529068   -0.0613484     0.0376972     0.139901    -0.071879    -0.0322175   -0.084527      0.12393      -0.176506    -0.0503189    0.0823448    0.0451197  -0.046234    -0.166759
 -0.162059    -0.261146    -0.0164514    -0.0390735    0.117941     -0.0588018   -0.126188     -0.0708891     0.150217     0.0177441    0.0650937   -0.0679664    0.0862103    0.0371442     0.309402     -0.0411607    0.113936    -0.0339065    0.0922949     0.0407222     0.00370938   0.0290841   -0.0148231    0.0351056  -0.0676943   -0.0314852
 -0.0746112    0.00630441   0.0355822     0.0954357    0.0358944    -0.132303     0.0851698    -0.0850311    -0.0625275   -0.00647111  -0.113628     0.315638     0.0271974    0.0271601    -0.0204833    -0.044376    -0.153758    -0.141725     0.0542539     0.0555716    -0.0148655   -0.0472578    0.0163273    0.206773    0.0743767    0.233096
 -0.0866322    0.0592033   -0.101979     -0.0161658   -0.00193712   -0.25805     -0.00699261   -0.115439     -0.0454793    0.119949     0.0393504    0.0899925    0.18777      0.0147187     0.126941      0.188206     0.00706746   0.124242    -0.0172301    -0.201532      0.0566965   -0.0349354   -0.0230475   -0.116916    0.12206     -0.238289
 -0.0346388   -0.0292232   -0.0554158    -0.229306    -0.115466     -0.165209    -0.119133     -0.108657      0.159294     0.0289103   -0.00710579   0.0316932    0.0306735   -0.0689321     0.115852      0.0244326    0.108353     0.0804729   -0.0181141    -0.0285004     0.0545499    0.0275315    0.0296629   -0.135633    0.14742     -0.0958207
  0.0392234   -0.0395894    0.230073      0.117243    -0.0658296     0.055836    -0.0143193     0.0215567    -0.0342393   -0.105391     0.102859    -0.151737    -0.209982     0.188148      0.0498386    -0.0840374   -0.0516324    0.155173     0.0312687    -0.122479      0.118954    -0.0886867    0.088012     0.0796096   0.110936    -0.0741903
 -0.0412259    0.0762996    0.0377114    -0.0381616   -0.123685      0.113252     0.0765485    -0.175206      0.0824836    0.0867718    0.0762041   -0.0373509   -0.0411021   -0.0382016     0.219017      0.037076    -0.0449045    0.0226405   -0.10412       0.0113996    -0.0580988   -0.00884306   0.095766     0.133007   -0.0237139   -0.187069
  0.069608     0.00485174  -0.157538     -0.0945041    0.0699975     0.0291254    0.0285312     0.0887301    -0.2384       0.106096     0.109872     8.88688e-5   0.0376637   -0.0567251     0.046021      0.0337624    0.0732428   -0.224429    -0.0279559     0.0447924     0.0546242    0.00951629  -0.219462    -0.0470508  -0.199589     0.0533169
 -0.018305    -0.00133748  -0.0467245    -0.0476027    0.0814629    -0.0172288   -0.268871     -0.0408387    -0.0822203   -0.0627814   -0.245934     0.0426206    0.0156919    0.000745102   0.0118173     0.0887006    0.122441     0.032703     0.0292529     0.0293889    -0.0598899    0.0999153    0.143585     0.0853201   0.170392    -0.0661336
 -0.102651     0.0743994   -0.142023     -0.0755767   -0.0488321    -0.0654222    0.043817     -0.00648166    0.185002     0.108503    -0.200707    -0.0284861    0.0424145    0.103424     -0.0164414    -0.116747     0.00830286   0.0387983    0.0115032    -0.078841      0.0356993   -0.0522782    0.0904308    0.111892    0.0674301    0.048512
 -0.188991    -0.117887     0.025314     -0.0389907   -0.146989      0.0420893    0.215365      0.0271165     0.138126     0.0637692    0.0909117   -0.0646337    0.106257    -0.0605871     0.0402742    -0.211717     0.129992    -0.112019    -0.15626       0.0426079    -0.157964     0.0505064   -0.240289    -0.0486743  -0.213574     0.00411465
 -0.179229     0.165415     0.0458773    -0.0910085    0.0659205     0.102002    -0.142125     -0.0566668     0.00646691   0.0193711   -0.0877902    0.0593384   -0.106673    -0.0343025    -0.15418      -0.160629     0.120869     0.122347    -0.0533425     0.00614729   -0.0677679   -0.0718842   -0.159996    -0.069198    0.015934    -0.0653672
  0.104196    -0.0378083    0.0552005    -0.0808891   -0.110515      0.0513954   -0.0121862    -0.000615988   0.0666633    0.111974     0.085843     0.0388268    0.241957    -0.0831839     0.143429      0.170587    -0.0740524   -0.122994     0.108301     -0.0537211     0.0862916   -0.068585    -0.0747437   -0.0753992  -0.0629817   -0.122918
  0.0107521   -0.0355089    0.0633928    -0.203335    -0.0648674    -0.00385127  -0.00658952    0.0279982    -0.0293002    0.201161    -0.0135277   -0.0836071   -0.0141237    0.0159481    -0.255991      0.187143     0.0396209    0.0724107   -0.00936936    0.0797872    -0.159705    -0.0246543    0.0522357    0.0801068   0.0681506   -0.19116
  0.187622    -0.114123    -0.0110473     0.0457713    0.0675872    -0.0818786    0.0235953    -0.0428914     0.0600847    0.161712    -0.126867     0.00957792  -0.0117131    0.241765     -0.00147024    0.145389     0.173836    -0.120574    -0.0906893    -0.0101566    -0.132463     0.0457062   -0.0869918    0.0097869  -0.0203059    0.0780432
  0.0201952    0.0584176    0.0730391     0.00319287   0.0847321    -0.159087    -0.0231606     0.112184     -0.00856082   0.0714123    0.00391832   0.0326701   -0.0221866   -0.00844231   -0.0167872     0.180295     0.159        0.13243     -0.0203472    -0.000684132  -0.111711    -0.126688     0.0074949    0.128811   -0.100066     0.101995
 -0.105268     0.14011      0.205879      0.00957511   0.013537      0.0066942   -0.00990425   -0.0378549     0.0482405    0.019268    -0.173794    -0.0309454    0.129709     0.000818837  -0.00191368    0.0542798    0.0359009   -0.0341401   -0.0455421    -0.0237444    -0.0133962   -0.0805726    0.161868     0.0207949  -0.213576    -0.0971302
  0.0765542    0.0281258   -0.0361625    -0.00554175   0.100603     -0.0406787   -0.0831009     0.0957576     0.0312201    0.0994311   -0.00184206   0.0179407    0.0784191    0.17026       0.0307234     0.172546     0.0317714    0.00363028  -0.032133      0.287078     -0.0618572   -0.164659     0.0765974   -0.0505182   0.106393     0.0318421
  0.00229023  -0.0532941    0.0152556     0.0110492   -0.0409056     0.170611     0.0818768     0.0107061     0.0486528   -0.0352656   -0.186037     0.0665529    0.0127657    0.1751        0.0984603     0.107272     0.188826     0.0426489    0.160803      0.0864649     0.0445003    0.0600817    0.10036      0.081071    0.0419971   -0.13367
 -0.118069     0.0536552    0.132494     -0.151705    -0.0878217    -0.0782459   -0.115398      0.0317176     0.0356221    0.0026728    0.0301786   -0.184167    -0.0307504   -0.051412      0.0599931    -0.10082      0.0134405   -0.0162981    0.0984387    -0.0190325    -0.125756    -0.0568269   -0.107819     0.0889632   0.102458     0.215783
 -0.0293398    0.093198     0.00692415   -0.0765837   -0.147888     -0.0868928   -0.0166135     0.138702      0.0245001   -0.0255503    0.172032     0.133989    -0.0383304    0.0954099    -0.0180085    -0.0746829   -0.0015818    0.0519351   -0.0220379    -0.167155      0.106439    -0.0885961    0.13468     -0.0240429  -0.00742462  -0.0369035
 -0.1907      -0.0756662   -0.0419118    -0.0550502    0.224968      0.0829634    0.0885547    -0.0885076    -0.0348577    0.0595469    0.00757652  -0.0573931   -0.195238    -0.0799324    -0.122001     -0.155813    -0.0550001    0.0639034    0.00975507   -0.0297722     0.0205319    0.0753603   -0.144253     0.10838    -0.0475056   -0.117381
 -0.132535     0.00200475  -0.131516     -0.0408508   -0.0756145     0.134249     0.124344     -0.00120555    0.0095511    0.0427505   -0.0226518    0.00206428   0.123552    -0.00173281    0.154554      0.019692    -0.0452078    0.0073524    0.000437585  -0.023688      0.0584486    0.116255    -0.00574453   0.153183   -0.133074     0.200975
  0.00829344   0.0393299    0.0267547    -0.245666    -0.000361985  -0.0849117   -0.0631319    -0.13398      -0.0131014   -0.0773992    0.193316    -0.0514709    0.129574     0.171877      0.0752242    -0.189453    -0.0977386    0.0163542   -0.0953199    -0.154573     -0.00717593   0.0280038    0.0708796   -0.0457134  -0.00530969   0.0540521
 -0.0439161   -0.0309302    0.138701     -0.125084     0.00377834    0.124489    -0.000763729  -0.0991449     0.0375013    0.117761     0.0307055   -0.175983     0.0885888    0.117498      0.120336      0.112739    -0.0928359    0.160924    -0.135635      0.187184     -0.154565    -0.341351    -0.163331    -0.173207    0.103431     0.100129
 -0.0927447    0.195306     0.0698107    -0.0441969    0.092033      0.0761712   -0.108252     -0.185701      0.171511     0.112802     0.0127935   -0.0323219   -0.106809    -0.0930375    -0.0742697    -0.047778    -0.0514594   -0.0751343   -0.137258     -0.0919892    -0.0902615    0.0343507    0.066983    -0.144423    0.0520464    0.16927
  0.0550127   -0.0272163   -0.177342      0.0733064   -0.0443365    -0.107286     0.0995093    -0.00576962   -0.200898     0.0537558   -0.0715382    0.167769     0.131836     0.0111978     0.0370274     0.0394005   -0.079084    -0.0700344   -0.0783764    -0.00591394    0.032052     0.0950126    0.0475683   -0.171206    0.0619505   -0.0445416
 -0.182008     0.0375221    0.0293924     0.0928344    0.0809899     0.006728    -0.00134901   -0.022994     -0.039756    -0.0387622   -0.0463799   -0.085043     0.054778    -0.178413     -0.128119      0.0412852   -0.0565511    0.156424     0.14636      -0.0466067     0.0462438   -0.18973      0.0321227   -0.0259884   0.128396     0.0137339
 -0.0017514   -0.088809     0.000898529   0.0568867   -0.0489225     0.0986191   -0.0396118    -0.085151      0.0618694   -0.144935     0.0346076    0.0176725   -0.019577    -0.110014     -0.100198     -0.00701507  -0.143123    -0.118894    -0.191361     -0.162021     -0.00665008  -0.074402    -0.10105     -0.0615198  -0.0848574    0.0259679
 -0.0265142   -0.10829      0.159812     -0.0188502   -0.163682     -0.104091     0.034208      0.122596     -0.0142725   -0.0152915   -0.108278    -0.00883487  -0.0530546    0.0235073     0.117054     -0.0965422   -0.0170815   -0.0758471    0.0887137    -0.162428      0.135588    -0.0173923    0.00938292  -0.0789347  -0.0172666    0.0995013
  0.0250714   -0.0835456    0.0603395    -0.119772    -0.00833069    0.109401     0.00974802    0.0929403    -0.123158     0.0458256    0.0963678   -0.00905453  -0.00123352   0.033747     -0.00762758   -0.171698    -0.157995    -0.0731764    0.0498975    -0.0393808     0.00900455   0.0233672    0.132779     0.0332534   0.00930118  -0.087162
 -0.0645343   -0.0332129   -0.083873      0.107781    -0.0214014    -0.0832409    0.151051      0.0349665     0.170237     0.0338028   -0.0265086    0.0368751    0.0319381    0.102389     -0.000557642   0.0542363    0.0206684    0.172485     0.0115135     0.020195      0.13632     -0.234948    -0.00634903   0.0329183  -0.0122114   -0.195087kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.372809147618657
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.372880
[ Info: iteration 2, average log likelihood -1.372797
[ Info: iteration 3, average log likelihood -1.372135
[ Info: iteration 4, average log likelihood -1.365179
[ Info: iteration 5, average log likelihood -1.348821
[ Info: iteration 6, average log likelihood -1.342366
[ Info: iteration 7, average log likelihood -1.340968
[ Info: iteration 8, average log likelihood -1.340176
[ Info: iteration 9, average log likelihood -1.339546
[ Info: iteration 10, average log likelihood -1.338967
[ Info: iteration 11, average log likelihood -1.338386
[ Info: iteration 12, average log likelihood -1.337770
[ Info: iteration 13, average log likelihood -1.337105
[ Info: iteration 14, average log likelihood -1.336419
[ Info: iteration 15, average log likelihood -1.335656
[ Info: iteration 16, average log likelihood -1.334819
[ Info: iteration 17, average log likelihood -1.334222
[ Info: iteration 18, average log likelihood -1.333894
[ Info: iteration 19, average log likelihood -1.333723
[ Info: iteration 20, average log likelihood -1.333631
[ Info: iteration 21, average log likelihood -1.333578
[ Info: iteration 22, average log likelihood -1.333546
[ Info: iteration 23, average log likelihood -1.333526
[ Info: iteration 24, average log likelihood -1.333512
[ Info: iteration 25, average log likelihood -1.333502
[ Info: iteration 26, average log likelihood -1.333494
[ Info: iteration 27, average log likelihood -1.333489
[ Info: iteration 28, average log likelihood -1.333484
[ Info: iteration 29, average log likelihood -1.333480
[ Info: iteration 30, average log likelihood -1.333477
[ Info: iteration 31, average log likelihood -1.333474
[ Info: iteration 32, average log likelihood -1.333472
[ Info: iteration 33, average log likelihood -1.333470
[ Info: iteration 34, average log likelihood -1.333468
[ Info: iteration 35, average log likelihood -1.333466
[ Info: iteration 36, average log likelihood -1.333465
[ Info: iteration 37, average log likelihood -1.333463
[ Info: iteration 38, average log likelihood -1.333461
[ Info: iteration 39, average log likelihood -1.333460
[ Info: iteration 40, average log likelihood -1.333458
[ Info: iteration 41, average log likelihood -1.333457
[ Info: iteration 42, average log likelihood -1.333455
[ Info: iteration 43, average log likelihood -1.333454
[ Info: iteration 44, average log likelihood -1.333452
[ Info: iteration 45, average log likelihood -1.333450
[ Info: iteration 46, average log likelihood -1.333449
[ Info: iteration 47, average log likelihood -1.333447
[ Info: iteration 48, average log likelihood -1.333445
[ Info: iteration 49, average log likelihood -1.333443
[ Info: iteration 50, average log likelihood -1.333441
┌ Info: EM with 100000 data points 50 iterations avll -1.333441
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3728799679298753
│     -1.3727965296747435
│      ⋮
└     -1.333440729554868
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.333544
[ Info: iteration 2, average log likelihood -1.333434
[ Info: iteration 3, average log likelihood -1.332964
[ Info: iteration 4, average log likelihood -1.328492
[ Info: iteration 5, average log likelihood -1.313114
[ Info: iteration 6, average log likelihood -1.301412
[ Info: iteration 7, average log likelihood -1.297539
[ Info: iteration 8, average log likelihood -1.295907
[ Info: iteration 9, average log likelihood -1.295075
[ Info: iteration 10, average log likelihood -1.294633
[ Info: iteration 11, average log likelihood -1.294373
[ Info: iteration 12, average log likelihood -1.294202
[ Info: iteration 13, average log likelihood -1.294076
[ Info: iteration 14, average log likelihood -1.293975
[ Info: iteration 15, average log likelihood -1.293890
[ Info: iteration 16, average log likelihood -1.293817
[ Info: iteration 17, average log likelihood -1.293754
[ Info: iteration 18, average log likelihood -1.293700
[ Info: iteration 19, average log likelihood -1.293654
[ Info: iteration 20, average log likelihood -1.293615
[ Info: iteration 21, average log likelihood -1.293582
[ Info: iteration 22, average log likelihood -1.293555
[ Info: iteration 23, average log likelihood -1.293533
[ Info: iteration 24, average log likelihood -1.293515
[ Info: iteration 25, average log likelihood -1.293501
[ Info: iteration 26, average log likelihood -1.293489
[ Info: iteration 27, average log likelihood -1.293480
[ Info: iteration 28, average log likelihood -1.293473
[ Info: iteration 29, average log likelihood -1.293467
[ Info: iteration 30, average log likelihood -1.293462
[ Info: iteration 31, average log likelihood -1.293458
[ Info: iteration 32, average log likelihood -1.293455
[ Info: iteration 33, average log likelihood -1.293453
[ Info: iteration 34, average log likelihood -1.293451
[ Info: iteration 35, average log likelihood -1.293449
[ Info: iteration 36, average log likelihood -1.293448
[ Info: iteration 37, average log likelihood -1.293447
[ Info: iteration 38, average log likelihood -1.293446
[ Info: iteration 39, average log likelihood -1.293446
[ Info: iteration 40, average log likelihood -1.293445
[ Info: iteration 41, average log likelihood -1.293445
[ Info: iteration 42, average log likelihood -1.293444
[ Info: iteration 43, average log likelihood -1.293444
[ Info: iteration 44, average log likelihood -1.293444
[ Info: iteration 45, average log likelihood -1.293444
[ Info: iteration 46, average log likelihood -1.293444
[ Info: iteration 47, average log likelihood -1.293444
[ Info: iteration 48, average log likelihood -1.293444
[ Info: iteration 49, average log likelihood -1.293443
[ Info: iteration 50, average log likelihood -1.293443
┌ Info: EM with 100000 data points 50 iterations avll -1.293443
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.333543849485749
│     -1.3334339689182735
│      ⋮
└     -1.2934433857130438
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.293582
[ Info: iteration 2, average log likelihood -1.293431
[ Info: iteration 3, average log likelihood -1.292971
[ Info: iteration 4, average log likelihood -1.289554
[ Info: iteration 5, average log likelihood -1.277937
[ Info: iteration 6, average log likelihood -1.264450
[ Info: iteration 7, average log likelihood -1.256303
[ Info: iteration 8, average log likelihood -1.252675
[ Info: iteration 9, average log likelihood -1.250466
[ Info: iteration 10, average log likelihood -1.248731
[ Info: iteration 11, average log likelihood -1.247395
[ Info: iteration 12, average log likelihood -1.246523
[ Info: iteration 13, average log likelihood -1.245891
[ Info: iteration 14, average log likelihood -1.245349
[ Info: iteration 15, average log likelihood -1.244816
[ Info: iteration 16, average log likelihood -1.244259
[ Info: iteration 17, average log likelihood -1.243685
[ Info: iteration 18, average log likelihood -1.243132
[ Info: iteration 19, average log likelihood -1.242644
[ Info: iteration 20, average log likelihood -1.242248
[ Info: iteration 21, average log likelihood -1.241945
[ Info: iteration 22, average log likelihood -1.241721
[ Info: iteration 23, average log likelihood -1.241559
[ Info: iteration 24, average log likelihood -1.241447
[ Info: iteration 25, average log likelihood -1.241371
[ Info: iteration 26, average log likelihood -1.241321
[ Info: iteration 27, average log likelihood -1.241291
[ Info: iteration 28, average log likelihood -1.241274
[ Info: iteration 29, average log likelihood -1.241263
[ Info: iteration 30, average log likelihood -1.241257
[ Info: iteration 31, average log likelihood -1.241253
[ Info: iteration 32, average log likelihood -1.241250
[ Info: iteration 33, average log likelihood -1.241248
[ Info: iteration 34, average log likelihood -1.241246
[ Info: iteration 35, average log likelihood -1.241245
[ Info: iteration 36, average log likelihood -1.241244
[ Info: iteration 37, average log likelihood -1.241242
[ Info: iteration 38, average log likelihood -1.241242
[ Info: iteration 39, average log likelihood -1.241241
[ Info: iteration 40, average log likelihood -1.241240
[ Info: iteration 41, average log likelihood -1.241239
[ Info: iteration 42, average log likelihood -1.241238
[ Info: iteration 43, average log likelihood -1.241237
[ Info: iteration 44, average log likelihood -1.241237
[ Info: iteration 45, average log likelihood -1.241236
[ Info: iteration 46, average log likelihood -1.241235
[ Info: iteration 47, average log likelihood -1.241234
[ Info: iteration 48, average log likelihood -1.241234
[ Info: iteration 49, average log likelihood -1.241233
[ Info: iteration 50, average log likelihood -1.241232
┌ Info: EM with 100000 data points 50 iterations avll -1.241232
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2935820738804158
│     -1.293430849761203
│      ⋮
└     -1.241231797482346
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.241425
[ Info: iteration 2, average log likelihood -1.241208
[ Info: iteration 3, average log likelihood -1.240017
[ Info: iteration 4, average log likelihood -1.227038
[ Info: iteration 5, average log likelihood -1.194286
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.166787
[ Info: iteration 7, average log likelihood -1.176291
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.153831
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     11
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.142754
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.166630
[ Info: iteration 11, average log likelihood -1.151093
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.135054
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.151102
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.140447
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.140928
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.153735
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.146118
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.138822
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.150089
[ Info: iteration 20, average log likelihood -1.149108
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.133211
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.156001
[ Info: iteration 23, average log likelihood -1.154109
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.134473
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.151126
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.149519
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.142220
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.137858
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.147752
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.147638
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.152105
[ Info: iteration 32, average log likelihood -1.149121
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.133246
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     13
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.131807
[ Info: iteration 35, average log likelihood -1.167516
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.152571
[ Info: iteration 37, average log likelihood -1.148499
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.132018
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     11
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.134905
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.158245
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.146303
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.146881
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.144167
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.135125
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.153007
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.146683
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.141411
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.149193
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.151195
[ Info: iteration 50, average log likelihood -1.149882
┌ Info: EM with 100000 data points 50 iterations avll -1.149882
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.241425471573369
│     -1.2412081691726446
│      ⋮
└     -1.1498819207621236
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.133522
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     25
│     26
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.127688
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.126763
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     22
│     25
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.109012
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│     21
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.086779
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     15
│     25
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.067033
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      5
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.053621
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     21
│     25
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.032827
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│     11
│     15
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.035548
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│     25
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.038090
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│     21
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.033301
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     15
│     25
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.031796
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│     11
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.030710
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     21
│     25
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.032914
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│     15
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.037240
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│     25
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.029174
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│     11
│     21
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.027037
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     25
│     26
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.037993
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│     15
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.028524
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     21
│     25
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.031038
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│     11
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.031779
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│     25
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.026865
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│     15
│     17
│     21
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.025011
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     25
│     26
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.046984
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│     11
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.027705
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     21
│     25
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.032306
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│     15
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.036969
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│     25
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.028746
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│     11
│     21
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.026440
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     25
│     26
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.036969
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│     15
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.026344
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     21
│     25
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.026317
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│     11
│     17
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.024467
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│     25
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.039428
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│     15
│     21
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.033953
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     25
│     26
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.037966
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│     11
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.024501
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│     15
│     21
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.031425
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.042411
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│     25
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.021245
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│     11
│     15
│     21
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.021438
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     17
│     25
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.036022
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│      5
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.038897
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│     15
│     21
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.028004
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      4
│     11
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.039134
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      5
│     25
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.029962
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│     15
│     21
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.030471
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     25
│     26
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.036560
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│     11
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.022754
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     21
│     25
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.027549
┌ Info: EM with 100000 data points 50 iterations avll -1.027549
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.133522025606765
│     -1.1276881386945319
│      ⋮
└     -1.027548593210413
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.372809147618657
│     -1.3728799679298753
│     -1.3727965296747435
│     -1.372134685053697
│      ⋮
│     -1.036560332489697
│     -1.022753556126994
└     -1.027548593210413
32×26 Array{Float64,2}:
 -0.0985671   0.210242      0.0127151   -0.0530444    0.097377      0.101926    -0.12417     -0.175489      0.17796      0.111594    -0.000433044  -0.0808872   -0.613065     -0.179713    -0.047425      0.0116156   -0.0155209   -0.0632265   -0.0912486  -0.161181    -0.114199     0.0574169   0.12571     -0.142742      0.201284     0.04496
 -0.087524    0.175848      0.119561    -0.0295429    0.0823207     0.0549313   -0.111664    -0.19668       0.166745     0.11447      0.0579592     0.0036989    0.470029     -0.0187799   -0.168189     -0.0905641   -0.0566269   -0.106333    -0.189204   -0.137435    -0.0702918    0.0334066  -0.0219865   -0.144735     -0.0747314    0.257587
  0.0246094  -0.0952941     0.0649273   -0.114484     0.0231791     0.108855    -0.0205445    0.0892896    -0.123519     0.00759738   0.0676506    -0.134843     0.0321105     0.0390061   -0.00120384   -0.153479    -0.331737    -0.100451     0.0448197  -0.0360226    0.0112357   -0.123691   -0.0837277    0.0568891    -0.00896368  -0.383721
  0.0245239  -0.0711843     0.0596229   -0.150105     0.0136928     0.110242     0.0281405    0.0976745    -0.148309     0.114614     0.124753      0.0994508   -0.00923415    0.0350695   -0.00564686   -0.225928     0.136136    -0.0561346    0.052393   -0.0361167    0.0181527    0.189101    0.336672    -0.0352789     0.0181988    0.167294
  0.0130732   0.0354459     0.0239983   -0.211962    -0.0068062    -0.0636406   -0.0631067   -0.137406     -0.00254059  -0.0639969    0.179059     -0.0121139    0.126117      0.163025     0.0608317    -0.137332    -0.0807291    0.00293595  -0.097093   -0.0839777   -0.0118697   -0.0141108   0.0429235   -0.0423417    -0.00912834   0.0683429
 -0.0478263   0.0757161     0.0377297   -0.0419175   -0.133797      0.116336     0.0797351   -0.174414      0.0507931    0.0789119    0.0663299    -0.0500521   -0.033036     -0.0422219    0.239249      0.066327    -0.0426552    0.0145087   -0.0917926  -0.0869188   -0.0544574   -0.0232441   0.0895905    0.14157      -0.00401089  -0.186721
 -0.0430622  -0.123341      0.162645    -0.0585362   -0.174913     -0.109402     0.036455     0.165065      0.00592931  -0.0496633   -0.135139     -0.4381      -0.0267164    -0.0310494    0.0929324    -0.110532    -0.0137989   -0.0823321    0.0514122  -0.144268     0.133456    -0.180059   -0.0190185   -0.0722816    -0.0433299    0.121572
  0.0245519  -0.121404      0.132488    -0.00979184  -0.141691     -0.0669829    0.0251814    0.0471046    -0.0564419    0.0212367   -0.0530118     0.489237    -0.0642302     0.146423     0.141503     -0.0346329   -0.0532355   -0.0651851    0.112314   -0.185962     0.138361     0.174244    0.042592    -0.0790352    -0.0145569    0.0618936
  0.0361648  -0.125731      0.360055     0.0544739    0.0171429     0.0968276   -0.0662791   -0.0881463     0.0918754   -0.159748     0.12173       0.0165709   -0.0124966    -0.103455    -0.139712     -0.00597657  -0.142085    -0.110605    -0.181463   -0.784156     0.223143    -0.0612757  -0.103822     0.0208033    -0.0845982    0.0483652
 -0.0430325  -0.0312337    -0.295666     0.0515302   -0.068102      0.0980428   -0.0246325   -0.0855874     0.0187675   -0.0939301   -0.0658631     0.0156111   -0.0288909    -0.116005    -0.0684995    -0.0278639   -0.142141    -0.169371    -0.232316    0.343454    -0.19831     -0.0742925  -0.0985768   -0.149647     -0.080422    -0.0434673
  0.155644   -0.127581     -0.0418221    0.0188213    0.0578528    -0.133715     0.0217015   -0.062123      0.0672126    0.13539     -0.128197     -0.0153736    0.000987669   0.25326      0.0141385     0.168391     0.165091    -0.0679718   -0.0674922  -0.0131889   -0.134756     0.0514689  -0.0730872   -0.000838707  -0.00714335   0.0570954
 -0.104712    0.0153603     0.0333826    0.0461071    0.0266052     0.131476     0.0174364    0.00113154    0.0237886   -0.0557183   -0.109614     -0.0216116    0.0354108    -0.0285247   -0.0183451     0.074755     0.0527412    0.105994     0.176217   -0.00994393   0.0629711   -0.0779221   0.0596188    0.0199764     0.0952985   -0.0820416
 -0.0120526   0.0499424     0.072639     0.00055165   0.119791     -0.13162     -0.0306272    0.099401      0.0141174    0.0741147    0.00301739    0.044599     0.00747765   -0.0355404    0.0130321     0.172475     0.18225      0.114621    -0.0192184   0.0501715   -0.127487    -0.0979096  -0.00825708   0.163263     -0.095656     0.105923
  0.102479    0.115471      0.0876631    0.00609971  -0.0333907    -0.117741    -0.0586754    0.0582284     0.20341     -0.0552523   -0.013642     -0.0230427   -0.0586571    -0.069587     0.0275568     0.152503    -0.0934788   -0.0226041   -0.0987258   0.0821432   -0.17485     -0.0378934   0.078919     0.0553072    -0.0205953   -0.187562
 -0.139205    0.151128      0.0485381   -0.051905     0.0699769     0.104909    -0.134707    -0.0468596     0.028008     0.0247787   -0.118751      0.0554412   -0.0839983    -0.00386214  -0.134661     -0.152511     0.122718     0.130192    -0.0440915   0.00479906  -0.0428431   -0.0543659  -0.1958      -0.0808054     0.00464929  -0.0677271
 -0.069111   -0.0150924    -0.0182588    0.106759     0.00869983   -0.103778     0.120411    -0.0189601     0.0859719    0.0138519   -0.0776122     0.188563     0.0391384     0.0675404   -0.00211357    0.0072845   -0.0719099    0.00876906   0.0281736   0.0386876    0.0603118   -0.153348   -0.00922041   0.106621      0.0301194    0.0291271
 -0.0095947  -0.00280095   -0.0438306   -0.0418653    0.0330108     0.015802    -0.264002    -0.0495918    -0.0817925   -0.0403982   -0.22999       0.0419956    0.0204478    -0.0319447   -0.015644      0.0855677    0.096916     0.0376531    0.0441872   0.0257631   -0.0495867    0.0901402   0.136478     0.0867441     0.167445    -0.0974463
 -0.0229083   0.0328022    -0.0138121   -0.112243    -0.00493324   -0.0281463   -0.0111947   -0.0010226    -0.0231781    0.0819536   -0.031965     -0.0244069    0.054405     -0.0355331    0.000149326   0.0749518    0.0568069   -0.0460903   -0.053827    0.0129474   -0.00440245  -0.020432    0.0136611   -0.0305723    -0.0727941   -0.0832438
 -0.0260033  -0.0451604     0.142862    -0.15067     -0.000817829   0.127485    -0.00623433  -0.154997      0.0243279    0.0845132    0.031939     -0.1777       0.0838666     0.115901     0.119013      0.106355    -0.109495     0.158098    -0.135426    0.175632    -0.143827    -0.342851   -0.18075     -0.175546      0.13088      0.117388
 -0.176338   -0.181525     -0.0144632   -0.0407879    0.162938      0.0242825   -0.0203377   -0.101044      0.0550845    0.0581767    0.0304978    -0.0473075   -0.0580341    -0.0276035    0.0818155    -0.0946442    0.0269596    0.0365611    0.0579715   0.0406766    0.0132786    0.0628921  -0.088783     0.0920888    -0.0428843   -0.0706754
  0.127582   -0.022871      0.0727424   -0.0762061   -0.116138      0.0323626   -0.0143304   -0.000616464   0.0424322    0.106437     0.0844865     0.0564998    0.210096     -0.0848317    0.131484      0.106859    -0.0616756   -0.124366     0.10926    -0.0630429    0.117478    -0.0779444  -0.0785891   -0.075222     -0.0710125   -0.132042
 -0.132978    0.0266225     0.124903    -0.156221    -0.0902207    -0.0795617   -0.115333     0.00525233    0.0182031    0.00788736   0.0205268    -0.181678    -0.016562     -0.0463676    0.0611252    -0.10599     -0.00166857  -0.010781     0.0926761  -0.0208403   -0.128004    -0.0550674  -0.0983564    0.11833       0.104759     0.226953
  0.0285718  -0.0359761     0.22824      0.101525    -0.0594787     0.0535379   -0.0207336    0.0557273    -0.0344064   -0.103425     0.117552     -0.138047    -0.212343      0.189323     0.0534581    -0.0680029   -0.0382342    0.158224     0.0449416  -0.118345     0.097827    -0.0889804   0.0733525    0.0786949     0.139559    -0.0776164
 -0.0276844   0.106574      0.00157102  -0.0848354   -0.146717     -0.0956736   -0.00432541   0.126476      0.0244775   -0.0261386    0.149882      0.123158    -0.0309957     0.103559    -0.0431932    -0.0838453   -0.0466818    0.0441187   -0.02252    -0.201614     0.110477    -0.0871292   0.135296     0.00719718    0.0169575   -0.0498352
  0.162563    0.172954     -0.0294877   -0.0919187    0.0997126    -0.0424499   -0.202171     0.100448     -0.00318033  -0.00674794  -0.00173621    0.00880053   0.0662588     0.168226     0.0307558     0.146282    -0.0476288   -0.325013    -0.0350934   0.287769    -0.120926    -0.130429    0.0823313   -0.0461395     0.0994254    0.0207427
 -0.0340285  -0.0943026    -0.0425083    0.0760921    0.102305     -0.0400873    0.0206769    0.0903964     0.0420578    0.209541    -0.000537245   0.0229644    0.0833615     0.177134     0.0309035     0.138397     0.106842     0.296849    -0.0270096   0.288499    -0.0372453   -0.263547    0.0726947   -0.0440641     0.0995535    0.029772
  0.01806     0.0479093    -0.140914     0.0042618   -0.0650516    -0.0678327   -0.447957    -0.0388826     0.130707     0.116093    -0.177372     -0.0307413    0.009022      0.204651    -0.0231535    -0.124179     0.0071672    0.0460813    0.0305625   0.0144647    0.0623016   -0.0535687   0.0913005    0.207772      0.0934841    0.0620118
 -0.244825    0.101712     -0.147157    -0.169111    -0.0524835    -0.0675929    0.718937     0.00288647    0.295526     0.0981363   -0.227752     -0.0310996    0.0835871    -0.0448003   -0.0518933    -0.111451     0.00793619   0.0137849    0.0228489  -0.177162    -0.0293942   -0.0487601   0.0888856    0.0372148     0.0532842    0.0491623
 -0.0213662   0.00839422   -0.132138    -0.0130562   -0.0312694    -0.183838     0.0632788   -0.0602831    -0.141901     0.0844972   -0.0274889     0.119045     0.159674     -0.00977403   0.0582762     0.100539    -0.0629009    0.0119311   -0.0488062  -0.0950749    0.0267958    0.0279543  -0.0281742   -0.13079       0.0876807   -0.160568
 -0.121932    0.000179753  -0.121378    -0.0343752   -0.0406496     0.0863156    0.129014    -0.0116572     0.017441     0.0442      -0.0263407    -0.00878117   0.11886       0.00636762   0.126517      0.036691    -0.00304748   0.00938931  -0.0111     -0.0189253    0.0293685    0.124592   -0.011413     0.143121     -0.085612     0.199757
 -0.0472627  -0.111331      0.0363079   -0.0389489   -0.255059     -0.00857796  -1.02121      0.0505498     0.138258     0.240969     0.0964028    -0.0403045    0.0461749    -0.108357     0.0441796    -0.131221     0.219075    -0.0795878   -0.147315    0.199539    -0.270437     0.111078   -0.208856    -0.0651455    -0.200617     0.18492
 -0.210835   -0.119075      0.0199495   -0.0390822   -0.105217      0.0730447    0.806962     0.0187864     0.138229    -0.036426     0.0906399    -0.0665169    0.111093     -0.0454419    0.109308     -0.221741     0.085872    -0.10182     -0.155778   -0.0303068   -0.11006      0.0139096  -0.257844    -0.039565     -0.193676    -0.0833991[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│     15
│     17
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.028984
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.014544
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     11
│     15
│     17
│     21
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.012703
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.023305
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│     15
│     17
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.019645
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      5
│     11
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.006605
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│     15
│     17
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.028934
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.013878
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│     11
│     15
│     17
│     21
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.012273
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│     15
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.023304
┌ Info: EM with 100000 data points 10 iterations avll -1.023304
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind diag, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.216060e+05
      1       6.325900e+05      -1.890161e+05 |       32
      2       6.087912e+05      -2.379874e+04 |       32
      3       5.952401e+05      -1.355114e+04 |       32
      4       5.850798e+05      -1.016034e+04 |       32
      5       5.782783e+05      -6.801422e+03 |       32
      6       5.743592e+05      -3.919124e+03 |       32
      7       5.721791e+05      -2.180093e+03 |       32
      8       5.709868e+05      -1.192351e+03 |       32
      9       5.702482e+05      -7.385286e+02 |       32
     10       5.696861e+05      -5.621311e+02 |       32
     11       5.691614e+05      -5.247340e+02 |       32
     12       5.684711e+05      -6.902646e+02 |       32
     13       5.676629e+05      -8.082095e+02 |       32
     14       5.672610e+05      -4.018805e+02 |       32
     15       5.671266e+05      -1.343694e+02 |       32
     16       5.670712e+05      -5.545579e+01 |       30
     17       5.670284e+05      -4.282966e+01 |       32
     18       5.669830e+05      -4.531838e+01 |       32
     19       5.669367e+05      -4.632669e+01 |       32
     20       5.668674e+05      -6.934370e+01 |       32
     21       5.667881e+05      -7.928949e+01 |       32
     22       5.667137e+05      -7.437953e+01 |       32
     23       5.666420e+05      -7.167505e+01 |       32
     24       5.665802e+05      -6.185080e+01 |       32
     25       5.665282e+05      -5.196721e+01 |       32
     26       5.664758e+05      -5.245726e+01 |       32
     27       5.664330e+05      -4.270232e+01 |       30
     28       5.664077e+05      -2.537997e+01 |       32
     29       5.663904e+05      -1.726591e+01 |       31
     30       5.663809e+05      -9.551705e+00 |       30
     31       5.663733e+05      -7.584166e+00 |       25
     32       5.663687e+05      -4.600234e+00 |       25
     33       5.663655e+05      -3.125635e+00 |       26
     34       5.663630e+05      -2.520137e+00 |       25
     35       5.663607e+05      -2.277146e+00 |       19
     36       5.663591e+05      -1.633107e+00 |       20
     37       5.663579e+05      -1.194078e+00 |       13
     38       5.663568e+05      -1.103015e+00 |       18
     39       5.663555e+05      -1.332555e+00 |       16
     40       5.663545e+05      -1.031756e+00 |       15
     41       5.663535e+05      -9.433149e-01 |       16
     42       5.663529e+05      -6.133026e-01 |       15
     43       5.663523e+05      -6.212665e-01 |       10
     44       5.663520e+05      -3.092616e-01 |       12
     45       5.663515e+05      -4.323499e-01 |       13
     46       5.663511e+05      -4.574613e-01 |       10
     47       5.663507e+05      -4.214095e-01 |        9
     48       5.663504e+05      -2.595416e-01 |        9
     49       5.663498e+05      -6.394182e-01 |        9
     50       5.663494e+05      -3.688630e-01 |        6
K-means terminated without convergence after 50 iterations (objv = 566349.3843347689)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.290914
[ Info: iteration 2, average log likelihood -1.259163
[ Info: iteration 3, average log likelihood -1.228279
[ Info: iteration 4, average log likelihood -1.194255
[ Info: iteration 5, average log likelihood -1.154768
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.101141
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      6
│      7
│     18
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.046265
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.094647
[ Info: iteration 9, average log likelihood -1.091540
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     21
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.041623
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│      6
│      7
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.049008
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.057373
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      3
│      4
│      9
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.021968
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.073234
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      6
│     16
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.037061
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     10
│     18
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.044484
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.076894
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.034974
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     10
│     18
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.010994
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.078965
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.057463
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     18
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.017445
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     10
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.037854
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      7
│     21
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.042008
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.039304
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.031931
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      9
│     10
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.007476
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     18
│     21
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.028133
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.072795
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.030227
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      7
│      9
│     10
│     18
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -0.989323
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.068297
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.045560
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      6
│     18
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.011849
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      9
│     10
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.029689
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│     21
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.044290
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     19
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.039801
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.038781
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│      6
│      9
│     10
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -0.994741
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     18
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.058379
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.063670
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.015923
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      9
│     10
│     18
│     21
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -0.979944
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      7
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.079049
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.059137
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.012106
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      9
│     10
│     21
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -0.996012
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     19
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.064522
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     18
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.039386
32×26 Array{Float64,2}:
 -0.00805421  -0.127393     0.150218     -0.0334827   -0.162764    -0.0894794    0.0325462    0.114379     -0.0332326   -0.0139176    -0.100211     0.0105057   -0.0499511    0.0561641    0.130093    -0.0847053   -0.0386882   -0.077472     0.085305    -0.165704     0.136874    -0.00730109  ┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      7
│      9
│     21
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.010515
┌ Info: EM with 100000 data points 50 iterations avll -1.010515
└ 59.0 data points per parameter
 0.00690504  -0.0782375   -0.0336636    0.0956048
 -0.0474715    0.0785502    0.0368176    -0.0399896   -0.135032     0.116315     0.0773249   -0.174431      0.0502954    0.0742602     0.0665959   -0.0513197   -0.0322926   -0.0423182    0.245657     0.0695569   -0.0469673    0.019349    -0.0885589   -0.0834211   -0.0544064   -0.0242135    0.0942023    0.138699    -0.00448323  -0.18882
 -0.104432     0.0728093   -0.14583      -0.0744125   -0.0589981   -0.0671633    0.092891    -0.0202646     0.210557     0.107556     -0.20248     -0.0308701    0.0435449    0.0911026   -0.0327919   -0.120445     0.00776223   0.029846     0.0272236   -0.0748412    0.0228886   -0.0515693    0.0905047    0.131444     0.0744656    0.0571439
 -0.047823     0.0080128   -0.0865824    -0.232943    -0.12056     -0.157306    -0.0641687   -0.111767      0.168173    -0.0181857    -0.00201506   0.0202225    0.0214036   -0.0602277    0.101205    -0.0107177    0.0954524    0.0638087   -0.0663197   -0.0282886    0.050375     0.0193832    0.0458075   -0.196614     0.145769    -0.124477
 -0.0845815    0.136232     0.127176      0.00576139   0.0346798    0.00664805  -0.0187086   -0.0401707     0.0474137   -0.000976334  -0.191583    -0.0374296    0.121665    -0.00835982  -0.0299584    0.0750831    0.0365992   -0.037513    -0.107732    -0.024481    -0.00319323  -0.0739988    0.157709     0.00945485  -0.206649    -0.104802
 -0.186426     0.168205     0.0494611    -0.0075331    0.0821915    0.123626    -0.144843    -0.0339176     0.0577631    0.0223442    -0.148373     0.0635778   -0.178468    -0.024677    -0.166522    -0.152222     0.119671     0.135404    -0.0340672    0.00207158  -0.0334481   -0.0671128   -0.258412    -0.08543      0.0107267   -0.0908272
  0.0118837    0.044674     0.0255021    -0.210031    -0.00824651  -0.0683098   -0.0649523   -0.14044       0.00409147  -0.0717829     0.191714    -0.0136422    0.13621      0.175243     0.0752224   -0.170521    -0.0940742    0.00831114  -0.0960905   -0.108151    -0.00822431  -0.0139588    0.0514055   -0.0420165   -0.00654518   0.0808072
  0.0281299   -0.0376777    0.229828      0.115168    -0.060976     0.0542862   -0.0214499    0.0525975    -0.0355886   -0.106713      0.122831    -0.140851    -0.215058     0.190547     0.0569262   -0.0730745   -0.0395873    0.163181     0.0467893   -0.120149     0.108254    -0.0890685    0.0709396    0.0815172    0.142339    -0.0769841
  0.0650424    0.0406443   -0.0352723    -0.00927071   0.100852    -0.0411949   -0.0921062    0.096144      0.0192625    0.0999026    -0.00118045   0.0155605    0.0750513    0.172978     0.0307548    0.142663     0.0305947   -0.0169505   -0.0311513    0.28726     -0.0784362   -0.195317     0.0770549   -0.0448905    0.0993285    0.0244573
  0.0246834   -0.083346     0.0621774    -0.132662     0.0199233    0.109323     0.00336975   0.0935923    -0.138079     0.0595693     0.0935419   -0.0214009    0.00733419   0.0378573   -0.00245014  -0.188229    -0.101493    -0.0785342    0.0471416   -0.0360558    0.0152717    0.0325951    0.122216     0.0147947    0.00447251  -0.10675
 -0.0931847    0.193348     0.0659052    -0.0416675    0.0898572    0.0782129   -0.118802    -0.186269      0.172418     0.113106      0.0290169   -0.0388723   -0.0789195   -0.100658    -0.106946    -0.0391864   -0.0366009   -0.0852649   -0.138127    -0.1491      -0.093046     0.044926     0.0528735   -0.143643     0.0648256    0.152061
  0.0648931    0.0077805   -0.167013     -0.0776094    0.0706909    0.0174448    0.0313358    0.0911817    -0.253731     0.144509      0.0989295   -0.00070729   0.0393611   -0.0581903    0.0456567    0.0554081    0.0673287   -0.217027    -0.0156209    0.0396293    0.0435116    0.014389    -0.217463    -0.0557306   -0.203231     0.0553246
 -0.0174085    0.0502839    0.0736373     0.00325853   0.130247    -0.117759    -0.0262925    0.104645      0.0101245    0.0745858     0.00183798   0.0436261    0.00471581  -0.028451     0.0120796    0.164933     0.18071      0.115609    -0.015977     0.0537231   -0.125564    -0.103071    -0.00862174   0.149608    -0.0979459    0.108266
 -0.00406544  -0.07833      0.0335925     0.0532035   -0.0257196    0.0974584   -0.0452363   -0.0869085     0.0555418   -0.126964      0.0283175    0.0160882   -0.0205877   -0.110033    -0.104406    -0.0169155   -0.142056    -0.139728    -0.206624    -0.222161     0.0138537   -0.0675829   -0.10123     -0.0640584   -0.0822041    0.0024518
 -0.128859     0.00127446  -0.128381     -0.0261442   -0.0399683    0.0906074    0.133801    -0.0136177     0.0189199    0.0406152    -0.0269015   -0.00683074   0.123256     0.00647994   0.148999     0.028169    -0.00381354   0.00640602  -0.0127133   -0.0248198    0.0379544    0.129944    -0.0138849    0.151354    -0.0967116    0.200616
 -0.06893     -0.0139336   -0.0181736     0.106331     0.00752176  -0.103099     0.121262    -0.0191563     0.0848979    0.0139034    -0.0778656    0.186737     0.0387046    0.0671602   -0.00270318   0.00729225  -0.0713496    0.00900131   0.0281698    0.0388587    0.0607374   -0.15222     -0.0121998    0.10859      0.029861     0.0261913
 -0.0862465    0.00131139   0.0279135     0.0532754    0.0394331    0.119437     0.0254309    0.00199336    0.0234051   -0.0450487    -0.119886    -0.0186503    0.0327547   -0.00299257  -0.0188656    0.0794572    0.0660997    0.102031     0.153746    -0.00908684   0.0453856   -0.0624843    0.0499182    0.0146309    0.0858677   -0.0651589
 -0.26264     -0.154225     0.000269838  -0.0273906    0.237814     0.0858712    0.0869109   -0.132944     -0.0356161    0.0582278     0.0104947   -0.0384092   -0.195815    -0.0849026   -0.120259    -0.148984    -0.0587143    0.108337     0.026747     0.0239763    0.0257273    0.0791176   -0.152948     0.230736    -0.039631    -0.12551
  0.0127776    0.0171897    0.0456215    -0.205387    -0.0456393   -0.107783    -0.0588123   -0.197587     -0.0321015   -0.0786034     0.0603087   -0.0219543    0.053503     0.114127     0.0125153   -0.055661     0.0171424    0.0666732   -0.0154519   -0.180412     0.0208448   -0.0358748    0.0725244   -0.0586402    0.115475     0.159411
 -0.0288419   -0.0437024    0.143841     -0.150077     1.19848e-5   0.127958    -0.00603827  -0.157143      0.0235076    0.0858012     0.0313985   -0.17638      0.0836353    0.115107     0.119242     0.105522    -0.110609     0.160413    -0.135462     0.173043    -0.143574    -0.341785    -0.182812    -0.17677      0.129889     0.112825
 -0.164031    -0.117331     0.0241506    -0.039417    -0.149176     0.0507556    0.28192      0.0277616     0.137936     0.0402734     0.0920493   -0.0584729    0.0926897   -0.0649619    0.0941073   -0.19744      0.124646    -0.0963347   -0.153782     0.0344174   -0.154222     0.0425429   -0.246087    -0.0478046   -0.196723    -0.00405365
 -0.163768    -0.261391    -0.0178837    -0.0191614    0.119292    -0.0349954   -0.132421    -0.0834044     0.153246     0.0605313     0.0698632   -0.0702502    0.0829525    0.0377658    0.316344    -0.0375482    0.106697    -0.0224062    0.092316     0.0742353    0.00431889   0.0446645   -0.0182241    0.0494236   -0.0504058   -0.0330704
 -0.00826517  -0.00307576  -0.0455435    -0.039707     0.0367137    0.0145327   -0.269903    -0.04817      -0.0858155   -0.045222     -0.238787     0.0428947    0.0225363   -0.040563    -0.00692095   0.0845279    0.102986     0.0381961    0.040983     0.0263087   -0.0514751    0.0914845    0.135928     0.0894176    0.167964    -0.0923737
 -0.0277395    0.107876     0.00191336   -0.0851222   -0.146786    -0.0963458   -0.00351361   0.125966      0.0244957   -0.0266582     0.149417     0.12455     -0.0317503    0.103689    -0.0436206   -0.0849689   -0.046664     0.0439147   -0.0224992   -0.20227      0.110755    -0.0870198    0.135181     0.00537243   0.0157261   -0.0494441
 -0.0862371    0.0485704   -0.104181     -0.0313616   -0.0221956   -0.253722     0.00294968  -0.118126     -0.0774648    0.118467      0.0358942    0.0917932    0.181085    -0.0186244    0.136773     0.185017    -0.00194124   0.106153    -0.00932545  -0.201271     0.0339154   -0.0478282   -0.0844167   -0.111803     0.112435    -0.261606
  0.104182     0.119781     0.0880917     0.00644088  -0.0318412   -0.120253    -0.0609793    0.0627925     0.206284    -0.0554622    -0.0128519   -0.0228962   -0.0619592   -0.0689331    0.0300034    0.14967     -0.0943722   -0.024082    -0.100029     0.0886597   -0.177035    -0.0386184    0.0798559    0.0506127   -0.0210274   -0.185309
  0.0405579    0.0994236    0.0384705    -0.280467    -0.0021408   -0.00871041  -0.0788213   -0.0977761    -0.0184673    0.0148011     0.0486648    0.0982211    0.17374     -0.0136773    0.0131351   -0.135795     0.0452447    0.0705635   -0.0244256   -0.0453442   -0.0414086   -0.0277869    0.0101809   -0.0721159   -0.0174382    0.0534022
 -0.139085     0.0291328    0.127005     -0.152187    -0.0894869   -0.0755825   -0.119141     0.00933214    0.0210473    0.00568895    0.0229507   -0.183436    -0.0153185   -0.0482671    0.0614263   -0.113238    -0.00174854  -0.0129603    0.0976727   -0.0240335   -0.128194    -0.0547421   -0.103802     0.118581     0.104697     0.234328
  0.0098422   -0.0303871    0.0618273    -0.220207    -0.0632061    0.016758     0.0184107    0.0255833    -0.0334878    0.18699      -0.0462777   -0.080297    -0.013386     0.00275536  -0.24924      0.19289      0.0307358    0.0723241   -0.00683253   0.0911652   -0.145055    -0.0165394    0.0663687    0.0800809    0.072448    -0.186628
  0.0420488   -0.0223563   -0.1691        0.035061    -0.0434679   -0.123681     0.110063    -0.00731522   -0.218269     0.0493265    -0.08591      0.168886     0.163685    -0.00593113   0.0307724    0.00783328  -0.128687    -0.0863861   -0.0871768   -0.0140419    0.0335558    0.106343     0.0232976   -0.169447     0.0596363   -0.0490146
  0.185514    -0.119421    -0.0343093     0.0198709    0.0628766   -0.14086      0.016332    -0.0494906     0.0778202    0.146891     -0.127171    -0.0213039   -0.00276539   0.244824     0.00369476   0.168266     0.168168    -0.108228    -0.0808976   -0.0129106   -0.138205     0.0393405   -0.0890003    0.00125316  -0.0143263    0.066005
  0.127205    -0.021921     0.0730163    -0.0761615   -0.116598     0.0343015   -0.0140689   -0.000749057   0.0422394    0.10633       0.0840675    0.0565469    0.21022     -0.0849181    0.131177     0.10937     -0.0613407   -0.12495      0.109522    -0.0638309    0.117262    -0.0797937   -0.0783693   -0.0752486   -0.071522    -0.132247[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     10
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.043077
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      5
│     10
│     18
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.000214
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      6
│      7
│     10
│     18
│     19
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.005047
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│     10
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.991916
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      9
│     10
│     18
│     21
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.977687
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│      6
│      7
│     10
│     19
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.015112
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│      5
│     10
│     18
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -0.996285
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      9
│     10
│     21
│     23
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.985069
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│      6
│      7
│      ⋮
│     19
│     23
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.012781
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      5
│     10
│     23
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.000339
┌ Info: EM with 100000 data points 10 iterations avll -1.000339
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0270541    0.0904594     0.281721     0.167364    -0.154276     -0.156464     0.0426223    -0.0503797    0.00457257   -0.105214    0.0808625     0.0627321    -0.0919976     0.123237      0.0601366    0.0824375    -0.00494319    0.0098608    -0.259988    -0.177542     0.120622    -0.0216434   -0.125277    -0.194348     0.119282     -0.129806
  0.0668805    0.051624      0.176486     0.165874     0.0158923     0.162238     0.0927728     0.0135446    0.157027      0.0407424   0.0120875     0.0668594    -0.0944911     0.0790856     0.063775     0.000167363   0.0191786     0.195787      0.165903    -0.114145     0.132239     0.0152278   -0.00753415  -0.075654    -0.0802426    -0.124572
  0.0178689   -0.00826949    0.0643773    0.0574705    0.00521263   -0.0363071   -0.0634274     0.128142     0.124094      0.0869388   0.165185      0.158219      0.130988     -0.0761476    -0.0445017    0.00192342   -0.0394213    -0.0397616     0.0997041   -0.0369746    0.105437     0.0506496    0.0251589   -0.0585479    0.102929     -0.0815403
  0.0124757    0.166521      0.121191    -0.0644029   -0.024528     -0.0416471    0.0333963     0.142463    -0.260938      0.0722833  -0.109316      0.0549471     0.113979      0.0343229    -0.0649101    0.0331159    -0.0958317    -0.0780001    -0.00331518  -0.0375053   -0.024209    -0.0725658    0.133539    -0.0666536   -0.0656929    -0.0983912
 -0.0397389    0.0687975     0.11333     -0.11168      0.0163445    -0.0782521    0.124807     -0.113205    -0.143491      0.051429   -0.0875117     0.0218821     0.151109      0.164719     -0.0892557    0.0622812    -0.19187      -0.000991202  -0.197816    -0.00132413  -0.0378081   -0.0713658    0.0553828    0.078736     0.16058      -0.0148298
  0.055296    -0.0215713    -0.0108307   -0.0973997   -0.0107031    -0.176883     0.180545      0.131596     0.0522419     0.031012   -0.0797793     0.0239816    -0.0659772     0.00741513   -0.0503347   -0.0791561     0.15792       0.138037      0.0866482   -0.0199465    0.0624582    0.0424167   -0.17974     -0.0306792   -0.0544446    -0.0288052
  0.174715    -0.0275373     0.100078     0.0798438   -0.154243     -0.156071     0.0794967    -0.141319    -0.0722937    -0.079259    0.26357      -0.202964      0.0756721     0.111512     -0.0699259   -0.0822196    -0.0613656    -0.197388     -0.0145806   -0.128347    -0.059936    -0.163126    -0.0895962   -0.0210117    0.182306     -0.0735941
 -0.0620343   -0.0264852    -0.0149533    0.0677949    0.0821918    -0.167472    -0.0482623     0.024267    -0.0258177     0.0626518  -0.0889182    -0.193633     -0.0667563     0.0815491    -0.181516    -0.0874951     0.000808913  -0.231366      0.00147604  -0.0267894    0.0678733    0.229578    -0.0889568    0.0187171    0.0366264    -0.0853227
  0.117165    -0.153736      0.0179127    0.234668     0.0447724    -0.0388482    0.106588     -0.0310468    0.0445366     0.0551224  -0.0447629    -0.047125     -0.0557281     0.116902      0.0350291   -0.118632     -0.0760127    -0.0043681     0.206638     0.0968604    0.187978    -0.0508796    0.081463     0.125209     0.0840562    -0.00546394
  0.0787342    0.0122241     0.131236     0.0480938   -0.125055     -0.114006     0.192923     -0.191525     0.0848856    -0.0109699  -0.0715006     0.103941      0.190102     -0.0331751     0.00838377  -0.0621981     0.10323       0.0883748    -0.00619091  -0.0611746   -0.0520265    0.269531    -0.150968    -0.264124     0.110785      0.0362739
  0.0459972    0.132175      0.0461994   -0.121708    -0.2513       -0.0521494    0.0577416     0.0766251    0.0555181     0.147744   -0.125354      0.0655789    -0.00727224    0.226323      0.0392699    0.139453     -0.241519     -0.0957969    -0.229328    -0.124302    -0.074569    -0.0790205    0.135511     0.0756866    0.0633941    -0.036484
 -0.0770925    0.0393602    -0.102558    -0.0185566   -0.160383     -0.0669596   -0.064727      0.201519    -0.0248581     0.0324266  -0.0871461    -0.157587     -0.0107904     0.0932969    -0.0319108   -0.149341      0.171754     -0.023608      0.0680572   -0.060119    -0.0935489   -0.0171208   -0.0879818    0.312738    -0.226416     -0.0822688
 -0.0174604    0.0117799    -0.0147813   -0.149851     0.321331     -0.105328    -0.140876      0.101653    -0.0235696    -0.0308481  -0.218641     -0.0377686     0.0599146     0.0598964     0.122091     0.00820514   -0.00847782   -0.0331701     0.0868146   -0.00960173   0.181517     0.0277329    0.00915144   0.135189    -0.0114499    -0.0282808
  0.056254    -0.0702186     0.0499902    0.094412     0.22615       0.00603685  -0.151687     -0.0756073   -0.150355     -0.0602251   0.113099     -0.158005     -0.123738      0.0612933    -0.125712     0.138331      0.0841612     0.0259772    -0.0546992   -0.177914    -0.0896046   -0.0536368   -0.0971902   -0.0614619    0.0779827     0.0381822
  0.0594265   -0.013765     -0.0649591    0.0232311   -0.0161493     0.107256     0.0174982    -0.102238    -0.187689     -0.237787   -0.08668      -0.0851503    -0.0292152     0.128         0.0461879    0.0394781     0.102615     -0.000271371   0.0555509    0.0134416    0.075353    -0.107026    -0.304767    -0.110367    -0.0113786     0.0862823
  0.12751      0.0489578    -0.0019218    0.0408733   -0.0397304    -0.0259495    0.0171146    -0.250101    -0.0293674     0.18512    -0.0298737    -0.114555      0.0351131    -0.0848523     0.0522766   -0.0574856     0.11837      -0.0883232    -0.111824    -0.0212147   -0.100133    -0.231677     0.0323409   -0.217581    -0.168943     -0.109022
 -0.00624491   0.0799434    -0.102205    -0.00311583  -0.00222825   -0.0395441    0.186844      0.224289     0.0885851    -0.144697   -0.0752137     0.119233     -0.0388563     0.0875142    -0.0823956   -0.126306     -0.0542825     0.157731      0.0159887   -0.0248238    0.0466684   -0.0314322    0.16622      0.040743    -0.0394556    -0.0344991
  0.154752    -0.0490298    -0.0670083    0.101223     0.0414828     0.0454995   -0.0190593    -0.0662391   -0.0451793     0.096578    0.0475874     0.224025      0.0359298    -0.0585197     0.0770596    0.0346339     0.0547862     0.140796      0.0316102   -0.102257    -0.0485507    0.0736033   -0.0540769   -0.0080646    0.0488155    -0.125965
 -0.121854    -0.000234006   0.0107598   -0.0297576   -0.104297      0.137854     0.000541477  -0.0146912   -0.0531106     0.187028    0.0108599    -0.214122      0.0986193     0.11996       0.087552    -0.211834     -0.0559546     0.0592752    -0.0453184    0.198911    -0.14053      0.0799704    0.190632    -0.030542     0.0326254     0.00516359
  0.0382195   -0.0450868    -0.2194       0.111541     0.0168695    -0.105625     0.014922      0.00442128  -0.0197076    -0.0611069   0.0677751     0.0419125    -0.0447925     0.0551059     0.0540176    0.0494561    -0.160907     -0.0122016     0.139147     0.0627821    0.0064526    0.0531995   -0.00301857   0.127512    -0.0636048     0.0038992
 -0.0193221   -0.0191158    -0.163441     0.177814    -0.10982       0.138473    -0.0603802     0.0900037    0.05507      -0.0262157   0.1074        0.145921     -0.105099     -0.109996      0.141781     0.0200764    -0.181314      0.0439439     0.262411     0.0829746    0.00925556  -0.035103     0.225265     0.0428207    0.114061      0.0215454
  0.0516278    0.0572207    -0.00367485  -0.128842     0.0401871    -0.0880428    0.185054     -0.0451492   -0.107929     -0.0327577  -0.166381      0.00350152   -0.0605654     0.0241252    -0.0242889    0.0536736    -0.0710914    -0.0535562     0.378046     0.00175667  -0.118098    -0.0401949    0.00292577  -0.0283343   -0.0523128     0.0526603
 -0.0168114   -0.0971592     0.255608    -0.0110836    0.241824     -0.13958     -0.0940837    -0.0210038   -0.0999412    -0.127505    0.0538192     0.0786687     0.14482      -0.029089      0.0581344   -0.0811243     0.0150375     0.0730255    -0.110839     0.0336565   -0.0520137   -0.155191     0.00102283  -0.188335    -0.0925047     0.0329162
 -0.0297192    0.213093     -0.0343192   -0.0910009    0.105532      0.0778609    0.0264474    -0.0618553    0.115551      0.0073088   0.000766483   0.0874578    -0.140607     -0.00764797   -0.0939536   -0.209177      0.0332765    -0.0475725     0.0703822   -0.0411538    0.146248    -0.0606639    0.113988     0.114476    -0.0158245    -0.155431
  0.00863686   0.0256554     0.0900174    0.0305611    0.000593401   0.0900014    0.0361511    -0.029177    -0.135704     -0.105419    0.0582623     0.00220927   -0.0627009     0.0083546    -0.0306223   -0.159946      0.0508781    -0.0793802    -0.0524547   -0.12525      0.154485    -0.0182839   -0.0487927    0.0320496   -0.195632      0.0485269
 -0.132179     0.013471     -0.0939339    0.103555    -0.0522613     0.0881113   -0.0012372    -0.056544     0.0601468    -0.126781   -0.0421125    -0.000899618   0.0102118     0.00159481    0.0686368   -0.139657      0.0302905    -0.0327493     0.0885561    0.0275611    0.0260307    0.00120908   0.169771    -0.0528843    0.136801      0.128848
 -0.13503     -0.0165385     0.111747     0.0298916    0.0448697     0.112413    -0.116108      0.00772898  -0.133978     -0.0351021  -0.0326267    -0.094402     -0.175001     -0.0942164     0.152104     0.0976182     0.0615294    -0.0515742     0.0764096    0.0338906    0.303681     0.09692      0.103522    -0.104326    -0.00972543   -0.107921
  0.0286046    0.196433      0.0477489   -0.0194393    0.0820019    -0.0481954   -0.0313663     0.169332     0.000445772  -0.146451    0.0232479    -0.13847       0.000969663   0.0419062    -0.112781     0.00502354    0.105792      0.0610523    -0.0403847   -0.0914308    0.15503      0.122454     0.0331388   -0.260567    -0.141301      0.0162672
  0.205743    -0.0125914    -0.191516     0.0944812   -0.0355571     0.0978894   -0.268798      0.178464    -0.184304      0.0616467   0.0379938     0.0969737     0.15212       0.0256368     0.0682094    0.0736692    -0.0760054     0.18965       0.168593     0.0338564    0.0640589    0.106448    -0.0386514    0.0413122   -0.0731104    -0.0548684
  0.0707032    0.0595549    -0.0865969    0.0654361   -0.114834      0.284687     0.136552     -0.0682454    0.0130125     0.0166273   0.00821164   -0.0729003     0.0637212    -0.00180156   -0.0980017    0.0645282    -0.0267616    -0.174435     -0.072886     0.057058     0.18854     -0.0281477    0.130929     0.00904897  -0.025531     -0.0125363
 -0.0738294    0.0408782    -0.0490926   -0.0327381    0.181894     -0.0449269   -0.0588373     0.11313      0.0898645     0.0273647  -0.10703       0.104676      0.00784482   -0.0213748    -0.0114478    0.15938      -0.0106758     0.108354      0.0535079    0.139781    -0.0574814    0.225962    -0.0610406    0.038411    -0.032097     -0.0573521
 -0.0552325   -0.25646       0.0297744    0.0276996   -0.166514      0.117861    -0.0232492     0.0971684    0.0563854    -0.133994    0.163516     -0.100889     -0.125357      0.000197289  -0.0355753   -0.164903      0.0991908     0.0729144     0.176507    -0.0260881   -0.150038     0.0875631   -0.0825816   -0.0312773   -0.000177779  -0.038831kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4160927224683375
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416111
[ Info: iteration 2, average log likelihood -1.416042
[ Info: iteration 3, average log likelihood -1.415995
[ Info: iteration 4, average log likelihood -1.415948
[ Info: iteration 5, average log likelihood -1.415898
[ Info: iteration 6, average log likelihood -1.415843
[ Info: iteration 7, average log likelihood -1.415777
[ Info: iteration 8, average log likelihood -1.415684
[ Info: iteration 9, average log likelihood -1.415513
[ Info: iteration 10, average log likelihood -1.415153
[ Info: iteration 11, average log likelihood -1.414431
[ Info: iteration 12, average log likelihood -1.413270
[ Info: iteration 13, average log likelihood -1.411981
[ Info: iteration 14, average log likelihood -1.411082
[ Info: iteration 15, average log likelihood -1.410665
[ Info: iteration 16, average log likelihood -1.410513
[ Info: iteration 17, average log likelihood -1.410460
[ Info: iteration 18, average log likelihood -1.410442
[ Info: iteration 19, average log likelihood -1.410435
[ Info: iteration 20, average log likelihood -1.410433
[ Info: iteration 21, average log likelihood -1.410431
[ Info: iteration 22, average log likelihood -1.410431
[ Info: iteration 23, average log likelihood -1.410430
[ Info: iteration 24, average log likelihood -1.410430
[ Info: iteration 25, average log likelihood -1.410429
[ Info: iteration 26, average log likelihood -1.410429
[ Info: iteration 27, average log likelihood -1.410429
[ Info: iteration 28, average log likelihood -1.410429
[ Info: iteration 29, average log likelihood -1.410428
[ Info: iteration 30, average log likelihood -1.410428
[ Info: iteration 31, average log likelihood -1.410428
[ Info: iteration 32, average log likelihood -1.410428
[ Info: iteration 33, average log likelihood -1.410428
[ Info: iteration 34, average log likelihood -1.410428
[ Info: iteration 35, average log likelihood -1.410428
[ Info: iteration 36, average log likelihood -1.410427
[ Info: iteration 37, average log likelihood -1.410427
[ Info: iteration 38, average log likelihood -1.410427
[ Info: iteration 39, average log likelihood -1.410427
[ Info: iteration 40, average log likelihood -1.410427
[ Info: iteration 41, average log likelihood -1.410427
[ Info: iteration 42, average log likelihood -1.410427
[ Info: iteration 43, average log likelihood -1.410427
[ Info: iteration 44, average log likelihood -1.410427
[ Info: iteration 45, average log likelihood -1.410427
[ Info: iteration 46, average log likelihood -1.410427
[ Info: iteration 47, average log likelihood -1.410427
[ Info: iteration 48, average log likelihood -1.410427
[ Info: iteration 49, average log likelihood -1.410427
[ Info: iteration 50, average log likelihood -1.410427
┌ Info: EM with 100000 data points 50 iterations avll -1.410427
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4161105582566305
│     -1.4160418815138545
│      ⋮
└     -1.4104269049980738
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410441
[ Info: iteration 2, average log likelihood -1.410373
[ Info: iteration 3, average log likelihood -1.410321
[ Info: iteration 4, average log likelihood -1.410265
[ Info: iteration 5, average log likelihood -1.410200
[ Info: iteration 6, average log likelihood -1.410126
[ Info: iteration 7, average log likelihood -1.410044
[ Info: iteration 8, average log likelihood -1.409958
[ Info: iteration 9, average log likelihood -1.409873
[ Info: iteration 10, average log likelihood -1.409794
[ Info: iteration 11, average log likelihood -1.409728
[ Info: iteration 12, average log likelihood -1.409675
[ Info: iteration 13, average log likelihood -1.409637
[ Info: iteration 14, average log likelihood -1.409611
[ Info: iteration 15, average log likelihood -1.409594
[ Info: iteration 16, average log likelihood -1.409582
[ Info: iteration 17, average log likelihood -1.409574
[ Info: iteration 18, average log likelihood -1.409568
[ Info: iteration 19, average log likelihood -1.409563
[ Info: iteration 20, average log likelihood -1.409559
[ Info: iteration 21, average log likelihood -1.409556
[ Info: iteration 22, average log likelihood -1.409553
[ Info: iteration 23, average log likelihood -1.409550
[ Info: iteration 24, average log likelihood -1.409548
[ Info: iteration 25, average log likelihood -1.409546
[ Info: iteration 26, average log likelihood -1.409543
[ Info: iteration 27, average log likelihood -1.409541
[ Info: iteration 28, average log likelihood -1.409539
[ Info: iteration 29, average log likelihood -1.409537
[ Info: iteration 30, average log likelihood -1.409536
[ Info: iteration 31, average log likelihood -1.409534
[ Info: iteration 32, average log likelihood -1.409532
[ Info: iteration 33, average log likelihood -1.409530
[ Info: iteration 34, average log likelihood -1.409528
[ Info: iteration 35, average log likelihood -1.409527
[ Info: iteration 36, average log likelihood -1.409525
[ Info: iteration 37, average log likelihood -1.409523
[ Info: iteration 38, average log likelihood -1.409521
[ Info: iteration 39, average log likelihood -1.409519
[ Info: iteration 40, average log likelihood -1.409517
[ Info: iteration 41, average log likelihood -1.409514
[ Info: iteration 42, average log likelihood -1.409512
[ Info: iteration 43, average log likelihood -1.409510
[ Info: iteration 44, average log likelihood -1.409507
[ Info: iteration 45, average log likelihood -1.409504
[ Info: iteration 46, average log likelihood -1.409500
[ Info: iteration 47, average log likelihood -1.409497
[ Info: iteration 48, average log likelihood -1.409493
[ Info: iteration 49, average log likelihood -1.409489
[ Info: iteration 50, average log likelihood -1.409484
┌ Info: EM with 100000 data points 50 iterations avll -1.409484
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4104414339516311
│     -1.4103734546567854
│      ⋮
└     -1.4094837291934914
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409488
[ Info: iteration 2, average log likelihood -1.409410
[ Info: iteration 3, average log likelihood -1.409334
[ Info: iteration 4, average log likelihood -1.409240
[ Info: iteration 5, average log likelihood -1.409122
[ Info: iteration 6, average log likelihood -1.408983
[ Info: iteration 7, average log likelihood -1.408831
[ Info: iteration 8, average log likelihood -1.408684
[ Info: iteration 9, average log likelihood -1.408550
[ Info: iteration 10, average log likelihood -1.408435
[ Info: iteration 11, average log likelihood -1.408338
[ Info: iteration 12, average log likelihood -1.408257
[ Info: iteration 13, average log likelihood -1.408191
[ Info: iteration 14, average log likelihood -1.408136
[ Info: iteration 15, average log likelihood -1.408092
[ Info: iteration 16, average log likelihood -1.408057
[ Info: iteration 17, average log likelihood -1.408028
[ Info: iteration 18, average log likelihood -1.408004
[ Info: iteration 19, average log likelihood -1.407984
[ Info: iteration 20, average log likelihood -1.407966
[ Info: iteration 21, average log likelihood -1.407951
[ Info: iteration 22, average log likelihood -1.407938
[ Info: iteration 23, average log likelihood -1.407925
[ Info: iteration 24, average log likelihood -1.407914
[ Info: iteration 25, average log likelihood -1.407903
[ Info: iteration 26, average log likelihood -1.407893
[ Info: iteration 27, average log likelihood -1.407884
[ Info: iteration 28, average log likelihood -1.407875
[ Info: iteration 29, average log likelihood -1.407866
[ Info: iteration 30, average log likelihood -1.407858
[ Info: iteration 31, average log likelihood -1.407851
[ Info: iteration 32, average log likelihood -1.407843
[ Info: iteration 33, average log likelihood -1.407836
[ Info: iteration 34, average log likelihood -1.407830
[ Info: iteration 35, average log likelihood -1.407823
[ Info: iteration 36, average log likelihood -1.407817
[ Info: iteration 37, average log likelihood -1.407811
[ Info: iteration 38, average log likelihood -1.407805
[ Info: iteration 39, average log likelihood -1.407800
[ Info: iteration 40, average log likelihood -1.407794
[ Info: iteration 41, average log likelihood -1.407789
[ Info: iteration 42, average log likelihood -1.407784
[ Info: iteration 43, average log likelihood -1.407780
[ Info: iteration 44, average log likelihood -1.407775
[ Info: iteration 45, average log likelihood -1.407770
[ Info: iteration 46, average log likelihood -1.407766
[ Info: iteration 47, average log likelihood -1.407762
[ Info: iteration 48, average log likelihood -1.407758
[ Info: iteration 49, average log likelihood -1.407754
[ Info: iteration 50, average log likelihood -1.407750
┌ Info: EM with 100000 data points 50 iterations avll -1.407750
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4094879643324985
│     -1.4094102108554536
│      ⋮
└     -1.4077501220770363
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407756
[ Info: iteration 2, average log likelihood -1.407699
[ Info: iteration 3, average log likelihood -1.407651
[ Info: iteration 4, average log likelihood -1.407596
[ Info: iteration 5, average log likelihood -1.407530
[ Info: iteration 6, average log likelihood -1.407448
[ Info: iteration 7, average log likelihood -1.407351
[ Info: iteration 8, average log likelihood -1.407242
[ Info: iteration 9, average log likelihood -1.407125
[ Info: iteration 10, average log likelihood -1.407007
[ Info: iteration 11, average log likelihood -1.406893
[ Info: iteration 12, average log likelihood -1.406787
[ Info: iteration 13, average log likelihood -1.406690
[ Info: iteration 14, average log likelihood -1.406604
[ Info: iteration 15, average log likelihood -1.406529
[ Info: iteration 16, average log likelihood -1.406465
[ Info: iteration 17, average log likelihood -1.406410
[ Info: iteration 18, average log likelihood -1.406363
[ Info: iteration 19, average log likelihood -1.406322
[ Info: iteration 20, average log likelihood -1.406287
[ Info: iteration 21, average log likelihood -1.406257
[ Info: iteration 22, average log likelihood -1.406230
[ Info: iteration 23, average log likelihood -1.406205
[ Info: iteration 24, average log likelihood -1.406184
[ Info: iteration 25, average log likelihood -1.406164
[ Info: iteration 26, average log likelihood -1.406145
[ Info: iteration 27, average log likelihood -1.406128
[ Info: iteration 28, average log likelihood -1.406112
[ Info: iteration 29, average log likelihood -1.406097
[ Info: iteration 30, average log likelihood -1.406083
[ Info: iteration 31, average log likelihood -1.406069
[ Info: iteration 32, average log likelihood -1.406056
[ Info: iteration 33, average log likelihood -1.406043
[ Info: iteration 34, average log likelihood -1.406031
[ Info: iteration 35, average log likelihood -1.406020
[ Info: iteration 36, average log likelihood -1.406008
[ Info: iteration 37, average log likelihood -1.405997
[ Info: iteration 38, average log likelihood -1.405987
[ Info: iteration 39, average log likelihood -1.405976
[ Info: iteration 40, average log likelihood -1.405966
[ Info: iteration 41, average log likelihood -1.405956
[ Info: iteration 42, average log likelihood -1.405946
[ Info: iteration 43, average log likelihood -1.405936
[ Info: iteration 44, average log likelihood -1.405927
[ Info: iteration 45, average log likelihood -1.405918
[ Info: iteration 46, average log likelihood -1.405908
[ Info: iteration 47, average log likelihood -1.405899
[ Info: iteration 48, average log likelihood -1.405890
[ Info: iteration 49, average log likelihood -1.405882
[ Info: iteration 50, average log likelihood -1.405873
┌ Info: EM with 100000 data points 50 iterations avll -1.405873
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4077556078213103
│     -1.4076993519962666
│      ⋮
└     -1.4058728573226915
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405873
[ Info: iteration 2, average log likelihood -1.405802
[ Info: iteration 3, average log likelihood -1.405733
[ Info: iteration 4, average log likelihood -1.405651
[ Info: iteration 5, average log likelihood -1.405547
[ Info: iteration 6, average log likelihood -1.405417
[ Info: iteration 7, average log likelihood -1.405262
[ Info: iteration 8, average log likelihood -1.405087
[ Info: iteration 9, average log likelihood -1.404903
[ Info: iteration 10, average log likelihood -1.404721
[ Info: iteration 11, average log likelihood -1.404549
[ Info: iteration 12, average log likelihood -1.404392
[ Info: iteration 13, average log likelihood -1.404253
[ Info: iteration 14, average log likelihood -1.404130
[ Info: iteration 15, average log likelihood -1.404024
[ Info: iteration 16, average log likelihood -1.403931
[ Info: iteration 17, average log likelihood -1.403851
[ Info: iteration 18, average log likelihood -1.403781
[ Info: iteration 19, average log likelihood -1.403720
[ Info: iteration 20, average log likelihood -1.403666
[ Info: iteration 21, average log likelihood -1.403619
[ Info: iteration 22, average log likelihood -1.403578
[ Info: iteration 23, average log likelihood -1.403540
[ Info: iteration 24, average log likelihood -1.403506
[ Info: iteration 25, average log likelihood -1.403475
[ Info: iteration 26, average log likelihood -1.403447
[ Info: iteration 27, average log likelihood -1.403421
[ Info: iteration 28, average log likelihood -1.403397
[ Info: iteration 29, average log likelihood -1.403375
[ Info: iteration 30, average log likelihood -1.403354
[ Info: iteration 31, average log likelihood -1.403334
[ Info: iteration 32, average log likelihood -1.403315
[ Info: iteration 33, average log likelihood -1.403297
[ Info: iteration 34, average log likelihood -1.403280
[ Info: iteration 35, average log likelihood -1.403264
[ Info: iteration 36, average log likelihood -1.403248
[ Info: iteration 37, average log likelihood -1.403234
[ Info: iteration 38, average log likelihood -1.403219
[ Info: iteration 39, average log likelihood -1.403206
[ Info: iteration 40, average log likelihood -1.403193
[ Info: iteration 41, average log likelihood -1.403180
[ Info: iteration 42, average log likelihood -1.403168
[ Info: iteration 43, average log likelihood -1.403156
[ Info: iteration 44, average log likelihood -1.403145
[ Info: iteration 45, average log likelihood -1.403134
[ Info: iteration 46, average log likelihood -1.403124
[ Info: iteration 47, average log likelihood -1.403113
[ Info: iteration 48, average log likelihood -1.403104
[ Info: iteration 49, average log likelihood -1.403094
[ Info: iteration 50, average log likelihood -1.403086
┌ Info: EM with 100000 data points 50 iterations avll -1.403086
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4058726247061322
│     -1.4058019877987211
│      ⋮
└     -1.403085512770452
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4160927224683375
│     -1.4161105582566305
│     -1.4160418815138545
│     -1.4159953664207816
│      ⋮
│     -1.4031038028318528
│     -1.403094485818989
└     -1.403085512770452
32×26 Array{Float64,2}:
  0.453747    -0.0443778   -0.378099   -0.21367    -0.557785     0.148172   -0.265892    0.288893    0.417947     0.0246677   -0.056173    0.0789431    0.267292    -0.00724459  -0.208618   -0.0714149  -0.208459     0.228728     0.469945    -0.0386034    0.418788    0.19413     0.526135   -0.395093   -0.113183   -0.356335
 -0.0493043   -0.643063     0.237977    0.368881   -0.116253     0.116832   -0.40225     0.113638    0.34402     -0.0367905   -0.0434463  -0.170039     0.306448     0.667195     0.232037   -0.025667   -0.236691    -0.0906281    0.50639      0.208797     0.0958003   0.295864   -0.0424314  -0.405636   -0.0527566  -0.681249
 -0.306307    -0.0618361   -0.518008   -0.297329   -0.169167     0.340488    0.47346    -0.429522   -0.245637     0.0227724    0.205619    0.185667    -0.105286     0.264281    -0.197016    0.517078    0.0123744    0.190701     0.255167     0.281231     1.02563     0.0991424   0.204957   -1.06854     0.273091   -0.0207386
 -0.182788    -0.0930918    0.158633   -0.182187   -0.654289     0.270536    0.819749   -0.161912    0.201066    -0.245892     0.0516065  -0.21458     -0.281221     0.300584    -0.11161    -0.275524    0.34323      0.583846     0.0215019    0.0258677    0.776531    0.145752   -0.178369    0.334598    0.324981   -0.150151
  0.0350766   -0.0846438   -0.387145   -0.278858    0.0570657   -0.260441   -0.208705   -0.437223    0.178103     0.321847     0.020651   -0.139628    -0.29606     -0.239891     0.25787     0.381374    0.0835728    0.0179013    0.0819992    0.179477    -0.114475   -0.0377533  -0.139922   -0.381646    0.131526    0.271354
 -0.497884     0.319145    -0.484291    0.218462    0.124782    -0.375172    0.0279579   0.0707864  -0.274633     0.114836     0.136236   -0.150997     0.0489059   -0.185806     0.0509842  -0.230877   -0.0462742    0.146013     0.00567188  -0.186321     0.0423025  -0.0239497   0.3203     -0.0954447   0.267667   -0.109982
  0.146052     0.0880949    0.249287   -0.204122    0.061667    -0.485392   -0.452495    0.0155571  -0.0203205   -0.250143    -0.020304   -0.0815662    0.102856    -0.507437    -0.130724   -0.213921    0.143817    -0.198308     0.144389    -0.0226982   -0.0917355   0.412026   -0.184621    0.245136    0.271625    0.267252
  0.24926     -0.169421     0.852455    0.269565   -0.565956     0.417448   -0.086939   -0.309952   -0.0491624    0.144749     0.194678    0.358113     0.0843424   -0.147779     0.341658   -0.254869   -0.104492     0.0610659    0.00597177   0.131977    -0.010976   -0.0902387  -0.205605    0.106017    0.151667    0.31746
 -0.202602     0.24212     -0.140412    0.0246818   0.151671     0.104827   -0.0756467  -0.545904    0.35027      0.0998049    0.0930685   0.220464     0.150583    -0.0654366   -0.23522    -0.507001    0.855251    -0.65432     -0.396879     0.340402     0.0325551   0.130368    0.0280903  -0.0559325   0.201355   -0.569352
 -0.388083    -0.00620382   0.0138681   0.198193    0.173179     0.151395    0.200057    0.400905   -0.0784411   -0.649767    -0.153674    0.238623     0.0773816    0.250735    -0.342996   -0.206172    0.322968    -0.0541609    0.048102    -0.126111     0.0530081   0.159666   -0.0357444  -0.0638939  -0.497115   -0.689547
 -0.179926     0.141142     0.0610328   0.444724   -0.0517321    0.434292    0.398469    0.123468    0.113516    -0.161825     0.0329303  -0.287847    -0.185602     0.329279    -0.385765   -0.382711    0.777044    -0.385374    -0.0680774   -0.626878    -0.30757    -0.328571    0.429304   -0.377496   -0.0371062   0.310984
 -0.108909     0.0285557   -0.0828328  -0.351679   -0.100837     0.0601617   0.20672     0.758437   -0.175914     0.161676     0.014538   -0.757594     0.0384769    0.094072    -0.72716    -0.441242    0.114898    -0.445527    -0.485997    -0.108929    -0.469296   -0.223846    0.550318    0.984197   -0.372743    0.321656
  0.328175    -0.0141146    0.221567    0.125905    0.352109     0.379215    0.255193   -0.162129   -0.00143704   0.241208    -0.394066   -0.0601725   -0.00468672   0.495584     0.142655    0.254503   -0.386595    -0.387099    -0.262483     0.0920827   -0.0583582  -0.228412   -0.228183    0.173893   -0.175997   -0.084175
  0.0729851    0.00551643   0.102231    0.0565873  -0.0184297    0.0892098   0.0983295   0.0171178  -0.0341813   -0.0426002    0.0107351  -0.00880098  -0.0167713    0.114863    -0.0384284   0.0222222  -0.00919559   0.0130705    0.070755    -0.0176479    0.111161    0.0203005   0.0144135   0.0173333  -0.05308    -0.0680549
  0.270516    -0.105807    -0.0647522  -0.963033   -0.219004     0.0261922   0.486547    0.0844053  -0.316903    -0.0258251    0.0885512   0.435118    -0.39681      0.336485    -0.201034    0.0897012  -0.236569     0.629665     0.280058    -0.252386    -0.401356   -0.245818   -0.534721    0.0895649  -0.478957    0.338507
  0.335545     0.18654      0.291351    0.551759    0.291626    -0.205352    0.0589039   0.729189   -0.104387    -0.408561    -0.103781   -0.24658     -0.200219    -0.102379     0.240011    0.232032   -0.295815     0.579829     0.188384    -0.424352    -0.308089   -0.343336   -0.199665   -0.0982232  -0.305736    0.257266
 -0.178873     0.528693    -0.193799   -0.138663    0.911044    -0.0392135  -0.869562    0.407893    0.0351871    0.21101     -0.100535    0.65083      0.3849      -0.140681     0.719224   -0.614896   -0.221391     0.0943739    0.222419     0.0810645   -0.392976   -0.69661    -0.0883305  -0.463886   -0.648049   -0.665874
 -0.00472867   0.328221    -0.0152977   0.301016    0.465821     0.110357   -0.56578     0.0961624  -0.617141     0.0799945   -0.418179    0.431658     0.00237655  -0.471125     0.157273    0.697922   -0.338948    -0.496134     0.145433    -0.353481    -0.43488    -0.0668036  -0.0402935  -0.499258   -0.326747    0.460743
 -0.475427     0.299888     0.273534   -0.328022    0.430596    -0.0841195   0.473876   -0.45047    -0.354057     0.13112     -0.0683105   0.347578     0.333062    -0.174444     0.19835     0.17562     0.278222     0.452747    -0.568912    -0.0314503    0.263494   -0.538249    0.183822   -0.469591   -0.439907   -0.322012
 -0.804046     0.0762066   -0.179361    0.143633    0.54995      0.302658    0.275145   -0.158754   -0.559922     0.349654    -0.150089    0.0885028   -0.172227    -0.0431703    0.394905   -0.383309   -0.119896     0.476905    -0.306757     0.090239    -0.051956   -0.469224    0.150636    0.900702   -0.397537   -0.255472
 -0.670385     0.0753657   -0.0677236   0.10623    -0.210281    -0.0960925  -1.11525     0.687892   -0.0664575   -0.128344     0.357929    0.00799957   0.180207    -0.395559     0.238053   -0.845918    0.0310085    0.16446      0.549991    -0.557765     0.323352    0.191094    0.38292     0.415426   -0.0483376   0.0140415
  0.32149      0.0265798    0.478899    0.106362   -0.272056     0.308176    0.039659    0.494247   -0.535799     0.00767733   0.162349    0.039197     0.350913    -0.256506    -0.279105    0.0509233  -0.212191    -0.0146339    0.0863672   -0.0563968    0.886724    0.673373    0.407183    0.48813    -0.602328   -0.465515
  0.359186     0.0876745    0.625266    0.40562     0.482059    -0.420996   -0.257128    0.041132    0.175131    -0.480895    -0.048598   -0.870489     1.14683     -0.257356     0.353158   -0.200775    0.346876    -0.134032    -0.348425    -0.0594782   -0.0280779  -0.0574583   0.0431331   0.0497193   0.0938432  -0.435021
  0.46851     -0.10171      1.26671     0.536883    0.168552    -0.150492   -0.0821818   0.372292   -0.0812494   -0.410042    -0.32384     0.213842    -0.0788284   -0.121014     0.395546   -0.663107    0.13135     -0.0547677   -0.247782    -0.532936    -0.680339    0.184462   -0.256608    1.2973     -0.268962    0.202109
  0.117371     0.273268     0.0258322  -0.400352   -0.0198993   -0.777277    0.0337852   0.371009   -0.234583    -0.225721     0.664892    0.272035     0.161982    -0.630077    -0.177252    0.122333    0.122275     0.00678385   0.118007    -0.221215     0.0249212   0.995057   -0.0532826  -0.315298    0.452002    0.168076
 -0.526553     0.128531    -0.596512   -0.221393   -0.29329     -0.348075   -0.715095   -0.297089    0.338911     0.300824     0.467267   -0.344881     0.133012    -0.22805      0.181884    0.306965    0.143124     0.001548     0.0416122    0.0594984   -0.311153   -0.355091    0.243501   -0.819495    0.11915    -0.129504
  0.21413      0.294009    -0.173895   -0.0833874   0.173618    -0.231408   -0.468748   -0.389881    0.104113     0.443967     0.0539138   0.0481959   -0.149756    -0.168474     0.601416    0.214786   -0.791608     0.191991     0.258032     0.552471     0.629354    0.249651   -0.16312     0.37915     0.282796   -0.324344
 -0.0835333    0.0838214   -0.11151     0.0273985  -0.377635    -0.0740465  -0.0621019  -0.322883   -0.0888049    0.618555     0.195711   -0.0520965   -0.351641    -0.691827     0.218216   -0.100532    0.0457941    0.166407    -0.0741811   -0.0881793    0.181532   -0.0911605   0.176226    0.354445    0.775304    1.2176
  0.501222    -0.305771    -0.108884    0.0766547  -0.210912    -0.0127444   0.390906    0.11434    -0.394787    -0.429052    -0.0764408  -0.224034     0.0276021    0.74741     -0.875619   -0.0220456   0.0394831   -0.492391     0.218146     0.143406    -0.0321328   0.107033   -0.150639    0.40074     0.477871    0.107593
  0.748427    -0.363756    -0.187844    0.270652   -0.308743    -0.426427    0.245119    0.227129    0.758835    -0.209168    -0.185613   -0.0644336   -0.529885     0.540516     0.244419    0.483111   -0.388087    -0.372971    -0.00709645  -0.229775    -0.0516331   0.614417    0.108855   -0.412112    0.301963    0.312313
  0.0963921   -0.456581    -0.189605    0.127304    0.109711     0.239178    0.394883    0.258242    0.0291764   -0.0459544   -0.335462    0.0461327   -0.043691     0.705319    -0.357471    0.242214   -0.135126    -0.20628     -0.0977722   -0.00862073  -0.46593    -0.254042   -0.197115   -0.229207   -0.84252    -0.36747
  0.19972      0.0156032    0.129749    0.0952531   0.00122756   0.19384     0.394891   -0.282916    0.12489     -0.0142633   -0.22463     0.108077    -0.208348     0.266518    -0.0302758   0.0149497  -0.0673964    0.185429     0.0566464    0.279696     0.0469332  -0.224272   -0.344146   -0.058216    0.20404    -0.0478235[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.403077
[ Info: iteration 2, average log likelihood -1.403069
[ Info: iteration 3, average log likelihood -1.403061
[ Info: iteration 4, average log likelihood -1.403053
[ Info: iteration 5, average log likelihood -1.403045
[ Info: iteration 6, average log likelihood -1.403038
[ Info: iteration 7, average log likelihood -1.403031
[ Info: iteration 8, average log likelihood -1.403025
[ Info: iteration 9, average log likelihood -1.403018
[ Info: iteration 10, average log likelihood -1.403012
┌ Info: EM with 100000 data points 10 iterations avll -1.403012
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind full, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.246656e+05
      1       6.916536e+05      -2.330121e+05 |       32
      2       6.802928e+05      -1.136079e+04 |       32
      3       6.751989e+05      -5.093854e+03 |       32
      4       6.726006e+05      -2.598369e+03 |       32
      5       6.710173e+05      -1.583243e+03 |       32
      6       6.699020e+05      -1.115301e+03 |       32
      7       6.690639e+05      -8.381384e+02 |       32
      8       6.683919e+05      -6.719587e+02 |       32
      9       6.677847e+05      -6.071824e+02 |       32
     10       6.672253e+05      -5.594317e+02 |       32
     11       6.667392e+05      -4.861074e+02 |       32
     12       6.663410e+05      -3.981723e+02 |       32
     13       6.659816e+05      -3.594442e+02 |       32
     14       6.656485e+05      -3.330497e+02 |       32
     15       6.653745e+05      -2.740829e+02 |       32
     16       6.651312e+05      -2.432708e+02 |       32
     17       6.649188e+05      -2.123398e+02 |       32
     18       6.647298e+05      -1.889969e+02 |       32
     19       6.645558e+05      -1.740019e+02 |       32
     20       6.643979e+05      -1.579721e+02 |       32
     21       6.642600e+05      -1.378949e+02 |       32
     22       6.641362e+05      -1.238148e+02 |       32
     23       6.640195e+05      -1.166529e+02 |       32
     24       6.638969e+05      -1.226036e+02 |       32
     25       6.637850e+05      -1.119360e+02 |       32
     26       6.636752e+05      -1.097491e+02 |       32
     27       6.635731e+05      -1.021449e+02 |       32
     28       6.634742e+05      -9.883559e+01 |       32
     29       6.633785e+05      -9.570339e+01 |       32
     30       6.632761e+05      -1.024682e+02 |       32
     31       6.631653e+05      -1.107439e+02 |       32
     32       6.630703e+05      -9.497854e+01 |       32
     33       6.629943e+05      -7.603813e+01 |       32
     34       6.629295e+05      -6.475950e+01 |       32
     35       6.628672e+05      -6.230871e+01 |       32
     36       6.628046e+05      -6.260131e+01 |       32
     37       6.627463e+05      -5.837775e+01 |       32
     38       6.626921e+05      -5.419864e+01 |       32
     39       6.626437e+05      -4.840929e+01 |       32
     40       6.626058e+05      -3.785088e+01 |       32
     41       6.625695e+05      -3.630807e+01 |       32
     42       6.625366e+05      -3.285659e+01 |       32
     43       6.625052e+05      -3.146752e+01 |       32
     44       6.624750e+05      -3.020356e+01 |       32
     45       6.624429e+05      -3.211028e+01 |       32
     46       6.624148e+05      -2.805274e+01 |       32
     47       6.623860e+05      -2.884036e+01 |       32
     48       6.623557e+05      -3.025094e+01 |       32
     49       6.623272e+05      -2.850987e+01 |       32
     50       6.623033e+05      -2.389119e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 662303.3087710016)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415184
[ Info: iteration 2, average log likelihood -1.410108
[ Info: iteration 3, average log likelihood -1.408826
[ Info: iteration 4, average log likelihood -1.407916
[ Info: iteration 5, average log likelihood -1.406898
[ Info: iteration 6, average log likelihood -1.405824
[ Info: iteration 7, average log likelihood -1.404976
[ Info: iteration 8, average log likelihood -1.404466
[ Info: iteration 9, average log likelihood -1.404186
[ Info: iteration 10, average log likelihood -1.404016
[ Info: iteration 11, average log likelihood -1.403898
[ Info: iteration 12, average log likelihood -1.403806
[ Info: iteration 13, average log likelihood -1.403729
[ Info: iteration 14, average log likelihood -1.403663
[ Info: iteration 15, average log likelihood -1.403605
[ Info: iteration 16, average log likelihood -1.403552
[ Info: iteration 17, average log likelihood -1.403504
[ Info: iteration 18, average log likelihood -1.403460
[ Info: iteration 19, average log likelihood -1.403420
[ Info: iteration 20, average log likelihood -1.403382
[ Info: iteration 21, average log likelihood -1.403348
[ Info: iteration 22, average log likelihood -1.403316
[ Info: iteration 23, average log likelihood -1.403286
[ Info: iteration 24, average log likelihood -1.403258
[ Info: iteration 25, average log likelihood -1.403232
[ Info: iteration 26, average log likelihood -1.403208
[ Info: iteration 27, average log likelihood -1.403186
[ Info: iteration 28, average log likelihood -1.403164
[ Info: iteration 29, average log likelihood -1.403145
[ Info: iteration 30, average log likelihood -1.403126
[ Info: iteration 31, average log likelihood -1.403108
[ Info: iteration 32, average log likelihood -1.403091
[ Info: iteration 33, average log likelihood -1.403075
[ Info: iteration 34, average log likelihood -1.403060
[ Info: iteration 35, average log likelihood -1.403046
[ Info: iteration 36, average log likelihood -1.403032
[ Info: iteration 37, average log likelihood -1.403019
[ Info: iteration 38, average log likelihood -1.403006
[ Info: iteration 39, average log likelihood -1.402994
[ Info: iteration 40, average log likelihood -1.402982
[ Info: iteration 41, average log likelihood -1.402970
[ Info: iteration 42, average log likelihood -1.402959
[ Info: iteration 43, average log likelihood -1.402949
[ Info: iteration 44, average log likelihood -1.402938
[ Info: iteration 45, average log likelihood -1.402928
[ Info: iteration 46, average log likelihood -1.402919
[ Info: iteration 47, average log likelihood -1.402909
[ Info: iteration 48, average log likelihood -1.402900
[ Info: iteration 49, average log likelihood -1.402891
32×26 Array{Float64,2}:
[ Info: iteration 50, average log likelihood -1.402882
┌ Info: EM with 100000 data points 50 iterations avll -1.402882
└ 59.0 data points per parameter
 -0.316874   -0.258529   -0.522319   -0.333394    0.748924    -0.584111    -0.121313     0.145143    -0.0354649   -0.418656   -0.195836    -0.127004    -0.058151    0.0696178   0.0266652   0.820456      0.0925504   0.0313692   -0.195434     0.377302   -0.315522     0.0142627   0.111545    -0.74932    -0.0811326  -0.330141
  0.101107    0.0106897   0.102781    0.0485892   0.0409372   -0.261757    -0.194021     0.163512     0.0979622   -0.105683    0.00034838  -0.225544     0.0151849  -0.244576   -0.0272836  -0.106233      0.012559    0.0257055    0.171064    -0.225393   -0.0880548    0.149012    0.0311702    0.0287946   0.0118043   0.0824799
 -0.155367   -0.209228    0.110802    0.2787     -0.0144948    0.384447    -0.290426     0.16838      0.326959    -0.211476   -0.139522    -0.736574     0.0943876   0.104733   -0.347228   -0.512238      1.05236    -0.977273    -0.315663    -0.243128   -0.849311    -0.190982    0.630087    -0.0264435  -0.389604    0.453082
  0.473685   -0.0817035   0.918278    0.655691    0.40566     -0.515075    -0.180212     0.579532     0.0558285   -0.616417   -0.371442    -0.297767     0.221798   -0.21797     0.386648   -0.428407      0.0481481   0.0221483   -0.163511    -0.37312    -0.510376     0.0256896  -0.18673      0.666322   -0.263233   -0.0723292
 -0.195875    0.333317    0.316377    0.142799    0.208463     0.435544     0.356053    -0.876152     0.312108    -0.0909215  -0.085902     0.46684     -0.349637    0.620674    0.066888    0.16835       0.539983   -0.542038    -0.21948      0.275392    0.0666829   -0.132739   -0.67791     -0.0224582   0.151135   -0.256686
  0.211183    0.176308   -0.074936    0.195414    0.335554    -0.180681    -0.294912     0.126796     0.178737     0.331511   -0.088828     0.255936    -0.0396553   0.153625    0.297195    0.0597745    -0.872489    0.270179     0.412301     0.504704    0.781651     0.356075    0.00726065   0.153935    0.0981846  -0.806192
  0.284265   -0.67268    -0.118356   -0.143187   -0.163274    -0.112136    -0.278211    -0.12656      0.0388455   -0.295774   -0.330267    -0.0710095    0.297575    0.735276   -0.0980845  -0.254713     -0.248834   -0.738219     0.505513     0.315576   -0.135526     0.372344   -0.364063     0.0397294  -0.0982266  -0.606117
  0.151934    0.0792147  -0.130866    0.385308   -0.664003    -0.150333    -0.544721    -0.229465     0.105573     0.0249425   0.767911    -0.486741     0.945193    0.215362    0.568176    0.0229634    -0.282483    0.34944     -0.244181     0.0113988  -0.088147    -0.453273   -0.241015    -0.559339    0.455994   -0.300482
  0.574122   -0.44878     0.464044    0.0920451   0.00399861   0.732853     0.499571     0.296985    -0.45679      0.162508   -0.379003     0.0888761   -0.0169865   0.476797   -0.527434   -0.000143894  -0.379322   -0.441541    -0.200441     0.0174456   0.136569    -0.019056    0.178694     0.71153    -0.123216    0.201779
 -0.274818   -0.177143   -0.387136   -0.43585    -0.392045     0.397534     0.407843    -0.53116     -0.0284192    0.0754029   0.251912     0.162845    -0.0557195   0.085944   -0.0654016   0.166242      0.187485    0.331291     0.236124     0.249365    1.16862      0.226249    0.336632    -0.739219    0.400633   -0.0972516
  0.0491147   0.132966   -0.273549   -0.0673442  -0.350765    -0.143756     0.341438     0.705015    -0.0308985   -0.388952   -0.0403596   -0.0927122    0.566981    0.339179   -0.757159    0.0143528     0.0536627   0.106555     0.266851    -0.453751    0.332108     0.164003    0.415632    -0.404227   -0.274415   -0.24168
 -0.107766    0.108461   -0.209001   -0.239182   -0.234138    -0.678334    -0.00476278  -0.0629425   -0.0248515    0.201842    0.207379     0.0885565   -0.11824    -0.383347   -0.375998   -0.283693      0.179163   -0.0459928    0.20887      0.140219   -0.104778    -0.0206261  -0.0538261    0.0502057   0.850723    0.584592
 -0.662706    0.318607   -0.531267    0.32043    -0.0797632   -0.448122    -0.726369     0.0358735   -0.110391    -0.597525    0.059632    -0.165823    -0.543113   -0.418773    0.536178   -0.546398      0.258106    0.453991     0.641255    -0.153352    0.355812     0.257681    0.139472    -0.034252    0.343331    0.207624
 -0.130722    0.0313548  -0.176015   -0.0366344  -0.0627092    0.0991704    0.0995583   -0.142565    -0.0816923    0.0142104   0.0394163    0.146288    -0.0584455   0.118565    0.0190905   0.0482074     0.0196264   0.0759645    0.042283     0.137203    0.28151      0.0486342   0.0695389   -0.153548   -0.0205237  -0.176661
 -0.500503    0.173265   -0.0935413   0.544518    0.180477     0.316193     0.814039     0.629998    -0.21381     -0.161034   -0.164705    -0.081727    -0.554524    0.0713315  -0.394627   -0.57483       0.600787    0.130211    -0.053496    -0.449848   -0.0204989   -0.263482    0.281491     0.0217643   0.130182    0.226465
  0.196428    0.0744526   0.137642    0.168838    0.268924     0.119915     0.468972     0.11972     -0.10767      0.0348693  -0.122979    -0.304142     0.0833855   0.61064    -0.13015     0.205428     -0.140583   -0.333304    -0.19464     -0.216487   -0.162815    -0.319212   -0.0468417    0.0579881  -0.147625    0.0215226
  0.31401    -0.0906256   0.4225      0.279238   -0.218903     0.317015    -0.0666566   -0.271855     0.0041533    0.480648   -0.0857498    0.107447    -0.158609   -0.139555    0.514073   -0.200156     -0.3202      0.0578704    0.00798497   0.218943   -0.0639409   -0.16041    -0.196496     0.129718    0.426147    0.552226
  0.160113   -0.641906    0.204927    0.481536   -0.484948     0.431794    -0.380056     0.317802     0.694776    -0.0134167  -0.137392    -0.103192     0.186592    0.532526   -0.0359083   0.175621      0.0752828   0.0754988    0.42256     -0.0123811  -0.125984    -0.10918     0.376856    -0.652825   -0.106059   -0.44697
 -0.407099   -0.117835   -0.700944   -0.403262   -0.601721     0.293613     0.258558    -0.574675     0.00926369   0.556741    0.114351     0.353049    -0.811259    0.355427   -0.274778    0.144812     -0.22301     0.00282896   0.0933676   -0.458514   -0.470865    -0.392305   -0.129219    -0.485784   -0.217185    0.302544
  0.151778    0.178336   -0.344948   -0.397019    0.00611193  -0.318568    -0.542642    -0.762593     0.240722     0.753261    0.0991175   -0.324002    -0.17673    -0.548319    0.532235    0.46795      -0.250702   -0.1076      -0.0143769    0.244634    0.319445     0.133549    0.162247     0.085987    0.313598    0.314735
 -0.244926    0.417741   -0.23655     0.153835    0.245233    -0.0930021   -0.276014    -0.0751752    0.110902     0.102186    0.209096    -0.0973498    0.478931   -0.361334   -0.191996   -0.642348      0.610856   -0.410453    -0.344814    -0.0135261  -0.0293565   -0.0160563   0.431242    -0.0134274   0.0323021  -0.624148
  0.528678   -0.0505682   0.237573   -0.335488   -0.246452    -0.00999683   0.567596     0.0966623   -0.00507222  -0.323695   -0.190948     0.234568    -0.298763    0.151829    0.174418    0.469367     -0.318414    0.915812     0.423812    -0.0312069   0.00578591  -0.178875   -0.620713    -0.0155034  -0.388903    0.203223
  0.0592776   0.343475    0.0186726   0.397232    0.467153     0.108236    -0.590215     0.229825    -0.529843     0.0559861  -0.326652     0.315342     0.0197378  -0.470596    0.217506    0.623158     -0.3957     -0.367823     0.199176    -0.383684   -0.329165    -0.108943   -0.0526345   -0.392289   -0.376036    0.347938
 -0.250653    0.250341    0.253887   -0.0702972  -0.349107    -0.18651     -0.419399     0.251805    -0.110683     0.218105    0.479091    -0.0263299    0.257598   -0.614866    0.0444667  -0.238943     -0.0130828   0.146223     0.223456    -0.221773    0.372931     0.29548     0.150008     0.327507    0.131617    0.0234705
 -0.0786442  -0.131381   -0.0119302  -0.88044    -0.0701542   -0.0209516   -0.320264     0.791144    -0.174166     0.220656    0.645361    -0.0715956   -0.201323    0.213015   -0.226349   -0.218376     -0.413795    0.21047     -0.0779648   -0.249655   -0.771116    -0.134948   -0.114705     0.723023   -0.749626    0.455022
  0.306837   -0.161453   -0.0595709  -0.101105   -0.527628     0.133894     0.684757     0.030689    -0.10957     -0.575304    0.256174    -0.730443    -0.0810995   0.583463   -0.5728     -0.377688      0.550873   -0.0347679   -0.217518     0.217941    0.293801     0.384829   -0.133588     0.772239    0.5777     -0.0925359
 -0.265152    0.514478   -0.179844   -0.144561    0.919829     0.0176354   -0.375939     0.254622     0.0178028    0.0642663  -0.044904     0.394524     0.43297     0.0298644   0.611601   -0.60936       0.0271519   0.235702     0.0376407   -0.125096   -0.241507    -0.577913   -0.080608    -0.354104   -0.640669   -0.562359
  0.0349113  -0.0249925   0.628317    0.160965   -0.246584     0.641541     0.00966025   0.00674086  -0.239942    -0.359975    0.143146     0.251422     0.0664306  -0.162226   -0.0587778  -0.302321      0.122218    0.019766     0.0263914   -0.0965271   0.235004     0.422257   -0.0858039    0.417336   -0.464231   -0.365021
  0.310777   -0.229314   -0.0637656   0.171631    0.147897     0.0809904    0.522642    -0.298611     0.141684    -0.0317564  -0.435642    -0.00871955  -0.247377    0.394608   -0.10541     0.341157     -0.147312    0.140317    -0.0432938    0.373812   -0.112074    -0.266516   -0.306574    -0.275738   -0.07302    -0.166907
  0.672536   -0.22092    -0.221659    0.309831   -0.466404    -0.570295     0.0861039    0.537145     0.405469    -0.325337    0.255559    -0.126981    -0.430132    0.266722    0.0129275   0.386829     -0.291497   -0.452693     0.149163    -0.158701    0.0458883    0.886217   -0.0156376   -0.406598    0.502097    0.395325
  0.208737    0.33826     0.554137   -0.544549    0.549925    -0.619875     0.206544    -0.444706    -0.544851    -0.281263    0.156618     0.373157     0.388715   -0.799112    0.109144    0.174738      0.360823    0.107757    -0.442212    -0.160943    0.00613916   0.586036   -0.201294    -0.0155523   0.207655    0.360112
 -0.777678    0.113726   -0.0485613  -0.0280628   0.323728     0.0596755    0.27796     -0.200573    -0.460328     0.350528   -0.211874     0.176415     0.143048   -0.0712183   0.28362    -0.128648     -0.0819594   0.574463    -0.440072     0.0744958   0.0830421   -0.703198    0.251514     0.216209   -0.414661   -0.309927[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.402874
[ Info: iteration 2, average log likelihood -1.402866
[ Info: iteration 3, average log likelihood -1.402857
[ Info: iteration 4, average log likelihood -1.402850
[ Info: iteration 5, average log likelihood -1.402842
[ Info: iteration 6, average log likelihood -1.402835
[ Info: iteration 7, average log likelihood -1.402827
[ Info: iteration 8, average log likelihood -1.402820
[ Info: iteration 9, average log likelihood -1.402813
[ Info: iteration 10, average log likelihood -1.402806
┌ Info: EM with 100000 data points 10 iterations avll -1.402806
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
