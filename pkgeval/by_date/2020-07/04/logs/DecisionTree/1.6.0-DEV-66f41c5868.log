Julia Version 1.6.0-DEV.360
Commit 66f41c5868 (2020-07-03 11:12 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed ScikitLearnBase ─ v0.5.0
  Installed DecisionTree ──── v0.10.5
Updating `~/.julia/environments/v1.6/Project.toml`
  [7806a523] + DecisionTree v0.10.5
Updating `~/.julia/environments/v1.6/Manifest.toml`
  [7806a523] + DecisionTree v0.10.5
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [2a0f44e3] + Base64
  [8bb1440f] + DelimitedFiles
  [8ba89e20] + Distributed
  [b77e0a4c] + InteractiveUtils
  [8f399da3] + Libdl
  [37e2e46d] + LinearAlgebra
  [56ddb016] + Logging
  [d6f4376e] + Markdown
  [a63ad114] + Mmap
  [9a3f8284] + Random
  [9e88b42a] + Serialization
  [6462fe0b] + Sockets
  [2f01184e] + SparseArrays
  [10745b16] + Statistics
  [8dfed614] + Test
    Testing DecisionTree
Status `/tmp/jl_QyIECj/Project.toml`
  [7806a523] DecisionTree v0.10.5
  [6e75b9c4] ScikitLearnBase v0.5.0
  [8bb1440f] DelimitedFiles
  [8ba89e20] Distributed
  [37e2e46d] LinearAlgebra
  [9a3f8284] Random
  [10745b16] Statistics
  [8dfed614] Test
Status `/tmp/jl_QyIECj/Manifest.toml`
  [7806a523] DecisionTree v0.10.5
  [6e75b9c4] ScikitLearnBase v0.5.0
  [2a0f44e3] Base64
  [8bb1440f] DelimitedFiles
  [8ba89e20] Distributed
  [b77e0a4c] InteractiveUtils
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [d6f4376e] Markdown
  [a63ad114] Mmap
  [9a3f8284] Random
  [9e88b42a] Serialization
  [6462fe0b] Sockets
  [2f01184e] SparseArrays
  [10745b16] Statistics
  [8dfed614] Test
Julia version: 1.6.0-DEV.360
TEST: classification/random.jl 

Feature 2, Threshold 0.6056544585515548
L-> Feature 5, Threshold 0.3519102249662106
    L-> Feature 4, Threshold 0.3964305172913062
        L-> 1 : 61/97
        R-> 1 : 93/136
    R-> Feature 4, Threshold 0.5443369813935621
        L-> 0 : 116/195
        R-> 1 : 123/168
R-> Feature 3, Threshold 0.40770541203275457
    L-> Feature 5, Threshold 0.5034714805111138
        L-> 0 : 71/88
        R-> 0 : 50/82
    R-> Feature 1, Threshold 0.5347975865461467
        L-> 0 : 80/123
        R-> 1 : 77/111
random.jl: Test Failed at /home/pkgeval/.julia/packages/DecisionTree/lNaGR/test/classification/random.jl:107
  Expression: length.(m1.trees) == length.(m2.trees)
   Evaluated: [121, 105, 129, 123, 106] == [123, 125, 116, 109, 112]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/DecisionTree/lNaGR/test/classification/random.jl:107
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope
   @ ~/.julia/packages/DecisionTree/lNaGR/test/classification/random.jl:4
random.jl: Test Failed at /home/pkgeval/.julia/packages/DecisionTree/lNaGR/test/classification/random.jl:108
  Expression: depth.(m1.trees) == depth.(m2.trees)
   Evaluated: [14, 11, 12, 12, 11] == [12, 11, 13, 11, 10]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/DecisionTree/lNaGR/test/classification/random.jl:108
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope
   @ ~/.julia/packages/DecisionTree/lNaGR/test/classification/random.jl:4

##### nfoldCV Classification Tree #####

Fold 1
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 0  18    1  0
 0  81   34  0
 0  42  139  0
 0   0   18  0
Accuracy: 0.6606606606606606
Kappa:    0.37203364373685793

Fold 2
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 0   25    0  0
 0  121   35  0
 0   35  100  0
 0    0   17  0
Accuracy: 0.6636636636636637
Kappa:    0.39973926898749457

Fold 3
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 0   18    0  0
 0  115   33  0
 0   33  115  0
 0    0   19  0
Accuracy: 0.6906906906906907
Kappa:    0.4432432432432432

Mean Accuracy: 0.6716716716716716

Fold 1
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 0  18    1  0
 0  81   34  0
 0  42  139  0
 0   0   18  0
Accuracy: 0.6606606606606606
Kappa:    0.37203364373685793

Fold 2
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 0   25    0  0
 0  121   35  0
 0   35  100  0
 0    0   17  0
Accuracy: 0.6636636636636637
Kappa:    0.39973926898749457

Fold 3
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 0   18    0  0
 0  115   33  0
 0   33  115  0
 0    0   19  0
Accuracy: 0.6906906906906907
Kappa:    0.4432432432432432

Mean Accuracy: 0.6716716716716716

Fold 1
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 0   21    0  0
 0  104   39  0
 0   36  111  0
 0    0   22  0
Accuracy: 0.6456456456456456
Kappa:    0.3721197788501486

Fold 2
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 0   19    0  0
 0  103   36  0
 0   30  127  0
 0    0   18  0
Accuracy: 0.6906906906906907
Kappa:    0.4408744131455398

Fold 3
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 0   21    1  0
 0  110   28  0
 0   44  115  0
 0    0   14  0
Accuracy: 0.6756756756756757
Kappa:    0.41632990895369776

Mean Accuracy: 0.6706706706706708

##### nfoldCV Classification Forest #####

Fold 1
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 18    1    0   0
  0  115    0   0
  0    5  176   0
  0    0    0  18
Accuracy: 0.9819819819819819
Kappa:    0.9690001861850679

Fold 2
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 22    3    0   0
  0  156    0   0
  0    3  132   0
  0    0    2  15
Accuracy: 0.975975975975976
Kappa:    0.9600731392943859

Fold 3
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 16    2    0   0
  0  148    0   0
  0    3  145   0
  0    0    1  18
Accuracy: 0.9819819819819819
Kappa:    0.969730483130577

Mean Accuracy: 0.97997997997998

Fold 1
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 16    3    0   0
  0  113    2   0
  0    6  175   0
  0    0    2  16
Accuracy: 0.960960960960961
Kappa:    0.9322195778793764

Fold 2
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 20    5    0   0
  0  155    1   0
  0    1  134   0
  0    0    2  15
Accuracy: 0.972972972972973
Kappa:    0.9549479127519807

Fold 3
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 15    3    0   0
  0  146    2   0
  0    3  145   0
  0    0    1  18
Accuracy: 0.972972972972973
Kappa:    0.9545061250512319

Mean Accuracy: 0.968968968968969

Fold 1
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 17    4    0   0
  0  141    2   0
  0    3  144   0
  0    0    1  21
Accuracy: 0.96996996996997
Kappa:    0.9505178536933295

Fold 2
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 16    3    0   0
  0  139    0   0
  0    5  152   0
  0    0    2  16
Accuracy: 0.96996996996997
Kappa:    0.9493042657491703

Fold 3
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 21    1    0   0
  0  135    3   0
  0    2  157   0
  0    0    1  13
Accuracy: 0.978978978978979
Kappa:    0.9644675467211364

Mean Accuracy: 0.9729729729729729
random.jl: Test Failed at /home/pkgeval/.julia/packages/DecisionTree/lNaGR/test/classification/random.jl:139
  Expression: accuracy == accuracy2
   Evaluated: [0.9819819819819819, 0.975975975975976, 0.9819819819819819] == [0.960960960960961, 0.972972972972973, 0.972972972972973]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/DecisionTree/lNaGR/test/classification/random.jl:139
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope
   @ ~/.julia/packages/DecisionTree/lNaGR/test/classification/random.jl:4

##### nfoldCV Adaboosted Stumps #####

Fold 1
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 0  19    0  0
 0  78   37  0
 0  10  171  0
 0   0   18  0
Accuracy: 0.7477477477477478
Kappa:    0.5150317278685115

Fold 2
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 0   25    0  0
 0  131   25  0
 0   21  108  6
 0    0   17  0
Accuracy: 0.7177177177177178
Kappa:    0.5025506555423124

Fold 3
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 0   18    0  0
 2  126   20  0
 0   22  126  0
 0    0   19  0
Accuracy: 0.7567567567567568
Kappa:    0.5640022629919987

Mean Accuracy: 0.7407407407407408

Fold 1
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 0  19    0  0
 0  78   37  0
 0  10  171  0
 0   0   18  0
Accuracy: 0.7477477477477478
Kappa:    0.5150317278685115

Fold 2
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 0   25    0  0
 0  131   25  0
 0   21  108  6
 0    0   17  0
Accuracy: 0.7177177177177178
Kappa:    0.5025506555423124

Fold 3
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 0   18    0  0
 2  126   20  0
 0   22  126  0
 0    0   19  0
Accuracy: 0.7567567567567568
Kappa:    0.5640022629919987

Mean Accuracy: 0.7407407407407408

Fold 1
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 0   21    0  0
 2  115   26  0
 0   18  129  0
 0    0   22  0
Accuracy: 0.7327327327327328
Kappa:    0.528118332643378

Fold 2
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 0   19    0  0
 0  120   19  0
 0   26  131  0
 0    0   18  0
Accuracy: 0.7537537537537538
Kappa:    0.5565624086524408

Fold 3
Classes:  [-1, 0, 1, 2]
Matrix:   4×4 Matrix{Int64}:
 0   22    0  0
 0  120   18  0
 0   25  133  1
 0    0   14  0
Accuracy: 0.7597597597597597
Kappa:    0.5674903399681788

Mean Accuracy: 0.7487487487487487
==================================================
TEST: classification/low_precision.jl 


##### nfoldCV Classification Tree #####

Fold 1
Classes:  Int32[-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6]
Matrix:   12×12 Matrix{Int64}:
 6   0   0   0   0   0   0   0   0   0  0  0
 0  17   0   0   0   0   0   0   0   0  0  0
 0   0  25   0   0   0   0   0   0   0  0  0
 0   0   0  36   0   0   0   0   0   0  0  0
 0   0   0   0  56   0   0   0   0   0  0  0
 0   0   0   0   0  57   0   0   0   0  0  0
 0   0   0   0   0   0  65   0   0   0  0  0
 0   0   0   0   0   0   0  31   0   0  0  0
 0   0   0   0   0   0   0   0  22   0  0  0
 0   0   0   0   0   0   0   0   0  12  0  0
 0   0   0   0   0   0   0   0   0   0  2  0
 0   0   0   0   0   0   0   0   0   0  0  4
Accuracy: 1.0
Kappa:    1.0

Fold 2
Classes:  Int32[-6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6]
Matrix:   13×13 Matrix{Int64}:
 1  0   0   0   0   0   0   0   0   0   0  0  0
 0  4   0   0   0   0   0   0   0   0   0  0  0
 0  0  13   0   0   0   0   0   0   0   0  0  0
 0  0   0  31   0   0   0   0   0   0   0  0  0
 0  0   0   0  40   0   0   0   0   0   0  0  0
 0  0   0   0   0  37   0   0   0   0   0  0  0
 0  0   0   0   0   0  63   0   0   0   0  0  0
 0  0   0   0   0   0   0  51   0   0   0  0  0
 0  0   0   0   0   0   0   0  45   0   0  0  0
 0  0   0   0   0   0   0   0   0  29   0  0  0
 0  0   0   0   0   0   0   0   0   0  10  0  0
 0  0   0   0   0   0   0   0   0   0   0  8  0
 0  0   0   0   0   0   0   0   0   0   0  0  1
Accuracy: 1.0
Kappa:    1.0

Fold 3
Classes:  Int32[-7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 7]
Matrix:   14×14 Matrix{Int64}:
 1  0  0   0   0   0   0   0   0   0   0   0  0  0
 0  1  0   0   0   0   0   0   0   0   0   0  0  0
 0  0  2   0   0   0   0   0   0   0   0   0  0  0
 0  0  0  15   0   0   0   0   0   0   0   0  0  0
 0  0  0   0  18   0   0   0   0   0   0   0  0  0
 0  0  0   0   0  37   0   0   0   0   0   0  0  0
 0  0  0   0   0   0  52   0   0   0   0   0  0  0
 0  0  0   0   0   0   0  43   0   0   0   0  0  0
 0  0  0   0   0   0   0   0  63   0   0   0  0  0
 0  0  0   0   0   0   0   0   0  52   0   0  0  0
 0  0  0   0   0   0   0   0   0   0  25   0  0  0
 0  0  0   0   0   0   0   0   0   0   0  14  0  0
 0  0  0   0   0   0   0   0   0   0   0   0  9  0
 0  0  0   0   0   0   0   0   0   0   0   0  0  1
Accuracy: 1.0
Kappa:    1.0

Mean Accuracy: 1.0

##### nfoldCV Classification Forest #####

Fold 1
Classes:  Int32[-6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7]
Matrix:   14×14 Matrix{Int64}:
 0  0  0  1   0   0   0   0   0   0  0  0  0  0
 0  0  4  3   0   1   0   0   0   0  0  0  0  0
 0  0  9  3   2   2   0   0   0   0  0  0  0  0
 0  0  3  8   4   1   4   0   0   0  0  0  0  0
 0  0  1  1  21   6   3   1   0   0  0  0  0  0
 0  0  0  0   2  41   5   0   1   0  0  0  0  0
 0  0  0  0   1  10  36   1   3   0  0  0  0  0
 0  0  0  0   0   6   9  37   6   1  0  0  0  0
 0  0  0  0   0   1   3   6  42   0  0  0  0  0
 0  0  0  0   0   0   1   0   6  14  1  0  0  0
 0  0  0  0   0   0   2   0   5   2  4  0  1  0
 0  0  0  0   0   0   1   0   2   0  1  1  0  0
 0  0  0  0   0   0   0   0   0   0  0  0  2  0
 0  0  0  0   0   0   0   0   0   0  0  0  1  0
Accuracy: 0.6456456456456456
Kappa:    0.5915596902447898

Fold 2
Classes:  Int32[-7, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6]
Matrix:   13×13 Matrix{Int64}:
 0  0   0   1   0   0   0   0   0   0  0  0  0
 0  0   1   0   0   0   0   0   0   0  0  0  0
 0  0  13   4   0   1   0   0   0   0  0  0  0
 0  0   2  19   5   3   2   0   0   0  0  0  0
 0  0   1   2  22  10   2   0   0   0  0  0  0
 0  0   1   1   3  41   2   0   0   0  0  0  0
 0  0   0   0   2  10  35   2   2   0  0  0  0
 0  0   0   0   1   1   8  43   7   2  0  0  0
 0  0   0   0   0   1   2   4  26   3  0  0  0
 0  0   0   0   0   0   2   0  11  17  0  0  0
 0  0   0   0   0   0   0   0   5   1  4  0  0
 0  0   0   0   0   0   0   2   1   1  0  1  0
 0  0   0   0   0   0   0   0   0   2  1  0  0
Accuracy: 0.6636636636636637
Kappa:    0.6143880726641094

Fold 3
Classes:  Int32[-6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5]
Matrix:   12×12 Matrix{Int64}:
 0  0  0   1   0   0   0   0   0  0  0  0
 0  1  1   0   1   0   0   0   0  0  0  0
 0  0  6   2   0   3   0   0   0  0  0  0
 0  0  0  17   4   2   0   0   0  0  0  0
 0  0  1   2  24   6  10   0   0  0  0  0
 0  0  0   0   3  37   8   0   0  0  0  0
 0  0  0   0   0   4  51   2   4  0  0  0
 0  0  0   0   0   1  10  39   6  1  0  1
 0  0  0   0   0   3   2   5  30  0  0  0
 0  0  0   0   0   1   0   3  13  6  1  0
 0  0  0   0   0   0   0   0   5  1  6  0
 0  0  0   0   0   0   0   0   2  4  2  1
Accuracy: 0.6546546546546547
Kappa:    0.5993534415115658

Mean Accuracy: 0.6546546546546547

##### nfoldCV Adaboosted Stumps #####

Fold 1
Classes:  Int32[-6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5]
Matrix:   12×12 Matrix{Int64}:
 0  0  0  0   1  0  0   0   0  0  0  0
 0  0  0  1   4  0  0   0   0  0  0  0
 0  0  0  2   6  3  0   0   2  0  0  0
 0  0  1  8   7  9  0   0   3  0  0  0
 0  0  5  5  14  6  0   4   4  1  0  0
 0  0  6  3  11  6  0   7   5  2  0  0
 0  0  6  3   6  6  0  21   8  8  0  0
 0  0  6  3   3  2  0  26  20  5  0  0
 0  0  1  1   1  2  0  25  14  4  0  0
 0  0  0  1   0  0  0  11   5  2  0  0
 0  0  0  0   0  0  0   6   4  1  0  0
 0  0  0  0   0  0  0   5   1  0  0  0
Accuracy: 0.21021021021021022
Kappa:    0.08725286865170766

Fold 2
Classes:  Int32[-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7]
Matrix:   13×13 Matrix{Int64}:
 0  0  0  0  0   1  0  0  0  0  0  0  0
 0  0  3  2  0   7  0  0  1  0  0  0  0
 0  0  1  0  0  18  0  0  0  0  0  0  0
 0  0  3  1  0  35  0  0  0  2  0  0  0
 0  0  1  3  0  51  0  0  2  0  0  0  0
 0  0  2  1  2  49  0  2  1  0  0  0  0
 0  0  0  2  2  46  0  4  0  1  0  0  0
 0  0  0  0  0  34  0  3  0  0  0  0  0
 0  0  0  0  1  16  0  5  4  0  0  0  0
 0  0  0  0  0   8  0  4  2  0  0  0  0
 0  0  0  0  1   3  0  3  2  0  0  0  0
 0  0  0  0  0   2  0  0  1  0  0  0  0
 0  0  0  0  0   0  0  1  0  0  0  0  0
Accuracy: 0.17417417417417416
Kappa:    0.01958160250096354

Fold 3
Classes:  Int32[-7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6]
Matrix:   14×14 Matrix{Int64}:
 0  0  0  0  0   1  0  0   0  0   0  0  0  0
 0  0  0  0  0   1  0  0   0  0   0  0  0  0
 0  0  0  0  0   2  0  1   3  0   0  0  0  0
 0  0  0  0  3   5  0  0  10  0   1  0  0  0
 0  0  0  0  3  10  2  0  12  0   0  0  0  0
 0  0  0  0  2   6  2  1  22  0   0  0  0  0
 0  0  0  1  3   3  2  0  38  0   2  0  0  0
 0  0  0  1  3   4  1  0  35  2   2  0  0  0
 0  0  0  0  0   0  1  0  49  3   4  1  0  0
 0  0  0  0  1   0  1  0  28  5   8  0  0  0
 0  0  0  0  0   0  0  0  18  2  11  0  0  0
 0  0  0  0  0   1  0  0   6  2   2  0  0  0
 0  0  0  0  0   0  0  0   2  2   0  0  0  0
 0  0  0  0  0   0  0  0   0  2   0  0  0  0
Accuracy: 0.22822822822822822
Kappa:    0.09121704133969057

Mean Accuracy: 0.20420420420420418
==================================================
TEST: classification/heterogeneous.jl 

==================================================
TEST: classification/digits.jl 

==================================================
TEST: classification/iris.jl 

Feature 3, Threshold 2.45
L-> Iris-setosa : 50/50
R-> Feature 4, Threshold 1.75
    L-> Feature 3, Threshold 4.95
        L-> Feature 4, Threshold 1.65
            L-> Iris-versicolor : 47/47
            R-> Iris-virginica : 1/1
        R-> Feature 4, Threshold 1.55
            L-> Iris-virginica : 3/3
            R-> Feature 1, Threshold 6.95
                L-> Iris-versicolor : 2/2
                R-> Iris-virginica : 1/1
    R-> Feature 3, Threshold 4.85
        L-> Feature 2, Threshold 3.1
            L-> Iris-virginica : 2/2
            R-> Iris-versicolor : 1/1
        R-> Iris-virginica : 43/43

##### nfoldCV Classification Tree #####

Fold 1
Classes:  ["Iris-setosa", "Iris-versicolor", "Iris-virginica"]
Matrix:   3×3 Matrix{Int64}:
 14   0   0
  0  15   0
  0   0  21
Accuracy: 1.0
Kappa:    1.0

Fold 2
Classes:  ["Iris-setosa", "Iris-versicolor", "Iris-virginica"]
Matrix:   3×3 Matrix{Int64}:
 18   0   0
  0  15   0
  0   0  17
Accuracy: 1.0
Kappa:    1.0

Fold 3
Classes:  ["Iris-setosa", "Iris-versicolor", "Iris-virginica"]
Matrix:   3×3 Matrix{Int64}:
 18   0   0
  0  20   0
  0   0  12
Accuracy: 1.0
Kappa:    1.0

Mean Accuracy: 1.0

##### nfoldCV Classification Forest #####

Fold 1
Classes:  ["Iris-setosa", "Iris-versicolor", "Iris-virginica"]
Matrix:   3×3 Matrix{Int64}:
 15   0   0
  0  15   2
  0   0  18
Accuracy: 0.96
Kappa:    0.9397590361445782

Fold 2
Classes:  ["Iris-setosa", "Iris-versicolor", "Iris-virginica"]
Matrix:   3×3 Matrix{Int64}:
 18   0   0
  0  18   0
  0   1  13
Accuracy: 0.98
Kappa:    0.9697336561743342

Fold 3
Classes:  ["Iris-setosa", "Iris-versicolor", "Iris-virginica"]
Matrix:   3×3 Matrix{Int64}:
 17   0   0
  0  14   1
  0   0  18
Accuracy: 0.98
Kappa:    0.9698613622664255

Mean Accuracy: 0.9733333333333333

##### nfoldCV Classification Adaboosted Stumps #####

Fold 1
Classes:  ["Iris-setosa", "Iris-versicolor", "Iris-virginica"]
Matrix:   3×3 Matrix{Int64}:
 17   0   0
  0  12   1
  0   2  18
Accuracy: 0.94
Kappa:    0.9090357792601576

Fold 2
Classes:  ["Iris-setosa", "Iris-versicolor", "Iris-virginica"]
Matrix:   3×3 Matrix{Int64}:
 17   0  0
  0  20  1
  0   3  9
Accuracy: 0.92
Kappa:    0.8756218905472637

Fold 3
Classes:  ["Iris-setosa", "Iris-versicolor", "Iris-virginica"]
Matrix:   3×3 Matrix{Int64}:
 16   0   0
  0  15   1
  0   1  17
Accuracy: 0.96
Kappa:    0.9399038461538461

Mean Accuracy: 0.94
==================================================
TEST: classification/adult.jl 

==================================================
TEST: classification/scikitlearn.jl 

scikitlearn.jl: Test Failed at /home/pkgeval/.julia/packages/DecisionTree/lNaGR/test/classification/scikitlearn.jl:36
  Expression: predict_proba(fit!(RandomForestClassifier(; rng = 10), X, y), X) == predict_proba(fit!(RandomForestClassifier(; rng = 10), X, y), X)
   Evaluated: [0.0 1.0; 0.9 0.1; … ; 0.2 0.8; 0.5 0.5] == [0.2 0.8; 0.0 1.0; … ; 0.2 0.8; 0.2 0.8]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/DecisionTree/lNaGR/test/classification/scikitlearn.jl:36
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope
   @ ~/.julia/packages/DecisionTree/lNaGR/test/classification/scikitlearn.jl:3
==================================================
TEST: regression/random.jl 

random.jl: Error During Test at /home/pkgeval/.julia/packages/DecisionTree/lNaGR/test/regression/random.jl:1
  Got exception outside of a @test
  TaskFailedException:
  InexactError: trunc(UInt64, 1.6799176955493086e36)
  Stacktrace:
    [1] trunc
      @ ./float.jl:682 [inlined]
    [2] floor
      @ ./float.jl:363 [inlined]
    [3] hypergeometric_hyp
      @ ~/.julia/packages/DecisionTree/lNaGR/src/util.jl:237 [inlined]
    [4] hypergeometric(good::Int64, bad::Int64, sample::Int64, rng::MersenneTwister)
      @ DecisionTree.treeregressor.util ~/.julia/packages/DecisionTree/lNaGR/src/util.jl:296
    [5] _split!(X::Matrix{Any}, Y::Vector{Float64}, W::Vector{Float64}, node::DecisionTree.treeregressor.NodeMeta{Any}, max_features::Int64, max_depth::Int64, min_samples_leaf::Int64, min_samples_split::Int64, min_purity_increase::Float64, indX::Vector{Int64}, Xf::Vector{Any}, Yf::Vector{Float64}, Wf::Vector{Float64}, rng::MersenneTwister)
      @ DecisionTree.treeregressor ~/.julia/packages/DecisionTree/lNaGR/src/regression/tree.jl:109
    [6] _fit(X::Matrix{Any}, Y::Vector{Float64}, W::Vector{Float64}, max_features::Int64, max_depth::Int64, min_samples_leaf::Int64, min_samples_split::Int64, min_purity_increase::Float64, rng::MersenneTwister)
      @ DecisionTree.treeregressor ~/.julia/packages/DecisionTree/lNaGR/src/regression/tree.jl:282
    [7] fit(; X::Matrix{Any}, Y::Vector{Float64}, W::Nothing, max_features::Int64, max_depth::Int64, min_samples_leaf::Int64, min_samples_split::Int64, min_purity_increase::Float64, rng::MersenneTwister)
      @ DecisionTree.treeregressor ~/.julia/packages/DecisionTree/lNaGR/src/regression/tree.jl:328
    [8] build_tree(labels::Vector{Float64}, features::Matrix{Any}, n_subfeatures::Int64, max_depth::Int64, min_samples_leaf::Int64, min_samples_split::Int64, min_purity_increase::Float64; rng::MersenneTwister)
      @ DecisionTree ~/.julia/packages/DecisionTree/lNaGR/src/regression/main.jl:35
    [9] macro expansion
      @ ~/.julia/packages/DecisionTree/lNaGR/src/regression/main.jl:81 [inlined]
   [10] (::DecisionTree.var"#110#threadsfor_fun#35"{Vector{Float64},Matrix{Any},Int64,Int64,Int64,Float64,Int64,Int64,MersenneTwister,Vector{Union{Leaf{Float64}, Node{Any,Float64}}},UnitRange{Int64}})(onethread::Bool)
      @ DecisionTree ./threadingconstructs.jl:81
   [11] (::DecisionTree.var"#110#threadsfor_fun#35"{Vector{Float64},Matrix{Any},Int64,Int64,Int64,Float64,Int64,Int64,MersenneTwister,Vector{Union{Leaf{Float64}, Node{Any,Float64}}},UnitRange{Int64}})()
      @ DecisionTree ./threadingconstructs.jl:48
  Stacktrace:
    [1] wait
      @ ./task.jl:269 [inlined]
    [2] threading_run(func::Function)
      @ Base.Threads ./threadingconstructs.jl:34
    [3] macro expansion
      @ ./threadingconstructs.jl:93 [inlined]
    [4] build_forest(labels::Vector{Float64}, features::Matrix{Any}, n_subfeatures::Int64, n_trees::Int64, partial_sampling::Float64, max_depth::Int64, min_samples_leaf::Int64, min_samples_split::Int64, min_purity_increase::Float64; rng::Int64)
      @ DecisionTree ~/.julia/packages/DecisionTree/lNaGR/src/regression/main.jl:79
    [5] top-level scope
      @ ~/.julia/packages/DecisionTree/lNaGR/test/regression/random.jl:169
    [6] top-level scope
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
    [7] top-level scope
      @ ~/.julia/packages/DecisionTree/lNaGR/test/regression/random.jl:3
    [8] include(fname::String)
      @ Base.MainInclude ./client.jl:444
    [9] run_tests(list::Vector{String})
      @ Main ~/.julia/packages/DecisionTree/lNaGR/test/runtests.jl:13
   [10] macro expansion
      @ ~/.julia/packages/DecisionTree/lNaGR/test/runtests.jl:52 [inlined]
   [11] macro expansion
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
   [12] macro expansion
      @ ~/.julia/packages/DecisionTree/lNaGR/test/runtests.jl:52 [inlined]
   [13] macro expansion
      @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115 [inlined]
   [14] top-level scope
      @ ~/.julia/packages/DecisionTree/lNaGR/test/runtests.jl:47
   [15] include(fname::String)
      @ Base.MainInclude ./client.jl:444
   [16] top-level scope
      @ none:6
   [17] eval(m::Module, e::Any)
      @ Core ./boot.jl:340
   [18] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:260
   [19] _start()
      @ Base ./client.jl:485
  
==================================================
TEST: regression/low_precision.jl 


##### nfoldCV Regression Tree #####

Fold 1
Mean Squared Error:     0.953998693124603
Correlation Coeff:      0.9618843907204211
Coeff of Determination: 0.9250446829669072

Fold 2
Mean Squared Error:     0.8208320849016333
Correlation Coeff:      0.9659857438323732
Coeff of Determination: 0.9328855953695734

Fold 3
Mean Squared Error:     0.8045528440841636
Correlation Coeff:      0.9680701151453298
Coeff of Determination: 0.9370790138925564

Mean Coeff of Determination: 0.9316697640763456

##### nfoldCV Regression Forest #####

Fold 1
Mean Squared Error:     1.1322651961465764
Correlation Coeff:      0.969675786377562
Coeff of Determination: 0.9177026677244376

Fold 2
Mean Squared Error:     0.9217486520832228
Correlation Coeff:      0.9660951400925645
Coeff of Determination: 0.9157165839892374

Fold 3
Mean Squared Error:     0.9975171721855309
Correlation Coeff:      0.9710690163529505
Coeff of Determination: 0.9230664930272455

Mean Coeff of Determination: 0.9188285815803069
==================================================
TEST: regression/digits.jl 

==================================================
TEST: regression/scikitlearn.jl 

scikitlearn.jl: Test Failed at /home/pkgeval/.julia/packages/DecisionTree/lNaGR/test/regression/scikitlearn.jl:31
  Expression: fit_predict!(RandomForestRegressor(; rng = 10), X, y) == fit_predict!(RandomForestRegressor(; rng = 10), X, y)
   Evaluated: [-0.6060175651728421, -0.44022057657572766, 0.1490272703468859, 0.4329159848909018, -0.4226098458299038, -0.38400152926673253, 0.3389795067786353, 0.049427998311157614, 0.041622448015647316, 0.4148367079885299  …  -0.12763741819689783, -0.20837332648057344, -0.33917234046031564, -0.4211797270472376, 0.33802670982434485, 0.3384575900345826, -0.1382327988396107, -0.28368663359999063, -0.5557912270066563, -0.6612975912449185] == [-0.34058890740186765, -0.2547667210137202, 0.1393183012008637, 0.45464182171522394, -0.23372903684429774, -0.5855582844519577, -0.07552963034698226, 0.026874850082918865, -0.9653650842848773, -0.5406329629061428  …  -0.4251554847133018, 0.04141059664817853, -0.033854833194950903, -0.2688068769571398, 0.0427429681581251, 0.19999714330798005, -0.22695042218837114, -0.3159922041788377, -0.3640533277685877, -0.9622853763494972]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/DecisionTree/lNaGR/test/regression/scikitlearn.jl:31
 [2] top-level scope
   @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1115
 [3] top-level scope
   @ ~/.julia/packages/DecisionTree/lNaGR/test/regression/scikitlearn.jl:3
==================================================
TEST: miscellaneous/convert.jl 

==================================================
Test Summary:        | Pass  Fail  Error  Total
Test Suites          |  125     5      1    131
  Classification     |   84     4            88
    random.jl        |   25     3            28
    low_precision.jl |   16                  16
    heterogeneous.jl |    3                   3
    digits.jl        |    9                   9
    iris.jl          |   24                  24
    adult.jl         |    3                   3
    scikitlearn.jl   |    4     1             5
  Regression         |   38     1      1     40
    random.jl        |   16            1     17
    low_precision.jl |   10                  10
    digits.jl        |    7                   7
    scikitlearn.jl   |    5     1             6
  Miscellaneous      |    3                   3
ERROR: LoadError: Some tests did not pass: 125 passed, 5 failed, 1 errored, 0 broken.
in expression starting at /home/pkgeval/.julia/packages/DecisionTree/lNaGR/test/runtests.jl:46
ERROR: Package DecisionTree errored during testing
Stacktrace:
  [1] pkgerror(msg::String)
    @ Pkg.Types /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Types.jl:52
  [2] test(ctx::Pkg.Types.Context, pkgs::Vector{Pkg.Types.PackageSpec}; coverage::Bool, julia_args::Cmd, test_args::Cmd, test_fn::Nothing)
    @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1561
  [3] test(ctx::Pkg.Types.Context, pkgs::Vector{Pkg.Types.PackageSpec}; coverage::Bool, test_fn::Nothing, julia_args::Cmd, test_args::Cmd, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:327
  [4] test(ctx::Pkg.Types.Context, pkgs::Vector{Pkg.Types.PackageSpec})
    @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:314
  [5] #test#61
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:67 [inlined]
  [6] test
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:67 [inlined]
  [7] #test#60
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:66 [inlined]
  [8] test
    @ /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:66 [inlined]
  [9] test(pkg::String; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:65
 [10] test(pkg::String)
    @ Pkg.API /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:65
 [11] top-level scope
    @ none:16
