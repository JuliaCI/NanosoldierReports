Julia Version 1.5.0-DEV.492
Commit 60f52677d9 (2020-03-22 11:09 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed TimerOutputs ─────── v0.5.3
  Installed Reexport ─────────── v0.2.0
  Installed FFTW_jll ─────────── v3.3.9+4
  Installed CodecZlib ────────── v0.7.0
  Installed MKL_jll ──────────── v2019.0.117+2
  Installed StaticArrays ─────── v0.12.1
  Installed BinaryProvider ───── v0.5.8
  Installed Oceananigans ─────── v0.27.1
  Installed VersionParsing ───── v1.2.0
  Installed Zlib_jll ─────────── v1.2.11+8
  Installed CEnum ────────────── v0.2.0
  Installed OrderedCollections ─ v1.1.0
  Installed CFTime ───────────── v0.1.0
  Installed Parsers ──────────── v0.3.12
  Installed NCDatasets ───────── v0.10.1
  Installed DataStructures ───── v0.17.10
  Installed LLVM ─────────────── v1.3.4
  Installed Adapt ────────────── v1.0.1
  Installed CondaBinDeps ─────── v0.2.0
  Installed Requires ─────────── v1.0.1
  Installed AbstractFFTs ─────── v0.5.0
  Installed FileIO ───────────── v1.2.3
  Installed Cassette ─────────── v0.3.1
  Installed NNlib ────────────── v0.6.6
  Installed CuArrays ─────────── v1.7.0
  Installed IntelOpenMP_jll ──── v2018.0.3+0
  Installed BinDeps ──────────── v1.0.0
  Installed GPUArrays ────────── v2.0.1
  Installed JLD2 ─────────────── v0.1.3
  Installed CUDAapi ──────────── v2.1.0
  Installed MacroTools ───────── v0.5.4
  Installed JSON ─────────────── v0.21.0
  Installed GPUifyLoops ──────── v0.2.9
  Installed Conda ────────────── v1.4.1
  Installed TranscodingStreams ─ v0.9.5
  Installed CUDAdrv ──────────── v5.1.0
  Installed FFTW ─────────────── v1.2.0
  Installed URIParser ────────── v0.4.0
  Installed OffsetArrays ─────── v1.0.3
  Installed CUDAnative ───────── v2.9.1
                                                                           0.7%######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
#                                                                          2.3%######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
   9e8cae18 + Oceananigans v0.27.1
   Updating `~/.julia/environments/v1.5/Manifest.toml`
   621f4979 + AbstractFFTs v0.5.0
   79e6a3ab + Adapt v1.0.1
   9e28174c + BinDeps v1.0.0
   b99e7846 + BinaryProvider v0.5.8
   fa961155 + CEnum v0.2.0
   179af706 + CFTime v0.1.0
   3895d2a7 + CUDAapi v2.1.0
   c5f51814 + CUDAdrv v5.1.0
   be33ccc6 + CUDAnative v2.9.1
   7057c7e9 + Cassette v0.3.1
   944b1d66 + CodecZlib v0.7.0
   8f4d0f93 + Conda v1.4.1
   a9693cdc + CondaBinDeps v0.2.0
   3a865a2d + CuArrays v1.7.0
   864edb3b + DataStructures v0.17.10
   7a1cc6ca + FFTW v1.2.0
   f5851436 + FFTW_jll v3.3.9+4
   5789e2e9 + FileIO v1.2.3
   0c68f7d7 + GPUArrays v2.0.1
   ba82f77b + GPUifyLoops v0.2.9
   1d5cc7b8 + IntelOpenMP_jll v2018.0.3+0
   033835bb + JLD2 v0.1.3
   682c06a0 + JSON v0.21.0
   929cbde3 + LLVM v1.3.4
   856f044c + MKL_jll v2019.0.117+2
   1914dd2f + MacroTools v0.5.4
   85f8d34a + NCDatasets v0.10.1
   872c559c + NNlib v0.6.6
   9e8cae18 + Oceananigans v0.27.1
   6fe1bfb0 + OffsetArrays v1.0.3
   bac558e1 + OrderedCollections v1.1.0
   69de0a69 + Parsers v0.3.12
   189a3867 + Reexport v0.2.0
   ae029012 + Requires v1.0.1
   90137ffa + StaticArrays v0.12.1
   a759f4b9 + TimerOutputs v0.5.3
   3bb67fe8 + TranscodingStreams v0.9.5
   30578b45 + URIParser v0.4.0
   81def892 + VersionParsing v1.2.0
   83775a58 + Zlib_jll v1.2.11+8
   2a0f44e3 + Base64
   ade2ca70 + Dates
   8ba89e20 + Distributed
   b77e0a4c + InteractiveUtils
   76f85450 + LibGit2
   8f399da3 + Libdl
   37e2e46d + LinearAlgebra
   56ddb016 + Logging
   d6f4376e + Markdown
   a63ad114 + Mmap
   44cfe95a + Pkg
   de0858da + Printf
   3fa0cd96 + REPL
   9a3f8284 + Random
   ea8e919c + SHA
   9e88b42a + Serialization
   6462fe0b + Sockets
   2f01184e + SparseArrays
   10745b16 + Statistics
   8dfed614 + Test
   cf7118a7 + UUIDs
   4ec0a83e + Unicode
   Building Conda ─────→ `~/.julia/packages/Conda/3rPhK/deps/build.log`
   Building NCDatasets → `~/.julia/packages/NCDatasets/Tb4eK/deps/build.log`
   Building NNlib ─────→ `~/.julia/packages/NNlib/FAI3o/deps/build.log`
   Building FFTW ──────→ `~/.julia/packages/FFTW/qqcBj/deps/build.log`
    Testing Oceananigans
                                                                           0.3%################################                                          44.5%######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
                                                                           0.4%#############################################################             85.4%######################################################################## 100.0%
#                                                                          1.7%######################################################################## 100.0%
###############                                                           22.2%######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
#                                                                          2.1%######################################################################## 100.0%
#                                                                          2.7%######################################################################## 100.0%
                                                                           0.3%#########################################                                 57.6%######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
                                                                           0.8%######################################################################## 100.0%
#                                                                          1.7%######################################################################## 100.0%
#                                                                          2.3%######################################################################## 100.0%
####                                                                       6.6%######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                         ############                                                              16.9%###################################################                       71.8%######################################################################## 100.0%
     Status `/tmp/jl_oHTYeW/Project.toml`
   79e6a3ab Adapt v1.0.1
   3895d2a7 CUDAapi v2.1.0
   c5f51814 CUDAdrv v5.1.0
   be33ccc6 CUDAnative v2.9.1
   3a865a2d CuArrays v1.7.0
   7a1cc6ca FFTW v1.2.0
   ba82f77b GPUifyLoops v0.2.9
   033835bb JLD2 v0.1.3
   85f8d34a NCDatasets v0.10.1
   9e8cae18 Oceananigans v0.27.1
   6fe1bfb0 OffsetArrays v1.0.3
   bac558e1 OrderedCollections v1.1.0
   91a5bcdd Plots v0.29.8
   bdfc003b TimesDates v0.2.5
   ade2ca70 Dates
   37e2e46d LinearAlgebra
   56ddb016 Logging
   de0858da Printf
   9a3f8284 Random
   10745b16 Statistics
   8dfed614 Test
     Status `/tmp/jl_oHTYeW/Manifest.toml`
   621f4979 AbstractFFTs v0.5.0
   79e6a3ab Adapt v1.0.1
   9e28174c BinDeps v1.0.0
   b99e7846 BinaryProvider v0.5.8
   6e34b625 Bzip2_jll v1.0.6+1
   fa961155 CEnum v0.2.0
   179af706 CFTime v0.1.0
   3895d2a7 CUDAapi v2.1.0
   c5f51814 CUDAdrv v5.1.0
   be33ccc6 CUDAnative v2.9.1
   7057c7e9 Cassette v0.3.1
   944b1d66 CodecZlib v0.7.0
   3da002f7 ColorTypes v0.10.0
   5ae59095 Colors v0.12.0
   a216cea6 CompoundPeriods v0.4.0
   8f4d0f93 Conda v1.4.1
   a9693cdc CondaBinDeps v0.2.0
   d38c429a Contour v0.5.2
   3a865a2d CuArrays v1.7.0
   9a962f9c DataAPI v1.1.0
   864edb3b DataStructures v0.17.10
   e2ba6199 ExprTools v0.1.0
   8f5d6c58 EzXML v1.1.0
   c87230d0 FFMPEG v0.3.0
   b22a6f82 FFMPEG_jll v4.1.0+2
   7a1cc6ca FFTW v1.2.0
   f5851436 FFTW_jll v3.3.9+4
   5789e2e9 FileIO v1.2.3
   53c48c17 FixedPointNumbers v0.8.0
   d7e528f0 FreeType2_jll v2.10.1+1
   559328eb FriBidi_jll v1.0.5+2
   0c68f7d7 GPUArrays v2.0.1
   ba82f77b GPUifyLoops v0.2.9
   28b8d3ca GR v0.48.0
   4d00f742 GeometryTypes v0.7.6
   1d5cc7b8 IntelOpenMP_jll v2018.0.3+0
   c8e1da08 IterTools v1.3.0
   033835bb JLD2 v0.1.3
   682c06a0 JSON v0.21.0
   c1c5ebd0 LAME_jll v3.100.0+0
   929cbde3 LLVM v1.3.4
   dd192d2f LibVPX_jll v1.8.1+1
   94ce4f54 Libiconv_jll v1.16.0+1
   856f044c MKL_jll v2019.0.117+2
   1914dd2f MacroTools v0.5.4
   442fdcdd Measures v0.3.1
   e1d29d7a Missings v0.4.3
   78c3b35d Mocking v0.7.1
   85f8d34a NCDatasets v0.10.1
   872c559c NNlib v0.6.6
   77ba4419 NaNMath v0.3.3
   9e8cae18 Oceananigans v0.27.1
   6fe1bfb0 OffsetArrays v1.0.3
   e7412a2a Ogg_jll v1.3.3+0
   458c3c95 OpenSSL_jll v1.1.1+1
   91d4177d Opus_jll v1.3.1+0
   bac558e1 OrderedCollections v1.1.0
   69de0a69 Parsers v0.3.12
   ccf2f8ad PlotThemes v1.0.1
   995b91a9 PlotUtils v0.6.4
   91a5bcdd Plots v0.29.8
   3cdcf5f2 RecipesBase v0.8.0
   189a3867 Reexport v0.2.0
   ae029012 Requires v1.0.1
   992d4aef Showoff v0.3.1
   a2af1166 SortingAlgorithms v0.3.1
   90137ffa StaticArrays v0.12.1
   2913bbd2 StatsBase v0.32.2
   f269a46b TimeZones v0.11.0
   a759f4b9 TimerOutputs v0.5.3
   bdfc003b TimesDates v0.2.5
   3bb67fe8 TranscodingStreams v0.9.5
   30578b45 URIParser v0.4.0
   81def892 VersionParsing v1.2.0
   02c8fc9c XML2_jll v2.9.9+1
   83775a58 Zlib_jll v1.2.11+8
   0ac62f75 libass_jll v0.14.0+0
   f638f0a6 libfdk_aac_jll v0.1.6+1
   f27f6e37 libvorbis_jll v1.3.6+2
   1270edf5 x264_jll v2019.5.25+1
   dfaa095f x265_jll v3.0.0+0
   2a0f44e3 Base64
   ade2ca70 Dates
   8bb1440f DelimitedFiles
   8ba89e20 Distributed
   b77e0a4c InteractiveUtils
   76f85450 LibGit2
   8f399da3 Libdl
   37e2e46d LinearAlgebra
   56ddb016 Logging
   d6f4376e Markdown
   a63ad114 Mmap
   44cfe95a Pkg
   de0858da Printf
   3fa0cd96 REPL
   9a3f8284 Random
   ea8e919c SHA
   9e88b42a Serialization
   6462fe0b Sockets
   2f01184e SparseArrays
   10745b16 Statistics
   8dfed614 Test
   cf7118a7 UUIDs
   4ec0a83e Unicode
CUDA-enabled GPU(s) detected:
CuDevice(0): Tesla T4
┌ Warning: Incompatibility detected between CUDA and LLVM 8.0+; disabling debug info emission for CUDA kernels
└ @ CUDAnative ~/.julia/packages/CUDAnative/JfXpo/src/CUDAnative.jl:88
[23/03/2020 01:32:12] Testing grids... ---  Info /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_grids.jl:97
[23/03/2020 01:32:12]   Testing regular Cartesian grid... ---  Info /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_grids.jl:100
[23/03/2020 01:32:12]     Testing grid initialization... ---  Info /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_grids.jl:103
[23/03/2020 01:32:17]     Testing grid constructor errors... ---  Info /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_grids.jl:117
[23/03/2020 01:32:20]   Testing vertically stretched Cartesian grid... ---  Info /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_grids.jl:155
[23/03/2020 01:32:20]     Testing grid initialization... ---  Info /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_grids.jl:158
[23/03/2020 01:32:32] Testing operators... ---  Info /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_operators.jl:58
[23/03/2020 01:32:32]   Testing function differentiation... ---  Info /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_operators.jl:61
[23/03/2020 01:32:32]   Testing function interpolation... ---  Info /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_operators.jl:66
[23/03/2020 01:32:32]   Testing 2D operators... ---  Info /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_operators.jl:71
[23/03/2020 01:32:37] Testing boundary conditions... ---  Info /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_boundary_conditions.jl:29
[23/03/2020 01:32:38]   Testing boundary functions... ---  Info /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_boundary_conditions.jl:32
[23/03/2020 01:32:38]   Testing field boundary functions... ---  Info /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_boundary_conditions.jl:50
[23/03/2020 01:32:41] Testing fields... ---  Info /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
[23/03/2020 01:32:41]   Testing field initialization... ---  Info /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32
[23/03/2020 01:33:02] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:35
  Test threw exception
  Expression: correct_field_size(arch, grid, CellField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Periodic,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Periodic,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Periodic,StepRangeLen{Float32,Float64,Float64}}, ::typeof(CellField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:35 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:09] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:36
  Test threw exception
  Expression: correct_field_size(arch, grid, XFaceField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Periodic,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Periodic,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Periodic,StepRangeLen{Float32,Float64,Float64}}, ::typeof(XFaceField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:36 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:09] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:37
  Test threw exception
  Expression: correct_field_size(arch, grid, YFaceField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Periodic,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Periodic,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Periodic,StepRangeLen{Float32,Float64,Float64}}, ::typeof(YFaceField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:37 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:09] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:38
  Test threw exception
  Expression: correct_field_size(arch, grid, ZFaceField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Periodic,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Periodic,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Periodic,StepRangeLen{Float32,Float64,Float64}}, ::typeof(ZFaceField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:38 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:10] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:41
  Test threw exception
  Expression: correct_field_size(arch, grid, CellField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(CellField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:41 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:10] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:42
  Test threw exception
  Expression: correct_field_size(arch, grid, XFaceField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(XFaceField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:42 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:10] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:43
  Test threw exception
  Expression: correct_field_size(arch, grid, YFaceField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(YFaceField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:43 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:10] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:44
  Test threw exception
  Expression: correct_field_size(arch, grid, ZFaceField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 2 * H[3] + 1)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(ZFaceField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:44 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:11] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:47
  Test threw exception
  Expression: correct_field_size(arch, grid, CellField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Bounded,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Bounded,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float32,Periodic,Bounded,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(CellField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:47 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:11] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:48
  Test threw exception
  Expression: correct_field_size(arch, grid, XFaceField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Bounded,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Bounded,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float32,Periodic,Bounded,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(XFaceField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:48 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:11] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:49
  Test threw exception
  Expression: correct_field_size(arch, grid, YFaceField, N[1] + 2 * H[1], N[2] + 1 + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Bounded,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Bounded,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float32,Periodic,Bounded,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(YFaceField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:49 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:11] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:50
  Test threw exception
  Expression: correct_field_size(arch, grid, ZFaceField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 1 + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Bounded,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Bounded,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float32,Periodic,Bounded,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(ZFaceField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:50 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:12] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:53
  Test threw exception
  Expression: correct_field_size(arch, grid, CellField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Bounded,Bounded,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Bounded,Bounded,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float32,Bounded,Bounded,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(CellField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:53 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:12] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:54
  Test threw exception
  Expression: correct_field_size(arch, grid, XFaceField, N[1] + 1 + 2 * H[1], N[2] + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Bounded,Bounded,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Bounded,Bounded,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float32,Bounded,Bounded,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(XFaceField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:54 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:12] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:55
  Test threw exception
  Expression: correct_field_size(arch, grid, YFaceField, N[1] + 2 * H[1], N[2] + 1 + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Bounded,Bounded,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Bounded,Bounded,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float32,Bounded,Bounded,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(YFaceField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:55 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:12] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:56
  Test threw exception
  Expression: correct_field_size(arch, grid, ZFaceField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 1 + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Bounded,Bounded,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Bounded,Bounded,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float32,Bounded,Bounded,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(ZFaceField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:56 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:13] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:35
  Test threw exception
  Expression: correct_field_size(arch, grid, CellField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Periodic,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Periodic,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Periodic,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::typeof(CellField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:35 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:13] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:36
  Test threw exception
  Expression: correct_field_size(arch, grid, XFaceField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Periodic,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Periodic,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Periodic,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::typeof(XFaceField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:36 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:13] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:37
  Test threw exception
  Expression: correct_field_size(arch, grid, YFaceField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Periodic,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Periodic,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Periodic,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::typeof(YFaceField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:37 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:14] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:38
  Test threw exception
  Expression: correct_field_size(arch, grid, ZFaceField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Periodic,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Periodic,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Periodic,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::typeof(ZFaceField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:38 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:14] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:41
  Test threw exception
  Expression: correct_field_size(arch, grid, CellField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::typeof(CellField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:41 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:14] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:42
  Test threw exception
  Expression: correct_field_size(arch, grid, XFaceField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::typeof(XFaceField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:42 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:14] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:43
  Test threw exception
  Expression: correct_field_size(arch, grid, YFaceField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::typeof(YFaceField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:43 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:15] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:44
  Test threw exception
  Expression: correct_field_size(arch, grid, ZFaceField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 2 * H[3] + 1)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::typeof(ZFaceField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:44 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:15] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:47
  Test threw exception
  Expression: correct_field_size(arch, grid, CellField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Bounded,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Bounded,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float64,Periodic,Bounded,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::typeof(CellField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:47 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:15] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:48
  Test threw exception
  Expression: correct_field_size(arch, grid, XFaceField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Bounded,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Bounded,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float64,Periodic,Bounded,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::typeof(XFaceField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:48 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:15] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:49
  Test threw exception
  Expression: correct_field_size(arch, grid, YFaceField, N[1] + 2 * H[1], N[2] + 1 + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Bounded,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Bounded,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float64,Periodic,Bounded,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::typeof(YFaceField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:49 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:15] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:50
  Test threw exception
  Expression: correct_field_size(arch, grid, ZFaceField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 1 + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Bounded,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Bounded,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float64,Periodic,Bounded,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::typeof(ZFaceField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:50 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:16] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:53
  Test threw exception
  Expression: correct_field_size(arch, grid, CellField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Bounded,Bounded,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Bounded,Bounded,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float64,Bounded,Bounded,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::typeof(CellField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:53 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:16] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:54
  Test threw exception
  Expression: correct_field_size(arch, grid, XFaceField, N[1] + 1 + 2 * H[1], N[2] + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Bounded,Bounded,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Bounded,Bounded,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float64,Bounded,Bounded,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::typeof(XFaceField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:54 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:16] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:55
  Test threw exception
  Expression: correct_field_size(arch, grid, YFaceField, N[1] + 2 * H[1], N[2] + 1 + 2 * H[2], N[3] + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Bounded,Bounded,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Bounded,Bounded,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float64,Bounded,Bounded,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::typeof(YFaceField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:55 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:16] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Field initialization: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:56
  Test threw exception
  Expression: correct_field_size(arch, grid, ZFaceField, N[1] + 2 * H[1], N[2] + 2 * H[2], N[3] + 1 + 2 * H[3])
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Bounded,Bounded,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Bounded,Bounded,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_size(::GPU, ::RegularCartesianGrid{Float64,Bounded,Bounded,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::typeof(ZFaceField), ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:7
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:56 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:32 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:16]   Testing field setting... ---  Info /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68
[23/03/2020 01:33:28] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(CellField), ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:29] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(CellField), ::Int8) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:29] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(CellField), ::Int16) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:29] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(CellField), ::Int32) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:29] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(CellField), ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:29] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(CellField), ::Int128) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:29] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(CellField), ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:30] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(CellField), ::UInt8) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:30] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(CellField), ::UInt16) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:30] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(CellField), ::UInt32) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:30] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(CellField), ::UInt64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:30] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(CellField), ::UInt128) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:30] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(CellField), ::Float64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:30] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(CellField), ::Float64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:31] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(CellField), ::Float64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:31] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(CellField), ::Float32) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:31] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(CellField), ::Rational{Int64}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:31] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(CellField), ::Rational{Int64}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:31] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(CellField), ::Irrational{:π}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:32] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(XFaceField), ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:32] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(XFaceField), ::Int8) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:32] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(XFaceField), ::Int16) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:32] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(XFaceField), ::Int32) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:32] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(XFaceField), ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:32] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(XFaceField), ::Int128) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:32] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(XFaceField), ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:33] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(XFaceField), ::UInt8) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:33] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(XFaceField), ::UInt16) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:33] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(XFaceField), ::UInt32) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:33] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(XFaceField), ::UInt64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:33] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(XFaceField), ::UInt128) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:33] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(XFaceField), ::Float64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:33] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(XFaceField), ::Float64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:34] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(XFaceField), ::Float64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:34] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(XFaceField), ::Float32) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:34] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(XFaceField), ::Rational{Int64}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:34] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(XFaceField), ::Rational{Int64}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:34] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] XFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:119
   [29] XFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:153 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(XFaceField), ::Irrational{:π}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:34] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(YFaceField), ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:34] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(YFaceField), ::Int8) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:35] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(YFaceField), ::Int16) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:35] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(YFaceField), ::Int32) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:35] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(YFaceField), ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:35] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(YFaceField), ::Int128) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:35] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(YFaceField), ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:35] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(YFaceField), ::UInt8) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:35] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(YFaceField), ::UInt16) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:35] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(YFaceField), ::UInt32) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:36] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(YFaceField), ::UInt64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:36] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(YFaceField), ::UInt128) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:36] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(YFaceField), ::Float64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:36] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(YFaceField), ::Float64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:36] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(YFaceField), ::Float64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:36] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(YFaceField), ::Float32) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:36] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(YFaceField), ::Rational{Int64}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:37] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(YFaceField), ::Rational{Int64}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:37] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] YFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:134
   [29] YFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:154 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(YFaceField), ::Irrational{:π}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:37] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(ZFaceField), ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:37] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(ZFaceField), ::Int8) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:37] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(ZFaceField), ::Int16) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:37] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(ZFaceField), ::Int32) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:37] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(ZFaceField), ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:38] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(ZFaceField), ::Int128) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:38] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(ZFaceField), ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:38] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(ZFaceField), ::UInt8) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:38] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(ZFaceField), ::UInt16) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:38] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(ZFaceField), ::UInt32) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:38] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(ZFaceField), ::UInt64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:38] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(ZFaceField), ::UInt128) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:39] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(ZFaceField), ::Float64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:39] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(ZFaceField), ::Float64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:39] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(ZFaceField), ::Float64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:39] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(ZFaceField), ::Float32) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:39] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(ZFaceField), ::Rational{Int64}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:39] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(ZFaceField), ::Rational{Int64}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:39] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74
  Test threw exception
  Expression: correct_field_value_was_set(arch, grid, fieldtype, val)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] ZFaceField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:149
   [29] ZFaceField at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:155 [inlined]
   [30] correct_field_value_was_set(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::typeof(ZFaceField), ::Irrational{:π}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:17
   [31] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:74 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
  
[23/03/2020 01:33:39] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Setting fields: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:67
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] CellField(::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:152
   [30] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:78 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:68 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_fields.jl:23
   [35] include(::String) at ./client.jl:441
   [36] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/runtests.jl:124 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] (::var"#11#12")() at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/runtests.jl:121
   [39] with_logstate(::var"#11#12", ::Base.CoreLogging.LogState) at ./logging.jl:398
   [40] with_logger(::Function, ::ModelLogger) at ./logging.jl:505
   [41] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/runtests.jl:119
   [42] include(::String) at ./client.jl:441
   [43] top-level scope at none:6
   [44] eval(::Module, ::Any) at ./boot.jl:331
   [45] exec_options(::Base.JLOptions) at ./client.jl:264
   [46] _start() at ./client.jl:490
  
[23/03/2020 01:33:40] Testing halo regions... ---  Info /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:42
[23/03/2020 01:33:40]   Testing initializing halo regions... ---  Info /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:51
[23/03/2020 01:33:43] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Initializing halo regions: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53
  Test threw exception
  Expression: halo_regions_initalized_correctly(arch, FT, N...)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] halo_regions_initalized_correctly(::GPU, ::Type{T} where T, ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:6
   [30] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:51 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:42
  
[23/03/2020 01:33:44] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Initializing halo regions: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53
  Test threw exception
  Expression: halo_regions_initalized_correctly(arch, FT, N...)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] halo_regions_initalized_correctly(::GPU, ::Type{T} where T, ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:6
   [30] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:51 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:42
  
[23/03/2020 01:33:44] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Initializing halo regions: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53
  Test threw exception
  Expression: halo_regions_initalized_correctly(arch, FT, N...)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] halo_regions_initalized_correctly(::GPU, ::Type{T} where T, ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:6
   [30] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:51 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:42
  
[23/03/2020 01:33:44] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Initializing halo regions: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53
  Test threw exception
  Expression: halo_regions_initalized_correctly(arch, FT, N...)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] halo_regions_initalized_correctly(::GPU, ::Type{T} where T, ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:6
   [30] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:51 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:42
  
[23/03/2020 01:33:44] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Initializing halo regions: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53
  Test threw exception
  Expression: halo_regions_initalized_correctly(arch, FT, N...)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] halo_regions_initalized_correctly(::GPU, ::Type{T} where T, ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:6
   [30] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:51 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:42
  
[23/03/2020 01:33:44] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Initializing halo regions: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53
  Test threw exception
  Expression: halo_regions_initalized_correctly(arch, FT, N...)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] halo_regions_initalized_correctly(::GPU, ::Type{T} where T, ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:6
   [30] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:51 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:42
  
[23/03/2020 01:33:44] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Initializing halo regions: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53
  Test threw exception
  Expression: halo_regions_initalized_correctly(arch, FT, N...)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] halo_regions_initalized_correctly(::GPU, ::Type{T} where T, ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:6
   [30] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:51 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:42
  
[23/03/2020 01:33:44] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Initializing halo regions: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53
  Test threw exception
  Expression: halo_regions_initalized_correctly(arch, FT, N...)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] halo_regions_initalized_correctly(::GPU, ::Type{T} where T, ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:6
   [30] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:51 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:42
  
[23/03/2020 01:33:44] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Initializing halo regions: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53
  Test threw exception
  Expression: halo_regions_initalized_correctly(arch, FT, N...)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] halo_regions_initalized_correctly(::GPU, ::Type{T} where T, ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:6
   [30] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:51 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:42
  
[23/03/2020 01:33:44] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Initializing halo regions: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53
  Test threw exception
  Expression: halo_regions_initalized_correctly(arch, FT, N...)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float32,3,Nothing}, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float32,Periodic,Periodic,Bounded,StepRangeLen{Float32,Float64,Float64}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] halo_regions_initalized_correctly(::GPU, ::Type{T} where T, ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:6
   [30] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:51 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:42
  
[23/03/2020 01:33:45] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Initializing halo regions: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53
  Test threw exception
  Expression: halo_regions_initalized_correctly(arch, FT, N...)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] halo_regions_initalized_correctly(::GPU, ::Type{T} where T, ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:6
   [30] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:51 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:42
  
[23/03/2020 01:33:45] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Initializing halo regions: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53
  Test threw exception
  Expression: halo_regions_initalized_correctly(arch, FT, N...)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] halo_regions_initalized_correctly(::GPU, ::Type{T} where T, ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:6
   [30] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:51 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:42
  
[23/03/2020 01:33:45] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Initializing halo regions: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53
  Test threw exception
  Expression: halo_regions_initalized_correctly(arch, FT, N...)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] halo_regions_initalized_correctly(::GPU, ::Type{T} where T, ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:6
   [30] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:51 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:42
  
[23/03/2020 01:33:45] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Initializing halo regions: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53
  Test threw exception
  Expression: halo_regions_initalized_correctly(arch, FT, N...)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] halo_regions_initalized_correctly(::GPU, ::Type{T} where T, ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:6
   [30] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:51 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:42
  
[23/03/2020 01:33:45] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Initializing halo regions: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53
  Test threw exception
  Expression: halo_regions_initalized_correctly(arch, FT, N...)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] halo_regions_initalized_correctly(::GPU, ::Type{T} where T, ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:6
   [30] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:51 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:42
  
[23/03/2020 01:33:45] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Initializing halo regions: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53
  Test threw exception
  Expression: halo_regions_initalized_correctly(arch, FT, N...)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] halo_regions_initalized_correctly(::GPU, ::Type{T} where T, ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:6
   [30] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:51 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:42
  
[23/03/2020 01:33:45] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Initializing halo regions: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53
  Test threw exception
  Expression: halo_regions_initalized_correctly(arch, FT, N...)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] halo_regions_initalized_correctly(::GPU, ::Type{T} where T, ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:6
   [30] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:51 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:42
  
[23/03/2020 01:33:45] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Initializing halo regions: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53
  Test threw exception
  Expression: halo_regions_initalized_correctly(arch, FT, N...)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] halo_regions_initalized_correctly(::GPU, ::Type{T} where T, ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:6
   [30] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:51 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:42
  
[23/03/2020 01:33:45] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Initializing halo regions: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53
  Test threw exception
  Expression: halo_regions_initalized_correctly(arch, FT, N...)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] halo_regions_initalized_correctly(::GPU, ::Type{T} where T, ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:6
   [30] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:51 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:42
  
[23/03/2020 01:33:45] Building the CUDAnative run-time library for your sm_75 device, this might take a while... ---  Info /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:188
Initializing halo regions: Error During Test at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53
  Test threw exception
  Expression: halo_regions_initalized_correctly(arch, FT, N...)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#93"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), CUDAnative.var"#postprocess#92"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob(CUDAnative.Runtime.unbox_uint64, Tuple{Any}, v"7.5.0", false, nothing, nothing, nothing, nothing, nothing), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#93",CUDAnative.var"#hook_module_activation#94"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#92",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#97"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#98"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:148
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/irgen.jl:165
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:104 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:103
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:144
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:154
   [11] (::CUDAnative.var"#139#142"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:189
   [12] get!(::CUDAnative.var"#139#142"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/rtlib.jl:182
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:99
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:52
   [16] #compile#150 at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/compiler/driver.jl:33 [inlined]
   [17] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:393 [inlined]
   [18] cufunction(::GPUArrays.var"#25#26", ::Type{Tuple{CuArrays.CuKernelState,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [19] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:360
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/JfXpo/src/execution.jl:179 [inlined]
   [21] _gpu_call(::CuArrays.CuArrayBackend, ::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Tuple{Tuple{Int64},Tuple{Int64}}) at /home/pkgeval/.julia/packages/CuArrays/1njKF/src/gpuarray_interface.jl:62
   [22] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:151 [inlined]
   [23] gpu_call(::Function, ::CuArray{Float64,3,Nothing}, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/abstract_gpu_interface.jl:128
   [24] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:48 [inlined]
   [25] copyto! at /home/pkgeval/.julia/packages/GPUArrays/1wgPO/src/broadcast.jl:60 [inlined]
   [26] materialize! at ./broadcast.jl:823 [inlined]
   [27] zeros(::Type{T} where T, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}, ::Tuple{DataType,DataType,DataType}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:351
   [28] CellField(::DataType, ::GPU, ::RegularCartesianGrid{Float64,Periodic,Periodic,Bounded,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/src/Fields/field.jl:104
   [29] halo_regions_initalized_correctly(::GPU, ::Type{T} where T, ::Int64, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:6
   [30] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:53 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:51 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] top-level scope at /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:42
  
[23/03/2020 01:33:46]   Testing filling halo regions... ---  Info /home/pkgeval/.julia/packages/Oceananigans/Vea3t/test/test_halo_regions.jl:58
