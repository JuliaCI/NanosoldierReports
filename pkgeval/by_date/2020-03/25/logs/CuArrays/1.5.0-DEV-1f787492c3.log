Julia Version 1.5.0-DEV.507
Commit 1f787492c3 (2020-03-25 15:03 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed Reexport ─────────── v0.2.0
  Installed Adapt ────────────── v1.0.1
  Installed TimerOutputs ─────── v0.5.3
  Installed OrderedCollections ─ v1.1.0
  Installed BinaryProvider ───── v0.5.8
  Installed LLVM ─────────────── v1.3.4
  Installed CuArrays ─────────── v2.0.0
  Installed CUDAnative ───────── v3.0.1
  Installed CEnum ────────────── v0.2.0
  Installed TerminalMenus ────── v0.1.0
  Installed CodeTracking ─────── v0.5.8
  Installed Requires ─────────── v1.0.1
  Installed Compat ───────────── v2.2.0
  Installed CUDAapi ──────────── v4.0.0
  Installed GPUArrays ────────── v3.1.0
  Installed AbstractFFTs ─────── v0.5.0
  Installed NNlib ────────────── v0.6.6
  Installed Cthulhu ──────────── v1.0.0
  Installed MacroTools ───────── v0.5.5
  Installed DataStructures ───── v0.17.10
  Installed CUDAdrv ──────────── v6.2.1
   Updating `~/.julia/environments/v1.5/Project.toml`
   3a865a2d + CuArrays v2.0.0
   Updating `~/.julia/environments/v1.5/Manifest.toml`
   621f4979 + AbstractFFTs v0.5.0
   79e6a3ab + Adapt v1.0.1
   b99e7846 + BinaryProvider v0.5.8
   fa961155 + CEnum v0.2.0
   3895d2a7 + CUDAapi v4.0.0
   c5f51814 + CUDAdrv v6.2.1
   be33ccc6 + CUDAnative v3.0.1
   da1fd8a2 + CodeTracking v0.5.8
   34da2185 + Compat v2.2.0
   f68482b8 + Cthulhu v1.0.0
   3a865a2d + CuArrays v2.0.0
   864edb3b + DataStructures v0.17.10
   0c68f7d7 + GPUArrays v3.1.0
   929cbde3 + LLVM v1.3.4
   1914dd2f + MacroTools v0.5.5
   872c559c + NNlib v0.6.6
   bac558e1 + OrderedCollections v1.1.0
   189a3867 + Reexport v0.2.0
   ae029012 + Requires v1.0.1
   dc548174 + TerminalMenus v0.1.0
   a759f4b9 + TimerOutputs v0.5.3
   2a0f44e3 + Base64
   ade2ca70 + Dates
   8bb1440f + DelimitedFiles
   8ba89e20 + Distributed
   b77e0a4c + InteractiveUtils
   76f85450 + LibGit2
   8f399da3 + Libdl
   37e2e46d + LinearAlgebra
   56ddb016 + Logging
   d6f4376e + Markdown
   a63ad114 + Mmap
   44cfe95a + Pkg
   de0858da + Printf
   3fa0cd96 + REPL
   9a3f8284 + Random
   ea8e919c + SHA
   9e88b42a + Serialization
   1a1011a3 + SharedArrays
   6462fe0b + Sockets
   2f01184e + SparseArrays
   10745b16 + Statistics
   8dfed614 + Test
   cf7118a7 + UUIDs
   4ec0a83e + Unicode
   Building NNlib → `~/.julia/packages/NNlib/FAI3o/deps/build.log`
    Testing CuArrays
     Status `/tmp/jl_C44FNg/Project.toml`
   621f4979 AbstractFFTs v0.5.0
   79e6a3ab Adapt v1.0.1
   fa961155 CEnum v0.2.0
   3895d2a7 CUDAapi v4.0.0
   c5f51814 CUDAdrv v6.2.1
   be33ccc6 CUDAnative v3.0.1
   3a865a2d CuArrays v2.0.0
   864edb3b DataStructures v0.17.10
   7a1cc6ca FFTW v1.2.0
   1a297f60 FillArrays v0.8.5
   f6369f11 ForwardDiff v0.10.9
   0c68f7d7 GPUArrays v3.1.0
   1914dd2f MacroTools v0.5.5
   872c559c NNlib v0.6.6
   189a3867 Reexport v0.2.0
   ae029012 Requires v1.0.1
   a759f4b9 TimerOutputs v0.5.3
   8f399da3 Libdl
   37e2e46d LinearAlgebra
   44cfe95a Pkg
   de0858da Printf
   9a3f8284 Random
   2f01184e SparseArrays
   10745b16 Statistics
   8dfed614 Test
     Status `/tmp/jl_C44FNg/Manifest.toml`
   621f4979 AbstractFFTs v0.5.0
   79e6a3ab Adapt v1.0.1
   b99e7846 BinaryProvider v0.5.8
   fa961155 CEnum v0.2.0
   3895d2a7 CUDAapi v4.0.0
   c5f51814 CUDAdrv v6.2.1
   be33ccc6 CUDAnative v3.0.1
   da1fd8a2 CodeTracking v0.5.8
   bbf7d656 CommonSubexpressions v0.2.0
   34da2185 Compat v2.2.0
   e66e0078 CompilerSupportLibraries_jll v0.3.1+0
   f68482b8 Cthulhu v1.0.0
   3a865a2d CuArrays v2.0.0
   864edb3b DataStructures v0.17.10
   163ba53b DiffResults v1.0.2
   b552c78f DiffRules v1.0.1
   7a1cc6ca FFTW v1.2.0
   f5851436 FFTW_jll v3.3.9+4
   1a297f60 FillArrays v0.8.5
   f6369f11 ForwardDiff v0.10.9
   0c68f7d7 GPUArrays v3.1.0
   1d5cc7b8 IntelOpenMP_jll v2018.0.3+0
   929cbde3 LLVM v1.3.4
   856f044c MKL_jll v2019.0.117+2
   1914dd2f MacroTools v0.5.5
   872c559c NNlib v0.6.6
   77ba4419 NaNMath v0.3.3
   efe28fd5 OpenSpecFun_jll v0.5.3+3
   bac558e1 OrderedCollections v1.1.0
   189a3867 Reexport v0.2.0
   ae029012 Requires v1.0.1
   276daf66 SpecialFunctions v0.10.0
   90137ffa StaticArrays v0.12.1
   dc548174 TerminalMenus v0.1.0
   a759f4b9 TimerOutputs v0.5.3
   2a0f44e3 Base64
   ade2ca70 Dates
   8bb1440f DelimitedFiles
   8ba89e20 Distributed
   b77e0a4c InteractiveUtils
   76f85450 LibGit2
   8f399da3 Libdl
   37e2e46d LinearAlgebra
   56ddb016 Logging
   d6f4376e Markdown
   a63ad114 Mmap
   44cfe95a Pkg
   de0858da Printf
   3fa0cd96 REPL
   9a3f8284 Random
   ea8e919c SHA
   9e88b42a Serialization
   1a1011a3 SharedArrays
   6462fe0b Sockets
   2f01184e SparseArrays
   10745b16 Statistics
   8dfed614 Test
   cf7118a7 UUIDs
   4ec0a83e Unicode
[ Info: Testing using device Tesla T4 (compute capability 7.5.0, 14.558 GiB available memory) on CUDA driver 10.2.0 and toolkit 10.2.89
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
value constructors: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:135
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(GPUArrays.uniformscaling_kernel),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(GPUArrays.uniformscaling_kernel), ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},Int64,LinearAlgebra.UniformScaling{Bool}}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},Int64,LinearAlgebra.UniformScaling{Bool}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] AbstractGPUArray at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:33 [inlined]
   [28] CuArray{Float32,2,P} where P(::LinearAlgebra.UniformScaling{Bool}, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:39
   [29] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:169 [inlined]
   [30] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [31] value_constructor(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:136
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:5 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] test_construction(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:3
   [35] test(::Type{CuArray}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:49
   [36] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [37] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [38] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [39] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [40] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:40
   [41] include(::String) at ./client.jl:441
   [42] top-level scope at none:6
   [43] eval(::Module, ::Any) at ./boot.jl:331
   [44] exec_options(::Base.JLOptions) at ./client.jl:264
   [45] _start() at ./client.jl:490
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
iterator constructors: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:193
  Test threw exception
  Expression: AT(Fill(T(0), (10,))) == fill(AT{T}, T(0), (10,))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Bool,1,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},typeof(==),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float32,1,CUDAnative.AS.Global},Tuple{Bool},Tuple{Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float32,1,CUDAnative.AS.Global},Tuple{Bool},Tuple{Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Bool,1,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},typeof(==),Tuple{Base.Broadcast.Extruded{CuArray{Float32,1,Nothing},Tuple{Bool},Tuple{Int64}},Base.Broadcast.Extruded{CuArray{Float32,1,Nothing},Tuple{Bool},Tuple{Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{1},Nothing,typeof(==),Tuple{CuArray{Float32,1,Nothing},CuArray{Float32,1,Nothing}}}) at ./broadcast.jl:820
   [33] map(::Function, ::CuArray{Float32,1,Nothing}, ::CuArray{Float32,1,Nothing}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:91
   [34] #mapreduce#600 at ./reducedim.jl:308 [inlined]
   [35] mapreduce at ./reducedim.jl:308 [inlined]
   [36] ==(::CuArray{Float32,1,Nothing}, ::CuArray{Float32,1,Nothing}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/mapreduce.jl:54
   [37] eval_test(::Expr, ::Expr, ::LineNumberNode, ::Bool) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:246
   [38] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:193 [inlined]
   [39] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [40] iterator_constructors(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:192
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
iterator constructors: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:194
  Test threw exception
  Expression: AT(Fill(T(0), (10, 10))) == fill(AT{T}, T(0), (10, 10))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Bool,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(==),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Bool,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(==),Tuple{Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(==),Tuple{CuArray{Float32,2,Nothing},CuArray{Float32,2,Nothing}}}) at ./broadcast.jl:820
   [33] map(::Function, ::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:91
   [34] #mapreduce#600 at ./reducedim.jl:308 [inlined]
   [35] mapreduce at ./reducedim.jl:308 [inlined]
   [36] ==(::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/mapreduce.jl:54
   [37] eval_test(::Expr, ::Expr, ::LineNumberNode, ::Bool) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:246
   [38] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:194 [inlined]
   [39] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [40] iterator_constructors(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:192
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
iterator constructors: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:198
  Test threw exception
  Expression: AT(Eye{T}(10)) == AT{T}(I, 10, 10)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(GPUArrays.uniformscaling_kernel),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(GPUArrays.uniformscaling_kernel), ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},Int64,LinearAlgebra.UniformScaling{Bool}}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},Int64,LinearAlgebra.UniformScaling{Bool}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] AbstractGPUArray at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:33 [inlined]
   [28] CuArray{Float32,N,P} where P where N(::LinearAlgebra.UniformScaling{Bool}, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:39
   [29] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:198 [inlined]
   [30] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [31] iterator_constructors(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:192
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
iterator constructors: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:193
  Test threw exception
  Expression: AT(Fill(T(0), (10,))) == fill(AT{T}, T(0), (10,))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#10#11",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::GPUArrays.var"#10#11", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float64,1,CUDAnative.AS.Global},Float64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float64,1,Nothing},Float64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:46 [inlined]
   [28] fill! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:12 [inlined]
   [29] fill(::Type{CuArray{Float64,N,P} where P where N}, ::Float64, ::Tuple{Int64}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:9
   [30] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:193 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] iterator_constructors(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:192
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
iterator constructors: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:194
  Test threw exception
  Expression: AT(Fill(T(0), (10, 10))) == fill(AT{T}, T(0), (10, 10))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#10#11",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::GPUArrays.var"#10#11", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float64,2,CUDAnative.AS.Global},Float64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float64,2,Nothing},Float64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:46 [inlined]
   [28] fill! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:12 [inlined]
   [29] fill(::Type{CuArray{Float64,N,P} where P where N}, ::Float64, ::Tuple{Int64,Int64}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:9
   [30] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:194 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] iterator_constructors(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:192
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
iterator constructors: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:198
  Test threw exception
  Expression: AT(Eye{T}(10)) == AT{T}(I, 10, 10)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#10#11",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::GPUArrays.var"#10#11", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float64,2,CUDAnative.AS.Global},Float64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float64,2,Nothing},Float64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:46 [inlined]
   [28] fill! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:12 [inlined]
   [29] fill at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:9 [inlined]
   [30] zeros at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:20 [inlined]
   [31] AbstractGPUArray at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:32 [inlined]
   [32] CuArray{Float64,N,P} where P where N(::LinearAlgebra.UniformScaling{Bool}, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:39
   [33] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:198 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] iterator_constructors(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:192
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
iterator constructors: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:193
  Test threw exception
  Expression: AT(Fill(T(0), (10,))) == fill(AT{T}, T(0), (10,))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Bool,1,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},typeof(==),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int32,1,CUDAnative.AS.Global},Tuple{Bool},Tuple{Int64}},Base.Broadcast.Extruded{CuDeviceArray{Int32,1,CUDAnative.AS.Global},Tuple{Bool},Tuple{Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Bool,1,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},typeof(==),Tuple{Base.Broadcast.Extruded{CuArray{Int32,1,Nothing},Tuple{Bool},Tuple{Int64}},Base.Broadcast.Extruded{CuArray{Int32,1,Nothing},Tuple{Bool},Tuple{Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{1},Tuple{Base.OneTo{Int64}},typeof(==),Tuple{CuArray{Int32,1,Nothing},CuArray{Int32,1,Nothing}}}) at ./broadcast.jl:840
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] map at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:91 [inlined]
   [34] #mapreduce#600 at ./reducedim.jl:308 [inlined]
   [35] mapreduce at ./reducedim.jl:308 [inlined]
   [36] ==(::CuArray{Int32,1,Nothing}, ::CuArray{Int32,1,Nothing}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/mapreduce.jl:54
   [37] eval_test(::Expr, ::Expr, ::LineNumberNode, ::Bool) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:246
   [38] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:193 [inlined]
   [39] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [40] iterator_constructors(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:192
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
iterator constructors: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:194
  Test threw exception
  Expression: AT(Fill(T(0), (10, 10))) == fill(AT{T}, T(0), (10, 10))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Bool,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(==),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Int32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Bool,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(==),Tuple{Base.Broadcast.Extruded{CuArray{Int32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Int32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(==),Tuple{CuArray{Int32,2,Nothing},CuArray{Int32,2,Nothing}}}) at ./broadcast.jl:840
   [32] materialize(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(==),Tuple{CuArray{Int32,2,Nothing},CuArray{Int32,2,Nothing}}}) at ./broadcast.jl:820
   [33] map(::Function, ::CuArray{Int32,2,Nothing}, ::CuArray{Int32,2,Nothing}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:91
   [34] mapreduce(::Function, ::Function, ::CuArray{Int32,2,Nothing}, ::Vararg{CuArray{Int32,2,Nothing},N} where N; kw::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at ./reducedim.jl:308
   [35] mapreduce at ./reducedim.jl:308 [inlined]
   [36] ==(::CuArray{Int32,2,Nothing}, ::CuArray{Int32,2,Nothing}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/mapreduce.jl:54
   [37] eval_test(::Expr, ::Expr, ::LineNumberNode, ::Bool) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:246
   [38] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:194 [inlined]
   [39] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [40] iterator_constructors(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:192
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
iterator constructors: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:198
  Test threw exception
  Expression: AT(Eye{T}(10)) == AT{T}(I, 10, 10)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(GPUArrays.uniformscaling_kernel),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(GPUArrays.uniformscaling_kernel), ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int32,2,CUDAnative.AS.Global},Int64,LinearAlgebra.UniformScaling{Bool}}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int32,2,Nothing},Int64,LinearAlgebra.UniformScaling{Bool}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] AbstractGPUArray at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:33 [inlined]
   [28] CuArray{Int32,N,P} where P where N(::LinearAlgebra.UniformScaling{Bool}, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:39
   [29] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:198 [inlined]
   [30] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [31] iterator_constructors(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:192
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
iterator constructors: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:193
  Test threw exception
  Expression: AT(Fill(T(0), (10,))) == fill(AT{T}, T(0), (10,))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#10#11",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::GPUArrays.var"#10#11", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int64,1,CUDAnative.AS.Global},Int64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int64,1,Nothing},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:46 [inlined]
   [28] fill! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:12 [inlined]
   [29] fill(::Type{CuArray{Int64,N,P} where P where N}, ::Int64, ::Tuple{Int64}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:9
   [30] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:193 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] iterator_constructors(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:192
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
iterator constructors: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:194
  Test threw exception
  Expression: AT(Fill(T(0), (10, 10))) == fill(AT{T}, T(0), (10, 10))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#10#11",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::GPUArrays.var"#10#11", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int64,2,CUDAnative.AS.Global},Int64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int64,2,Nothing},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:46 [inlined]
   [28] fill! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:12 [inlined]
   [29] fill(::Type{CuArray{Int64,N,P} where P where N}, ::Int64, ::Tuple{Int64,Int64}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:9
   [30] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:194 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] iterator_constructors(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:192
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
iterator constructors: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:198
  Test threw exception
  Expression: AT(Eye{T}(10)) == AT{T}(I, 10, 10)
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#10#11",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::GPUArrays.var"#10#11", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int64,2,CUDAnative.AS.Global},Int64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int64,2,Nothing},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:46 [inlined]
   [28] fill! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:12 [inlined]
   [29] fill at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:9 [inlined]
   [30] zeros at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:20 [inlined]
   [31] AbstractGPUArray at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:32 [inlined]
   [32] CuArray{Int64,N,P} where P where N(::LinearAlgebra.UniformScaling{Bool}, ::Int64, ::Int64) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:39
   [33] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:198 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] iterator_constructors(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:192
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
iterator constructors: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:193
  Test threw exception
  Expression: AT(Fill(T(0), (10,))) == fill(AT{T}, T(0), (10,))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#10#11",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::GPUArrays.var"#10#11", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Complex{Float32},1,CUDAnative.AS.Global},Complex{Float32}}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Complex{Float32},1,Nothing},Complex{Float32}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:46 [inlined]
   [28] fill! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:12 [inlined]
   [29] fill(::Type{CuArray{Complex{Float32},N,P} where P where N}, ::Complex{Float32}, ::Tuple{Int64}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:9
   [30] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:193 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] iterator_constructors(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:192
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
iterator constructors: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:194
  Test threw exception
  Expression: AT(Fill(T(0), (10, 10))) == fill(AT{T}, T(0), (10, 10))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#10#11",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::GPUArrays.var"#10#11", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Complex{Float32},2,CUDAnative.AS.Global},Complex{Float32}}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Complex{Float32},2,Nothing},Complex{Float32}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:46 [inlined]
   [28] fill! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:12 [inlined]
   [29] fill(::Type{CuArray{Complex{Float32},N,P} where P where N}, ::Complex{Float32}, ::Tuple{Int64,Int64}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:9
   [30] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:194 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] iterator_constructors(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:192
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
iterator constructors: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:193
  Test threw exception
  Expression: AT(Fill(T(0), (10,))) == fill(AT{T}, T(0), (10,))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#10#11",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::GPUArrays.var"#10#11", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Complex{Float64},1,CUDAnative.AS.Global},Complex{Float64}}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Complex{Float64},1,Nothing},Complex{Float64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:46 [inlined]
   [28] fill! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:12 [inlined]
   [29] fill(::Type{CuArray{Complex{Float64},N,P} where P where N}, ::Complex{Float64}, ::Tuple{Int64}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:9
   [30] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:193 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] iterator_constructors(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:192
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
iterator constructors: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:194
  Test threw exception
  Expression: AT(Fill(T(0), (10, 10))) == fill(AT{T}, T(0), (10, 10))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#10#11",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::GPUArrays.var"#10#11", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Complex{Float64},2,CUDAnative.AS.Global},Complex{Float64}}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Complex{Float64},2,Nothing},Complex{Float64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:46 [inlined]
   [28] fill! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:12 [inlined]
   [29] fill(::Type{CuArray{Complex{Float64},N,P} where P where N}, ::Complex{Float64}, ::Tuple{Int64,Int64}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:9
   [30] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:194 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] iterator_constructors(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/construction.jl:192
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
parallel execution interface: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/gpuinterface.jl:2
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int64,1,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int64,1,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:75 [inlined]
   [31] materialize!(::CuArray{Int64,1,Nothing}, ::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{0},Nothing,typeof(identity),Tuple{Int64}}) at ./broadcast.jl:823
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/gpuinterface.jl:5 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] test_gpuinterface(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/gpuinterface.jl:3
   [35] test(::Type{CuArray}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:50
   [36] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [37] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [38] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [39] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [40] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:40
   [41] include(::String) at ./client.jl:441
   [42] top-level scope at none:6
   [43] eval(::Module, ::Any) at ./boot.jl:331
   [44] exec_options(::Base.JLOptions) at ./client.jl:264
   [45] _start() at ./client.jl:490
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
Indexing with Float32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:48
  Test threw exception
  Expression: Array(src[1:3]) == x[1:3]
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(GPUArrays.index_kernel),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(GPUArrays.index_kernel), ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,1,CUDAnative.AS.Global},CuDeviceArray{Float32,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,1,Nothing},CuArray{Float32,1,Nothing},Tuple{Int64},Tuple{UnitRange{Int64}}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:46 [inlined]
   [28] _unsafe_getindex! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:125 [inlined]
   [29] _unsafe_getindex at ./multidimensional.jl:749 [inlined]
   [30] _getindex at ./multidimensional.jl:735 [inlined]
   [31] getindex(::CuArray{Float32,1,Nothing}, ::UnitRange{Int64}) at ./abstractarray.jl:980
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:48 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:43 [inlined]
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:63 [inlined]
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:41 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] test_indexing(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:3
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
Indexing with Float32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:49
  Test threw exception
  Expression: Array(src[3:end]) == x[3:end]
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(GPUArrays.index_kernel),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(GPUArrays.index_kernel), ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,1,CUDAnative.AS.Global},CuDeviceArray{Float32,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,1,Nothing},CuArray{Float32,1,Nothing},Tuple{Int64},Tuple{UnitRange{Int64}}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:46 [inlined]
   [28] _unsafe_getindex! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:125 [inlined]
   [29] _unsafe_getindex at ./multidimensional.jl:749 [inlined]
   [30] _getindex at ./multidimensional.jl:735 [inlined]
   [31] getindex(::CuArray{Float32,1,Nothing}, ::UnitRange{Int64}) at ./abstractarray.jl:980
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:49 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:43 [inlined]
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:63 [inlined]
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:41 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] test_indexing(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:3
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
multi dim, sliced setindex: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:51
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(GPUArrays.setindex_kernel!),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(GPUArrays.setindex_kernel!), ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,4,CUDAnative.AS.Global},CuDeviceArray{Float32,4,CUDAnative.AS.Global},NTuple{4,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},Base.Slice{Base.OneTo{Int64}},Base.Slice{Base.OneTo{Int64}}},Int64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,4,Nothing},CuArray{Float32,4,Nothing},NTuple{4,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},Base.Slice{Base.OneTo{Int64}},Base.Slice{Base.OneTo{Int64}}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:152 [inlined]
   [28] _setindex! at ./multidimensional.jl:777 [inlined]
   [29] setindex!(::CuArray{Float32,4,Nothing}, ::CuArray{Float32,4,Nothing}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::Function, ::Function) at ./abstractarray.jl:1073
   [30] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:55 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:52 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:63 [inlined]
   [34] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:41 [inlined]
   [35] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [36] test_indexing(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:3
   [37] test(::Type{CuArray}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:51
   [38] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [39] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [40] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [41] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [42] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:40
   [43] include(::String) at ./client.jl:441
   [44] top-level scope at none:6
   [45] eval(::Module, ::Any) at ./boot.jl:331
   [46] exec_options(::Base.JLOptions) at ./client.jl:264
   [47] _start() at ./client.jl:490
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
multi dim, sliced setindex, CPU source: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:58
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(GPUArrays.setindex_kernel!),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(GPUArrays.setindex_kernel!), ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,3,CUDAnative.AS.Global},CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{Base.Slice{Base.OneTo{Int64}},Base.Slice{Base.OneTo{Int64}},Int64},Int64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,3,Nothing},CuArray{Float32,2,Nothing},Tuple{Int64,Int64,Int64},Tuple{Base.Slice{Base.OneTo{Int64}},Base.Slice{Base.OneTo{Int64}},Int64},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float32,3,Nothing}, ::Array{Float32,2}, ::Base.Slice{Base.OneTo{Int64}}, ::Vararg{Union{Real, AbstractArray},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:152
   [28] _setindex! at ./multidimensional.jl:777 [inlined]
   [29] setindex!(::CuArray{Float32,3,Nothing}, ::Array{Float32,2}, ::Function, ::Function, ::Int64) at ./abstractarray.jl:1073
   [30] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:62 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:59 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:63 [inlined]
   [34] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:41 [inlined]
   [35] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [36] test_indexing(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:3
   [37] test(::Type{CuArray}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:51
   [38] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [39] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [40] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [41] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [42] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:40
   [43] include(::String) at ./client.jl:441
   [44] top-level scope at none:6
   [45] eval(::Module, ::Any) at ./boot.jl:331
   [46] exec_options(::Base.JLOptions) at ./client.jl:264
   [47] _start() at ./client.jl:490
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
Indexing with Int32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:48
  Test threw exception
  Expression: Array(src[1:3]) == x[1:3]
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(GPUArrays.index_kernel),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(GPUArrays.index_kernel), ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int32,1,CUDAnative.AS.Global},CuDeviceArray{Int32,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int32,1,Nothing},CuArray{Int32,1,Nothing},Tuple{Int64},Tuple{UnitRange{Int64}}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:46 [inlined]
   [28] _unsafe_getindex! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:125 [inlined]
   [29] _unsafe_getindex at ./multidimensional.jl:749 [inlined]
   [30] _getindex at ./multidimensional.jl:735 [inlined]
   [31] getindex(::CuArray{Int32,1,Nothing}, ::UnitRange{Int64}) at ./abstractarray.jl:980
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:48 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:43 [inlined]
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:63 [inlined]
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:41 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] test_indexing(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:3
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
Indexing with Int32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:49
  Test threw exception
  Expression: Array(src[3:end]) == x[3:end]
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(GPUArrays.index_kernel),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(GPUArrays.index_kernel), ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int32,1,CUDAnative.AS.Global},CuDeviceArray{Int32,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int32,1,Nothing},CuArray{Int32,1,Nothing},Tuple{Int64},Tuple{UnitRange{Int64}}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:46 [inlined]
   [28] _unsafe_getindex! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:125 [inlined]
   [29] _unsafe_getindex at ./multidimensional.jl:749 [inlined]
   [30] _getindex at ./multidimensional.jl:735 [inlined]
   [31] getindex(::CuArray{Int32,1,Nothing}, ::UnitRange{Int64}) at ./abstractarray.jl:980
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:49 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:43 [inlined]
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:63 [inlined]
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:41 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] test_indexing(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:3
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
multi dim, sliced setindex: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:51
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#51#52"{Int32},DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::GPUArrays.var"#51#52"{Int32}, ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int32,4,CUDAnative.AS.Global},CuDeviceArray{NTuple{4,UInt32},1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int32,4,Nothing},CuArray{NTuple{4,UInt32},1,Nothing}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] gpu_call(::Function, ::CuArray{Int32,4,Nothing}, ::Vararg{Any,N} where N; target::CuArray{Int32,4,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60
   [27] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:46 [inlined]
   [28] rand! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/random.jl:94 [inlined]
   [29] rand!(::CuArray{Int32,4,Nothing}) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/rand/random.jl:188
   [30] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:54 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:52 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:63 [inlined]
   [34] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:41 [inlined]
   [35] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [36] test_indexing(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:3
   [37] test(::Type{CuArray}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:51
   [38] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [39] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [40] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [41] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [42] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:40
   [43] include(::String) at ./client.jl:441
   [44] top-level scope at none:6
   [45] eval(::Module, ::Any) at ./boot.jl:331
   [46] exec_options(::Base.JLOptions) at ./client.jl:264
   [47] _start() at ./client.jl:490
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
multi dim, sliced setindex, CPU source: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:58
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(GPUArrays.setindex_kernel!),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(GPUArrays.setindex_kernel!), ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int32,3,CUDAnative.AS.Global},CuDeviceArray{Int32,2,CUDAnative.AS.Global},Tuple{Int64,Int64,Int64},Tuple{Base.Slice{Base.OneTo{Int64}},Base.Slice{Base.OneTo{Int64}},Int64},Int64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int32,3,Nothing},CuArray{Int32,2,Nothing},Tuple{Int64,Int64,Int64},Tuple{Base.Slice{Base.OneTo{Int64}},Base.Slice{Base.OneTo{Int64}},Int64},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Int32,3,Nothing}, ::Array{Int32,2}, ::Base.Slice{Base.OneTo{Int64}}, ::Vararg{Union{Real, AbstractArray},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:152
   [28] _setindex! at ./multidimensional.jl:777 [inlined]
   [29] setindex!(::CuArray{Int32,3,Nothing}, ::Array{Int32,2}, ::Function, ::Function, ::Int64) at ./abstractarray.jl:1073
   [30] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:62 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:59 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:63 [inlined]
   [34] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:41 [inlined]
   [35] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [36] test_indexing(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:3
   [37] test(::Type{CuArray}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:51
   [38] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [39] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [40] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [41] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [42] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:40
   [43] include(::String) at ./client.jl:441
   [44] top-level scope at none:6
   [45] eval(::Module, ::Any) at ./boot.jl:331
   [46] exec_options(::Base.JLOptions) at ./client.jl:264
   [47] _start() at ./client.jl:490
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
Indexing with Float32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:68
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(GPUArrays.setindex_kernel!),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(GPUArrays.setindex_kernel!), ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,1,CUDAnative.AS.Global},CuDeviceArray{Float32,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,1,Nothing},CuArray{Float32,1,Nothing},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:152 [inlined]
   [28] _setindex! at ./multidimensional.jl:777 [inlined]
   [29] setindex!(::CuArray{Float32,1,Nothing}, ::Array{Float32,1}, ::UnitRange{Int64}) at ./abstractarray.jl:1073
   [30] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:75 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:69 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:63 [inlined]
   [34] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:67 [inlined]
   [35] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [36] test_indexing(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:3
   [37] test(::Type{CuArray}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:51
   [38] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [39] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [40] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [41] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [42] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:40
   [43] include(::String) at ./client.jl:441
   [44] top-level scope at none:6
   [45] eval(::Module, ::Any) at ./boot.jl:331
   [46] exec_options(::Base.JLOptions) at ./client.jl:264
   [47] _start() at ./client.jl:490
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
Indexing with Int32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:68
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(GPUArrays.setindex_kernel!),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(GPUArrays.setindex_kernel!), ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int32,1,CUDAnative.AS.Global},CuDeviceArray{Int32,1,CUDAnative.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int32,1,Nothing},CuArray{Int32,1,Nothing},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:152 [inlined]
   [28] _setindex! at ./multidimensional.jl:777 [inlined]
   [29] setindex!(::CuArray{Int32,1,Nothing}, ::Array{Int32,1}, ::UnitRange{Int64}) at ./abstractarray.jl:1073
   [30] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:75 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:69 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:63 [inlined]
   [34] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:67 [inlined]
   [35] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [36] test_indexing(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:3
   [37] test(::Type{CuArray}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:51
   [38] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [39] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [40] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [41] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [42] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:40
   [43] include(::String) at ./client.jl:441
   [44] top-level scope at none:6
   [45] eval(::Module, ::Any) at ./boot.jl:331
   [46] exec_options(::Base.JLOptions) at ./client.jl:264
   [47] _start() at ./client.jl:490
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
Colon() Float32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:93
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(GPUArrays.setindex_kernel!),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(GPUArrays.setindex_kernel!), ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,1,CUDAnative.AS.Global},Float32,Tuple{Int64},Tuple{Base.Slice{Base.OneTo{Int64}}},Int64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,1,Nothing},Float32,Tuple{Int64},Tuple{Base.Slice{Base.OneTo{Int64}}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:152 [inlined]
   [28] _setindex! at ./multidimensional.jl:777 [inlined]
   [29] setindex!(::CuArray{Float32,1,Nothing}, ::Float32, ::Function) at ./abstractarray.jl:1073
   [30] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:96 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:94 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:63 [inlined]
   [34] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:92 [inlined]
   [35] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [36] test_indexing(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:3
   [37] test(::Type{CuArray}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:51
   [38] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [39] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [40] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [41] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [42] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:40
   [43] include(::String) at ./client.jl:441
   [44] top-level scope at none:6
   [45] eval(::Module, ::Any) at ./boot.jl:331
   [46] exec_options(::Base.JLOptions) at ./client.jl:264
   [47] _start() at ./client.jl:490
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
Colon() Int32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:93
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(GPUArrays.setindex_kernel!),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(GPUArrays.setindex_kernel!), ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int32,1,CUDAnative.AS.Global},Int32,Tuple{Int64},Tuple{Base.Slice{Base.OneTo{Int64}}},Int64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int32,1,Nothing},Int32,Tuple{Int64},Tuple{Base.Slice{Base.OneTo{Int64}}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:152 [inlined]
   [28] _setindex! at ./multidimensional.jl:777 [inlined]
   [29] setindex!(::CuArray{Int32,1,Nothing}, ::Int32, ::Function) at ./abstractarray.jl:1073
   [30] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:96 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:94 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:63 [inlined]
   [34] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:92 [inlined]
   [35] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [36] test_indexing(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/indexing.jl:3
   [37] test(::Type{CuArray}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:51
   [38] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [39] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [40] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [41] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [42] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:40
   [43] include(::String) at ./client.jl:441
   [44] top-level scope at none:6
   [45] eval(::Module, ::Any) at ./boot.jl:331
   [46] exec_options(::Base.JLOptions) at ./client.jl:264
   [47] _start() at ./client.jl:490
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
copyto!: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:30
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(GPUArrays.copy_kernel!),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(GPUArrays.copy_kernel!), ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},CartesianIndex{2},CuDeviceArray{Float32,2,CUDAnative.AS.Global},CartesianIndex{2},Tuple{Int64,Int64},Int64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},CartesianIndex{2},CuArray{Float32,2,Nothing},CartesianIndex{2},Tuple{Int64,Int64},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] copyto!(::CuArray{Float32,2,Nothing}, ::CartesianIndices{2,Tuple{UnitRange{Int64},UnitRange{Int64}}}, ::CuArray{Float32,2,Nothing}, ::CartesianIndices{2,Tuple{UnitRange{Int64},UnitRange{Int64}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/abstractarray.jl:142
   [28] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:38 [inlined]
   [29] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [30] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:31 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] test_base(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:30
   [33] test(::Type{CuArray}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:53
   [34] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [35] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [36] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [37] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [38] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:40
   [39] include(::String) at ./client.jl:441
   [40] top-level scope at none:6
   [41] eval(::Module, ::Any) at ./boot.jl:331
   [42] exec_options(::Base.JLOptions) at ./client.jl:264
   [43] _start() at ./client.jl:490
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
vcat + hcat: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:83
  Test threw exception
  Expression: compare(vcat, AT, fill(0.0f0, (10, 10)), rand(Float32, 20, 10))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(GPUArrays.setindex_kernel!),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(GPUArrays.setindex_kernel!), ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},Base.Slice{Base.OneTo{Int64}}},Int64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},CuArray{Float32,2,Nothing},Tuple{Int64,Int64},Tuple{UnitRange{Int64},Base.Slice{Base.OneTo{Int64}}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:152 [inlined]
   [28] _setindex! at ./multidimensional.jl:777 [inlined]
   [29] setindex! at ./abstractarray.jl:1073 [inlined]
   [30] _typed_vcat(::Type{Float32}, ::Tuple{CuArray{Float32,2,Nothing},CuArray{Float32,2,Nothing}}) at ./abstractarray.jl:1366
   [31] typed_vcat at ./abstractarray.jl:1372 [inlined]
   [32] vcat(::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}) at ./abstractarray.jl:1350
   [33] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:83 [inlined]
   [36] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [37] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:83 [inlined]
   [38] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [39] test_base(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:30
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
vcat + hcat: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:84
  Test threw exception
  Expression: compare(hcat, AT, fill(0.0f0, (10, 10)), rand(Float32, 10, 10))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(GPUArrays.setindex_kernel!),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(GPUArrays.setindex_kernel!), ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{Base.Slice{Base.OneTo{Int64}},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},CuArray{Float32,2,Nothing},Tuple{Int64,Int64},Tuple{Base.Slice{Base.OneTo{Int64}},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:152 [inlined]
   [28] _setindex! at ./multidimensional.jl:777 [inlined]
   [29] setindex! at ./abstractarray.jl:1073 [inlined]
   [30] _typed_hcat(::Type{Float32}, ::Tuple{CuArray{Float32,2,Nothing},CuArray{Float32,2,Nothing}}) at ./abstractarray.jl:1342
   [31] typed_hcat at ./abstractarray.jl:1310 [inlined]
   [32] hcat(::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}) at ./abstractarray.jl:1313
   [33] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:84 [inlined]
   [36] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [37] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:83 [inlined]
   [38] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [39] test_base(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:30
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
vcat + hcat: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:86
  Test threw exception
  Expression: compare(hcat, AT, rand(Float32, 3, 3), rand(Float32, 3, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(GPUArrays.setindex_kernel!),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(GPUArrays.setindex_kernel!), ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{Base.Slice{Base.OneTo{Int64}},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},CuArray{Float32,2,Nothing},Tuple{Int64,Int64},Tuple{Base.Slice{Base.OneTo{Int64}},UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:152 [inlined]
   [28] _setindex! at ./multidimensional.jl:777 [inlined]
   [29] setindex! at ./abstractarray.jl:1073 [inlined]
   [30] _typed_hcat(::Type{Float32}, ::Tuple{CuArray{Float32,2,Nothing},CuArray{Float32,2,Nothing}}) at ./abstractarray.jl:1342
   [31] typed_hcat at ./abstractarray.jl:1310 [inlined]
   [32] hcat(::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}) at ./abstractarray.jl:1313
   [33] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:86 [inlined]
   [36] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [37] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:83 [inlined]
   [38] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [39] test_base(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:30
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
vcat + hcat: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:87
  Test threw exception
  Expression: compare(vcat, AT, rand(Float32, 3, 3), rand(Float32, 3, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(GPUArrays.setindex_kernel!),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(GPUArrays.setindex_kernel!), ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},Base.Slice{Base.OneTo{Int64}}},Int64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},CuArray{Float32,2,Nothing},Tuple{Int64,Int64},Tuple{UnitRange{Int64},Base.Slice{Base.OneTo{Int64}}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] _unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:152 [inlined]
   [28] _setindex! at ./multidimensional.jl:777 [inlined]
   [29] setindex! at ./abstractarray.jl:1073 [inlined]
   [30] _typed_vcat(::Type{Float32}, ::Tuple{CuArray{Float32,2,Nothing},CuArray{Float32,2,Nothing}}) at ./abstractarray.jl:1366
   [31] typed_vcat at ./abstractarray.jl:1372 [inlined]
   [32] vcat(::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}) at ./abstractarray.jl:1350
   [33] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:87 [inlined]
   [36] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [37] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:83 [inlined]
   [38] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [39] test_base(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:30
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
vcat + hcat: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:88
  Test threw exception
  Expression: compare(((a, b)->begin
            cat(a, b; dims = 4)
        end), AT, rand(Float32, 3, 4), rand(Float32, 3, 4))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(GPUArrays.setindex_kernel!),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(GPUArrays.setindex_kernel!), ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,4,CUDAnative.AS.Global},CuDeviceArray{Float32,2,CUDAnative.AS.Global},NTuple{4,Int64},NTuple{4,UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,4,Nothing},CuArray{Float32,2,Nothing},NTuple{4,Int64},NTuple{4,UnitRange{Int64}},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float32,4,Nothing}, ::CuArray{Float32,2,Nothing}, ::UnitRange{Int64}, ::Vararg{UnitRange{Int64},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/indexing.jl:152
   [28] _setindex! at ./multidimensional.jl:777 [inlined]
   [29] setindex! at ./abstractarray.jl:1073 [inlined]
   [30] __cat(::CuArray{Float32,4,Nothing}, ::NTuple{4,Int64}, ::NTuple{4,Bool}, ::CuArray{Float32,2,Nothing}, ::Vararg{CuArray{Float32,2,Nothing},N} where N) at ./abstractarray.jl:1463
   [31] _cat_t(::Int64, ::Type{T} where T, ::CuArray{Float32,2,Nothing}, ::Vararg{CuArray{Float32,2,Nothing},N} where N) at ./abstractarray.jl:1445
   [32] cat_t(::Type{Float32}, ::CuArray{Float32,2,Nothing}, ::Vararg{CuArray{Float32,2,Nothing},N} where N; dims::Int64) at ./abstractarray.jl:1437
   [33] _cat at ./abstractarray.jl:1574 [inlined]
   [34] #cat#110 at ./abstractarray.jl:1573 [inlined]
   [35] (::Main.TestSuite.var"#38#48")(::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}) at ./none:0
   [36] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [37] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [38] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:88 [inlined]
   [39] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [40] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:83 [inlined]
   [41] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [42] test_base(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:30
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
ntuple test: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:117
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(Main.TestSuite.ntuple_test),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(Main.TestSuite.ntuple_test), ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Tuple{Float32,Float32,Float32},1,CUDAnative.AS.Global},Val{3}}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Tuple{Float32,Float32,Float32},1,Nothing},Val{3}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] gpu_call(::Function, ::CuArray{Tuple{Float32,Float32,Float32},1,Nothing}, ::Val{3}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:46
   [28] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:119 [inlined]
   [29] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [30] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:118 [inlined]
   [31] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [32] test_base(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:30
   [33] test(::Type{CuArray}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:53
   [34] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [35] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [36] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [37] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [38] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:40
   [39] include(::String) at ./client.jl:441
   [40] top-level scope at none:6
   [41] eval(::Module, ::Any) at ./boot.jl:331
   [42] exec_options(::Base.JLOptions) at ./client.jl:264
   [43] _start() at ./client.jl:490
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
cartesian iteration: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:126
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto!(::CuArray{Float32,2,Nothing}, ::Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{CuArray{Float32,2,Nothing}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63
   [30] copyto!(::CuArray{Float32,2,Nothing}, ::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{CuArray{Float32,2,Nothing}}}) at ./broadcast.jl:864
   [31] copy(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{CuArray{Float32,2,Nothing}}}) at ./broadcast.jl:840
   [32] materialize(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(identity),Tuple{CuArray{Float32,2,Nothing}}}) at ./broadcast.jl:820
   [33] copy(::CuArray{Float32,2,Nothing}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/abstractarray.jl:173
   [34] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:129 [inlined]
   [35] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:127 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] test_base(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:30
   [39] test(::Type{CuArray}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:53
   [40] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [41] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [42] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [43] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [44] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:40
   [45] include(::String) at ./client.jl:441
   [46] top-level scope at none:6
   [47] eval(::Module, ::Any) at ./boot.jl:331
   [48] exec_options(::Base.JLOptions) at ./client.jl:264
   [49] _start() at ./client.jl:490
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
Custom kernel from Julia function: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:134
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(Main.TestSuite.clmap!),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(Main.TestSuite.clmap!), ::Type{Tuple{CuArrays.CuKernelContext,typeof(-),CuDeviceArray{Float32,1,CUDAnative.AS.Global},CuDeviceArray{Float32,1,CUDAnative.AS.Global}}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{typeof(-),CuArray{Float32,1,Nothing},CuArray{Float32,1,Nothing}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] gpu_call(::Function, ::Function, ::Vararg{Any,N} where N; target::CuArray{Float32,1,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60
   [27] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:137 [inlined]
   [28] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [29] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:135 [inlined]
   [30] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [31] test_base(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:30
   [32] test(::Type{CuArray}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:53
   [33] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [34] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [35] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [36] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   [37] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:40
   [38] include(::String) at ./client.jl:441
   [39] top-level scope at none:6
   [40] eval(::Module, ::Any) at ./boot.jl:331
   [41] exec_options(::Base.JLOptions) at ./client.jl:264
   [42] _start() at ./client.jl:490
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
map: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:143
  Test threw exception
  Expression: compare(((a, b)->begin
            map(+, a, b)
        end), AT, rand(Float32, 10), rand(Float32, 10))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,1,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float32,1,CUDAnative.AS.Global},Tuple{Bool},Tuple{Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float32,1,CUDAnative.AS.Global},Tuple{Bool},Tuple{Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,1,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Float32,1,Nothing},Tuple{Bool},Tuple{Int64}},Base.Broadcast.Extruded{CuArray{Float32,1,Nothing},Tuple{Bool},Tuple{Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{1},Tuple{Base.OneTo{Int64}},typeof(+),Tuple{CuArray{Float32,1,Nothing},CuArray{Float32,1,Nothing}}}) at ./broadcast.jl:840
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] map at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:91 [inlined]
   [34] (::Main.TestSuite.var"#39#49")(::CuArray{Float32,1,Nothing}, ::CuArray{Float32,1,Nothing}) at ./none:0
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float32,1}, ::Vararg{Array{Float32,1},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [36] compare(::Function, ::Type{CuArray}, ::Array{Float32,1}, ::Vararg{Array{Float32,1},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [37] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:143 [inlined]
   [38] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [39] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:143 [inlined]
   [40] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [41] test_base(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:30
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
map: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:144
  Test threw exception
  Expression: compare(((a, b)->begin
            map!(-, a, b)
        end), AT, rand(Float32, 10), rand(Float32, 10))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,1,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},typeof(-),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float32,1,CUDAnative.AS.Global},Tuple{Bool},Tuple{Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,1,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},typeof(-),Tuple{Base.Broadcast.Extruded{CuArray{Float32,1,Nothing},Tuple{Bool},Tuple{Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize! at ./broadcast.jl:823 [inlined]
   [32] map! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:86 [inlined]
   [33] (::Main.TestSuite.var"#40#50")(::CuArray{Float32,1,Nothing}, ::CuArray{Float32,1,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float32,1}, ::Vararg{Array{Float32,1},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float32,1}, ::Vararg{Array{Float32,1},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:144 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:143 [inlined]
   [39] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [40] test_base(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:30
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
map: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:145
  Test threw exception
  Expression: compare(((a, b, c, d)->begin
            map!(*, a, b, c, d)
        end), AT, rand(Float32, 10), rand(Float32, 10), rand(Float32, 10), rand(Float32, 10))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,1,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},typeof(*),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float32,1,CUDAnative.AS.Global},Tuple{Bool},Tuple{Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float32,1,CUDAnative.AS.Global},Tuple{Bool},Tuple{Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float32,1,CUDAnative.AS.Global},Tuple{Bool},Tuple{Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,1,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},typeof(*),Tuple{Base.Broadcast.Extruded{CuArray{Float32,1,Nothing},Tuple{Bool},Tuple{Int64}},Base.Broadcast.Extruded{CuArray{Float32,1,Nothing},Tuple{Bool},Tuple{Int64}},Base.Broadcast.Extruded{CuArray{Float32,1,Nothing},Tuple{Bool},Tuple{Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize!(::CuArray{Float32,1,Nothing}, ::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{1},Nothing,typeof(*),Tuple{CuArray{Float32,1,Nothing},CuArray{Float32,1,Nothing},CuArray{Float32,1,Nothing}}}) at ./broadcast.jl:823
   [32] map!(::Function, ::CuArray{Float32,1,Nothing}, ::CuArray{Float32,1,Nothing}, ::CuArray{Float32,1,Nothing}, ::CuArray{Float32,1,Nothing}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:86
   [33] (::Main.TestSuite.var"#41#51")(::CuArray{Float32,1,Nothing}, ::CuArray{Float32,1,Nothing}, ::CuArray{Float32,1,Nothing}, ::CuArray{Float32,1,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float32,1}, ::Vararg{Array{Float32,1},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float32,1}, ::Vararg{Array{Float32,1},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:145 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:143 [inlined]
   [39] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [40] test_base(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:30
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
repeat: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:149
  Test threw exception
  Expression: compare((a->begin
            repeat(a, 5, 6)
        end), AT, rand(Float32, 10))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#12#13",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::GPUArrays.var"#12#13", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},CuDeviceArray{Float32,1,CUDAnative.AS.Global},Int64,Int64,Int64,Int64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},CuArray{Float32,1,Nothing},Int64,Int64,Int64,Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] repeat at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/base.jl:6 [inlined]
   [28] (::Main.TestSuite.var"#42#52")(::CuArray{Float32,1,Nothing}) at ./none:0
   [29] compare(::Function, ::Type{CuArray}, ::Array{Float32,1}, ::Vararg{Array{Float32,1},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [30] compare(::Function, ::Type{CuArray}, ::Array{Float32,1}, ::Vararg{Array{Float32,1},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [31] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:149 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:149 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] test_base(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:30
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
repeat: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:150
  Test threw exception
  Expression: compare((a->begin
            repeat(a, 5)
        end), AT, rand(Float32, 10))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#14#15",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::GPUArrays.var"#14#15", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,1,CUDAnative.AS.Global},CuDeviceArray{Float32,1,CUDAnative.AS.Global},Int64,Int64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,1,Nothing},CuArray{Float32,1,Nothing},Int64,Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] repeat at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/base.jl:26 [inlined]
   [28] (::Main.TestSuite.var"#43#53")(::CuArray{Float32,1,Nothing}) at ./none:0
   [29] compare(::Function, ::Type{CuArray}, ::Array{Float32,1}, ::Vararg{Array{Float32,1},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [30] compare(::Function, ::Type{CuArray}, ::Array{Float32,1}, ::Vararg{Array{Float32,1},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [31] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:150 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:149 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] test_base(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:30
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
repeat: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:151
  Test threw exception
  Expression: compare((a->begin
            repeat(a, 5)
        end), AT, rand(Float32, 5, 4))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#12#13",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::GPUArrays.var"#12#13", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},CuDeviceArray{Float32,2,CUDAnative.AS.Global},Int64,Int64,Int64,Int64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},CuArray{Float32,2,Nothing},Int64,Int64,Int64,Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] repeat at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/base.jl:6 [inlined]
   [28] repeat at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/base.jl:4 [inlined]
   [29] (::Main.TestSuite.var"#44#54")(::CuArray{Float32,2,Nothing}) at ./none:0
   [30] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [31] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:151 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:149 [inlined]
   [35] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [36] test_base(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:30
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
repeat: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:152
  Test threw exception
  Expression: compare((a->begin
            repeat(a, 4, 3)
        end), AT, rand(Float32, 10, 15))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#12#13",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::GPUArrays.var"#12#13", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},CuDeviceArray{Float32,2,CUDAnative.AS.Global},Int64,Int64,Int64,Int64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},CuArray{Float32,2,Nothing},Int64,Int64,Int64,Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] repeat at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/base.jl:6 [inlined]
   [28] (::Main.TestSuite.var"#45#55")(::CuArray{Float32,2,Nothing}) at ./none:0
   [29] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [30] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [31] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:152 [inlined]
   [32] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [33] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:149 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] test_base(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:30
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
permutedims: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:156
  Test threw exception
  Expression: compare((x->begin
            permutedims(x, [1, 2])
        end), AT, rand(4, 4))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#45#46",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::GPUArrays.var"#45#46", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float64,2,CUDAnative.AS.Global},CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float64,2,Nothing},CuArray{Float64,2,Nothing},Tuple{Int64,Int64}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] gpu_call(::Function, ::CuArray{Float64,2,Nothing}, ::Vararg{Any,N} where N; target::CuArray{Float64,2,Nothing}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60
   [27] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:46 [inlined]
   [28] permutedims!(::CuArray{Float64,2,Nothing}, ::CuArray{Float64,2,Nothing}, ::Array{Int64,1}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/linalg.jl:163
   [29] permutedims(::CuArray{Float64,2,Nothing}, ::Array{Int64,1}) at ./multidimensional.jl:1417
   [30] (::Main.TestSuite.var"#46#56")(::CuArray{Float64,2,Nothing}) at ./none:0
   [31] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [32] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [33] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:156 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:156 [inlined]
   [36] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [37] test_base(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:30
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
permutedims: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:159
  Test threw exception
  Expression: compare((x->begin
            permutedims(view(x, inds, :), (3, 2, 1))
        end), AT, rand(100, 100))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,PermutedDimsArray{Float64,3,(3, 2, 1),(3, 2, 1),CuDeviceArray{Float64,3,CUDAnative.AS.Global}},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Base.Broadcast.Extruded{SubArray{Float64,3,CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{CuDeviceArray{Int64,2,CUDAnative.AS.Global},Base.Slice{Base.OneTo{Int64}}},false},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{PermutedDimsArray{Float64,3,(3, 2, 1),(3, 2, 1),CuArray{Float64,3,Nothing}},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Base.Broadcast.Extruded{SubArray{Float64,3,CuArray{Float64,2,Nothing},Tuple{Array{Int64,2},Base.Slice{Base.OneTo{Int64}}},false},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize! at ./broadcast.jl:823 [inlined]
   [32] _copy!(::PermutedDimsArray{Float64,3,(3, 2, 1),(3, 2, 1),CuArray{Float64,3,Nothing}}, ::SubArray{Float64,3,CuArray{Float64,2,Nothing},Tuple{Array{Int64,2},Base.Slice{Base.OneTo{Int64}}},false}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/base.jl:44
   [33] permutedims!(::CuArray{Float64,3,Nothing}, ::SubArray{Float64,3,CuArray{Float64,2,Nothing},Tuple{Array{Int64,2},Base.Slice{Base.OneTo{Int64}}},false}, ::Tuple{Int64,Int64,Int64}) at ./permuteddimsarray.jl:194
   [34] permutedims at ./permuteddimsarray.jl:113 [inlined]
   [35] (::Main.TestSuite.var"#47#57"{Array{Int64,2}})(::CuArray{Float64,2,Nothing}) at ./none:0
   [36] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [37] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [38] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:159 [inlined]
   [39] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [40] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:156 [inlined]
   [41] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [42] test_base(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/base.jl:30
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
mapreducedim! Float32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/mapreduce.jl:7
  Test threw exception
  Expression: compare(((A, R)->begin
            Base.mapreducedim!(identity, +, R, A)
        end), AT, rand(range, sz), zeros(ET, red))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CuArrays.mapreduce_grid),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(CuArrays.mapreduce_grid), ::Type{Tuple{typeof(identity),typeof(+),CuDeviceArray{Float32,1,CUDAnative.AS.Global},CuDeviceArray{Float32,1,CUDAnative.AS.Global},Nothing,CartesianIndices{1,Tuple{Base.OneTo{Int64}}},CartesianIndices{1,Tuple{Base.OneTo{Int64}}},Val{true}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [25] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [26] macro expansion at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/mapreduce.jl:161 [inlined]
   [27] mapreducedim!(::Function, ::Function, ::CuArray{Float32,1,Nothing}, ::CuArray{Float32,1,Nothing}, ::Nothing) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/nvtx/highlevel.jl:85
   [28] mapreducedim! at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/nvtx/highlevel.jl:83 [inlined]
   [29] mapreducedim! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/mapreduce.jl:6 [inlined]
   [30] (::Main.TestSuite.var"#58#106")(::CuArray{Float32,1,Nothing}, ::CuArray{Float32,1,Nothing}) at ./none:0
   [31] compare(::Function, ::Type{CuArray}, ::Array{Float32,1}, ::Vararg{Array{Float32,1},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [32] compare(::Function, ::Type{CuArray}, ::Array{Float32,1}, ::Vararg{Array{Float32,1},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [33] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/mapreduce.jl:7 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188 [inlined]
   [35] test_mapreduce(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/mapreduce.jl:2
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
mapreducedim! Float32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/mapreduce.jl:8
  Test threw exception
  Expression: compare(((A, R)->begin
            Base.mapreducedim!(identity, *, R, A)
        end), AT, rand(range, sz), ones(ET, red))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CuArrays.mapreduce_grid),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(CuArrays.mapreduce_grid), ::Type{Tuple{typeof(identity),typeof(*),CuDeviceArray{Float32,1,CUDAnative.AS.Global},CuDeviceArray{Float32,1,CUDAnative.AS.Global},Nothing,CartesianIndices{1,Tuple{Base.OneTo{Int64}}},CartesianIndices{1,Tuple{Base.OneTo{Int64}}},Val{true}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [25] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [26] macro expansion at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/mapreduce.jl:161 [inlined]
   [27] mapreducedim!(::Function, ::Function, ::CuArray{Float32,1,Nothing}, ::CuArray{Float32,1,Nothing}, ::Nothing) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/nvtx/highlevel.jl:85
   [28] mapreducedim! at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/nvtx/highlevel.jl:83 [inlined]
   [29] mapreducedim! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/mapreduce.jl:6 [inlined]
   [30] (::Main.TestSuite.var"#59#107")(::CuArray{Float32,1,Nothing}, ::CuArray{Float32,1,Nothing}) at ./none:0
   [31] compare(::Function, ::Type{CuArray}, ::Array{Float32,1}, ::Vararg{Array{Float32,1},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [32] compare(::Function, ::Type{CuArray}, ::Array{Float32,1}, ::Vararg{Array{Float32,1},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [33] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/mapreduce.jl:8 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188 [inlined]
   [35] test_mapreduce(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/mapreduce.jl:2
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
mapreducedim! Float32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/mapreduce.jl:9
  Test threw exception
  Expression: compare(((A, R)->begin
            Base.mapreducedim!((x->begin
                        x + x
                    end), +, R, A)
        end), AT, rand(range, sz), zeros(ET, red))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},typeof(CuArrays.mapreduce_grid),DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::typeof(CuArrays.mapreduce_grid), ::Type{Tuple{Main.TestSuite.var"#61#109",typeof(+),CuDeviceArray{Float32,1,CUDAnative.AS.Global},CuDeviceArray{Float32,1,CUDAnative.AS.Global},Nothing,CartesianIndices{1,Tuple{Base.OneTo{Int64}}},CartesianIndices{1,Tuple{Base.OneTo{Int64}}},Val{true}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] cufunction(::Function, ::Type{T} where T) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [25] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [26] macro expansion at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/mapreduce.jl:161 [inlined]
   [27] mapreducedim!(::Function, ::Function, ::CuArray{Float32,1,Nothing}, ::CuArray{Float32,1,Nothing}, ::Nothing) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/nvtx/highlevel.jl:85
   [28] mapreducedim! at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/nvtx/highlevel.jl:83 [inlined]
   [29] mapreducedim! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/mapreduce.jl:6 [inlined]
   [30] (::Main.TestSuite.var"#60#108")(::CuArray{Float32,1,Nothing}, ::CuArray{Float32,1,Nothing}) at ./none:0
   [31] compare(::Function, ::Type{CuArray}, ::Array{Float32,1}, ::Vararg{Array{Float32,1},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [32] compare(::Function, ::Type{CuArray}, ::Array{Float32,1}, ::Vararg{Array{Float32,1},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [33] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/mapreduce.jl:9 [inlined]
   [34] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1188 [inlined]
   [35] test_mapreduce(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/mapreduce.jl:2
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
RefValue: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,1,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},typeof(Main.TestSuite.test_idx),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int64,1,CUDAnative.AS.Global},Tuple{Bool},Tuple{Int64}},CUDAnative.CuRefValue{CuDeviceArray{Float32,1,CUDAnative.AS.Global}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,1,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},typeof(Main.TestSuite.test_idx),Tuple{Base.Broadcast.Extruded{CuArray{Int64,1,Nothing},Tuple{Bool},Tuple{Int64}},Base.RefValue{CuArray{Float32,1,Nothing}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize!(::CuArray{Float32,1,Nothing}, ::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{1},Nothing,typeof(Main.TestSuite.test_idx),Tuple{CuArray{Int64,1,Nothing},Base.RefValue{CuArray{Float32,1,Nothing}}}}) at ./broadcast.jl:823
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:43 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:37 [inlined]
   [35] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [36] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
   [37] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:3 [inlined]
   [38] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [39] test_broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:3
   [40] test(::Type{CuArray}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:55
   [41] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [42] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   ... (the last 2 lines are repeated 1 more time)
   [45] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:40
   [46] include(::String) at ./client.jl:441
   [47] top-level scope at none:6
   [48] eval(::Module, ::Any) at ./boot.jl:331
   [49] exec_options(::Base.JLOptions) at ./client.jl:264
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
Tuple: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:49
  Test threw exception
  Expression: compare(AT, rand(ET, 3, N), rand(ET, 3, N), rand(ET, N), rand(ET, N), rand(ET, N)) do out, arr, a, b, c
    broadcast!(out, arr, (a, b, c)) do xx, yy
        xx + first(yy)
    end
end
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},Main.TestSuite.var"#156#178",Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Tuple{CuDeviceArray{Float32,1,CUDAnative.AS.Global},CuDeviceArray{Float32,1,CUDAnative.AS.Global},CuDeviceArray{Float32,1,CUDAnative.AS.Global}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},Main.TestSuite.var"#156#178",Tuple{Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Tuple{CuArray{Float32,1,Nothing},CuArray{Float32,1,Nothing},CuArray{Float32,1,Nothing}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize! at ./broadcast.jl:823 [inlined]
   [32] broadcast! at ./broadcast.jl:797 [inlined]
   [33] (::Main.TestSuite.var"#155#177")(::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}, ::CuArray{Float32,1,Nothing}, ::CuArray{Float32,1,Nothing}, ::CuArray{Float32,1,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:49 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:49 [inlined]
   [39] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [40] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
Adjoint and Transpose: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:56
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,LinearAlgebra.Adjoint{Float32,CuDeviceArray{Float32,1,CUDAnative.AS.Global}},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Float32}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{LinearAlgebra.Adjoint{Float32,CuArray{Float32,1,Nothing}},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Float32}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:75 [inlined]
   [31] materialize!(::LinearAlgebra.Adjoint{Float32,CuArray{Float32,1,Nothing}}, ::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{0},Nothing,typeof(identity),Tuple{Float32}}) at ./broadcast.jl:823
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:58 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:57 [inlined]
   [35] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [36] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
   [37] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:3 [inlined]
   [38] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [39] test_broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:3
   [40] test(::Type{CuArray}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:55
   [41] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [42] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   ... (the last 2 lines are repeated 1 more time)
   [45] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:40
   [46] include(::String) at ./client.jl:441
   [47] top-level scope at none:6
   [48] eval(::Module, ::Any) at ./boot.jl:331
   [49] exec_options(::Base.JLOptions) at ./client.jl:264
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:66
  Test threw exception
  Expression: compare(((a, b)->begin
            a .+ b
        end), AT, rand(ET, 4, 5, 3), rand(ET, 1, 5, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float32,3,CUDAnative.AS.Global},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float32,3,CUDAnative.AS.Global},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Float32,3,Nothing},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}},Base.Broadcast.Extruded{CuArray{Float32,3,Nothing},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{3},Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{CuArray{Float32,3,Nothing},CuArray{Float32,3,Nothing}}}) at ./broadcast.jl:840
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] (::Main.TestSuite.var"#157#179")(::CuArray{Float32,3,Nothing}, ::CuArray{Float32,3,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float32,3}, ::Vararg{Array{Float32,3},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float32,3}, ::Vararg{Array{Float32,3},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:66 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:67
  Test threw exception
  Expression: compare(((a, b)->begin
            a .+ b
        end), AT, rand(ET, 4, 5, 3), rand(ET, 1, 5, 1))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float32,3,CUDAnative.AS.Global},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float32,3,CUDAnative.AS.Global},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Float32,3,Nothing},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}},Base.Broadcast.Extruded{CuArray{Float32,3,Nothing},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{3},Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{CuArray{Float32,3,Nothing},CuArray{Float32,3,Nothing}}}) at ./broadcast.jl:840
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] (::Main.TestSuite.var"#158#180")(::CuArray{Float32,3,Nothing}, ::CuArray{Float32,3,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float32,3}, ::Vararg{Array{Float32,3},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float32,3}, ::Vararg{Array{Float32,3},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:67 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:72
  Test threw exception
  Expression: compare(AT, rand(ET, dim), rand(ET, dim), rand(ET, dim)) do tmp, a1, a2
    tmp .= a1 .+ a2 .* ET(2)
end
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Float32}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Float32}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize!(::CuArray{Float32,2,Nothing}, ::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),Tuple{CuArray{Float32,2,Nothing},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{CuArray{Float32,2,Nothing},Float32}}}}) at ./broadcast.jl:823
   [32] (::Main.TestSuite.var"#159#181"{DataType})(::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}) at ./none:0
   [33] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:72 [inlined]
   [36] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [37] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:79
  Test threw exception
  Expression: compare(((a1, a2)->begin
            muladd.(ET(2), a1, a2)
        end), AT, rand(ET, dim), rand(ET, dim))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(muladd),Tuple{Float32,Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(muladd),Tuple{Float32,Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(muladd),Tuple{Float32,CuArray{Float32,2,Nothing},CuArray{Float32,2,Nothing}}}) at ./broadcast.jl:820
   [33] (::Main.TestSuite.var"#160#182"{DataType})(::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:79 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:85
  Test threw exception
  Expression: compare(AT, rand(ET, dim), rand(ET, dim), rand(ET, dim), rand(ET, dim), rand(ET, dim), rand(ET, dim)) do a1, a2, a3, a4, a5, a6
    #= /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:86 =# @__dot__ a1 = a2 + 1.2 * (1.3a3 + 1.4a4 + 1.5a5 + 1.6a6)
end
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float64,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),NTuple{4,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float64,Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float64,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),NTuple{4,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float64,Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize! at ./broadcast.jl:823 [inlined]
   [32] (::Main.TestSuite.var"#161#183")(::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}) at ./none:0
   [33] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:85 [inlined]
   [36] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [37] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:89
  Test threw exception
  Expression: compare(AT, rand(ET, dim), rand(ET, dim), rand(ET, dim), rand(ET, dim)) do u, uprev, duprev, ku
    fract = ET(1 // 2)
    dt = ET(1.4)
    dt2 = dt ^ 2
    #= /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:93 =# @__dot__ u = uprev + dt * duprev + dt2 * (fract * ku)
end
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float32,Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float32,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float32,Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float32,Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float32,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float32,Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize!(::CuArray{Float32,2,Nothing}, ::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),Tuple{CuArray{Float32,2,Nothing},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float32,CuArray{Float32,2,Nothing}}},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float32,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float32,CuArray{Float32,2,Nothing}}}}}}}) at ./broadcast.jl:823
   [32] (::Main.TestSuite.var"#162#184"{DataType})(::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}) at ./none:0
   [33] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:89 [inlined]
   [36] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [37] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:95
  Test threw exception
  Expression: compare((x->begin
            (-).(x)
        end), AT, rand(ET, 2, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(-),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(-),Tuple{Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] (::Main.TestSuite.var"#163#185")(::CuArray{Float32,2,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:95 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:97
  Test threw exception
  Expression: compare(AT, rand(ET, dim), rand(ET, dim), rand(ET, dim), rand(ET, dim), rand(ET, dim), rand(ET, dim)) do utilde, gA, k1, k2, k3, k4
    btilde1 = ET(1)
    btilde2 = ET(1)
    btilde3 = ET(1)
    btilde4 = ET(1)
    dt = ET(1)
    #= /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:103 =# @__dot__ utilde = dt * (btilde1 * k1 + btilde2 * k2 + btilde3 * k3 + btilde4 * k4)
end
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Float32,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),NTuple{4,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float32,Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Float32,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),NTuple{4,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float32,Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize!(::CuArray{Float32,2,Nothing}, ::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float32,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),NTuple{4,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float32,CuArray{Float32,2,Nothing}}}}}}}) at ./broadcast.jl:823
   [32] (::Main.TestSuite.var"#164#186"{DataType})(::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}) at ./none:0
   [33] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:97 [inlined]
   [36] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [37] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:108
  Test threw exception
  Expression: compare(((x, y)->begin
            map(+, x, y)
        end), AT, rand(ET, 2, 3), rand(ET, 2, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),Tuple{CuArray{Float32,2,Nothing},CuArray{Float32,2,Nothing}}}) at ./broadcast.jl:820
   [33] map(::Function, ::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:91
   [34] (::Main.TestSuite.var"#166#188")(::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}) at ./none:0
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [36] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [37] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:108 [inlined]
   [38] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [39] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:110
  Test threw exception
  Expression: compare((x->begin
            2x
        end), AT, rand(ET, 2, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Int64,Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Int64,Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] broadcast_preserving_zero_d at ./broadcast.jl:809 [inlined]
   [34] * at ./arraymath.jl:52 [inlined]
   [35] (::Main.TestSuite.var"#167#189")(::CuArray{Float32,2,Nothing}) at ./none:0
   [36] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [37] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [38] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:110 [inlined]
   [39] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [40] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:111
  Test threw exception
  Expression: compare(((x, y)->begin
            x .+ y
        end), AT, rand(ET, 2, 3), rand(ET, 1, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] (::Main.TestSuite.var"#168#190")(::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:111 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:112
  Test threw exception
  Expression: compare(((z, x, y)->begin
            z .= x .+ y
        end), AT, rand(ET, 2, 3), rand(ET, 2, 3), rand(ET, 2))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float32,1,CUDAnative.AS.Global},Tuple{Bool},Tuple{Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Float32,1,Nothing},Tuple{Bool},Tuple{Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize! at ./broadcast.jl:823 [inlined]
   [32] (::Main.TestSuite.var"#169#191")(::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}, ::CuArray{Float32,1,Nothing}) at ./none:0
   [33] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:112 [inlined]
   [36] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [37] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:114
  Test threw exception
  Expression: compare((A->begin
            A .= identity.(ET(10))
        end), AT, rand(ET, 40, 40))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Float32}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Float32}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:75 [inlined]
   [31] materialize!(::CuArray{Float32,2,Nothing}, ::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{0},Nothing,typeof(identity),Tuple{Float32}}) at ./broadcast.jl:823
   [32] (::Main.TestSuite.var"#170#192"{DataType})(::CuArray{Float32,2,Nothing}) at ./none:0
   [33] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:114 [inlined]
   [36] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [37] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:115
  Test threw exception
  Expression: compare((A->begin
            test_kernel.(A, ET(10))
        end), AT, rand(ET, 40, 40))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(Main.TestSuite.test_kernel),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Float32}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(Main.TestSuite.test_kernel),Tuple{Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Float32}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(Main.TestSuite.test_kernel),Tuple{CuArray{Float32,2,Nothing},Float32}}) at ./broadcast.jl:820
   [33] (::Main.TestSuite.var"#171#193"{DataType})(::CuArray{Float32,2,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:115 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:116
  Test threw exception
  Expression: compare((A->begin
            A .* ET(10)
        end), AT, rand(ET, 40, 40))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Float32}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Float32}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{CuArray{Float32,2,Nothing},Float32}}) at ./broadcast.jl:820
   [33] (::Main.TestSuite.var"#172#194"{DataType})(::CuArray{Float32,2,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:116 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:117
  Test threw exception
  Expression: compare(((A, B)->begin
            A .* B
        end), AT, rand(ET, 40, 40), rand(ET, 40, 40))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] (::Main.TestSuite.var"#173#195")(::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:117 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:118
  Test threw exception
  Expression: compare(((A, B)->begin
            A .* B .+ ET(10)
        end), AT, rand(ET, 40, 40), rand(ET, 40, 40))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}},Float32}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Float32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}},Float32}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),Tuple{Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{CuArray{Float32,2,Nothing},CuArray{Float32,2,Nothing}}},Float32}}) at ./broadcast.jl:820
   [33] (::Main.TestSuite.var"#174#196"{DataType})(::CuArray{Float32,2,Nothing}, ::CuArray{Float32,2,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float32,2}, ::Vararg{Array{Float32,2},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:118 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
RefValue: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float64,1,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},typeof(Main.TestSuite.test_idx),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int64,1,CUDAnative.AS.Global},Tuple{Bool},Tuple{Int64}},CUDAnative.CuRefValue{CuDeviceArray{Float64,1,CUDAnative.AS.Global}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float64,1,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},typeof(Main.TestSuite.test_idx),Tuple{Base.Broadcast.Extruded{CuArray{Int64,1,Nothing},Tuple{Bool},Tuple{Int64}},Base.RefValue{CuArray{Float64,1,Nothing}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize!(::CuArray{Float64,1,Nothing}, ::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{1},Nothing,typeof(Main.TestSuite.test_idx),Tuple{CuArray{Int64,1,Nothing},Base.RefValue{CuArray{Float64,1,Nothing}}}}) at ./broadcast.jl:823
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:43 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:37 [inlined]
   [35] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [36] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
   [37] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:3 [inlined]
   [38] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [39] test_broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:3
   [40] test(::Type{CuArray}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:55
   [41] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [42] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   ... (the last 2 lines are repeated 1 more time)
   [45] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:40
   [46] include(::String) at ./client.jl:441
   [47] top-level scope at none:6
   [48] eval(::Module, ::Any) at ./boot.jl:331
   [49] exec_options(::Base.JLOptions) at ./client.jl:264
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
Tuple: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:49
  Test threw exception
  Expression: compare(AT, rand(ET, 3, N), rand(ET, 3, N), rand(ET, N), rand(ET, N), rand(ET, N)) do out, arr, a, b, c
    broadcast!(out, arr, (a, b, c)) do xx, yy
        xx + first(yy)
    end
end
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},Main.TestSuite.var"#156#178",Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Tuple{CuDeviceArray{Float64,1,CUDAnative.AS.Global},CuDeviceArray{Float64,1,CUDAnative.AS.Global},CuDeviceArray{Float64,1,CUDAnative.AS.Global}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},Main.TestSuite.var"#156#178",Tuple{Base.Broadcast.Extruded{CuArray{Float64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Tuple{CuArray{Float64,1,Nothing},CuArray{Float64,1,Nothing},CuArray{Float64,1,Nothing}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize! at ./broadcast.jl:823 [inlined]
   [32] broadcast! at ./broadcast.jl:797 [inlined]
   [33] (::Main.TestSuite.var"#155#177")(::CuArray{Float64,2,Nothing}, ::CuArray{Float64,2,Nothing}, ::CuArray{Float64,1,Nothing}, ::CuArray{Float64,1,Nothing}, ::CuArray{Float64,1,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:49 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:49 [inlined]
   [39] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [40] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
Adjoint and Transpose: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:56
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,LinearAlgebra.Adjoint{Float64,CuDeviceArray{Float64,1,CUDAnative.AS.Global}},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Float64}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{LinearAlgebra.Adjoint{Float64,CuArray{Float64,1,Nothing}},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Float64}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:75 [inlined]
   [31] materialize!(::LinearAlgebra.Adjoint{Float64,CuArray{Float64,1,Nothing}}, ::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{0},Nothing,typeof(identity),Tuple{Float64}}) at ./broadcast.jl:823
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:58 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:57 [inlined]
   [35] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [36] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
   [37] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:3 [inlined]
   [38] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [39] test_broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:3
   [40] test(::Type{CuArray}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:55
   [41] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [42] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   ... (the last 2 lines are repeated 1 more time)
   [45] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:40
   [46] include(::String) at ./client.jl:441
   [47] top-level scope at none:6
   [48] eval(::Module, ::Any) at ./boot.jl:331
   [49] exec_options(::Base.JLOptions) at ./client.jl:264
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:66
  Test threw exception
  Expression: compare(((a, b)->begin
            a .+ b
        end), AT, rand(ET, 4, 5, 3), rand(ET, 1, 5, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Float64,3,Nothing},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}},Base.Broadcast.Extruded{CuArray{Float64,3,Nothing},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{3},Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{CuArray{Float64,3,Nothing},CuArray{Float64,3,Nothing}}}) at ./broadcast.jl:840
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] (::Main.TestSuite.var"#157#179")(::CuArray{Float64,3,Nothing}, ::CuArray{Float64,3,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float64,3}, ::Vararg{Array{Float64,3},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float64,3}, ::Vararg{Array{Float64,3},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:66 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:67
  Test threw exception
  Expression: compare(((a, b)->begin
            a .+ b
        end), AT, rand(ET, 4, 5, 3), rand(ET, 1, 5, 1))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float64,3,CUDAnative.AS.Global},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Float64,3,Nothing},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}},Base.Broadcast.Extruded{CuArray{Float64,3,Nothing},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{3},Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{CuArray{Float64,3,Nothing},CuArray{Float64,3,Nothing}}}) at ./broadcast.jl:840
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] (::Main.TestSuite.var"#158#180")(::CuArray{Float64,3,Nothing}, ::CuArray{Float64,3,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float64,3}, ::Vararg{Array{Float64,3},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float64,3}, ::Vararg{Array{Float64,3},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:67 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:72
  Test threw exception
  Expression: compare(AT, rand(ET, dim), rand(ET, dim), rand(ET, dim)) do tmp, a1, a2
    tmp .= a1 .+ a2 .* ET(2)
end
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Float64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Float64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Base.Broadcast.Extruded{CuArray{Float64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Float64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize!(::CuArray{Float64,2,Nothing}, ::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),Tuple{CuArray{Float64,2,Nothing},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{CuArray{Float64,2,Nothing},Float64}}}}) at ./broadcast.jl:823
   [32] (::Main.TestSuite.var"#159#181"{DataType})(::CuArray{Float64,2,Nothing}, ::CuArray{Float64,2,Nothing}, ::CuArray{Float64,2,Nothing}) at ./none:0
   [33] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:72 [inlined]
   [36] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [37] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:79
  Test threw exception
  Expression: compare(((a1, a2)->begin
            muladd.(ET(2), a1, a2)
        end), AT, rand(ET, dim), rand(ET, dim))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(muladd),Tuple{Float64,Base.Broadcast.Extruded{CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(muladd),Tuple{Float64,Base.Broadcast.Extruded{CuArray{Float64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Float64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(muladd),Tuple{Float64,CuArray{Float64,2,Nothing},CuArray{Float64,2,Nothing}}}) at ./broadcast.jl:820
   [33] (::Main.TestSuite.var"#160#182"{DataType})(::CuArray{Float64,2,Nothing}, ::CuArray{Float64,2,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:79 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:85
  Test threw exception
  Expression: compare(AT, rand(ET, dim), rand(ET, dim), rand(ET, dim), rand(ET, dim), rand(ET, dim), rand(ET, dim)) do a1, a2, a3, a4, a5, a6
    #= /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:86 =# @__dot__ a1 = a2 + 1.2 * (1.3a3 + 1.4a4 + 1.5a5 + 1.6a6)
end
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float64,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),NTuple{4,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float64,Base.Broadcast.Extruded{CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Float64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float64,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),NTuple{4,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float64,Base.Broadcast.Extruded{CuArray{Float64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize! at ./broadcast.jl:823 [inlined]
   [32] (::Main.TestSuite.var"#161#183")(::CuArray{Float64,2,Nothing}, ::CuArray{Float64,2,Nothing}, ::CuArray{Float64,2,Nothing}, ::CuArray{Float64,2,Nothing}, ::CuArray{Float64,2,Nothing}, ::CuArray{Float64,2,Nothing}) at ./none:0
   [33] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:85 [inlined]
   [36] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [37] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:89
  Test threw exception
  Expression: compare(AT, rand(ET, dim), rand(ET, dim), rand(ET, dim), rand(ET, dim)) do u, uprev, duprev, ku
    fract = ET(1 // 2)
    dt = ET(1.4)
    dt2 = dt ^ 2
    #= /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:93 =# @__dot__ u = uprev + dt * duprev + dt2 * (fract * ku)
end
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float64,Base.Broadcast.Extruded{CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float64,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float64,Base.Broadcast.Extruded{CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Float64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float64,Base.Broadcast.Extruded{CuArray{Float64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float64,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float64,Base.Broadcast.Extruded{CuArray{Float64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize!(::CuArray{Float64,2,Nothing}, ::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),Tuple{CuArray{Float64,2,Nothing},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float64,CuArray{Float64,2,Nothing}}},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float64,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float64,CuArray{Float64,2,Nothing}}}}}}}) at ./broadcast.jl:823
   [32] (::Main.TestSuite.var"#162#184"{DataType})(::CuArray{Float64,2,Nothing}, ::CuArray{Float64,2,Nothing}, ::CuArray{Float64,2,Nothing}, ::CuArray{Float64,2,Nothing}) at ./none:0
   [33] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:89 [inlined]
   [36] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [37] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:95
  Test threw exception
  Expression: compare((x->begin
            (-).(x)
        end), AT, rand(ET, 2, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(-),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(-),Tuple{Base.Broadcast.Extruded{CuArray{Float64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] (::Main.TestSuite.var"#163#185")(::CuArray{Float64,2,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:95 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:97
  Test threw exception
  Expression: compare(AT, rand(ET, dim), rand(ET, dim), rand(ET, dim), rand(ET, dim), rand(ET, dim), rand(ET, dim)) do utilde, gA, k1, k2, k3, k4
    btilde1 = ET(1)
    btilde2 = ET(1)
    btilde3 = ET(1)
    btilde4 = ET(1)
    dt = ET(1)
    #= /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:103 =# @__dot__ utilde = dt * (btilde1 * k1 + btilde2 * k2 + btilde3 * k3 + btilde4 * k4)
end
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Float64,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),NTuple{4,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float64,Base.Broadcast.Extruded{CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Float64,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),NTuple{4,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float64,Base.Broadcast.Extruded{CuArray{Float64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize!(::CuArray{Float64,2,Nothing}, ::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float64,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),NTuple{4,Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Float64,CuArray{Float64,2,Nothing}}}}}}}) at ./broadcast.jl:823
   [32] (::Main.TestSuite.var"#164#186"{DataType})(::CuArray{Float64,2,Nothing}, ::CuArray{Float64,2,Nothing}, ::CuArray{Float64,2,Nothing}, ::CuArray{Float64,2,Nothing}, ::CuArray{Float64,2,Nothing}, ::CuArray{Float64,2,Nothing}) at ./none:0
   [33] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:97 [inlined]
   [36] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [37] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:107
  Test threw exception
  Expression: compare((x->begin
            fill!(x, 1)
        end), AT, rand(ET, 3, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#10#11",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::GPUArrays.var"#10#11", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float64,2,CUDAnative.AS.Global},Float64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float64,2,Nothing},Float64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:46 [inlined]
   [28] fill! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:12 [inlined]
   [29] (::Main.TestSuite.var"#165#187")(::CuArray{Float64,2,Nothing}) at ./none:0
   [30] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [31] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:107 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:108
  Test threw exception
  Expression: compare(((x, y)->begin
            map(+, x, y)
        end), AT, rand(ET, 2, 3), rand(ET, 2, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Float64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Float64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),Tuple{CuArray{Float64,2,Nothing},CuArray{Float64,2,Nothing}}}) at ./broadcast.jl:820
   [33] map(::Function, ::CuArray{Float64,2,Nothing}, ::CuArray{Float64,2,Nothing}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:91
   [34] (::Main.TestSuite.var"#166#188")(::CuArray{Float64,2,Nothing}, ::CuArray{Float64,2,Nothing}) at ./none:0
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [36] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [37] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:108 [inlined]
   [38] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [39] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:110
  Test threw exception
  Expression: compare((x->begin
            2x
        end), AT, rand(ET, 2, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Int64,Base.Broadcast.Extruded{CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Int64,Base.Broadcast.Extruded{CuArray{Float64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] broadcast_preserving_zero_d at ./broadcast.jl:809 [inlined]
   [34] * at ./arraymath.jl:52 [inlined]
   [35] (::Main.TestSuite.var"#167#189")(::CuArray{Float64,2,Nothing}) at ./none:0
   [36] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [37] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [38] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:110 [inlined]
   [39] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [40] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:111
  Test threw exception
  Expression: compare(((x, y)->begin
            x .+ y
        end), AT, rand(ET, 2, 3), rand(ET, 1, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Float64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Float64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] (::Main.TestSuite.var"#168#190")(::CuArray{Float64,2,Nothing}, ::CuArray{Float64,2,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:111 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:112
  Test threw exception
  Expression: compare(((z, x, y)->begin
            z .= x .+ y
        end), AT, rand(ET, 2, 3), rand(ET, 2, 3), rand(ET, 2))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float64,1,CUDAnative.AS.Global},Tuple{Bool},Tuple{Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Float64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Float64,1,Nothing},Tuple{Bool},Tuple{Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize! at ./broadcast.jl:823 [inlined]
   [32] (::Main.TestSuite.var"#169#191")(::CuArray{Float64,2,Nothing}, ::CuArray{Float64,2,Nothing}, ::CuArray{Float64,1,Nothing}) at ./none:0
   [33] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:112 [inlined]
   [36] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [37] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:114
  Test threw exception
  Expression: compare((A->begin
            A .= identity.(ET(10))
        end), AT, rand(ET, 40, 40))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Float64}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Float64}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:75 [inlined]
   [31] materialize!(::CuArray{Float64,2,Nothing}, ::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{0},Nothing,typeof(identity),Tuple{Float64}}) at ./broadcast.jl:823
   [32] (::Main.TestSuite.var"#170#192"{DataType})(::CuArray{Float64,2,Nothing}) at ./none:0
   [33] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:114 [inlined]
   [36] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [37] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:115
  Test threw exception
  Expression: compare((A->begin
            test_kernel.(A, ET(10))
        end), AT, rand(ET, 40, 40))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(Main.TestSuite.test_kernel),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Float64}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(Main.TestSuite.test_kernel),Tuple{Base.Broadcast.Extruded{CuArray{Float64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Float64}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(Main.TestSuite.test_kernel),Tuple{CuArray{Float64,2,Nothing},Float64}}) at ./broadcast.jl:820
   [33] (::Main.TestSuite.var"#171#193"{DataType})(::CuArray{Float64,2,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:115 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:116
  Test threw exception
  Expression: compare((A->begin
            A .* ET(10)
        end), AT, rand(ET, 40, 40))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Float64}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Base.Broadcast.Extruded{CuArray{Float64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Float64}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{CuArray{Float64,2,Nothing},Float64}}) at ./broadcast.jl:820
   [33] (::Main.TestSuite.var"#172#194"{DataType})(::CuArray{Float64,2,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:116 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:117
  Test threw exception
  Expression: compare(((A, B)->begin
            A .* B
        end), AT, rand(ET, 40, 40), rand(ET, 40, 40))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Base.Broadcast.Extruded{CuArray{Float64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Float64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] (::Main.TestSuite.var"#173#195")(::CuArray{Float64,2,Nothing}, ::CuArray{Float64,2,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:117 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Float64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:118
  Test threw exception
  Expression: compare(((A, B)->begin
            A .* B .+ ET(10)
        end), AT, rand(ET, 40, 40), rand(ET, 40, 40))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Float64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}},Float64}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Float64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Base.Broadcast.Extruded{CuArray{Float64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Float64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}},Float64}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),Tuple{Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{CuArray{Float64,2,Nothing},CuArray{Float64,2,Nothing}}},Float64}}) at ./broadcast.jl:820
   [33] (::Main.TestSuite.var"#174#196"{DataType})(::CuArray{Float64,2,Nothing}, ::CuArray{Float64,2,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Float64,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:118 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
RefValue: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int32,1,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},typeof(Main.TestSuite.test_idx),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int64,1,CUDAnative.AS.Global},Tuple{Bool},Tuple{Int64}},CUDAnative.CuRefValue{CuDeviceArray{Int32,1,CUDAnative.AS.Global}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int32,1,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},typeof(Main.TestSuite.test_idx),Tuple{Base.Broadcast.Extruded{CuArray{Int64,1,Nothing},Tuple{Bool},Tuple{Int64}},Base.RefValue{CuArray{Int32,1,Nothing}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize!(::CuArray{Int32,1,Nothing}, ::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{1},Nothing,typeof(Main.TestSuite.test_idx),Tuple{CuArray{Int64,1,Nothing},Base.RefValue{CuArray{Int32,1,Nothing}}}}) at ./broadcast.jl:823
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:43 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:37 [inlined]
   [35] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [36] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
   [37] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:3 [inlined]
   [38] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [39] test_broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:3
   [40] test(::Type{CuArray}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:55
   [41] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [42] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   ... (the last 2 lines are repeated 1 more time)
   [45] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:40
   [46] include(::String) at ./client.jl:441
   [47] top-level scope at none:6
   [48] eval(::Module, ::Any) at ./boot.jl:331
   [49] exec_options(::Base.JLOptions) at ./client.jl:264
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
Tuple: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:49
  Test threw exception
  Expression: compare(AT, rand(ET, 3, N), rand(ET, 3, N), rand(ET, N), rand(ET, N), rand(ET, N)) do out, arr, a, b, c
    broadcast!(out, arr, (a, b, c)) do xx, yy
        xx + first(yy)
    end
end
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},Main.TestSuite.var"#156#178",Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Tuple{CuDeviceArray{Int32,1,CUDAnative.AS.Global},CuDeviceArray{Int32,1,CUDAnative.AS.Global},CuDeviceArray{Int32,1,CUDAnative.AS.Global}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},Main.TestSuite.var"#156#178",Tuple{Base.Broadcast.Extruded{CuArray{Int32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Tuple{CuArray{Int32,1,Nothing},CuArray{Int32,1,Nothing},CuArray{Int32,1,Nothing}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize! at ./broadcast.jl:823 [inlined]
   [32] broadcast! at ./broadcast.jl:797 [inlined]
   [33] (::Main.TestSuite.var"#155#177")(::CuArray{Int32,2,Nothing}, ::CuArray{Int32,2,Nothing}, ::CuArray{Int32,1,Nothing}, ::CuArray{Int32,1,Nothing}, ::CuArray{Int32,1,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Int32,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Int32,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:49 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:49 [inlined]
   [39] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [40] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
Adjoint and Transpose: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:56
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,LinearAlgebra.Adjoint{Int32,CuDeviceArray{Int32,1,CUDAnative.AS.Global}},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int32}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{LinearAlgebra.Adjoint{Int32,CuArray{Int32,1,Nothing}},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int32}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:75 [inlined]
   [31] materialize!(::LinearAlgebra.Adjoint{Int32,CuArray{Int32,1,Nothing}}, ::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{0},Nothing,typeof(identity),Tuple{Int32}}) at ./broadcast.jl:823
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:58 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:57 [inlined]
   [35] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [36] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
   [37] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:3 [inlined]
   [38] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [39] test_broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:3
   [40] test(::Type{CuArray}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:55
   [41] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [42] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   ... (the last 2 lines are repeated 1 more time)
   [45] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:40
   [46] include(::String) at ./client.jl:441
   [47] top-level scope at none:6
   [48] eval(::Module, ::Any) at ./boot.jl:331
   [49] exec_options(::Base.JLOptions) at ./client.jl:264
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:66
  Test threw exception
  Expression: compare(((a, b)->begin
            a .+ b
        end), AT, rand(ET, 4, 5, 3), rand(ET, 1, 5, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int32,3,CUDAnative.AS.Global},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Int32,3,CUDAnative.AS.Global},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Int32,3,Nothing},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}},Base.Broadcast.Extruded{CuArray{Int32,3,Nothing},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{3},Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{CuArray{Int32,3,Nothing},CuArray{Int32,3,Nothing}}}) at ./broadcast.jl:840
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] (::Main.TestSuite.var"#157#179")(::CuArray{Int32,3,Nothing}, ::CuArray{Int32,3,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Int32,3}, ::Vararg{Array{Int32,3},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Int32,3}, ::Vararg{Array{Int32,3},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:66 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:67
  Test threw exception
  Expression: compare(((a, b)->begin
            a .+ b
        end), AT, rand(ET, 4, 5, 3), rand(ET, 1, 5, 1))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int32,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int32,3,CUDAnative.AS.Global},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Int32,3,CUDAnative.AS.Global},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int32,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Int32,3,Nothing},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}},Base.Broadcast.Extruded{CuArray{Int32,3,Nothing},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{3},Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{CuArray{Int32,3,Nothing},CuArray{Int32,3,Nothing}}}) at ./broadcast.jl:840
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] (::Main.TestSuite.var"#158#180")(::CuArray{Int32,3,Nothing}, ::CuArray{Int32,3,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Int32,3}, ::Vararg{Array{Int32,3},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Int32,3}, ::Vararg{Array{Int32,3},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:67 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:72
  Test threw exception
  Expression: compare(AT, rand(ET, dim), rand(ET, dim), rand(ET, dim)) do tmp, a1, a2
    tmp .= a1 .+ a2 .* ET(2)
end
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Int32}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Int32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Base.Broadcast.Extruded{CuArray{Int32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Int32}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize!(::CuArray{Int32,2,Nothing}, ::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),Tuple{CuArray{Int32,2,Nothing},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{CuArray{Int32,2,Nothing},Int32}}}}) at ./broadcast.jl:823
   [32] (::Main.TestSuite.var"#159#181"{DataType})(::CuArray{Int32,2,Nothing}, ::CuArray{Int32,2,Nothing}, ::CuArray{Int32,2,Nothing}) at ./none:0
   [33] compare(::Function, ::Type{CuArray}, ::Array{Int32,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [34] compare(::Function, ::Type{CuArray}, ::Array{Int32,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:72 [inlined]
   [36] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [37] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:108
  Test threw exception
  Expression: compare(((x, y)->begin
            map(+, x, y)
        end), AT, rand(ET, 2, 3), rand(ET, 2, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Int32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Int32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Int32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),Tuple{CuArray{Int32,2,Nothing},CuArray{Int32,2,Nothing}}}) at ./broadcast.jl:820
   [33] map(::Function, ::CuArray{Int32,2,Nothing}, ::CuArray{Int32,2,Nothing}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:91
   [34] (::Main.TestSuite.var"#166#188")(::CuArray{Int32,2,Nothing}, ::CuArray{Int32,2,Nothing}) at ./none:0
   [35] compare(::Function, ::Type{CuArray}, ::Array{Int32,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [36] compare(::Function, ::Type{CuArray}, ::Array{Int32,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [37] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:108 [inlined]
   [38] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [39] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:110
  Test threw exception
  Expression: compare((x->begin
            2x
        end), AT, rand(ET, 2, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Int64,Base.Broadcast.Extruded{CuDeviceArray{Int32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Int64,Base.Broadcast.Extruded{CuArray{Int32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] broadcast_preserving_zero_d at ./broadcast.jl:809 [inlined]
   [34] *(::Int64, ::CuArray{Int32,2,Nothing}) at ./arraymath.jl:52
   [35] (::Main.TestSuite.var"#167#189")(::CuArray{Int32,2,Nothing}) at ./none:0
   [36] compare(::Function, ::Type{CuArray}, ::Array{Int32,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [37] compare(::Function, ::Type{CuArray}, ::Array{Int32,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [38] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:110 [inlined]
   [39] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [40] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:111
  Test threw exception
  Expression: compare(((x, y)->begin
            x .+ y
        end), AT, rand(ET, 2, 3), rand(ET, 1, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Int32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Int32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Int32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] (::Main.TestSuite.var"#168#190")(::CuArray{Int32,2,Nothing}, ::CuArray{Int32,2,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Int32,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Int32,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:111 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:112
  Test threw exception
  Expression: compare(((z, x, y)->begin
            z .= x .+ y
        end), AT, rand(ET, 2, 3), rand(ET, 2, 3), rand(ET, 2))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Int32,1,CUDAnative.AS.Global},Tuple{Bool},Tuple{Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Int32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Int32,1,Nothing},Tuple{Bool},Tuple{Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize! at ./broadcast.jl:823 [inlined]
   [32] (::Main.TestSuite.var"#169#191")(::CuArray{Int32,2,Nothing}, ::CuArray{Int32,2,Nothing}, ::CuArray{Int32,1,Nothing}) at ./none:0
   [33] compare(::Function, ::Type{CuArray}, ::Array{Int32,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [34] compare(::Function, ::Type{CuArray}, ::Array{Int32,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:112 [inlined]
   [36] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [37] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:114
  Test threw exception
  Expression: compare((A->begin
            A .= identity.(ET(10))
        end), AT, rand(ET, 40, 40))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int32}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int32}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:75 [inlined]
   [31] materialize!(::CuArray{Int32,2,Nothing}, ::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{0},Nothing,typeof(identity),Tuple{Int32}}) at ./broadcast.jl:823
   [32] (::Main.TestSuite.var"#170#192"{DataType})(::CuArray{Int32,2,Nothing}) at ./none:0
   [33] compare(::Function, ::Type{CuArray}, ::Array{Int32,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [34] compare(::Function, ::Type{CuArray}, ::Array{Int32,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:114 [inlined]
   [36] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [37] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:115
  Test threw exception
  Expression: compare((A->begin
            test_kernel.(A, ET(10))
        end), AT, rand(ET, 40, 40))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(Main.TestSuite.test_kernel),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Int32}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(Main.TestSuite.test_kernel),Tuple{Base.Broadcast.Extruded{CuArray{Int32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Int32}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(Main.TestSuite.test_kernel),Tuple{CuArray{Int32,2,Nothing},Int32}}) at ./broadcast.jl:820
   [33] (::Main.TestSuite.var"#171#193"{DataType})(::CuArray{Int32,2,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Int32,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Int32,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:115 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:116
  Test threw exception
  Expression: compare((A->begin
            A .* ET(10)
        end), AT, rand(ET, 40, 40))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Int32}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Base.Broadcast.Extruded{CuArray{Int32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Int32}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{CuArray{Int32,2,Nothing},Int32}}) at ./broadcast.jl:820
   [33] (::Main.TestSuite.var"#172#194"{DataType})(::CuArray{Int32,2,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Int32,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Int32,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:116 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:117
  Test threw exception
  Expression: compare(((A, B)->begin
            A .* B
        end), AT, rand(ET, 40, 40), rand(ET, 40, 40))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Int32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Base.Broadcast.Extruded{CuArray{Int32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Int32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] (::Main.TestSuite.var"#173#195")(::CuArray{Int32,2,Nothing}, ::CuArray{Int32,2,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Int32,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Int32,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:117 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int32: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:118
  Test threw exception
  Expression: compare(((A, B)->begin
            A .* B .+ ET(10)
        end), AT, rand(ET, 40, 40), rand(ET, 40, 40))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int32,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Int32,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}},Int32}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int32,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Base.Broadcast.Extruded{CuArray{Int32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Int32,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}},Int32}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),Tuple{Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{CuArray{Int32,2,Nothing},CuArray{Int32,2,Nothing}}},Int32}}) at ./broadcast.jl:820
   [33] (::Main.TestSuite.var"#174#196"{DataType})(::CuArray{Int32,2,Nothing}, ::CuArray{Int32,2,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Int32,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Int32,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:118 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
RefValue: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int64,1,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},typeof(Main.TestSuite.test_idx),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int64,1,CUDAnative.AS.Global},Tuple{Bool},Tuple{Int64}},CUDAnative.CuRefValue{CuDeviceArray{Int64,1,CUDAnative.AS.Global}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int64,1,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},typeof(Main.TestSuite.test_idx),Tuple{Base.Broadcast.Extruded{CuArray{Int64,1,Nothing},Tuple{Bool},Tuple{Int64}},Base.RefValue{CuArray{Int64,1,Nothing}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize!(::CuArray{Int64,1,Nothing}, ::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{1},Nothing,typeof(Main.TestSuite.test_idx),Tuple{CuArray{Int64,1,Nothing},Base.RefValue{CuArray{Int64,1,Nothing}}}}) at ./broadcast.jl:823
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:43 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:37 [inlined]
   [35] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [36] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
   [37] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:3 [inlined]
   [38] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [39] test_broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:3
   [40] test(::Type{CuArray}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:55
   [41] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [42] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   ... (the last 2 lines are repeated 1 more time)
   [45] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:40
   [46] include(::String) at ./client.jl:441
   [47] top-level scope at none:6
   [48] eval(::Module, ::Any) at ./boot.jl:331
   [49] exec_options(::Base.JLOptions) at ./client.jl:264
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
Tuple: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:49
  Test threw exception
  Expression: compare(AT, rand(ET, 3, N), rand(ET, 3, N), rand(ET, N), rand(ET, N), rand(ET, N)) do out, arr, a, b, c
    broadcast!(out, arr, (a, b, c)) do xx, yy
        xx + first(yy)
    end
end
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},Main.TestSuite.var"#156#178",Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Tuple{CuDeviceArray{Int64,1,CUDAnative.AS.Global},CuDeviceArray{Int64,1,CUDAnative.AS.Global},CuDeviceArray{Int64,1,CUDAnative.AS.Global}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},Main.TestSuite.var"#156#178",Tuple{Base.Broadcast.Extruded{CuArray{Int64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Tuple{CuArray{Int64,1,Nothing},CuArray{Int64,1,Nothing},CuArray{Int64,1,Nothing}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize! at ./broadcast.jl:823 [inlined]
   [32] broadcast! at ./broadcast.jl:797 [inlined]
   [33] (::Main.TestSuite.var"#155#177")(::CuArray{Int64,2,Nothing}, ::CuArray{Int64,2,Nothing}, ::CuArray{Int64,1,Nothing}, ::CuArray{Int64,1,Nothing}, ::CuArray{Int64,1,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Int64,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Int64,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:49 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:49 [inlined]
   [39] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [40] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
Adjoint and Transpose: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:56
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,LinearAlgebra.Adjoint{Int64,CuDeviceArray{Int64,1,CUDAnative.AS.Global}},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{LinearAlgebra.Adjoint{Int64,CuArray{Int64,1,Nothing}},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:75 [inlined]
   [31] materialize!(::LinearAlgebra.Adjoint{Int64,CuArray{Int64,1,Nothing}}, ::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{0},Nothing,typeof(identity),Tuple{Int64}}) at ./broadcast.jl:823
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:58 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:57 [inlined]
   [35] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [36] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
   [37] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:3 [inlined]
   [38] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [39] test_broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:3
   [40] test(::Type{CuArray}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:55
   [41] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [42] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   ... (the last 2 lines are repeated 1 more time)
   [45] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:40
   [46] include(::String) at ./client.jl:441
   [47] top-level scope at none:6
   [48] eval(::Module, ::Any) at ./boot.jl:331
   [49] exec_options(::Base.JLOptions) at ./client.jl:264
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:66
  Test threw exception
  Expression: compare(((a, b)->begin
            a .+ b
        end), AT, rand(ET, 4, 5, 3), rand(ET, 1, 5, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int64,3,CUDAnative.AS.Global},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Int64,3,CUDAnative.AS.Global},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Int64,3,Nothing},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}},Base.Broadcast.Extruded{CuArray{Int64,3,Nothing},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{3},Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{CuArray{Int64,3,Nothing},CuArray{Int64,3,Nothing}}}) at ./broadcast.jl:840
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] (::Main.TestSuite.var"#157#179")(::CuArray{Int64,3,Nothing}, ::CuArray{Int64,3,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Int64,3}, ::Vararg{Array{Int64,3},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Int64,3}, ::Vararg{Array{Int64,3},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:66 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:67
  Test threw exception
  Expression: compare(((a, b)->begin
            a .+ b
        end), AT, rand(ET, 4, 5, 3), rand(ET, 1, 5, 1))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int64,3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int64,3,CUDAnative.AS.Global},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Int64,3,CUDAnative.AS.Global},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int64,3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Int64,3,Nothing},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}},Base.Broadcast.Extruded{CuArray{Int64,3,Nothing},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{3},Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{CuArray{Int64,3,Nothing},CuArray{Int64,3,Nothing}}}) at ./broadcast.jl:840
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] (::Main.TestSuite.var"#158#180")(::CuArray{Int64,3,Nothing}, ::CuArray{Int64,3,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Int64,3}, ::Vararg{Array{Int64,3},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Int64,3}, ::Vararg{Array{Int64,3},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:67 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:72
  Test threw exception
  Expression: compare(AT, rand(ET, dim), rand(ET, dim), rand(ET, dim)) do tmp, a1, a2
    tmp .= a1 .+ a2 .* ET(2)
end
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Int64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Base.Broadcast.Extruded{CuArray{Int64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize!(::CuArray{Int64,2,Nothing}, ::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),Tuple{CuArray{Int64,2,Nothing},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{CuArray{Int64,2,Nothing},Int64}}}}) at ./broadcast.jl:823
   [32] (::Main.TestSuite.var"#159#181"{DataType})(::CuArray{Int64,2,Nothing}, ::CuArray{Int64,2,Nothing}, ::CuArray{Int64,2,Nothing}) at ./none:0
   [33] compare(::Function, ::Type{CuArray}, ::Array{Int64,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [34] compare(::Function, ::Type{CuArray}, ::Array{Int64,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:72 [inlined]
   [36] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [37] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:107
  Test threw exception
  Expression: compare((x->begin
            fill!(x, 1)
        end), AT, rand(ET, 3, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#10#11",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::GPUArrays.var"#10#11", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int64,2,CUDAnative.AS.Global},Int64}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int64,2,Nothing},Int64}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:46 [inlined]
   [28] fill! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:12 [inlined]
   [29] (::Main.TestSuite.var"#165#187")(::CuArray{Int64,2,Nothing}) at ./none:0
   [30] compare(::Function, ::Type{CuArray}, ::Array{Int64,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [31] compare(::Function, ::Type{CuArray}, ::Array{Int64,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:107 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:108
  Test threw exception
  Expression: compare(((x, y)->begin
            map(+, x, y)
        end), AT, rand(ET, 2, 3), rand(ET, 2, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Int64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Int64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Int64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),Tuple{CuArray{Int64,2,Nothing},CuArray{Int64,2,Nothing}}}) at ./broadcast.jl:820
   [33] map(::Function, ::CuArray{Int64,2,Nothing}, ::CuArray{Int64,2,Nothing}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:91
   [34] (::Main.TestSuite.var"#166#188")(::CuArray{Int64,2,Nothing}, ::CuArray{Int64,2,Nothing}) at ./none:0
   [35] compare(::Function, ::Type{CuArray}, ::Array{Int64,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [36] compare(::Function, ::Type{CuArray}, ::Array{Int64,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [37] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:108 [inlined]
   [38] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [39] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:110
  Test threw exception
  Expression: compare((x->begin
            2x
        end), AT, rand(ET, 2, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Int64,Base.Broadcast.Extruded{CuDeviceArray{Int64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Int64,Base.Broadcast.Extruded{CuArray{Int64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] broadcast_preserving_zero_d at ./broadcast.jl:809 [inlined]
   [34] * at ./arraymath.jl:52 [inlined]
   [35] (::Main.TestSuite.var"#167#189")(::CuArray{Int64,2,Nothing}) at ./none:0
   [36] compare(::Function, ::Type{CuArray}, ::Array{Int64,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [37] compare(::Function, ::Type{CuArray}, ::Array{Int64,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [38] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:110 [inlined]
   [39] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [40] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:111
  Test threw exception
  Expression: compare(((x, y)->begin
            x .+ y
        end), AT, rand(ET, 2, 3), rand(ET, 1, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Int64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Int64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Int64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] (::Main.TestSuite.var"#168#190")(::CuArray{Int64,2,Nothing}, ::CuArray{Int64,2,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Int64,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Int64,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:111 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:112
  Test threw exception
  Expression: compare(((z, x, y)->begin
            z .= x .+ y
        end), AT, rand(ET, 2, 3), rand(ET, 2, 3), rand(ET, 2))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Int64,1,CUDAnative.AS.Global},Tuple{Bool},Tuple{Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Int64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Int64,1,Nothing},Tuple{Bool},Tuple{Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize! at ./broadcast.jl:823 [inlined]
   [32] (::Main.TestSuite.var"#169#191")(::CuArray{Int64,2,Nothing}, ::CuArray{Int64,2,Nothing}, ::CuArray{Int64,1,Nothing}) at ./none:0
   [33] compare(::Function, ::Type{CuArray}, ::Array{Int64,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [34] compare(::Function, ::Type{CuArray}, ::Array{Int64,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:112 [inlined]
   [36] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [37] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:114
  Test threw exception
  Expression: compare((A->begin
            A .= identity.(ET(10))
        end), AT, rand(ET, 40, 40))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Int64}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:75 [inlined]
   [31] materialize!(::CuArray{Int64,2,Nothing}, ::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{0},Nothing,typeof(identity),Tuple{Int64}}) at ./broadcast.jl:823
   [32] (::Main.TestSuite.var"#170#192"{DataType})(::CuArray{Int64,2,Nothing}) at ./none:0
   [33] compare(::Function, ::Type{CuArray}, ::Array{Int64,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [34] compare(::Function, ::Type{CuArray}, ::Array{Int64,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:114 [inlined]
   [36] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [37] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:115
  Test threw exception
  Expression: compare((A->begin
            test_kernel.(A, ET(10))
        end), AT, rand(ET, 40, 40))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(Main.TestSuite.test_kernel),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Int64}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(Main.TestSuite.test_kernel),Tuple{Base.Broadcast.Extruded{CuArray{Int64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Int64}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(Main.TestSuite.test_kernel),Tuple{CuArray{Int64,2,Nothing},Int64}}) at ./broadcast.jl:820
   [33] (::Main.TestSuite.var"#171#193"{DataType})(::CuArray{Int64,2,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Int64,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Int64,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:115 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:116
  Test threw exception
  Expression: compare((A->begin
            A .* ET(10)
        end), AT, rand(ET, 40, 40))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Int64}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Base.Broadcast.Extruded{CuArray{Int64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Int64}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{CuArray{Int64,2,Nothing},Int64}}) at ./broadcast.jl:820
   [33] (::Main.TestSuite.var"#172#194"{DataType})(::CuArray{Int64,2,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Int64,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Int64,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:116 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:117
  Test threw exception
  Expression: compare(((A, B)->begin
            A .* B
        end), AT, rand(ET, 40, 40), rand(ET, 40, 40))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Int64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(*),Tuple{Base.Broadcast.Extruded{CuArray{Int64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Int64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] (::Main.TestSuite.var"#173#195")(::CuArray{Int64,2,Nothing}, ::CuArray{Int64,2,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Int64,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Int64,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:117 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Int64: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:118
  Test threw exception
  Expression: compare(((A, B)->begin
            A .* B .+ ET(10)
        end), AT, rand(ET, 40, 40), rand(ET, 40, 40))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Int64,2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Int64,2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}},Int64}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Int64,2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Base.Broadcast.Extruded{CuArray{Int64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Int64,2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}},Int64}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),Tuple{Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{CuArray{Int64,2,Nothing},CuArray{Int64,2,Nothing}}},Int64}}) at ./broadcast.jl:820
   [33] (::Main.TestSuite.var"#174#196"{DataType})(::CuArray{Int64,2,Nothing}, ::CuArray{Int64,2,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Int64,2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Int64,2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:118 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
RefValue: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Complex{Float32},1,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},typeof(Main.TestSuite.test_idx),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Int64,1,CUDAnative.AS.Global},Tuple{Bool},Tuple{Int64}},CUDAnative.CuRefValue{CuDeviceArray{Complex{Float32},1,CUDAnative.AS.Global}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Complex{Float32},1,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},typeof(Main.TestSuite.test_idx),Tuple{Base.Broadcast.Extruded{CuArray{Int64,1,Nothing},Tuple{Bool},Tuple{Int64}},Base.RefValue{CuArray{Complex{Float32},1,Nothing}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize!(::CuArray{Complex{Float32},1,Nothing}, ::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{1},Nothing,typeof(Main.TestSuite.test_idx),Tuple{CuArray{Int64,1,Nothing},Base.RefValue{CuArray{Complex{Float32},1,Nothing}}}}) at ./broadcast.jl:823
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:43 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:37 [inlined]
   [35] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [36] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
   [37] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:3 [inlined]
   [38] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [39] test_broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:3
   [40] test(::Type{CuArray}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:55
   [41] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [42] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   ... (the last 2 lines are repeated 1 more time)
   [45] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:40
   [46] include(::String) at ./client.jl:441
   [47] top-level scope at none:6
   [48] eval(::Module, ::Any) at ./boot.jl:331
   [49] exec_options(::Base.JLOptions) at ./client.jl:264
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
Tuple: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:49
  Test threw exception
  Expression: compare(AT, rand(ET, 3, N), rand(ET, 3, N), rand(ET, N), rand(ET, N), rand(ET, N)) do out, arr, a, b, c
    broadcast!(out, arr, (a, b, c)) do xx, yy
        xx + first(yy)
    end
end
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Complex{Float32},2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},Main.TestSuite.var"#156#178",Tuple{Base.Broadcast.Extruded{CuDeviceArray{Complex{Float32},2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Tuple{CuDeviceArray{Complex{Float32},1,CUDAnative.AS.Global},CuDeviceArray{Complex{Float32},1,CUDAnative.AS.Global},CuDeviceArray{Complex{Float32},1,CUDAnative.AS.Global}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Complex{Float32},2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},Main.TestSuite.var"#156#178",Tuple{Base.Broadcast.Extruded{CuArray{Complex{Float32},2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Tuple{CuArray{Complex{Float32},1,Nothing},CuArray{Complex{Float32},1,Nothing},CuArray{Complex{Float32},1,Nothing}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize! at ./broadcast.jl:823 [inlined]
   [32] broadcast! at ./broadcast.jl:797 [inlined]
   [33] (::Main.TestSuite.var"#155#177")(::CuArray{Complex{Float32},2,Nothing}, ::CuArray{Complex{Float32},2,Nothing}, ::CuArray{Complex{Float32},1,Nothing}, ::CuArray{Complex{Float32},1,Nothing}, ::CuArray{Complex{Float32},1,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Complex{Float32},2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Complex{Float32},2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:49 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:49 [inlined]
   [39] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [40] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
Adjoint and Transpose: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:56
  Got exception outside of a @test
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,LinearAlgebra.Adjoint{Complex{Float32},CuDeviceArray{Complex{Float32},1,CUDAnative.AS.Global}},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Complex{Float32}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{LinearAlgebra.Adjoint{Complex{Float32},CuArray{Complex{Float32},1,Nothing}},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(identity),Tuple{Complex{Float32}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:75 [inlined]
   [31] materialize!(::LinearAlgebra.Adjoint{Complex{Float32},CuArray{Complex{Float32},1,Nothing}}, ::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{0},Nothing,typeof(identity),Tuple{Complex{Float32}}}) at ./broadcast.jl:823
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:58 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:57 [inlined]
   [35] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [36] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
   [37] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:3 [inlined]
   [38] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [39] test_broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:3
   [40] test(::Type{CuArray}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:55
   [41] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:49
   [42] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114
   ... (the last 2 lines are repeated 1 more time)
   [45] top-level scope at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/test/runtests.jl:40
   [46] include(::String) at ./client.jl:441
   [47] top-level scope at none:6
   [48] eval(::Module, ::Any) at ./boot.jl:331
   [49] exec_options(::Base.JLOptions) at ./client.jl:264
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Complex{Float32}: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:66
  Test threw exception
  Expression: compare(((a, b)->begin
            a .+ b
        end), AT, rand(ET, 4, 5, 3), rand(ET, 1, 5, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Complex{Float32},3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Complex{Float32},3,CUDAnative.AS.Global},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Complex{Float32},3,CUDAnative.AS.Global},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Complex{Float32},3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Complex{Float32},3,Nothing},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}},Base.Broadcast.Extruded{CuArray{Complex{Float32},3,Nothing},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{3},Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{CuArray{Complex{Float32},3,Nothing},CuArray{Complex{Float32},3,Nothing}}}) at ./broadcast.jl:840
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] (::Main.TestSuite.var"#157#179")(::CuArray{Complex{Float32},3,Nothing}, ::CuArray{Complex{Float32},3,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Complex{Float32},3}, ::Vararg{Array{Complex{Float32},3},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Complex{Float32},3}, ::Vararg{Array{Complex{Float32},3},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:66 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Complex{Float32}: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:67
  Test threw exception
  Expression: compare(((a, b)->begin
            a .+ b
        end), AT, rand(ET, 4, 5, 3), rand(ET, 1, 5, 1))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Complex{Float32},3,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Complex{Float32},3,CUDAnative.AS.Global},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Complex{Float32},3,CUDAnative.AS.Global},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Complex{Float32},3,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Complex{Float32},3,Nothing},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}},Base.Broadcast.Extruded{CuArray{Complex{Float32},3,Nothing},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{3},Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{CuArray{Complex{Float32},3,Nothing},CuArray{Complex{Float32},3,Nothing}}}) at ./broadcast.jl:840
   [32] materialize at ./broadcast.jl:820 [inlined]
   [33] (::Main.TestSuite.var"#158#180")(::CuArray{Complex{Float32},3,Nothing}, ::CuArray{Complex{Float32},3,Nothing}) at ./none:0
   [34] compare(::Function, ::Type{CuArray}, ::Array{Complex{Float32},3}, ::Vararg{Array{Complex{Float32},3},N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [35] compare(::Function, ::Type{CuArray}, ::Array{Complex{Float32},3}, ::Vararg{Array{Complex{Float32},3},N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [36] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:67 [inlined]
   [37] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [38] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Complex{Float32}: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:72
  Test threw exception
  Expression: compare(AT, rand(ET, dim), rand(ET, dim), rand(ET, dim)) do tmp, a1, a2
    tmp .= a1 .+ a2 .* ET(2)
end
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Complex{Float32},2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Complex{Float32},2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Complex{Float32},2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Complex{Float32}}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Complex{Float32},2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Complex{Float32},2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{Base.Broadcast.Extruded{CuArray{Complex{Float32},2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Complex{Float32}}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] materialize!(::CuArray{Complex{Float32},2,Nothing}, ::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),Tuple{CuArray{Complex{Float32},2,Nothing},Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(*),Tuple{CuArray{Complex{Float32},2,Nothing},Complex{Float32}}}}}) at ./broadcast.jl:823
   [32] (::Main.TestSuite.var"#159#181"{DataType})(::CuArray{Complex{Float32},2,Nothing}, ::CuArray{Complex{Float32},2,Nothing}, ::CuArray{Complex{Float32},2,Nothing}) at ./none:0
   [33] compare(::Function, ::Type{CuArray}, ::Array{Complex{Float32},2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [34] compare(::Function, ::Type{CuArray}, ::Array{Complex{Float32},2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [35] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:72 [inlined]
   [36] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [37] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Complex{Float32}: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:107
  Test threw exception
  Expression: compare((x->begin
            fill!(x, 1)
        end), AT, rand(ET, 3, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{Nothing,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#10#11",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] cufunction(::GPUArrays.var"#10#11", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Complex{Float32},2,CUDAnative.AS.Global},Complex{Float32}}}; kwargs::Base.Iterators.Pairs{Symbol,Nothing,Tuple{Symbol},NamedTuple{(:name,),Tuple{Nothing}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:422
   [24] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [25] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Complex{Float32},2,Nothing},Complex{Float32}}, ::Int64; name::Nothing) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [26] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [27] gpu_call at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:46 [inlined]
   [28] fill! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/construction.jl:12 [inlined]
   [29] (::Main.TestSuite.var"#165#187")(::CuArray{Complex{Float32},2,Nothing}) at ./none:0
   [30] compare(::Function, ::Type{CuArray}, ::Array{Complex{Float32},2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [31] compare(::Function, ::Type{CuArray}, ::Array{Complex{Float32},2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [32] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:107 [inlined]
   [33] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [34] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
[ Info: Building the CUDAnative run-time library for your sm_75 device, this might take a while...
broadcast Complex{Float32}: Error During Test at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:108
  Test threw exception
  Expression: compare(((x, y)->begin
            map(+, x, y)
        end), AT, rand(ET, 2, 3), rand(ET, 2, 3))
  MethodError: no method matching Base.CodegenParams(; cached=false, track_allocations=false, code_coverage=false, static_alloc=false, prefer_specsig=true, module_setup=CUDAnative.var"#hook_module_setup#116"(Core.Box(#undef)), module_activation=CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), CUDAnative.var"#postprocess#115"(), Core.Box(nothing), DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}(Dict{Core.MethodInstance,Array{LLVM.Function,1}}()), Core.Box(#undef), Core.Box(#undef)), emit_function=CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.MethodInstance[]), emitted_function=CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}}(CUDAnative.CompilerJob for unbox_uint64(Any) (cap=7.5), Core.Box(nothing), Core.MethodInstance[]), gnu_pubnames=false, debug_info_kind=0)
  Closest candidates are:
    Base.CodegenParams(; track_allocations, code_coverage, static_alloc, prefer_specsig, gnu_pubnames, debug_info_kind, module_setup, module_activation, raise_exception, emit_function, emitted_function) at reflection.jl:986 got unsupported keyword argument "cached"
  Stacktrace:
   [1] kwerr(::NamedTuple{(:cached, :track_allocations, :code_coverage, :static_alloc, :prefer_specsig, :module_setup, :module_activation, :emit_function, :emitted_function, :gnu_pubnames, :debug_info_kind),Tuple{Bool,Bool,Bool,Bool,Bool,CUDAnative.var"#hook_module_setup#116",CUDAnative.var"#hook_module_activation#117"{CUDAnative.CompilerJob,CUDAnative.var"#postprocess#115",DataStructures.MultiDict{Core.MethodInstance,LLVM.Function}},CUDAnative.var"#hook_emit_function#120"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},CUDAnative.var"#hook_emitted_function#121"{CUDAnative.CompilerJob,Array{Core.MethodInstance,1}},Bool,Int32}}, ::Type{T} where T) at ./error.jl:157
   [2] compile_method_instance(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:151
   [3] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [4] irgen(::CUDAnative.CompilerJob, ::Core.MethodInstance, ::UInt64) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/irgen.jl:168
   [5] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [6] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:97 [inlined]
   [7] macro expansion at /home/pkgeval/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]
   [8] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:96
   [9] emit_function!(::LLVM.Module, ::VersionNumber, ::Function, ::Tuple{DataType}, ::String) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:130
   [10] build_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:140
   [11] (::CUDAnative.var"#156#159"{VersionNumber,String})() at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:175
   [12] get!(::CUDAnative.var"#156#159"{VersionNumber,String}, ::Dict{String,LLVM.Module}, ::String) at ./dict.jl:450
   [13] load_runtime(::VersionNumber) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/rtlib.jl:168
   [14] codegen(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:92
   [15] compile(::Symbol, ::CUDAnative.CompilerJob; libraries::Bool, dynamic_parallelism::Bool, optimize::Bool, strip::Bool, strict::Bool) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:45
   [16] #compile#169 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/compiler/driver.jl:33 [inlined]
   [17] cufunction_slow(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:326
   [18] #217 at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:393 [inlined]
   [19] get!(::CUDAnative.var"#217#218"{String,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},GPUArrays.var"#26#27",DataType,Int64}, ::Dict{UInt64,CUDAnative.HostKernel}, ::UInt64) at ./dict.jl:450
   [20] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:392 [inlined]
   [21] macro expansion at ./lock.jl:183 [inlined]
   [22] cufunction_fast(::Function, ::Type{T} where T, ::Int64; name::String, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:391
   [23] getproperty at ./Base.jl:33 [inlined]
   [24] merge at ./namedtuple.jl:253 [inlined]
   [25] cufunction(::GPUArrays.var"#26#27", ::Type{Tuple{CuArrays.CuKernelContext,CuDeviceArray{Complex{Float32},2,CUDAnative.AS.Global},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuDeviceArray{Complex{Float32},2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuDeviceArray{Complex{Float32},2,CUDAnative.AS.Global},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}}; kwargs::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:name,),Tuple{String}}}) at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:0
   [26] macro expansion at /home/pkgeval/.julia/packages/CUDAnative/j8fTC/src/execution.jl:157 [inlined]
   [27] gpu_call(::CuArrays.CuArrayBackend, ::Function, ::Tuple{CuArray{Complex{Float32},2,Nothing},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},typeof(+),Tuple{Base.Broadcast.Extruded{CuArray{Complex{Float32},2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}},Base.Broadcast.Extruded{CuArray{Complex{Float32},2,Nothing},Tuple{Bool,Bool},Tuple{Int64,Int64}}}}}, ::Int64; name::String) at /home/pkgeval/.julia/packages/CuArrays/WPJ2b/src/gpuarrays.jl:32
   [28] #gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/device/execution.jl:60 [inlined]
   [29] copyto! at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:63 [inlined]
   [30] copyto! at ./broadcast.jl:864 [inlined]
   [31] copy at ./broadcast.jl:840 [inlined]
   [32] materialize(::Base.Broadcast.Broadcasted{CuArrays.CuArrayStyle{2},Nothing,typeof(+),Tuple{CuArray{Complex{Float32},2,Nothing},CuArray{Complex{Float32},2,Nothing}}}) at ./broadcast.jl:820
   [33] map(::Function, ::CuArray{Complex{Float32},2,Nothing}, ::CuArray{Complex{Float32},2,Nothing}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/src/host/broadcast.jl:91
   [34] (::Main.TestSuite.var"#166#188")(::CuArray{Complex{Float32},2,Nothing}, ::CuArray{Complex{Float32},2,Nothing}) at ./none:0
   [35] compare(::Function, ::Type{CuArray}, ::Array{Complex{Float32},2}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:23
   [36] compare(::Function, ::Type{CuArray}, ::Array{Complex{Float32},2}, ::Vararg{Any,N} where N) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite.jl:20
   [37] macro expansion at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:108 [inlined]
   [38] macro expansion at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1114 [inlined]
   [39] broadcasting(::Type{T} where T) at /home/pkgeval/.julia/packages/GPUArrays/QDGmr/test/testsuite/broadcasting.jl:36
  
