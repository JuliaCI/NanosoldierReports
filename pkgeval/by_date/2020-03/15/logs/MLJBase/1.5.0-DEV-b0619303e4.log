Julia Version 1.5.0-DEV.462
Commit b0619303e4 (2020-03-15 15:46 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
  Installed SortingAlgorithms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.1
  Installed ProgressMeter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.2.0
  Installed Compat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v3.8.0
  Installed QuadGK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.3.1
  Installed Syslogs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.0
  Installed JLSO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.1.0
  Installed DataStructures â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.17.10
  Installed MLJBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.1
  Installed FixedPointNumbers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.1
  Installed IniFile â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.0
  Installed BinaryProvider â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.8
  Installed OpenSpecFun_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.3+3
  Installed ScientificTypes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.2
  Installed Reexport â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.0
  Installed Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.0
  Installed MLJModelInterface â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.0
  Installed CategoricalArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.7
  Installed StatsFuns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.4
  Installed OpenBLAS_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.7+7
  Installed TableTraits â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
  Installed MbedTLS_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.16.0+1
  Installed Parsers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.12
  Installed RecipesBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.0
  Installed Tables â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.3
  Installed HTTP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.12
  Installed DataValueInterfaces â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
  Installed Arpack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
  Installed OrderedCollections â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
  Installed TranscodingStreams â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.5
  Installed Arpack_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v3.5.0+2
  Installed Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.1
  Installed JSON â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.21.0
  Installed SpecialFunctions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.10.0
  Installed Libiconv_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.16.0+1
  Installed InvertedIndices â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
  Installed Missings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.3
  Installed Crayons â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v4.0.1
  Installed XML2_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.9.9+1
  Installed IteratorInterfaceExtensions â”€â”€ v1.0.0
  Installed ExprTools â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.1.0
  Installed ComputationalResources â”€â”€â”€â”€â”€â”€â”€ v0.3.1
  Installed PrettyTables â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.4
  Installed Distributions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.22.5
  Installed LearnBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.2
  Installed Mocking â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.1
  Installed FillArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.5
  Installed MbedTLS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.1
  Installed Rmath_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.2+0
  Installed StatsBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.32.2
  Installed LossFunctions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.1
  Installed TimeZones â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.1
  Installed CodecZlib â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
  Installed Memento â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.1
  Installed CompilerSupportLibraries_jll â”€ v0.2.0+1
  Installed Zlib_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.2.11+8
  Installed DataAPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
  Installed Formatting â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.1
  Installed EzXML â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
  Installed ColorTypes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.1
  Installed MLJScientificTypes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.1
  Installed PDMats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.12
  Installed BSON â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.5
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                         ##                                                                         3.0%#####                                                                      7.8%##########                                                                14.1%###############                                                           21.1%#####################                                                     30.1%#############################                                             41.1%########################################                                  55.7%####################################################                      73.4%######################################################################    98.3%######################################################################## 100.0%
#=#=#                                                                         #######################                                                   33.0%######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                         ############################################################              84.4%######################################################################## 100.0%
#=#=#                                                                         ##########                                                                14.1%#####################################                                     52.1%######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                         ######################################################################## 100.0%
#=#=#                                                                         ####                                                                       6.1%###############                                                           22.0%############################                                              40.3%##################################################                        69.7%######################################################################## 100.0%
   Updating `~/.julia/environments/v1.5/Project.toml`
   a7f614a8 + MLJBase v0.12.1
   Updating `~/.julia/environments/v1.5/Manifest.toml`
   7d9fca2a + Arpack v0.4.0
   68821587 + Arpack_jll v3.5.0+2
   fbb218c0 + BSON v0.2.5
   b99e7846 + BinaryProvider v0.5.8
   324d7699 + CategoricalArrays v0.7.7
   944b1d66 + CodecZlib v0.6.0
   3da002f7 + ColorTypes v0.9.1
   34da2185 + Compat v3.8.0
   e66e0078 + CompilerSupportLibraries_jll v0.2.0+1
   ed09eef8 + ComputationalResources v0.3.1
   a8cc5b0e + Crayons v4.0.1
   9a962f9c + DataAPI v1.1.0
   864edb3b + DataStructures v0.17.10
   e2d170a0 + DataValueInterfaces v1.0.0
   31c24e10 + Distributions v0.22.5
   e2ba6199 + ExprTools v0.1.0
   8f5d6c58 + EzXML v1.1.0
   1a297f60 + FillArrays v0.8.5
   53c48c17 + FixedPointNumbers v0.7.1
   59287772 + Formatting v0.4.1
   cd3eb016 + HTTP v0.8.12
   83e8ac13 + IniFile v0.5.0
   41ab1584 + InvertedIndices v1.0.0
   82899510 + IteratorInterfaceExtensions v1.0.0
   9da8a3cd + JLSO v2.1.0
   682c06a0 + JSON v0.21.0
   7f8f8fb0 + LearnBase v0.2.2
   94ce4f54 + Libiconv_jll v1.16.0+1
   30fc2ffe + LossFunctions v0.5.1
   a7f614a8 + MLJBase v0.12.1
   e80e1ace + MLJModelInterface v0.2.0
   2e2323e0 + MLJScientificTypes v0.2.1
   739be429 + MbedTLS v1.0.1
   c8ffd9c3 + MbedTLS_jll v2.16.0+1
   f28f55f0 + Memento v0.12.1
   e1d29d7a + Missings v0.4.3
   78c3b35d + Mocking v0.7.1
   4536629a + OpenBLAS_jll v0.3.7+7
   efe28fd5 + OpenSpecFun_jll v0.5.3+3
   bac558e1 + OrderedCollections v1.1.0
   90014a1f + PDMats v0.9.12
   d96e819e + Parameters v0.12.0
   69de0a69 + Parsers v0.3.12
   08abe8d2 + PrettyTables v0.8.4
   92933f4c + ProgressMeter v1.2.0
   1fd47b50 + QuadGK v2.3.1
   3cdcf5f2 + RecipesBase v0.8.0
   189a3867 + Reexport v0.2.0
   79098fc4 + Rmath v0.6.1
   f50d1b31 + Rmath_jll v0.2.2+0
   321657f4 + ScientificTypes v0.7.2
   a2af1166 + SortingAlgorithms v0.3.1
   276daf66 + SpecialFunctions v0.10.0
   2913bbd2 + StatsBase v0.32.2
   4c63d2b9 + StatsFuns v0.9.4
   cea106d9 + Syslogs v0.3.0
   3783bdb8 + TableTraits v1.0.0
   bd369af6 + Tables v1.0.3
   f269a46b + TimeZones v1.0.1
   3bb67fe8 + TranscodingStreams v0.9.5
   02c8fc9c + XML2_jll v2.9.9+1
   83775a58 + Zlib_jll v1.2.11+8
   2a0f44e3 + Base64
   ade2ca70 + Dates
   8bb1440f + DelimitedFiles
   8ba89e20 + Distributed
   9fa8497b + Future
   b77e0a4c + InteractiveUtils
   76f85450 + LibGit2
   8f399da3 + Libdl
   37e2e46d + LinearAlgebra
   56ddb016 + Logging
   d6f4376e + Markdown
   a63ad114 + Mmap
   44cfe95a + Pkg
   de0858da + Printf
   3fa0cd96 + REPL
   9a3f8284 + Random
   ea8e919c + SHA
   9e88b42a + Serialization
   1a1011a3 + SharedArrays
   6462fe0b + Sockets
   2f01184e + SparseArrays
   10745b16 + Statistics
   4607b0f0 + SuiteSparse
   8dfed614 + Test
   cf7118a7 + UUIDs
   4ec0a83e + Unicode
   Building TimeZones â†’ `~/.julia/packages/TimeZones/zymSN/deps/build.log`
   Building CodecZlib â†’ `~/.julia/packages/CodecZlib/5t9zO/deps/build.log`
    Testing MLJBase
     Status `/tmp/jl_gYP1Cg/Project.toml`
   336ed68f CSV v0.5.26
   324d7699 CategoricalArrays v0.7.7
   ed09eef8 ComputationalResources v0.3.1
   a93c6f00 DataFrames v0.20.2
   7806a523 DecisionTree v0.10.1
   b4f34e82 Distances v0.8.2
   31c24e10 Distributions v0.22.5
   cd3eb016 HTTP v0.8.12
   41ab1584 InvertedIndices v1.0.0
   9da8a3cd JLSO v2.1.0
   682c06a0 JSON v0.21.0
   30fc2ffe LossFunctions v0.5.1
   a7f614a8 MLJBase v0.12.1
   e80e1ace MLJModelInterface v0.2.0
   2e2323e0 MLJScientificTypes v0.2.1
   e1d29d7a Missings v0.4.3
   6f286f6a MultivariateStats v0.7.0
   b8a86587 NearestNeighbors v0.4.4
   bac558e1 OrderedCollections v1.1.0
   d96e819e Parameters v0.12.0
   08abe8d2 PrettyTables v0.8.4
   92933f4c ProgressMeter v1.2.0
   321657f4 ScientificTypes v0.7.2
   2913bbd2 StatsBase v0.32.2
   bd369af6 Tables v1.0.3
   9d95f2ec TypedTables v1.2.0
   8bb1440f DelimitedFiles
   8ba89e20 Distributed
   b77e0a4c InteractiveUtils
   37e2e46d LinearAlgebra
   56ddb016 Logging
   9a3f8284 Random
   10745b16 Statistics
   8dfed614 Test
     Status `/tmp/jl_gYP1Cg/Manifest.toml`
   7d9fca2a Arpack v0.4.0
   68821587 Arpack_jll v3.5.0+2
   fbb218c0 BSON v0.2.5
   b99e7846 BinaryProvider v0.5.8
   336ed68f CSV v0.5.26
   324d7699 CategoricalArrays v0.7.7
   944b1d66 CodecZlib v0.6.0
   3da002f7 ColorTypes v0.9.1
   34da2185 Compat v3.8.0
   e66e0078 CompilerSupportLibraries_jll v0.2.0+1
   ed09eef8 ComputationalResources v0.3.1
   a8cc5b0e Crayons v4.0.1
   9a962f9c DataAPI v1.1.0
   a93c6f00 DataFrames v0.20.2
   864edb3b DataStructures v0.17.10
   e2d170a0 DataValueInterfaces v1.0.0
   7806a523 DecisionTree v0.10.1
   85a47980 Dictionaries v0.2.1
   b4f34e82 Distances v0.8.2
   31c24e10 Distributions v0.22.5
   e2ba6199 ExprTools v0.1.0
   8f5d6c58 EzXML v1.1.0
   48062228 FilePathsBase v0.7.0
   1a297f60 FillArrays v0.8.5
   53c48c17 FixedPointNumbers v0.7.1
   59287772 Formatting v0.4.1
   cd3eb016 HTTP v0.8.12
   313cdc1a Indexing v1.1.0
   83e8ac13 IniFile v0.5.0
   41ab1584 InvertedIndices v1.0.0
   82899510 IteratorInterfaceExtensions v1.0.0
   9da8a3cd JLSO v2.1.0
   682c06a0 JSON v0.21.0
   7f8f8fb0 LearnBase v0.2.2
   94ce4f54 Libiconv_jll v1.16.0+1
   30fc2ffe LossFunctions v0.5.1
   a7f614a8 MLJBase v0.12.1
   e80e1ace MLJModelInterface v0.2.0
   2e2323e0 MLJScientificTypes v0.2.1
   739be429 MbedTLS v1.0.1
   c8ffd9c3 MbedTLS_jll v2.16.0+1
   f28f55f0 Memento v0.12.1
   e1d29d7a Missings v0.4.3
   78c3b35d Mocking v0.7.1
   6f286f6a MultivariateStats v0.7.0
   b8a86587 NearestNeighbors v0.4.4
   4536629a OpenBLAS_jll v0.3.7+7
   efe28fd5 OpenSpecFun_jll v0.5.3+3
   bac558e1 OrderedCollections v1.1.0
   90014a1f PDMats v0.9.12
   d96e819e Parameters v0.12.0
   69de0a69 Parsers v0.3.12
   2dfb63ee PooledArrays v0.5.3
   08abe8d2 PrettyTables v0.8.4
   92933f4c ProgressMeter v1.2.0
   1fd47b50 QuadGK v2.3.1
   3cdcf5f2 RecipesBase v0.8.0
   189a3867 Reexport v0.2.0
   79098fc4 Rmath v0.6.1
   f50d1b31 Rmath_jll v0.2.2+0
   321657f4 ScientificTypes v0.7.2
   6e75b9c4 ScikitLearnBase v0.5.0
   a2af1166 SortingAlgorithms v0.3.1
   276daf66 SpecialFunctions v0.10.0
   03a91e81 SplitApplyCombine v1.0.0
   90137ffa StaticArrays v0.12.1
   2913bbd2 StatsBase v0.32.2
   4c63d2b9 StatsFuns v0.9.4
   cea106d9 Syslogs v0.3.0
   3783bdb8 TableTraits v1.0.0
   bd369af6 Tables v1.0.3
   f269a46b TimeZones v1.0.1
   3bb67fe8 TranscodingStreams v0.9.5
   9d95f2ec TypedTables v1.2.0
   ea10d353 WeakRefStrings v0.6.2
   02c8fc9c XML2_jll v2.9.9+1
   83775a58 Zlib_jll v1.2.11+8
   2a0f44e3 Base64
   ade2ca70 Dates
   8bb1440f DelimitedFiles
   8ba89e20 Distributed
   9fa8497b Future
   b77e0a4c InteractiveUtils
   76f85450 LibGit2
   8f399da3 Libdl
   37e2e46d LinearAlgebra
   56ddb016 Logging
   d6f4376e Markdown
   a63ad114 Mmap
   44cfe95a Pkg
   de0858da Printf
   3fa0cd96 REPL
   9a3f8284 Random
   ea8e919c SHA
   9e88b42a Serialization
   1a1011a3 SharedArrays
   6462fe0b Sockets
   2f01184e SparseArrays
   10745b16 Statistics
   4607b0f0 SuiteSparse
   8dfed614 Test
   cf7118a7 UUIDs
   4ec0a83e Unicode
[ Info: nprocs() = 41
[ Info: nthreads() = 2
Loading some models for testing...                                           Test Summary: | Pass  Total
misc          |   94     94
Test Summary: | Pass  Total
interface     |   78     78
Test Summary: | Pass  Total
measures      |  211    211
Progress:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                  |  ETA: 0:00:07[KProgress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:01[K
Progress:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                  |  ETA: 0:00:18[KProgress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             |  ETA: 0:00:02[KProgress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      |  ETA: 0:00:01[KProgress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:04[K
Progress:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                  |  ETA: 0:00:02[KProgress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      |  ETA: 0:00:00[KProgress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:00[K
[ Info: Updating [34mMachine{Resampler{Holdout,â€¦}} @ 6â€¦60[39m.
[ Info: Updating [34mMachine{Resampler{Holdout,â€¦}} @ 6â€¦63[39m.
[ Info: Updating [34mMachine{Resampler{Holdout,â€¦}} @ 2â€¦10[39m.
[ Info: Distributing evaluations among 40 workers.
[ Info: Creating subsamples from a subset of all rows. 
[ Info: Training [34mMachine{Resampler{CV,â€¦}} @ 6â€¦17[39m.
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Training [34mMachine{Resampler{CV,â€¦}} @ 1â€¦71[39m.
[ Info: Creating subsamples from a subset of all rows. 
[ Info: Training [34mMachine{Resampler{CV,â€¦}} @ 1â€¦48[39m.
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Training [34mMachine{Resampler{CV,â€¦}} @ 2â€¦36[39m.
[ Info: Creating subsamples from a subset of all rows. 
[ Info: Training [34mMachine{Resampler{CV,â€¦}} @ 1â€¦72[39m.
[ Info: Passing machine sample weights to any supported measures. 
[ Info: Training [34mMachine{Resampler{CV,â€¦}} @ 1â€¦22[39m.
Test Summary: | Pass  Total
resampling    |  125    125
Test Summary: | Pass  Total
data          |  119    119
[ Info: Training [34mMachine{ConstantClassifier} @ 1â€¦96[39m.
[ Info: Training [34mMachine{ConstantClassifier} @ 4â€¦66[39m.
[ Info: Training [34mNodalMachine{Scale} @ 1â€¦47[39m.
[ Info: Training [34mMachine{DecisionTreeRegressor} @ 7â€¦25[39m.
[ Info: Training [34mMachine{DecisionTreeRegressor} @ 1â€¦71[39m.
[ Info: Training [34mMachine{DecisionTreeRegressor} @ 1â€¦00[39m.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 1â€¦89[39m.
[ Info: Training [34mNodalMachine{FooBarRegressor} @ 1â€¦73[39m.
[ Info: Training [34mNodalMachine{SimpleDeterministicCompositeModel{FooBarRegressor,â€¦}} @ 5â€¦26[39m.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 2â€¦23[39m.
[ Info: Training [34mNodalMachine{FooBarRegressor} @ 1â€¦97[39m.
[ Info: Updating [34mNodalMachine{SimpleDeterministicCompositeModel{FooBarRegressor,â€¦}} @ 5â€¦26[39m.
[ Info: Updating [34mNodalMachine{FeatureSelector} @ 2â€¦23[39m.
[ Info: Training [34mNodalMachine{FooBarRegressor} @ 1â€¦97[39m.
[ Info: Training [34mNodalMachine{SimpleDeterministicCompositeModel{FooBarRegressor,â€¦}} @ 5â€¦26[39m.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 1â€¦64[39m.
[ Info: Training [34mNodalMachine{FooBarRegressor} @ 1â€¦74[39m.
[ Info: Training [34mMachine{WrappedRidge} @ 4â€¦90[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 7â€¦79[39m.
[ Info: Training [34mNodalMachine{UnivariateBoxCoxTransformer} @ 1â€¦60[39m.
[ Info: Training [34mNodalMachine{FooBarRegressor} @ 6â€¦95[39m.
[ Info: Updating [34mMachine{WrappedRidge} @ 4â€¦90[39m.
â”Œ Info: Not retraining [34mNodalMachine{Standardizer} @ 7â€¦79[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
â”Œ Info: Not retraining [34mNodalMachine{UnivariateBoxCoxTransformer} @ 1â€¦60[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
[ Info: Updating [34mNodalMachine{FooBarRegressor} @ 6â€¦95[39m.
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 8â€¦14[39m.
[ Info: Spawning 3 sub-features to one-hot encode feature :x1.
[ Info: Training [34mNodalMachine{UnivariateStandardizer} @ 4â€¦04[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 1â€¦27[39m.
[ Info: Training [34mNodalMachine{DecisionTreeRegressor} @ 1â€¦19[39m.
train_args = Source{:input}[[34mSource{:input} @ 1â€¦47[39m]
mach.model = [34mOneHotEncoder @ 7â€¦72[39m
train_args = Node{Nothing}[[34mNode{Nothing} @ 9â€¦31[39m]
mach.model = UnivariateStandardizer @ 1â€¦32
train_args = Node[[34mNode{NodalMachine{OneHotEncoder}} @ 7â€¦38[39m, [34mNode{NodalMachine{UnivariateStandardizer}} @ 1â€¦21[39m]
mach.model = [34mKNNRegressor @ 8â€¦85[39m
train_args = Node[[34mNode{NodalMachine{OneHotEncoder}} @ 7â€¦38[39m, [34mNode{NodalMachine{UnivariateStandardizer}} @ 1â€¦21[39m]
mach.model = [34mDecisionTreeRegressor @ 5â€¦23[39m
train_args = Source{:input}[[34mSource{:input} @ 1â€¦37[39m]
mach.model = [34mOneHotEncoder @ 7â€¦72[39m
train_args = Node{Nothing}[[34mNode{Nothing} @ 7â€¦77[39m]
mach.model = UnivariateStandardizer @ 4â€¦87
train_args = Node[[34mNode{NodalMachine{OneHotEncoder}} @ 1â€¦40[39m, [34mNode{NodalMachine{UnivariateStandardizer}} @ 1â€¦15[39m]
mach.model = [34mKNNRegressor @ 8â€¦85[39m
train_args = Node[[34mNode{NodalMachine{OneHotEncoder}} @ 1â€¦40[39m, [34mNode{NodalMachine{UnivariateStandardizer}} @ 1â€¦15[39m]
mach.model = [34mDecisionTreeRegressor @ 8â€¦94[39m
train_args = Source{:input}[[34mSource{:input} @ 1â€¦02[39m]
mach.model = [34mOneHotEncoder @ 1â€¦88[39m
train_args = Node{Nothing}[[34mNode{Nothing} @ 4â€¦13[39m]
mach.model = UnivariateStandardizer @ 2â€¦53
train_args = Node[[34mNode{NodalMachine{OneHotEncoder}} @ 5â€¦26[39m, [34mNode{NodalMachine{UnivariateStandardizer}} @ 2â€¦11[39m]
mach.model = [34mKNNRegressor @ 8â€¦61[39m
train_args = Node[[34mNode{NodalMachine{OneHotEncoder}} @ 5â€¦26[39m, [34mNode{NodalMachine{UnivariateStandardizer}} @ 2â€¦11[39m]
mach.model = [34mDecisionTreeRegressor @ 1â€¦55[39m
train_args = Source{:input}[[34mSource{:input} @ 1â€¦95[39m]
mach.model = [34mOneHotEncoder @ 6â€¦28[39m
train_args = Node{NodalMachine{OneHotEncoder}}[[34mNode{NodalMachine{OneHotEncoder}} @ 9â€¦66[39m]
mach.model = [34mStandardizer @ 1â€¦29[39m
[ Info: Training [34mNodalMachine{Standardizer} @ 9â€¦18[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 5â€¦52[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 9â€¦18[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 5â€¦52[39m.
[ Info: Training [34mMachine{Composite3} @ 7â€¦51[39m.
train_args = Source{:input}[[34mSource{:input} @ 3â€¦78[39m]
mach.model = [34mStandardizer @ 6â€¦68[39m
train_args = AbstractNode[[34mNode{NodalMachine{Standardizer}} @ 1â€¦85[39m, [34mSource{:target} @ 1â€¦24[39m, [34mSource{:weights} @ 1â€¦23[39m]
mach.model = ConstantClassifier @ 1â€¦08
[ Info: Training [34mNodalMachine{Standardizer} @ 5â€¦74[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 4â€¦52[39m.
[ Info: Training [34mMachine{Composite3} @ 1â€¦84[39m.
train_args = Source{:input}[[34mSource{:input} @ 1â€¦01[39m]
mach.model = [34mStandardizer @ 1â€¦49[39m
train_args = AbstractNode[[34mNode{NodalMachine{Standardizer}} @ 3â€¦69[39m, [34mSource{:target} @ 4â€¦30[39m, [34mSource{:weights} @ 2â€¦23[39m]
mach.model = ConstantClassifier @ 1â€¦08
[ Info: Training [34mNodalMachine{Standardizer} @ 1â€¦88[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 1â€¦99[39m.
[ Info: Training [34mMachine{CompositeWithNoFields} @ 1â€¦63[39m.
train_args = Source{:input}[[34mSource{:input} @ 1â€¦41[39m]
mach.model = [34mStandardizer @ 4â€¦92[39m
train_args = AbstractNode[[34mNode{NodalMachine{Standardizer}} @ 1â€¦46[39m, [34mSource{:target} @ 1â€¦63[39m, [34mSource{:weights} @ 1â€¦34[39m]
mach.model = ConstantClassifier @ 1â€¦08
[ Info: Training [34mNodalMachine{Standardizer} @ 8â€¦89[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 1â€¦85[39m.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 5â€¦88[39m.
[ Info: Training [34mNodalMachine{UnivariateStandardizer} @ 2â€¦17[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 1â€¦35[39m.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 1â€¦15[39m.
[ Info: Training [34mNodalMachine{UnivariateStandardizer} @ 1â€¦54[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 4â€¦74[39m.
[ Info: Updating [34mNodalMachine{FeatureSelector} @ 5â€¦88[39m.
â”Œ Info: Not retraining [34mNodalMachine{UnivariateStandardizer} @ 2â€¦17[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 1â€¦35[39m.
[ Info: Updating [34mNodalMachine{FeatureSelector} @ 1â€¦15[39m.
â”Œ Info: Not retraining [34mNodalMachine{UnivariateStandardizer} @ 1â€¦54[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 4â€¦74[39m.
[ Info: Training [34mMachine{Pipe} @ 1â€¦06[39m.
train_args = Source{:input}[[34mSource{:input} @ 1â€¦59[39m]
mach.model = [34mFeatureSelector @ 6â€¦17[39m
train_args = Source{:target}[[34mSource{:target} @ 1â€¦25[39m]
mach.model = UnivariateStandardizer @ 1â€¦37
train_args = AbstractNode[[34mNode{NodalMachine{FeatureSelector}} @ 1â€¦59[39m, [34mNode{NodalMachine{UnivariateStandardizer}} @ 3â€¦59[39m, [34mSource{:weights} @ 1â€¦07[39m]
mach.model = [34mKNNRegressor @ 1â€¦40[39m
[ Info: Training [34mNodalMachine{FeatureSelector} @ 9â€¦14[39m.
[ Info: Training [34mNodalMachine{UnivariateStandardizer} @ 1â€¦57[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 1â€¦60[39m.
[ Info: Training [34mMachine{Pipe21} @ 1â€¦01[39m.
train_args = Source{:input}[[34mSource{:input} @ 4â€¦79[39m]
mach.model = [34mOneHotEncoder @ 5â€¦71[39m
train_args = AbstractNode[[34mNode{NodalMachine{OneHotEncoder}} @ 6â€¦74[39m, [34mSource{:target} @ 8â€¦98[39m, [34mSource{:weights} @ 1â€¦23[39m]
mach.model = ConstantClassifier @ 1â€¦08
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 1â€¦16[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 1â€¦41[39m.
[ Info: Training [34mMachine{Piper3} @ 1â€¦75[39m.
train_args = Source{:input}[[34mSource{:input} @ 3â€¦14[39m]
mach.model = [34mOneHotEncoder @ 2â€¦51[39m
train_args = AbstractNode[[34mNode{NodalMachine{OneHotEncoder}} @ 1â€¦93[39m, [34mSource{:target} @ 1â€¦59[39m, [34mSource{:weights} @ 4â€¦95[39m]
mach.model = ConstantClassifier @ 1â€¦08
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 1â€¦74[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 1â€¦84[39m.
[ Info: Training [34mMachine{Piper3} @ 7â€¦30[39m.
train_args = Source{:input}[[34mSource{:input} @ 8â€¦92[39m]
mach.model = [34mOneHotEncoder @ 2â€¦51[39m
train_args = AbstractNode[[34mNode{NodalMachine{OneHotEncoder}} @ 2â€¦29[39m, [34mSource{:target} @ 1â€¦87[39m, [34mSource{:weights} @ 1â€¦33[39m]
mach.model = ConstantClassifier @ 1â€¦08
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 4â€¦64[39m.
[ Info: Training [34mNodalMachine{ConstantClassifier} @ 6â€¦19[39m.
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 1â€¦54[39m.
[ Info: Spawning 3 sub-features to one-hot encode feature :x3.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 9â€¦73[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 7â€¦60[39m.
[ Info: Training [34mMachine{Pipe4} @ 2â€¦17[39m.
train_args = Source{:input}[[34mSource{:input} @ 8â€¦38[39m]
mach.model = [34mOneHotEncoder @ 1â€¦35[39m
train_args = Node{NodalMachine{OneHotEncoder}}[[34mNode{NodalMachine{OneHotEncoder}} @ 1â€¦88[39m]
mach.model = [34mFeatureSelector @ 1â€¦67[39m
train_args = Source{:target}[[34mSource{:target} @ 1â€¦42[39m]
mach.model = [34mStaticTransformer @ 9â€¦27[39m
train_args = AbstractNode[[34mNode{NodalMachine{FeatureSelector}} @ 4â€¦65[39m, [34mNode{NodalMachine{StaticTransformer}} @ 6â€¦44[39m, [34mSource{:weights} @ 1â€¦28[39m]
mach.model = [34mKNNRegressor @ 1â€¦22[39m
train_args = Node{NodalMachine{KNNRegressor}}[[34mNode{NodalMachine{KNNRegressor}} @ 5â€¦18[39m]
mach.model = [34mStaticTransformer @ 1â€¦28[39m
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 1â€¦04[39m.
[ Info: Spawning 3 sub-features to one-hot encode feature :x3.
[ Info: Training [34mNodalMachine{FeatureSelector} @ 8â€¦91[39m.
[ Info: Training [34mNodalMachine{StaticTransformer} @ 1â€¦23[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 1â€¦99[39m.
[ Info: Training [34mNodalMachine{StaticTransformer} @ 4â€¦44[39m.
[ Info: Training [34mMachine{Pipe9} @ 7â€¦40[39m.
train_args = Node{Nothing}[[34mNode{Nothing} @ 4â€¦75[39m]
mach.model = [34mOneHotEncoder @ 7â€¦13[39m
train_args = Source{:target}[[34mSource{:target} @ 1â€¦41[39m]
mach.model = UnivariateStandardizer @ 2â€¦41
train_args = AbstractNode[[34mNode{NodalMachine{OneHotEncoder}} @ 1â€¦09[39m, [34mNode{NodalMachine{UnivariateStandardizer}} @ 2â€¦15[39m, [34mSource{:weights} @ 9â€¦24[39m]
mach.model = [34mKNNRegressor @ 1â€¦40[39m
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 1â€¦14[39m.
[ Info: Spawning 2 sub-features to one-hot encode feature :gender.
[ Info: Training [34mNodalMachine{UnivariateStandardizer} @ 1â€¦93[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 4â€¦71[39m.
[ Info: Training [34mMachine{Pipe99} @ 1â€¦08[39m.
train_args = Node{Nothing}[[34mNode{Nothing} @ 1â€¦88[39m]
mach.model = [34mOneHotEncoder @ 1â€¦21[39m
train_args = Node{NodalMachine{OneHotEncoder}}[[34mNode{NodalMachine{OneHotEncoder}} @ 1â€¦32[39m]
mach.model = [34mMyTransformer @ 1â€¦12[39m
[ Info: Training [34mNodalMachine{OneHotEncoder} @ 1â€¦07[39m.
[ Info: Spawning 2 sub-features to one-hot encode feature :gender.
[ Info: Training [34mNodalMachine{MyTransformer} @ 1â€¦23[39m.
â”Œ Info: Not retraining [34mNodalMachine{KNNRegressor} @ 7â€¦99[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
[ Info: Training [34mMachine{KNNRegressor} @ 3â€¦36[39m.
[ Info: Training [34mNodalMachine{MyTransformer1} @ 8â€¦99[39m.
train_args = Node{Nothing}[[34mNode{Nothing} @ 8â€¦71[39m]
mach.model = [34mStandardizer @ 7â€¦51[39m
train_args = Source{:target}[[34mSource{:target} @ 5â€¦59[39m]
mach.model = [34mUnivariateBoxCoxTransformer @ 1â€¦44[39m
train_args = AbstractNode[[34mNode{NodalMachine{Standardizer}} @ 7â€¦97[39m, [34mNode{NodalMachine{UnivariateBoxCoxTransformer}} @ 1â€¦69[39m, [34mSource{:weights} @ 8â€¦51[39m]
mach.model = [34mKNNRegressor @ 1â€¦28[39m
train_args = Source{:input}[[34mSource{:input} @ 7â€¦36[39m]
mach.model = [34mMyTransformer @ 1â€¦24[39m
train_args = Node{NodalMachine{Main.TestLearningNetworks.MyTransformer}}[[34mNode{NodalMachine{MyTransformer}} @ 1â€¦35[39m]
mach.model = [34mStandardizer @ 1â€¦79[39m
train_args = Source{:target}[[34mSource{:target} @ 9â€¦85[39m]
mach.model = [34mUnivariateBoxCoxTransformer @ 1â€¦30[39m
train_args = AbstractNode[[34mNode{NodalMachine{Standardizer}} @ 1â€¦86[39m, [34mNode{NodalMachine{UnivariateBoxCoxTransformer}} @ 1â€¦77[39m, [34mSource{:weights} @ 1â€¦40[39m]
mach.model = [34mKNNRegressor @ 1â€¦22[39m
train_args = Node{Nothing}[[34mNode{Nothing} @ 1â€¦81[39m]
mach.model = [34mStandardizer @ 8â€¦08[39m
train_args = Source{:target}[[34mSource{:target} @ 7â€¦08[39m]
mach.model = [34mUnivariateBoxCoxTransformer @ 1â€¦86[39m
train_args = Node[[34mNode{NodalMachine{Standardizer}} @ 1â€¦05[39m, [34mNode{NodalMachine{UnivariateBoxCoxTransformer}} @ 1â€¦92[39m]
mach.model = [34mKNNRegressor @ 1â€¦60[39m
train_args = Union{}[]
mach.model = [34mMyTransformer @ 1â€¦66[39m
train_args = Node{NodalMachine{Main.TestLearningNetworks.MyTransformer}}[[34mNode{NodalMachine{MyTransformer}} @ 4â€¦28[39m]
mach.model = [34mStandardizer @ 2â€¦19[39m
train_args = Source{:target}[[34mSource{:target} @ 8â€¦29[39m]
mach.model = [34mUnivariateBoxCoxTransformer @ 1â€¦64[39m
train_args = Node[[34mNode{NodalMachine{Standardizer}} @ 5â€¦04[39m, [34mNode{NodalMachine{UnivariateBoxCoxTransformer}} @ 4â€¦02[39m]
mach.model = [34mKNNRegressor @ 1â€¦93[39m
[ Info: Training [34mNodalMachine{KNNRegressor} @ 4â€¦91[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 1â€¦08[39m.
[ Info: Training [34mNodalMachine{UnivariateBoxCoxTransformer} @ 2â€¦58[39m.
[ Info: Training [34mNodalMachine{RidgeRegressor} @ 1â€¦75[39m.
â”Œ Info: Not retraining [34mNodalMachine{Standardizer} @ 1â€¦08[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
â”Œ Info: Not retraining [34mNodalMachine{UnivariateBoxCoxTransformer} @ 2â€¦58[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
[ Info: Updating [34mNodalMachine{RidgeRegressor} @ 1â€¦75[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 7â€¦59[39m.
[ Info: Training [34mNodalMachine{PCA} @ 3â€¦82[39m.
â”Œ Info: Not retraining [34mNodalMachine{Standardizer} @ 7â€¦59[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
â”Œ Info: Not retraining [34mNodalMachine{PCA} @ 3â€¦82[39m.
â””  It appears up-to-date. Use `force=true` to force retraining.
[ Info: Training [34mNodalMachine{RidgeRegressor} @ 1â€¦22[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 1â€¦77[39m.
[ Info: Training [34mNodalMachine{PCA} @ 1â€¦22[39m.
[ Info: Training [34mNodalMachine{RidgeRegressor} @ 8â€¦45[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 1â€¦16[39m.
[ Info: Training [34mNodalMachine{PCA} @ 1â€¦67[39m.
[ Info: Training [34mNodalMachine{UnivariateBoxCoxTransformer} @ 6â€¦62[39m.
[ Info: Training [34mNodalMachine{RidgeRegressor} @ 1â€¦92[39m.
[ Info: Training [34mNodalMachine{DecisionTreeRegressor} @ 8â€¦50[39m.
[ Info: Training [34mNodalMachine{DecisionTreeRegressor} @ 6â€¦96[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 8â€¦33[39m.
[ Info: Training [34mNodalMachine{UnivariateBoxCoxTransformer} @ 7â€¦57[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 1â€¦08[39m.
[ Info: Training [34mNodalMachine{MyTransformer} @ 3â€¦82[39m.
[ Info: Training [34mNodalMachine{Standardizer} @ 3â€¦08[39m.
[ Info: Training [34mNodalMachine{UnivariateBoxCoxTransformer} @ 6â€¦41[39m.
[ Info: Training [34mNodalMachine{KNNRegressor} @ 8â€¦11[39m.
Test Summary:        | Pass  Total
machines+composition |  293    293
Test Summary: | Pass  Total
hyperparam    |  114    114
Test Summary: | Pass  Total
openml        |   15     15
â”Œ Warning: Forcibly interrupting busy workers
â”‚   exception = rmprocs: pids [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41] not terminated after 5.0 seconds.
â”” @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1234
â”Œ Warning: rmprocs: process 1 not removed
â”” @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
    Testing MLJBase tests passed 
