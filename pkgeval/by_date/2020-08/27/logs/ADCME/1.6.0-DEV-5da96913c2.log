Julia Version 1.6.0-DEV.733
Commit 5da96913c2 (2020-08-26 17:46 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake-avx512)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
[ Info: LEGAL NOTICE: package operations send anonymous data about your system to https://pkg.julialang.org (your current package server), including the operating system and Julia versions you are using, and a random client UUID. Running `Pkg.telemetryinfo()` will show exactly what data is sent. See https://julialang.org/legal/data/ for more details about what this data is used for, how long it is retained, and how to opt out of sending it.
  Installed FFTW ───────────────────────── v1.2.4
  Installed JSON ───────────────────────── v0.21.0
  Installed BinDeps ────────────────────── v1.0.1
  Installed Reexport ───────────────────── v0.2.0
  Installed SpecialFunctions ───────────── v0.10.3
  Installed OpenSpecFun_jll ────────────── v0.5.3+3
  Installed Compat ─────────────────────── v3.14.0
  Installed AbstractFFTs ───────────────── v0.5.0
  Installed Conda ──────────────────────── v1.4.1
  Installed MAT ────────────────────────── v0.8.0
  Installed ADCME ──────────────────────── v0.5.9
  Installed PyCall ─────────────────────── v1.91.4
  Installed URIParser ──────────────────── v0.4.1
  Installed HDF5 ───────────────────────── v0.13.5
  Installed VersionParsing ─────────────── v1.2.0
  Installed HDF5_jll ───────────────────── v1.10.5+5
  Installed Zlib_jll ───────────────────── v1.2.11+16
  Installed BufferedStreams ────────────── v1.0.0
  Installed MacroTools ─────────────────── v0.5.5
  Installed Zstd_jll ───────────────────── v1.4.5+1
  Installed MKL_jll ────────────────────── v2020.2.254+0
  Installed Blosc_jll ──────────────────── v1.14.3+1
  Installed Lz4_jll ────────────────────── v1.9.2+2
  Installed CodecZlib ──────────────────── v0.7.0
  Installed Blosc ──────────────────────── v0.7.0
  Installed Parsers ────────────────────── v1.0.10
  Installed CompilerSupportLibraries_jll ─ v0.3.3+0
  Installed IntelOpenMP_jll ────────────── v2018.0.3+0
  Installed FFTW_jll ───────────────────── v3.3.9+5
  Installed CMake ──────────────────────── v1.2.0
  Installed TranscodingStreams ─────────── v0.9.5
Updating `~/.julia/environments/v1.6/Project.toml`
  [07b341a0] + ADCME v0.5.9
Updating `~/.julia/environments/v1.6/Manifest.toml`
  [07b341a0] + ADCME v0.5.9
  [621f4979] + AbstractFFTs v0.5.0
  [9e28174c] + BinDeps v1.0.1
  [a74b3585] + Blosc v0.7.0
  [0b7ba130] + Blosc_jll v1.14.3+1
  [e1450e63] + BufferedStreams v1.0.0
  [631607c0] + CMake v1.2.0
  [944b1d66] + CodecZlib v0.7.0
  [34da2185] + Compat v3.14.0
  [e66e0078] + CompilerSupportLibraries_jll v0.3.3+0
  [8f4d0f93] + Conda v1.4.1
  [7a1cc6ca] + FFTW v1.2.4
  [f5851436] + FFTW_jll v3.3.9+5
  [f67ccb44] + HDF5 v0.13.5
  [0234f1f7] + HDF5_jll v1.10.5+5
  [1d5cc7b8] + IntelOpenMP_jll v2018.0.3+0
  [682c06a0] + JSON v0.21.0
  [5ced341a] + Lz4_jll v1.9.2+2
  [23992714] + MAT v0.8.0
  [856f044c] + MKL_jll v2020.2.254+0
  [1914dd2f] + MacroTools v0.5.5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+3
  [69de0a69] + Parsers v1.0.10
  [438e738f] + PyCall v1.91.4
  [189a3867] + Reexport v0.2.0
  [276daf66] + SpecialFunctions v0.10.3
  [3bb67fe8] + TranscodingStreams v0.9.5
  [30578b45] + URIParser v0.4.1
  [81def892] + VersionParsing v1.2.0
  [83775a58] + Zlib_jll v1.2.11+16
  [3161d3a3] + Zstd_jll v1.4.5+1
  [2a0f44e3] + Base64
  [ade2ca70] + Dates
  [8bb1440f] + DelimitedFiles
  [8ba89e20] + Distributed
  [b77e0a4c] + InteractiveUtils
  [76f85450] + LibGit2
  [8f399da3] + Libdl
  [37e2e46d] + LinearAlgebra
  [56ddb016] + Logging
  [d6f4376e] + Markdown
  [a63ad114] + Mmap
  [44cfe95a] + Pkg
  [de0858da] + Printf
  [3fa0cd96] + REPL
  [9a3f8284] + Random
  [ea8e919c] + SHA
  [9e88b42a] + Serialization
  [1a1011a3] + SharedArrays
  [6462fe0b] + Sockets
  [2f01184e] + SparseArrays
  [10745b16] + Statistics
  [8dfed614] + Test
  [cf7118a7] + UUIDs
  [4ec0a83e] + Unicode
   Building Conda ─→ `~/.julia/packages/Conda/3rPhK/deps/build.log`
   Building PyCall → `~/.julia/packages/PyCall/zqDXB/deps/build.log`
   Building CMake ─→ `~/.julia/packages/CMake/ULbyn/deps/build.log`
   Building HDF5 ──→ `~/.julia/packages/HDF5/hPEcL/deps/build.log`
   Building FFTW ──→ `~/.julia/packages/FFTW/DMUbN/deps/build.log`
   Building ADCME ─→ `~/.julia/packages/ADCME/DBZ10/deps/build.log`
    Testing ADCME
Status `/tmp/jl_NrbnMn/Project.toml`
  [07b341a0] ADCME v0.5.9
  [9e28174c] BinDeps v1.0.1
  [631607c0] CMake v1.2.0
  [7a1cc6ca] FFTW v1.2.4
  [23992714] MAT v0.8.0
  [76087f3c] NLopt v0.6.0
  [429524aa] Optim v0.22.0
  [438e738f] PyCall v1.91.4
  [276daf66] SpecialFunctions v0.10.3
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [44cfe95a] Pkg
  [9a3f8284] Random
  [2f01184e] SparseArrays
  [10745b16] Statistics
  [8dfed614] Test
Status `/tmp/jl_NrbnMn/Manifest.toml`
  [07b341a0] ADCME v0.5.9
  [621f4979] AbstractFFTs v0.5.0
  [4fba245c] ArrayInterface v2.12.0
  [9e28174c] BinDeps v1.0.1
  [a74b3585] Blosc v0.7.0
  [0b7ba130] Blosc_jll v1.14.3+1
  [e1450e63] BufferedStreams v1.0.0
  [631607c0] CMake v1.2.0
  [944b1d66] CodecZlib v0.7.0
  [bbf7d656] CommonSubexpressions v0.3.0
  [34da2185] Compat v3.14.0
  [e66e0078] CompilerSupportLibraries_jll v0.3.3+0
  [8f4d0f93] Conda v1.4.1
  [9a962f9c] DataAPI v1.3.0
  [864edb3b] DataStructures v0.17.20
  [163ba53b] DiffResults v1.0.2
  [b552c78f] DiffRules v1.0.1
  [7a1cc6ca] FFTW v1.2.4
  [f5851436] FFTW_jll v3.3.9+5
  [1a297f60] FillArrays v0.8.14
  [6a86dc24] FiniteDiff v2.6.0
  [f6369f11] ForwardDiff v0.10.12
  [f67ccb44] HDF5 v0.13.5
  [0234f1f7] HDF5_jll v1.10.5+5
  [1d5cc7b8] IntelOpenMP_jll v2018.0.3+0
  [682c06a0] JSON v0.21.0
  [d3d80556] LineSearches v7.1.0
  [5ced341a] Lz4_jll v1.9.2+2
  [23992714] MAT v0.8.0
  [856f044c] MKL_jll v2020.2.254+0
  [1914dd2f] MacroTools v0.5.5
  [fdba3010] MathProgBase v0.7.8
  [e1d29d7a] Missings v0.4.4
  [d41bc354] NLSolversBase v7.7.0
  [76087f3c] NLopt v0.6.0
  [079eb43e] NLopt_jll v2.6.2+0
  [77ba4419] NaNMath v0.3.4
  [efe28fd5] OpenSpecFun_jll v0.5.3+3
  [429524aa] Optim v0.22.0
  [bac558e1] OrderedCollections v1.3.0
  [d96e819e] Parameters v0.12.1
  [69de0a69] Parsers v1.0.10
  [85a6dd25] PositiveFactorizations v0.2.3
  [438e738f] PyCall v1.91.4
  [189a3867] Reexport v0.2.0
  [ae029012] Requires v1.0.1
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.10.3
  [90137ffa] StaticArrays v0.12.4
  [2913bbd2] StatsBase v0.33.0
  [3bb67fe8] TranscodingStreams v0.9.5
  [30578b45] URIParser v0.4.1
  [3a884ed6] UnPack v1.0.2
  [81def892] VersionParsing v1.2.0
  [83775a58] Zlib_jll v1.2.11+16
  [3161d3a3] Zstd_jll v1.4.5+1
  [2a0f44e3] Base64
  [ade2ca70] Dates
  [8bb1440f] DelimitedFiles
  [8ba89e20] Distributed
  [b77e0a4c] InteractiveUtils
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [d6f4376e] Markdown
  [a63ad114] Mmap
  [44cfe95a] Pkg
  [de0858da] Printf
  [3fa0cd96] REPL
  [9a3f8284] Random
  [ea8e919c] SHA
  [9e88b42a] Serialization
  [1a1011a3] SharedArrays
  [6462fe0b] Sockets
  [2f01184e] SparseArrays
  [10745b16] Statistics
  [8dfed614] Test
  [cf7118a7] UUIDs
  [4ec0a83e] Unicode
    Testing Running tests...
WARNING: Method definition size(PyCall.PyObject) in module PyCall at /home/pkgeval/.julia/packages/PyCall/zqDXB/src/PyCall.jl:798 overwritten in module ADCME at /home/pkgeval/.julia/packages/ADCME/DBZ10/src/variable.jl:212.
  ** incremental compilation may be fatally broken for this module **

WARNING: Method definition length(PyCall.PyObject) in module PyCall at /home/pkgeval/.julia/packages/PyCall/zqDXB/src/PyCall.jl:797 overwritten in module ADCME at /home/pkgeval/.julia/packages/ADCME/DBZ10/src/variable.jl:236.
  ** incremental compilation may be fatally broken for this module **

WARNING: Method definition lastindex(PyCall.PyObject) in module PyCall at deprecated.jl:70 overwritten in module ADCME at /home/pkgeval/.julia/packages/ADCME/DBZ10/src/variable.jl:424.
  ** incremental compilation may be fatally broken for this module **

WARNING: Method definition *(PyCall.PyObject, PyCall.PyObject) in module PyCall at /home/pkgeval/.julia/packages/PyCall/zqDXB/src/pyoperators.jl:11 overwritten in module ADCME at /home/pkgeval/.julia/packages/ADCME/DBZ10/src/ops.jl:102.
  ** incremental compilation may be fatally broken for this module **

[ Info: You are using ADCME for the first time. Precompiling built-in custom operators may take some time...
-- The C compiler identification is GNU 5.4.0
-- The CXX compiler identification is GNU 5.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-gcc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-g++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
JULIA=/opt/julia/bin/julia
┌ Warning: Cannot load /home/pkgeval/.julia/packages/ADCME/DBZ10/src/../deps/CustomOps/build/libadcme.so. Please recompile the shared library by `ADCME.precompile()` for using custom operators.
└ @ ADCME ~/.julia/packages/ADCME/DBZ10/src/ADCME.jl:95
Python path=/home/pkgeval/.julia/conda/3/bin/python
PREFIXDIR=/home/pkgeval/.julia/conda/3/lib/Libraries
TF_INC=/home/pkgeval/.julia/conda/3/lib/python3.7/site-packages/tensorflow_core/include
TF_ABI=1
TF_LIB_FILE=/home/pkgeval/.julia/conda/3/lib/python3.7/site-packages/tensorflow_core/libtensorflow_framework.so.1
MPI_INCLUDE_PATH and/or MPI_C_LIBRARIES is not set. MPI operators are not compiled.
-- Configuring done
-- Generating done
-- Build files have been written to: /home/pkgeval/.julia/packages/ADCME/DBZ10/deps/CustomOps/build
[1/17] Building CXX object CMakeFiles/adcme.dir/OT/src/sinkhorn.cpp.o
[2/17] Building CXX object CMakeFiles/adcme.dir/SparseAccumulate/Impl.cpp.o
[3/17] Building CXX object CMakeFiles/adcme.dir/SparseAccumulate/SparseAccumulator.cpp.o
[4/17] Building CXX object CMakeFiles/adcme.dir/TriLu/TriLu.cpp.o
[5/17] Building CXX object CMakeFiles/adcme.dir/SparseToDense/SparseToDense.cpp.o
[6/17] Building CXX object CMakeFiles/adcme.dir/SparseFactorizationSolve/lru_cache.cpp.o
[7/17] Building CXX object CMakeFiles/adcme.dir/SparseScatterUpdate/SparseScatterUpdate.cpp.o
[8/17] Building CXX object CMakeFiles/adcme.dir/SparseConcate/SparseConcate.cpp.o
[9/17] Building CXX object CMakeFiles/adcme.dir/OT/SinkhornKnopp/SinkhornKnopp.cpp.o
[10/17] Building CXX object CMakeFiles/adcme.dir/SparseIndexing/SparseIndexing.cpp.o
[11/17] Building CXX object CMakeFiles/adcme.dir/SparseFactorizationSolve/Solve/Solve.cpp.o
[12/17] Building CXX object CMakeFiles/adcme.dir/SparseMatMul/SparseMatMul.cpp.o
[13/17] Building CXX object CMakeFiles/adcme.dir/SolveBatchedRhs/SolveBatchedRhs.cpp.o
[14/17] Building CXX object CMakeFiles/adcme.dir/SparseFactorizationSolve/Factorization/SparseFactorization.cpp.o
[15/17] Building CXX object CMakeFiles/adcme.dir/SparseLeastSquare/SparseLeastSquare.cpp.o
[16/17] Building CXX object CMakeFiles/adcme.dir/SparseSolver/SparseSolver.cpp.o
[17/17] Linking CXX shared library libadcme.so
2020-08-27 19:56:13.741254: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-27 19:56:13.872394: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
2020-08-27 19:56:13.917005: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x183cfd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-27 19:56:13.917153: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[✔️] Julia version
[✔️] TensorFlow version
[✔️] TensorFlow-Probability version
[✔️] Python executable file
[✘] Julia path (Optional)

[Reason]
`julia` outputs nothing. This will break custom operator compilation.


[Instruction]
Add your julia binary path to your environment path, e.g. (Unix systems) 

export PATH=/opt/julia/bin:$PATH

For convenience, you can add the above line to your `~/.bashrc` (Linux) or `~/.bash_profile` (Apple).
For Windows, you need to add it to system environment.

[✘] Dynamic library path (Optional)

[Reason]
/home/pkgeval/.julia/conda/3/lib is not in LD_LIBRARY_PATH. This MAY break custom operator compilation. However, in most cases, ADCME automatic fixes this problem for you.


[Instruction]
Add your dynamic library path path to your environment path, e.g. (Unix systems) 

export LD_LIBRARY_PATH=/home/pkgeval/.julia/conda/3/lib:$LD_LIBRARY_PATH

For convenience, you can add the above line to your `~/.bashrc` (Linux or Apple).
For Windows, you need to add it to PATH instead of LD_LIBRARY_PATH.

[✔️] Memory Address Length =  64
[✘] Binaries path

[Reason]
/home/pkgeval/.julia/conda/3/bin is not in PATH. This path contains compatible tools such as a GCC compiler, `cmake`, `make`, or any other tools you want to use directly from terminal.
However, setting the path is NOT a requirement, and ADCME works totally fine without any action.


[Instruction]
(Optional) Add your binary path to your environment path, e.g. (Unix systems) 

export PATH=/home/pkgeval/.julia/conda/3/bin:$PATH

For convenience, you can add the above line to your `~/.bashrc` (Linux) or `~/.bash_profile` (Apple).
For Windows, you need to add it to system environment.

[✘] GPU Support (Optional)

[Reason]
ADCME is not compiled against GPU.


[Instruction]
If you intend to use GPU, set ENV["GPU"] = 1 and then rebuild ADCME.

Dependency file is located at: /home/pkgeval/.julia/packages/ADCME/DBZ10/src/../deps/deps.jl
OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-39
OMP: Info #156: KMP_AFFINITY: 40 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #179: KMP_AFFINITY: 2 packages x 10 cores/pkg x 2 threads/core (20 total cores)
OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 20 maps to package 0 core 0 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 21 maps to package 0 core 1 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 22 maps to package 0 core 2 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 23 maps to package 0 core 3 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 4 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 24 maps to package 0 core 4 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 8 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 25 maps to package 0 core 8 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 9 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 26 maps to package 0 core 9 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 10 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 27 maps to package 0 core 10 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 8 maps to package 0 core 11 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 28 maps to package 0 core 11 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 9 maps to package 0 core 12 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 29 maps to package 0 core 12 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 10 maps to package 1 core 0 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 30 maps to package 1 core 0 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 11 maps to package 1 core 1 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 31 maps to package 1 core 1 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 12 maps to package 1 core 2 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 32 maps to package 1 core 2 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 13 maps to package 1 core 3 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 33 maps to package 1 core 3 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 14 maps to package 1 core 4 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 34 maps to package 1 core 4 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 15 maps to package 1 core 8 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 35 maps to package 1 core 8 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 16 maps to package 1 core 9 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 36 maps to package 1 core 9 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 17 maps to package 1 core 10 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 37 maps to package 1 core 10 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 18 maps to package 1 core 11 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 38 maps to package 1 core 11 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 19 maps to package 1 core 12 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 39 maps to package 1 core 12 thread 1 
OMP: Info #250: KMP_AFFINITY: pid 5587 tid 5587 thread 0 bound to OS proc set 0
2020-08-27 19:56:14.409523: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Test Summary:               | Pass  Total
indexing for rank 3 tensors |    3      3
[ Info: Copy "/home/pkgeval/.julia/packages/ADCME/DBZ10/src/../deps/AdeptCMakeLists.txt" to "/home/pkgeval/.julia/conda/3/lib/Adept-2/adept/CMakeLists.txt" ... 
[ Info: Remove /home/pkgeval/.julia/conda/3/lib/Adept-2/adept/build ... 
[ Info: Make /home/pkgeval/.julia/conda/3/lib/Adept-2/adept/build ... 
[ Info: Change directory into /home/pkgeval/.julia/conda/3/lib/Adept-2/adept/build ... 
[ Info: Cmake ... 
-- The C compiler identification is GNU 5.4.0
-- The CXX compiler identification is GNU 5.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-gcc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-g++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
JULIA=/opt/julia/bin/julia
Python path=/home/pkgeval/.julia/conda/3/bin/python
PREFIXDIR=/home/pkgeval/.julia/conda/3/lib/Libraries
TF_INC=/home/pkgeval/.julia/conda/3/lib/python3.7/site-packages/tensorflow_core/include
TF_ABI=1
TF_LIB_FILE=/home/pkgeval/.julia/conda/3/lib/python3.7/site-packages/tensorflow_core/libtensorflow_framework.so.1
Use openblas library /home/pkgeval/.julia/conda/3/lib/libopenblas.so
-- Configuring done
-- Generating done
-- Build files have been written to: /home/pkgeval/.julia/conda/3/lib/Adept-2/adept/build
[ Info: Make ... 
[1/12] Building CXX object CMakeFiles/adept.dir/StackStorageOrig.cpp.o
[2/12] Building CXX object CMakeFiles/adept.dir/cppblas.cpp.o
[3/12] Building CXX object CMakeFiles/adept.dir/settings.cpp.o
[4/12] Building CXX object CMakeFiles/adept.dir/Storage.cpp.o
[5/12] Building CXX object CMakeFiles/adept.dir/index.cpp.o
[6/12] Building CXX object CMakeFiles/adept.dir/Array.cpp.o
[7/12] Building CXX object CMakeFiles/adept.dir/Stack.cpp.o
[8/12] Building CXX object CMakeFiles/adept.dir/inv.cpp.o
[9/12] Building CXX object CMakeFiles/adept.dir/vector_utilities.cpp.o
[10/12] Building CXX object CMakeFiles/adept.dir/jacobian.cpp.o
[11/12] Building CXX object CMakeFiles/adept.dir/solve.cpp.o
[12/12] Linking CXX shared library /home/pkgeval/.julia/conda/3/lib/libadept.so
∘ Add the following lines to CMakeLists.txt 

include_directories(${LIBDIR}/Adept-2/include)
find_library(ADEPT_LIB_FILE adept HINTS ${LIBDIR})
find_library(LIBOPENBLAS openblas HINTS ${LIBDIR})
message("ADEPT_LIB_FILE=${ADEPT_LIB_FILE}")
message("LIBOPENBLAS=${LIBOPENBLAS}")

∘ Add `${ADEPT_LIB_FILE}` and `${LIBOPENBLAS}` to `target_link_libraries`
-- The C compiler identification is GNU 5.4.0
-- The CXX compiler identification is GNU 5.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-gcc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /home/pkgeval/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-g++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
JULIA=/opt/julia/bin/julia
Python path=/home/pkgeval/.julia/conda/3/bin/python
PREFIXDIR=/home/pkgeval/.julia/conda/3/lib/Libraries
TF_INC=/home/pkgeval/.julia/conda/3/lib/python3.7/site-packages/tensorflow_core/include
TF_ABI=1
TF_LIB_FILE=/home/pkgeval/.julia/conda/3/lib/python3.7/site-packages/tensorflow_core/libtensorflow_framework.so.1
ADEPT_LIB_FILE=/home/pkgeval/.julia/conda/3/lib/libadept.so
-- Configuring done
-- Generating done
-- Build files have been written to: /home/pkgeval/.julia/packages/ADCME/DBZ10/deps/Plugin/ExtendedNN/build
[1/2] Building CXX object CMakeFiles/ExtendedNn.dir/ExtendedNn.cpp.o
[2/2] Linking CXX shared library libExtendedNn.so
Load library operator (with gradient, multiple outputs = true): /home/pkgeval/.julia/packages/ADCME/DBZ10/deps/Plugin/ExtendedNN/build/libExtendedNn.so ==> extended_nn
Test Summary: | Pass  Total
fcx           |    4      4
Test Summary: | Pass  Total
dropout       |    2      2
Test Summary:      | Pass  Total
sparse_constructor |    7      7
Test Summary:     | Pass  Total
sparse_arithmetic |    4      4
Test Summary:  | Pass  Total
sparse_adjoint |    1      1
Test Summary: | Pass  Total
sparse_mul    |    6      6
Test Summary:    | Pass  Total
sparse_vcat_hcat |    2      2
Test Summary:   | Pass  Total
sparse_indexing |    3      3
Test Summary: | Pass  Total
sparse_solve  |    1      1
k = 1
k = 2
k = 3
k = 4
k = 5
k = 6
k = 7
k = 8
k = 9
k = 10
v = [0.8534413534831464, 0.796698177517698, 0.6932109759953244, 0.39623905294611905, 0.5058970166139904, 0.9151864364486002, 0.8433633173276138, 0.7080067262032599, 0.49596031515656147, 0.3778015569707529]
2020-08-27 19:57:43.492402: I ../SparseAccumulate/Impl.cpp:68] Create a new sparse assembler [Handle ID = 100] with 20 rows and tolerance 0.

2020-08-27 19:57:43.492468: I ../SparseAccumulate/Impl.cpp:69] Current sparse assembler:
2020-08-27 19:57:43.492483: I ../SparseAccumulate/Impl.cpp:74]  100 |
2020-08-27 19:57:43.492522: I ../SparseAccumulate/Impl.cpp:82] destroy_sparse_assembler
2020-08-27 19:57:43.621151: I ../SparseAccumulate/Impl.cpp:68] Create a new sparse assembler [Handle ID = 100] with 5 rows and tolerance 1.

2020-08-27 19:57:43.621218: I ../SparseAccumulate/Impl.cpp:69] Current sparse assembler:
2020-08-27 19:57:43.621233: I ../SparseAccumulate/Impl.cpp:74]  100 |
2020-08-27 19:57:43.621267: I ../SparseAccumulate/Impl.cpp:82] destroy_sparse_assembler
2020-08-27 19:57:43.809295: I ../SparseAccumulate/Impl.cpp:68] Create a new sparse assembler [Handle ID = 100] with 5 rows and tolerance 0.

2020-08-27 19:57:43.809572: I ../SparseAccumulate/Impl.cpp:69] Current sparse assembler:
2020-08-27 19:57:43.809628: I ../SparseAccumulate/Impl.cpp:74]  100 |
2020-08-27 19:57:43.809720: I ../SparseAccumulate/Impl.cpp:82] destroy_sparse_assembler
Test Summary:    | Pass  Total
sparse_assembler |    3      3
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = \(s::SparseTensor, o::PyObject, method::String) at sparse.jl:408
└ @ ADCME ~/.julia/packages/ADCME/DBZ10/src/sparse.jl:408
Test Summary:       | Pass  Total
sparse_least_square |    1      1
Test Summary:  | Pass  Total
sparse mat mul |    3      3
Test Summary: | Pass  Total
spdiag        |    3      3
Test Summary: | Pass  Total
spzero        |    2      2
Test Summary:   | Pass  Total
sparse indexing |    1      1
Test Summary: | Pass  Total
sum           |    3      3
Test Summary:   | Pass  Total
dense_to_sparse |    2      2
Test Summary: | Pass  Total
spdiagm       |    4      4
Test Summary: | Pass  Total
hvcat         |    1      1
Test Summary: | Pass  Total
find          |    6      6
Test Summary:             | Pass  Total
sparse scatter update add |    2      2
Test Summary:   | Pass  Total
constant sparse |    1      1
Test Summary: | Pass  Total
get index     |    1      1
2020-08-27 19:58:01.874027: I ../SparseFactorizationSolve/Factorization/SparseFactorization.h:32] Factorization: current matrix id= 1, maximum cache size = 999999

2020-08-27 19:58:01.937831: I ../SparseFactorizationSolve/Factorization/SparseFactorization.h:32] Factorization: current matrix id= 2, maximum cache size = 999999

Test Summary:                  | Pass  Total
sparse_factorization_and_solve |    2      2
2020-08-27 19:58:02.113781: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at SparseSolver.cpp:139 : Internal: Sparse solver factorization failed.
2020-08-27 19:58:02.114767: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at SparseSolver.cpp:139 : Internal: Sparse solver factorization failed.
Test Summary:         | Pass  Total
sparse solver warning |    1      1
Test Summary:  | Pass  Total
sparse promote |    6      6
Test Summary: | Broken  Total
random        |     47     47
Test Summary: | Pass  Total
save and load |    1      1
Test Summary:   | Pass  Total
psave and pload |    1      1
tensorboard --logdir="/tmp/jl_kgXbYk" --port 0
tensorboard --logdir="/tmp/jl_LsSejN" --port 0
Test Summary: |
diary         | No tests
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = macro expansion at variable.jl:17 [inlined]
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:17
Test Summary: | Pass  Total
indexing      |   28     28
Test Summary: | Pass  Total
Variables     |    4      4
Test Summary: | Pass  Total
tensor        |    2      2
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:64
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:64
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:64
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:64
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:64
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:64
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:64
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:64
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:64
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:64
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:64
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:64
Test Summary: | Pass  Total
Hessian       |    2      2
Test Summary: | Pass  Total
Jacobian      |    1      1
Test Summary: | Pass  Total
gradients_v   |    1      1
Test Summary:   | Pass  Total
size and length |    9      9
Test Summary: | Pass  Total
copy          |    1      1
Test Summary: | Pass  Total
getindex      |    1      1
Test Summary:     | Pass  Total
convert_to_tensor |    5      5
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:131
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:131
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at variable.jl:132
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/variable.jl:132
Test Summary: | Pass  Total
cell          |    2      2
Test Summary:    | Pass  Total
special matrices |    2      2
Test Summary:   | Pass  Total
ones/zeros like |    2      2
Test Summary:      | Pass  Total
gradient_magnitude |    1      1
Test Summary:        | Pass  Total
indexing with tensor |    6      6
Test Summary: | Pass  Total
ndims         |    4      4
Test Summary:      | Pass  Total
gradients_colocate |    1      1
OMP: Info #250: KMP_AFFINITY: pid 5587 tid 6279 thread 1 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 5587 tid 6280 thread 2 bound to OS proc set 2
Test Summary: | Pass  Total
*             |   27     27
Test Summary: | Pass  Total
reshape       |    6      6
Test Summary:  | Pass  Total
scatter_update |    9      9
Test Summary: | Pass  Total
adjoint       |    4      4
Test Summary:           | Pass  Total
scatter_update_pyobject |    9      9
Test Summary: | Pass  Total
Operators     |   14     14
Test Summary:   | Pass  Total
Other Operators |    1      1
Test Summary:    | Pass  Total
Concat and stack |    6      6
Test Summary: | Pass  Total
Vectorize     |    5      5
Test Summary: | Pass  Total
Solve         |    3      3
Test Summary: | Pass  Total
diff          |    3      3
Test Summary: | Pass  Total
clip          |    1      1
Test Summary: | Pass  Total
map           |    1      1
Test Summary: | Pass  Total
diag          |    2      2
Test Summary: | Pass  Total
dot           |    3      3
Test Summary: | Pass  Total
prod          |    1      1
Test Summary: | Pass  Total
findall       |    2      2
Test Summary: | Pass  Total
svd           |    1      1
Test Summary: | Pass  Total
vector        |    1      1
Test Summary: | Pass  Total
repeat        |    6      6
Test Summary: | Pass  Total
pmap          |    3      3
Test Summary: | Pass  Total
reshape       |    1      1
Test Summary: | Pass  Total
batch mul     |    1      1
Test Summary: | Pass  Total
sort          |    2      2
Test Summary: | Pass  Total
set_shape     |    3      3
Test Summary: | Pass  Total
activation    |    8      8
Test Summary: | Pass  Total
trace         |    1      1
Test Summary: | Pass  Total
trilu         |   22     22
Test Summary: | Pass  Total
reverse       |    3      3
Test Summary: | Pass  Total
solve batch   |    2      2
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = (::var"#45#46"{PyObject,Int64})() at core.jl:18
└ @ Main ~/.julia/packages/ADCME/DBZ10/test/core.jl:18
Test Summary:      | Pass  Total
control_dependency |    2      2
WARNING: Method definition body(Any, Any) in module Main at /home/pkgeval/.julia/packages/ADCME/DBZ10/test/core.jl:40 overwritten at /home/pkgeval/.julia/packages/ADCME/DBZ10/test/core.jl:73.
Test Summary: | Pass  Total
while loop    |    3      3
Test Summary: | Pass  Total
if_clause     |    1      1
Test Summary:     | Pass  Total
if_else: tf.where |    2      2
Test Summary:          | Pass  Total
get and add collection |    1      1
Test Summary: | Pass  Total
has_gpu       |    1      1
2020-08-27 19:59:29.319532: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
OMP: Info #250: KMP_AFFINITY: pid 5587 tid 6510 thread 6 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 5587 tid 6515 thread 11 bound to OS proc set 11
OMP: Info #250: KMP_AFFINITY: pid 5587 tid 6516 thread 12 bound to OS proc set 12
OMP: Info #250: KMP_AFFINITY: pid 5587 tid 6520 thread 16 bound to OS proc set 16
OMP: Info #250: KMP_AFFINITY: pid 5587 tid 6523 thread 19 bound to OS proc set 19
OMP: Info #250: KMP_AFFINITY: pid 5587 tid 6519 thread 15 bound to OS proc set 15
OMP: Info #250: KMP_AFFINITY: pid 5587 tid 6521 thread 17 bound to OS proc set 17
OMP: Info #250: KMP_AFFINITY: pid 5587 tid 6509 thread 5 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 5587 tid 6511 thread 7 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 5587 tid 6512 thread 8 bound to OS proc set 8
OMP: Info #250: KMP_AFFINITY: pid 5587 tid 6524 thread 20 bound to OS proc set 20
OMP: Info #250: KMP_AFFINITY: pid 5587 tid 6518 thread 14 bound to OS proc set 14
OMP: Info #250: KMP_AFFINITY: pid 5587 tid 6507 thread 3 bound to OS proc set 3
OMP: Info #250: KMP_AFFINITY: pid 5587 tid 6517 thread 13 bound to OS proc set 13
OMP: Info #250: KMP_AFFINITY: pid 5587 tid 6513 thread 9 bound to OS proc set 9
OMP: Info #250: KMP_AFFINITY: pid 5587 tid 6522 thread 18 bound to OS proc set 18
OMP: Info #250: KMP_AFFINITY: pid 5587 tid 6508 thread 4 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 5587 tid 6525 thread 21 bound to OS proc set 21
OMP: Info #250: KMP_AFFINITY: pid 5587 tid 6514 thread 10 bound to OS proc set 10
┌ Info: Timeline information saved in test.json
│ - Open Chrome and navigate to chrome://tracing
└ - Load the timeline file
Test Summary: |
timeline      | No tests
Test Summary: | Pass  Total
independent   |    1      1
Test Summary:    | Pass  Total
run corner cases |    1      1
Test Summary: | Pass  Total
@cpu @gpu     |    4      4
Test Summary: | Pass  Total
xavier_init   |    1      1
Load library operator: /home/pkgeval/.julia/packages/ADCME/DBZ10/deps/CustomOps/build/libadcme.so ==> sparse_solver
Load library operator (with gradient, multiple outputs = false): /home/pkgeval/.julia/packages/ADCME/DBZ10/deps/CustomOps/build/libadcme.so ==> sparse_solver
Test Summary: | Pass  Total
load_op       |    2      2
Test Summary: | Pass  Total
ae            |    1      1
[ Info: (1/4)Intializing TensorArray...
[ Info: (2/4)Parsing Condition...
[ Info: (3/4)Parsing Main Loop...
[ Info: (4/4)Postprocessing Results...
Newton-Raphson with absolute tolerance = 1.0e-12 and relative tolerance = 1.0e-12
ITER  2 >>> Error = 15.652475842498529 | Relative Error = 15.652475842498529
ITER  3 >>> Error = 64.928788679993914 | Relative Error = 15.652475842498529
ITER  4 >>> Error = 15.489950495968388 | Relative Error = 64.928788679993914
ITER  5 >>> Error = 2.2725864326069174 | Relative Error = 15.489950495968388
ITER  6 >>> Error = 0.084320075161598992 | Relative Error = 2.2725864326069174
ITER  7 >>> Error = 0.00013179440739372649 | Relative Error = 0.084320075161598992
ITER  8 >>> Error = 3.2366684481841166e-10 | Relative Error = 0.00013179440739372649
ITER  9 >>> Error = 0 | Relative Error = 3.2366684481841166e-10
Test Summary: | Pass  Total
register      |    4      4
Test Summary:         | Pass  Total
list_physical_devices |    1      1
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([1.0], 5, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([2.0945514815423265], 17, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.9708700202758002], 7, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.7390848428905966], 19, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.9999996474271033], 21, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([1.2999999999998648], 43, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.45840750163141014], 24, true)
Test Summary:                  | Pass  Total
newton raphson with linesearch |    7      7
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:50
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:50
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:51
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:51
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:51
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:51
[CustomOptimizer] Number of inequalities constraints = 1, Number of equality constraints = 0
[CustomOptimizer] Total number of variables = 4
Test Summary: | Pass  Total
NLopt         |    1      1
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:71
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:71
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:71
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:71
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:71
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:71
[CustomOptimizer] Number of inequalities constraints = 0, Number of equality constraints = 0
[CustomOptimizer] Total number of variables = 2
[CustomOptimizer] No bounds provided, use (-∞, +∞) as default; or you need to provide bounds in the function CustomOptimizer
(f, df, c, dc, x0) = (ADCME.var"#f#468"{PyObject}(PyObject <function ExternalOptimizerInterface._make_eval_func.<locals>.eval_func at 0x7f7d29456b90>), ADCME.var"#df#469"{PyObject}(PyObject <function ExternalOptimizerInterface._make_eval_func.<locals>.eval_func at 0x7f7d29456b90>), ADCME.var"#c#470"{Vector{Float64},Vector{Any},Vector{Any},Int64,Int64}([0.8534413534831464, 0.796698177517698], Any[], Any[], 0, 0), ADCME.var"#dc#473"{Vector{Float64},Vector{Any},Vector{Any},Int64,Int64,Int64,Int64}([0.8534413534831464, 0.796698177517698], Any[], Any[], 0, 2, 0, 0), [0.8534413534831464, 0.796698177517698])
Test Summary: | Pass  Total
Optim         |    1      1
Test Summary:  | Broken  Total
newton raphson |      1      1
Test Summary:               | Broken  Total
NonlinearConstrainedProblem |      1      1
[ Info: Optimization starts...
iter 1, current loss = 10414.995452361656
[ Info: (0, 10414.995452361656)
================== STEP 0 ==================
iter 2, current loss = 8.673244982901532e11
iter 3, current loss = 3948.0652798051747
[ Info: (1, 3948.0652798051747)
================== STEP 1 ==================
iter 4, current loss = 3563.6170055635807
iter 5, current loss = 2446.75992340608
iter 6, current loss = 6964.938868031668
iter 7, current loss = 1994.9625510051103
[ Info: (2, 1994.9625510051103)
================== STEP 2 ==================
iter 8, current loss = 1988.5382546162152
iter 9, current loss = 1962.9446754434198
iter 10, current loss = 1837.4633327662139
iter 11, current loss = 1272.2204490495492
iter 12, current loss = 0.10177220035692155
iter 13, current loss = 7.896979584061348e-21
[ Info: (3, 7.896979584061348e-21)
================== STEP 3 ==================
iter 14, current loss = 2.700658339302451e-18
iter 15, current loss = 7.840283419536301e-21
[ Info: (4, 7.840283419536301e-21)
================== STEP 4 ==================
Test Summary: | Pass  Total
Custom BFGS!  |    1      1
[ Info: Optimization starts...
iter 0, current loss=4.0
iter 1, current loss=1.0
================ STEP 0 ===============
Test Summary: | Pass  Total
var_to_bounds |    1      1
┌ Warning: θ is not a PyObject, no gradients is available
└ @ ADCME ~/.julia/packages/ADCME/DBZ10/src/optim.jl:591
Test Summary:            | Pass  Total
newton_raphson_with_grad |    3      3
Test Summary:   | Pass  Total
pack and unpack |    2      2
Test Summary:    | Pass  Total
search direction |    1      1
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:300
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:300
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:300
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:300
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = top-level scope at optim.jl:300
└ @ Core ~/.julia/packages/ADCME/DBZ10/test/optim.jl:300
[ Info: Optimization starts...
iter 1, current loss = 15.945395705412741
[ Info: (0, 15.945395705412741)
================== STEP 0 ==================
iter 2, current loss = 3.5970304007877785e8
iter 3, current loss = 15.90024363626926
iter 4, current loss = 1.367441577871825
[ Info: (1, 1.367441577871825)
================== STEP 1 ==================
iter 5, current loss = 0.4035147756110498
iter 6, current loss = 0.35266678517631295
[ Info: (2, 0.35266678517631295)
================== STEP 2 ==================
iter 7, current loss = 0.3501023058083816
iter 8, current loss = 0.3429182530689169
iter 9, current loss = 0.40058749753492195
iter 10, current loss = 0.34108682659881867
[ Info: (3, 0.34108682659881867)
================== STEP 3 ==================
iter 11, current loss = 0.323822860056014
iter 12, current loss = 0.2815625299027021
iter 13, current loss = 4.052894993822562
iter 14, current loss = 0.2813104307741537
[ Info: (4, 0.2813104307741537)
================== STEP 4 ==================
iter 15, current loss = 0.2115155646374418
iter 16, current loss = 0.3092860229767921
iter 17, current loss = 0.1713874043521048
[ Info: (5, 0.1713874043521048)
================== STEP 5 ==================
iter 18, current loss = 0.13450546394601604
iter 19, current loss = 0.13175087690052817
[ Info: (6, 0.13175087690052817)
================== STEP 6 ==================
iter 20, current loss = 0.10178076391421229
iter 21, current loss = 0.09141216696706024
[ Info: (7, 0.09141216696706024)
================== STEP 7 ==================
iter 22, current loss = 1.061127231420273
iter 23, current loss = 0.08499167666378413
[ Info: (8, 0.08499167666378413)
================== STEP 8 ==================
iter 24, current loss = 0.11398512550886776
iter 25, current loss = 0.06919747445411902
[ Info: (9, 0.06919747445411902)
================== STEP 9 ==================
iter 26, current loss = 0.06545878446630174
iter 27, current loss = 0.05695705381818446
[ Info: (10, 0.05695705381818446)
================== STEP 10 ==================
iter 28, current loss = 0.045194797716066645
iter 29, current loss = 0.2613796131600875
iter 30, current loss = 0.04444245362238663
[ Info: (11, 0.04444245362238663)
================== STEP 11 ==================
iter 31, current loss = 0.02651720534376837
iter 32, current loss = 0.004413384158068556
iter 33, current loss = 0.004111135498552248
[ Info: (12, 0.004111135498552248)
================== STEP 12 ==================
iter 34, current loss = 0.010806537882644074
iter 35, current loss = 0.0024594396339953127
[ Info: (13, 0.0024594396339953127)
================== STEP 13 ==================
iter 36, current loss = 0.0013297050174965995
iter 37, current loss = 0.002071597175530237
iter 38, current loss = 0.0004594304132050863
[ Info: (14, 0.0004594304132050863)
================== STEP 14 ==================
iter 39, current loss = 6.970874682241422e-5
iter 40, current loss = 0.0021327926173249447
iter 41, current loss = 2.0426562768735276e-5
[ Info: (15, 2.0426562768735276e-5)
================== STEP 15 ==================
iter 42, current loss = 6.692547637220963e-6
iter 43, current loss = 4.96321678994831e-7
[ Info: (16, 4.96321678994831e-7)
================== STEP 16 ==================
iter 44, current loss = 1.9012236478271023e-8
iter 45, current loss = 4.477382106104498e-6
iter 46, current loss = 3.2721021998949694e-11
[ Info: (17, 3.2721021998949694e-11)
================== STEP 17 ==================
iter 47, current loss = 1.8424967053846652e-15
iter 48, current loss = 5.171528871175632e-10
iter 49, current loss = 1.0627637574836886e-15
[ Info: (18, 1.0627637574836886e-15)
================== STEP 18 ==================
iter 50, current loss = 5.393531248885961e-22
iter 51, current loss = 1.69739475486261e-14
iter 52, current loss = 1.0224948812919243e-25
[ Info: (19, 1.0224948812919243e-25)
================== STEP 19 ==================
iter 53, current loss = 0.0
[ Info: (20, 0.0)
================== STEP 20 ==================
[ Info: Optimization starts...
iter 1, current loss = 15.945395705412741
[ Info: (0, 15.945395705412741)
================== STEP 0 ==================
iter 2, current loss = 838715.142448343
iter 3, current loss = 15.111942331743817
iter 4, current loss = 1.3015095398650793
[ Info: (1, 1.3015095398650793)
================== STEP 1 ==================
iter 5, current loss = 0.7854017543830847
iter 6, current loss = 0.35760429413272676
[ Info: (2, 0.35760429413272676)
================== STEP 2 ==================
iter 7, current loss = 0.3563203718870314
iter 8, current loss = 0.3520291543077633
[ Info: (3, 0.3520291543077633)
================== STEP 3 ==================
iter 9, current loss = 0.3509348617661783
iter 10, current loss = 8.844541424559752
iter 11, current loss = 0.3404665959693982
iter 12, current loss = 8.424076158304825
iter 13, current loss = 0.6678294204720265
iter 14, current loss = 0.30114931765745717
[ Info: (4, 0.30114931765745717)
================== STEP 4 ==================
iter 15, current loss = 0.3936966702496124
iter 16, current loss = 0.2651438518426606
[ Info: (5, 0.2651438518426606)
================== STEP 5 ==================
iter 17, current loss = 0.2566623748554466
iter 18, current loss = 0.26149312740421105
iter 19, current loss = 0.2357928525701288
[ Info: (6, 0.2357928525701288)
================== STEP 6 ==================
iter 20, current loss = 0.2292635438465798
iter 21, current loss = 0.1845776645663505
[ Info: (7, 0.1845776645663505)
================== STEP 7 ==================
iter 22, current loss = 0.1225295902337916
iter 23, current loss = 0.0824015546154835
[ Info: (8, 0.0824015546154835)
================== STEP 8 ==================
iter 24, current loss = 0.08060678691167972
iter 25, current loss = 0.07408650103279128
[ Info: (9, 0.07408650103279128)
================== STEP 9 ==================
iter 26, current loss = 0.06116981129906204
iter 27, current loss = 0.2680689815004643
iter 28, current loss = 0.06237754687835271
iter 29, current loss = 0.02390730879373093
iter 30, current loss = 0.025459864820678878
[ Info: (10, 0.025459864820678878)
================== STEP 10 ==================
iter 31, current loss = 0.02801903846266264
iter 32, current loss = 0.022418618059996523
[ Info: (11, 0.022418618059996523)
================== STEP 11 ==================
iter 33, current loss = 0.022195633194037508
iter 34, current loss = 0.01597204504460111
[ Info: (12, 0.01597204504460111)
================== STEP 12 ==================
iter 35, current loss = 0.00569461916432148
iter 36, current loss = 0.002029089877683393
[ Info: (13, 0.002029089877683393)
================== STEP 13 ==================
iter 37, current loss = 0.0019426517540307264
iter 38, current loss = 0.001820352265550672
[ Info: (14, 0.001820352265550672)
================== STEP 14 ==================
iter 39, current loss = 0.0017304908527267565
iter 40, current loss = 0.0008640057847485198
[ Info: (15, 0.0008640057847485198)
================== STEP 15 ==================
iter 41, current loss = 0.0023014338615339027
iter 42, current loss = 0.0001883763980607821
[ Info: (16, 0.0001883763980607821)
================== STEP 16 ==================
iter 43, current loss = 0.0001873609486479322
iter 44, current loss = 0.00018484713434034302
[ Info: (17, 0.00018484713434034302)
================== STEP 17 ==================
iter 45, current loss = 0.00018473229471236064
iter 46, current loss = 2.4953980704244138e-6
[ Info: (18, 2.4953980704244138e-6)
================== STEP 18 ==================
iter 47, current loss = 0.06499168863185227
iter 48, current loss = 4.485610666091391e-7
[ Info: (19, 4.485610666091391e-7)
================== STEP 19 ==================
iter 49, current loss = 3.9186663441363477e-7
iter 50, current loss = 3.239075138474641e-7
[ Info: (20, 3.239075138474641e-7)
================== STEP 20 ==================
iter 51, current loss = 3.238533480415504e-7
iter 52, current loss = 1.322102239716603e-10
[ Info: (21, 1.322102239716603e-10)
================== STEP 21 ==================
iter 53, current loss = 2.8204423590105923e-5
iter 54, current loss = 3.5136368371637595e-13
[ Info: (22, 3.5136368371637595e-13)
================== STEP 22 ==================
iter 55, current loss = 3.512397895401207e-13
iter 56, current loss = 3.497655542297614e-13
[ Info: (23, 3.497655542297614e-13)
================== STEP 23 ==================
iter 57, current loss = 3.4497727096372005e-13
iter 58, current loss = 4.90111784052289e-21
[ Info: (24, 4.90111784052289e-21)
================== STEP 24 ==================
iter 59, current loss = 3.91217241956375e-18
iter 60, current loss = 1.5689654543940704e-24
[ Info: (25, 1.5689654543940704e-24)
================== STEP 25 ==================
iter 61, current loss = 1.5644926746912255e-24
iter 62, current loss = 1.5256891491052762e-24
iter 63, current loss = 1.359103666116525e-24
iter 64, current loss = 6.721017135728146e-25
iter 65, current loss = 8.73844939844278e-25
iter 66, current loss = 1.1617209424543807e-26
[ Info: (26, 1.1617209424543807e-26)
================== STEP 26 ==================
iter 67, current loss = 8.526753594842257e-24
iter 68, current loss = 1.232595164407831e-30
[ Info: (27, 1.232595164407831e-30)
================== STEP 27 ==================
Test Summary: | Pass  Total
Optim         |    2      2
[ Info: 3.900395163047295e-8
[2.6873403110589567, 2.2848777584058286, 1.959485177894072, 1.695402405085309, 1.480263493197685, 1.304318508155104, 1.1598475045894157, 1.0407152651051803, 0.9420302552703156, 0.8598815076342153]
[2.6873403110589567, 2.284877740310942, 1.959485148600987, 1.6954023693861155, 1.4802634543798443, 1.3043184684311486, 1.159847465406238, 1.0407152273674067, 0.9420302195019173, 0.8598814740954399]
[ Info: 1.74923517585932e-6
[2.6873403110589567, 2.51968033219294, 2.3591800737664697, 2.2059474319979726, 2.060057321374523, 1.9215424113722332, 1.7903868796137, 1.6665331065514706, 1.5498999348193685, 1.4403938823398208]
[2.6873403110589567, 2.519680372297153, 2.3591806721463433, 2.205949060790531, 2.0600593252906663, 1.9215446484117813, 1.7903894445161121, 1.666535679326616, 1.5499024452536934, 1.4403964019318742]
[ Info: 0.009280891261506044
[2.6873403110589567, 2.5196803348281445, 2.407655825231478, 2.3197815374114255, 2.2461502831672484, 2.1821637837734777, 2.1252505434992806, 2.0738022333150226, 2.0267344163791177, 1.9832752878804252]
[2.6873403110589567, 2.52894669594942, 2.420490642269895, 2.334573816587063, 2.262184980528145, 2.199051744362444, 2.142753602200173, 2.091763168313902, 2.0450438762274734, 2.001854279772373]
[ Info: 0.0002640108007748801
[2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567, 2.6873403110589567]
[2.6873403110589567, 2.6872637777504984, 2.6871862715585118, 2.687108108244675, 2.6870294441458276, 2.6869503723706374, 2.686870954600783, 2.6867912346415777, 2.686711245167153, 2.686631011454236]
ADCME.Optimizer.RMSProp: 
[2.6873403110589567, 2.1809229506849572, 1.876707980129773, 1.6546592408302836, 1.479244033062772, 1.334696176675614, 1.2124398515964887, 1.1071870862263171, 1.015408944687647, 0.9346163191023285]
ADCME.Optimizer.AMSGrad: 
[2.6873403110589567, 2.180931270734746, 1.6124928714759128, 1.108615178036389, 0.7379095523937292, 0.5260637392759812, 0.4585161239500093, 0.48774999629589677, 0.5512317022689825, 0.5952183172262842]
ADCME.Optimizer.NADAM: 
[2.6873403110589567, 2.4425702565335135, 2.2636223209469, 2.1059931830955145, 1.9611223452288686, 1.8261560639124625, 1.699821585350836, 1.5814319739611475, 1.4705621558870792, 1.3669096060903072]
ADCME.Optimizer.Momentum: 
[2.6873403110589567, 0.5561138694752268, 1.901919174485902, 1.5251751312785733, 0.0420157941282293, 1.107065572875359, 0.9972859136071747, 0.092505967405753, 0.8373703084967706, 0.9155307151492693]
ADCME.Optimizer.Nesterov: 
[2.6873403110589567, 1.959349802300281, 1.270153711798689, 0.7838060906690358, 0.5406336834135216, 0.48898653622901855, 0.5361697434507271, 0.593802848884102, 0.6052577936273842, 0.553136858054489]
ADCME.Optimizer.RADAM: 
[2.6873403110589567, 2.2848777584058286, 1.9432397781298896, 1.6552856125616948, 1.4144226819237642, 1.41260788266853, 1.409924914461023, 1.40654531582648, 1.4025672017224886, 1.3980581649489405]
ADCME.Optimizer.AdaMax: 
[2.6873403110589567, 2.51968033219294, 2.3622082113112657, 2.2144819560814186, 2.076059233397677, 1.9464997124427983, 1.8253670164593165, 1.7122304206311472, 1.6066663584779952, 1.5082598767767736]
Test Summary: | Pass  Total
Optimizers    |    4      4
Test Summary: | Pass  Total
sinkhorn      |    1      1
Test Summary: | Pass  Total
dist          |    5      5
WARNING: Method definition f(Any, Any, Any) in module Main at /home/pkgeval/.julia/packages/ADCME/DBZ10/test/ode.jl:2 overwritten at /home/pkgeval/.julia/packages/ADCME/DBZ10/test/ode.jl:13.
Test Summary: | Pass  Total
runge_kutta   |    6      6
Test Summary: | Pass  Total
alpha scheme  |    2      2
Test Summary: | Pass  Total
LinearFlow    |    2      2
Test Summary:      | Pass  Total
AffineConstantFlow |    2      2
ActNorm: initializing s and t...
Test Summary: | Pass  Total
ActNorm       |    2      2
Test Summary: | Pass  Total
SlowMAF       |    2      2
Test Summary: | Pass  Total
MAF           |    2      2
Test Summary: | Pass  Total
IAF           |    2      2
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = tril(o::PyObject, num::Int64) at ops.jl:1136
└ @ ADCME ~/.julia/packages/ADCME/DBZ10/src/ops.jl:1136
┌ Warning: `getindex(o::PyObject, i::Integer)` is deprecated, use `get(o, i - 1)` instead.
│   caller = triu(o::PyObject, num::Int64) at ops.jl:1152
└ @ ADCME ~/.julia/packages/ADCME/DBZ10/src/ops.jl:1152
Test Summary:     | Pass  Total
Invertible1x1Conv |    2      2
Test Summary:  | Pass  Total
AffineHalfFlow |    2      2
Test Summary:      | Pass  Total
NeuralCouplingFlow |    2      2
Test Summary: | Pass  Total
Permute       |    2      2
Test Summary: | Pass  Total
composite     |    2      2
    Testing ADCME tests passed 
