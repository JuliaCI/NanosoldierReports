Julia Version 1.6.0-DEV.680
Commit bcbb00004d (2020-08-20 17:48 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake-avx512)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
[ Info: LEGAL NOTICE: package operations send anonymous data about your system to https://pkg.julialang.org (your current package server), including the operating system and Julia versions you are using, and a random client UUID. Running `Pkg.telemetryinfo()` will show exactly what data is sent. See https://julialang.org/legal/data/ for more details about what this data is used for, how long it is retained, and how to opt out of sending it.
  Installed CompilerSupportLibraries_jll ─ v0.3.3+0
  Installed CEnum ──────────────────────── v0.4.1
  Installed MacroTools ─────────────────── v0.5.5
  Installed OrderedCollections ─────────── v1.3.0
  Installed SpecialFunctions ───────────── v0.10.3
  Installed LLVM ───────────────────────── v2.0.0
  Installed Knet ───────────────────────── v1.4.0
  Installed CUDA ───────────────────────── v1.3.0
  Installed BinaryProvider ─────────────── v0.5.10
  Installed AutoGrad ───────────────────── v1.2.3
  Installed Reexport ───────────────────── v0.2.0
  Installed Zlib_jll ───────────────────── v1.2.11+15
  Installed AbstractFFTs ───────────────── v0.5.0
  Installed FileIO ─────────────────────── v1.4.1
  Installed GPUCompiler ────────────────── v0.6.0
  Installed GPUArrays ──────────────────── v5.1.0
  Installed TimerOutputs ───────────────── v0.5.6
  Installed ExprTools ──────────────────── v0.1.1
  Installed CodecZlib ──────────────────── v0.7.0
  Installed Requires ───────────────────── v1.0.1
  Installed OpenSpecFun_jll ────────────── v0.5.3+3
  Installed JLD2 ───────────────────────── v0.1.14
  Installed TranscodingStreams ─────────── v0.9.5
  Installed Adapt ──────────────────────── v2.0.2
  Installed DataStructures ─────────────── v0.17.20
  Installed NNlib ──────────────────────── v0.7.4
Updating `~/.julia/environments/v1.6/Project.toml`
  [1902f260] + Knet v1.4.0
Updating `~/.julia/environments/v1.6/Manifest.toml`
  [621f4979] + AbstractFFTs v0.5.0
  [79e6a3ab] + Adapt v2.0.2
  [6710c13c] + AutoGrad v1.2.3
  [b99e7846] + BinaryProvider v0.5.10
  [fa961155] + CEnum v0.4.1
  [052768ef] + CUDA v1.3.0
  [944b1d66] + CodecZlib v0.7.0
  [e66e0078] + CompilerSupportLibraries_jll v0.3.3+0
  [864edb3b] + DataStructures v0.17.20
  [e2ba6199] + ExprTools v0.1.1
  [5789e2e9] + FileIO v1.4.1
  [0c68f7d7] + GPUArrays v5.1.0
  [61eb1bfa] + GPUCompiler v0.6.0
  [033835bb] + JLD2 v0.1.14
  [1902f260] + Knet v1.4.0
  [929cbde3] + LLVM v2.0.0
  [1914dd2f] + MacroTools v0.5.5
  [872c559c] + NNlib v0.7.4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+3
  [bac558e1] + OrderedCollections v1.3.0
  [189a3867] + Reexport v0.2.0
  [ae029012] + Requires v1.0.1
  [276daf66] + SpecialFunctions v0.10.3
  [a759f4b9] + TimerOutputs v0.5.6
  [3bb67fe8] + TranscodingStreams v0.9.5
  [83775a58] + Zlib_jll v1.2.11+15
  [2a0f44e3] + Base64
  [ade2ca70] + Dates
  [8ba89e20] + Distributed
  [b77e0a4c] + InteractiveUtils
  [76f85450] + LibGit2
  [8f399da3] + Libdl
  [37e2e46d] + LinearAlgebra
  [56ddb016] + Logging
  [d6f4376e] + Markdown
  [a63ad114] + Mmap
  [44cfe95a] + Pkg
  [de0858da] + Printf
  [3fa0cd96] + REPL
  [9a3f8284] + Random
  [ea8e919c] + SHA
  [9e88b42a] + Serialization
  [6462fe0b] + Sockets
  [2f01184e] + SparseArrays
  [10745b16] + Statistics
  [8dfed614] + Test
  [cf7118a7] + UUIDs
  [4ec0a83e] + Unicode
    Testing Knet
Status `/tmp/jl_MjpwZ8/Project.toml`
  [6710c13c] AutoGrad v1.2.3
  [052768ef] CUDA v1.3.0
  [5789e2e9] FileIO v1.4.1
  [033835bb] JLD2 v0.1.14
  [1902f260] Knet v1.4.0
  [872c559c] NNlib v0.7.4
  [276daf66] SpecialFunctions v0.10.3
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [44cfe95a] Pkg
  [de0858da] Printf
  [9a3f8284] Random
  [10745b16] Statistics
  [8dfed614] Test
Status `/tmp/jl_MjpwZ8/Manifest.toml`
  [621f4979] AbstractFFTs v0.5.0
  [79e6a3ab] Adapt v2.0.2
  [6710c13c] AutoGrad v1.2.3
  [b99e7846] BinaryProvider v0.5.10
  [fa961155] CEnum v0.4.1
  [052768ef] CUDA v1.3.0
  [944b1d66] CodecZlib v0.7.0
  [e66e0078] CompilerSupportLibraries_jll v0.3.3+0
  [864edb3b] DataStructures v0.17.20
  [e2ba6199] ExprTools v0.1.1
  [5789e2e9] FileIO v1.4.1
  [0c68f7d7] GPUArrays v5.1.0
  [61eb1bfa] GPUCompiler v0.6.0
  [033835bb] JLD2 v0.1.14
  [1902f260] Knet v1.4.0
  [929cbde3] LLVM v2.0.0
  [1914dd2f] MacroTools v0.5.5
  [872c559c] NNlib v0.7.4
  [efe28fd5] OpenSpecFun_jll v0.5.3+3
  [bac558e1] OrderedCollections v1.3.0
  [189a3867] Reexport v0.2.0
  [ae029012] Requires v1.0.1
  [276daf66] SpecialFunctions v0.10.3
  [a759f4b9] TimerOutputs v0.5.6
  [3bb67fe8] TranscodingStreams v0.9.5
  [83775a58] Zlib_jll v1.2.11+15
  [2a0f44e3] Base64
  [ade2ca70] Dates
  [8ba89e20] Distributed
  [b77e0a4c] InteractiveUtils
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [d6f4376e] Markdown
  [a63ad114] Mmap
  [44cfe95a] Pkg
  [de0858da] Printf
  [3fa0cd96] REPL
  [9a3f8284] Random
  [ea8e919c] SHA
  [9e88b42a] Serialization
  [6462fe0b] Sockets
  [2f01184e] SparseArrays
  [10745b16] Statistics
  [8dfed614] Test
  [cf7118a7] UUIDs
  [4ec0a83e] Unicode
    Testing Running tests...
kptr.jl	255.085157 seconds (18.90 M allocations: 1.112 GiB, 0.62% gc time)
gpu.jl	Knet.LibKnet8.libknet8 = "/home/pkgeval/.julia/artifacts/5e1e317677e88277f0ee67ab9e17587a8edc4f7a/libknet8"
readdir(artifact"libknet8") = ["libknet8.so"]
CuDevice(0): Tesla T4
length(CUDA.devices()) = 1
CUDA.capability(CUDA.device()) = v"7.5.0"
CUDA.warpsize(CUDA.device()) = 32
CUDA.find_toolkit() = ["/usr/local/cuda-10.2/targets/x86_64-linux", "/usr/local/cuda-10.2"]
CUDA.version() = v"11.0.0"
Mem.info() = (15730475008, 15843721216)
CUDA.synchronize() = nothing
NVML.driver_version() = v"450.36.6"
NVML.version() = v"11.0.0+450.36.6"
NVML.cuda_driver_version() = v"11.0.0"
NVML.memory_info(nvmldev) = (total = 15843721216, free = 15730475008, used = 113246208)
CUBLAS.handle() = Ptr{Nothing} @0x0000000009207b40
CUBLAS.version() = v"10.2.2"
gpu: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/gpu.jl:3
  Got exception outside of a @test
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] top-level scope
      @ show.jl:868
   [14] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/gpu.jl:39
   [15] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [16] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/gpu.jl:8
   [17] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [18] macro expansion
      @ ./timing.jl:174 [inlined]
   [19] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
   [20] macro expansion
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
   [22] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [23] top-level scope
      @ none:6
   [24] eval(m::Module, e::Any)
      @ Core ./boot.jl:344
   [25] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:260
   [26] _start()
      @ Base ./client.jl:484
  
  5.568778 seconds (3.03 M allocations: 169.689 MiB, 0.88% gc time)
distributions.jl	  2.285759 seconds (3.22 M allocations: 181.224 MiB, 3.72% gc time)
dropout.jl	 19.113377 seconds (6.60 M allocations: 413.248 MiB, 0.85% gc time)
gcnode.jl	gcnode: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/gcnode.jl:8
  Got exception outside of a @test
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] (::RNN)(x::KnetArray{Float32,3}; batchSizes::Nothing)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/rnn.jl:348
   [14] (::RNN)(x::KnetArray{Float32,3})
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/rnn.jl:328
   [15] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/gcnode.jl:18
   [16] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [17] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/gcnode.jl:11
   [18] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [19] macro expansion
      @ ./timing.jl:174 [inlined]
   [20] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
   [21] macro expansion
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
   [22] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
   [23] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [24] top-level scope
      @ none:6
   [25] eval(m::Module, e::Any)
      @ Core ./boot.jl:344
   [26] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:260
   [27] _start()
      @ Base ./client.jl:484
  
  3.116943 seconds (4.50 M allocations: 246.909 MiB, 4.14% gc time)
jld.jl	 29.351070 seconds (29.50 M allocations: 1.567 GiB, 2.73% gc time)
statistics.jl	 26.620064 seconds (23.33 M allocations: 1.368 GiB, 2.61% gc time)
bmm.jl	Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4448
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3930
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4129 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6699
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7059
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7093
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr at /workspace/srcdir/src/jitlayers.cpp:313
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1888
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7ff4dc409a6f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
unknown function (ip: 0x7ff4dc408f23)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
unknown function (ip: 0x7ff4dc408cfc)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7ff4dc408b24)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7ff4dc4085d7)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
unknown function (ip: 0x7ff4dc407aab)
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
unknown function (ip: 0x7ff4dc4069c4)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_body at /workspace/srcdir/src/interpreter.c:436
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:41 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:9
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_15030.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1752 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4448
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3930
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4129 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6699
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7059
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7093
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /workspace/srcdir/src/jitlayers.cpp:350
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1894
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7ff4dc409a6f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
unknown function (ip: 0x7ff4dc408f23)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
unknown function (ip: 0x7ff4dc408cfc)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7ff4dc408b24)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7ff4dc4085d7)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
unknown function (ip: 0x7ff4dc407aab)
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
unknown function (ip: 0x7ff4dc4069c4)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_body at /workspace/srcdir/src/interpreter.c:436
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:41 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:9
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_15030.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1752 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
bmm: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:8
  Got exception outside of a @test
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/bmm.jl:41
   [31] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/bmm.jl:9
   [33] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [34] macro expansion
      @ ./timing.jl:174 [inlined]
   [35] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
   [36] macro expansion
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
   [37] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
   [38] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [39] top-level scope
      @ none:6
   [40] eval(m::Module, e::Any)
      @ Core ./boot.jl:344
   [41] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:260
   [42] _start()
      @ Base ./client.jl:484
  
 49.886610 seconds (43.40 M allocations: 2.483 GiB, 4.55% gc time)
serialize.jl	serialize: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/serialize.jl:10
  Got exception outside of a @test
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] (::RNN)(x::KnetArray{Float32,3}; batchSizes::Nothing)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/rnn.jl:348
   [14] RNN
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20/rnn.jl:328 [inlined]
   [15] (::var"#m1test#61")(M1::RNN, xgpu::KnetArray{Float32,3}, xcpu::Array{Float32,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/serialize.jl:40
   [16] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/serialize.jl:50
   [17] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/serialize.jl:11
   [19] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [20] macro expansion
      @ ./timing.jl:174 [inlined]
   [21] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
   [22] macro expansion
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
   [23] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
   [24] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [25] top-level scope
      @ none:6
   [26] eval(m::Module, e::Any)
      @ Core ./boot.jl:344
   [27] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:260
   [28] _start()
      @ Base ./client.jl:484
  
  8.762922 seconds (6.86 M allocations: 392.643 MiB, 2.85% gc time)
loss.jl	
Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Function)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
 [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}})
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
 [21] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [22] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [23] (::AutoGrad.var"#203#205"{Tuple{},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [25] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [26] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [27] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float64})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [28] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:17
 [29] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [30] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [31] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [32] macro expansion
    @ ./timing.jl:174 [inlined]
 [33] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [34] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [35] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [36] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [37] top-level scope
    @ none:6
 [38] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [39] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [40] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:17
  Test threw exception
  Expression: gradcheck(f, k)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float64})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:17
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Function)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
   [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}})
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
   [21] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [22] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [23] (::AutoGrad.var"#203#205"{Tuple{},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [25] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [26] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [27] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float64})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [28] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:17
   [29] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [22] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [23] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [24] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [25] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:18
 [26] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [28] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [29] macro expansion
    @ ./timing.jl:174 [inlined]
 [30] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [31] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [32] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [33] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [34] top-level scope
    @ none:6
 [35] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [36] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [37] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:18
  Test threw exception
  Expression: gradcheck(f, k, kw = (:dims => 1,))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:18
   [5] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [22] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [23] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [24] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [25] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:18
   [26] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
 [21] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [22] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [26] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:19
 [27] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [28] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [29] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [30] macro expansion
    @ ./timing.jl:174 [inlined]
 [31] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [32] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [33] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [34] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [35] top-level scope
    @ none:6
 [36] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [37] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [38] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:19
  Test threw exception
  Expression: gradcheck(f, k, kw = (:dims => 2,))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:19
   [5] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
   [21] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [22] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [26] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:19
   [27] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [28] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:20
  Test threw exception
  Expression: isapprox(f(a), f(k))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] #logsoftmax#46
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13 [inlined]
   [18] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64})
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:20
   [20] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:21
  Test threw exception
  Expression: isapprox(f(a, dims = 1), f(k, dims = 1))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:21
   [19] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:22
  Test threw exception
  Expression: isapprox(f(a, dims = 2), f(k, dims = 2))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:22
   [20] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{KnetArray{Float64,3}}; dims::Function)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
 [20] logsoftmax(x::Param{KnetArray{Float64,3}})
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
 [21] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [22] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [23] (::AutoGrad.var"#203#205"{Tuple{},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [25] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [26] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [27] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [28] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:36
 [29] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [30] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [31] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [32] macro expansion
    @ ./timing.jl:174 [inlined]
 [33] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [34] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [35] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [36] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [37] top-level scope
    @ none:6
 [38] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [39] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [40] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:36
  Test threw exception
  Expression: gradcheck(f, k)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:36
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{KnetArray{Float64,3}}; dims::Function)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
   [20] logsoftmax(x::Param{KnetArray{Float64,3}})
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
   [21] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [22] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [23] (::AutoGrad.var"#203#205"{Tuple{},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [25] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [26] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [27] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [28] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:36
   [29] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:37
  Test threw exception
  Expression: isapprox(f(a), f(k))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::KnetArray{Float64,3}; dims::Function)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
   [18] logsoftmax(x::KnetArray{Float64,3})
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:37
   [20] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{KnetArray{Float64,3}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [22] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [23] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [24] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [25] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:39
 [26] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [28] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [29] macro expansion
    @ ./timing.jl:174 [inlined]
 [30] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [31] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [32] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [33] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [34] top-level scope
    @ none:6
 [35] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [36] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [37] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:39
  Test threw exception
  Expression: gradcheck(f, k, kw = (:dims => d,))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:39
   [5] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{KnetArray{Float64,3}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [22] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [23] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [24] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [25] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:39
   [26] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:40
  Test threw exception
  Expression: isapprox(f(a, dims = d), f(k, dims = d))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:40
   [19] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:53
  Test threw exception
  Expression: softmax(k, dims = d) ≈ exp.(logsoftmax(k, dims = d))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:53
   [19] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:54
  Test threw exception
  Expression: all(Array(sum(softmax(k, dims = d), dims = d)) .≈ 1)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:54
   [19] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:53
  Test threw exception
  Expression: softmax(k, dims = d) ≈ exp.(logsoftmax(k, dims = d))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:53
   [19] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:54
  Test threw exception
  Expression: all(Array(sum(softmax(k, dims = d), dims = d)) .≈ 1)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:54
   [19] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] nll(scores::Param{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
 [21] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [22] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(nll),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [26] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:69
 [27] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [28] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [29] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [30] macro expansion
    @ ./timing.jl:174 [inlined]
 [31] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [32] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [33] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [34] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [35] top-level scope
    @ none:6
 [36] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [37] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [38] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:69
  Test threw exception
  Expression: gradcheck(nll, k, indices, kw = (:dims => 1,), args = 1)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:69
   [5] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] nll(scores::Param{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [21] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [22] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(nll),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [26] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:69
   [27] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [28] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
 [21] nll(scores::Param{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
 [22] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [23] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(nll),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [25] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [26] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:70
 [28] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:70
  Test threw exception
  Expression: gradcheck(nll, k, indices, kw = (:dims => 2,), args = 1)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:70
   [5] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
   [21] nll(scores::Param{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [22] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [23] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(nll),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [25] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [26] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:70
   [28] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:73
  Test threw exception
  Expression: isapprox(nll(k, indices, dims = 1), nll(a, indices, dims = 1))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] nll(scores::Knet.KnetArrays.KnetMatrix{Float64}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:73
   [20] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:74
  Test threw exception
  Expression: isapprox(nll(k, indices, dims = 2), nll(a, indices, dims = 2))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
   [19] nll(scores::Knet.KnetArrays.KnetMatrix{Float64}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:74
   [21] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [22] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:87
  Test threw exception
  Expression: isapprox(softmax(x, dims = 1), _cudnnSoftmaxForward(x, algo = CUDNN_SOFTMAX_FAST))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:87
   [19] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:88
  Test threw exception
  Expression: isapprox(softmax(x, dims = 1), _cudnnSoftmaxForward(x, algo = CUDNN_SOFTMAX_ACCURATE))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:88
   [19] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:89
  Test threw exception
  Expression: isapprox(logsoftmax(x, dims = 1), _cudnnSoftmaxForward(x, algo = CUDNN_SOFTMAX_LOG))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:89
   [19] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:90
  Test threw exception
  Expression: isapprox(∇softmax(x, y1, dy, dims = 1), _cudnnSoftmaxBackward(y1, dy, algo = CUDNN_SOFTMAX_FAST))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:90
   [18] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:91
  Test threw exception
  Expression: isapprox(∇softmax(x, y1, dy, dims = 1), _cudnnSoftmaxBackward(y1, dy, algo = CUDNN_SOFTMAX_ACCURATE))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:91
   [18] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:92
  Test threw exception
  Expression: isapprox(∇logsoftmax(x, y2, dy, dims = 1), _cudnnSoftmaxBackward(y2, dy, algo = CUDNN_SOFTMAX_LOG))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:92
   [18] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] (::var"#70#80")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#70#80",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:93
 [28] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:93
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:93 =# @gcheck _cudnnSoftmaxForward(Param(x), algo = CUDNN_SOFTMAX_FAST)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:93
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] (::var"#70#80")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#70#80",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:93
   [28] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] (::var"#71#81")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#71#81",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:94
 [28] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:94
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:94 =# @gcheck _cudnnSoftmaxForward(Param(x), algo = CUDNN_SOFTMAX_ACCURATE)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:94
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] (::var"#71#81")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#71#81",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:94
   [28] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] (::var"#72#82")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#72#82",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:95
 [28] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:95
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:95 =# @gcheck _cudnnSoftmaxForward(Param(x), algo = CUDNN_SOFTMAX_LOG)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:95
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] (::var"#72#82")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#72#82",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:95
   [28] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
 [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxBackward#56
    @ ./none:0 [inlined]
 [19] (::var"#73#83")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#73#83",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:96
 [28] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:96
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:96 =# @gcheck _cudnnSoftmaxBackward(Param(y1), Param(dy), algo = CUDNN_SOFTMAX_FAST)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:96
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxBackward#56
      @ ./none:0 [inlined]
   [19] (::var"#73#83")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#73#83",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:96
   [28] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
 [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxBackward#56
    @ ./none:0 [inlined]
 [19] (::var"#74#84")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#74#84",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:97
 [28] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:97
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:97 =# @gcheck _cudnnSoftmaxBackward(Param(y1), Param(dy), algo = CUDNN_SOFTMAX_ACCURATE)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:97
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxBackward#56
      @ ./none:0 [inlined]
   [19] (::var"#74#84")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#74#84",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:97
   [28] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
 [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxBackward#56
    @ ./none:0 [inlined]
 [19] (::var"#75#85")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#75#85",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:98
 [28] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:98
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:98 =# @gcheck _cudnnSoftmaxBackward(Param(y2), Param(dy), algo = CUDNN_SOFTMAX_LOG)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:98
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxBackward#56
      @ ./none:0 [inlined]
   [19] (::var"#75#85")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#75#85",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:98
   [28] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:107
  Test threw exception
  Expression: isapprox(f(a, b, c), f(A, B, C))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] nll(scores::Knet.KnetArrays.KnetMatrix{Float64}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [19] nll
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38 [inlined]
   [20] (::var"#f#86")(w::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:107
   [22] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [23] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
 [21] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64})
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38
 [22] (::var"#f#86")(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
 [23] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
 [25] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
 [26] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:108
 [28] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:108
  Test threw exception
  Expression: isapprox(∇f(a, b, c), ∇f(A, B, C))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [3] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [4] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:108
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [21] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64})
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38
   [22] (::var"#f#86")(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
   [23] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [25] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [26] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:108
   [28] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
 [21] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64})
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38
 [22] (::var"#f#86")(w::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
 [23] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
 [25] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
 [26] gradfun
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221 [inlined]
 [27] (::var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}})(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64}, j::Int64)
    @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:103
 [28] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [29] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
 [30] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
 [31] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
 [32] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
 [33] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] macro expansion
    @ ./timing.jl:174 [inlined]
 [37] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [38] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [39] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [40] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [41] top-level scope
    @ none:6
 [42] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [43] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [44] _start()
    @ Base ./client.jl:484

Stacktrace:
  [1] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
  [2] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
  [3] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
  [4] gradfun
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221 [inlined]
  [5] (::var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}})(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64}, j::Int64)
    @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:103
  [6] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
  [7] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
  [8] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
  [9] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
 [10] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
 [11] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [12] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [13] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [14] macro expansion
    @ ./timing.jl:174 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [16] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [17] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [18] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [19] top-level scope
    @ none:6
 [20] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [21] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [22] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:110
  Test threw exception
  Expression: isapprox(∇∇fj(a, b, c, i), ∇∇fj(A, B, C, i))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [3] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [4] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
    [2] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
    [3] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
    [4] gradfun
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221 [inlined]
    [5] (::var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}})(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64}, j::Int64)
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:103
    [6] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
    [7] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
    [8] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
    [9] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [10] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
   [11] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [12] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/d6WNR/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/d6WNR/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/d6WNR/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [21] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64})
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38
   [22] (::var"#f#86")(w::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
   [23] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [25] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [26] gradfun
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221 [inlined]
   [27] (::var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}})(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64}, j::Int64)
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:103
   [28] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [29] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [30] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [31] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
   [33] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
 71.972613 seconds (50.44 M allocations: 2.958 GiB, 2.72% gc time)
cuarray.jl	┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{2}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4448
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3930
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4129 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6699
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7059
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7093
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr at /workspace/srcdir/src/jitlayers.cpp:313
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1888
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7ff4dc38c1bf)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
unknown function (ip: 0x7ff4dc38bad5)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
unknown function (ip: 0x7ff4dc38b87f)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7ff4dc38b6c1)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7ff4dc38b0d0)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
hcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
#104 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7ff4dc38359c)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7ff4dc38347c)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7ff4dc513224)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_body at /workspace/srcdir/src/interpreter.c:436
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_15030.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1752 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4448
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3930
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4129 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6699
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7059
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7093
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /workspace/srcdir/src/jitlayers.cpp:350
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1894
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7ff4dc38c1bf)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
unknown function (ip: 0x7ff4dc38bad5)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
unknown function (ip: 0x7ff4dc38b87f)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7ff4dc38b6c1)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7ff4dc38b0d0)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
hcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
#104 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7ff4dc38359c)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7ff4dc38347c)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7ff4dc513224)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_body at /workspace/srcdir/src/interpreter.c:436
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_15030.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1752 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuVector{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{2})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] hcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
 [35] (::var"#104#124"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
 [44] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 =# @gcheck hcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuVector{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{2})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] hcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
   [35] (::var"#104#124"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [44] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{1}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4448
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3930
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4129 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6699
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7059
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7093
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr at /workspace/srcdir/src/jitlayers.cpp:313
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1888
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7ff4dc3935cf)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
unknown function (ip: 0x7ff4dc392f05)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
unknown function (ip: 0x7ff4dc392cbf)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7ff4dc392b11)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7ff4dc3927d0)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
vcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
#105 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7ff4dc39003c)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7ff4dc38ff1c)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7ff4dc513224)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_body at /workspace/srcdir/src/interpreter.c:436
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_15030.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1752 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4448
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3930
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4129 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6699
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7059
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7093
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /workspace/srcdir/src/jitlayers.cpp:350
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1894
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7ff4dc3935cf)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
unknown function (ip: 0x7ff4dc392f05)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
unknown function (ip: 0x7ff4dc392cbf)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7ff4dc392b11)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7ff4dc3927d0)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
vcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
#105 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7ff4dc39003c)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7ff4dc38ff1c)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7ff4dc513224)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_body at /workspace/srcdir/src/interpreter.c:436
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_15030.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1752 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{1})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] vcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
 [35] (::var"#105#125"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
 [44] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 =# @gcheck vcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{1})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] vcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
   [35] (::var"#105#125"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [44] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Int64) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4448
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3930
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4129 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6699
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7059
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7093
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr at /workspace/srcdir/src/jitlayers.cpp:313
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1888
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7ff4dc3a3f4f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
unknown function (ip: 0x7ff4dc3a3893)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
unknown function (ip: 0x7ff4dc3a366c)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7ff4dc3a34a4)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7ff4dc3a31e7)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
unknown function (ip: 0x7ff4dc3a2c1b)
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
unknown function (ip: 0x7ff4dc3a1ff4)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:23 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_15030.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1752 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4448
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3930
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4129 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6699
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7059
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7093
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /workspace/srcdir/src/jitlayers.cpp:350
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1894
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7ff4dc3a3f4f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
unknown function (ip: 0x7ff4dc3a3893)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
unknown function (ip: 0x7ff4dc3a366c)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7ff4dc3a34a4)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7ff4dc3a31e7)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
unknown function (ip: 0x7ff4dc3a2c1b)
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
unknown function (ip: 0x7ff4dc3a1ff4)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:23 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_15030.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1752 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:23
  Test threw exception
  Expression: permutedims(a0, (2, 1)) == permutedims(a1, (2, 1))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:23
   [31] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:24
  Test threw exception
  Expression: permutedims(a0, (1, 2)) == permutedims(a1, (1, 2))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:24
   [31] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#98#118"{Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [36] (::AutoGrad.var"#220#225"{Tuple{},var"#98#118"{Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [40] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29 =# @gcheck permutedims(a3, (2, 1))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#98#118"{Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [36] (::AutoGrad.var"#220#225"{Tuple{},var"#98#118"{Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [40] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#99#119"{Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [36] (::AutoGrad.var"#220#225"{Tuple{},var"#99#119"{Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [40] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30 =# @gcheck permutedims(a3, (1, 2))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#99#119"{Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [36] (::AutoGrad.var"#220#225"{Tuple{},var"#99#119"{Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [40] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{2}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4448
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3930
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4129 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6699
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7059
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7093
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr at /workspace/srcdir/src/jitlayers.cpp:313
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1888
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7ff4dc3b512f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
unknown function (ip: 0x7ff4dc3b4a25)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
unknown function (ip: 0x7ff4dc3b47cf)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7ff4dc3b4611)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7ff4dc3b42b0)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
hcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
#104 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7ff4dc3b226c)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7ff4dc3b214c)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7ff4dc513224)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_body at /workspace/srcdir/src/interpreter.c:436
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_15030.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1752 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4448
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3930
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4129 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6699
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7059
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7093
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /workspace/srcdir/src/jitlayers.cpp:350
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1894
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7ff4dc3b512f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
unknown function (ip: 0x7ff4dc3b4a25)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
unknown function (ip: 0x7ff4dc3b47cf)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7ff4dc3b4611)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7ff4dc3b42b0)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
hcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
#104 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7ff4dc3b226c)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7ff4dc3b214c)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7ff4dc513224)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_body at /workspace/srcdir/src/interpreter.c:436
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_15030.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1752 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{2})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] hcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
 [35] (::var"#104#124"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
 [44] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 =# @gcheck hcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{2})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] hcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
   [35] (::var"#104#124"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [44] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{1}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{1})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] vcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
 [35] (::var"#105#125"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
 [44] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 =# @gcheck vcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{1})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] vcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
   [35] (::var"#105#125"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [44] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4448
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3930
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4129 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6699
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7059
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7093
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr at /workspace/srcdir/src/jitlayers.cpp:313
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1888
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7ff4dc3c387f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
unknown function (ip: 0x7ff4dc3c315e)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
unknown function (ip: 0x7ff4dc3c2ef8)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7ff4dc3c2d2b)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7ff4dc3c29f8)
_unsafe_getindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
getindex at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
unknown function (ip: 0x7ff4dc3c2296)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:14 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_15030.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1752 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4448
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3930
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4129 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6699
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7059
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7093
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /workspace/srcdir/src/jitlayers.cpp:350
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1894
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7ff4dc3c387f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
unknown function (ip: 0x7ff4dc3c315e)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
unknown function (ip: 0x7ff4dc3c2ef8)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7ff4dc3c2d2b)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7ff4dc3c29f8)
_unsafe_getindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
getindex at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
unknown function (ip: 0x7ff4dc3c2296)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:14 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_15030.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1752 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:14
  Test threw exception
  Expression: getindex(a0, idx...) == getindex(a1, idx...)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:119
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
   [28] _unsafe_getindex!
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
   [29] getindex(::KnetArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:14
   [31] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:119
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
 [28] _unsafe_getindex!
    @ ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
 [29] getindex(::KnetArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] getindex
    @ ./none:0 [inlined]
 [33] (::var"#91#111"{Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Param{KnetArray{Float64,3}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [36] (::AutoGrad.var"#220#225"{Tuple{},var"#91#111"{Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Param{KnetArray{Float64,3}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [40] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16 =# @gcheck getindex(a3, idx...)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:119
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
   [28] _unsafe_getindex!
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
   [29] getindex(::KnetArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] getindex
      @ ./none:0 [inlined]
   [33] (::var"#91#111"{Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Param{KnetArray{Float64,3}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [36] (::AutoGrad.var"#220#225"{Tuple{},var"#91#111"{Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Param{KnetArray{Float64,3}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [40] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:32
  Test threw exception
  Expression: permutedims(a0, (1, 3, 2)) == permutedims(a1, (1, 3, 2))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:32
   [31] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#101#121"{Param{KnetArray{Float64,3}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [36] (::AutoGrad.var"#220#225"{Tuple{},var"#101#121"{Param{KnetArray{Float64,3}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [40] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34 =# @gcheck permutedims(a3, (1, 3, 2))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#101#121"{Param{KnetArray{Float64,3}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [36] (::AutoGrad.var"#220#225"{Tuple{},var"#101#121"{Param{KnetArray{Float64,3}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [40] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{2}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4448
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3930
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4129 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6699
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7059
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7093
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr at /workspace/srcdir/src/jitlayers.cpp:313
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1888
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7ff4dc1d5bbf)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
unknown function (ip: 0x7ff4dc1d5475)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
unknown function (ip: 0x7ff4dc1d51ef)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7ff4dc1d5001)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7ff4dc1d4c70)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134 [inlined]
hcat at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:130
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:36 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_15030.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1752 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4448
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3930
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4129 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6699
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7059
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7093
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /workspace/srcdir/src/jitlayers.cpp:350
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1894
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7ff4dc1d5bbf)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
unknown function (ip: 0x7ff4dc1d5475)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
unknown function (ip: 0x7ff4dc1d51ef)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7ff4dc1d5001)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7ff4dc1d4c70)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134 [inlined]
hcat at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:130
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:36 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_15030.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1752 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:36
  Test threw exception
  Expression: hcat(a0, b0) == hcat(a1, b1)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{2})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] hcat(::KnetArray{Float64,3}, ::KnetArray{Float64,3})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:130
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:36
   [34] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [35] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{2})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] hcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
 [35] (::var"#104#124"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
 [44] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 =# @gcheck hcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{2})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] hcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
   [35] (::var"#104#124"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [44] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{1}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{1})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] vcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
 [35] (::var"#105#125"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
 [44] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 =# @gcheck vcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{1})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] vcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
   [35] (::var"#105#125"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [44] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:47
  Test threw exception
  Expression: setindex!(a0, b0[idx...], idx...) == setindex!(a1, b1[idx...], idx...)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:119
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
   [28] _unsafe_getindex!
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
   [29] getindex(::KnetArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:47
   [31] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
  Expression: argmax(a0, dims = i) == argmax(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(8, 1, 1) CartesianIndex(5, 2, 1) … CartesianIndex(3, 7, 1) CartesianIndex(6, 8, 1)]

CartesianIndex{3}[CartesianIndex(5, 1, 2) CartesianIndex(4, 2, 2) … CartesianIndex(5, 7, 2) CartesianIndex(1, 8, 2)]

CartesianIndex{3}[CartesianIndex(8, 1, 3) CartesianIndex(2, 2, 3) … CartesianIndex(3, 7, 3) CartesianIndex(4, 8, 3)]

CartesianIndex{3}[CartesianIndex(1, 1, 4) CartesianIndex(2, 2, 4) … CartesianIndex(7, 7, 4) CartesianIndex(5, 8, 4)]

CartesianIndex{3}[CartesianIndex(2, 1, 5) CartesianIndex(6, 2, 5) … CartesianIndex(8, 7, 5) CartesianIndex(5, 8, 5)]

CartesianIndex{3}[CartesianIndex(3, 1, 6) CartesianIndex(6, 2, 6) … CartesianIndex(2, 7, 6) CartesianIndex(7, 8, 6)]

CartesianIndex{3}[CartesianIndex(8, 1, 7) CartesianIndex(6, 2, 7) … CartesianIndex(2, 7, 7) CartesianIndex(2, 8, 7)]

CartesianIndex{3}[CartesianIndex(2, 1, 8) CartesianIndex(3, 2, 8) … CartesianIndex(3, 7, 8) CartesianIndex(5, 8, 8)] == CartesianIndex{3}[CartesianIndex(8, 1, 1) CartesianIndex(5, 2, 1) … CartesianIndex(3, 7, 1) CartesianIndex(6, 8, 1)]

CartesianIndex{3}[CartesianIndex(5, 1, 2) CartesianIndex(5, 2, 2) … CartesianIndex(5, 7, 2) CartesianIndex(1, 8, 2)]

CartesianIndex{3}[CartesianIndex(8, 1, 3) CartesianIndex(4, 2, 3) … CartesianIndex(3, 7, 3) CartesianIndex(4, 8, 3)]

CartesianIndex{3}[CartesianIndex(1, 1, 4) CartesianIndex(6, 2, 4) … CartesianIndex(7, 7, 4) CartesianIndex(5, 8, 4)]

CartesianIndex{3}[CartesianIndex(2, 1, 5) CartesianIndex(6, 2, 5) … CartesianIndex(8, 7, 5) CartesianIndex(5, 8, 5)]

CartesianIndex{3}[CartesianIndex(3, 1, 6) CartesianIndex(6, 2, 6) … CartesianIndex(2, 7, 6) CartesianIndex(7, 8, 6)]

CartesianIndex{3}[CartesianIndex(8, 1, 7) CartesianIndex(6, 2, 7) … CartesianIndex(2, 7, 7) CartesianIndex(2, 8, 7)]

CartesianIndex{3}[CartesianIndex(2, 1, 8) CartesianIndex(3, 2, 8) … CartesianIndex(3, 7, 8) CartesianIndex(5, 8, 8)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
 [2] top-level scope
   @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
  Expression: argmin(a0, dims = i) == argmin(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(4, 1, 1) CartesianIndex(8, 2, 1) … CartesianIndex(8, 7, 1) CartesianIndex(3, 8, 1)]

CartesianIndex{3}[CartesianIndex(3, 1, 2) CartesianIndex(3, 2, 2) … CartesianIndex(7, 7, 2) CartesianIndex(4, 8, 2)]

CartesianIndex{3}[CartesianIndex(1, 1, 3) CartesianIndex(4, 2, 3) … CartesianIndex(5, 7, 3) CartesianIndex(7, 8, 3)]

CartesianIndex{3}[CartesianIndex(7, 1, 4) CartesianIndex(1, 2, 4) … CartesianIndex(3, 7, 4) CartesianIndex(1, 8, 4)]

CartesianIndex{3}[CartesianIndex(5, 1, 5) CartesianIndex(7, 2, 5) … CartesianIndex(1, 7, 5) CartesianIndex(6, 8, 5)]

CartesianIndex{3}[CartesianIndex(5, 1, 6) CartesianIndex(7, 2, 6) … CartesianIndex(5, 7, 6) CartesianIndex(8, 8, 6)]

CartesianIndex{3}[CartesianIndex(1, 1, 7) CartesianIndex(3, 2, 7) … CartesianIndex(5, 7, 7) CartesianIndex(1, 8, 7)]

CartesianIndex{3}[CartesianIndex(1, 1, 8) CartesianIndex(2, 2, 8) … CartesianIndex(4, 7, 8) CartesianIndex(7, 8, 8)] == CartesianIndex{3}[CartesianIndex(4, 1, 1) CartesianIndex(8, 2, 1) … CartesianIndex(8, 7, 1) CartesianIndex(3, 8, 1)]

CartesianIndex{3}[CartesianIndex(3, 1, 2) CartesianIndex(3, 2, 2) … CartesianIndex(7, 7, 2) CartesianIndex(4, 8, 2)]

CartesianIndex{3}[CartesianIndex(1, 1, 3) CartesianIndex(3, 2, 3) … CartesianIndex(5, 7, 3) CartesianIndex(7, 8, 3)]

CartesianIndex{3}[CartesianIndex(7, 1, 4) CartesianIndex(2, 2, 4) … CartesianIndex(3, 7, 4) CartesianIndex(1, 8, 4)]

CartesianIndex{3}[CartesianIndex(5, 1, 5) CartesianIndex(7, 2, 5) … CartesianIndex(1, 7, 5) CartesianIndex(6, 8, 5)]

CartesianIndex{3}[CartesianIndex(5, 1, 6) CartesianIndex(7, 2, 6) … CartesianIndex(5, 7, 6) CartesianIndex(8, 8, 6)]

CartesianIndex{3}[CartesianIndex(1, 1, 7) CartesianIndex(3, 2, 7) … CartesianIndex(5, 7, 7) CartesianIndex(1, 8, 7)]

CartesianIndex{3}[CartesianIndex(1, 1, 8) CartesianIndex(2, 2, 8) … CartesianIndex(4, 7, 8) CartesianIndex(7, 8, 8)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
 [2] top-level scope
   @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
  Expression: findmax(a0, dims = i) == findmax(a1, dims = i)
   Evaluated: ([0.9546754666596038 0.9333860017479498 … 0.9653395532222706 0.8941852438554894]

[0.9523306475869449 0.9891601449593961 … 0.9470515128554 0.782542121214354]

[0.8804503275054871 0.9497246552650624 … 0.8916881513166606 0.9524050224982874]

[0.9132709641551144 0.8001901670213212 … 0.6673843409359193 0.9515556940444527]

[0.9295112608866625 0.9976922252206566 … 0.9920460576865235 0.98419996876651]

[0.8958679241150136 0.7559132659141219 … 0.8645724245263573 0.6931630376938496]

[0.9505118042348875 0.8663879798016021 … 0.9959626472627832 0.9555122543162526]

[0.9152504245450046 0.8480254807508998 … 0.8831186573369891 0.9748751216341489], CartesianIndex{3}[CartesianIndex(8, 1, 1) CartesianIndex(5, 2, 1) … CartesianIndex(3, 7, 1) CartesianIndex(6, 8, 1)]

CartesianIndex{3}[CartesianIndex(5, 1, 2) CartesianIndex(4, 2, 2) … CartesianIndex(5, 7, 2) CartesianIndex(1, 8, 2)]

CartesianIndex{3}[CartesianIndex(8, 1, 3) CartesianIndex(2, 2, 3) … CartesianIndex(3, 7, 3) CartesianIndex(4, 8, 3)]

CartesianIndex{3}[CartesianIndex(1, 1, 4) CartesianIndex(2, 2, 4) … CartesianIndex(7, 7, 4) CartesianIndex(5, 8, 4)]

CartesianIndex{3}[CartesianIndex(2, 1, 5) CartesianIndex(6, 2, 5) … CartesianIndex(8, 7, 5) CartesianIndex(5, 8, 5)]

CartesianIndex{3}[CartesianIndex(3, 1, 6) CartesianIndex(6, 2, 6) … CartesianIndex(2, 7, 6) CartesianIndex(7, 8, 6)]

CartesianIndex{3}[CartesianIndex(8, 1, 7) CartesianIndex(6, 2, 7) … CartesianIndex(2, 7, 7) CartesianIndex(2, 8, 7)]

CartesianIndex{3}[CartesianIndex(2, 1, 8) CartesianIndex(3, 2, 8) … CartesianIndex(3, 7, 8) CartesianIndex(5, 8, 8)]) == ([0.9546754666596038 0.9333860017479498 … 0.9653395532222706 0.8941852438554894]

[0.9523306475869449 0.9577923170489482 … 0.9470515128554 0.782542121214354]

[0.8804503275054871 0.9178366078569256 … 0.8916881513166606 0.9524050224982874]

[0.9132709641551144 0.7939518732411608 … 0.6673843409359193 0.9515556940444527]

[0.9295112608866625 0.9976922252206566 … 0.9920460576865235 0.98419996876651]

[0.8958679241150136 0.7559132659141219 … 0.8645724245263573 0.6931630376938496]

[0.9505118042348875 0.8663879798016021 … 0.9959626472627832 0.9555122543162526]

[0.9152504245450046 0.8480254807508998 … 0.8831186573369891 0.9748751216341489], CartesianIndex{3}[CartesianIndex(8, 1, 1) CartesianIndex(5, 2, 1) … CartesianIndex(3, 7, 1) CartesianIndex(6, 8, 1)]

CartesianIndex{3}[CartesianIndex(5, 1, 2) CartesianIndex(5, 2, 2) … CartesianIndex(5, 7, 2) CartesianIndex(1, 8, 2)]

CartesianIndex{3}[CartesianIndex(8, 1, 3) CartesianIndex(4, 2, 3) … CartesianIndex(3, 7, 3) CartesianIndex(4, 8, 3)]

CartesianIndex{3}[CartesianIndex(1, 1, 4) CartesianIndex(6, 2, 4) … CartesianIndex(7, 7, 4) CartesianIndex(5, 8, 4)]

CartesianIndex{3}[CartesianIndex(2, 1, 5) CartesianIndex(6, 2, 5) … CartesianIndex(8, 7, 5) CartesianIndex(5, 8, 5)]

CartesianIndex{3}[CartesianIndex(3, 1, 6) CartesianIndex(6, 2, 6) … CartesianIndex(2, 7, 6) CartesianIndex(7, 8, 6)]

CartesianIndex{3}[CartesianIndex(8, 1, 7) CartesianIndex(6, 2, 7) … CartesianIndex(2, 7, 7) CartesianIndex(2, 8, 7)]

CartesianIndex{3}[CartesianIndex(2, 1, 8) CartesianIndex(3, 2, 8) … CartesianIndex(3, 7, 8) CartesianIndex(5, 8, 8)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
 [2] top-level scope
   @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
  Expression: findmin(a0, dims = i) == findmin(a1, dims = i)
   Evaluated: ([0.1493076359639245 0.02253246200002934 … 0.03660688595480299 0.07631565439626709]

[0.08005127867623485 0.4038057390976424 … 0.04964447696693175 0.1398468516011775]

[0.0883753777458085 0.2233873439280678 … 0.1491798398622044 0.1356286642210447]

[0.04307841934760015 0.2688994428597744 … 0.07100604453707149 0.10657303350837899]

[0.08011629491969807 0.002209693151838721 … 0.07034051976001221 0.09775501631794592]

[0.02448989013587366 0.2669023614373067 … 0.06075737445959839 0.0681143783110707]

[0.241760678299896 0.027728912441334463 … 0.25891239475713723 0.15856023332837554]

[0.03980561593299914 0.1404699046045228 … 0.12622283933451128 0.12093813719415625], CartesianIndex{3}[CartesianIndex(4, 1, 1) CartesianIndex(8, 2, 1) … CartesianIndex(8, 7, 1) CartesianIndex(3, 8, 1)]

CartesianIndex{3}[CartesianIndex(3, 1, 2) CartesianIndex(3, 2, 2) … CartesianIndex(7, 7, 2) CartesianIndex(4, 8, 2)]

CartesianIndex{3}[CartesianIndex(1, 1, 3) CartesianIndex(4, 2, 3) … CartesianIndex(5, 7, 3) CartesianIndex(7, 8, 3)]

CartesianIndex{3}[CartesianIndex(7, 1, 4) CartesianIndex(1, 2, 4) … CartesianIndex(3, 7, 4) CartesianIndex(1, 8, 4)]

CartesianIndex{3}[CartesianIndex(5, 1, 5) CartesianIndex(7, 2, 5) … CartesianIndex(1, 7, 5) CartesianIndex(6, 8, 5)]

CartesianIndex{3}[CartesianIndex(5, 1, 6) CartesianIndex(7, 2, 6) … CartesianIndex(5, 7, 6) CartesianIndex(8, 8, 6)]

CartesianIndex{3}[CartesianIndex(1, 1, 7) CartesianIndex(3, 2, 7) … CartesianIndex(5, 7, 7) CartesianIndex(1, 8, 7)]

CartesianIndex{3}[CartesianIndex(1, 1, 8) CartesianIndex(2, 2, 8) … CartesianIndex(4, 7, 8) CartesianIndex(7, 8, 8)]) == ([0.1493076359639245 0.02253246200002934 … 0.03660688595480299 0.07631565439626709]

[0.08005127867623485 0.014246752026393139 … 0.04964447696693175 0.1398468516011775]

[0.0883753777458085 0.04904548599778935 … 0.1491798398622044 0.1356286642210447]

[0.04307841934760015 0.23843488823876902 … 0.07100604453707149 0.10657303350837899]

[0.08011629491969807 0.002209693151838721 … 0.07034051976001221 0.09775501631794592]

[0.02448989013587366 0.2669023614373067 … 0.06075737445959839 0.0681143783110707]

[0.241760678299896 0.027728912441334463 … 0.25891239475713723 0.15856023332837554]

[0.03980561593299914 0.1404699046045228 … 0.12622283933451128 0.12093813719415625], CartesianIndex{3}[CartesianIndex(4, 1, 1) CartesianIndex(8, 2, 1) … CartesianIndex(8, 7, 1) CartesianIndex(3, 8, 1)]

CartesianIndex{3}[CartesianIndex(3, 1, 2) CartesianIndex(3, 2, 2) … CartesianIndex(7, 7, 2) CartesianIndex(4, 8, 2)]

CartesianIndex{3}[CartesianIndex(1, 1, 3) CartesianIndex(3, 2, 3) … CartesianIndex(5, 7, 3) CartesianIndex(7, 8, 3)]

CartesianIndex{3}[CartesianIndex(7, 1, 4) CartesianIndex(2, 2, 4) … CartesianIndex(3, 7, 4) CartesianIndex(1, 8, 4)]

CartesianIndex{3}[CartesianIndex(5, 1, 5) CartesianIndex(7, 2, 5) … CartesianIndex(1, 7, 5) CartesianIndex(6, 8, 5)]

CartesianIndex{3}[CartesianIndex(5, 1, 6) CartesianIndex(7, 2, 6) … CartesianIndex(5, 7, 6) CartesianIndex(8, 8, 6)]

CartesianIndex{3}[CartesianIndex(1, 1, 7) CartesianIndex(3, 2, 7) … CartesianIndex(5, 7, 7) CartesianIndex(1, 8, 7)]

CartesianIndex{3}[CartesianIndex(1, 1, 8) CartesianIndex(2, 2, 8) … CartesianIndex(4, 7, 8) CartesianIndex(7, 8, 8)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
 [2] top-level scope
   @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
  Expression: argmax(a0, dims = i) == argmax(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 2, 1); CartesianIndex(2, 2, 1); … ; CartesianIndex(7, 7, 1); CartesianIndex(8, 6, 1)]

CartesianIndex{3}[CartesianIndex(1, 5, 2); CartesianIndex(2, 3, 2); … ; CartesianIndex(7, 6, 2); CartesianIndex(8, 2, 2)]

CartesianIndex{3}[CartesianIndex(1, 5, 3); CartesianIndex(2, 5, 3); … ; CartesianIndex(7, 3, 3); CartesianIndex(8, 1, 3)]

CartesianIndex{3}[CartesianIndex(1, 1, 4); CartesianIndex(2, 5, 4); … ; CartesianIndex(7, 6, 4); CartesianIndex(8, 4, 4)]

CartesianIndex{3}[CartesianIndex(1, 4, 5); CartesianIndex(2, 1, 5); … ; CartesianIndex(7, 5, 5); CartesianIndex(8, 7, 5)]

CartesianIndex{3}[CartesianIndex(1, 5, 6); CartesianIndex(2, 7, 6); … ; CartesianIndex(7, 7, 6); CartesianIndex(8, 6, 6)]

CartesianIndex{3}[CartesianIndex(1, 6, 7); CartesianIndex(2, 7, 7); … ; CartesianIndex(7, 3, 7); CartesianIndex(8, 1, 7)]

CartesianIndex{3}[CartesianIndex(1, 2, 8); CartesianIndex(2, 1, 8); … ; CartesianIndex(7, 1, 8); CartesianIndex(8, 4, 8)] == CartesianIndex{3}[CartesianIndex(1, 2, 1); CartesianIndex(2, 2, 1); … ; CartesianIndex(7, 7, 1); CartesianIndex(8, 6, 1)]

CartesianIndex{3}[CartesianIndex(1, 5, 2); CartesianIndex(2, 6, 2); … ; CartesianIndex(7, 6, 2); CartesianIndex(8, 2, 2)]

CartesianIndex{3}[CartesianIndex(1, 5, 3); CartesianIndex(2, 5, 3); … ; CartesianIndex(7, 3, 3); CartesianIndex(8, 1, 3)]

CartesianIndex{3}[CartesianIndex(1, 1, 4); CartesianIndex(2, 5, 4); … ; CartesianIndex(7, 6, 4); CartesianIndex(8, 4, 4)]

CartesianIndex{3}[CartesianIndex(1, 4, 5); CartesianIndex(2, 1, 5); … ; CartesianIndex(7, 5, 5); CartesianIndex(8, 7, 5)]

CartesianIndex{3}[CartesianIndex(1, 5, 6); CartesianIndex(2, 7, 6); … ; CartesianIndex(7, 7, 6); CartesianIndex(8, 6, 6)]

CartesianIndex{3}[CartesianIndex(1, 6, 7); CartesianIndex(2, 7, 7); … ; CartesianIndex(7, 3, 7); CartesianIndex(8, 1, 7)]

CartesianIndex{3}[CartesianIndex(1, 2, 8); CartesianIndex(2, 1, 8); … ; CartesianIndex(7, 1, 8); CartesianIndex(8, 4, 8)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
 [2] top-level scope
   @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
  Expression: argmin(a0, dims = i) == argmin(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 5, 1); CartesianIndex(2, 7, 1); … ; CartesianIndex(7, 2, 1); CartesianIndex(8, 2, 1)]

CartesianIndex{3}[CartesianIndex(1, 3, 2); CartesianIndex(2, 5, 2); … ; CartesianIndex(7, 7, 2); CartesianIndex(8, 3, 2)]

CartesianIndex{3}[CartesianIndex(1, 1, 3); CartesianIndex(2, 1, 3); … ; CartesianIndex(7, 8, 3); CartesianIndex(8, 6, 3)]

CartesianIndex{3}[CartesianIndex(1, 3, 4); CartesianIndex(2, 3, 4); … ; CartesianIndex(7, 5, 4); CartesianIndex(8, 3, 4)]

CartesianIndex{3}[CartesianIndex(1, 7, 5); CartesianIndex(2, 2, 5); … ; CartesianIndex(7, 2, 5); CartesianIndex(8, 2, 5)]

CartesianIndex{3}[CartesianIndex(1, 6, 6); CartesianIndex(2, 1, 6); … ; CartesianIndex(7, 3, 6); CartesianIndex(8, 8, 6)]

CartesianIndex{3}[CartesianIndex(1, 8, 7); CartesianIndex(2, 3, 7); … ; CartesianIndex(7, 5, 7); CartesianIndex(8, 5, 7)]

CartesianIndex{3}[CartesianIndex(1, 1, 8); CartesianIndex(2, 3, 8); … ; CartesianIndex(7, 8, 8); CartesianIndex(8, 6, 8)] == CartesianIndex{3}[CartesianIndex(1, 5, 1); CartesianIndex(2, 7, 1); … ; CartesianIndex(7, 2, 1); CartesianIndex(8, 2, 1)]

CartesianIndex{3}[CartesianIndex(1, 3, 2); CartesianIndex(2, 3, 2); … ; CartesianIndex(7, 7, 2); CartesianIndex(8, 3, 2)]

CartesianIndex{3}[CartesianIndex(1, 1, 3); CartesianIndex(2, 1, 3); … ; CartesianIndex(7, 8, 3); CartesianIndex(8, 6, 3)]

CartesianIndex{3}[CartesianIndex(1, 3, 4); CartesianIndex(2, 2, 4); … ; CartesianIndex(7, 5, 4); CartesianIndex(8, 3, 4)]

CartesianIndex{3}[CartesianIndex(1, 7, 5); CartesianIndex(2, 2, 5); … ; CartesianIndex(7, 2, 5); CartesianIndex(8, 2, 5)]

CartesianIndex{3}[CartesianIndex(1, 6, 6); CartesianIndex(2, 1, 6); … ; CartesianIndex(7, 3, 6); CartesianIndex(8, 8, 6)]

CartesianIndex{3}[CartesianIndex(1, 8, 7); CartesianIndex(2, 3, 7); … ; CartesianIndex(7, 5, 7); CartesianIndex(8, 5, 7)]

CartesianIndex{3}[CartesianIndex(1, 1, 8); CartesianIndex(2, 3, 8); … ; CartesianIndex(7, 8, 8); CartesianIndex(8, 6, 8)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
 [2] top-level scope
   @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
  Expression: findmax(a0, dims = i) == findmax(a1, dims = i)
   Evaluated: ([0.590282358848728; 0.9038949733338475; … ; 0.7980123909272003; 0.9747012303119156]

[0.8917986691092941; 0.9600839321429395; … ; 0.9117912372121053; 0.9114783217097475]

[0.7685418944558948; 0.988215122639426; … ; 0.9517486691841521; 0.8804503275054871]

[0.9132709641551144; 0.9890000156733612; … ; 0.9781856543502603; 0.8114926427206952]

[0.9040096600772254; 0.9295112608866625; … ; 0.9693610042052316; 0.9920460576865235]

[0.9488242214240152; 0.8645724245263573; … ; 0.8618983638267195; 0.9626722920749566]

[0.9960950417741823; 0.9959626472627832; … ; 0.7039915276243205; 0.9505118042348875]

[0.7682950096064953; 0.9152504245450046; … ; 0.8817096290462945; 0.6799216211199501], CartesianIndex{3}[CartesianIndex(1, 2, 1); CartesianIndex(2, 2, 1); … ; CartesianIndex(7, 7, 1); CartesianIndex(8, 6, 1)]

CartesianIndex{3}[CartesianIndex(1, 5, 2); CartesianIndex(2, 3, 2); … ; CartesianIndex(7, 6, 2); CartesianIndex(8, 2, 2)]

CartesianIndex{3}[CartesianIndex(1, 5, 3); CartesianIndex(2, 5, 3); … ; CartesianIndex(7, 3, 3); CartesianIndex(8, 1, 3)]

CartesianIndex{3}[CartesianIndex(1, 1, 4); CartesianIndex(2, 5, 4); … ; CartesianIndex(7, 6, 4); CartesianIndex(8, 4, 4)]

CartesianIndex{3}[CartesianIndex(1, 4, 5); CartesianIndex(2, 1, 5); … ; CartesianIndex(7, 5, 5); CartesianIndex(8, 7, 5)]

CartesianIndex{3}[CartesianIndex(1, 5, 6); CartesianIndex(2, 7, 6); … ; CartesianIndex(7, 7, 6); CartesianIndex(8, 6, 6)]

CartesianIndex{3}[CartesianIndex(1, 6, 7); CartesianIndex(2, 7, 7); … ; CartesianIndex(7, 3, 7); CartesianIndex(8, 1, 7)]

CartesianIndex{3}[CartesianIndex(1, 2, 8); CartesianIndex(2, 1, 8); … ; CartesianIndex(7, 1, 8); CartesianIndex(8, 4, 8)]) == ([0.590282358848728; 0.9038949733338475; … ; 0.7980123909272003; 0.9747012303119156]

[0.8917986691092941; 0.931108929875542; … ; 0.9117912372121053; 0.9114783217097475]

[0.7685418944558948; 0.988215122639426; … ; 0.9517486691841521; 0.8804503275054871]

[0.9132709641551144; 0.9890000156733612; … ; 0.9781856543502603; 0.8114926427206952]

[0.9040096600772254; 0.9295112608866625; … ; 0.9693610042052316; 0.9920460576865235]

[0.9488242214240152; 0.8645724245263573; … ; 0.8618983638267195; 0.9626722920749566]

[0.9960950417741823; 0.9959626472627832; … ; 0.7039915276243205; 0.9505118042348875]

[0.7682950096064953; 0.9152504245450046; … ; 0.8817096290462945; 0.6799216211199501], CartesianIndex{3}[CartesianIndex(1, 2, 1); CartesianIndex(2, 2, 1); … ; CartesianIndex(7, 7, 1); CartesianIndex(8, 6, 1)]

CartesianIndex{3}[CartesianIndex(1, 5, 2); CartesianIndex(2, 6, 2); … ; CartesianIndex(7, 6, 2); CartesianIndex(8, 2, 2)]

CartesianIndex{3}[CartesianIndex(1, 5, 3); CartesianIndex(2, 5, 3); … ; CartesianIndex(7, 3, 3); CartesianIndex(8, 1, 3)]

CartesianIndex{3}[CartesianIndex(1, 1, 4); CartesianIndex(2, 5, 4); … ; CartesianIndex(7, 6, 4); CartesianIndex(8, 4, 4)]

CartesianIndex{3}[CartesianIndex(1, 4, 5); CartesianIndex(2, 1, 5); … ; CartesianIndex(7, 5, 5); CartesianIndex(8, 7, 5)]

CartesianIndex{3}[CartesianIndex(1, 5, 6); CartesianIndex(2, 7, 6); … ; CartesianIndex(7, 7, 6); CartesianIndex(8, 6, 6)]

CartesianIndex{3}[CartesianIndex(1, 6, 7); CartesianIndex(2, 7, 7); … ; CartesianIndex(7, 3, 7); CartesianIndex(8, 1, 7)]

CartesianIndex{3}[CartesianIndex(1, 2, 8); CartesianIndex(2, 1, 8); … ; CartesianIndex(7, 1, 8); CartesianIndex(8, 4, 8)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
 [2] top-level scope
   @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
  Expression: findmin(a0, dims = i) == findmin(a1, dims = i)
   Evaluated: ([0.14704471925616414; 0.10061575215343832; … ; 0.04994986853835437; 0.02253246200002934]

[0.07609472495229697; 0.26286407801553424; … ; 0.04964447696693175; 0.12498671510772996]

[0.0883753777458085; 0.12227378750828044; … ; 0.1356286642210447; 0.10621425959183117]

[0.08756667870386892; 0.044029649188539244; … ; 0.011069057339788024; 0.007870784879729031]

[0.07034051976001221; 0.13413317070102848; … ; 0.002209693151838721; 0.08859762752196687]

[0.03244600485511273; 0.10636157789806999; … ; 0.2519887990045562; 0.0681143783110707]

[0.15856023332837554; 0.0339942752023048; … ; 0.012841634411384417; 0.019445527170818044]

[0.03980561593299914; 0.022184600771628205; … ; 0.12093813719415625; 0.036321200028904155], CartesianIndex{3}[CartesianIndex(1, 5, 1); CartesianIndex(2, 7, 1); … ; CartesianIndex(7, 2, 1); CartesianIndex(8, 2, 1)]

CartesianIndex{3}[CartesianIndex(1, 3, 2); CartesianIndex(2, 5, 2); … ; CartesianIndex(7, 7, 2); CartesianIndex(8, 3, 2)]

CartesianIndex{3}[CartesianIndex(1, 1, 3); CartesianIndex(2, 1, 3); … ; CartesianIndex(7, 8, 3); CartesianIndex(8, 6, 3)]

CartesianIndex{3}[CartesianIndex(1, 3, 4); CartesianIndex(2, 3, 4); … ; CartesianIndex(7, 5, 4); CartesianIndex(8, 3, 4)]

CartesianIndex{3}[CartesianIndex(1, 7, 5); CartesianIndex(2, 2, 5); … ; CartesianIndex(7, 2, 5); CartesianIndex(8, 2, 5)]

CartesianIndex{3}[CartesianIndex(1, 6, 6); CartesianIndex(2, 1, 6); … ; CartesianIndex(7, 3, 6); CartesianIndex(8, 8, 6)]

CartesianIndex{3}[CartesianIndex(1, 8, 7); CartesianIndex(2, 3, 7); … ; CartesianIndex(7, 5, 7); CartesianIndex(8, 5, 7)]

CartesianIndex{3}[CartesianIndex(1, 1, 8); CartesianIndex(2, 3, 8); … ; CartesianIndex(7, 8, 8); CartesianIndex(8, 6, 8)]) == ([0.14704471925616414; 0.10061575215343832; … ; 0.04994986853835437; 0.02253246200002934]

[0.07609472495229697; 0.10399411027477523; … ; 0.04964447696693175; 0.12498671510772996]

[0.0883753777458085; 0.12227378750828044; … ; 0.1356286642210447; 0.10621425959183117]

[0.08756667870386892; 0.23843488823876902; … ; 0.011069057339788024; 0.007870784879729031]

[0.07034051976001221; 0.13413317070102848; … ; 0.002209693151838721; 0.08859762752196687]

[0.03244600485511273; 0.10636157789806999; … ; 0.2519887990045562; 0.0681143783110707]

[0.15856023332837554; 0.0339942752023048; … ; 0.012841634411384417; 0.019445527170818044]

[0.03980561593299914; 0.022184600771628205; … ; 0.12093813719415625; 0.036321200028904155], CartesianIndex{3}[CartesianIndex(1, 5, 1); CartesianIndex(2, 7, 1); … ; CartesianIndex(7, 2, 1); CartesianIndex(8, 2, 1)]

CartesianIndex{3}[CartesianIndex(1, 3, 2); CartesianIndex(2, 3, 2); … ; CartesianIndex(7, 7, 2); CartesianIndex(8, 3, 2)]

CartesianIndex{3}[CartesianIndex(1, 1, 3); CartesianIndex(2, 1, 3); … ; CartesianIndex(7, 8, 3); CartesianIndex(8, 6, 3)]

CartesianIndex{3}[CartesianIndex(1, 3, 4); CartesianIndex(2, 2, 4); … ; CartesianIndex(7, 5, 4); CartesianIndex(8, 3, 4)]

CartesianIndex{3}[CartesianIndex(1, 7, 5); CartesianIndex(2, 2, 5); … ; CartesianIndex(7, 2, 5); CartesianIndex(8, 2, 5)]

CartesianIndex{3}[CartesianIndex(1, 6, 6); CartesianIndex(2, 1, 6); … ; CartesianIndex(7, 3, 6); CartesianIndex(8, 8, 6)]

CartesianIndex{3}[CartesianIndex(1, 8, 7); CartesianIndex(2, 3, 7); … ; CartesianIndex(7, 5, 7); CartesianIndex(8, 5, 7)]

CartesianIndex{3}[CartesianIndex(1, 1, 8); CartesianIndex(2, 3, 8); … ; CartesianIndex(7, 8, 8); CartesianIndex(8, 6, 8)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
 [2] top-level scope
   @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
  Expression: argmax(a0, dims = i) == argmax(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 1, 4) CartesianIndex(1, 2, 5) … CartesianIndex(1, 7, 6) CartesianIndex(1, 8, 2); CartesianIndex(2, 1, 5) CartesianIndex(2, 2, 3) … CartesianIndex(2, 7, 7) CartesianIndex(2, 8, 7); … ; CartesianIndex(7, 1, 2) CartesianIndex(7, 2, 4) … CartesianIndex(7, 7, 6) CartesianIndex(7, 8, 6); CartesianIndex(8, 1, 1) CartesianIndex(8, 2, 2) … CartesianIndex(8, 7, 5) CartesianIndex(8, 8, 7)] == CartesianIndex{3}[CartesianIndex(1, 1, 4) CartesianIndex(1, 2, 5) … CartesianIndex(1, 7, 6) CartesianIndex(1, 8, 2); CartesianIndex(2, 1, 5) CartesianIndex(2, 2, 3) … CartesianIndex(2, 7, 7) CartesianIndex(2, 8, 7); … ; CartesianIndex(7, 1, 2) CartesianIndex(7, 2, 4) … CartesianIndex(7, 7, 6) CartesianIndex(7, 8, 6); CartesianIndex(8, 1, 1) CartesianIndex(8, 2, 2) … CartesianIndex(8, 7, 5) CartesianIndex(8, 8, 7)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
 [2] top-level scope
   @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
  Expression: argmin(a0, dims = i) == argmin(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 1, 8) CartesianIndex(1, 2, 4) … CartesianIndex(1, 7, 5) CartesianIndex(1, 8, 4); CartesianIndex(2, 1, 6) CartesianIndex(2, 2, 5) … CartesianIndex(2, 7, 1) CartesianIndex(2, 8, 4); … ; CartesianIndex(7, 1, 4) CartesianIndex(7, 2, 5) … CartesianIndex(7, 7, 2) CartesianIndex(7, 8, 8); CartesianIndex(8, 1, 2) CartesianIndex(8, 2, 1) … CartesianIndex(8, 7, 1) CartesianIndex(8, 8, 6)] == CartesianIndex{3}[CartesianIndex(1, 1, 8) CartesianIndex(1, 2, 4) … CartesianIndex(1, 7, 5) CartesianIndex(1, 8, 4); CartesianIndex(2, 1, 6) CartesianIndex(2, 2, 5) … CartesianIndex(2, 7, 1) CartesianIndex(2, 8, 4); … ; CartesianIndex(7, 1, 4) CartesianIndex(7, 2, 5) … CartesianIndex(7, 7, 2) CartesianIndex(7, 8, 8); CartesianIndex(8, 1, 2) CartesianIndex(8, 2, 1) … CartesianIndex(8, 7, 1) CartesianIndex(8, 8, 6)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
 [2] top-level scope
   @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
  Expression: findmax(a0, dims = i) == findmax(a1, dims = i)
   Evaluated: ([0.9132709641551144 0.8914418148542571 … 0.7501350338833179 0.782542121214354; 0.9295112608866625 0.9497246552650624 … 0.9959626472627832 0.9555122543162526; … ; 0.909588889699366 0.6763041325340906 … 0.8618983638267195 0.6931630376938496; 0.9546754666596038 0.9114783217097475 … 0.9920460576865235 0.5621320474757701], CartesianIndex{3}[CartesianIndex(1, 1, 4) CartesianIndex(1, 2, 5) … CartesianIndex(1, 7, 6) CartesianIndex(1, 8, 2); CartesianIndex(2, 1, 5) CartesianIndex(2, 2, 3) … CartesianIndex(2, 7, 7) CartesianIndex(2, 8, 7); … ; CartesianIndex(7, 1, 2) CartesianIndex(7, 2, 4) … CartesianIndex(7, 7, 6) CartesianIndex(7, 8, 6); CartesianIndex(8, 1, 1) CartesianIndex(8, 2, 2) … CartesianIndex(8, 7, 5) CartesianIndex(8, 8, 7)]) == ([0.9132709641551144 0.8914418148542571 … 0.7501350338833179 0.782542121214354; 0.9295112608866625 0.9164552838084328 … 0.9959626472627832 0.9555122543162526; … ; 0.909588889699366 0.6763041325340906 … 0.8618983638267195 0.6931630376938496; 0.9546754666596038 0.9114783217097475 … 0.9920460576865235 0.5621320474757701], CartesianIndex{3}[CartesianIndex(1, 1, 4) CartesianIndex(1, 2, 5) … CartesianIndex(1, 7, 6) CartesianIndex(1, 8, 2); CartesianIndex(2, 1, 5) CartesianIndex(2, 2, 3) … CartesianIndex(2, 7, 7) CartesianIndex(2, 8, 7); … ; CartesianIndex(7, 1, 2) CartesianIndex(7, 2, 4) … CartesianIndex(7, 7, 6) CartesianIndex(7, 8, 6); CartesianIndex(8, 1, 1) CartesianIndex(8, 2, 2) … CartesianIndex(8, 7, 5) CartesianIndex(8, 8, 7)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
 [2] top-level scope
   @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
  Expression: findmin(a0, dims = i) == findmin(a1, dims = i)
   Evaluated: ([0.03980561593299914 0.2688994428597744 … 0.07034051976001221 0.10657303350837899; 0.10636157789806999 0.13413317070102848 … 0.10061575215343832 0.381121807975346; … ; 0.04307841934760015 0.002209693151838721 … 0.04964447696693175 0.12093813719415625; 0.18315272014360406 0.02253246200002934 … 0.03660688595480299 0.0681143783110707], CartesianIndex{3}[CartesianIndex(1, 1, 8) CartesianIndex(1, 2, 4) … CartesianIndex(1, 7, 5) CartesianIndex(1, 8, 4); CartesianIndex(2, 1, 6) CartesianIndex(2, 2, 5) … CartesianIndex(2, 7, 1) CartesianIndex(2, 8, 4); … ; CartesianIndex(7, 1, 4) CartesianIndex(7, 2, 5) … CartesianIndex(7, 7, 2) CartesianIndex(7, 8, 8); CartesianIndex(8, 1, 2) CartesianIndex(8, 2, 1) … CartesianIndex(8, 7, 1) CartesianIndex(8, 8, 6)]) == ([0.03980561593299914 0.2688994428597744 … 0.07034051976001221 0.10657303350837899; 0.10636157789806999 0.13413317070102848 … 0.10061575215343832 0.381121807975346; … ; 0.04307841934760015 0.002209693151838721 … 0.04964447696693175 0.12093813719415625; 0.18315272014360406 0.02253246200002934 … 0.03660688595480299 0.0681143783110707], CartesianIndex{3}[CartesianIndex(1, 1, 8) CartesianIndex(1, 2, 4) … CartesianIndex(1, 7, 5) CartesianIndex(1, 8, 4); CartesianIndex(2, 1, 6) CartesianIndex(2, 2, 5) … CartesianIndex(2, 7, 1) CartesianIndex(2, 8, 4); … ; CartesianIndex(7, 1, 4) CartesianIndex(7, 2, 5) … CartesianIndex(7, 7, 2) CartesianIndex(7, 8, 8); CartesianIndex(8, 1, 2) CartesianIndex(8, 2, 1) … CartesianIndex(8, 7, 1) CartesianIndex(8, 8, 6)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
 [2] top-level scope
   @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 42.693230 seconds (22.12 M allocations: 1.291 GiB, 3.00% gc time)
update.jl	┌ Warning: optimizers is deprecated, use sgd, adam etc. instead.
└ @ Knet.Train20 ~/.julia/packages/Knet/Mfd6L/src/train20/update.jl:598
 75.810946 seconds (63.80 M allocations: 3.077 GiB, 5.11% gc time)
linalg.jl	Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4448
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3930
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4129 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6699
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7059
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7093
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr at /workspace/srcdir/src/jitlayers.cpp:313
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1888
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7ff4dc29f1ef)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
unknown function (ip: 0x7ff4dc29eb33)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
unknown function (ip: 0x7ff4dc29e90c)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7ff4dc29e744)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7ff4dc29e487)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
p2 at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
unknown function (ip: 0x7ff4dc29de2f)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:88 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_15030.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1752 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4448
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3930
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4129 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6699
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7059
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7093
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /workspace/srcdir/src/jitlayers.cpp:350
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1894
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7ff4dc29f1ef)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
unknown function (ip: 0x7ff4dc29eb33)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
unknown function (ip: 0x7ff4dc29e90c)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7ff4dc29e744)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7ff4dc29e487)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
p2 at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
unknown function (ip: 0x7ff4dc29de2f)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:88 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_15030.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1752 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:88
  Test threw exception
  Expression: isapprox(p2(a), Array(p2(ka)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p2#141"{Vector{Int64}})(x::Knet.KnetArrays.KnetMatrix{Float32})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:88
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float32}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p2#141"{Vector{Int64}})(x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
 [34] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p2#141"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
  Test threw exception
  Expression: gradcheck(p2, ka)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float32}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p2#141"{Vector{Int64}})(x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
   [34] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p2#141"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:88
  Test threw exception
  Expression: isapprox(p2(a), Array(p2(ka)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p2#141"{Vector{Int64}})(x::Knet.KnetArrays.KnetMatrix{Float32})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:88
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float32}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p2#141"{Vector{Int64}})(x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
 [34] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p2#141"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
  Test threw exception
  Expression: gradcheck(p2, ka)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float32}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p2#141"{Vector{Int64}})(x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
   [34] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p2#141"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4448
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3930
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4129 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6699
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7059
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7093
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr at /workspace/srcdir/src/jitlayers.cpp:313
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1888
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7ff4dc2aea9f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
unknown function (ip: 0x7ff4dc2ae3c3)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
unknown function (ip: 0x7ff4dc2ae19c)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7ff4dc2adfc4)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7ff4dc2add07)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
p4 at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
unknown function (ip: 0x7ff4dc2ad6af)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_15030.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1752 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4448
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3930
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4129 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6699
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7059
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7093
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /workspace/srcdir/src/jitlayers.cpp:350
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1894
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7ff4dc2aea9f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
unknown function (ip: 0x7ff4dc2ae3c3)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
unknown function (ip: 0x7ff4dc2ae19c)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7ff4dc2adfc4)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7ff4dc2add07)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
p4 at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
unknown function (ip: 0x7ff4dc2ad6af)
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1752 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_15030.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1752 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
  Test threw exception
  Expression: gradcheck(p4, k4)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,4})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,4})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
  Test threw exception
  Expression: gradcheck(p4, k4)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,4})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,4})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
  Test threw exception
  Expression: gradcheck(p4, k4)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,4})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,4})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
  Test threw exception
  Expression: gradcheck(p4, k4)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,4})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,4})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
  Test threw exception
  Expression: gradcheck(p4, k4)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,4})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,4})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/d6WNR/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260

signal (15): Terminated
in expression starting at none:16
pthread_cond_wait at /lib/x86_64-linux-gnu/libpthread.so.0 (unknown line)
